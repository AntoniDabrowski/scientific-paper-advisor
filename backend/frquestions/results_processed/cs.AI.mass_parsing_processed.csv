Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
92,"So we further study the influence of the change of p under the interval-value
generalized orthogonal fuzzy environment on the group decision-making method in this paper.","From the formula of the IVq-ROFYWA operator, we can see that there is also p that affects

the aggregation.","When q=3 and p takes 1, 2, 3, 4, and 5 respectively, calculate the changed values of ùõº and ùõΩ
multiple times , The score ranking and the ranking results of the schemes are shown in Table 17.",2022-01-04 08:11:28+00:00,A integrating critic-waspas group decision making method under interval-valued q-rung orthogonal fuzzy enviroment,cs.AI,['cs.AI'],"[arxiv.Result.Author('Benting Wan'), arxiv.Result.Author('Shufen Zhou')]","This paper provides a new tool for multi-attribute multi-objective group
decision-making with unknown weights and attributes' weights. An
interval-valued generalized orthogonal fuzzy group decision-making method is
proposed based on the Yager operator and CRITIC-WASPAS method with unknown
weights. The method integrates Yager operator, CRITIC, WASPAS, and interval
value generalized orthogonal fuzzy group. Its merits lie in allowing
decision-makers greater freedom, avoiding bias due to decision-makers' weight,
and yielding accurate evaluation. The research includes: expanding the interval
value generalized distance measurement method for comparison and application of
similarity measurement and decision-making methods; developing a new scoring
function for comparing the size of interval value generalized orthogonal fuzzy
numbers,and further existing researches. The proposed interval-valued Yager
weighted average operator (IVq-ROFYWA) and Yager weighted geometric average
operator (IVq-ROFYWG) are used for information aggregation. The CRITIC-WASPAS
combines the advantages of CRITIC and WASPAS, which not only work in the single
decision but also serve as the basis of the group decision. The in-depth study
of the decision-maker's weight matrix overcomes the shortcomings of taking the
decision as a whole, and weighs the decision-maker's information aggregation.
Finally, the group decision algorithm is used for hypertension risk management.
The results are consistent with decision-makers' opinions. Practice and case
analysis have proved the effectiveness of the method proposed in this paper. At
the same time, it is compared with other operators and decision-making methods,
which proves the method effective and feasible.",-0.16270022,0.3337716,0.08400593,B
176,"3.2.3 Stable Deep Value-Based Learning

These considerations discouraged further research in deep reinforcement learn-
ing for many years.","With function approximation convergence may be even slower, due to values being
assigned to incorrect states.","Instead, research focused on linear function approximators,
which have better convergence guarantees.",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.39634442,0.060295377,0.13736838,C
177,"The DeepMind control suite is especially designed for further research
in the eld [756, 510, 507, 509, 508].","In addition to learning from state derived features, results are presented where
the agent learns from 84 √ó 84 pixel information, in a simulated form of visuo-motor
interaction.","Other environment suites are Meta-World [863],
Surreal [233], RLbench [374].",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.4957313,-0.19347504,0.098784626,C
178,"Furthermore, in some experiments with a large number of time steps performance
of model-based methods plateaus well below model-free performance, indicating
the need for further research.","The score that the
policy achieves varies greatly for di erent problems, and is sensitive to di erent
hyperparameter values.","Additionally, the performance of the model-based
methods themselves di ered substantially, also indicating a need for further research.",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",-0.07033841,0.18225384,-0.028739862,B
179,"Additionally, the performance of the model-based
methods themselves di ered substantially, also indicating a need for further research.","Furthermore, in some experiments with a large number of time steps performance
of model-based methods plateaus well below model-free performance, indicating
the need for further research.","Recent surveys are [528, 600].",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",-0.102895476,0.15385866,-0.037866157,B
180,"This new result, tabula rasa learning in Go with a pure self-play design, inspired
much further research in self-play reinforcement learning.","The program was called AlphaGo Zero, since it
learned from zero-knowledge; not a single grandmaster game was learned from,
nor was there any heuristic domain knowledge hand coded into the program.","6.3.2 AlphaGo Zero Performance

In their paper Silver et al.",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.3259203,0.08963821,0.23164767,C
181,"For further research in multi-agent systems refer
to [846, 792].","A related eld is
swarm intelligence, where communication between homogeneous agents is tak-
ing place [405, 217, 207, 78].","For collective intelligence, see, for example, [405, 208, 257, 847, 598].",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.14142221,0.30598158,0.21688929,B
182,"8.3 Four Rooms, and One Room with Subpolicy and Subgoal [744]

   The promising results stimulate further research in deep hierarchical methods,
and more benchmark studies of large problems are needed.","8.3 Hierarchical Environments  235

Fig.","Let us have a closer
look at the environments that have been used so far.",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.22572848,0.17587122,-0.16987205,C
183,"The
design has spawned much further research, as well as inspired general interest in
arti cial intelligence and reinforcement learning [213, 463, 686, 551, 454, 238, 678,
384].","The AlphaZero design includes an MCTS planner
in a self-play loop that improves a dual-headed deep residual network [703].","10.2.3 Hierarchical Reinforcement Learning

Team play is important in multi-agent problems, and hierarchical approaches can
structure the environment in a hierarchy of agents.",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.52622116,0.19064566,0.25633326,C
184,"Optimization-based
methods such as MAML learn better initial network parameters for new tasks, and
have spawned much further research.","In the elds of image recognition and natural language processing it has become
common practice to use networks that are pretrained on ImageNet [191, 236]
or BERT [193] or other large pretrained networks [547, 92].","Zero-shot learning is a meta-learning approach where outside information is
learned, such as attributes or a textual description for image content, that is then
used to recognize individuals from a new class [635, 718, 850, 10].",2022-01-04 11:47:21+00:00,Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.29204333,-0.28716376,-0.14147487,C
185,"3.2.3 Stable Deep Value-Based Learning

These considerations discouraged further research in deep reinforcement learn-
ing for many years.","With function approximation convergence may be even slower, due to values being
assigned to incorrect states.","Instead, research focused for some time on linear function
approximators, which have better convergence guarantees.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.39555433,0.06399143,0.13100156,C
186,"The DeepMind control suite is especially designed for further research
in the eld [757, 511, 508, 510, 509].","In addition to learning from state derived features, results are presented where
the agent learns from 84 √ó 84 pixel information, in a simulated form of visuo-motor
interaction.","Other environment suites are Meta-World [864],
Surreal [234], RLbench [375].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.4970827,-0.1944938,0.09787378,C_centroid
187,"There is a need for further research in deep model-based methods,
especially into robustness of results.","Another nding is that in some experiments with a large number of time steps,
the performance of model-based methods plateaus well below model-free per-
formance, and the performance of the model-based methods themselves di ers
substantially.","More benchmarking studies are needed that
compare di erent methods.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.19610366,-0.07069565,-0.26523054,C
188,"This new result, tabula rasa learning in Go with a pure self-play design, inspired
much further research in self-play reinforcement learning.","The program was called AlphaGo Zero, since it learned
from zero-knowledge; not a single grandmaster game was learned from, nor was
there any heuristic domain knowledge hand coded into the program.","6.3.2 AlphaGo Zero Performance

In their paper Silver et al.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.3259203,0.08963821,0.23164767,C
189,"For further research in multi-agent systems refer
to [847, 793].","A related eld is
swarm intelligence, where communication between homogeneous agents is tak-
ing place [406, 217, 207, 78].","For collective intelligence, see, for example [406, 208, 258, 848, 599].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.13171566,0.3062665,0.21929471,B
190,"The promising results stimulate further research in deep hierarchical methods,
and more benchmark studies of large problems are needed.","Many promising methods have
been discussed, and most report to outperform one or more at baseline algorithms.","Let us have a closer
look at the environments that have been used so far.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.30718493,0.08745867,-0.31707913,C
191,"The
design has spawned much further research, as well as inspired general interest in
arti cial intelligence and reinforcement learning [213, 464, 687, 552, 455, 239, 679,
385].","The AlphaZero design includes an MCTS planner
in a self-play loop that improves a dual-headed deep residual network [704].","10.2.3 Hierarchical Reinforcement Learning

Team play is important in multi-agent problems, and hierarchical approaches can
structure the environment in a hierarchy of agents.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.5191817,0.19586745,0.25644982,C
192,"Optimization-based
methods such as MAML learn better initial network parameters for new tasks, and
have spawned much further research.","In the elds of image recognition and natural language processing it has become
common practice to use networks that are pretrained on ImageNet [191, 237]
or BERT [193] or other large pretrained networks [548, 92].","Zero-shot learning is a meta-learning approach where outside information is
learned, such as attributes or a textual description for image content, that is then
used to recognize individuals from a new class [636, 719, 851, 10].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.29144207,-0.2882309,-0.14046085,C
193,"3.2.3 Stable Deep Value-Based Learning

These considerations discouraged further research in deep reinforcement learn-
ing for many years.","With function approximation convergence may be even slower, due to values being
assigned to incorrect states.","Instead, research focused for some time on linear function
approximators, which have better convergence guarantees.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.39555433,0.06399143,0.13100156,C
194,"The DeepMind control suite is especially designed for further research
in the eld [757, 511, 508, 510, 509].","In addition to learning from state derived features, results are presented where
the agent learns from 84 √ó 84 pixel information, in a simulated form of visuo-motor
interaction.","Other environment suites are Meta-World [864],
Surreal [234], RLbench [375].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.4970827,-0.1944938,0.09787378,C
195,"There is a need for further research in deep model-based methods,
especially into robustness of results.","Another nding is that in some experiments with a large number of time steps,
the performance of model-based methods plateaus well below model-free per-
formance, and the performance of the model-based methods themselves di ers
substantially.","More benchmarking studies are needed that
compare di erent methods.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.19610366,-0.07069565,-0.26523054,C
196,"This new result, tabula rasa learning in Go with a pure self-play design, inspired
much further research in self-play reinforcement learning.","The program was called AlphaGo Zero, since it learned
from zero-knowledge; not a single grandmaster game was learned from, nor was
there any heuristic domain knowledge hand coded into the program.","6.3.2 AlphaGo Zero Performance

In their paper Silver et al.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.3259203,0.08963821,0.23164767,C
197,"For further research in multi-agent systems refer
to [847, 793].","A related eld is
swarm intelligence, where communication between homogeneous agents is tak-
ing place [406, 217, 207, 78].","For collective intelligence, see, for example [406, 208, 258, 848, 599].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.13171566,0.3062665,0.21929471,B
198,"The promising results stimulate further research in deep hierarchical methods,
and more benchmark studies of large problems are needed.","Many promising methods have
been discussed, and most report to outperform one or more at baseline algorithms.","Let us have a closer
look at the environments that have been used so far.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.30718493,0.08745867,-0.31707913,C
199,"The
design has spawned much further research, as well as inspired general interest in
arti cial intelligence and reinforcement learning [213, 464, 687, 552, 455, 239, 679,
385].","The AlphaZero design includes an MCTS planner
in a self-play loop that improves a dual-headed deep residual network [704].","10.2.3 Hierarchical Reinforcement Learning

Team play is important in multi-agent problems, and hierarchical approaches can
structure the environment in a hierarchy of agents.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.5191817,0.19586745,0.25644982,C
200,"Optimization-based
methods such as MAML learn better initial network parameters for new tasks, and
have spawned much further research.","In the elds of image recognition and natural language processing it has become
common practice to use networks that are pretrained on ImageNet [191, 237]
or BERT [193] or other large pretrained networks [548, 92].","Zero-shot learning is a meta-learning approach where outside information is
learned, such as attributes or a textual description for image content, that is then
used to recognize individuals from a new class [636, 719, 851, 10].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.29144207,-0.2882309,-0.14046085,C
201,"3.2.3 Stable Deep Value-Based Learning

These considerations discouraged further research in deep reinforcement learn-
ing for many years.","With function approximation convergence may be even slower, due to values being
assigned to incorrect states.","Instead, research focused for some time on linear function
approximators, which have better convergence guarantees.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.39555433,0.06399143,0.13100156,C
202,"The DeepMind control suite is especially designed for further research
in the eld [757, 511, 508, 510, 509].","In addition to learning from state derived features, results are presented where
the agent learns from 84 √ó 84 pixel information, in a simulated form of visuo-motor
interaction.","Other environment suites are Meta-World [864],
Surreal [234], RLbench [375].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.4970827,-0.1944938,0.09787378,C
203,"There is a need for further research in deep model-based methods,
especially into robustness of results.","Another nding is that in some experiments with a large number of time steps,
the performance of model-based methods plateaus well below model-free per-
formance, and the performance of the model-based methods themselves di ers
substantially.","More benchmarking studies are needed that
compare di erent methods.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.19610366,-0.07069565,-0.26523054,C
204,"This new result, tabula rasa learning in Go with a pure self-play design, inspired
much further research in self-play reinforcement learning.","The program was called AlphaGo Zero, since it learned
from zero-knowledge; not a single grandmaster game was learned from, nor was
there any heuristic domain knowledge hand coded into the program.","6.3.2 AlphaGo Zero Performance

In their paper Silver et al.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.3259203,0.08963821,0.23164767,C
205,"For further research in multi-agent systems refer
to [847, 793].","A related eld is
swarm intelligence, where communication between homogeneous agents is tak-
ing place [406, 217, 207, 78].","For collective intelligence, see, for example [406, 208, 258, 848, 599].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.13171566,0.3062665,0.21929471,B
206,"The promising results stimulate further research in deep hierarchical methods,
and more benchmark studies of large problems are needed.","Many promising methods have
been discussed, and most report to outperform one or more at baseline algorithms.","Let us have a closer
look at the environments that have been used so far.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.30718493,0.08745867,-0.31707913,C
207,"The
design has spawned much further research, as well as inspired general interest in
arti cial intelligence and reinforcement learning [213, 464, 687, 552, 455, 239, 679,
385].","The AlphaZero design includes an MCTS planner
in a self-play loop that improves a dual-headed deep residual network [704].","10.2.3 Hierarchical Reinforcement Learning

Team play is important in multi-agent problems, and hierarchical approaches can
structure the environment in a hierarchy of agents.",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.5191817,0.19586745,0.25644982,C
208,"Optimization-based
methods such as MAML learn better initial network parameters for new tasks, and
have spawned much further research.","In the elds of image recognition and natural language processing it has become
common practice to use networks that are pretrained on ImageNet [191, 237]
or BERT [193] or other large pretrained networks [548, 92].","Zero-shot learning is a meta-learning approach where outside information is
learned, such as attributes or a textual description for image content, that is then
used to recognize individuals from a new class [636, 719, 851, 10].",2022-01-04 11:47:21+00:00,"Deep Reinforcement Learning, a textbook",cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Aske Plaat')],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",0.29144207,-0.2882309,-0.14046085,C
674,"Moreover,

34
the different definitions of ‚Äòreproducible‚Äô in previous studies and various evaluation metrics greatly
hinder the method comparison for further research.","For instance, as
shown in Table 4, more than half of the radiomic studies did not report the image scale.","35
8.",2022-01-17 16:30:15+00:00,"Data Harmonisation for Information Fusion in Digital Healthcare: A State-of-the-Art Systematic Review, Meta-Analysis and Future Research Directions",cs.AI,"['cs.AI', 'cs.CV']","[arxiv.Result.Author('Yang Nan'), arxiv.Result.Author('Javier Del Ser'), arxiv.Result.Author('Simon Walsh'), arxiv.Result.Author('Carola Sch√∂nlieb'), arxiv.Result.Author('Michael Roberts'), arxiv.Result.Author('Ian Selby'), arxiv.Result.Author('Kit Howard'), arxiv.Result.Author('John Owen'), arxiv.Result.Author('Jon Neville'), arxiv.Result.Author('Julien Guiot'), arxiv.Result.Author('Benoit Ernst'), arxiv.Result.Author('Ana Pastor'), arxiv.Result.Author('Angel Alberich-Bayarri'), arxiv.Result.Author('Marion I. Menzel'), arxiv.Result.Author('Sean Walsh'), arxiv.Result.Author('Wim Vos'), arxiv.Result.Author('Nina Flerin'), arxiv.Result.Author('Jean-Paul Charbonnier'), arxiv.Result.Author('Eva van Rikxoort'), arxiv.Result.Author('Avishek Chatterjee'), arxiv.Result.Author('Henry Woodruff'), arxiv.Result.Author('Philippe Lambin'), arxiv.Result.Author('Leonor Cerd√°-Alberich'), arxiv.Result.Author('Luis Mart√≠-Bonmat√≠'), arxiv.Result.Author('Francisco Herrera'), arxiv.Result.Author('Guang Yang')]","Removing the bias and variance of multicentre data has always been a
challenge in large scale digital healthcare studies, which requires the ability
to integrate clinical features extracted from data acquired by different
scanners and protocols to improve stability and robustness. Previous studies
have described various computational approaches to fuse single modality
multicentre datasets. However, these surveys rarely focused on evaluation
metrics and lacked a checklist for computational data harmonisation studies. In
this systematic review, we summarise the computational data harmonisation
approaches for multi-modality data in the digital healthcare field, including
harmonisation strategies and evaluation metrics based on different theories. In
addition, a comprehensive checklist that summarises common practices for data
harmonisation studies is proposed to guide researchers to report their research
findings more effectively. Last but not least, flowcharts presenting possible
ways for methodology and metric selection are proposed and the limitations of
different methods have been surveyed for future research.",-0.30137223,-0.06543248,-0.019860791,A
774,"The system is meant to provide a uniÔ¨Åed and up-to-date site
for current contributions, so as to facilitate and encourage further research and future comparisons.","All data, properly validated and timestamped, is available for download
and inspection, along with scoreboards and statistics.","OPTHUB, whose
development is still ongoing, currently hosts four of the formulations discussed in this survey.",2022-01-19 11:00:24+00:00,"Educational Timetabling: Problems, Benchmarks, and State-of-the-Art Results",cs.AI,"['cs.AI', 'cs.DM']","[arxiv.Result.Author('Sara Ceschia'), arxiv.Result.Author('Luca Di Gaspero'), arxiv.Result.Author('Andrea Schaerf')]","We propose a survey of the research contributions on the field of Educational
Timetabling with a specific focus on ""standard"" formulations and the
corresponding benchmark instances. We identify six of such formulations and we
discuss their features, pointing out their relevance and usability. Other
available formulations and datasets are also reviewed and briefly discussed.
Subsequently, we report the main state-of-the-art results on the selected
benchmarks, in terms of solution quality (upper and lower bounds), search
techniques, running times, statistical distributions, and other side settings.",-0.2279126,0.051173583,-0.059160862,A
843,"However, some improvement can be carried out and further research should focus on the
following aspects:

    ‚Ä¢ By exploiting the social network curiously, a curiosity-driven recommender system should
       be capable of generalizing to unrated items or new users.","With some acceptable
expense of accuracy, curiosity-driven recommender system can outperform traditional methods in
terms of coverage, diversity and personalization, which are more desirable in real-world applications.","‚Ä¢ Besides various MF methods, there are other types of techniques such as collaborative deep
       learning [129] and collaborative topic regression [96, 128] performing better than MF.",2022-01-20 17:07:03+00:00,From Psychological Curiosity to Artificial Curiosity: Curiosity-Driven Learning in Artificial Intelligence Tasks,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Chenyu Sun'), arxiv.Result.Author('Hangwei Qian'), arxiv.Result.Author('Chunyan Miao')]","Psychological curiosity plays a significant role in human intelligence to
enhance learning through exploration and information acquisition. In the
Artificial Intelligence (AI) community, artificial curiosity provides a natural
intrinsic motivation for efficient learning as inspired by human cognitive
development; meanwhile, it can bridge the existing gap between AI research and
practical application scenarios, such as overfitting, poor generalization,
limited training samples, high computational cost, etc. As a result,
curiosity-driven learning (CDL) has become increasingly popular, where agents
are self-motivated to learn novel knowledge. In this paper, we first present a
comprehensive review on the psychological study of curiosity and summarize a
unified framework for quantifying curiosity as well as its arousal mechanism.
Based on the psychological principle, we further survey the literature of
existing CDL methods in the fields of Reinforcement Learning, Recommendation,
and Classification, where both advantages and disadvantages as well as future
work are discussed. As a result, this work provides fruitful insights for
future CDL research and yield possible directions for further improvement.",0.11292642,-0.13869743,-0.03784605,C
882,More involved decision heuristics are subject to further research.,"6 The decision can be made for example by considering the size of the already explored

   state space such that the expansion is stopped if a size threshold has been reached.","Under-Approximating Expected Total Rewards in POMDPs                   13

    Input : POMDP M = M, Z, O with M = S, Act , P, sinit , reward

         structure R, goal states G ‚äÜ S, under-approx.",2022-01-21 16:43:03+00:00,Under-Approximating Expected Total Rewards in POMDPs,cs.AI,"['cs.AI', 'cs.LO']","[arxiv.Result.Author('Alexander Bork'), arxiv.Result.Author('Joost-Pieter Katoen'), arxiv.Result.Author('Tim Quatmann')]","We consider the problem: is the optimal expected total reward to reach a goal
state in a partially observable Markov decision process (POMDP) below a given
threshold? We tackle this -- generally undecidable -- problem by computing
under-approximations on these total expected rewards. This is done by
abstracting finite unfoldings of the infinite belief MDP of the POMDP. The key
issue is to find a suitable under-approximation of the value function. We
provide two techniques: a simple (cut-off) technique that uses a good policy on
the POMDP, and a more advanced technique (belief clipping) that uses minimal
shifts of probabilities between beliefs. We use mixed-integer linear
programming (MILP) to find such minimal probability shifts and experimentally
show that our techniques scale quite well while providing tight lower bounds on
the expected total reward.",0.056121193,0.2696729,0.2133036,B
998,"Finally, the conclusions and directions for further research are discussed in Section 5.","The experimental setup and results are
described in Section 4.",2We will use the terms ‚ÄúASP‚Äù and ‚ÄúCR-Prolog‚Äù interchangeably in this paper.,2022-01-25 12:24:22+00:00,Combining Commonsense Reasoning and Knowledge Acquisition to Guide Deep Learning in Robotics,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG', 'cs.LO', 'cs.RO']","[arxiv.Result.Author('Mohan Sridharan'), arxiv.Result.Author('Tiago Mota')]","Algorithms based on deep network models are being used for many pattern
recognition and decision-making tasks in robotics and AI. Training these models
requires a large labeled dataset and considerable computational resources,
which are not readily available in many domains. Also, it is difficult to
explore the internal representations and reasoning mechanisms of these models.
As a step towards addressing the underlying knowledge representation,
reasoning, and learning challenges, the architecture described in this paper
draws inspiration from research in cognitive systems. As a motivating example,
we consider an assistive robot trying to reduce clutter in any given scene by
reasoning about the occlusion of objects and stability of object configurations
in an image of the scene. In this context, our architecture incrementally
learns and revises a grounding of the spatial relations between objects and
uses this grounding to extract spatial information from input images.
Non-monotonic logical reasoning with this information and incomplete
commonsense domain knowledge is used to make decisions about stability and
occlusion. For images that cannot be processed by such reasoning, regions
relevant to the tasks at hand are automatically identified and used to train
deep network models to make the desired decisions. Image regions used to train
the deep networks are also used to incrementally acquire previously unknown
state constraints that are merged with the existing knowledge for subsequent
reasoning. Experimental evaluation performed using simulated and real-world
images indicates that in comparison with baselines based just on deep networks,
our architecture improves reliability of decision making and reduces the effort
involved in training data-driven deep network models.",-0.23989908,0.14988819,-0.12892199,A
1005,"In this section, by means of transitive closure, we give the concept of transitive degree of a binary relation
to further study the relationship between a general binary relation and transitivity.","In view of this, authors presented the concept of transitive closure (See DeÔ¨Ånition 3) and investigated

                                                                      8
its property.",DeÔ¨Ånition 4.,2022-01-25 13:39:37+00:00,Comparison research on binary relations based on transitive degrees and cluster degrees,cs.AI,['cs.AI'],"[arxiv.Result.Author('Zhaohao Wang'), arxiv.Result.Author('Huifang Yue')]","Interval-valued information systems are generalized models of single-valued
information systems. By rough set approach, interval-valued information systems
have been extensively studied. Authors could establish many binary relations
from the same interval-valued information system. In this paper, we do some
researches on comparing these binary relations so as to provide numerical
scales for choosing suitable relations in dealing with interval-valued
information systems. Firstly, based on similarity degrees, we compare the most
common three binary relations induced from the same interval-valued information
system. Secondly, we propose the concepts of transitive degree and cluster
degree, and investigate their properties. Finally, we provide some methods to
compare binary relations by means of the transitive degree and the cluster
degree. Furthermore, we use these methods to analyze the most common three
relations induced from Face Recognition Dataset, and obtain that $RF_{B}
^{\lambda}$ is a good choice when we deal with an interval-valued information
system by means of rough set approach.",-0.34073633,0.088704675,-0.103588164,A
1186,"Possible directions for future work in this area may in-
With the aim of equipping neural modules with relational                volve further research on incorporating the attention mech-
                                                                        anism, which is additionally motivated by the impressive
                                                                        performance of attention-based models in other domains,
                                                                        e.g.",size.,"[100, 101, 102, 103].",2022-01-28 19:24:30+00:00,Deep Learning Methods for Abstract Visual Reasoning: A Survey on Raven's Progressive Matrices,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG', 'I.2; I.5.4; I.5.1']","[arxiv.Result.Author('Miko≈Çaj Ma≈Çki≈Ñski'), arxiv.Result.Author('Jacek Ma≈Ñdziuk')]","Abstract visual reasoning (AVR) domain encompasses problems solving which
requires the ability to reason about relations among entities present in a
given scene. While humans, generally, solve AVR tasks in a ``natural'' way,
even without prior experience, this type of problems has proven difficult for
current machine learning systems. The paper summarises recent progress in
applying deep learning methods to solving AVR problems, as a proxy for studying
machine intelligence. We focus on the most common type of AVR tasks -- the
Raven's Progressive Matrices (RPMs) -- and provide a comprehensive review of
the learning methods and deep neural models applied to solve RPMs, as well as,
the RPM benchmark sets. Performance analysis of the state-of-the-art approaches
to solving RPMs leads to formulation of certain insights and remarks on the
current and future trends in this area. We conclude the paper by demonstrating
how real-world problems can benefit from the discoveries of RPM studies.",0.17825852,-0.23129547,-0.1129718,C
1187,"Possible directions for future work in this area may in-  of the visual backbone for each image along RPM‚Äôs rows
volve further research on incorporating the attention mech-     and columns, respectively.","the sample  initial object representation is obtained by summing outputs
size.","Next, these representations are
anism, which is additionally motivated by the impressive        iteratively reÔ¨Åned using the contrast module.",2022-01-28 19:24:30+00:00,Deep Learning Methods for Abstract Visual Reasoning: A Survey on Raven's Progressive Matrices,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG', 'I.2; I.5.4; I.5.1']","[arxiv.Result.Author('Miko≈Çaj Ma≈Çki≈Ñski'), arxiv.Result.Author('Jacek Ma≈Ñdziuk')]","Abstract visual reasoning (AVR) domain encompasses problems solving which
requires the ability to reason about relations among entities present in a
given scene. While humans, generally, solve AVR tasks in a ""natural"" way, even
without prior experience, this type of problems has proven difficult for
current machine learning systems. The paper summarises recent progress in
applying deep learning methods to solving AVR problems, as a proxy for studying
machine intelligence. We focus on the most common type of AVR tasks -- the
Raven's Progressive Matrices (RPMs) -- and provide a comprehensive review of
the learning methods and deep neural models applied to solve RPMs, as well as,
the RPM benchmark sets. Performance analysis of the state-of-the-art approaches
to solving RPMs leads to formulation of certain insights and remarks on the
current and future trends in this area. We conclude the paper by demonstrating
how real-world problems can benefit from the discoveries of RPM studies.",0.11218585,-0.15319969,-0.21783909,C
1239,"Only further research will clarify the implications
of one approach as opposed to the other.","Indeed, metacognition
may be a self-reflective aspect of cognition itself.",6.,2022-01-30 17:34:53+00:00,Computational Metacognition,cs.AI,"['cs.AI', 'I.2.8']","[arxiv.Result.Author('Michael Cox'), arxiv.Result.Author('Zahiduddin Mohammad'), arxiv.Result.Author('Sravya Kondrakunta'), arxiv.Result.Author('Ventaksamapth Raja Gogineni'), arxiv.Result.Author('Dustin Dannenhauer'), arxiv.Result.Author('Othalia Larue')]","Computational metacognition represents a cognitive systems perspective on
high-order reasoning in integrated artificial systems that seeks to leverage
ideas from human metacognition and from metareasoning approaches in artificial
intelligence. The key characteristic is to declaratively represent and then
monitor traces of cognitive activity in an intelligent system in order to
manage the performance of cognition itself. Improvements in cognition then lead
to improvements in behavior and thus performance. We illustrate these concepts
with an agent implementation in a cognitive architecture called MIDCA and show
the value of metacognition in problem-solving. The results illustrate how
computational metacognition improves performance by changing cognition through
meta-level goal operations and learning.",-0.17285544,-0.1604144,0.3123536,A
1359,"To make the approach applicable to larger data sets, further research in reducing
the run time is needed.","A serious limitation is the run time of our implemen-
tation.","Finally, the accuracy of the learned arguments for the Boston
Housing Dataset depends on the used discretization algorithm with DBSCAN giving
the highest performance.",2022-02-01 12:52:30+00:00,Explainable AI through the Learning of Arguments,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Jonas Bei'), arxiv.Result.Author('David Pomerenke'), arxiv.Result.Author('Lukas Schreiner'), arxiv.Result.Author('Sepideh Sharbaf'), arxiv.Result.Author('Pieter Collins'), arxiv.Result.Author('Nico Roos')]","Learning arguments is highly relevant to the field of explainable artificial
intelligence. It is a family of symbolic machine learning techniques that is
particularly human-interpretable. These techniques learn a set of arguments as
an intermediate representation. Arguments are small rules with exceptions that
can be chained to larger arguments for making predictions or decisions. We
investigate the learning of arguments, specifically the learning of arguments
from a 'case model' proposed by Verheij [34]. The case model in Verheij's
approach are cases or scenarios in a legal setting. The number of cases in a
case model are relatively low. Here, we investigate whether Verheij's approach
can be used for learning arguments from other types of data sets with a much
larger number of instances. We compare the learning of arguments from a case
model with the HeRO algorithm [15] and learning a decision tree.",-0.02172277,0.14921573,-0.28640297,B
1422,"An analysis of
                  these clause qualities, especially in the context of LBD [15], seems like a fruitful pursuit
                  for further research.","It seems reasonable that runtimes
                  are heavily influenced by the quality of the ‚Äúbest‚Äù and ‚Äúworst‚Äù clauses.","Supporting information

                  S1 File.",2022-02-01 10:16:04+00:00,Too much information: CDCL solvers need to forget and perform restarts,cs.AI,"['cs.AI', 'E.1; G.3; G.4; I.2.0']","[arxiv.Result.Author('Tom Kr√ºger'), arxiv.Result.Author('Jan-Hendrik Lorenz'), arxiv.Result.Author('Florian W√∂rz')]","Conflict-driven clause learning (CDCL) is a remarkably successful paradigm
for solving the satisfiability problem of propositional logic. Instead of a
simple depth-first backtracking approach, this kind of solver learns the reason
behind occurring conflicts in the form of additional clauses. However, despite
the enormous success of CDCL solvers, there is still only a shallow
understanding of what influences the performance of these solvers in what way.
  This paper will demonstrate, quite surprisingly, that clause learning
(without being able to get rid of some clauses) can not only improve the
runtime but can oftentimes deteriorate it dramatically. By conducting extensive
empirical analysis, we find that the runtime distributions of CDCL solvers are
multimodal. This multimodality can be seen as a reason for the deterioration
phenomenon described above. Simultaneously, it also gives an indication of why
clause learning in combination with clause deletion and restarts is virtually
the de facto standard of SAT solving in spite of this phenomenon. As a final
contribution, we will show that Weibull mixture distributions can accurately
describe the multimodal distributions. Thus, adding new clauses to a base
instance has an inherent effect of making runtimes long-tailed. This insight
provides a theoretical explanation as to why the techniques of restarts and
clause deletion are useful in CDCL solvers.",-0.2874208,0.075202085,-0.12083757,A
1423,"7 Conclusion and further research

               We have modeled the technique of clause learning in CDCL solvers by solving new
               logically equivalent formulas of a base instance.","However, this is only a hypothesis
               that should be further investigated in other future research.","This allowed us to analyze the resulting
               runtime distribution.",2022-02-01 10:16:04+00:00,Too much information: why CDCL solvers need to forget learned clauses,cs.AI,"['cs.AI', 'E.1; G.3; G.4; I.2.0']","[arxiv.Result.Author('Tom Kr√ºger'), arxiv.Result.Author('Jan-Hendrik Lorenz'), arxiv.Result.Author('Florian W√∂rz')]","Conflict-driven clause learning (CDCL) is a remarkably successful paradigm
for solving the satisfiability problem of propositional logic. Instead of a
simple depth-first backtracking approach, this kind of solver learns the reason
behind occurring conflicts in the form of additional clauses. However, despite
the enormous success of CDCL solvers, there is still only a limited
understanding of what influences the performance of these solvers in what way.
  Considering different measures, this paper demonstrates, quite surprisingly,
that clause learning (without being able to get rid of some clauses) can not
only help the solver but can oftentimes deteriorate the solution process
dramatically. By conducting extensive empirical analysis, we furthermore find
that the runtime distributions of CDCL solvers are multimodal. This
multimodality can be seen as a reason for the deterioration phenomenon
described above. Simultaneously, it also gives an indication of why clause
learning in combination with clause deletion is virtually the de facto standard
of SAT solving, in spite of this phenomenon. As a final contribution, we show
that Weibull mixture distributions can accurately describe the multimodal
distributions. Thus, adding new clauses to a base instance has an inherent
effect of making runtimes long-tailed. This insight provides an explanation as
to why the technique of forgetting clauses is useful in CDCL solvers apart from
the optimization of unit propagation speed.",0.021216571,0.047639154,-0.12342647,C
1424,"An analysis of
               these clause qualities, especially in the context of LBD [9], seems like a fruitful pursuit
               for further research.","It seems reasonable that runtimes
               are heavily influenced by the quality of the ‚Äúbest‚Äù and ‚Äúworst‚Äù clauses.","A refined approach in future research could also investigate the influence of different

June 20, 2022                                             23/31
               batches of learned clauses on the runtime (e. g., are clauses learned later always more
               helpful than clauses learned earlier ‚Äútowards the way of‚Äù a solution?).",2022-02-01 10:16:04+00:00,Too much information: why CDCL solvers need to forget learned clauses,cs.AI,"['cs.AI', 'E.1; G.3; G.4; I.2.0']","[arxiv.Result.Author('Tom Kr√ºger'), arxiv.Result.Author('Jan-Hendrik Lorenz'), arxiv.Result.Author('Florian W√∂rz')]","Conflict-driven clause learning (CDCL) is a remarkably successful paradigm
for solving the satisfiability problem of propositional logic. Instead of a
simple depth-first backtracking approach, this kind of solver learns the reason
behind occurring conflicts in the form of additional clauses. However, despite
the enormous success of CDCL solvers, there is still only a limited
understanding of what influences the performance of these solvers in what way.
  Considering different measures, this paper demonstrates, quite surprisingly,
that clause learning (without being able to get rid of some clauses) can not
only help the solver but can oftentimes deteriorate the solution process
dramatically. By conducting extensive empirical analysis, we furthermore find
that the runtime distributions of CDCL solvers are multimodal. This
multimodality can be seen as a reason for the deterioration phenomenon
described above. Simultaneously, it also gives an indication of why clause
learning in combination with clause deletion is virtually the de facto standard
of SAT solving, in spite of this phenomenon. As a final contribution, we show
that Weibull mixture distributions can accurately describe the multimodal
distributions. Thus, adding new clauses to a base instance has an inherent
effect of making runtimes long-tailed. This insight provides an explanation as
to why the technique of forgetting clauses is useful in CDCL solvers apart from
the optimization of unit propagation speed.",-0.11597404,0.025102895,-0.059814658,A
1725,the above are directions of the further research and development.,All               375‚Äì378.,"[12] Daniel Valcarce, Javier Parapar, and √Ålvaro Barreiro.",2022-02-08 21:09:36+00:00,Using a Language Model in a Kiosk Recommender System at Fast-Food Restaurants,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Author('Eduard Zubchuk'), arxiv.Result.Author('Dmitry Menshikov'), arxiv.Result.Author('Nikolay Mikhaylovskiy')]","Kiosks are a popular self-service option in many fast-food restaurants, they
save time for the visitors and save labor for the fast-food chains. In this
paper, we propose an effective design of a kiosk shopping cart recommender
system that combines a language model as a vectorizer and a neural
network-based classifier. The model performs better than other models in
offline tests and exhibits performance comparable to the best models in A/B/C
tests.",-0.070227034,0.04309747,0.041544326,A
1882,"straints representing the valid assignments is typically inde-
pendent of the user, it has to be compiled once for all and the                      Among the perspectives for further research, we plan to
resulting circuit can be considered without any change for a                      extend our top-k algorithms to a multicriteria setting, i.e.,
number of users (each of them characterized by his/her own                        when several value functions ŒΩi onto distinct sets Ki are
utility function ŒΩ).","However, since the set of con-                     the top-k solutions problem.",This heavily contrasts with the approach                     considered at the same time.,2022-02-11 23:53:43+00:00,Pseudo Polynomial-Time Top-k Algorithms for d-DNNF Circuits,cs.AI,['cs.AI'],"[arxiv.Result.Author('Pierre Bourhis'), arxiv.Result.Author('Laurence Duchien'), arxiv.Result.Author('J√©r√©mie Dusart'), arxiv.Result.Author('Emmanuel Lonca'), arxiv.Result.Author('Pierre Marquis'), arxiv.Result.Author('Cl√©ment Quinton')]","We are interested in computing $k$ most preferred models of a given d-DNNF
circuit $C$, where the preference relation is based on an algebraic structure
called a monotone, totally ordered, semigroup $(K, \otimes, <)$. In our
setting, every literal in $C$ has a value in $K$ and the value of an assignment
is an element of $K$ obtained by aggregating using $\otimes$ the values of the
corresponding literals. We present an algorithm that computes $k$ models of $C$
among those having the largest values w.r.t. $<$, and show that this algorithm
runs in time polynomial in $k$ and in the size of $C$. We also present a pseudo
polynomial-time algorithm for deriving the top-$k$ values that can be reached,
provided that an additional (but not very demanding) requirement on the
semigroup is satisfied. Under the same assumption, we present a pseudo
polynomial-time algorithm that transforms $C$ into a d-DNNF circuit $C'$
satisfied exactly by the models of $C$ having a value among the top-$k$ ones.
Finally, focusing on the semigroup $(\mathbb{N}, +, <)$, we compare on a large
number of instances the performances of our compilation-based algorithm for
computing $k$ top solutions with those of an algorithm tackling the same
problem, but based on a partial weighted MaxSAT solver.",-0.039669313,0.20039633,-0.22246784,B
1883,"Berlin,
   Among the perspectives for further research, we plan to      Heidelberg: Springer Berlin Heidelberg.","In Schulte, C., ed., Principles
                                                                and Practice of Constraint Programming, 247‚Äì262.","extend our top-k algorithms to a multicriteria setting, i.e.,
when several value functions ŒΩi onto distinct sets Ki are       Davies, J.",2022-02-11 23:53:43+00:00,Pseudo Polynomial-Time Top-k Algorithms for d-DNNF Circuits,cs.AI,['cs.AI'],"[arxiv.Result.Author('Pierre Bourhis'), arxiv.Result.Author('Laurence Duchien'), arxiv.Result.Author('J√©r√©mie Dusart'), arxiv.Result.Author('Emmanuel Lonca'), arxiv.Result.Author('Pierre Marquis'), arxiv.Result.Author('Cl√©ment Quinton')]","We are interested in computing $k$ most preferred models of a given d-DNNF
circuit $C$, where the preference relation is based on an algebraic structure
called a monotone, totally ordered, semigroup $(K, \otimes, <)$. In our
setting, every literal in $C$ has a value in $K$ and the value of an assignment
is an element of $K$ obtained by aggregating using $\otimes$ the values of the
corresponding literals. We present an algorithm that computes $k$ models of $C$
among those having the largest values w.r.t. $<$, and show that this algorithm
runs in time polynomial in $k$ and in the size of $C$. We also present a pseudo
polynomial-time algorithm for deriving the top-$k$ values that can be reached,
provided that an additional (but not very demanding) requirement on the
semigroup is satisfied. Under the same assumption, we present a pseudo
polynomial-time algorithm that transforms $C$ into a d-DNNF circuit $C'$
satisfied exactly by the models of $C$ having a value among the top-$k$ ones.
Finally, focusing on the semigroup $(\mathbb{N}, +, <)$, we compare on a large
number of instances the performances of our compilation-based algorithm for
computing $k$ top solutions with those of an algorithm tackling the same
problem, but based on a partial weighted MaxSAT solver.",-0.014162921,0.22395062,-0.3232767,B
1945,"Also, in the process of creating a datasheet for the BookCorpus, Bandy and Vincent
                                        [1] stated that further research is necessary to explore the detection of potential inappropriate concepts in text data.","[11]
                                        shows that careful manual documentation is difficult, if not even unfeasible, due to the immense size of current datasets:
                                        ‚ÄòWe manually checked 50K [out of 12M] random images in RedCaps and found one image containing nudity (exposed
                                        buttocks; no identifiable face)‚Äô.","Authors‚Äô addresses: Patrick Schramowski, schramowski@cs.tu-darmstadt.de, Technical University Darmstadt, Darmstadt, Germany; Christopher
                                        Tauchmann, Technical University Darmstadt, Darmstadt, Germany; Kristian Kersting, kersting@cs.tu-darmstadt.de, Technical University Darmstadt,
                                        Darmstadt, Germany.",2022-02-14 13:00:31+00:00,"Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?",cs.AI,"['cs.AI', 'cs.CV', 'cs.CY']","[arxiv.Result.Author('Patrick Schramowski'), arxiv.Result.Author('Christopher Tauchmann'), arxiv.Result.Author('Kristian Kersting')]","Large datasets underlying much of current machine learning raise serious
issues concerning inappropriate content such as offensive, insulting,
threatening, or might otherwise cause anxiety. This calls for increased dataset
documentation, e.g., using datasheets. They, among other topics, encourage to
reflect on the composition of the datasets. So far, this documentation,
however, is done manually and therefore can be tedious and error-prone,
especially for large image datasets. Here we ask the arguably ""circular""
question of whether a machine can help us reflect on inappropriate content,
answering Question 16 in Datasheets. To this end, we propose to use the
information stored in pre-trained transformer models to assist us in the
documentation process. Specifically, prompt-tuning based on a dataset of
socio-moral values steers CLIP to identify potentially inappropriate content,
therefore reducing human labor. We then document the inappropriate images found
using word clouds, based on captions generated using a vision-language model.
The documentations of two popular, large-scale computer vision datasets --
ImageNet and OpenImages -- produced this way suggest that machines can indeed
help dataset creators to answer Question 16 on inappropriate image content.",-0.26422894,-0.35948026,-0.12411365,A
1946,"Also, in the process of creating
                                        a datasheet for the BookCorpus, Bandy and Vincent [2021] stated that further research is necessary to explore the

                                                                                                                                    1
                                                                                                                                                                  Schramowski, et al.","[2021] shows that careful manual documentation is difficult, if not even
                                        unfeasible, due to the immense size of current datasets: ‚ÄòWe manually checked 50K [out of 12M] random images in
                                        RedCaps and found one image containing nudity (exposed buttocks; no identifiable face)‚Äô.",Fig.,2022-02-14 13:00:31+00:00,"Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?",cs.AI,"['cs.AI', 'cs.CV', 'cs.CY']","[arxiv.Result.Author('Patrick Schramowski'), arxiv.Result.Author('Christopher Tauchmann'), arxiv.Result.Author('Kristian Kersting')]","Large datasets underlying much of current machine learning raise serious
issues concerning inappropriate content such as offensive, insulting,
threatening, or might otherwise cause anxiety. This calls for increased dataset
documentation, e.g., using datasheets. They, among other topics, encourage to
reflect on the composition of the datasets. So far, this documentation,
however, is done manually and therefore can be tedious and error-prone,
especially for large image datasets. Here we ask the arguably ""circular""
question of whether a machine can help us reflect on inappropriate content,
answering Question 16 in Datasheets. To this end, we propose to use the
information stored in pre-trained transformer models to assist us in the
documentation process. Specifically, prompt-tuning based on a dataset of
socio-moral values steers CLIP to identify potentially inappropriate content,
therefore reducing human labor. We then document the inappropriate images found
using word clouds, based on captions generated using a vision-language model.
The documentations of two popular, large-scale computer vision datasets --
ImageNet and OpenImages -- produced this way suggest that machines can indeed
help dataset creators to answer Question 16 on inappropriate image content.",-0.21355914,-0.20676355,-0.13619418,A
1973,"Belousov and
Peters (2019) further study a particular class of f -divergence, called Œ±-divergence, resulting
in compatible policy update and value function improvement in the actor-critic methods.","Œ±-divergence has been extensively studied in RL context by Belousov
and Peters (2019), that propose to use it as the divergence measurement policy search,
generalizing the relative entropy policy search to constrain the policy update.",Lee et al.,2022-02-11 15:30:08+00:00,A Unified Perspective on Value Backup and Exploration in Monte-Carlo Tree Search,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Tuan Dam'), arxiv.Result.Author(""Carlo D'Eramo""), arxiv.Result.Author('Jan Peters'), arxiv.Result.Author('Joni Pajarinen')]","Monte-Carlo Tree Search (MCTS) is a class of methods for solving complex
decision-making problems through the synergy of Monte-Carlo planning and
Reinforcement Learning (RL). The highly combinatorial nature of the problems
commonly addressed by MCTS requires the use of efficient exploration strategies
for navigating the planning tree and quickly convergent value backup methods.
These crucial problems are particularly evident in recent advances that combine
MCTS with deep neural networks for function approximation. In this work, we
propose two methods for improving the convergence rate and exploration based on
a newly introduced backup operator and entropy regularization. We provide
strong theoretical guarantees to bound convergence rate, approximation error,
and regret of our methods. Moreover, we introduce a mathematical framework
based on the use of the $\alpha$-divergence for backup and exploration in MCTS.
We show that this theoretical formulation unifies different approaches,
including our newly introduced ones, under the same mathematical framework,
allowing to obtain different methods by simply changing the value of $\alpha$.
In practice, our unified perspective offers a flexible way to balance between
exploration and exploitation by tuning the single $\alpha$ parameter according
to the problem at hand. We validate our methods through a rigorous empirical
study from basic toy problems to the complex Atari games, and including both
MDP and POMDP problems.",0.19666283,0.1543341,0.196633,C
1987,"Still, further research on
comparing Contextual inÔ¨Çuence and AFA methods is interesting and ongoing.","Furthermore, there‚Äôs no additivity requirement on Contextual inÔ¨Çuence, even
though additivity could be imposed by normalization.","3 Experimental Evaluation

In this section we compare CIU, contextual inÔ¨Çuence, Shapley values and LIME
for three known functions that have two input features x1, x2 and one output
value y.",2022-02-15 10:18:21+00:00,Contextual Importance and Utility: aTheoretical Foundation,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Kary Fr√§mling')],"This paper provides new theory to support to the eXplainable AI (XAI) method
Contextual Importance and Utility (CIU). CIU arithmetic is based on the
concepts of Multi-Attribute Utility Theory, which gives CIU a solid theoretical
foundation. The novel concept of contextual influence is also defined, which
makes it possible to compare CIU directly with so-called additive feature
attribution (AFA) methods for model-agnostic outcome explanation. One key
takeaway is that the ""influence"" concept used by AFA methods is inadequate for
outcome explanation purposes even for simple models to explain. Experiments
with simple models show that explanations using contextual importance (CI) and
contextual utility (CU) produce explanations where influence-based methods
fail. It is also shown that CI and CU guarantees explanation faithfulness
towards the explained model.",-0.1644699,-0.11508004,-0.17726871,A
2006,"whether the model architecture could live without (at least
                                                                 some of) the hyperparameters, which is also a part of our
                                                                 further research.","However, it would be more interesting to investigate
ple efÔ¨Åciency of our model.","References

Chen, F.; Chen, S.; Gao, Y.; and Ma, Z.",2022-02-15 14:04:44+00:00,Interpretable Reinforcement Learning with Multilevel Subgoal Discovery,cs.AI,"['cs.AI', 'cs.LG', 'I.2.6']","[arxiv.Result.Author('Alexander Demin'), arxiv.Result.Author('Denis Ponomaryov')]","We propose a novel Reinforcement Learning model for discrete environments,
which is inherently interpretable and supports the discovery of deep subgoal
hierarchies. In the model, an agent learns information about environment in the
form of probabilistic rules, while policies for (sub)goals are learned as
combinations thereof. No reward function is required for learning; an agent
only needs to be given a primary goal to achieve. Subgoals of a goal G from the
hierarchy are computed as descriptions of states, which if previously achieved
increase the total efficiency of the available policies for G. These state
descriptions are introduced as new sensor predicates into the rule language of
the agent, which allows for sensing important intermediate states and for
updating environment rules and policies accordingly.",-0.026286641,0.19394767,-0.20626163,B
2062,"The rigorous development of
such a model is left for further research.","Such a model would allow us to reason with Gaussian probability
and possibility distributions as well as with linear equations.",1Ref.,2022-02-16 14:06:05+00:00,Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy sets: general framework and practical models,cs.AI,"['cs.AI', 'stat.ME']",[arxiv.Result.Author('Thierry Denoeux')],"We introduce a general theory of epistemic random fuzzy sets for reasoning
with fuzzy or crisp evidence. This framework generalizes both the
Dempster-Shafer theory of belief functions, and possibility theory. Independent
epistemic random fuzzy sets are combined by the generalized
product-intersection rule, which extends both Dempster's rule for combining
belief functions, and the product conjunctive combination of possibility
distributions. We introduce Gaussian random fuzzy numbers and their
multi-dimensional extensions, Gaussian random fuzzy vectors, as practical
models for quantifying uncertainty about scalar or vector quantities.
Closed-form expressions for the combination, projection and vacuous extension
of Gaussian random fuzzy numbers and vectors are derived.",-0.13407564,0.24652514,0.12612014,B
2063,"Finally, the extension
of the model introduced in this paper to take into account linear equations, as well as the
development of computational procedures for reasoning with GRFV‚Äôs over many variables
are promising avenues for further research.","We also consider using this framework in machine
learning, to quantify prediction uncertainty in regression problems.","References

References

 [1] P. A. Bromiley.",2022-02-16 14:06:05+00:00,Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy sets: general framework and practical models,cs.AI,"['cs.AI', 'stat.ME']",[arxiv.Result.Author('Thierry Denoeux')],"We introduce a general theory of epistemic random fuzzy sets for reasoning
with fuzzy or crisp evidence. This framework generalizes both the
Dempster-Shafer theory of belief functions, and possibility theory. Independent
epistemic random fuzzy sets are combined by the generalized
product-intersection rule, which extends both Dempster's rule for combining
belief functions, and the product conjunctive combination of possibility
distributions. We introduce Gaussian random fuzzy numbers and their
multi-dimensional extensions, Gaussian random fuzzy vectors, as practical
models for quantifying uncertainty about scalar or vector quantities.
Closed-form expressions for the combination, projection and vacuous extension
of Gaussian random fuzzy numbers and vectors are derived.",-0.07843093,0.02225238,-0.026025355,A
2064,"The rigorous development of
such a model is left for further research.","Such a model would allow us to reason with Gaussian probability
and possibility distributions as well as with linear equations.",1Ref.,2022-02-16 14:06:05+00:00,Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy sets: general framework and practical models,cs.AI,"['cs.AI', 'stat.ME']",[arxiv.Result.Author('Thierry Denoeux')],"We introduce a general theory of epistemic random fuzzy sets for reasoning
with fuzzy or crisp evidence. This framework generalizes both the
Dempster-Shafer theory of belief functions, and possibility theory. Independent
epistemic random fuzzy sets are combined by the generalized
product-intersection rule, which extends both Dempster's rule for combining
belief functions, and the product conjunctive combination of possibility
distributions. We introduce Gaussian random fuzzy numbers and their
multi-dimensional extensions, Gaussian random fuzzy vectors, as practical
models for quantifying uncertainty about scalar or vector quantities.
Closed-form expressions for the combination, projection and vacuous extension
of Gaussian random fuzzy numbers and vectors are derived.",-0.13407564,0.24652514,0.12612014,B
2065,"Finally, the extension
of the model introduced in this paper to take into account linear equations, as well as the
development of computational procedures for reasoning with GRFV‚Äôs over many variables
are promising avenues for further research.","We also consider using this framework in machine
learning, to quantify prediction uncertainty in regression problems.","References

References

 [1] P. A. Bromiley.",2022-02-16 14:06:05+00:00,Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy sets: general framework and practical models,cs.AI,"['cs.AI', 'stat.ME']",[arxiv.Result.Author('Thierry Denoeux')],"We introduce a general theory of epistemic random fuzzy sets for reasoning
with fuzzy or crisp evidence. This framework generalizes both the
Dempster-Shafer theory of belief functions, and possibility theory. Independent
epistemic random fuzzy sets are combined by the generalized
product-intersection rule, which extends both Dempster's rule for combining
belief functions, and the product conjunctive combination of possibility
distributions. We introduce Gaussian random fuzzy numbers and their
multi-dimensional extensions, Gaussian random fuzzy vectors, as practical
models for quantifying uncertainty about scalar or vector quantities.
Closed-form expressions for the combination, projection and vacuous extension
of Gaussian random fuzzy numbers and vectors are derived.",-0.07843093,0.02225238,-0.026025355,A
2131,"1
                                      Amadini, Gabbrielli, Liu & Mauro

    We believe that further study on this issue is necessary because often meta-solvers are
evaluated on heterogeneous scenarios, characterized by a diÔ¨Äerent number of problems, dif-
ferent timeouts, and diÔ¨Äerent individual solvers from which the meta-solvers approaches
are built.","A Ô¨Åne-tuned solver can be seen as a meta-solver where we consider diÔ¨Äerent conÔ¨Ågurations of the same
                                             solver as diÔ¨Äerent solvers.","In this paper, starting from some surprising results presented by Liu, Amadini,
Mauro, and Gabbrielli (2021) showing dramatic ranking changes with diÔ¨Äerent, but rea-
sonable, metrics we would like to draw more attention on the evaluation of meta-solvers
approaches by shedding some light on the strengths and weaknesses of diÔ¨Äerent metrics.",2022-02-17 11:51:48+00:00,On the evaluation of (meta-)solver approaches,cs.AI,"['cs.AI', 'cs.LG', 'cs.PF']","[arxiv.Result.Author('Roberto Amadini'), arxiv.Result.Author('Maurizio Gabbrielli'), arxiv.Result.Author('Tong Liu'), arxiv.Result.Author('Jacopo Mauro')]","Meta-solver approaches exploits a number of individual solvers to potentially
build a better solver. To assess the performance of meta-solvers, one can
simply adopt the metrics typically used for individual solvers (e.g., runtime
or solution quality), or employ more specific evaluation metrics (e.g., by
measuring how close the meta-solver gets to its virtual best performance). In
this paper, based on some recently published works, we provide an overview of
different performance metrics for evaluating (meta-)solvers, by underlying
their strengths and weaknesses.",-0.064325444,0.1598905,-0.046824,B
2137,"However, further research is needed to better understand the back-end mech-
             anisms and to reveal the potential interactions with clinical and pharmacokinetic
             factors.","Studies have indicated that some drugs, chemicals or food supplements
             could be related to preventing or delaying neurodegeneration and cognitive decline
             [12].","In this paper, we encode biomedical concepts and their rich relations into
             a knowledge graph through literature mining [13].",2022-02-17 15:33:27+00:00,Mining On Alzheimer's Diseases Related Knowledge Graph to Identity Potential AD-related Semantic Triples for Drug Repurposing,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Yi Nian'), arxiv.Result.Author('Xinyue Hu'), arxiv.Result.Author('Rui Zhang'), arxiv.Result.Author('Jingna Feng'), arxiv.Result.Author('Jingcheng Du'), arxiv.Result.Author('Fang Li'), arxiv.Result.Author('Yong Chen'), arxiv.Result.Author('Cui Tao')]","To date, there are no effective treatments for most neurodegenerative
diseases. Knowledge graphs can provide comprehensive and semantic
representation for heterogeneous data, and have been successfully leveraged in
many biomedical applications including drug repurposing. Our objective is to
construct a knowledge graph from literature to study relations between
Alzheimer's disease (AD) and chemicals, drugs and dietary supplements in order
to identify opportunities to prevent or delay neurodegenerative progression. We
collected biomedical annotations and extracted their relations using SemRep via
SemMedDB. We used both a BERT-based classifier and rule-based methods during
data preprocessing to exclude noise while preserving most AD-related semantic
triples. The 1,672,110 filtered triples were used to train with knowledge graph
completion algorithms (i.e., TransE, DistMult, and ComplEx) to predict
candidates that might be helpful for AD treatment or prevention. Among three
knowledge graph completion models, TransE outperformed the other two (MR =
13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further
evaluate the prediction results. We found supporting evidence for most highly
ranked candidates predicted by our model which indicates that our approach can
inform reliable new knowledge. This paper shows that our graph mining model can
predict reliable new relationships between AD and other entities (i.e., dietary
supplements, chemicals, and drugs). The knowledge graph constructed can
facilitate data-driven knowledge discoveries and the generation of novel
hypotheses.",-0.16748312,-0.21615198,0.022914376,A
2138,"However, further research is needed to better understand the back-end mech-
             anisms and to reveal the potential interactions with clinical and pharmacokinetic
Nian et al.","Studies have indicated that some drugs, chemicals or food supplements
             could be related to preventing or delaying neurodegeneration and cognitive decline
             [13].","Page 3 of 14

             factors.",2022-02-17 15:33:27+00:00,Mining On Alzheimer's Diseases Related Knowledge Graph to Identity Potential AD-related Semantic Triples for Drug Repurposing,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Yi Nian'), arxiv.Result.Author('Xinyue Hu'), arxiv.Result.Author('Rui Zhang'), arxiv.Result.Author('Jingna Feng'), arxiv.Result.Author('Jingcheng Du'), arxiv.Result.Author('Fang Li'), arxiv.Result.Author('Yong Chen'), arxiv.Result.Author('Cui Tao')]","To date, there are no effective treatments for most neurodegenerative
diseases. Knowledge graphs can provide comprehensive and semantic
representation for heterogeneous data, and have been successfully leveraged in
many biomedical applications including drug repurposing. Our objective is to
construct a knowledge graph from literature to study relations between
Alzheimer's disease (AD) and chemicals, drugs and dietary supplements in order
to identify opportunities to prevent or delay neurodegenerative progression. We
collected biomedical annotations and extracted their relations using SemRep via
SemMedDB. We used both a BERT-based classifier and rule-based methods during
data preprocessing to exclude noise while preserving most AD-related semantic
triples. The 1,672,110 filtered triples were used to train with knowledge graph
completion algorithms (i.e., TransE, DistMult, and ComplEx) to predict
candidates that might be helpful for AD treatment or prevention. Among three
knowledge graph completion models, TransE outperformed the other two (MR =
13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further
evaluate the prediction results. We found supporting evidence for most highly
ranked candidates predicted by our model which indicates that our approach can
inform reliable new knowledge. This paper shows that our graph mining model can
predict reliable new relationships between AD and other entities (i.e., dietary
supplements, chemicals, and drugs). The knowledge graph constructed can
facilitate data-driven knowledge discoveries and the generation of novel
hypotheses.",-0.20795783,-0.049275167,0.15057045,A
2139,"However, further research is needed to better understand the back-end mech-
             anisms and to reveal the potential interactions with clinical and pharmacokinetic
Nian et al.","Studies have indicated that some drugs, chemicals or food supplements
             could be related to preventing or delaying neurodegeneration and cognitive decline
             [13].","Page 3 of 14

             factors.",2022-02-17 15:33:27+00:00,Mining On Alzheimer's Diseases Related Knowledge Graph to Identity Potential AD-related Semantic Triples for Drug Repurposing,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Yi Nian'), arxiv.Result.Author('Xinyue Hu'), arxiv.Result.Author('Rui Zhang'), arxiv.Result.Author('Jingna Feng'), arxiv.Result.Author('Jingcheng Du'), arxiv.Result.Author('Fang Li'), arxiv.Result.Author('Yong Chen'), arxiv.Result.Author('Cui Tao')]","To date, there are no effective treatments for most neurodegenerative
diseases. Knowledge graphs can provide comprehensive and semantic
representation for heterogeneous data, and have been successfully leveraged in
many biomedical applications including drug repurposing. Our objective is to
construct a knowledge graph from literature to study relations between
Alzheimer's disease (AD) and chemicals, drugs and dietary supplements in order
to identify opportunities to prevent or delay neurodegenerative progression. We
collected biomedical annotations and extracted their relations using SemRep via
SemMedDB. We used both a BERT-based classifier and rule-based methods during
data preprocessing to exclude noise while preserving most AD-related semantic
triples. The 1,672,110 filtered triples were used to train with knowledge graph
completion algorithms (i.e., TransE, DistMult, and ComplEx) to predict
candidates that might be helpful for AD treatment or prevention. Among three
knowledge graph completion models, TransE outperformed the other two (MR =
13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further
evaluate the prediction results. We found supporting evidence for most highly
ranked candidates predicted by our model which indicates that our approach can
inform reliable new knowledge. This paper shows that our graph mining model can
predict reliable new relationships between AD and other entities (i.e., dietary
supplements, chemicals, and drugs). The knowledge graph constructed can
facilitate data-driven knowledge discoveries and the generation of novel
hypotheses.",-0.20795783,-0.049275167,0.15057045,A
2140,"However, further research is needed to better understand the back-end mech-
             anisms and to reveal the potential interactions with clinical and pharmacokinetic
Nian et al.","Studies have indicated that some drugs, chemicals or food supplements
             could be related to preventing or delaying neurodegeneration and cognitive decline
             [13].","Page 3 of 14

             factors.",2022-02-17 15:33:27+00:00,Mining On Alzheimer's Diseases Related Knowledge Graph to Identity Potential AD-related Semantic Triples for Drug Repurposing,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Yi Nian'), arxiv.Result.Author('Xinyue Hu'), arxiv.Result.Author('Rui Zhang'), arxiv.Result.Author('Jingna Feng'), arxiv.Result.Author('Jingcheng Du'), arxiv.Result.Author('Fang Li'), arxiv.Result.Author('Yong Chen'), arxiv.Result.Author('Cui Tao')]","To date, there are no effective treatments for most neurodegenerative
diseases. Knowledge graphs can provide comprehensive and semantic
representation for heterogeneous data, and have been successfully leveraged in
many biomedical applications including drug repurposing. Our objective is to
construct a knowledge graph from literature to study relations between
Alzheimer's disease (AD) and chemicals, drugs and dietary supplements in order
to identify opportunities to prevent or delay neurodegenerative progression. We
collected biomedical annotations and extracted their relations using SemRep via
SemMedDB. We used both a BERT-based classifier and rule-based methods during
data preprocessing to exclude noise while preserving most AD-related semantic
triples. The 1,672,110 filtered triples were used to train with knowledge graph
completion algorithms (i.e., TransE, DistMult, and ComplEx) to predict
candidates that might be helpful for AD treatment or prevention. Among three
knowledge graph completion models, TransE outperformed the other two (MR =
13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further
evaluate the prediction results. We found supporting evidence for most highly
ranked candidates predicted by our model which indicates that our approach can
inform reliable new knowledge. This paper shows that our graph mining model can
predict reliable new relationships between AD and other entities (i.e., dietary
supplements, chemicals, and drugs). The knowledge graph constructed can
facilitate data-driven knowledge discoveries and the generation of novel
hypotheses.",-0.20795783,-0.049275167,0.15057045,A
2218,"Exploiting the class context besides surrounding
classes, such as different annotation properties, data properties, and logical expressions, is
still a big challenge for the further research, for not only improving BERTMap but also other
BERT applications in OWL ontologies.","Besides the promising performance of BERTSubs, the evaluation also shows that the
current simple solution of utilizing multiple labels by different annotation properties still
has ample space for further improvement.","Meanwhile, we currently use the class hierarchy
extracted from just declared subsumptions for computing the class context.",2022-02-20 11:14:04+00:00,Contextual Semantic Embeddings for Ontology Subsumption Prediction,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Jiaoyan Chen'), arxiv.Result.Author('Yuan He'), arxiv.Result.Author('Yuxia Geng'), arxiv.Result.Author('Ernesto Jimenez-Ruiz'), arxiv.Result.Author('Hang Dong'), arxiv.Result.Author('Ian Horrocks')]","Automating ontology construction and curation is an important but challenging
task in knowledge engineering and artificial intelligence. Prediction by
machine learning techniques such as contextual semantic embedding is a
promising direction, but the relevant research is still preliminary especially
for expressive ontologies in Web Ontology Language (OWL). In this paper, we
present a new subsumption prediction method named BERTSubs for classes of OWL
ontology. It exploits the pre-trained language model BERT to compute contextual
embeddings of a class, where customized templates are proposed to incorporate
the class context (e.g., neighbouring classes) and the logical existential
restriction. BERTSubs is quite general, being able to predict multiple kinds of
subsumers including named classes and existential restrictions from the same
ontology or another ontology. Extensive evaluation on five real-world
ontologies for three different subsumption tasks has shown the effectiveness of
the templates and that BERTSubs can dramatically outperform the baselines that
use (literal-aware) knowledge graph embeddings, non-contextual word embeddings
and the state-of-the-art OWL ontology embeddings.",-0.18587501,-0.13529459,-0.28682995,A
2230,"We also hope that this work will spark further research
on cooperative AI, a new subÔ¨Åeld of multi-agent learning that focuses on how to
best achieve mutually beneÔ¨Åcial outcomes in both human-AI interactions and AI-AI
interactions.","We also expect it to contribute to establishing a paradigm that
goes beyond the conventional perspective of a single reinforcement learning agent
navigating an environment.","Contents

1 Introduction                                                12

2 Literature Review                                           15

2.1 Social dilemmas .",2022-02-20 16:50:37+00:00,Cooperative Artificial Intelligence,cs.AI,"['cs.AI', 'cs.GT', 'cs.MA']",[arxiv.Result.Author('Tobias Baumann')],"In the future, artificial learning agents are likely to become increasingly
widespread in our society. They will interact with both other learning agents
and humans in a variety of complex settings including social dilemmas. We argue
that there is a need for research on the intersection between game theory and
artificial intelligence, with the goal of achieving cooperative artificial
intelligence that can navigate social dilemmas well. We consider the problem of
how an external agent can promote cooperation between artificial learners by
distributing additional rewards and punishments based on observing the actions
of the learners. We propose a rule for automatically learning how to create the
right incentives by considering the anticipated parameter updates of each
agent. Using this learning rule leads to cooperation with high social welfare
in matrix games in which the agents would otherwise learn to defect with high
probability. We show that the resulting cooperative outcome is stable in
certain games even if the planning agent is turned off after a given number of
episodes, while other games require ongoing intervention to maintain mutual
cooperation. Finally, we reflect on what the goals of multi-agent reinforcement
learning should be in the first place, and discuss the necessary building
blocks towards the goal of building cooperative AI.",0.2996896,0.05632063,0.4054085,C
2260,"Still, further research placed at the intersection of AVR
4.3.2 Generation                                                  and natural language generation is needed to advance the
                                                                  current ML systems in this human-speciÔ¨Åc ability.",activation function.,"Another type of prediction challenge, posed by some AVR
tasks, is image generation [139‚Äì141].",2022-02-21 14:58:02+00:00,A Review of Emerging Research Directions in Abstract Visual Reasoning,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Miko≈Çaj Ma≈Çki≈Ñski'), arxiv.Result.Author('Jacek Ma≈Ñdziuk')]","Abstract Visual Reasoning (AVR) problems are commonly used to approximate
human intelligence. They test the ability of applying previously gained
knowledge, experience and skills in a completely new setting, which makes them
particularly well-suited for this task. Recently, the AVR problems have become
popular as a proxy to study machine intelligence, which has led to emergence of
new distinct types of problems and multiple benchmark sets. In this work we
review this emerging AVR research and propose a taxonomy to categorise the AVR
tasks along 5 dimensions: input shapes, hidden rules, target task, cognitive
function, and main challenge. The perspective taken in this survey allows to
characterise AVR problems with respect to their shared and distinct properties,
provides a unified view on the existing approaches for solving AVR tasks, shows
how the AVR problems relate to practical applications, and outlines promising
directions for future work. One of them refers to the observation that in the
machine learning literature different tasks are considered in isolation, which
is in the stark contrast with the way the AVR tasks are used to measure human
intelligence, where multiple types of problems are combined within a single IQ
test.",0.24519959,-0.3090644,-0.04815745,C
2261,"Still, further research placed at the intersection of AVR                                                                                                            18
and natural language generation is needed to advance the
current ML systems in this human-speciÔ¨Åc ability.","As a result, the existing models to solve               fundamental challenge posed by BPs, where a description
                                                                             of abstract rules that differentiate left and right matrix parts
                                                                             has to be generated.","5.1.1 Few-shot vs multiple-epoch training

4.3.4 Auxiliary tasks                                           One of the main differentiators in measuring human and
                                                                machine performance in solving AVR tasks is the training
In addition to the already described target tasks, some         regime.",2022-02-21 14:58:02+00:00,A Review of Emerging Research Directions in Abstract Visual Reasoning,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Miko≈Çaj Ma≈Çki≈Ñski'), arxiv.Result.Author('Jacek Ma≈Ñdziuk')]","Abstract Visual Reasoning (AVR) problems are commonly used to approximate
human intelligence. They test the ability of applying previously gained
knowledge, experience and skills in a completely new setting, which makes them
particularly well-suited for this task. Recently, the AVR problems have become
popular as a proxy to study machine intelligence, which has led to emergence of
new distinct types of problems and multiple benchmark sets. In this work we
review this emerging AVR research and propose a taxonomy to categorise the AVR
tasks along 5 dimensions: input shapes, hidden rules, target task, cognitive
function, and main challenge. The perspective taken in this survey allows to
characterise AVR problems with respect to their shared and distinct properties,
provides a unified view on the existing approaches for solving AVR tasks, shows
how the AVR problems relate to practical applications, and outlines promising
directions for future work. One of them refers to the observation that in the
machine learning literature different tasks are considered in isolation, which
is in the stark contrast with the way the AVR tasks are used to measure human
intelligence, where multiple types of problems are combined within a single IQ
test.",0.15012607,-0.22024041,-0.04031586,C
2341,"Our data
discusses open research questions that require further study.","Finally, section VI                           continental United States in the last decade [10].","generation, to a large extent, is based on work on large-
                                                                                         scale vector and raster analysis [15], and uses a principled
          II.",2022-02-23 02:02:32+00:00,Designing Decision Support Systems for Emergency Response: Challenges and Opportunities,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Geoffrey Pettet'), arxiv.Result.Author('Hunter Baxter'), arxiv.Result.Author('Sayyed Mohsen Vazirizade'), arxiv.Result.Author('Hemant Purohit'), arxiv.Result.Author('Meiyi Ma'), arxiv.Result.Author('Ayan Mukhopadhyay'), arxiv.Result.Author('Abhishek Dubey')]","Designing effective emergency response management (ERM) systems to respond to
incidents such as road accidents is a major problem faced by communities. In
addition to responding to frequent incidents each day (about 240 million
emergency medical services calls and over 5 million road accidents in the US
each year), these systems also support response during natural hazards.
Recently, there has been a consistent interest in building decision support and
optimization tools that can help emergency responders provide more efficient
and effective response. This includes a number of principled subsystems that
implement early incident detection, incident likelihood forecasting and
strategic resource allocation and dispatch policies. In this paper, we
highlight the key challenges and provide an overview of the approach developed
by our team in collaboration with our community partners.",-0.012402768,-0.032499105,-0.15111503,C
2342,"The hierarchical      for further research is the integration of practical constraints
framework was also able to scale to the full system, and further   into the decision support procedures.","approach easily scaled to the full ERM system with reason-
able computation times, and reduced mean incident response            Practical Constraints: Another issue that is an opportunity
times compared to centralized planning [11].","Such dynamic con-
improved average response times compared to the decentral-         siderations include reduction in the number of ambulances
ized approach due to making fewer assumptions regarding the        available, constraints on the maximum mileage that can be
agents‚Äô interactions [9].",2022-02-23 02:02:32+00:00,Designing Decision Support Systems for Emergency Response: Challenges and Opportunities,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Geoffrey Pettet'), arxiv.Result.Author('Hunter Baxter'), arxiv.Result.Author('Sayyed Mohsen Vazirizade'), arxiv.Result.Author('Hemant Purohit'), arxiv.Result.Author('Meiyi Ma'), arxiv.Result.Author('Ayan Mukhopadhyay'), arxiv.Result.Author('Abhishek Dubey')]","Designing effective emergency response management (ERM) systems to respond to
incidents such as road accidents is a major problem faced by communities. In
addition to responding to frequent incidents each day (about 240 million
emergency medical services calls and over 5 million road accidents in the US
each year), these systems also support response during natural hazards.
Recently, there has been a consistent interest in building decision support and
optimization tools that can help emergency responders provide more efficient
and effective response. This includes a number of principled subsystems that
implement early incident detection, incident likelihood forecasting and
strategic resource allocation and dispatch policies. In this paper, we
highlight the key challenges and provide an overview of the approach developed
by our team in collaboration with our community partners.",-0.09231165,0.3825866,0.11795153,B
2343,"Finally, section VI discusses open                  stored in the vector form, information about vegetation, fuel,
research questions that require further study.","For example, while Ô¨Åre occurrence data is usually
to communication failures.",and topographic features is available in a raster model.,2022-02-23 02:02:32+00:00,Designing Decision Support Systems for Emergency Response: Challenges and Opportunities,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Geoffrey Pettet'), arxiv.Result.Author('Hunter Baxter'), arxiv.Result.Author('Sayyed Mohsen Vazirizade'), arxiv.Result.Author('Hemant Purohit'), arxiv.Result.Author('Meiyi Ma'), arxiv.Result.Author('Ayan Mukhopadhyay'), arxiv.Result.Author('Abhishek Dubey')]","Designing effective emergency response management (ERM) systems to respond to
incidents such as road accidents is a major problem faced by communities. In
addition to responding to frequent incidents each day (about 240 million
emergency medical services calls and over 5 million road accidents in the US
each year), these systems also support response during natural hazards.
Recently, there has been a consistent interest in building decision support and
optimization tools that can help emergency responders provide more efficient
and effective response. This includes a number of principled subsystems that
implement early incident detection, incident likelihood forecasting and
strategic resource allocation and dispatch policies. In this paper, we
highlight the key challenges and provide an overview of the approach developed
by our team in collaboration with our community partners.",-0.18788919,-0.040008478,-0.22105107,A
2344,"The hierarchical      for further research is the integration of practical constraints
framework was also able to scale to the full system, and further   into the decision support procedures.","approach easily scaled to the full ERM system with reason-
able computation times, and reduced mean incident response            Practical Constraints: Another issue that is an opportunity
times compared to centralized planning [10].","Such dynamic con-
improved average response times compared to the decentral-         siderations include reduction in the number of ambulances
ized approach due to making fewer assumptions regarding the        available, constraints on the maximum mileage that can be
agents‚Äô interactions [6].",2022-02-23 02:02:32+00:00,Designing Decision Support Systems for Emergency Response: Challenges and Opportunities,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Geoffrey Pettet'), arxiv.Result.Author('Hunter Baxter'), arxiv.Result.Author('Sayyed Mohsen Vazirizade'), arxiv.Result.Author('Hemant Purohit'), arxiv.Result.Author('Meiyi Ma'), arxiv.Result.Author('Ayan Mukhopadhyay'), arxiv.Result.Author('Abhishek Dubey')]","Designing effective emergency response management (ERM) systems to respond to
incidents such as road accidents is a major problem faced by communities. In
addition to responding to frequent incidents each day (about 240 million
emergency medical services calls and over 5 million road accidents in the US
each year), these systems also support response during natural hazards.
Recently, there has been a consistent interest in building decision support and
optimization tools that can help emergency responders provide more efficient
and effective response. This includes a number of principled subsystems that
implement early incident detection, incident likelihood forecasting and
strategic resource allocation and dispatch policies. In this paper, we
highlight the key challenges and provide an overview of the approach developed
by our team in collaboration with our community partners.",-0.09366669,0.38071162,0.11630966,B
2547,"In this direction, several interesting perspectives deserve further research efforts: (1)
estimation methods for time-varying parameters of the GVW model and empirical studies in
different advertising media; (2) optimal advertising strategy based on the GVW; and (3)
application of the GVW model to multi-channel advertising decisions due to its strength of
encoding the potential heterogeneity among different media vehicles.","Note that econometric models can
capture diminishing returns on a strict complex condition related to multiple coefficients and
advertising variables.","Acknowledgment
The authors are thankful to anonymous reviewers who provided valuable suggestions that led
to a considerable improvement in the organization and presentation of this manuscript.",2022-02-28 06:31:02+00:00,Learning Parameters for a Generalized Vidale-Wolfe Response Model with Flexible Ad Elasticity and Word-of-Mouth,cs.AI,"['cs.AI', 'cs.IR', 'cs.LG', 'cs.SY', 'eess.SY', '68Txx', 'I.2.6']","[arxiv.Result.Author('Yanwu Yang'), arxiv.Result.Author('Baozhu Feng'), arxiv.Result.Author('Daniel Zeng')]","In this research, we investigate a generalized form of Vidale-Wolfe (GVW)
model. One key element of our modeling work is that the GVW model contains two
useful indexes representing advertiser's elasticity and the word-of-mouth (WoM)
effect, respectively. Moreover, we discuss some desirable properties of the GVW
model, and present a deep neural network (DNN)-based estimation method to learn
its parameters. Furthermore, based on three realworld datasets, we conduct
computational experiments to validate the GVW model and identified properties.
In addition, we also discuss potential advantages of the GVW model over
econometric models. The research outcome shows that both the ad elasticity
index and the WoM index have significant influences on advertising responses,
and the GVW model has potential advantages over econometric models of
advertising, in terms of several interesting phenomena drawn from practical
advertising situations. The GVW model and its deep learning-based estimation
method provide a basis to support big data-driven advertising analytics and
decision makings; in the meanwhile, identified properties and experimental
findings of this research illuminate critical managerial insights for
advertisers in various advertising forms.",-0.14253163,0.20349064,0.12823944,B
2797,"For further research, it is, hence, desirable to concentrate on the
diÔ¨Äerent ways to evaluate statements and on the diÔ¨Äerent ways to transfer
justiÔ¨Åcation of arguments to justiÔ¨Åcation of statements, yielding statement-
labellings.","For this enterprise, investigating indecision on a statement level seems
crucial.","Although recent work already allows for a distinction between two
kinds of indecision-labels on a statement level, I argued that it is necessary to
distinguish even more forms of indecision.",2022-03-04 09:33:49+00:00,Forms and Norms of Indecision in Argumentation Theory,cs.AI,"['cs.AI', 'cs.LO']",[arxiv.Result.Author('Daniela Schuster')],"One main goal of argumentation theory is to evaluate arguments and to
determine whether they should be accepted or rejected. When there is no clear
answer, a third option, being undecided, has to be taken into account.
Indecision is often not considered explicitly, but rather taken to be a
collection of all unclear or troubling cases. However, current philosophy makes
a strong point for taking indecision itself to be a proper object of
consideration. This paper aims at revealing parallels between the findings
concerning indecision in philosophy and the treatment of indecision in
argumentation theory. By investigating what philosophical forms and norms of
indecision are involved in argumentation theory, we can improve our
understanding of the different uncertain evidential situations in argumentation
theory.",-0.4802752,-0.08930689,0.064834796,A
2899,"In the MLN setting, because the map has             dealing with a large environment, as we can see from the
accurate semantics and is sensitive to blurring and rotation      third line of Table II: val seen environment models trained
operations, large scale pretraining on maps is challenging        without agent pose information provoke a drop of 7.2% in
and requires further study.","scale vision data show a good visual adaptation in unseen
environments.","success rate (SR), while for smaller unseen environments,
                                                                  the performance remains stable.",2022-03-07 07:40:33+00:00,Find a Way Forward: a Language-Guided Semantic Map Navigator,cs.AI,['cs.AI'],"[arxiv.Result.Author('Zehao Wang'), arxiv.Result.Author('Mingxiao Li'), arxiv.Result.Author('Minye Wu'), arxiv.Result.Author('Marie-Francine Moens'), arxiv.Result.Author('Tinne Tuytelaars')]","This paper attacks the problem of language-guided navigation in a new
perspective by using novel semantic navigation maps, which enables robots to
carry out natural language instructions and move to a target position based on
the map observations. We break down this problem into parts and introduce three
different modules to solve the corresponding subproblems. Our approach
leverages map information to provide Deterministic Path Candidate Proposals to
reduce the solution space. Different from traditional methods that predict
robots' movements toward the target step-by-step, we design an attention-based
Language Driven Discriminator to evaluate path candidates and determine the
best path as the final result. To represent the map observations along a path
for a better modality alignment, a novel Path Feature Encoding scheme tailored
for semantic navigation maps is proposed. Unlike traditional methods that tend
to produce cumulative errors or be stuck in local decisions, our method which
plans paths based on global information can greatly alleviate these problems.
The proposed approach has noticeable performance gains, especially in
long-distance navigation cases. Also, its training efficiency is significantly
higher than of other methods.",0.32142204,-0.11667255,-0.05647505,C
3579,A negative literal will also be called a state    generalization to discrete variables without further study.,"A negative literal is a negated state ¬¨(X = xi), typically    quantiÔ¨Åcation for Boolean logic and suggested the following
denoted by x¬Øi.",if the variable has only two values.,2022-03-20 04:39:41+00:00,On the Computation of Necessary and Sufficient Explanations,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Adnan Darwiche'), arxiv.Result.Author('Chunxi Ji')]","The complete reason behind a decision is a Boolean formula that characterizes
why the decision was made. This recently introduced notion has a number of
applications, which include generating explanations, detecting decision bias
and evaluating counterfactual queries. Prime implicants of the complete reason
are known as sufficient reasons for the decision and they correspond to what is
known as PI explanations and abductive explanations. In this paper, we refer to
the prime implicates of a complete reason as necessary reasons for the
decision. We justify this terminology semantically and show that necessary
reasons correspond to what is known as contrastive explanations. We also study
the computation of complete reasons for multi-class decision trees and graphs
with nominal and numeric features for which we derive efficient, closed-form
complete reasons. We further investigate the computation of shortest necessary
and sufficient reasons for a broad class of complete reasons, which include the
derived closed forms and the complete reasons for Sentential Decision Diagrams
(SDDs). We provide an algorithm which can enumerate their shortest necessary
reasons in output polynomial time. Enumerating shortest sufficient reasons for
this class of complete reasons is hard even for a single reason. For this
problem, we provide an algorithm that appears to be quite efficient as we show
empirically.",-0.22946966,-0.01388691,-0.038133472,A
3611,"Nevertheless, further research work
is required to hone and highlight aspects related to workers‚Äô safety and how the current
architecture supports this.","Furthermore, it
conÔ¨Årms the interplay between the architecture modules to deliver a human-centric
experience aligned with the Industry 5.0 paradigm.",Ongoing and future work is and will be focused on three research directions.,2022-03-21 08:16:46+00:00,Human-Centric Artificial Intelligence Architecture for Industry 5.0 Applications,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jo≈æe M. Ro≈æanec'), arxiv.Result.Author('Inna Novalija'), arxiv.Result.Author('Patrik Zajec'), arxiv.Result.Author('Klemen Kenda'), arxiv.Result.Author('Hooman Tavakoli'), arxiv.Result.Author('Sungho Suh'), arxiv.Result.Author('Entso Veliou'), arxiv.Result.Author('Dimitrios Papamartzivanos'), arxiv.Result.Author('Thanassis Giannetsos'), arxiv.Result.Author('Sofia Anna Menesidou'), arxiv.Result.Author('Ruben Alonso'), arxiv.Result.Author('Nino Cauli'), arxiv.Result.Author('Antonello Meloni'), arxiv.Result.Author('Diego Reforgiato Recupero'), arxiv.Result.Author('Dimosthenis Kyriazis'), arxiv.Result.Author('Georgios Sofianidis'), arxiv.Result.Author('Spyros Theodoropoulos'), arxiv.Result.Author('Bla≈æ Fortuna'), arxiv.Result.Author('Dunja Mladeniƒá'), arxiv.Result.Author('John Soldatos')]","Human-centricity is the core value behind the evolution of manufacturing
towards Industry 5.0. Nevertheless, there is a lack of architecture that
considers safety, trustworthiness, and human-centricity at its core. Therefore,
we propose an architecture that integrates Artificial Intelligence (Active
Learning, Forecasting, Explainable Artificial Intelligence), simulated reality,
decision-making, and users' feedback, focusing on synergies between humans and
machines. Furthermore, we align the proposed architecture with the Big Data
Value Association Reference Architecture Model. Finally, we validate it on
three use cases from real-world case studies.",-0.15044583,0.046221647,0.1035114,A
3626,"In        [8] T. Kim, S. Ahn, and Y. Bengio, ‚ÄúVariational temporal abstraction,‚Äù
addition to multi-view images, world models that incorporate           Neural Information Processing Systems, 2019.
more modalities such as audio, tactile sensing, and depth
sensors would be an intriguing one which could be usefully        [9] D. Ha and J. Schmidhuber, ‚ÄúRecurrent world models facilitate policy
explored in further research.","Our method can be seen as an example of a multi-
view version of the generalized multimodal world model.","In addition, embedding domain            evolution,‚Äù in Neural Information Processing Systems, 2018.
information such as camera coordinates and robot proprio-
ception into the latent state of each viewpoint would be a       [10] A. X. Lee, A. Nagabandi, P. Abbeel, and S. Levine, ‚ÄúStochastic latent
fruitful area for further work.",2022-03-15 02:33:31+00:00,Multi-View Dreaming: Multi-View World Model with Contrastive Learning,cs.AI,"['cs.AI', 'cs.RO', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Akira Kinose'), arxiv.Result.Author('Masashi Okada'), arxiv.Result.Author('Ryo Okumura'), arxiv.Result.Author('Tadahiro Taniguchi')]","In this paper, we propose Multi-View Dreaming, a novel reinforcement learning
agent for integrated recognition and control from multi-view observations by
extending Dreaming. Most current reinforcement learning method assumes a
single-view observation space, and this imposes limitations on the observed
data, such as lack of spatial information and occlusions. This makes obtaining
ideal observational information from the environment difficult and is a
bottleneck for real-world robotics applications. In this paper, we use
contrastive learning to train a shared latent space between different
viewpoints, and show how the Products of Experts approach can be used to
integrate and control the probability distributions of latent states for
multiple viewpoints. We also propose Multi-View DreamingV2, a variant of
Multi-View Dreaming that uses a categorical distribution to model the latent
state instead of the Gaussian distribution. Experiments show that the proposed
method outperforms simple extensions of existing methods in a realistic robot
control task.",0.2549511,-0.13954481,-0.012183277,C
3684,"1
    This work presents the experience from our attempt to address the aforementioned problem based on the
use of SatisÔ¨Åability Modulo Theory (SMT) solvers, which provide certain advantages, as well as limitations
that justify the need for further research eÔ¨Äorts.","‚àóAcknowledgment: This work has received funding from the European Union‚Äôs Horizon 2020 research and innovation
                                        programme under grant agreement No 956123.","Among their advantages, we stress their potential to deliver
sound and complete veriÔ¨Åcation procedures for the equivalence between two neural networks.",2022-03-22 11:31:12+00:00,On Neural Network Equivalence Checking using SMT Solvers,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO', 'cs.NE']","[arxiv.Result.Author('Charis Eleftheriadis'), arxiv.Result.Author('Nikolaos Kekatos'), arxiv.Result.Author('Panagiotis Katsaros'), arxiv.Result.Author('Stavros Tripakis')]","Two pretrained neural networks are deemed equivalent if they yield similar
outputs for the same inputs. Equivalence checking of neural networks is of
great importance, due to its utility in replacing learning-enabled components
with equivalent ones, when there is need to fulfill additional requirements or
to address security threats, as is the case for example when using knowledge
distillation, adversarial training etc. SMT solvers can potentially provide
solutions to the problem of neural network equivalence checking that will be
sound and complete, but as it is expected any such solution is associated with
significant limitations with respect to the size of neural networks to be
checked. This work presents a first SMT-based encoding of the equivalence
checking problem, explores its utility and limitations and proposes avenues for
future research and improvements towards more scalable and practically
applicable solutions. We present experimental results that shed light to the
aforementioned issues, for diverse types of neural network models (classifiers
and regression networks) and equivalence criteria, towards a general and
application-independent equivalence checking approach.",0.07254314,0.05421532,-0.21882623,C
3782,"We further study the inÔ¨Çuence of uncontrollable features with CAFA for
global explanations.","This suggests that CAFA successfully excludes inÔ¨Çuences of uncontrollable
features with its calculation, while maintaining properties of standard fea-
ture attribution algorithms such as SHAP.","We randomly sample 100 instances from each dataset
and compute global explanations with SHAP and CAFA.",2022-03-23 19:49:45+00:00,On Understanding the Influence of Controllable Factors with a Feature Attribution Algorithm: a Medical Case Study,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Veera Raghava Reddy Kovvuri'), arxiv.Result.Author('Siyuan Liu'), arxiv.Result.Author('Monika Seisenberger'), arxiv.Result.Author('Berndt M√ºller'), arxiv.Result.Author('Xiuyi Fan')]","Feature attribution XAI algorithms enable their users to gain insight into
the underlying patterns of large datasets through their feature importance
calculation. Existing feature attribution algorithms treat all features in a
dataset homogeneously, which may lead to misinterpretation of consequences of
changing feature values. In this work, we consider partitioning features into
controllable and uncontrollable parts and propose the Controllable fActor
Feature Attribution (CAFA) approach to compute the relative importance of
controllable features. We carried out experiments applying CAFA to two existing
datasets and our own COVID-19 non-pharmaceutical control measures dataset.
Experimental results show that with CAFA, we are able to exclude influences
from uncontrollable features in our explanation while keeping the full dataset
for prediction.",-0.114677645,-0.096459016,-0.15661663,A
3855,"The second term Lr(VbO) is to favor appropriate
relations between concepts, which needs further study to include rules like semantic logic and mathematical logic.","Suppose there are a total of
P possible paths connecting from input concepts to output concepts, and the p-th path has a total of Qp ‚àí 1 connection
steps (connecting Q concepts), we then have:

Ls(V O) =                                                        1                    (30)

b                                                     P Qp

                                                               S(Cq ‚Üí Cq+1)

                                                      p=1 q=1

                                                          14
                                        Figure 5: A WSM-based framework of intelligence

while for all paths, C1 ‚àà MI and CQ is a component of VbO.","The third term Lp(VbO) is a penalty that incorporates human habits such as the rules of language, for humans to better
understand, improve and communicate with the artiÔ¨Åcial IS.",2022-03-25 16:42:23+00:00,A World-Self Model Towards Understanding Intelligence,cs.AI,"['cs.AI', 'cs.IT', 'math.IT']",[arxiv.Result.Author('Yutao Yue')],"Artificial intelligence has achieved tremendous successes in various tasks,
while it is still out of question that there are big gaps between artificial
and human intelligence, and the nature of intelligence is still in darkness. In
this work we will first stress the importance of scope of discussion and
granularity of investigation for this type of research. We will carefully
compare human and artificial intelligence, and propose that a certain aspect
(Aspect 3) of human intelligence is the key to connect perception and
cognition, and the lack of a new model is preventing the understanding and
next-level implementation of intelligence. We will present the broader idea of
""concept"", the principles and mathematical frameworks of the new model
World-Self Model (WSM) of intelligence, and finally an unified general
framework of intelligence based on WSM. Rather than focusing on solving a
specific problem or discussing a certain kind of intelligence, our work is
instead towards a better understanding of the nature of the general phenomenon
of intelligence, independent of the kind of task or system of investigation.",-0.19838879,0.024393542,0.09291032,A
3856,"The second term Lr(VbO) is to favor appropriate
relations between concepts, which needs further study to include rules like semantic logic and mathematical logic.","Suppose there are a total of
P possible paths connecting from input concepts to output concepts, and the p-th path has a total of Qp ‚àí 1 connection
steps (connecting Q concepts), we then have:

Ls(V O) =                                                        1                    (30)

b                                                     P Qp

                                                               S(Cq ‚Üí Cq+1)

                                                      p=1 q=1

                                                          15
while for all paths, C1 ‚àà MI and CQ is a component of VbO.","The third term Lp(VbO) is a penalty that incorporates human habits such as the rules of language, for humans to better
understand, improve and communicate with the artiÔ¨Åcial IS.",2022-03-25 16:42:23+00:00,A World-Self Model Towards Understanding Intelligence,cs.AI,"['cs.AI', 'cs.IT', 'math.IT']",[arxiv.Result.Author('Yutao Yue')],"Artificial intelligence has achieved tremendous successes in various tasks,
while it is still out of question that there are big gaps between artificial
and human intelligence, and the nature of intelligence is still in darkness. In
this work we will first stress the importance of defining the scope of
discussion and choosing the right physical and informational granularity of
investigation. We will carefully compare human and artificial intelligence, and
propose that the information abstraction mechanism of human intelligence is the
key to connect perception and cognition, and the lack of a new model is
preventing the understanding and next-level implementation of intelligence. We
will present the broader idea of ""concept"", the principles and mathematical
frameworks of the new model World-Self Model (WSM) of intelligence, and finally
an unified general framework of intelligence based on WSM. Rather than focusing
on solving a specific problem or discussing a certain kind of intelligence, our
work is instead towards a better understanding of the nature of the general
phenomenon of intelligence, independent of the task or system of investigation.",-0.23285556,-0.002887139,0.09380409,A
3857,"The second term Lr(VbO) is to favor appropriate
relations between concepts, which needs further study to include rules like semantic logic and mathematical logic.","Suppose there are a total of
P possible paths connecting from input concepts to output concepts, and the p-th path has a total of Qp ‚àí 1 connection
steps (connecting Q concepts), we then have:

                                                 Ls(VbO) = P Qp 1 (30)
                                                                         S(Cq ‚Üí Cq+1)

                                                                                           p=1 q=1

while for all paths, C1 ‚àà MI and CQ is a component of VbO.","The third term Lp(VbO) is a penalty that incorporates human habits such as the rules of language, for humans to better
understand, improve and communicate with the artiÔ¨Åcial IS.",2022-03-25 16:42:23+00:00,A World-Self Model Towards Understanding Intelligence,cs.AI,"['cs.AI', 'cs.IT', 'math.IT', 'I.2.0; G.0; H.1.1']",[arxiv.Result.Author('Yutao Yue')],"The symbolism, connectionism and behaviorism approaches of artificial
intelligence have achieved a lot of successes in various tasks, while we still
do not have a clear definition of ""intelligence"" with enough consensus in the
community (although there are over 70 different ""versions"" of definitions). The
nature of intelligence is still in darkness. In this work we do not take any of
these three traditional approaches, instead we try to identify certain
fundamental aspects of the nature of intelligence, and construct a mathematical
model to represent and potentially reproduce these fundamental aspects. We
first stress the importance of defining the scope of discussion and granularity
of investigation. We carefully compare human and artificial intelligence, and
qualitatively demonstrate an information abstraction process, which we propose
to be the key to connect perception and cognition. We then present the broader
idea of ""concept"", separate the idea of self model out of the world model, and
construct a new model called world-self model (WSM). We show the mechanisms of
creating and connecting concepts, and the flow of how the WSM receives,
processes and outputs information with respect to an arbitrary type of problem
to solve. We also consider and discuss the potential computer implementation
issues of the proposed theoretical framework, and finally we propose a unified
general framework of intelligence based on WSM.",-0.22715619,-0.0030095447,0.10374921,A
4298,"Next, we examine what these properties are,
and derive theoretical results intended to guide further research.","Its
issue arises due to the properties of the RockSample environment                            proof is in Supplementary Section 1.2.
and not our model.",Lemma 6.3.,2022-04-03 21:00:51+00:00,Best-Response Bayesian Reinforcement Learning with Bayes-adaptive POMDPs for Centaurs,cs.AI,"['cs.AI', 'cs.LG', 'cs.MA']","[arxiv.Result.Author('Mustafa Mert √áelikok'), arxiv.Result.Author('Frans A. Oliehoek'), arxiv.Result.Author('Samuel Kaski')]","Centaurs are half-human, half-AI decision-makers where the AI's goal is to
complement the human. To do so, the AI must be able to recognize the goals and
constraints of the human and have the means to help them. We present a novel
formulation of the interaction between the human and the AI as a sequential
game where the agents are modelled using Bayesian best-response models. We show
that in this case the AI's problem of helping bounded-rational humans make
better decisions reduces to a Bayes-adaptive POMDP. In our simulated
experiments, we consider an instantiation of our framework for humans who are
subjectively optimistic about the AI's future behaviour. Our results show that
when equipped with a model of the human, the AI can infer the human's bounds
and nudge them towards better decisions. We discuss ways in which the machine
can learn to improve upon its own limitations as well with the help of the
human. We identify a novel trade-off for centaurs in partially observable
tasks: for the AI's actions to be acceptable to the human, the machine must
make sure their beliefs are sufficiently aligned, but aligning beliefs might be
costly. We present a preliminary theoretical analysis of this trade-off and its
dependence on task structure.",-0.18375656,0.15473807,-0.07586227,B
4545,"It covers various aspects, such as food, production, nav-
further study.","In general, we conclude that these isovist based     settlement provides, both to the Minecraft player and the simulated
measures seem a useful approach to PCG evaluation that warrant             villagers.","igability, security, etc.",2022-04-07 21:41:06+00:00,Automated Isovist Computation for Minecraft,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jean-Baptiste Herv√©'), arxiv.Result.Author('Christoph Salge')]","Procedural content generation for games is a growing trend in both research
and industry, even though there is no consensus of how good content looks, nor
how to automatically evaluate it. A number of metrics have been developed in
the past, usually focused on the artifact as a whole, and mostly lacking
grounding in human experience. In this study we develop a new set of automated
metrics, motivated by ideas from architecture, namely isovists and space
syntax, which have a track record of capturing human experience of space. These
metrics can be computed for a specific game state, from the player's
perspective, and take into account their embodiment in the game world. We show
how to apply those metrics to the 3d blockworld of Minecraft. We use a dataset
of generated settlements from the GDMC Settlement Generation Challenge in
Minecraft and establish several rank-based correlations between the isovist
properties and the rating human judges gave those settelements. We also produce
a range of heat maps that demonstrate the location based applicability of the
approach, which allows for development of those metrics as measures for a game
experience at a specific time and space.",-0.1976938,0.2407305,0.06153473,B
4620,"2https://github.com/slundberg/shap, released under MIT
License
   Based on our current Ô¨Åndings, we identify a few     our code to the public to facilitate further research
proÔ¨Åtable directions for future research.","1, 2, and 3‚Äîof the input sequence are those                                       do not rely on a few words to substantially affect
                                                                                       output logits.","(1) First    and development 3.
of all, the usage of logits-based metrics such as the
WDR appears to be very promising for detecting         References
adversarial inputs.",2022-04-10 09:24:41+00:00,"""That Is a Suspicious Reaction!"": Interpreting Logits Variation to Detect NLP Adversarial Attacks",cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Author('Edoardo Mosca'), arxiv.Result.Author('Shreyash Agarwal'), arxiv.Result.Author('Javier Rando-Ramirez'), arxiv.Result.Author('Georg Groh')]","Adversarial attacks are a major challenge faced by current machine learning
research. These purposely crafted inputs fool even the most advanced models,
precluding their deployment in safety-critical applications. Extensive research
in computer vision has been carried to develop reliable defense strategies.
However, the same issue remains less explored in natural language processing.
Our work presents a model-agnostic detector of adversarial text examples. The
approach identifies patterns in the logits of the target classifier when
perturbing the input text. The proposed detector improves the current
state-of-the-art performance in recognizing adversarial inputs and exhibits
strong generalization capabilities across different NLP models, datasets, and
word-level attacks.",-0.061538342,-0.19323024,-0.13235153,A
4661,"This highlights the direction of further research in what explanation is expected depending
on the context, e.g.","Although explainable ML is advocated as the methodological silver bullet for addressing transparency issues [1], some
user studies, similarly to this paper, show evidence of a limited or even no impact of the explanation on performance in
a task [39, 11, 40, 41, 42].",clinical setting.,2022-04-11 11:59:04+00:00,"Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making",cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Author('Oskar Wysocki'), arxiv.Result.Author('Jessica Katharine Davies'), arxiv.Result.Author('Markel Vigo'), arxiv.Result.Author('Anne Caroline Armstrong'), arxiv.Result.Author('D√≥nal Landers'), arxiv.Result.Author('Rebecca Lee'), arxiv.Result.Author('Andr√© Freitas')]","This paper contributes with a pragmatic evaluation framework for explainable
Machine Learning (ML) models for clinical decision support. The study revealed
a more nuanced role for ML explanation models, when these are pragmatically
embedded in the clinical context. Despite the general positive attitude of
healthcare professionals (HCPs) towards explanations as a safety and trust
mechanism, for a significant set of participants there were negative effects
associated with confirmation bias, accentuating model over-reliance and
increased effort to interact with the model. Also, contradicting one of its
main intended functions, standard explanatory models showed limited ability to
support a critical understanding of the limitations of the model. However, we
found new significant positive effects which repositions the role of
explanations within a clinical context: these include reduction of automation
bias, addressing ambiguous clinical cases (cases where HCPs were not certain
about their decision) and support of less experienced HCPs in the acquisition
of new domain knowledge.",-0.30923283,-0.32269582,0.32216668,A
4662,"This highlights the direction of further research in what explanation is expected depending
on the context, e.g.","Although explainable ML is advocated as the methodological silver bullet for addressing transparency issues [1], some
user studies, similarly to this paper, show evidence of a limited or even no impact of the explanation on performance in
a task [39, 11, 40, 41, 42].",clinical setting.,2022-04-11 11:59:04+00:00,"Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making",cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Author('Oskar Wysocki'), arxiv.Result.Author('Jessica Katharine Davies'), arxiv.Result.Author('Markel Vigo'), arxiv.Result.Author('Anne Caroline Armstrong'), arxiv.Result.Author('D√≥nal Landers'), arxiv.Result.Author('Rebecca Lee'), arxiv.Result.Author('Andr√© Freitas')]","This paper contributes with a pragmatic evaluation framework for explainable
Machine Learning (ML) models for clinical decision support. The study revealed
a more nuanced role for ML explanation models, when these are pragmatically
embedded in the clinical context. Despite the general positive attitude of
healthcare professionals (HCPs) towards explanations as a safety and trust
mechanism, for a significant set of participants there were negative effects
associated with confirmation bias, accentuating model over-reliance and
increased effort to interact with the model. Also, contradicting one of its
main intended functions, standard explanatory models showed limited ability to
support a critical understanding of the limitations of the model. However, we
found new significant positive effects which repositions the role of
explanations within a clinical context: these include reduction of automation
bias, addressing ambiguous clinical cases (cases where HCPs were not certain
about their decision) and support of less experienced HCPs in the acquisition
of new domain knowledge.",-0.30923283,-0.32269582,0.32216668,A
4663,"This highlights the direction of further research in what explanation is expected depending
on the context, e.g.","Although explainable ML is advocated as the methodological silver bullet for addressing transparency issues [1], some
user studies, similarly to this paper, show evidence of a limited or even no impact of the explanation on performance in
a task [54, 18, 55, 56, 57].",clinical setting.,2022-04-11 11:59:04+00:00,"Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making",cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Author('Oskar Wysocki'), arxiv.Result.Author('Jessica Katharine Davies'), arxiv.Result.Author('Markel Vigo'), arxiv.Result.Author('Anne Caroline Armstrong'), arxiv.Result.Author('D√≥nal Landers'), arxiv.Result.Author('Rebecca Lee'), arxiv.Result.Author('Andr√© Freitas')]","This paper contributes with a pragmatic evaluation framework for explainable
Machine Learning (ML) models for clinical decision support. The study revealed
a more nuanced role for ML explanation models, when these are pragmatically
embedded in the clinical context. Despite the general positive attitude of
healthcare professionals (HCPs) towards explanations as a safety and trust
mechanism, for a significant set of participants there were negative effects
associated with confirmation bias, accentuating model over-reliance and
increased effort to interact with the model. Also, contradicting one of its
main intended functions, standard explanatory models showed limited ability to
support a critical understanding of the limitations of the model. However, we
found new significant positive effects which repositions the role of
explanations within a clinical context: these include reduction of automation
bias, addressing ambiguous clinical cases (cases where HCPs were not certain
about their decision) and support of less experienced HCPs in the acquisition
of new domain knowledge.",-0.3102601,-0.32315773,0.3259105,A
4664,"However, we argue that the study points into the direction of a more nuanced role of
ML explanation models when these are pragmatically embedded in the clinical context and the results settle a solid base
for further research.","various backgrounds and levels of expertise) may hinder drawing
statistically robust conclusions.",HCPs acknowledged the role of explanations as a safety and trust mechanism.,2022-04-11 11:59:04+00:00,"Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making",cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Author('Oskar Wysocki'), arxiv.Result.Author('Jessica Katharine Davies'), arxiv.Result.Author('Markel Vigo'), arxiv.Result.Author('Anne Caroline Armstrong'), arxiv.Result.Author('D√≥nal Landers'), arxiv.Result.Author('Rebecca Lee'), arxiv.Result.Author('Andr√© Freitas')]","This paper contributes with a pragmatic evaluation framework for explainable
Machine Learning (ML) models for clinical decision support. The study revealed
a more nuanced role for ML explanation models, when these are pragmatically
embedded in the clinical context. Despite the general positive attitude of
healthcare professionals (HCPs) towards explanations as a safety and trust
mechanism, for a significant set of participants there were negative effects
associated with confirmation bias, accentuating model over-reliance and
increased effort to interact with the model. Also, contradicting one of its
main intended functions, standard explanatory models showed limited ability to
support a critical understanding of the limitations of the model. However, we
found new significant positive effects which repositions the role of
explanations within a clinical context: these include reduction of automation
bias, addressing ambiguous clinical cases (cases where HCPs were not certain
about their decision) and support of less experienced HCPs in the acquisition
of new domain knowledge.",-0.3060346,-0.3388195,0.29122984,A
4678,"We also release
                                                  our graph-based implementations to encourage further research in this direction.","We show that combining object-centered ar-
                                                  chitectures that are expressive enough with semantic relational goals enables an
                                                  efÔ¨Åcient transfer between skills and promotes behavioral diversity.","1 INTRODUCTION

                                        A central challenge in artiÔ¨Åcial intelligence (AI) consists in designing artiÔ¨Åcial agents capable of
                                        solving an unrestricted set of tasks in a continual and open-ended skill learning process.",2022-04-11 14:19:04+00:00,Learning Object-Centered Autotelic Behaviors with Graph Neural Networks,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Ahmed Akakzia'), arxiv.Result.Author('Olivier Sigaud')]","Although humans live in an open-ended world and endlessly face new
challenges, they do not have to learn from scratch each time they face the next
one. Rather, they have access to a handful of previously learned skills, which
they rapidly adapt to new situations. In artificial intelligence, autotelic
agents, which are intrinsically motivated to represent and set their own goals,
exhibit promising skill adaptation capabilities. However, these capabilities
are highly constrained by their policy and goal space representations. In this
paper, we propose to investigate the impact of these representations on the
learning capabilities of autotelic agents. We study different implementations
of autotelic agents using four types of Graph Neural Networks policy
representations and two types of goal spaces, either geometric or
predicate-based. We show that combining object-centered architectures that are
expressive enough with semantic relational goals enables an efficient transfer
between skills and promotes behavioral diversity. We also release our
graph-based implementations to encourage further research in this direction.",0.3240544,-0.21769142,0.12674974,C
4679,"Finally, we release our implementations of the considered GNN-based architectures in multi-object
manipulation domain to encourage further research in this direction1

2 RELATED WORK

This paper relies on several previous works from different areas of research within AI.","‚Ä¢ Coupling graph-based architectures with semantic goals helps to efÔ¨Åciently transfer be-
          tween goals and further improves the behavioral diversity.","Namely,
we consider recent Ô¨Åndings in automatic curriculum learning, semantic goal representations, graph
neural networks and graph-based autotelic learning.",2022-04-11 14:19:04+00:00,Learning Object-Centered Autotelic Behaviors with Graph Neural Networks,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Ahmed Akakzia'), arxiv.Result.Author('Olivier Sigaud')]","Although humans live in an open-ended world and endlessly face new
challenges, they do not have to learn from scratch each time they face the next
one. Rather, they have access to a handful of previously learned skills, which
they rapidly adapt to new situations. In artificial intelligence, autotelic
agents, which are intrinsically motivated to represent and set their own goals,
exhibit promising skill adaptation capabilities. However, these capabilities
are highly constrained by their policy and goal space representations. In this
paper, we propose to investigate the impact of these representations on the
learning capabilities of autotelic agents. We study different implementations
of autotelic agents using four types of Graph Neural Networks policy
representations and two types of goal spaces, either geometric or
predicate-based. We show that combining object-centered architectures that are
expressive enough with semantic relational goals enables an efficient transfer
between skills and promotes behavioral diversity. We also release our
graph-based implementations to encourage further research in this direction.",0.41230717,-0.24223776,-0.01608071,C
4680,"We also release our graph-based implementations to
                                                  encourage further research in this direction.","By testing agents on unseen goals, we show that
                                                  combining object-centered architectures that are expressive enough with semantic relational goals
                                                  helps learning to reach more difÔ¨Åcult goals.","1 INTRODUCTION

                                        A central challenge in artiÔ¨Åcial intelligence (AI) consists in designing artiÔ¨Åcial agents capable of solving an unrestricted
                                        set of tasks in a continual and open-ended skill learning process.",2022-04-11 14:19:04+00:00,Learning Object-Centered Autotelic Behaviors with Graph Neural Networks,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Ahmed Akakzia'), arxiv.Result.Author('Olivier Sigaud')]","Although humans live in an open-ended world and endlessly face new
challenges, they do not have to learn from scratch each time they face the next
one. Rather, they have access to a handful of previously learned skills, which
they rapidly adapt to new situations. In artificial intelligence, autotelic
agents, which are intrinsically motivated to represent and set their own goals,
exhibit promising skill adaptation capabilities. However, these capabilities
are highly constrained by their policy and goal space representations. In this
paper, we propose to investigate the impact of these representations on the
learning and transfer capabilities of autotelic agents. We study different
implementations of autotelic agents using four types of Graph Neural Networks
policy representations and two types of goal spaces, either geometric or
predicate-based. By testing agents on unseen goals, we show that combining
object-centered architectures that are expressive enough with semantic
relational goals helps learning to reach more difficult goals. We also release
our graph-based implementations to encourage further research in this
direction.",0.32480112,-0.1756806,0.13287023,C
4681,"Finally, we release our implementations of the con-
sidered GNN-based architectures in multi-object manipulation domain to encourage further research in this direction1

2 RELATED WORK

This paper relies on several previous works from different areas of research within AI.","These results suggest that coupling semantic goal spaces with sufÔ¨Åciently representative graph-based networks helps
to learn more complex goals and yields better transfer capabilities.","Namely, we consider recent
Ô¨Åndings in automatic curriculum learning, semantic goal representations, graph neural networks and graph-based
autotelic learning, and combinations of several of these aspects.",2022-04-11 14:19:04+00:00,Learning Object-Centered Autotelic Behaviors with Graph Neural Networks,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Ahmed Akakzia'), arxiv.Result.Author('Olivier Sigaud')]","Although humans live in an open-ended world and endlessly face new
challenges, they do not have to learn from scratch each time they face the next
one. Rather, they have access to a handful of previously learned skills, which
they rapidly adapt to new situations. In artificial intelligence, autotelic
agents, which are intrinsically motivated to represent and set their own goals,
exhibit promising skill adaptation capabilities. However, these capabilities
are highly constrained by their policy and goal space representations. In this
paper, we propose to investigate the impact of these representations on the
learning and transfer capabilities of autotelic agents. We study different
implementations of autotelic agents using four types of Graph Neural Networks
policy representations and two types of goal spaces, either geometric or
predicate-based. By testing agents on unseen goals, we show that combining
object-centered architectures that are expressive enough with semantic
relational goals helps learning to reach more difficult goals. We also release
our graph-based implementations to encourage further research in this
direction.",0.40573156,-0.23373279,-0.045007296,C
5175,"To stimulate further research in CPS, we present a deÔ¨Ånition and a framework of CPS,
                                              which we adopt to categorize existing AI methods in this Ô¨Åeld.","The emergence of increasingly autonomous systems
                                              dictates the necessity for AI agents to deal with environmental uncertainty through creativity.","Our framework consists of
                                              four main components of a CPS problem, namely, 1) problem formulation, 2) knowledge
                                              representation, 3) method of knowledge manipulation, and 4) method of evaluation.",2022-04-21 18:31:44+00:00,Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework,cs.AI,['cs.AI'],"[arxiv.Result.Author('Evana Gizzi'), arxiv.Result.Author('Lakshmi Nair'), arxiv.Result.Author('Sonia Chernova'), arxiv.Result.Author('Jivko Sinapov')]","Creative Problem Solving (CPS) is a sub-area within Artificial Intelligence
(AI) that focuses on methods for solving off-nominal, or anomalous problems in
autonomous systems. Despite many advancements in planning and learning,
resolving novel problems or adapting existing knowledge to a new context,
especially in cases where the environment may change in unpredictable ways post
deployment, remains a limiting factor in the safe and useful integration of
intelligent systems. The emergence of increasingly autonomous systems dictates
the necessity for AI agents to deal with environmental uncertainty through
creativity. To stimulate further research in CPS, we present a definition and a
framework of CPS, which we adopt to categorize existing AI methods in this
field. Our framework consists of four main components of a CPS problem, namely,
1) problem formulation, 2) knowledge representation, 3) method of knowledge
manipulation, and 4) method of evaluation. We conclude our survey with open
research questions, and suggested directions for the future.",0.073041975,0.005932108,0.23317286,C
5288,"Our case study shows the promise of conditional delegation, but
further study is required in each application domain of interest to      [8] Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece
develop the best design for human-AI collaboration in identifying             Kamar, Marco Tulio Ribeiro, and Daniel Weld.",2429‚Äì2437.,2021.,2022-04-25 17:00:02+00:00,Human-AI Collaboration via Conditional Delegation: A Case Study of Content Moderation,cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Author('Vivian Lai'), arxiv.Result.Author('Samuel Carton'), arxiv.Result.Author('Rajat Bhatnagar'), arxiv.Result.Author('Q. Vera Liao'), arxiv.Result.Author('Yunfeng Zhang'), arxiv.Result.Author('Chenhao Tan')]","Despite impressive performance in many benchmark datasets, AI models can
still make mistakes, especially among out-of-distribution examples. It remains
an open question how such imperfect models can be used effectively in
collaboration with humans. Prior work has focused on AI assistance that helps
people make individual high-stakes decisions, which is not scalable for a large
amount of relatively low-stakes decisions, e.g., moderating social media
comments. Instead, we propose conditional delegation as an alternative paradigm
for human-AI collaboration where humans create rules to indicate trustworthy
regions of a model. Using content moderation as a testbed, we develop novel
interfaces to assist humans in creating conditional delegation rules and
conduct a randomized experiment with two datasets to simulate in-distribution
and out-of-distribution scenarios. Our study demonstrates the promise of
conditional delegation in improving model performance and provides insights
into design for this novel paradigm, including the effect of AI explanations.",0.051957473,-0.11204054,0.24810302,C
5399,"In this paper, we provide     capabilities & skills?, RQ2: What are common understandings
                                        (i) an overview of the research Ô¨Åeld, (ii) an analysis of the       of capabilities & skills in research?, and RQ3: What are open
                                        characteristics of capabilities and skills, and (iii) a discussion  gaps and opportunities for further research?","We found 247 papers with a notion on capabilities          With this contribution, we aim to answer the following re-
                                        and skills and identiÔ¨Åed and analyzed 34 relevant papers which      search questions: RQ1: What is the current state of research of
                                        met this survey‚Äôs inclusion criteria.",on gaps and opportunities.,2022-04-26 17:15:25+00:00,Capabilities and Skills in Manufacturing: A Survey Over the Last Decade of ETFA,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Roman Froschauer'), arxiv.Result.Author('Aljosha K√∂cher'), arxiv.Result.Author('Kristof Meixner'), arxiv.Result.Author('Siwara Schmitt'), arxiv.Result.Author('Fabian Spitzer')]","Industry 4.0 envisions Cyber-Physical Production Systems (CPPSs) to foster
adaptive production of mass-customizable products. Manufacturing approaches
based on capabilities and skills aim to support this adaptability by
encapsulating machine functions and decoupling them from specific production
processes. At the 2022 IEEE conference on Emerging Technologies and Factory
Automation (ETFA), a special session on capability- and skill-based
manufacturing is hosted for the fourth time. However, an overview on
capability- and skill based systems in factory automation and manufacturing
systems is missing. This paper aims to provide such an overview and give
insights to this particular field of research. We conducted a concise
literature survey of papers covering the topics of capabilities and skills in
manufacturing from the last ten years of the ETFA conference. We found 247
papers with a notion on capabilities and skills and identified and analyzed 34
relevant papers which met this survey's inclusion criteria. In this paper, we
provide (i) an overview of the research field, (ii) an analysis of the
characteristics of capabilities and skills, and (iii) a discussion on gaps and
opportunities.",-0.2271581,0.0015492318,0.14365621,A
5400,"Current research on capabilities & skills in manufacturing
[S18] faced incorrectly modeled capabilities that needed to      still has open gaps and opportunities for further research
be Ô¨Åltered out by consistency checking.","[S5], [S13] had additional modeling
effort for the initial capabilities due to a lack of tools.",The second most          (RQ3).,2022-04-26 17:15:25+00:00,Capabilities and Skills in Manufacturing: A Survey Over the Last Decade of ETFA,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Roman Froschauer'), arxiv.Result.Author('Aljosha K√∂cher'), arxiv.Result.Author('Kristof Meixner'), arxiv.Result.Author('Siwara Schmitt'), arxiv.Result.Author('Fabian Spitzer')]","Industry 4.0 envisions Cyber-Physical Production Systems (CPPSs) to foster
adaptive production of mass-customizable products. Manufacturing approaches
based on capabilities and skills aim to support this adaptability by
encapsulating machine functions and decoupling them from specific production
processes. At the 2022 IEEE conference on Emerging Technologies and Factory
Automation (ETFA), a special session on capability- and skill-based
manufacturing is hosted for the fourth time. However, an overview on
capability- and skill based systems in factory automation and manufacturing
systems is missing. This paper aims to provide such an overview and give
insights to this particular field of research. We conducted a concise
literature survey of papers covering the topics of capabilities and skills in
manufacturing from the last ten years of the ETFA conference. We found 247
papers with a notion on capabilities and skills and identified and analyzed 34
relevant papers which met this survey's inclusion criteria. In this paper, we
provide (i) an overview of the research field, (ii) an analysis of the
characteristics of capabilities and skills, and (iii) a discussion on gaps and
opportunities.",-0.1547733,0.07246948,0.055527974,A
5401,"In this paper, we provide     capabilities & skills?, RQ2: What are common understandings
                                       (i) an overview of the research Ô¨Åeld, (ii) an analysis of the       of capabilities & skills in research?, and RQ3: What are open
                                       characteristics of capabilities and skills, and (iii) a discussion  gaps and opportunities for further research?","We found 247 papers with a notion on capabilities          With this contribution, we aim to answer the following re-
                                       and skills and identiÔ¨Åed and analyzed 34 relevant papers which      search questions: RQ1: What is the current state of research of
                                       met this survey‚Äôs inclusion criteria.",on gaps and opportunities.,2022-04-26 17:15:25+00:00,Capabilities and Skills in Manufacturing: A Survey Over the Last Decade of ETFA,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Roman Froschauer'), arxiv.Result.Author('Aljosha K√∂cher'), arxiv.Result.Author('Kristof Meixner'), arxiv.Result.Author('Siwara Schmitt'), arxiv.Result.Author('Fabian Spitzer')]","Industry 4.0 envisions Cyber-Physical Production Systems (CPPSs) to foster
adaptive production of mass-customizable products. Manufacturing approaches
based on capabilities and skills aim to support this adaptability by
encapsulating machine functions and decoupling them from specific production
processes. At the 2022 IEEE conference on Emerging Technologies and Factory
Automation (ETFA), a special session on capability- and skill-based
manufacturing is hosted for the fourth time. However, an overview on
capability- and skill based systems in factory automation and manufacturing
systems is missing. This paper aims to provide such an overview and give
insights to this particular field of research. We conducted a concise
literature survey of papers covering the topics of capabilities and skills in
manufacturing from the last ten years of the ETFA conference. We found 247
papers with a notion on capabilities and skills and identified and analyzed 34
relevant papers which met this survey's inclusion criteria. In this paper, we
provide (i) an overview of the research field, (ii) an analysis of the
characteristics of capabilities and skills, and (iii) a discussion on gaps and
opportunities.",-0.22715816,0.0015492481,0.14365616,A
5402,"Current research on capabilities & skills in manufacturing
[S18] faced incorrectly modeled capabilities that needed to      still has open gaps and opportunities for further research
be Ô¨Åltered out by consistency checking.","[S5], [S13] had additional modeling
effort for the initial capabilities due to a lack of tools.",The second most          (RQ3).,2022-04-26 17:15:25+00:00,Capabilities and Skills in Manufacturing: A Survey Over the Last Decade of ETFA,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Roman Froschauer'), arxiv.Result.Author('Aljosha K√∂cher'), arxiv.Result.Author('Kristof Meixner'), arxiv.Result.Author('Siwara Schmitt'), arxiv.Result.Author('Fabian Spitzer')]","Industry 4.0 envisions Cyber-Physical Production Systems (CPPSs) to foster
adaptive production of mass-customizable products. Manufacturing approaches
based on capabilities and skills aim to support this adaptability by
encapsulating machine functions and decoupling them from specific production
processes. At the 2022 IEEE conference on Emerging Technologies and Factory
Automation (ETFA), a special session on capability- and skill-based
manufacturing is hosted for the fourth time. However, an overview on
capability- and skill based systems in factory automation and manufacturing
systems is missing. This paper aims to provide such an overview and give
insights to this particular field of research. We conducted a concise
literature survey of papers covering the topics of capabilities and skills in
manufacturing from the last ten years of the ETFA conference. We found 247
papers with a notion on capabilities and skills and identified and analyzed 34
relevant papers which met this survey's inclusion criteria. In this paper, we
provide (i) an overview of the research field, (ii) an analysis of the
characteristics of capabilities and skills, and (iii) a discussion on gaps and
opportunities.",-0.1547733,0.07246948,0.055527974,A
5533,"However, we observe that both methods have low trust in class
                        0.98     Ag en t s                                        6, indicating that further research should be done on this point
                                 Ra n d o m                                       for the production deployment of such models.","2https://www.tensorÔ¨Çow.org
                                                                    3https://www.pytorch.org
                                                Trust score on MNIST + MNIST-C    that matters but the quality of the instances to be labeled.","Mean Net Tt rust Score  0.97                                                         Finally, as for the execution time, the procedure triggered
                                                                                  on each iteration for scenarios 1 and 2 took about 20 seconds
                        0.96                                                      and 6s in average, respectively, for both MNIST and Fashion-
                                                                                  MNIST.",2022-04-29 17:33:14+00:00,Human-in-the-loop online multi-agent approach to increase trustworthiness in ML models through trust scores and data augmentation,cs.AI,"['cs.AI', 'cs.MA']","[arxiv.Result.Author('Gusseppe Bravo-Rocca'), arxiv.Result.Author('Peini Liu'), arxiv.Result.Author('Jordi Guitart'), arxiv.Result.Author('Ajay Dholakia'), arxiv.Result.Author('David Ellison'), arxiv.Result.Author('Miroslav Hodak')]","Increasing a ML model accuracy is not enough, we must also increase its
trustworthiness. This is an important step for building resilient AI systems
for safety-critical applications such as automotive, finance, and healthcare.
For that purpose, we propose a multi-agent system that combines both machine
and human agents. In this system, a checker agent calculates a trust score of
each instance (which penalizes overconfidence and overcautiousness in
predictions) using an agreement-based method and ranks it; then an improver
agent filters the anomalous instances based on a human rule-based procedure
(which is considered safe), gets the human labels, applies geometric data
augmentation, and retrains with the augmented data using transfer learning. We
evaluate the system on corrupted versions of the MNIST and FashionMNIST
datasets. We get an improvement in accuracy and trust score with just few
additional labels compared to a baseline approach.",0.00053150393,0.09573485,-0.16183418,A
5534,"However, we observe that both methods have low trust in class
                        0.98     Ag en t s                                        6, indicating that further research should be done on this point
                                 Ra n d o m                                       for the production deployment of such models.","2https://www.tensorÔ¨Çow.org
                                                                    3https://www.pytorch.org
                                                Trust score on MNIST + MNIST-C    that matters but the quality of the instances to be labeled.","Mean Net Tt rust Score  0.97                                                         Finally, as for the execution time, the procedure triggered
                                                                                  on each iteration for scenarios 1 and 2 took about 20 seconds
                        0.96                                                      and 6s in average, respectively, for both MNIST and Fashion-
                                                                                  MNIST.",2022-04-29 17:33:14+00:00,Human-in-the-loop online multi-agent approach to increase trustworthiness in ML models through trust scores and data augmentation,cs.AI,"['cs.AI', 'cs.MA']","[arxiv.Result.Author('Gusseppe Bravo-Rocca'), arxiv.Result.Author('Peini Liu'), arxiv.Result.Author('Jordi Guitart'), arxiv.Result.Author('Ajay Dholakia'), arxiv.Result.Author('David Ellison'), arxiv.Result.Author('Miroslav Hodak')]","Increasing a ML model accuracy is not enough, we must also increase its
trustworthiness. This is an important step for building resilient AI systems
for safety-critical applications such as automotive, finance, and healthcare.
For that purpose, we propose a multi-agent system that combines both machine
and human agents. In this system, a checker agent calculates a trust score of
each instance (which penalizes overconfidence and overcautiousness in
predictions) using an agreement-based method and ranks it; then an improver
agent filters the anomalous instances based on a human rule-based procedure
(which is considered safe), gets the human labels, applies geometric data
augmentation, and retrains with the augmented data using transfer learning. We
evaluate the system on corrupted versions of the MNIST and FashionMNIST
datasets. We get an improvement in accuracy and trust score with just few
additional labels compared to a baseline approach.",0.00053150393,0.09573485,-0.16183418,A
5571,"However, these analysis methods are still intuition-
                                        creates the Professional Go Dataset (PGD), containing 98,043        driven rather than data-driven, as players rarely use purpose-
                                        games played by 2,148 professional players from 1950 to 2021.       fully collected data to conduct further research.",This paper      a game.,"After manual cleaning and labeling, we provide detailed meta-
                                        information for each player, game, and tournament.",2022-04-30 12:53:04+00:00,PGD: A Large-scale Professional Go Dataset for Data-driven Analytics,cs.AI,"['cs.AI', 'cs.LG']",[arxiv.Result.Author('Yifan Gao')],"Lee Sedol is on a winning streak--does this legend rise again after the
competition with AlphaGo? Ke Jie is invincible in the world championship--can
he still win the title this time? Go is one of the most popular board games in
East Asia, with a stable professional sports system that has lasted for decades
in China, Japan, and Korea. There are mature data-driven analysis technologies
for many sports, such as soccer, basketball, and esports. However, developing
such technology for Go remains nontrivial and challenging due to the lack of
datasets, meta-information, and in-game statistics. This paper creates the
Professional Go Dataset (PGD), containing 98,043 games played by 2,148
professional players from 1950 to 2021. After manual cleaning and labeling, we
provide detailed meta-information for each player, game, and tournament.
Moreover, the dataset includes analysis results for each move in the match
evaluated by advanced AlphaZero-based AI. To establish a benchmark for PGD, we
further analyze the data and extract meaningful in-game features based on prior
knowledge related to Go that can indicate the game status. With the help of
complete meta-information and constructed in-game features, our results
prediction system achieves an accuracy of 75.30%, much higher than several
state-of-the-art approaches (64%-65%). As far as we know, PGD is the first
dataset for data-driven analytics in Go and even in board games. Beyond this
promising result, we provide more examples of tasks that benefit from our
dataset. The ultimate goal of this paper is to bridge this ancient game and the
modern data science community. It will advance research on Go-related analytics
to enhance the fan experience, help players improve their ability, and
facilitate other promising aspects. The dataset will be made publicly
available.",-0.07553084,-0.052107766,0.09188342,A
5654,"We believe that the benchmark will
SymSS, and EditEmbD, we did statistical signiÔ¨Åcance tests            facilitate further research in this crucial area of student mod-
based on results for numEval = 10 independent rounds as              elling for block-based visual programming environments.","For the three techniques NeurSS,           for programming tasks.",mentioned earlier.,2022-05-03 01:32:47+00:00,From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Adish Singla'), arxiv.Result.Author('Nikitas Theodoropoulos')]","Block-based visual programming environments are increasingly used to
introduce computing concepts to beginners. Given that programming tasks are
open-ended and conceptual, novice students often struggle when learning in
these environments. AI-driven programming tutors hold great promise in
automatically assisting struggling students, and need several components to
realize this potential. We investigate the crucial component of student
modeling, in particular, the ability to automatically infer students'
misconceptions for predicting (synthesizing) their behavior. We introduce a
novel benchmark, StudentSyn, centered around the following challenge: For a
given student, synthesize the student's attempt on a new target task after
observing the student's attempt on a fixed reference task. This challenge is
akin to that of program synthesis; however, instead of synthesizing a
{solution} (i.e., program an expert would write), the goal here is to
synthesize a {student attempt} (i.e., program that a given student would
write). We first show that human experts (TutorSS) can achieve high performance
on the benchmark, whereas simple baselines perform poorly. Then, we develop two
neuro/symbolic techniques (NeurSS and SymSS) in a quest to close this gap with
TutorSS. We will publicly release the benchmark to facilitate future research
in this area.",-0.020636149,-0.026533369,-0.16290164,A
5655,"We believe that the benchmark will
instances in our experiments, we ensure that all target tasks   facilitate further research in this crucial area of student mod-
and behavior types are represented equally.",When sampling large number of         for programming tasks.,eling for block-based visual programming environments.,2022-05-03 01:32:47+00:00,From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Adish Singla'), arxiv.Result.Author('Nikitas Theodoropoulos')]","Block-based visual programming environments are increasingly used to
introduce computing concepts to beginners. Given that programming tasks are
open-ended and conceptual, novice students often struggle when learning in
these environments. AI-driven programming tutors hold great promise in
automatically assisting struggling students, and need several components to
realize this potential. We investigate the crucial component of student
modeling, in particular, the ability to automatically infer students'
misconceptions for predicting (synthesizing) their behavior. We introduce a
novel benchmark, StudentSyn, centered around the following challenge: For a
given student, synthesize the student's attempt on a new target task after
observing the student's attempt on a fixed reference task. This challenge is
akin to that of program synthesis; however, instead of synthesizing a
{solution} (i.e., program an expert would write), the goal here is to
synthesize a {student attempt} (i.e., program that a given student would
write). We first show that human experts (TutorSS) can achieve high performance
on the benchmark, whereas simple baselines perform poorly. Then, we develop two
neuro/symbolic techniques (NeurSS and SymSS) in a quest to close this gap with
TutorSS.",0.11291553,-0.09112212,-0.023043001,C
5664,"these limitations, the DrugEHRQA dataset is an invalu-
Following this, the questions were answered using           able resource which will encourage further research in
TREQS or BERT/Clinical BERT QA, based on the pre-           multimodal QA over EHRs.","But despite
modality selection network gave an accuracy of 99.6%.",dicted modality.,2022-05-03 03:50:50+00:00,DrugEHRQA: A Question Answering Dataset on Structured and Unstructured Electronic Health Records For Medicine Related Queries,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jayetri Bardhan'), arxiv.Result.Author('Anthony Colas'), arxiv.Result.Author('Kirk Roberts'), arxiv.Result.Author('Daisy Zhe Wang')]","This paper develops the first question answering dataset (DrugEHRQA)
containing question-answer pairs from both structured tables and unstructured
notes from a publicly available Electronic Health Record (EHR). EHRs contain
patient records, stored in structured tables and unstructured clinical notes.
The information in structured and unstructured EHRs is not strictly disjoint:
information may be duplicated, contradictory, or provide additional context
between these sources. Our dataset has medication-related queries, containing
over 70,000 question-answer pairs. To provide a baseline model and help analyze
the dataset, we have used a simple model (MultimodalEHRQA) which uses the
predictions of a modality selection network to choose between EHR tables and
clinical notes to answer the questions. This is used to direct the questions to
the table-based or text-based state-of-the-art QA model. In order to address
the problem arising from complex, nested queries, this is the first time
Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers (RAT-SQL)
has been used to test the structure of query templates in EHR data. Our goal is
to provide a benchmark dataset for multi-modal QA systems, and to open up new
avenues of research in improving question answering over EHR structured data by
using context from unstructured clinical data.",-0.097838774,-0.26875293,-0.1566531,A
5665,"Although several approaches and even
implemented systems exist Nazemi [2018], the increasingly complex and visual representations require further research
to meet the demands of a speciÔ¨Åc user or a user group.","It reduces the complexity of analytical
reasoning tasks and leads to more efÔ¨Åcient and effective problem-solving.","Visual parametrization and model adjustment: The direct and deep coupling of learning methods and interactive
visualizations enables visual parametrization and learning model adjustment to improve the learning results and to
reduce overÔ¨Åtting.",2022-05-03 04:17:21+00:00,Visual Knowledge Discovery with Artificial Intelligence: Challenges and Future Directions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Boris Kovalerchuk'), arxiv.Result.Author('RƒÉzvan Andonie'), arxiv.Result.Author('Nuno Datia'), arxiv.Result.Author('Kawa Nazemi')]","This volume is devoted to the emerging field of Integrated Visual Knowledge
Discovery that combines advances in Artificial Intelligence/Machine Learning
(AI/ML) and Visualization/Visual Analytics. Chapters included are extended
versions of the selected AI and Visual Analytics papers and related symposia at
the recent International Information Visualization Conferences (IV2019 and
IV2020). AI/ML face a long-standing challenge of explaining models to humans.
Models explanation is fundamentally human activity, not only an algorithmic
one. In this chapter we aim to present challenges and future directions within
the field of Visual Analytics, Visual Knowledge Discovery and AI/ML, and to
discuss the role of visualization in visual AI/ML. In addition, we describe
progress in emerging Full 2D ML, natural language processing, and AI/ML in
multidimensional data aided by visual means.",0.22187927,-0.2025932,-0.00029253005,C
5666,"Although several approaches and even
implemented systems exist Nazemi [2018], the increasingly complex and visual representations require further research
to meet the demands of a speciÔ¨Åc user or a user group.","It reduces the complexity of analytical
reasoning tasks and leads to more efÔ¨Åcient and effective problem-solving.","Visual parametrization and model adjustment: The direct and deep coupling of learning methods and interactive
visualizations enables visual parametrization and learning model adjustment to improve the learning results and to
reduce overÔ¨Åtting.",2022-05-03 04:17:21+00:00,Visual Knowledge Discovery with Artificial Intelligence: Challenges and Future Directions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Boris Kovalerchuk'), arxiv.Result.Author('RƒÉzvan Andonie'), arxiv.Result.Author('Nuno Datia'), arxiv.Result.Author('Kawa Nazemi'), arxiv.Result.Author('Ebad Banissi')]","This volume is devoted to the emerging field of Integrated Visual Knowledge
Discovery that combines advances in Artificial Intelligence/Machine Learning
(AI/ML) and Visualization/Visual Analytics. Chapters included are extended
versions of the selected AI and Visual Analytics papers and related symposia at
the recent International Information Visualization Conferences (IV2019 and
IV2020). AI/ML face a long-standing challenge of explaining models to humans.
Models explanation is fundamentally human activity, not only an algorithmic
one. In this chapter we aim to present challenges and future directions within
the field of Visual Analytics, Visual Knowledge Discovery and AI/ML, and to
discuss the role of visualization in visual AI/ML. In addition, we describe
progress in emerging Full 2D ML, natural language processing, and AI/ML in
multidimensional data aided by visual means.",0.22187927,-0.2025932,-0.00029253005,C
5669,"with respect to the state-of-the-art approaches does not seem
Even if LOLIB instances are heterogeneous, regarding their          relevant, which encourages further research on this kind of
origin or the procedure used to create them, training the model     models.","First, we are in the early stages of
                                                                    NN-based models for optimization, and the performance gap
   Table IV gathers the results obtained for the different setups.","Secondly, looking at Table II, the end-to-end model is
with random instances (setups 1 and 2) is notably better than       able to provide a solution in a few minutes for the largest size
training the model directly using the particular set of instances   (n = 1000), while metaheurstics require a couple of hours.",2022-05-03 07:54:56+00:00,Neural Combinatorial Optimization: a New Player in the Field,cs.AI,"['cs.AI', 'cs.DM']","[arxiv.Result.Author('Andoni I. Garmendia'), arxiv.Result.Author('Josu Ceberio'), arxiv.Result.Author('Alexander Mendiburu')]","Neural Combinatorial Optimization attempts to learn good heuristics for
solving a set of problems using Neural Network models and Reinforcement
Learning. Recently, its good performance has encouraged many practitioners to
develop neural architectures for a wide variety of combinatorial problems.
However, the incorporation of such algorithms in the conventional optimization
framework has raised many questions related to their performance and the
experimental comparison with other methods such as exact algorithms, heuristics
and metaheuristics. This paper presents a critical analysis on the
incorporation of algorithms based on neural networks into the classical
combinatorial optimization framework. Subsequently, a comprehensive study is
carried out to analyse the fundamental aspects of such algorithms, including
performance, transferability, computational cost and generalization to
larger-sized instances. To that end, we select the Linear Ordering Problem as a
case of study, an NP-hard problem, and develop a Neural Combinatorial
Optimization model to optimize it. Finally, we discuss how the analysed aspects
apply to a general learning framework, and suggest new directions for future
work in the area of Neural Combinatorial Optimization algorithms.",0.096448824,0.27087563,-0.29052132,B
5810,"With this, any
further research can be structured more easily, whether considering speciÔ¨Åc elements,
processes or the relation between them.",The framework gives an explicit formalisation of a monitoring setting.,"For instance, consider the frequency at which
each of these processes is run.",2022-05-05 10:51:59+00:00,"Monitoring AI systems: A Problem Analysis, Framework and Outlook",cs.AI,['cs.AI'],[arxiv.Result.Author('Annet Onnes')],"Knowledge-based systems have been used to monitor machines and processes in
the real world. In this paper we propose the use of knowledge-based systems to
monitor other AI systems in operation. We motivate and provide a problem
analysis of this novel setting and subsequently propose a framework that allows
for structuring future research related to this setting. Several directions for
further research are also discussed.",-0.3280459,0.2991445,0.011308856,B
5903,"Although, self-supervised learning is a        recommended more frequently and less popular items tend to
very promising research area in AI, it requires further research    get limited attention.","Popular items would thus be
the training burden.","Different from data bias, algorithmic bias
to reduce its training effort for sustainable development of AI.",2022-05-08 09:38:35+00:00,A Survey on AI Sustainability: Emerging Trends on Learning Algorithms and Research Challenges,cs.AI,['cs.AI'],"[arxiv.Result.Author('Zhenghua Chen'), arxiv.Result.Author('Min Wu'), arxiv.Result.Author('Alvin Chan'), arxiv.Result.Author('Xiaoli Li'), arxiv.Result.Author('Yew-Soon Ong')]","Artificial Intelligence (AI) is a fast-growing research and development (R&D)
discipline which is attracting increasing attention because of its promises to
bring vast benefits for consumers and businesses, with considerable benefits
promised in productivity growth and innovation. To date it has reported
significant accomplishments in many areas that have been deemed as challenging
for machines, ranging from computer vision, natural language processing, audio
analysis to smart sensing and many others. The technical trend in realizing the
successes has been towards increasing complex and large size AI models so as to
solve more complex problems at superior performance and robustness. This rapid
progress, however, has taken place at the expense of substantial environmental
costs and resources. Besides, debates on the societal impacts of AI, such as
fairness, safety and privacy, have continued to grow in intensity. These issues
have presented major concerns pertaining to the sustainable development of AI.
In this work, we review major trends in machine learning approaches that can
address the sustainability problem of AI. Specifically, we examine emerging AI
methodologies and algorithms for addressing the sustainability issue of AI in
two major aspects, i.e., environmental sustainability and social sustainability
of AI. We will also highlight the major limitations of existing studies and
propose potential research challenges and directions for the development of
next generation of sustainable AI techniques. We believe that this technical
review can help to promote a sustainable development of AI R&D activities for
the research community.",0.18833368,-0.15671022,0.1619469,C
6109,"However, the tools for mitigating
harms of generalist agents are relatively underdeveloped, and require further research before these agents
are deployed.","For the sake of transparency, we
document the intended use cases of Gato in the model card in Appendix A.","Since our generalist agent can act as a vision-language model, it inherits similar concerns as discussed in (Wei-
dinger et al., 2021; Bommasani et al., 2021; Rae et al., 2021; Alayrac et al., 2022).",2022-05-12 16:03:26+00:00,A Generalist Agent,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Scott Reed'), arxiv.Result.Author('Konrad Zolna'), arxiv.Result.Author('Emilio Parisotto'), arxiv.Result.Author('Sergio Gomez Colmenarejo'), arxiv.Result.Author('Alexander Novikov'), arxiv.Result.Author('Gabriel Barth-Maron'), arxiv.Result.Author('Mai Gimenez'), arxiv.Result.Author('Yury Sulsky'), arxiv.Result.Author('Jackie Kay'), arxiv.Result.Author('Jost Tobias Springenberg'), arxiv.Result.Author('Tom Eccles'), arxiv.Result.Author('Jake Bruce'), arxiv.Result.Author('Ali Razavi'), arxiv.Result.Author('Ashley Edwards'), arxiv.Result.Author('Nicolas Heess'), arxiv.Result.Author('Yutian Chen'), arxiv.Result.Author('Raia Hadsell'), arxiv.Result.Author('Oriol Vinyals'), arxiv.Result.Author('Mahyar Bordbar'), arxiv.Result.Author('Nando de Freitas')]","Inspired by progress in large-scale language modeling, we apply a similar
approach towards building a single generalist agent beyond the realm of text
outputs. The agent, which we refer to as Gato, works as a multi-modal,
multi-task, multi-embodiment generalist policy. The same network with the same
weights can play Atari, caption images, chat, stack blocks with a real robot
arm and much more, deciding based on its context whether to output text, joint
torques, button presses, or other tokens. In this report we describe the model
and the data, and document the current capabilities of Gato.",0.063330665,-0.12968874,0.16890661,C
6154,"An interesting direction for further research is to enable PURE to have
deeper interactions with the user.","Currently, we start with an
uncertainty-aware model for privacy classification and enhanced it further with users‚Äô personalized
risk for misclassification.","For example, it could interact with the user to obtain labels for
the images that it is uncertain about and further enhance its ability for classification with this new
personal data.",2022-05-13 10:15:04+00:00,A Self-aware Personal Assistant for Making Personalized Privacy Decisions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Gonul Ayci'), arxiv.Result.Author('Murat Sensoy'), arxiv.Result.Author('Arzucan √ñzg√úr'), arxiv.Result.Author('Pinar Yolum')]","Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well.",-0.14455032,-0.27791205,0.11964392,A
6155,"An interesting direction for further research is to enable PURE to have
deeper interactions with the user.","Currently, we start with an
uncertainty-aware model for privacy classification and enhanced it further with users‚Äô personalized
risk for misclassification.","For example, it could interact with the user to obtain labels for
the images that it is uncertain about and further enhance its ability for classification with this new
personal data.",2022-05-13 10:15:04+00:00,A Self-aware Personal Assistant for Making Personalized Privacy Decisions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Gonul Ayci'), arxiv.Result.Author('Murat Sensoy'), arxiv.Result.Author('Arzucan √ñzg√ºr'), arxiv.Result.Author('Pƒ±nar Yolum')]","Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well.",-0.14455032,-0.27791205,0.11964392,A
6156,"An interesting direction for further research is to enable PURE to have
deeper interactions with the user.","Currently, we start with an
uncertainty-aware model for privacy classification and enhanced it further with users‚Äô personalized
risk for misclassification.","For example, it could interact with the user to obtain labels for
the images that it is uncertain about and further enhance its ability for classification with this new
personal data.",2022-05-13 10:15:04+00:00,Uncertainty-aware Personal Assistant for Making Personalized Privacy Decisions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Gonul Ayci'), arxiv.Result.Author('Murat Sensoy'), arxiv.Result.Author('Arzucan √ñzg√ºr'), arxiv.Result.Author('Pƒ±nar Yolum')]","Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well.",-0.14455032,-0.27791205,0.11964392,A
6157,"An interesting direction for further research is to enable PURE to have
deeper interactions with the user.","Currently, we start with an
uncertainty-aware model for privacy classification and enhanced it further with users‚Äô personalized
risk for misclassification.","For example, it could interact with the user to obtain labels for
the images that it is uncertain about and further enhance its ability for classification with this new
personal data.",2022-05-13 10:15:04+00:00,Uncertainty-aware Personal Assistant for Making Personalized Privacy Decisions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Gonul Ayci'), arxiv.Result.Author('Murat Sensoy'), arxiv.Result.Author('Arzucan √ñzg√ºr'), arxiv.Result.Author('Pƒ±nar Yolum')]","Many software systems, such as online social networks enable users to share
information about themselves. While the action of sharing is simple, it
requires an elaborate thought process on privacy: what to share, with whom to
share, and for what purposes. Thinking about these for each piece of content to
be shared is tedious. Recent approaches to tackle this problem build personal
assistants that can help users by learning what is private over time and
recommending privacy labels such as private or public to individual content
that a user considers sharing. However, privacy is inherently ambiguous and
highly personal. Existing approaches to recommend privacy decisions do not
address these aspects of privacy sufficiently. Ideally, a personal assistant
should be able to adjust its recommendation based on a given user, considering
that user's privacy understanding. Moreover, the personal assistant should be
able to assess when its recommendation would be uncertain and let the user make
the decision on her own. Accordingly, this paper proposes a personal assistant
that uses evidential deep learning to classify content based on its privacy
label. An important characteristic of the personal assistant is that it can
model its uncertainty in its decisions explicitly, determine that it does not
know the answer, and delegate from making a recommendation when its uncertainty
is high. By factoring in the user's own understanding of privacy, such as risk
factors or own labels, the personal assistant can personalize its
recommendations per user. We evaluate our proposed personal assistant using a
well-known data set. Our results show that our personal assistant can
accurately identify uncertain cases, personalize them to its user's needs, and
thus helps users preserve their privacy well.",-0.14455032,-0.27791205,0.11964392,A
6172,"This paper Ô¨Ålls that gap and, we hope, provides a useful platform for further research.","However, until now this line of work has not
incorporated traditional economic phenomena such as trade, bargaining, specialisation, consumption,
and production.","Acknowledgements

We would like to thank Gillian HadÔ¨Åeld for a very helpful discussion with us on an early version of this
work.",2022-05-13 16:44:51+00:00,Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG', 'cs.MA']","[arxiv.Result.Author('Michael Bradley Johanson'), arxiv.Result.Author('Edward Hughes'), arxiv.Result.Author('Finbarr Timbers'), arxiv.Result.Author('Joel Z. Leibo')]","Advances in artificial intelligence often stem from the development of new
environments that abstract real-world situations into a form where research can
be done conveniently. This paper contributes such an environment based on ideas
inspired by elementary Microeconomics. Agents learn to produce resources in a
spatially complex world, trade them with one another, and consume those that
they prefer. We show that the emergent production, consumption, and pricing
behaviors respond to environmental conditions in the directions predicted by
supply and demand shifts in Microeconomics. We also demonstrate settings where
the agents' emergent prices for goods vary over space, reflecting the local
abundance of goods. After the price disparities emerge, some agents then
discover a niche of transporting goods between regions with different
prevailing prices -- a profitable strategy because they can buy goods where
they are cheap and sell them where they are expensive. Finally, in a series of
ablation experiments, we investigate how choices in the environmental rewards,
bartering actions, agent architecture, and ability to consume tradable goods
can either aid or inhibit the emergence of this economic behavior. This work is
part of the environment development branch of a research program that aims to
build human-like artificial general intelligence through multi-agent
interactions in simulated societies. By exploring which environment features
are needed for the basic phenomena of elementary microeconomics to emerge
automatically from learning, we arrive at an environment that differs from
those studied in prior multi-agent reinforcement learning work along several
dimensions. For example, the model incorporates heterogeneous tastes and
physical abilities, and agents negotiate with one another as a grounded form of
communication.",-0.31335604,0.26165685,0.08668593,B
6191,"input handling
                                                                                                                                                                                    6
   By sharing this work and associated code and data publicly,        Local player          Input devices                                              Game files           Read packets
we aim to encourage further research on maintaining trust in            (hacker)
online gaming.","‚Ä¢ We discuss the ethical and broader impact of sharing this                                                                                         Game process         Network
      work.","1, 2, 4, 5          1, 4, 5                                      9
II.",2022-05-14 13:33:23+00:00,GAN-Aimbots: Using Machine Learning for Cheating in First Person Shooters,cs.AI,"['cs.AI', 'cs.CR', 'cs.LG']","[arxiv.Result.Author('Anssi Kanervisto'), arxiv.Result.Author('Tomi Kinnunen'), arxiv.Result.Author('Ville Hautam√§ki')]","Playing games with cheaters is not fun, and in a multi-billion-dollar video
game industry with hundreds of millions of players, game developers aim to
improve the security and, consequently, the user experience of their games by
preventing cheating. Both traditional software-based methods and statistical
systems have been successful in protecting against cheating, but recent
advances in the automatic generation of content, such as images or speech,
threaten the video game industry; they could be used to generate artificial
gameplay indistinguishable from that of legitimate human players. To better
understand this threat, we begin by reviewing the current state of multiplayer
video game cheating, and then proceed to build a proof-of-concept method,
GAN-Aimbot. By gathering data from various players in a first-person shooter
game we show that the method improves players' performance while remaining
hidden from automatic and manual protection mechanisms. By sharing this work we
hope to raise awareness on this issue and encourage further research into
protecting the gaming communities.",-0.08519426,-0.010560257,0.26213953,A
6232,"Before all necessary data types can be
included in an ontology, further research in capturing data is also required [52].","For instance, maintenance, simulation, and
performance-based data are required to support SCCx applications while these data types were found in
relatively few ontologies (19%, 26%, and 35%, respectively).","For instance, where BIM
models do not exist, strategies such as 3D scanning or automated processes to convert 2D floor plans to
BIM models [80] can be employed to avoid manually inputting geometric data.",2022-05-11 13:59:45+00:00,A review of ontologies for smart and continuous commissioning,cs.AI,"['cs.AI', 'cs.DB']","[arxiv.Result.Author('Sara Gilani'), arxiv.Result.Author('Caroline Quinn'), arxiv.Result.Author('J. J. McArthur')]","Smart and continuous commissioning (SCCx) of buildings can result in a
significant reduction in the gap between design and operational performance.
Ontologies play an important role in SCCx as they facilitate data readability
and reasoning by machines. A better understanding of ontologies is required in
order to develop and incorporate them in SCCx. This paper critically reviews
the state-of-the-art research on building data ontologies since 2014 within the
SCCx domain through sorting them based on building data types, general
approaches, and applications. The data types of two main domains of building
information modeling and building management system have been considered in the
majority of existing ontologies. Three main applications are evident from a
critical analysis of existing ontologies: (1) key performance indicator
calculation, (2) building performance improvement, and (3) fault detection and
diagnosis. The key gaps found in the literature review are a holistic ontology
for SCCx and insight on how such approaches should be evaluated. Based on these
findings, this study provides recommendations for future necessary research
including: identification of SCCx-related data types, assessment of ontology
performance, and creation of open-source approaches.",-0.20210348,0.09101319,-0.24906072,A
6233,This review identified gaps in the literature and the need for further research.,"This review systematically selected publications
relating to data ontology for SCCx published since 2014 and performed a meta-analysis on building data
types, ontology approaches, and the overarching applications of ontologies.","Proposed ontologies
lacked the ability to meet SCCx ontology application of managing building operation and maintenance
data over its operational life, be thoroughly evaluated against their purpose, and be used in future
development due to their proprietary nature.",2022-05-11 13:59:45+00:00,A review of ontologies for smart and continuous commissioning,cs.AI,"['cs.AI', 'cs.DB']","[arxiv.Result.Author('Sara Gilani'), arxiv.Result.Author('Caroline Quinn'), arxiv.Result.Author('J. J. McArthur')]","Smart and continuous commissioning (SCCx) of buildings can result in a
significant reduction in the gap between design and operational performance.
Ontologies play an important role in SCCx as they facilitate data readability
and reasoning by machines. A better understanding of ontologies is required in
order to develop and incorporate them in SCCx. This paper critically reviews
the state-of-the-art research on building data ontologies since 2014 within the
SCCx domain through sorting them based on building data types, general
approaches, and applications. The data types of two main domains of building
information modeling and building management system have been considered in the
majority of existing ontologies. Three main applications are evident from a
critical analysis of existing ontologies: (1) key performance indicator
calculation, (2) building performance improvement, and (3) fault detection and
diagnosis. The key gaps found in the literature review are a holistic ontology
for SCCx and insight on how such approaches should be evaluated. Based on these
findings, this study provides recommendations for future necessary research
including: identification of SCCx-related data types, assessment of ontology
performance, and creation of open-source approaches.",-0.24822645,0.12826018,-0.14571714,A
6234,"Before all necessary data
types can be included in an ontology, further research in capturing data is also required [53].","For instance, maintenance,
simulation, and performance-based data are required to support SOCx applications while these data types
were found in relatively few ontologies (19%, 26%, and 35%, respectively).","For instance,
where BIM models do not exist, strategies such as 3D scanning or automated processes to convert 2D
floor plans to BIM models [90] can be employed to avoid manually inputting geometric data.",2022-05-11 13:59:45+00:00,A review of ontologies for smart and continuous commissioning,cs.AI,"['cs.AI', 'cs.DB', '68P05 (Primary), 68U35 (Secondary)', 'C.3']","[arxiv.Result.Author('Sara Gilani'), arxiv.Result.Author('Caroline Quinn'), arxiv.Result.Author('J. J. McArthur')]","Smart and continuous commissioning (SCCx) of buildings can result in a
significant reduction in the gap between design and operational performance.
Ontologies play an important role in SCCx as they facilitate data readability
and reasoning by machines. A better understanding of ontologies is required in
order to develop and incorporate them in SCCx. This paper critically reviews
the state-of-the-art research on building data ontologies since 2014 within the
SCCx domain through sorting them based on building data types, general
approaches, and applications. The data types of two main domains of building
information modeling and building management system have been considered in the
majority of existing ontologies. Three main applications are evident from a
critical analysis of existing ontologies: (1) key performance indicator
calculation, (2) building performance improvement, and (3) fault detection and
diagnosis. The key gaps found in the literature review are a holistic ontology
for SCCx and insight on how such approaches should be evaluated. Based on these
findings, this study provides recommendations for future necessary research
including: identification of SCCx-related data types, assessment of ontology
performance, and creation of open-source approaches.",-0.1956493,0.080616914,-0.24045141,A
6235,This review identified gaps in the literature and the need for further research.,"This review systematically selected publications relating to data
ontology for SOCx published since 2014 and performed a meta-analysis on building data types, ontology
approaches, and the overarching applications of ontologies.","Proposed ontologies lacked
the ability to meet SOCx ontology application of managing building operation and maintenance data over
its operational life, be thoroughly evaluated against their purpose, and be used in future development due
to their proprietary nature.",2022-05-11 13:59:45+00:00,A review of ontologies for smart and continuous commissioning,cs.AI,"['cs.AI', 'cs.DB', '68P05 (Primary), 68U35 (Secondary)', 'C.3']","[arxiv.Result.Author('Sara Gilani'), arxiv.Result.Author('Caroline Quinn'), arxiv.Result.Author('J. J. McArthur')]","Smart and continuous commissioning (SCCx) of buildings can result in a
significant reduction in the gap between design and operational performance.
Ontologies play an important role in SCCx as they facilitate data readability
and reasoning by machines. A better understanding of ontologies is required in
order to develop and incorporate them in SCCx. This paper critically reviews
the state-of-the-art research on building data ontologies since 2014 within the
SCCx domain through sorting them based on building data types, general
approaches, and applications. The data types of two main domains of building
information modeling and building management system have been considered in the
majority of existing ontologies. Three main applications are evident from a
critical analysis of existing ontologies: (1) key performance indicator
calculation, (2) building performance improvement, and (3) fault detection and
diagnosis. The key gaps found in the literature review are a holistic ontology
for SCCx and insight on how such approaches should be evaluated. Based on these
findings, this study provides recommendations for future necessary research
including: identification of SCCx-related data types, assessment of ontology
performance, and creation of open-source approaches.",-0.23461363,0.10694368,-0.13827997,A
6332,"The study pinpoints current gaps in research that may represent oppor-
tunities for further research on diÔ¨Äerent AI algorithms using communication
in multiple domains.","The various classiÔ¨Åcations provided in this work may serve researchers
as initial categorizations or a base foundation with the will to further extend
them in conducting other systematic mapping studies or systematic literature
reviews.","These gap areas lack the research which can be explored
further.",2022-05-17 14:38:38+00:00,A Comprehensive Study on Artificial Intelligence Algorithms to Implement Safety Using Communication Technologies,cs.AI,"['cs.AI', 'cs.NI']","[arxiv.Result.Author('Rafia Inam'), arxiv.Result.Author('Alberto Yukinobu Hata'), arxiv.Result.Author('Vlasjov Prifti'), arxiv.Result.Author('Sara Abbaspour Asadollah')]","The recent development of artificial intelligence (AI) has increased the
interest of researchers and practitioners towards applying its techniques into
multiple domains like automotive, health care and air space to achieve
automation. Combined to these applications, the attempt to use AI techniques
into carrying out safety issues is momentarily at a progressive state. As AI
problems are getting even more complex, large processing power is demanded for
safety-critical systems to fulfill real-time requirements. These challenges can
be solved through edge or cloud computing, which makes the communication an
integral part of the solution. This study aims at providing a comprehensive
picture of the state of the art AI based safety solutions that uses different
communication technologies in diverse application domains. To achieve this, a
systematic mapping study is conducted and 565 relevant papers are shortlisted
through a multistage selection process, which are then analyzed according to a
systematically defined classification framework. The results of the study are
based on these main objectives: to clarify current research gaps in the field,
to identify the possibility of increased usage of cellular communication in
multiple domains, to identify the mostly used AI algorithms and to summarize
the emerging future research trends on the topic. The results demonstrate that
automotive domain is the one applying AI and communication the most to
implement safety and the most used AI in this domain is neural networks,
clustering and computer vision; applying cellular communication to automotive
domain is highest; the use of non-cellular communication technologies is
dominant however a clear trend of a rapid increase in the use of cellular
communication is observed specially from 2020 with the roll-out of 5G
technology.",0.12048589,0.050914947,0.10288247,C
6335,"The
Empirical validation of our theory in these contexts requires   U.S. Government is authorized to reproduce and distribute
further research.",and S.C.-H.Y.,"Third, our framework currently relies on      reprints for Governmental purposes notwithstanding any
measurements of human generated explanations to predict         copyright notation thereon.",2022-05-17 15:52:24+00:00,A Psychological Theory of Explainability,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Scott Cheng-Hsin Yang'), arxiv.Result.Author('Tomas Folke'), arxiv.Result.Author('Patrick Shafto')]","The goal of explainable Artificial Intelligence (XAI) is to generate
human-interpretable explanations, but there are no computationally precise
theories of how humans interpret AI generated explanations. The lack of theory
means that validation of XAI must be done empirically, on a case-by-case basis,
which prevents systematic theory-building in XAI. We propose a psychological
theory of how humans draw conclusions from saliency maps, the most common form
of XAI explanation, which for the first time allows for precise prediction of
explainee inference conditioned on explanation. Our theory posits that absent
explanation humans expect the AI to make similar decisions to themselves, and
that they interpret an explanation by comparison to the explanations they
themselves would give. Comparison is formalized via Shepard's universal law of
generalization in a similarity space, a classic theory from cognitive science.
A pre-registered user study on AI image classifications with saliency map
explanations demonstrate that our theory quantitatively matches participants'
predictions of the AI.",-0.35537934,-0.14002883,0.07628615,A
6357,"Moreover, we
                                              an open-source repository for 14 embedding-based         provide a comparative evaluation of the latest EA methods
                                              EA methods and present the analysis for invoking         speciÔ¨Åc to the listed RQs to show which methods are better
                                              further research motivations in the Ô¨Åeld of EA.",We further create         formance adversary phenomena like hubness.,suited for a given industrial setting.,2022-05-18 07:59:03+00:00,"Entity Alignment For Knowledge Graphs: Progress, Challenges, and Empirical Studies",cs.AI,['cs.AI'],"[arxiv.Result.Author('Deepak Chaurasiya'), arxiv.Result.Author('Anil Surisetty'), arxiv.Result.Author('Nitish Kumar'), arxiv.Result.Author('Alok Singh'), arxiv.Result.Author('Vikrant Dey'), arxiv.Result.Author('Aakarsh Malhotra'), arxiv.Result.Author('Gaurav Dhama'), arxiv.Result.Author('Ankur Arora')]","Entity Alignment (EA) identifies entities across databases that refer to the
same entity. Knowledge graph-based embedding methods have recently dominated EA
techniques. Such methods map entities to a low-dimension space and align them
based on their similarities. With the corpus of EA methodologies growing
rapidly, this paper presents a comprehensive analysis of various existing EA
methods, elaborating their applications and limitations. Further, we
distinguish the methods based on their underlying algorithms and the
information they incorporate to learn entity representations. Based on
challenges in industrial datasets, we bring forward $4$ research questions
(RQs). These RQs empirically analyse the algorithms from the perspective of
\textit{Hubness, Degree distribution, Non-isomorphic neighbourhood,} and
\textit{Name bias}. For Hubness, where one entity turns up as the nearest
neighbour of many other entities, we define an $h$-score to quantify its effect
on the performance of various algorithms. Additionally, we try to level the
playing field for algorithms that rely primarily on name-bias existing in the
benchmarking open-source datasets by creating a low name bias dataset. We
further create an open-source repository for $14$ embedding-based EA methods
and present the analysis for invoking further research motivations in the field
of EA.",-0.15114118,0.05447734,-0.19141346,A
6372,"We compare the consistent explanation to the baseline           A couple of extensions and directions of further research
which is obtained by aggregating independent local counter-          can be based on this initial work.",4.,"In particular, driven by the
factual explanations for every decision: that means, we com-         speciÔ¨Åc application domain, we aim for the following: How
pute a counterfactual explanations of each model separately,         does the method perform for more than one sensor fault, i.e.",2022-05-18 14:55:56+00:00,One Explanation to Rule them All -- Ensemble Consistent Explanations,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Andr√© Artelt'), arxiv.Result.Author('Stelios Vrachimis'), arxiv.Result.Author('Demetrios Eliades'), arxiv.Result.Author('Marios Polycarpou'), arxiv.Result.Author('Barbara Hammer')]","Transparency is a major requirement of modern AI based decision making
systems deployed in real world. A popular approach for achieving transparency
is by means of explanations. A wide variety of different explanations have been
proposed for single decision making systems. In practice it is often the case
to have a set (i.e. ensemble) of decisions that are used instead of a single
decision only, in particular in complex systems. Unfortunately, explanation
methods for single decision making systems are not easily applicable to
ensembles -- i.e. they would yield an ensemble of individual explanations which
are not necessarily consistent, hence less useful and more difficult to
understand than a single consistent explanation of all observed phenomena. We
propose a novel concept for consistently explaining an ensemble of decisions
locally with a single explanation -- we introduce a formal concept, as well as
a specific implementation using counterfactual explanations.",-0.21440431,0.011958207,0.07463862,A
6465,"These different patterns show the adaptability of SPMARL and
demonstrate the importance to further study the interaction between agents, environment dynamics
and the characteristics of underlying MARL algorithms.","This is consistent with the linear case where the performance increases when
increasing the number of agents.","7 Conclusion

This paper presents a principled approach, self-paced multi-agent reinforcement learning (SPMARL),
to generate curricula for MARL.",2022-05-20 08:16:30+00:00,Self-Paced Multi-Agent Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG', 'cs.MA']","[arxiv.Result.Author('Wenshuai Zhao'), arxiv.Result.Author('Joni Pajarinen')]","Curriculum reinforcement learning (CRL) aims to speed up learning of a task
by changing gradually the difficulty of the task from easy to hard through
control of factors such as initial state or environment dynamics. While
automating CRL is well studied in the single-agent setting, in multi-agent
reinforcement learning (MARL) an open question is whether control of the number
of agents with other factors in a principled manner is beneficial, prior
approaches typically relying on hand-crafted heuristics. In addition, how the
tasks evolve as the number of agents changes remains understudied, which is
critical for scaling to more challenging tasks. We introduce self-paced MARL
(SPMARL) that enables optimizing the number of agents with other environment
factors in a principled way, and, show that usual assumptions such as that
fewer agents make the task always easier are not generally valid. The
curriculum induced by SPMARL reveals the evolution of tasks w.r.t. number of
agents and experiments show that SPMARL improves the performance when the
number of agents sufficiently influences task difficulty.",0.34835473,0.17921619,0.2425262,C
6476,"However, further research
                                                                         would be needed in order to deal with more complex use
                                                                         cases at intersections involving multiple vehicles.","‚Ä¢ Intersection use cases involving two vehicles have been
                                                                         deployed successfully, proving the added value of pre-
                                                                         diction in false positive cases.",B.,2022-04-25 12:10:45+00:00,Testing predictive automated driving systems: lessons learned and future recommendations,cs.AI,"['cs.AI', 'cs.RO', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Rub√©n Izquierdo Gonzalo'), arxiv.Result.Author('Carlota Salinas Maldonado'), arxiv.Result.Author('Javier Alonso Ruiz'), arxiv.Result.Author('Ignacio Parra Alonso'), arxiv.Result.Author('David Fern√°ndez Llorca'), arxiv.Result.Author('Miguel √Å. Sotelo')]","Conventional vehicles are certified through classical approaches, where
different physical certification tests are set up on test tracks to assess
required safety levels. These approaches are well suited for vehicles with
limited complexity and limited interactions with other entities as last-second
resources. However, these approaches do not allow to evaluate safety with real
behaviors for critical and edge cases, nor to evaluate the ability to
anticipate them in the mid or long term. This is particularly relevant for
automated and autonomous driving functions that make use of advanced predictive
systems to anticipate future actions and motions to be considered in the path
planning layer. In this paper, we present and analyze the results of physical
tests on proving grounds of several predictive systems in automated driving
functions developed within the framework of the BRAVE project. Based on our
experience in testing predictive automated driving functions, we identify the
main limitations of current physical testing approaches when dealing with
predictive systems, analyze the main challenges ahead, and provide a set of
practical actions and recommendations to consider in future physical testing
procedures for automated and autonomous driving functions.",-0.308918,0.11334872,0.0385843,A
6501,"We further study some key model parameters that

modulate spatial attention, context integration, and disentanglement.","of the space while VAE-like models fall on the low

recognizability ‚Äî high diversity end of the space.","Our results suggest that spatial

attention and context have an (almost) linear effect on the diversity vs. recognizability trade-off.",2022-05-20 13:17:08+00:00,Diversity vs. Recognizability: Human-like generalization in one-shot generative models,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Victor Boutin'), arxiv.Result.Author('Lakshya Singhal'), arxiv.Result.Author('Xavier Thomas'), arxiv.Result.Author('Thomas Serre')]","Robust generalization to new concepts has long remained a distinctive feature
of human intelligence. However, recent progress in deep generative models has
now led to neural architectures capable of synthesizing novel instances of
unknown visual concepts from a single training example. Yet, a more precise
comparison between these models and humans is not possible because existing
performance metrics for generative models (i.e., FID, IS, likelihood) are not
appropriate for the one-shot generation scenario. Here, we propose a new
framework to evaluate one-shot generative models along two axes: sample
recognizability vs. diversity (i.e., intra-class variability). Using this
framework, we perform a systematic evaluation of representative one-shot
generative models on the Omniglot handwritten dataset. We first show that
GAN-like and VAE-like models fall on opposite ends of the
diversity-recognizability space. Extensive analyses of the effect of key model
parameters further revealed that spatial attention and context integration have
a linear contribution to the diversity-recognizability trade-off. In contrast,
disentanglement transports the model along a parabolic curve that could be used
to maximize recognizability. Using the diversity-recognizability framework, we
were able to identify models and parameters that closely approximate human
data.",-0.01689547,-0.18463664,0.012418762,C
6502,"We further study some key model parameters that

modulate spatial attention, context integration, and disentanglement.","of the space while VAE-like models fall on the low

recognizability ‚Äî high diversity end of the space.","Our results suggest that spatial

attention and context have an (almost) linear effect on the diversity vs. recognizability trade-off.",2022-05-20 13:17:08+00:00,Diversity vs. Recognizability: Human-like generalization in one-shot generative models,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Victor Boutin'), arxiv.Result.Author('Lakshya Singhal'), arxiv.Result.Author('Xavier Thomas'), arxiv.Result.Author('Thomas Serre')]","Robust generalization to new concepts has long remained a distinctive feature
of human intelligence. However, recent progress in deep generative models has
now led to neural architectures capable of synthesizing novel instances of
unknown visual concepts from a single training example. Yet, a more precise
comparison between these models and humans is not possible because existing
performance metrics for generative models (i.e., FID, IS, likelihood) are not
appropriate for the one-shot generation scenario. Here, we propose a new
framework to evaluate one-shot generative models along two axes: sample
recognizability vs. diversity (i.e., intra-class variability). Using this
framework, we perform a systematic evaluation of representative one-shot
generative models on the Omniglot handwritten dataset. We first show that
GAN-like and VAE-like models fall on opposite ends of the
diversity-recognizability space. Extensive analyses of the effect of key model
parameters further revealed that spatial attention and context integration have
a linear contribution to the diversity-recognizability trade-off. In contrast,
disentanglement transports the model along a parabolic curve that could be used
to maximize recognizability. Using the diversity-recognizability framework, we
were able to identify models and parameters that closely approximate human
data.",-0.01689547,-0.18463664,0.012418762,C
6503,"We further study some key model parameters that

modulate spatial attention, context integration, and disentanglement.","of the space while VAE-like models fall on the low

recognizability ‚Äî high diversity end of the space.","Our results suggest that spatial

attention and context have an (almost) linear effect on the diversity vs. recognizability trade-off.",2022-05-20 13:17:08+00:00,Diversity vs. Recognizability: Human-like generalization in one-shot generative models,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Victor Boutin'), arxiv.Result.Author('Lakshya Singhal'), arxiv.Result.Author('Xavier Thomas'), arxiv.Result.Author('Thomas Serre')]","Robust generalization to new concepts has long remained a distinctive feature
of human intelligence. However, recent progress in deep generative models has
now led to neural architectures capable of synthesizing novel instances of
unknown visual concepts from a single training example. Yet, a more precise
comparison between these models and humans is not possible because existing
performance metrics for generative models (i.e., FID, IS, likelihood) are not
appropriate for the one-shot generation scenario. Here, we propose a new
framework to evaluate one-shot generative models along two axes: sample
recognizability vs. diversity (i.e., intra-class variability). Using this
framework, we perform a systematic evaluation of representative one-shot
generative models on the Omniglot handwritten dataset. We first show that
GAN-like and VAE-like models fall on opposite ends of the
diversity-recognizability space. Extensive analyses of the effect of key model
parameters further revealed that spatial attention and context integration have
a linear contribution to the diversity-recognizability trade-off. In contrast,
disentanglement transports the model along a parabolic curve that could be used
to maximize recognizability. Using the diversity-recognizability framework, we
were able to identify models and parameters that closely approximate human
data.",-0.01689547,-0.18463664,0.012418762,C
6513,"We hope the ideas presented here can serve to explain aspects of
human cognition, and will publish further research along those lines soon.","From a more
philosophical point of view, this work was derived from largely philosophical
foundations.",Acknowledgments.,2022-05-21 06:32:09+00:00,Computable Artificial General Intelligence,cs.AI,['cs.AI'],[arxiv.Result.Author('Michael Timothy Bennett')],"The general reinforcement learning agent AIXI may be the only mathematical
formalism of artificial general intelligence (AGI) supported by proof that its
performance is optimal. This is achieved using compression as a proxy for
intelligence. Unfortunately, AIXI is incomputable and claims of its optimality
were later shown to be subjective. This paper proposes an alternative,
supported by proof, which overcomes both problems. Integrating research from
cognitive science (enactivism), philosophy (intension and extension), machine
learning and planning (satplan), an arbitrary task is given mathematical
rigour. This serves as an enactive model of learning and reasoning within which
a description of intelligence is formalised. Instead of compression we use
weakness as our proxy, and the result is both computable and objective. We
formally prove that maximising weakness maximises intelligence. This proof is
then further supported with experimental results comparing weakness and
description length (the closest analogue to compression possible under the
enactive model that would not reintroduce the problem of subjective
performance). Our results show that weakness outperforms description length,
and is a better proxy for intelligence. The foremost limitation is that
intelligence as we have defined it is computationally complex, but may be
coupled with domain specific inductive biases to make real-world domains of
practical significance tractable (e.g. the domain of all tasks a human would
undertake). Like AIXI this is not intended to be a panacea but to demonstrate
useful principles, which may be integrated with existing tools such as neural
networks to improve performance.",-0.13452317,-0.185031,0.31796968,A
6631,"In the third group of baselines, to further study the impact of state-aware item rec-
ommender in the general CRS solutions, we added our TransGate and state-based item
recommender to UNICORN.",We denote this variant as MP.,We denote this variant as UR.,2022-05-24 05:06:52+00:00,Meta Policy Learning for Cold-Start Conversational Recommendation,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Author('Zhendong Chu'), arxiv.Result.Author('Hongning Wang'), arxiv.Result.Author('Yun Xiao'), arxiv.Result.Author('Bo Long'), arxiv.Result.Author('Lingfei Wu')]","Conversational recommender systems (CRS) explicitly solicit users'
preferences for improved recommendations on the fly. Most existing CRS
solutions employ reinforcement learning methods to train a single policy for a
population of users. However, for users new to the system, such a global policy
becomes ineffective to produce conversational recommendations, i.e., the
cold-start challenge.
  In this paper, we study CRS policy learning for cold-start users via meta
reinforcement learning. We propose to learn a meta policy and adapt it to new
users with only a few trials of conversational recommendations. To facilitate
policy adaptation, we design three synergetic components. First is a
meta-exploration policy dedicated to identify user preferences via exploratory
conversations. Second is a Transformer-based state encoder to model a user's
both positive and negative feedback during the conversation. And third is an
adaptive item recommender based on the embedded states. Extensive experiments
on three datasets demonstrate the advantage of our solution in serving new
users, compared with a rich set of state-of-the-art CRS solutions.",-0.0675367,0.05138876,-0.029107638,A
6771,"To further study the QD trade-off, we use scatter plots, showing the episode return on the y-axis, and
the diversity score, corresponding to the Hausdorff distance (Eq.",Similar Ô¨Ågures for other domains can be found in Appendix B.1.,"(5)), on the x-axis.",2022-05-26 17:40:52+00:00,Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Tom Zahavy'), arxiv.Result.Author('Yannick Schroecker'), arxiv.Result.Author('Feryal Behbahani'), arxiv.Result.Author('Kate Baumli'), arxiv.Result.Author('Sebastian Flennerhag'), arxiv.Result.Author('Shaobo Hou'), arxiv.Result.Author('Satinder Singh')]","Finding different solutions to the same problem is a key aspect of
intelligence associated with creativity and adaptation to novel situations. In
reinforcement learning, a set of diverse policies can be useful for
exploration, transfer, hierarchy, and robustness. We propose DOMiNO, a method
for Diversity Optimization Maintaining Near Optimality. We formalize the
problem as a Constrained Markov Decision Process where the objective is to find
diverse policies, measured by the distance between the state occupancies of the
policies in the set, while remaining near-optimal with respect to the extrinsic
reward. We demonstrate that the method can discover diverse and meaningful
behaviors in various domains, such as different locomotion patterns in the
DeepMind Control Suite. We perform extensive analysis of our approach, compare
it with other multi-objective baselines, demonstrate that we can control both
the quality and the diversity of the set via interpretable hyperparameters, and
show that the discovered set is robust to perturbations.",-0.12233059,0.12208751,-0.14366716,B
6780,"As such, this paper introduces an artificial
neural network to operate under such constraints in mouse dynamics, yielding the ques-
tion of whether more complex deep learning algorithms may be able to follow suit with
further research.","The ability to further distinguish one
genuine user from another on a trusted network (intra-class instances) possesses great
potential value and should not be ignored.",3.,2022-05-26 21:43:59+00:00,Machine and Deep Learning Applications to Mouse Dynamics for Continuous User Authentication,cs.AI,['cs.AI'],"[arxiv.Result.Author('Nyle Siddiqui'), arxiv.Result.Author('Rushit Dave'), arxiv.Result.Author('Naeem Seliya'), arxiv.Result.Author('Mounika Vanamala')]","Static authentication methods, like passwords, grow increasingly weak with
advancements in technology and attack strategies. Continuous authentication has
been proposed as a solution, in which users who have gained access to an
account are still monitored in order to continuously verify that the user is
not an imposter who had access to the user credentials. Mouse dynamics is the
behavior of a users mouse movements and is a biometric that has shown great
promise for continuous authentication schemes. This article builds upon our
previous published work by evaluating our dataset of 40 users using three
machine learning and deep learning algorithms. Two evaluation scenarios are
considered: binary classifiers are used for user authentication, with the top
performer being a 1-dimensional convolutional neural network with a peak
average test accuracy of 85.73% across the top 10 users. Multi class
classification is also examined using an artificial neural network which
reaches an astounding peak accuracy of 92.48% the highest accuracy we have seen
for any classifier on this dataset.",0.26136926,-0.15859807,0.075042844,C
6781,"Both authentication and
            classification scenarios in this article are proven to be viable with this dataset and with
            mouse dynamics as a whole, fostering further research.","The non-intrusive nature of
            mouse dynamics paired with the high-performance rate of our models on large, diverse
            data exhibits the immense potential of this behavioral biometric.","Supplementary Materials: Any additional information regarding model architecture, implementa-
            tion or data preprocessing methods can be provided by contacting the corresponding author.",2022-05-26 21:43:59+00:00,Machine and Deep Learning Applications to Mouse Dynamics for Continuous User Authentication,cs.AI,['cs.AI'],"[arxiv.Result.Author('Nyle Siddiqui'), arxiv.Result.Author('Rushit Dave'), arxiv.Result.Author('Naeem Seliya'), arxiv.Result.Author('Mounika Vanamala')]","Static authentication methods, like passwords, grow increasingly weak with
advancements in technology and attack strategies. Continuous authentication has
been proposed as a solution, in which users who have gained access to an
account are still monitored in order to continuously verify that the user is
not an imposter who had access to the user credentials. Mouse dynamics is the
behavior of a users mouse movements and is a biometric that has shown great
promise for continuous authentication schemes. This article builds upon our
previous published work by evaluating our dataset of 40 users using three
machine learning and deep learning algorithms. Two evaluation scenarios are
considered: binary classifiers are used for user authentication, with the top
performer being a 1-dimensional convolutional neural network with a peak
average test accuracy of 85.73% across the top 10 users. Multi class
classification is also examined using an artificial neural network which
reaches an astounding peak accuracy of 92.48% the highest accuracy we have seen
for any classifier on this dataset.",0.054604437,-0.1062866,0.01568129,C
6821,"Our Ô¨Åndings call upon the research community to further study the
important problem of misclassiÔ¨Åcation detection in medical imaging.","Importantly, none of the benchmarked conÔ¨Ådence score able to outperform a simple softmax
baseline consistently across datasets.","The developed testbed (which is made
publicly available) aims to facilitate future work, building an essential component for rigorous, comprehensive
testing and comparative evaluation of new approaches.",2022-05-27 16:50:48+00:00,Failure Detection in Medical Image Classification: A Reality Check and Benchmarking Testbed,cs.AI,['cs.AI'],"[arxiv.Result.Author('Melanie Bernhardt'), arxiv.Result.Author('Fabio De Sousa Ribeiro'), arxiv.Result.Author('Ben Glocker')]","Failure detection in automated image classification is a critical safeguard
for clinical deployment. Detected failure cases can be referred to human
assessment, ensuring patient safety in computer-aided clinical decision making.
Despite its paramount importance, there is insufficient evidence about the
ability of state-of-the-art confidence scoring methods to detect test-time
failures of classification models in the context of medical imaging. This paper
provides a reality check, establishing the performance of in-domain
misclassification detection methods, benchmarking 9 confidence scores on 6
medical imaging datasets with different imaging modalities, in multiclass and
binary classification settings. Our experiments show that the problem of
failure detection is far from being solved. We found that none of the
benchmarked advanced methods proposed in the computer vision and machine
learning literature can consistently outperform a simple softmax baseline. Our
developed testbed facilitates future work in this important area.",0.026820509,-0.30691838,-0.22342443,A
6822,"In summary, our study strongly suggests that failure detection requires further research towards Ô¨Ånding
more appropriate conÔ¨Ådence scoring schemes.","Given the variability of the results from one dataset to another, this experiment
setup demonstrates the need for more broad evaluation of new conÔ¨Ådence scores in the future.","Even without the presence of any input perturbation, current
methods are not reliable for detecting failure cases.",2022-05-27 16:50:48+00:00,Failure Detection in Medical Image Classification: A Reality Check and Benchmarking Testbed,cs.AI,['cs.AI'],"[arxiv.Result.Author('Melanie Bernhardt'), arxiv.Result.Author('Fabio De Sousa Ribeiro'), arxiv.Result.Author('Ben Glocker')]","Failure detection in automated image classification is a critical safeguard
for clinical deployment. Detected failure cases can be referred to human
assessment, ensuring patient safety in computer-aided clinical decision making.
Despite its paramount importance, there is insufficient evidence about the
ability of state-of-the-art confidence scoring methods to detect test-time
failures of classification models in the context of medical imaging. This paper
provides a reality check, establishing the performance of in-domain
misclassification detection methods, benchmarking 9 confidence scores on 6
medical imaging datasets with different imaging modalities, in multiclass and
binary classification settings. Our experiments show that the problem of
failure detection is far from being solved. We found that none of the
benchmarked advanced methods proposed in the computer vision and machine
learning literature can consistently outperform a simple softmax baseline. Our
developed testbed facilitates future work in this important area.",-0.1737364,-0.05058159,-0.099665835,A
6823,"Overall, our study strongly suggests that failure detection requires further research towards Ô¨Ånd-
ing more appropriate conÔ¨Ådence scoring schemes, as this topic is a key concern for the medical imaging
community where safety concerns are paramount for deployment of AI models.","We found that among all the benchmarked conÔ¨Ådence scores, none were able to
outperform the softmax baseline consistently across datasets ‚Äì demonstrating that improved model calibra-
tion or performance on OOD does not necessarily translate to improvement for in-domain misclassiÔ¨Åcation
detection.","This work facilitates further
investigations by providing a complete testbed for evaluating future progress in this space in a rigorous and
comprehensive manner.",2022-05-27 16:50:48+00:00,Failure Detection in Medical Image Classification: A Reality Check and Benchmarking Testbed,cs.AI,['cs.AI'],"[arxiv.Result.Author('Melanie Bernhardt'), arxiv.Result.Author('Fabio De Sousa Ribeiro'), arxiv.Result.Author('Ben Glocker')]","Failure detection in automated image classification is a critical safeguard
for clinical deployment. Detected failure cases can be referred to human
assessment, ensuring patient safety in computer-aided clinical decision making.
Despite its paramount importance, there is insufficient evidence about the
ability of state-of-the-art confidence scoring methods to detect test-time
failures of classification models in the context of medical imaging. This paper
provides a reality check, establishing the performance of in-domain
misclassification detection methods, benchmarking 9 widely used confidence
scores on 6 medical imaging datasets with different imaging modalities, in
multiclass and binary classification settings. Our experiments show that the
problem of failure detection is far from being solved. We found that none of
the benchmarked advanced methods proposed in the computer vision and machine
learning literature can consistently outperform a simple softmax baseline,
demonstrating that improved out-of-distribution detection or model calibration
do not necessarily translate to improved in-domain misclassification detection.
Our developed testbed facilitates future work in this important area",0.038737584,-0.2638848,-0.14372285,A
6851,Directions for further research are indicated in addition.,"This research is organized as follows: in the next section some background
is provided for convenience, a discussion on rationality and semantic domains
is part of the third section, the mereology used in this research is explained
and situated in the context of the following sections next, generalizations of
rough inclusion functions are reviewed and extended in the sixth section from an
axiomatic perspective, VPRS and granular rough set-theoretical generalizations
that may cover some hybrid variants are reviewed or proposed in the following
section (concrete concepts of substantial parthood are additionally introduced
in a subsection), new results on the connection of generalized VPRS with graded
rough sets are proved in the following section, in the ninth section, the granular
framework for rational generalized VPRS is proposed, illustrative examples are
constructed in the next section, subsequently the compatibility of the framework
and granular VPRS is explored, and meta applications to cluster validation,
medical imaging, and dynamic sorting are considered in the penultimate section.",2.,2022-05-28 08:08:26+00:00,Granular Generalized Variable Precision Rough Sets and Rational Approximations,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Mani A'), arxiv.Result.Author('Sushmita Mitra')]","Rational approximations are introduced and studied in granular graded sets
and generalizations thereof by the first author in recent research papers. The
concept of rationality is determined by related ontologies and coherence
between granularity, parthood perspective and approximations used in the
context. In addition, a framework is introduced by her in the mentioned
paper(s). Granular approximations constructed as per the procedures of VPRS are
likely to be more rational than those constructed from a classical perspective
under certain conditions. This may continue to hold for some generalizations of
the former; however, a formal characterization of such conditions is not
available in the previously published literature. In this research, theoretical
aspects of the problem are critically examined, uniform generalizations of
granular VPRS are introduced, new connections with granular graded rough sets
are proved, appropriate concepts of substantial parthood are introduced, and
their extent of compatibility with the framework is accessed. Furthermore, meta
applications to cluster validation, image segmentation and dynamic sorting are
invented. Basic assumptions made are explained, and additional examples are
constructed for readability.",-0.25623983,0.029670412,-0.29822773,A
6852,Directions for further research are indicated in addition.,"This research is organized as follows: in the next section some background
is provided for convenience, a discussion on rationality and semantic domains
is part of the third section, the mereology used in this research is explained
and situated in the context of the following sections next, generalizations of
rough inclusion functions are reviewed and extended in the sixth section from an
axiomatic perspective, VPRS and granular rough set-theoretical generalizations
that may cover some hybrid variants are reviewed or proposed in the following
section (concrete concepts of substantial parthood are additionally introduced
in a subsection), new results on the connection of generalized VPRS with graded
rough sets are proved in the following section, in the ninth section, the granular
framework for rational generalized VPRS is proposed, illustrative examples are
constructed in the next section, subsequently the compatibility of the framework
and granular VPRS is explored, and meta applications to cluster validation,
medical imaging, and dynamic sorting are considered in the penultimate section.",2.,2022-05-28 08:08:26+00:00,Granular Generalized Variable Precision Rough Sets and Rational Approximations,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Mani A'), arxiv.Result.Author('Sushmita Mitra')]","Rational approximations are introduced and studied in granular graded sets
and generalizations thereof by the first author in recent research papers. The
concept of rationality is determined by related ontologies and coherence
between granularity, parthood perspective and approximations used in the
context. In addition, a framework is introduced by her in the mentioned
paper(s). Granular approximations constructed as per the procedures of VPRS are
likely to be more rational than those constructed from a classical perspective
under certain conditions. This may continue to hold for some generalizations of
the former; however, a formal characterization of such conditions is not
available in the previously published literature. In this research, theoretical
aspects of the problem are critically examined, uniform generalizations of
granular VPRS are introduced, new connections with granular graded rough sets
are proved, appropriate concepts of substantial parthood are introduced, and
their extent of compatibility with the framework is accessed. Furthermore, meta
applications to cluster validation, image segmentation and dynamic sorting are
invented. Basic assumptions made are explained, and additional examples are
constructed for readability.",-0.25623983,0.029670412,-0.29822773,A
6865,Note that such descriptive concepts are higher-level                                                                       plementation of ABIN to foster further research1.,"We publish in public two
also abduction that yields intensional concept-level answers as                                                                          pre-processed benchmark datasets for AI-NLR and the im-
explanations.","abstractions of the set of entities and are more informative than
the set in some cases [10].",2022-05-29 07:41:50+00:00,Joint Abductive and Inductive Neural Logical Reasoning,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Zhenwei Tang'), arxiv.Result.Author('Shichao Pei'), arxiv.Result.Author('Xi Peng'), arxiv.Result.Author('Fuzhen Zhuang'), arxiv.Result.Author('Xiangliang Zhang'), arxiv.Result.Author('Robert Hoehndorf')]","Neural logical reasoning (NLR) is a fundamental task in knowledge discovery
and artificial intelligence. NLR aims at answering multi-hop queries with
logical operations on structured knowledge bases based on distributed
representations of queries and answers. While previous neural logical reasoners
can give specific entity-level answers, i.e., perform inductive reasoning from
the perspective of logic theory, they are not able to provide descriptive
concept-level answers, i.e., perform abductive reasoning, where each concept is
a summary of a set of entities. In particular, the abductive reasoning task
attempts to infer the explanations of each query with descriptive concepts,
which make answers comprehensible to users and is of great usefulness in the
field of applied ontology. In this work, we formulate the problem of the joint
abductive and inductive neural logical reasoning (AI-NLR), solving which needs
to address challenges in incorporating, representing, and operating on
concepts. We propose an original solution named ABIN for AI-NLR. Firstly, we
incorporate description logic-based ontological axioms to provide the source of
concepts. Then, we represent concepts and queries as fuzzy sets, i.e., sets
whose elements have degrees of membership, to bridge concepts and queries with
entities. Moreover, we design operators involving concepts on top of the fuzzy
set representation of concepts and queries for optimization and inference.
Extensive experimental results on two real-world datasets demonstrate the
effectiveness of ABIN for AI-NLR.",0.012697799,-0.32436264,-0.10793604,A
6866,"That is, we exploit all the in-    further research.","The processed datasets along
   Therefore, we introduce the One-more-hop experiment to serve         with the code for pre-processing will be published in public to foster
as baselines for the abduction task.","formation given by KB = (T , A) and simply degrade concepts
to entities in the training stage.",2022-05-29 07:41:50+00:00,Joint Abductive and Inductive Neural Logical Reasoning,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Zhenwei Tang'), arxiv.Result.Author('Shichao Pei'), arxiv.Result.Author('Xi Peng'), arxiv.Result.Author('Fuzhen Zhuang'), arxiv.Result.Author('Xiangliang Zhang'), arxiv.Result.Author('Robert Hoehndorf')]","Neural logical reasoning (NLR) is a fundamental task in knowledge discovery
and artificial intelligence. NLR aims at answering multi-hop queries with
logical operations on structured knowledge bases based on distributed
representations of queries and answers. While previous neural logical reasoners
can give specific entity-level answers, i.e., perform inductive reasoning from
the perspective of logic theory, they are not able to provide descriptive
concept-level answers, i.e., perform abductive reasoning, where each concept is
a summary of a set of entities. In particular, the abductive reasoning task
attempts to infer the explanations of each query with descriptive concepts,
which make answers comprehensible to users and is of great usefulness in the
field of applied ontology. In this work, we formulate the problem of the joint
abductive and inductive neural logical reasoning (AI-NLR), solving which needs
to address challenges in incorporating, representing, and operating on
concepts. We propose an original solution named ABIN for AI-NLR. Firstly, we
incorporate description logic-based ontological axioms to provide the source of
concepts. Then, we represent concepts and queries as fuzzy sets, i.e., sets
whose elements have degrees of membership, to bridge concepts and queries with
entities. Moreover, we design operators involving concepts on top of the fuzzy
set representation of concepts and queries for optimization and inference.
Extensive experimental results on two real-world datasets demonstrate the
effectiveness of ABIN for AI-NLR.",0.07222048,-0.12654106,-0.13097386,C
6867,published to foster further research of AI-MLR.,The processed datasets and code are ready to be             New Jersey.,"[21] Maxat Kulmanov, Wang Liu-Wei, Yuan Yan, and Robert Hoehndorf.",2022-05-29 07:41:50+00:00,Joint Abductive and Inductive Neural Logical Reasoning,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Zhenwei Tang'), arxiv.Result.Author('Shichao Pei'), arxiv.Result.Author('Xi Peng'), arxiv.Result.Author('Fuzhen Zhuang'), arxiv.Result.Author('Xiangliang Zhang'), arxiv.Result.Author('Robert Hoehndorf')]","Neural logical reasoning (NLR) is a fundamental task in knowledge discovery
and artificial intelligence. NLR aims at answering multi-hop queries with
logical operations on structured knowledge bases based on distributed
representations of queries and answers. While previous neural logical reasoners
can give specific entity-level answers, i.e., perform inductive reasoning from
the perspective of logic theory, they are not able to provide descriptive
concept-level answers, i.e., perform abductive reasoning, where each concept is
a summary of a set of entities. In particular, the abductive reasoning task
attempts to infer the explanations of each query with descriptive concepts,
which make answers comprehensible to users and is of great usefulness in the
field of applied ontology. In this work, we formulate the problem of the joint
abductive and inductive neural logical reasoning (AI-NLR), solving which needs
to address challenges in incorporating, representing, and operating on
concepts. We propose an original solution named ABIN for AI-NLR. Firstly, we
incorporate description logic-based ontological axioms to provide the source of
concepts. Then, we represent concepts and queries as fuzzy sets, i.e., sets
whose elements have degrees of membership, to bridge concepts and queries with
entities. Moreover, we design operators involving concepts on top of the fuzzy
set representation of concepts and queries for optimization and inference.
Extensive experimental results on two real-world datasets demonstrate the
effectiveness of ABIN for AI-NLR.",0.17828456,-0.02987982,-0.099740475,C
6868,"There-       benchmark datasets for TA-NLR and the implementation of TAR1
fore, the TA-NLR problem is more general than the regular NLR            to foster further research.","We publish in public two pre-processed
ontology which is highly useful in applied ontologies [12].","problem in terms of providing not only entity-level ABox answers,
but also concept-level TBox answers.",2022-05-29 07:41:50+00:00,TAR: Neural Logical Reasoning across TBox and ABox,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Zhenwei Tang'), arxiv.Result.Author('Shichao Pei'), arxiv.Result.Author('Xi Peng'), arxiv.Result.Author('Fuzhen Zhuang'), arxiv.Result.Author('Xiangliang Zhang'), arxiv.Result.Author('Robert Hoehndorf')]","Many ontologies, i.e., Description Logic (DL) knowledge bases, have been
developed to provide rich knowledge about various domains. An ontology consists
of an ABox, i.e., assertion axioms between two entities or between a concept
and an entity, and a TBox, i.e., terminology axioms between two concepts.
Neural logical reasoning (NLR) is a fundamental task to explore such knowledge
bases, which aims at answering multi-hop queries with logical operations based
on distributed representations of queries and answers. While previous NLR
methods can give specific entity-level answers, i.e., ABox answers, they are
not able to provide descriptive concept-level answers, i.e., TBox answers,
where each concept is a description of a set of entities. In other words,
previous NLR methods only reason over the ABox of an ontology while ignoring
the TBox. In particular, providing TBox answers enables inferring the
explanations of each query with descriptive concepts, which make answers
comprehensible to users and are of great usefulness in the field of applied
ontology. In this work, we formulate the problem of neural logical reasoning
across TBox and ABox (TA-NLR), solving which needs to address challenges in
incorporating, representing, and operating on concepts. We propose an original
solution named TAR for TA-NLR. Firstly, we incorporate description logic based
ontological axioms to provide the source of concepts. Then, we represent
concepts and queries as fuzzy sets, i.e., sets whose elements have degrees of
membership, to bridge concepts and queries with entities. Moreover, we design
operators involving concepts on top of fuzzy set representation of concepts and
queries for optimization and inference. Extensive experimental results on two
real-world datasets demonstrate the effectiveness of TAR for TA-NLR.",-0.16543993,-0.094102934,-0.2979747,A
6869,foster further research of TA-NLR.,"The processed datasets and code are ready to be published to
supplementary materials.","TAR: Neural Logical Reasoning across TBox and ABox                                         [31] Fatima Zohra Smaili, Xin Gao, and Robert Hoehndorf.",2022-05-29 07:41:50+00:00,TAR: Neural Logical Reasoning across TBox and ABox,cs.AI,"['cs.AI', 'cs.LG', 'cs.LO']","[arxiv.Result.Author('Zhenwei Tang'), arxiv.Result.Author('Shichao Pei'), arxiv.Result.Author('Xi Peng'), arxiv.Result.Author('Fuzhen Zhuang'), arxiv.Result.Author('Xiangliang Zhang'), arxiv.Result.Author('Robert Hoehndorf')]","Many ontologies, i.e., Description Logic (DL) knowledge bases, have been
developed to provide rich knowledge about various domains. An ontology consists
of an ABox, i.e., assertion axioms between two entities or between a concept
and an entity, and a TBox, i.e., terminology axioms between two concepts.
Neural logical reasoning (NLR) is a fundamental task to explore such knowledge
bases, which aims at answering multi-hop queries with logical operations based
on distributed representations of queries and answers. While previous NLR
methods can give specific entity-level answers, i.e., ABox answers, they are
not able to provide descriptive concept-level answers, i.e., TBox answers,
where each concept is a description of a set of entities. In other words,
previous NLR methods only reason over the ABox of an ontology while ignoring
the TBox. In particular, providing TBox answers enables inferring the
explanations of each query with descriptive concepts, which make answers
comprehensible to users and are of great usefulness in the field of applied
ontology. In this work, we formulate the problem of neural logical reasoning
across TBox and ABox (TA-NLR), solving which needs to address challenges in
incorporating, representing, and operating on concepts. We propose an original
solution named TAR for TA-NLR. Firstly, we incorporate description logic based
ontological axioms to provide the source of concepts. Then, we represent
concepts and queries as fuzzy sets, i.e., sets whose elements have degrees of
membership, to bridge concepts and queries with entities. Moreover, we design
operators involving concepts on top of fuzzy set representation of concepts and
queries for optimization and inference. Extensive experimental results on two
real-world datasets demonstrate the effectiveness of TAR for TA-NLR.",-0.0027447753,-0.19142967,-0.09599818,A
6911,"In Section 4, we discuss further research.",We discuss how to update belief and plausibility when getting a new piece of information.,"2 Preliminaries

In this section, we Ô¨Årst introduced the necessary deÔ¨Ånitions about BD logic and non-standard
probabilities.",2022-05-30 15:07:27+00:00,Updating belief functions over Belnap--Dunn logic,cs.AI,"['cs.AI', 'cs.LO', 'math.PR']","[arxiv.Result.Author('Sabine Frittella'), arxiv.Result.Author('Ondrej Majer'), arxiv.Result.Author('Sajad Nazari')]","Belief and plausibility are weaker measures of uncertainty than that of
probability. They are motivated by the situations when full probabilistic
information is not available. However, information can also be contradictory.
Therefore, the framework of classical logic is not necessarily the most
adequate. Belnap-Dunn logic was introduced to reason about incomplete and
contradictory information. Klein et al and Bilkova et al generalize the notion
of probability measures and belief functions to Belnap-Dunn logic,
respectively. In this article, we study how to update belief functions with new
pieces of information. We present a first approach via a frame semantics of
Belnap-Dunn logic.",-0.2785672,-0.040444132,0.098444544,A
6919,"We release the
                                                  pre-trained models and code to encourage further research in this direction.","We compare several approaches in this multi-game setting, such as online and
                                                  ofÔ¨Çine RL methods and behavioral cloning, and Ô¨Ånd that our Multi-Game Decision
                                                  Transformer models offer the best scalability and performance.","1

                                        1 Introduction

                                        Building large-scale generalist models that solve many tasks by training on massive task-agnostic
                                        datasets has emerged as a dominant approach in natural language processing [18, 12], computer
                                        vision [19, 6], and their intersection [59, 4].",2022-05-30 16:55:38+00:00,Multi-Game Decision Transformers,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Kuang-Huei Lee'), arxiv.Result.Author('Ofir Nachum'), arxiv.Result.Author('Mengjiao Yang'), arxiv.Result.Author('Lisa Lee'), arxiv.Result.Author('Daniel Freeman'), arxiv.Result.Author('Winnie Xu'), arxiv.Result.Author('Sergio Guadarrama'), arxiv.Result.Author('Ian Fischer'), arxiv.Result.Author('Eric Jang'), arxiv.Result.Author('Henryk Michalewski'), arxiv.Result.Author('Igor Mordatch')]","A longstanding goal of the field of AI is a strategy for compiling diverse
experience into a highly capable, generalist agent. In the subfields of vision
and language, this was largely achieved by scaling up transformer-based models
and training them on large, diverse datasets. Motivated by this progress, we
investigate whether the same strategy can be used to produce generalist
reinforcement learning agents. Specifically, we show that a single
transformer-based model - with a single set of weights - trained purely offline
can play a suite of up to 46 Atari games simultaneously at close-to-human
performance. When trained and evaluated appropriately, we find that the same
trends observed in language and vision hold, including scaling of performance
with model size and rapid adaptation to new games via fine-tuning. We compare
several approaches in this multi-game setting, such as online and offline RL
methods and behavioral cloning, and find that our Multi-Game Decision
Transformer models offer the best scalability and performance. We release the
pre-trained models and code to encourage further research in this direction.
Additional information, videos and code can be seen at:
sites.google.com/view/multi-game-transformers",0.3353814,-0.22704437,0.0060495352,C
6920,It is our hope this study can inspire further research in generalist agents.,"And third, we compare multiple approaches for
achieving this goal, Ô¨Ånding that decision transformers combined with guided generation perform the
best.","To aid this, we make
our pre-trained models and code publicly available.",2022-05-30 16:55:38+00:00,Multi-Game Decision Transformers,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Kuang-Huei Lee'), arxiv.Result.Author('Ofir Nachum'), arxiv.Result.Author('Mengjiao Yang'), arxiv.Result.Author('Lisa Lee'), arxiv.Result.Author('Daniel Freeman'), arxiv.Result.Author('Winnie Xu'), arxiv.Result.Author('Sergio Guadarrama'), arxiv.Result.Author('Ian Fischer'), arxiv.Result.Author('Eric Jang'), arxiv.Result.Author('Henryk Michalewski'), arxiv.Result.Author('Igor Mordatch')]","A longstanding goal of the field of AI is a strategy for compiling diverse
experience into a highly capable, generalist agent. In the subfields of vision
and language, this was largely achieved by scaling up transformer-based models
and training them on large, diverse datasets. Motivated by this progress, we
investigate whether the same strategy can be used to produce generalist
reinforcement learning agents. Specifically, we show that a single
transformer-based model - with a single set of weights - trained purely offline
can play a suite of up to 46 Atari games simultaneously at close-to-human
performance. When trained and evaluated appropriately, we find that the same
trends observed in language and vision hold, including scaling of performance
with model size and rapid adaptation to new games via fine-tuning. We compare
several approaches in this multi-game setting, such as online and offline RL
methods and behavioral cloning, and find that our Multi-Game Decision
Transformer models offer the best scalability and performance. We release the
pre-trained models and code to encourage further research in this direction.
Additional information, videos and code can be seen at:
sites.google.com/view/multi-game-transformers",0.23827617,-0.067032896,0.19422114,C
6921,"We release the
                                                  pre-trained models and code to encourage further research in this direction.1

                                        1 Introduction

                                        Building large-scale generalist models that solve many tasks by training on massive task-agnostic
                                        datasets has emerged as a dominant approach in natural language processing [18, 12], computer
                                        vision [19, 6], and their intersection [61, 4].","We compare several approaches in this multi-game setting, such as online and
                                                  ofÔ¨Çine RL methods and behavioral cloning, and Ô¨Ånd that our Multi-Game Decision
                                                  Transformer models offer the best scalability and performance.","These models can adapt to new tasks (such as translation
                                        [63, 78]), make use of unrelated data (such as using high-resource language to improve translations of
                                        low-resource languages [17]), or even incorporate new modalities by projecting images into language
                                        space [46, 75].",2022-05-30 16:55:38+00:00,Multi-Game Decision Transformers,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Kuang-Huei Lee'), arxiv.Result.Author('Ofir Nachum'), arxiv.Result.Author('Mengjiao Yang'), arxiv.Result.Author('Lisa Lee'), arxiv.Result.Author('Daniel Freeman'), arxiv.Result.Author('Winnie Xu'), arxiv.Result.Author('Sergio Guadarrama'), arxiv.Result.Author('Ian Fischer'), arxiv.Result.Author('Eric Jang'), arxiv.Result.Author('Henryk Michalewski'), arxiv.Result.Author('Igor Mordatch')]","A longstanding goal of the field of AI is a method for learning a highly
capable, generalist agent from diverse experience. In the subfields of vision
and language, this was largely achieved by scaling up transformer-based models
and training them on large, diverse datasets. Motivated by this progress, we
investigate whether the same strategy can be used to produce generalist
reinforcement learning agents. Specifically, we show that a single
transformer-based model - with a single set of weights - trained purely offline
can play a suite of up to 46 Atari games simultaneously at close-to-human
performance. When trained and evaluated appropriately, we find that the same
trends observed in language and vision hold, including scaling of performance
with model size and rapid adaptation to new games via fine-tuning. We compare
several approaches in this multi-game setting, such as online and offline RL
methods and behavioral cloning, and find that our Multi-Game Decision
Transformer models offer the best scalability and performance. We release the
pre-trained models and code to encourage further research in this direction.",0.28875798,-0.2678405,-0.05580544,C
6922,It is our hope this study can inspire further research in generalist agents.,"And third, we compare multiple approaches for
achieving this goal, Ô¨Ånding that decision transformers combined with guided generation perform the
best.","To aid this, we make
our pre-trained models and code publicly available.",2022-05-30 16:55:38+00:00,Multi-Game Decision Transformers,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Kuang-Huei Lee'), arxiv.Result.Author('Ofir Nachum'), arxiv.Result.Author('Mengjiao Yang'), arxiv.Result.Author('Lisa Lee'), arxiv.Result.Author('Daniel Freeman'), arxiv.Result.Author('Winnie Xu'), arxiv.Result.Author('Sergio Guadarrama'), arxiv.Result.Author('Ian Fischer'), arxiv.Result.Author('Eric Jang'), arxiv.Result.Author('Henryk Michalewski'), arxiv.Result.Author('Igor Mordatch')]","A longstanding goal of the field of AI is a method for learning a highly
capable, generalist agent from diverse experience. In the subfields of vision
and language, this was largely achieved by scaling up transformer-based models
and training them on large, diverse datasets. Motivated by this progress, we
investigate whether the same strategy can be used to produce generalist
reinforcement learning agents. Specifically, we show that a single
transformer-based model - with a single set of weights - trained purely offline
can play a suite of up to 46 Atari games simultaneously at close-to-human
performance. When trained and evaluated appropriately, we find that the same
trends observed in language and vision hold, including scaling of performance
with model size and rapid adaptation to new games via fine-tuning. We compare
several approaches in this multi-game setting, such as online and offline RL
methods and behavioral cloning, and find that our Multi-Game Decision
Transformer models offer the best scalability and performance. We release the
pre-trained models and code to encourage further research in this direction.",0.23827617,-0.067032896,0.19422114,C
6931,"To mitigate the risks, we encourage further research to develop methods to provide guarantees and
deÔ¨Ånitive answers about agent behavior.","The negative consequences of this work could include
the removal of human decision-making from the controller design loop, the unknown existence of
unforeseen loopholes in the engineered behavior, and vulnerability to policy induction attacks [6].","In other words, a general framework for making guaranteed
statements about the behavior of the trained agents is missing.",2022-05-30 18:49:33+00:00,Truly Deterministic Policy Optimization,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Ehsan Saleh'), arxiv.Result.Author('Saba Ghaffari'), arxiv.Result.Author('Timothy Bretl'), arxiv.Result.Author('Matthew West')]","In this paper, we present a policy gradient method that avoids exploratory
noise injection and performs policy search over the deterministic landscape. By
avoiding noise injection all sources of estimation variance can be eliminated
in systems with deterministic dynamics (up to the initial state distribution).
Since deterministic policy regularization is impossible using traditional
non-metric measures such as the KL divergence, we derive a Wasserstein-based
quadratic model for our purposes. We state conditions on the system model under
which it is possible to establish a monotonic policy improvement guarantee,
propose a surrogate function for policy gradient estimation, and show that it
is possible to compute exact advantage estimates if both the state transition
model and the policy are deterministic. Finally, we describe two novel robotic
control environments -- one with non-local rewards in the frequency domain and
the other with a long horizon (8000 time-steps) -- for which our policy
gradient method (TDPO) significantly outperforms existing methods (PPO, TRPO,
DDPG, and TD3). Our implementation with all the experimental settings is
available at https://github.com/ehsansaleh/code_tdpo",0.100439906,0.04584957,0.46731243,C
7004,"This is another
aspect that requires further research.","Regarding the operators used, in this case, the insert operators was chosen with literature support,
however, it is not clear if any operation can be accurately learned by the NI model.","Finally, we believe that obtaining the state-of-the-art using
neural improvement heuristics will be feasible in the future, but still considerable effort needs to be
devoted to the correct implementation of complex neural networks in C++ code.",2022-06-01 10:35:29+00:00,Neural Improvement Heuristics for Preference Ranking,cs.AI,"['cs.AI', 'cs.DM', 'cs.LG']","[arxiv.Result.Author('Andoni I. Garmendia'), arxiv.Result.Author('Josu Ceberio'), arxiv.Result.Author('Alexander Mendiburu')]","In recent years, Deep Learning based methods have been a revolution in the
field of combinatorial optimization. They learn to approximate solutions and
constitute an interesting choice when dealing with repetitive problems drawn
from similar distributions. Most effort has been devoted to investigating
neural constructive methods, while the works that propose neural models to
iteratively improve a candidate solution are less frequent. In this paper, we
present a Neural Improvement (NI) model for graph-based combinatorial problems
that, given an instance and a candidate solution, encodes the problem
information by means of edge features. Our model proposes a modification on the
pairwise precedence of items to increase the quality of the solution. We
demonstrate the practicality of the model by applying it as the building block
of a Neural Hill Climber and other trajectory-based methods. The algorithms are
used to solve the Preference Ranking Problem and results show that they
outperform conventional alternatives in simulated and real-world data.
Conducted experiments also reveal that the proposed model can be a milestone in
the development of efficiently guided trajectory-based optimization algorithms.",0.181681,0.032398164,-0.22201496,C
7076,"Then the system             lag far behind the human expert performance,
should use the results gained from the second table           and further research is needed.","The experimental results
system to locate and perform numerical reasoning              demonstrate that the current QA models still
on the second hierarchical table.",to reason on the Ô¨Årst table.,2022-06-03 00:24:35+00:00,MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Yilun Zhao'), arxiv.Result.Author('Yunxiang Li'), arxiv.Result.Author('Chenying Li'), arxiv.Result.Author('Rui Zhang')]","Numerical reasoning over hybrid data containing both textual and tabular
content (e.g., financial reports) has recently attracted much attention in the
NLP community. However, existing question answering (QA) benchmarks over hybrid
data only include a single flat table in each document and thus lack examples
of multi-step numerical reasoning across multiple hierarchical tables. To
facilitate data analytical progress, we construct a new large-scale benchmark,
MultiHiertt, with QA pairs over Multi Hierarchical Tabular and Textual data.
MultiHiertt is built from a wealth of financial reports and has the following
unique characteristics: 1) each document contain multiple tables and longer
unstructured texts; 2) most of tables contained are hierarchical; 3) the
reasoning process required for each question is more complex and challenging
than existing benchmarks; and 4) fine-grained annotations of reasoning
processes and supporting facts are provided to reveal complex numerical
reasoning. We further introduce a novel QA model termed MT2Net, which first
applies facts retrieving to extract relevant supporting facts from both tables
and text and then uses a reasoning module to perform symbolic reasoning over
retrieved facts. We conduct comprehensive experiments on various baselines. The
experimental results show that MultiHiertt presents a strong challenge for
existing baselines whose results lag far behind the performance of human
experts. The dataset and code are publicly available at
https://github.com/psunlpgroup/MultiHiertt.",-0.087653846,0.10584779,-0.007489222,A
7077,"This motivates further research on de-
veloping QA models for such complex hybrid data         Iz Beltagy, Matthew E. Peters, and Arman Cohan.",87.03%).,with multiple hierarchical tables.,2022-06-03 00:24:35+00:00,MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Yilun Zhao'), arxiv.Result.Author('Yunxiang Li'), arxiv.Result.Author('Chenying Li'), arxiv.Result.Author('Rui Zhang')]","Numerical reasoning over hybrid data containing both textual and tabular
content (e.g., financial reports) has recently attracted much attention in the
NLP community. However, existing question answering (QA) benchmarks over hybrid
data only include a single flat table in each document and thus lack examples
of multi-step numerical reasoning across multiple hierarchical tables. To
facilitate data analytical progress, we construct a new large-scale benchmark,
MultiHiertt, with QA pairs over Multi Hierarchical Tabular and Textual data.
MultiHiertt is built from a wealth of financial reports and has the following
unique characteristics: 1) each document contain multiple tables and longer
unstructured texts; 2) most of tables contained are hierarchical; 3) the
reasoning process required for each question is more complex and challenging
than existing benchmarks; and 4) fine-grained annotations of reasoning
processes and supporting facts are provided to reveal complex numerical
reasoning. We further introduce a novel QA model termed MT2Net, which first
applies facts retrieving to extract relevant supporting facts from both tables
and text and then uses a reasoning module to perform symbolic reasoning over
retrieved facts. We conduct comprehensive experiments on various baselines. The
experimental results show that MultiHiertt presents a strong challenge for
existing baselines whose results lag far behind the performance of human
experts. The dataset and code are publicly available at
https://github.com/psunlpgroup/MultiHiertt.",-0.12759057,0.15668304,-0.23119774,B
7084,"E.2 Ablation Results

Besides the experiments conducted in the paper, we further study the following aspects of the
application of MARL on real-world network load balancing problems.",The trafÔ¨Åc rate is normalised to consume on average 84.5% resources.,"E.2.1 Reward Engineering

To verify the effectiveness of the proposed potential function VBF, we compare it with a set of
different reward functions, including makespan (MS), PBF, and coefÔ¨Åcient of variation (CV).",2022-06-03 08:29:02+00:00,Learning Distributed and Fair Policies for Network Load Balancing as Markov Potentia Game,cs.AI,"['cs.AI', 'cs.DC', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Zhiyuan Yao'), arxiv.Result.Author('Zihan Ding')]","This paper investigates the network load balancing problem in data centers
(DCs) where multiple load balancers (LBs) are deployed, using the multi-agent
reinforcement learning (MARL) framework. The challenges of this problem consist
of the heterogeneous processing architecture and dynamic environments, as well
as limited and partial observability of each LB agent in distributed networking
systems, which can largely degrade the performance of in-production load
balancing algorithms in real-world setups.
Centralised-training-decentralised-execution (CTDE) RL scheme has been proposed
to improve MARL performance, yet it incurs -- especially in distributed
networking systems, which prefer distributed and plug-and-play design scheme --
additional communication and management overhead among agents. We formulate the
multi-agent load balancing problem as a Markov potential game, with a carefully
and properly designed workload distribution fairness as the potential function.
A fully distributed MARL algorithm is proposed to approximate the Nash
equilibrium of the game. Experimental evaluations involve both an event-driven
simulator and real-world system, where the proposed MARL load balancing
algorithm shows close-to-optimal performance in simulations, and superior
results over in-production LBs in the real-world system.",-0.06525292,0.40285987,0.10441538,B
7085,"E.2 Ablation Results

Besides the experiments conducted in the paper, we further study the following aspects of the
application of MARL on real-world network load balancing problems.",The trafÔ¨Åc rate is normalised to consume on average 84.5% resources.,"E.2.1 Reward Engineering

To verify the effectiveness of the proposed potential function VBF, we compare it with a set of
different reward functions, including makespan (MS), PBF, and coefÔ¨Åcient of variation (CV).",2022-06-03 08:29:02+00:00,Learning Distributed and Fair Policies for Network Load Balancing as Markov Potential Game,cs.AI,"['cs.AI', 'cs.DC', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Zhiyuan Yao'), arxiv.Result.Author('Zihan Ding')]","This paper investigates the network load balancing problem in data centers
(DCs) where multiple load balancers (LBs) are deployed, using the multi-agent
reinforcement learning (MARL) framework. The challenges of this problem consist
of the heterogeneous processing architecture and dynamic environments, as well
as limited and partial observability of each LB agent in distributed networking
systems, which can largely degrade the performance of in-production load
balancing algorithms in real-world setups.
Centralised-training-decentralised-execution (CTDE) RL scheme has been proposed
to improve MARL performance, yet it incurs -- especially in distributed
networking systems, which prefer distributed and plug-and-play design scheme --
additional communication and management overhead among agents. We formulate the
multi-agent load balancing problem as a Markov potential game, with a carefully
and properly designed workload distribution fairness as the potential function.
A fully distributed MARL algorithm is proposed to approximate the Nash
equilibrium of the game. Experimental evaluations involve both an event-driven
simulator and real-world system, where the proposed MARL load balancing
algorithm shows close-to-optimal performance in simulations, and superior
results over in-production LBs in the real-world system.",-0.06525292,0.40285987,0.10441538,B
7086,"E.2 Ablation Results

Besides the experiments conducted in the paper, we further study the following aspects of the
application of MARL on real-world network load balancing problems.",The trafÔ¨Åc rate is normalised to consume on average 84.5% resources.,"E.2.1 Reward Engineering

To verify the effectiveness of the proposed potential function VBF, we compare it with a set of
different reward functions, including makespan (MS), PBF, and coefÔ¨Åcient of variation (CV).",2022-06-03 08:29:02+00:00,Learning Distributed and Fair Policies for Network Load Balancing as Markov Potential Game,cs.AI,"['cs.AI', 'cs.DC', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Zhiyuan Yao'), arxiv.Result.Author('Zihan Ding')]","This paper investigates the network load balancing problem in data centers
(DCs) where multiple load balancers (LBs) are deployed, using the multi-agent
reinforcement learning (MARL) framework. The challenges of this problem consist
of the heterogeneous processing architecture and dynamic environments, as well
as limited and partial observability of each LB agent in distributed networking
systems, which can largely degrade the performance of in-production load
balancing algorithms in real-world setups.
Centralised-training-decentralised-execution (CTDE) RL scheme has been proposed
to improve MARL performance, yet it incurs -- especially in distributed
networking systems, which prefer distributed and plug-and-play design scheme --
additional communication and management overhead among agents. We formulate the
multi-agent load balancing problem as a Markov potential game, with a carefully
and properly designed workload distribution fairness as the potential function.
A fully distributed MARL algorithm is proposed to approximate the Nash
equilibrium of the game. Experimental evaluations involve both an event-driven
simulator and real-world system, where the proposed MARL load balancing
algorithm shows close-to-optimal performance in simulations, and superior
results over in-production LBs in the real-world system.",-0.06525292,0.40285987,0.10441538,B
7138,"This suggests further study into
sub-categories that are Tug-of-War speciÔ¨Åc and provides the      the types of strategies taken by C4RL users and how they
count for each.","although participant #6 constructed only 13 rules (which is
                                                                 less than the average), they successfully created rules from
Table 2 further decomposes the high-level categories into        10 different sub-categories.",The most common rule type was causal vio-        might be guided toward the most effective strategies.,2022-06-04 18:16:05+00:00,Beyond Value: CHECKLIST for Testing Inferences in Planning-Based RL,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Kin-Ho Lam'), arxiv.Result.Author('Delyar Tabatabai'), arxiv.Result.Author('Jed Irvine'), arxiv.Result.Author('Donald Bertucci'), arxiv.Result.Author('Anita Ruangrotsakun'), arxiv.Result.Author('Minsuk Kahng'), arxiv.Result.Author('Alan Fern')]","Reinforcement learning (RL) agents are commonly evaluated via their expected
value over a distribution of test scenarios. Unfortunately, this evaluation
approach provides limited evidence for post-deployment generalization beyond
the test distribution. In this paper, we address this limitation by extending
the recent CheckList testing methodology from natural language processing to
planning-based RL. Specifically, we consider testing RL agents that make
decisions via online tree search using a learned transition model and value
function. The key idea is to improve the assessment of future performance via a
CheckList approach for exploring and assessing the agent's inferences during
tree search. The approach provides the user with an interface and general
query-rule mechanism for identifying potential inference flaws and validating
expected inference invariances. We present a user study involving knowledgeable
AI researchers using the approach to evaluate an agent trained to play a
complex real-time strategy game. The results show the approach is effective in
allowing users to identify previously-unknown flaws in the agent's reasoning.
In addition, our analysis provides insight into how AI experts use this type of
testing approach, which may help improve future instantiations.",-0.14510489,0.027656086,0.17521669,A
7139,"This suggests further study into
sub-categories that are Tug-of-War speciÔ¨Åc and provides the      the types of strategies taken by C4RL users and how they
count for each.","although participant #6 constructed only 13 rules (which is
                                                                 less than the average), they successfully created rules from
Table 2 further decomposes the high-level categories into        10 different sub-categories.",The most common rule type was causal vio-        might be guided toward the most effective strategies.,2022-06-04 18:16:05+00:00,Beyond Value: CHECKLIST for Testing Inferences in Planning-Based RL,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Kin-Ho Lam'), arxiv.Result.Author('Delyar Tabatabai'), arxiv.Result.Author('Jed Irvine'), arxiv.Result.Author('Donald Bertucci'), arxiv.Result.Author('Anita Ruangrotsakun'), arxiv.Result.Author('Minsuk Kahng'), arxiv.Result.Author('Alan Fern')]","Reinforcement learning (RL) agents are commonly evaluated via their expected
value over a distribution of test scenarios. Unfortunately, this evaluation
approach provides limited evidence for post-deployment generalization beyond
the test distribution. In this paper, we address this limitation by extending
the recent CheckList testing methodology from natural language processing to
planning-based RL. Specifically, we consider testing RL agents that make
decisions via online tree search using a learned transition model and value
function. The key idea is to improve the assessment of future performance via a
CheckList approach for exploring and assessing the agent's inferences during
tree search. The approach provides the user with an interface and general
query-rule mechanism for identifying potential inference flaws and validating
expected inference invariances. We present a user study involving knowledgeable
AI researchers using the approach to evaluate an agent trained to play a
complex real-time strategy game. The results show the approach is effective in
allowing users to identify previously-unknown flaws in the agent's reasoning.
In addition, our analysis provides insight into how AI experts use this type of
testing approach, which may help improve future instantiations.",-0.14510489,0.027656086,0.17521669,A
7167,"We believe our investigation can inspire further researches to explore the possibilities of differentiable
           physics for more complex learning tasks.","‚Ä¢ We systematically investigated the key factors contributing to the differentiable physics based learning frame-
          work.","2 Differentiable Simulation Environments

2.1 Simulation settings

Our learning framework supports multiple types of differentiable physically-based deformable body simulators.",2022-06-06 04:01:12+00:00,Complex Locomotion Skill Learning via Differentiable Physics,cs.AI,"['cs.AI', 'cs.GR', 'cs.LG']","[arxiv.Result.Author('Yu Fang'), arxiv.Result.Author('Jiancheng Liu'), arxiv.Result.Author('Mingrui Zhang'), arxiv.Result.Author('Jiasheng Zhang'), arxiv.Result.Author('Yidong Ma'), arxiv.Result.Author('Minchen Li'), arxiv.Result.Author('Yuanming Hu'), arxiv.Result.Author('Chenfanfu Jiang'), arxiv.Result.Author('Tiantian Liu')]","Differentiable physics enables efficient gradient-based optimizations of
neural network (NN) controllers. However, existing work typically only delivers
NN controllers with limited capability and generalizability. We present a
practical learning framework that outputs unified NN controllers capable of
tasks with significantly improved complexity and diversity. To systematically
improve training robustness and efficiency, we investigated a suite of
improvements over the baseline approach, including periodic activation
functions, and tailored loss functions. In addition, we find our adoption of
batching and an Adam optimizer effective in training complex locomotion tasks.
We evaluate our framework on differentiable mass-spring and material point
method (MPM) simulations, with challenging locomotion tasks and multiple robot
designs. Experiments show that our learning framework, based on differentiable
physics, delivers better results than reinforcement learning and converges much
faster. We demonstrate that users can interactively control soft robot
locomotion and switch among multiple goals with specified velocity, height, and
direction instructions using a unified NN controller trained in our system.",0.118286565,-0.025994897,0.08763647,C
7274,"The KG-C adapter can thus gener-        vation would beneÔ¨Åt from the further study that
ate a relevant KG-aware query for a given sample      explores the optimal combination of KGs by expert
and help to fuse representations from suitable ex-    selection or rejection.","It     ingly, both cases have the ability not to focus on
veriÔ¨Åes that KG-awareness acquired with the KG        the expert adapter based on WikiData, which
classiÔ¨Åcation task is beneÔ¨Åcial to categorize the     can be seen as a redundant expert.4 This obser-
given sample.",pert adapters in our proposed framework.,2022-06-08 07:36:31+00:00,Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Author('Yu Jin Kim'), arxiv.Result.Author('Beong-woo Kwak'), arxiv.Result.Author('Youngwook Kim'), arxiv.Result.Author('Reinald Kim Amplayo'), arxiv.Result.Author('Seung-won Hwang'), arxiv.Result.Author('Jinyoung Yeo')]","Commonsense reasoning systems should be able to generalize to diverse
reasoning cases. However, most state-of-the-art approaches depend on expensive
data annotations and overfit to a specific benchmark without learning how to
perform general semantic reasoning. To overcome these drawbacks, zero-shot QA
systems have shown promise as a robust learning scheme by transforming a
commonsense knowledge graph (KG) into synthetic QA-form samples for model
training. Considering the increasing type of different commonsense KGs, this
paper aims to extend the zero-shot transfer learning scenario into
multiple-source settings, where different KGs can be utilized synergetically.
Towards this goal, we propose to mitigate the loss of knowledge from the
interference among the different knowledge sources, by developing a modular
variant of the knowledge aggregation as a new zero-shot commonsense reasoning
framework. Results on five commonsense reasoning benchmarks demonstrate the
efficacy of our framework, improving the performance with multiple KGs.",-0.103640966,-0.08812931,-0.06780909,A
7275,"The KG-C adapter can thus gener-        vation would beneÔ¨Åt from the further study that
ate a relevant KG-aware query for a given sample      explores the optimal combination of KGs by expert
and help to fuse representations from suitable ex-    selection or rejection.","It     ingly, both cases have the ability not to focus on
veriÔ¨Åes that KG-awareness acquired with the KG        the expert adapter based on WikiData, which
classiÔ¨Åcation task is beneÔ¨Åcial to categorize the     can be seen as a redundant expert.4 This obser-
given sample.",pert adapters in our proposed framework.,2022-06-08 07:36:31+00:00,Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Author('Yu Jin Kim'), arxiv.Result.Author('Beong-woo Kwak'), arxiv.Result.Author('Youngwook Kim'), arxiv.Result.Author('Reinald Kim Amplayo'), arxiv.Result.Author('Seung-won Hwang'), arxiv.Result.Author('Jinyoung Yeo')]","Commonsense reasoning systems should be able to generalize to diverse
reasoning cases. However, most state-of-the-art approaches depend on expensive
data annotations and overfit to a specific benchmark without learning how to
perform general semantic reasoning. To overcome these drawbacks, zero-shot QA
systems have shown promise as a robust learning scheme by transforming a
commonsense knowledge graph (KG) into synthetic QA-form samples for model
training. Considering the increasing type of different commonsense KGs, this
paper aims to extend the zero-shot transfer learning scenario into
multiple-source settings, where different KGs can be utilized synergetically.
Towards this goal, we propose to mitigate the loss of knowledge from the
interference among the different knowledge sources, by developing a modular
variant of the knowledge aggregation as a new zero-shot commonsense reasoning
framework. Results on five commonsense reasoning benchmarks demonstrate the
efficacy of our framework, improving the performance with multiple KGs.",-0.103640966,-0.08812931,-0.06780909,A
7311,"12
Societal Impact

Developing hierarchical reinforcement learning methods that are useful for real-world applications
will still require further research.","In International Conference on Machine
  Learning, 2019.","However, in the longer term future, it has the potential to help
humans automate more tasks by reducing the need to specify intermediate rewards.",2022-06-08 18:20:15+00:00,Deep Hierarchical Planning from Pixels,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO', 'stat.ML']","[arxiv.Result.Author('Danijar Hafner'), arxiv.Result.Author('Kuang-Huei Lee'), arxiv.Result.Author('Ian Fischer'), arxiv.Result.Author('Pieter Abbeel')]","Intelligent agents need to select long sequences of actions to solve complex
tasks. While humans easily break down tasks into subgoals and reach them
through millions of muscle commands, current artificial intelligence is limited
to tasks with horizons of a few hundred decisions, despite large compute
budgets. Research on hierarchical reinforcement learning aims to overcome this
limitation but has proven to be challenging, current methods rely on manually
specified goal spaces or subtasks, and no general solution exists. We introduce
Director, a practical method for learning hierarchical behaviors directly from
pixels by planning inside the latent space of a learned world model. The
high-level policy maximizes task and exploration rewards by selecting latent
goals and the low-level policy learns to achieve the goals. Despite operating
in latent space, the decisions are interpretable because the world model can
decode goals into images for visualization. Director outperforms exploration
methods on tasks with sparse rewards, including 3D maze traversal with a
quadruped robot from an egocentric camera and proprioception, without access to
the global position or top-down view that was used by prior work. Director also
learns successful behaviors across a wide range of environments, including
visual control, Atari games, and DMLab levels.",0.35758495,0.0096836565,0.28081882,C
7583,"We further developed a novel research rec-    Given the holistic analysis of the Ô¨Åeld that MACQ offers, we
ommendation procedure for the space of model acquisition        have identiÔ¨Åed several promising areas for further research.","We have imple-
mented the above encoding and found that modern SAT                        5 Open Research Questions
solvers and knowledge compilers are readily capable of han-
dling the theory.",techniques.,2022-06-14 00:18:12+00:00,MACQ: A Holistic View of Model Acquisition Techniques,cs.AI,"['cs.AI', '68T05', 'I.2.6']","[arxiv.Result.Author('Ethan Callanan'), arxiv.Result.Author('Rebecca De Venezia'), arxiv.Result.Author('Victoria Armstrong'), arxiv.Result.Author('Alison Paredes'), arxiv.Result.Author('Tathagata Chakraborti'), arxiv.Result.Author('Christian Muise')]","For over three decades, the planning community has explored countless methods
for data-driven model acquisition. These range in sophistication (e.g., simple
set operations to full-blown reformulations), methodology (e.g., logic-based
vs. planing-based), and assumptions (e.g., fully vs. partially observable).
With no fewer than 43 publications in the space, it can be overwhelming to
understand what approach could or should be applied in a new setting. We
present a holistic characterization of the action model acquisition space and
further introduce a unifying framework for automated action model acquisition.
We have re-implemented some of the landmark approaches in the area, and our
characterization of all the techniques offers deep insight into the research
opportunities that remain; i.e., those settings where no technique is capable
of solving.",-0.09562104,0.031842086,-0.20914386,A
7645,"Neural methods usu-
                                              plied to reason by analogy with a limited success,          ally have no mechanisms to distill high-level patterns, such
                                              motivating the need for further research towards            as entire situations or events, from exemplar data.","Experiments with language            standing analogies between proportions [Ushio et al., 2021b],
                                              models and neuro-symbolic AI reasoners on these             and they are likely to perform poorly on more complex analo-
                                              tasks reveal that state-of-the-art methods can be ap-       gies between two situations or domains.","Semi-
                                              comprehensive and scalable analogical reasoning             nal cognitively inspired architectures [Forbus et al., 1995;
                                              by AI.",2022-06-14 20:56:26+00:00,Understanding Narratives through Dimensions of Analogy,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Thiloshon Nagarajah'), arxiv.Result.Author('Filip Ilievski'), arxiv.Result.Author('Jay Pujara')]","Analogical reasoning is a powerful qualitative reasoning tool that enables
humans to connect two situations, and to generalize their knowledge from
familiar to novel situations. Cognitive Science research provides valuable
insights into the richness and complexity of analogical reasoning, together
with implementations of expressive analogical reasoners with limited
scalability. Modern scalable AI techniques with the potential to reason by
analogy have been only applied to the special case of proportional analogy, and
not to understanding higher-order analogies. In this paper, we aim to bridge
the gap by: 1) formalizing six dimensions of analogy based on mature insights
from Cognitive Science research, 2) annotating a corpus of fables with each of
these dimensions, and 3) defining four tasks with increasing complexity that
enable scalable evaluation of AI techniques. Experiments with language models
and neuro-symbolic AI reasoners on these tasks reveal that state-of-the-art
methods can be applied to reason by analogy with a limited success, motivating
the need for further research towards comprehensive and scalable analogical
reasoning by AI. We make all our code and data available.",0.11322961,-0.23932785,0.077073105,C
7646,"and neuro-symbolic AI reasoners on these tasks re-
                                              veal that state-of-the-art methods can be applied to           While a rich body of Cognitive Science work on analog-
                                              reason by analogy with a limited success, motivat-          ical reasoning exists [Gentner, 1983; Holyoak et al., 1995;
                                              ing the need for further research towards compre-           Tversky, 1977], modern AI techniques have not been adapted
                                              hensive and scalable analogical reasoning by AI.",Experiments with language models             variety of skills for relational awareness.,to this challenge at scale.,2022-06-14 20:56:26+00:00,Understanding Narratives through Dimensions of Analogy,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Thiloshon Nagarajah'), arxiv.Result.Author('Filip Ilievski'), arxiv.Result.Author('Jay Pujara')]","Analogical reasoning is a powerful qualitative reasoning tool that enables
humans to connect two situations, and to generalize their knowledge from
familiar to novel situations. Cognitive Science research provides valuable
insights into the richness and complexity of analogical reasoning, together
with implementations of expressive analogical reasoners with limited
scalability. Modern scalable AI techniques with the potential to reason by
analogy have been only applied to the special case of proportional analogy, and
not to understanding higher-order analogies. In this paper, we aim to bridge
the gap by: 1) formalizing six dimensions of analogy based on mature insights
from Cognitive Science research, 2) annotating a corpus of fables with each of
these dimensions, and 3) defining four tasks with increasing complexity that
enable scalable evaluation of AI techniques. Experiments with language models
and neuro-symbolic AI reasoners on these tasks reveal that state-of-the-art
methods can be applied to reason by analogy with a limited success, motivating
the need for further research towards comprehensive and scalable analogical
reasoning by AI. We make all our code and data available.",0.057684496,-0.24149278,0.16145948,C
7718,"Investigating how the
parameters and prioritisation of AI design change to reflect the diverse dimensions of disability
is an important area of further research to build on our initial framework.","Similarly, our focus on mobility-related disability is chosen
simply as a common example within which to analyse AI development.","As the scope governs the specific decisions made about data, use, and operational definition in
practice, we first describe the components of setting a technology‚Äôs scope and then examine the
elements of data, use, and operational definition for two example technology scopes within our
illustrative scenario.",2022-06-16 16:41:23+00:00,Definition drives design: Disability models and mechanisms of bias in AI technologies,cs.AI,"['cs.AI', 'cs.HC']","[arxiv.Result.Author('Denis Newman-Griffis'), arxiv.Result.Author('Jessica Sage Rauchberg'), arxiv.Result.Author('Rahaf Alharbi'), arxiv.Result.Author('Louise Hickman'), arxiv.Result.Author('Harry Hochheiser')]","The increasing deployment of artificial intelligence (AI) tools to inform
decision making across diverse areas including healthcare, employment, social
benefits, and government policy, presents a serious risk for disabled people,
who have been shown to face bias in AI implementations. While there has been
significant work on analysing and mitigating algorithmic bias, the broader
mechanisms of how bias emerges in AI applications are not well understood,
hampering efforts to address bias where it begins. In this article, we
illustrate how bias in AI-assisted decision making can arise from a range of
specific design decisions, each of which may seem self-contained and
non-biasing when considered separately. These design decisions include basic
problem formulation, the data chosen for analysis, the use the AI technology is
put to, and operational design elements in addition to the core algorithmic
design. We draw on three historical models of disability common to different
decision-making settings to demonstrate how differences in the definition of
disability can lead to highly distinct decisions on each of these aspects of
design, leading in turn to AI technologies with a variety of biases and
downstream effects. We further show that the potential harms arising from
inappropriate definitions of disability in fundamental design stages are
further amplified by a lack of transparency and disabled participation
throughout the AI design process. Our analysis provides a framework for
critically examining AI technologies in decision-making contexts and guiding
the development of a design praxis for disability-related AI analytics. We put
forth this article to provide key questions to facilitate disability-led design
and participatory development to produce more fair and equitable AI
technologies in disability-related contexts.",-0.118001066,-0.11987085,0.1504151,A
7719,"Investigating how the
parameters and prioritisation of AI design change to reflect the diverse dimensions of disability
is an important area of further research to build on our initial framework.","Similarly, our focus on mobility-related disability is chosen
simply as a common example within which to analyse AI development.","As the scope governs the specific decisions made about data, use, and operational definition in
practice, we first describe the components of setting a technology‚Äôs scope and then examine the
elements of data, use, and operational definition for two example technology scopes within our
illustrative scenario.",2022-06-16 16:41:23+00:00,Definition drives design: Disability models and mechanisms of bias in AI technologies,cs.AI,"['cs.AI', 'cs.HC']","[arxiv.Result.Author('Denis Newman-Griffis'), arxiv.Result.Author('Jessica Sage Rauchberg'), arxiv.Result.Author('Rahaf Alharbi'), arxiv.Result.Author('Louise Hickman'), arxiv.Result.Author('Harry Hochheiser')]","The increasing deployment of artificial intelligence (AI) tools to inform
decision making across diverse areas including healthcare, employment, social
benefits, and government policy, presents a serious risk for disabled people,
who have been shown to face bias in AI implementations. While there has been
significant work on analysing and mitigating algorithmic bias, the broader
mechanisms of how bias emerges in AI applications are not well understood,
hampering efforts to address bias where it begins. In this article, we
illustrate how bias in AI-assisted decision making can arise from a range of
specific design decisions, each of which may seem self-contained and
non-biasing when considered separately. These design decisions include basic
problem formulation, the data chosen for analysis, the use the AI technology is
put to, and operational design elements in addition to the core algorithmic
design. We draw on three historical models of disability common to different
decision-making settings to demonstrate how differences in the definition of
disability can lead to highly distinct decisions on each of these aspects of
design, leading in turn to AI technologies with a variety of biases and
downstream effects. We further show that the potential harms arising from
inappropriate definitions of disability in fundamental design stages are
further amplified by a lack of transparency and disabled participation
throughout the AI design process. Our analysis provides a framework for
critically examining AI technologies in decision-making contexts and guiding
the development of a design praxis for disability-related AI analytics. We put
forth this article to provide key questions to facilitate disability-led design
and participatory development to produce more fair and equitable AI
technologies in disability-related contexts.",-0.118001066,-0.11987085,0.1504151,A
7755,for further research.,"This is left  [Darwiche and Marquis, 2002] A. Darwiche and P. Marquis.",A knowledge compilation map.,2022-06-17 13:17:45+00:00,Rectifying Mono-Label Boolean Classifiers,cs.AI,['cs.AI'],"[arxiv.Result.Author('Sylvie Coste-Marquis'), arxiv.Result.Author('Pierre Marquis')]","We elaborate on the notion of rectification of a Boolean classifier $\Sigma$.
Given $\Sigma$ and some background knowledge $T$, postulates characterizing the
way $\Sigma$ must be changed into a new classifier $\Sigma \star T$ that
complies with $T$ have already been presented. We focus here on the specific
case of mono-label Boolean classifiers, i.e., there is a single target concept
and any instance is classified either as positive (an element of the concept),
or as negative (an element of the complementary concept). In this specific
case, our main contribution is twofold: (1) we show that there is a unique
rectification operator $\star$ satisfying the postulates, and (2) when $\Sigma$
and $T$ are Boolean circuits, we show how a classification circuit equivalent
to $\Sigma \star T$ can be computed in time linear in the size of $\Sigma$ and
$T$; when $\Sigma$ and $T$ are decision trees, a decision tree equivalent to
$\Sigma \star T$ can be computed in time polynomial in the size of $\Sigma$ and
$T$.",-0.1562269,-0.020427806,-0.21935016,A
7756,"This is left
                                                                for further research.","That mentioned, just like AGM belief revi-
                                                                sion is not suited to every revision issue (semi-revision
x2                          x3                                  [Hansson, 1997], promotion [Schwind et al., 2018], or im-
                                                                provement [Konieczny et al., 2010], can be used when the as-
0 x1            x2                  x2                          sumption does not hold), it would be interesting to determine
                                                                how to relax the basic assumption and deal with pieces of ex-
0 x3        0 x1                x2 1                            pert knowledge that might be faulty or conÔ¨Çicting.","10          0 x3            0 x1
                                                                Acknowledgements
                    10          0 x3
                                                                This work has beneÔ¨Åted from the support of the AI Chair
                                    10                          EXPEKCTATION (ANR-19-CHIA-0005-01) of the French
                                                                National Research Agency (ANR).",2022-06-17 13:17:45+00:00,Rectifying Mono-Label Boolean Classifiers,cs.AI,['cs.AI'],"[arxiv.Result.Author('Sylvie Coste-Marquis'), arxiv.Result.Author('Pierre Marquis')]","We elaborate on the notion of rectification of a Boolean classifier $\Sigma$.
Given $\Sigma$ and some background knowledge $T$, postulates characterizing the
way $\Sigma$ must be changed into a new classifier $\Sigma \star T$ that
complies with $T$ have already been presented. We focus here on the specific
case of mono-label Boolean classifiers, i.e., there is a single target concept
and any instance is classified either as positive (an element of the concept),
or as negative (an element of the complementary concept). In this specific
case, our main contribution is twofold: (1) we show that there is a unique
rectification operator $\star$ satisfying the postulates, and (2) when $\Sigma$
and $T$ are Boolean circuits, we show how a classification circuit equivalent
to $\Sigma \star T$ can be computed in time linear in the size of $\Sigma$ and
$T$; when $\Sigma$ and $T$ are decision trees, a decision tree equivalent to
$\Sigma \star T$ can be computed in time polynomial in the size of $\Sigma$ and
$T$.",-0.20640427,-0.0004398115,-0.13932778,A
7757,[33] conducted further research on the pre-trained NLP model.,"Kurita et
to deceive the artiÔ¨Åcial intelligence systems, and to simulate the     al.","malicious users‚Äô attack action by adding adversarial pixels to         On this basis, Sun et al.",2022-06-17 13:59:52+00:00,Is Multi-Modal Necessarily Better? Robustness Evaluation of Multi-modal Fake News Detection,cs.AI,"['cs.AI', 'cs.CY', 'cs.SI']","[arxiv.Result.Author('Jinyin Chen'), arxiv.Result.Author('Chengyu Jia'), arxiv.Result.Author('Haibin Zheng'), arxiv.Result.Author('Ruoxi Chen'), arxiv.Result.Author('Chenbo Fu')]","The proliferation of fake news and its serious negative social influence push
fake news detection methods to become necessary tools for web managers.
Meanwhile, the multi-media nature of social media makes multi-modal fake news
detection popular for its ability to capture more modal features than uni-modal
detection methods. However, current literature on multi-modal detection is more
likely to pursue the detection accuracy but ignore the robustness of the
detector. To address this problem, we propose a comprehensive robustness
evaluation of multi-modal fake news detectors. In this work, we simulate the
attack methods of malicious users and developers, i.e., posting fake news and
injecting backdoors. Specifically, we evaluate multi-modal detectors with five
adversarial and two backdoor attack methods. Experiment results imply that: (1)
The detection performance of the state-of-the-art detectors degrades
significantly under adversarial attacks, even worse than general detectors; (2)
Most multi-modal detectors are more vulnerable when subjected to attacks on
visual modality than textual modality; (3) Popular events' images will cause
significant degradation to the detectors when they are subjected to backdoor
attacks; (4) The performance of these detectors under multi-modal attacks is
worse than under uni-modal attacks; (5) Defensive methods will improve the
robustness of the multi-modal detectors.",0.13927908,-0.29508358,0.11059265,C
7791,"With many questions unanswered, we hope this preliminary work
would motivate further research.","And how to incubate an artiÔ¨Åcial agent with this ability through
interaction with the environment?","9
References

[1] Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C. L., and Parikh, D. (2015).",2022-06-18 13:32:41+00:00,EST: Evaluating Scientific Thinking in Artificial Agents,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Manjie Xu'), arxiv.Result.Author('Guangyuan Jiang'), arxiv.Result.Author('Chi Zhang'), arxiv.Result.Author('Song-Chun Zhu'), arxiv.Result.Author('Yixin Zhu')]","Theoretical ideas and empirical research have shown us a seemingly surprising
result: children, even very young toddlers, demonstrate learning and thinking
in a strikingly similar manner to scientific reasoning in formal research.
Encountering a novel phenomenon, children make hypotheses against data, conduct
causal inference from observation, test their theory via experimentation, and
correct the proposition if inconsistency arises. Rounds of such processes
continue until the underlying mechanism is found. Towards building machines
that can learn and think like people, one natural question for us to ask is:
whether the intelligence we achieve today manages to perform such a scientific
thinking process, and if any, at what level. In this work, we devise the EST
environment for evaluating the scientific thinking ability in artificial
agents. Motivated by the stream of research on causal discovery, we build our
interactive EST environment based on Blicket detection. Specifically, in each
episode of EST, an agent is presented with novel observations and asked to
figure out all objects' Blicketness. At each time step, the agent proposes new
experiments to validate its hypothesis and updates its current belief. By
evaluating Reinforcement Learning (RL) agents on both a symbolic and visual
version of this task, we notice clear failure of today's learning methods in
reaching a level of intelligence comparable to humans. Such inefficacy of
learning in scientific thinking calls for future research in building humanlike
intelligence.",0.12531067,0.10187969,0.35839936,C
7940,"In this paper, we further study L-fuzzy Œ≤-covering-based lower and upper rough approximation operators.","In addition, the
research of interdependency is necessary, which show a necessary and suÔ¨Écient condition under which two L-fuzzy
coverings can generate the same L-fuzzy Œ≤-covering-based rough approximation operators by introducing the notion
of reduct and core for a fuzzy covering.","Fol-
lowing the idea of [14] and [28], we give the deÔ¨Ånition of L-fuzzy Œ≤-covering-based lower and upper rough approx-
imation operators by introducing the concepts such as Œ≤-degree of intersection and Œ≤-subsethood degree, which are
generalizations of degree of intersection and subsethood degree, respectively.",2022-05-13 05:30:51+00:00,On three types of $L$-fuzzy $Œ≤$-covering-based rough sets,cs.AI,['cs.AI'],"[arxiv.Result.Author('Wei Li'), arxiv.Result.Author('Bin Yang'), arxiv.Result.Author('Junsheng Qiao')]","In this paper, we mainly construct three types of $L$-fuzzy
$\beta$-covering-based rough set models and study the axiom sets, matrix
representations and interdependency of these three pairs of $L$-fuzzy
$\beta$-covering-based rough approximation operators. Firstly, we propose three
pairs of $L$-fuzzy $\beta$-covering-based rough approximation operators by
introducing the concepts such as $\beta$-degree of intersection and
$\beta$-subsethood degree, which are generalizations of degree of intersection
and subsethood degree, respectively. And then, the axiom set for each of these
$L$-fuzzy $\beta$-covering-based rough approximation operator is investigated.
Thirdly, we give the matrix representations of three types of $L$-fuzzy
$\beta$-covering-based rough approximation operators, which make it valid to
calculate the $L$-fuzzy $\beta$-covering-based lower and upper rough
approximation operators through operations on matrices. Finally, the
interdependency of the three pairs of rough approximation operators based on
$L$-fuzzy $\beta$-covering is studied by using the notion of reducible elements
and independent elements. In other words, we present the necessary and
sufficient conditions under which two $L$-fuzzy $\beta$-coverings can generate
the same lower and upper rough approximation operations.",-0.2159589,0.19987915,-0.13099356,B
8044,"Finally, in Section
fected agents will start optimizing their individual ob-              5, conclusions are drawn and further research areas are
jectives with simple MIP techniques based on reduced                  suggested.","During disruptions, directly af-                sults with sample data are provided.","resources (capacity or material); resulting interim re-
sults will propagate along the chain to their suppli-                 2.",2022-06-23 10:28:54+00:00,A Novel Multi-Agent Scheduling Mechanism for Adaptation of Production Plans in Case of Supply Chain Disruptions,cs.AI,"['cs.AI', 'cs.MA', 'math.OC']","[arxiv.Result.Author('Jing Tan'), arxiv.Result.Author('Lars Braubach'), arxiv.Result.Author('Kai Jander'), arxiv.Result.Author('Rongjun Xu'), arxiv.Result.Author('Kai Chen')]","Manufacturing companies typically use sophisticated production planning
systems optimizing production steps, often delivering near-optimal solutions.
As a downside for delivering a near-optimal schedule, planning systems have
high computational demands resulting in hours of computation. Under normal
circumstances this is not issue if there is enough buffer time before
implementation of the schedule (e.g. at night for the next day). However, in
case of unexpected disruptions such as delayed part deliveries or defectively
manufactured goods, the planned schedule may become invalid and swift
replanning becomes necessary. Such immediate replanning is unsuited for
existing optimal planners due to the computational requirements. This paper
proposes a novel solution that can effectively and efficiently perform
replanning in case of different types of disruptions using an existing plan.
The approach is based on the idea to adhere to the existing schedule as much as
possible, adapting it based on limited local changes. For that purpose an
agent-based scheduling mechanism has been devised, in which agents represent
materials and production sites and use local optimization techniques and
negotiations to generate an adapted (sufficient, but non-optimal) schedule. The
approach has been evaluated using real production data from Huawei, showing
that efficient schedules are produced in short time. The system has been
implemented as proof of concept and is currently reimplemented and transferred
to a production system based on the Jadex agent platform.",0.039523046,0.29582626,0.04700202,B
8050,"In addition to the integration of DNNs into the framework, further research should be
performed in order to learn useful sequences of actions.","First,
BT AI3MF is not yet equipped with deep neural networks (DNNs), and is therefore unable to handle certain types
of inputs, such as images.","Typically, in the current version of BT AI3MF , we built in
the fact that each action should be repeated eight times in a row.",2022-06-24 22:07:21+00:00,Multi-Modal and Multi-Factor Branching Time Active Inference,cs.AI,['cs.AI'],"[arxiv.Result.Author('Th√©ophile Champion'), arxiv.Result.Author('Marek Grze≈õ'), arxiv.Result.Author('Howard Bowman')]","Active inference is a state-of-the-art framework for modelling the brain that
explains a wide range of mechanisms such as habit formation, dopaminergic
discharge and curiosity. Recently, two versions of branching time active
inference (BTAI) based on Monte-Carlo tree search have been developed to handle
the exponential (space and time) complexity class that occurs when computing
the prior over all possible policies up to the time horizon. However, those two
versions of BTAI still suffer from an exponential complexity class w.r.t the
number of observed and latent variables being modelled. In the present paper,
we resolve this limitation by first allowing the modelling of several
observations, each of them having its own likelihood mapping. Similarly, we
allow each latent state to have its own transition mapping. The inference
algorithm then exploits the factorisation of the likelihood and transition
mappings to accelerate the computation of the posterior. Those two
optimisations were tested on the dSprites environment in which the metadata of
the dSprites dataset was used as input to the model instead of the dSprites
images. On this task, $BTAI_{VMP}$ (Champion et al., 2022b,a) was able to solve
96.9\% of the task in 5.1 seconds, and $BTAI_{BF}$ (Champion et al., 2021a) was
able to solve 98.6\% of the task in 17.5 seconds. Our new approach
($BTAI_{3MF}$) outperformed both of its predecessors by solving the task
completly (100\%) in only 2.559 seconds. Finally, $BTAI_{3MF}$ has been
implemented in a flexible and easy to use (python) package, and we developed a
graphical user interface to enable the inspection of the model's beliefs,
planning process and behaviour.",0.3886558,-0.17249829,-0.060395204,C
8161,"Other types could
have been deÔ¨Åned and further research can be made in this aspect.","The reason for having diÔ¨Äerent types was to investigate their
impact on the inferential capacity of fuzzy reasoning models.","In conclusion, note that these knowledge bases were built by a single agent,
without the collaboration of other domain experts.",2022-06-28 12:28:47+00:00,Comparing and extending the use of defeasible argumentation with quantitative data in real-world contexts,cs.AI,"['cs.AI', 'I.2.4; I.2.1']","[arxiv.Result.Author('Lucas Rizzo'), arxiv.Result.Author('Luca Longo')]","Dealing with uncertain, contradicting, and ambiguous information is still a
central issue in Artificial Intelligence (AI). As a result, many formalisms
have been proposed or adapted so as to consider non-monotonicity, with only a
limited number of works and researchers performing any sort of comparison among
them. A non-monotonic formalism is one that allows the retraction of previous
conclusions or claims, from premises, in light of new evidence, offering some
desirable flexibility when dealing with uncertainty. This research article
focuses on evaluating the inferential capacity of defeasible argumentation, a
formalism particularly envisioned for modelling non-monotonic reasoning. In
addition to this, fuzzy reasoning and expert systems, extended for handling
non-monotonicity of reasoning, are selected and employed as baselines, due to
their vast and accepted use within the AI community. Computational trust was
selected as the domain of application of such models. Trust is an ill-defined
construct, hence, reasoning applied to the inference of trust can be seen as
non-monotonic. Inference models were designed to assign trust scalars to
editors of the Wikipedia project. In particular, argument-based models
demonstrated more robustness than those built upon the baselines despite the
knowledge bases or datasets employed. This study contributes to the body of
knowledge through the exploitation of defeasible argumentation and its
comparison to similar approaches. The practical use of such approaches coupled
with a modular design that facilitates similar experiments was exemplified and
their respective implementations made publicly available on GitHub [120, 121].
This work adds to previous works, empirically enhancing the generalisability of
defeasible argumentation as a compelling approach to reason with quantitative
data and uncertain knowledge.",-0.19294024,-0.019269744,-0.027548311,A
8176,"However, most research focuses on the single type
of fault, a preliminary study that needs further research.","With the advancements in Big data analysis using AI models,
it is possible to tackle this problem to a great extent.","Also, the researchers have focussed on single
sensor data, which again reduces the credibility of research as the health of machinery cannot be solely
predicted based on a single sensor parameter.",2022-05-30 14:54:27+00:00,Multi-Fault Diagnosis Of Industrial Rotating Machines Using Data-Driven Approach: A Review Of Two Decades Of Research,cs.AI,['cs.AI'],"[arxiv.Result.Author('Shreyas Gawde'), arxiv.Result.Author('Shruti Patil'), arxiv.Result.Author('Satish Kumar'), arxiv.Result.Author('Pooja Kamat'), arxiv.Result.Author('Ketan Kotecha'), arxiv.Result.Author('Ajith Abraham')]","Industry 4.0 is an era of smart manufacturing. Manufacturing is impossible
without the use of machinery. Majority of these machines comprise rotating
components and are called rotating machines. The engineers' top priority is to
maintain these critical machines to reduce the unplanned shutdown and increase
the useful life of machinery. Predictive maintenance (PDM) is the current trend
of smart maintenance. The challenging task in PDM is to diagnose the type of
fault. With Artificial Intelligence (AI) advancement, data-driven approach for
predictive maintenance is taking a new flight towards smart manufacturing.
Several researchers have published work related to fault diagnosis in rotating
machines, mainly exploring a single type of fault. However, a consolidated
review of literature that focuses more on multi-fault diagnosis of rotating
machines is lacking. There is a need to systematically cover all the aspects
right from sensor selection, data acquisition, feature extraction, multi-sensor
data fusion to the systematic review of AI techniques employed in multi-fault
diagnosis. In this regard, this paper attempts to achieve the same by
implementing a systematic literature review on a Data-driven approach for
multi-fault diagnosis of Industrial Rotating Machines using Preferred Reporting
Items for Systematic Reviews and Meta-Analysis (PRISMA) method. The PRISMA
method is a collection of guidelines for the composition and structure of
systematic reviews and other meta-analyses. This paper identifies the
foundational work done in the field and gives a comparative study of different
aspects related to multi-fault diagnosis of industrial rotating machines. The
paper also identifies the major challenges, research gap. It gives solutions
using recent advancements in AI in implementing multi-fault diagnosis, giving a
strong base for future research in this field.",-0.03459248,0.05807603,-0.09125702,B
8177,"Challenges and limitations in multi-fault diagnosis

          The challenges and limitations of multi-fault diagnosis are discussed in this paper that may
aid in further research.","Complete Summary of Literature Revie

                                                                                                                                                                    45
4.2.",Table 17 gives a systematic overview of the challenges and limitations.,2022-05-30 14:54:27+00:00,Multi-Fault Diagnosis Of Industrial Rotating Machines Using Data-Driven Approach: A Review Of Two Decades Of Research,cs.AI,['cs.AI'],"[arxiv.Result.Author('Shreyas Gawde'), arxiv.Result.Author('Shruti Patil'), arxiv.Result.Author('Satish Kumar'), arxiv.Result.Author('Pooja Kamat'), arxiv.Result.Author('Ketan Kotecha'), arxiv.Result.Author('Ajith Abraham')]","Industry 4.0 is an era of smart manufacturing. Manufacturing is impossible
without the use of machinery. Majority of these machines comprise rotating
components and are called rotating machines. The engineers' top priority is to
maintain these critical machines to reduce the unplanned shutdown and increase
the useful life of machinery. Predictive maintenance (PDM) is the current trend
of smart maintenance. The challenging task in PDM is to diagnose the type of
fault. With Artificial Intelligence (AI) advancement, data-driven approach for
predictive maintenance is taking a new flight towards smart manufacturing.
Several researchers have published work related to fault diagnosis in rotating
machines, mainly exploring a single type of fault. However, a consolidated
review of literature that focuses more on multi-fault diagnosis of rotating
machines is lacking. There is a need to systematically cover all the aspects
right from sensor selection, data acquisition, feature extraction, multi-sensor
data fusion to the systematic review of AI techniques employed in multi-fault
diagnosis. In this regard, this paper attempts to achieve the same by
implementing a systematic literature review on a Data-driven approach for
multi-fault diagnosis of Industrial Rotating Machines using Preferred Reporting
Items for Systematic Reviews and Meta-Analysis (PRISMA) method. The PRISMA
method is a collection of guidelines for the composition and structure of
systematic reviews and other meta-analyses. This paper identifies the
foundational work done in the field and gives a comparative study of different
aspects related to multi-fault diagnosis of industrial rotating machines. The
paper also identifies the major challenges, research gap. It gives solutions
using recent advancements in AI in implementing multi-fault diagnosis, giving a
strong base for future research in this field.",-0.13835314,0.13561419,-0.098251805,B
8185,"We then collected these 137 instances as the hard set to further study the cost distribution
of instances much harder than the training instances.","TRAINING DATASET                    HARD DATASET

            EXPANDED TIME SOLVED     NODES PER SEC  EXPANDED TIME SOLVED

SOKOLUTION    191436 310 S 100%             618     ‚Äî      ‚Äî         0%
DBFS          13776 370 S 93%                37
                                                    18651  537 69%

unsolved.","For each found plan (s0, a1, s1, ..., an, sn) from
the start state s0 to the goal state sn, we generated training tuples (si, lsi , vsi ) with policy label
lsi = ai+1 and remaining distance label vsi = n ‚àí i as training data.",2022-06-28 21:48:54+00:00,Left Heavy Tails and the Effectiveness of the Policy and Value Networks in DNN-based best-first search for Sokoban Planning,cs.AI,['cs.AI'],"[arxiv.Result.Author('Dieqiao Feng'), arxiv.Result.Author('Carla Gomes'), arxiv.Result.Author('Bart Selman')]","Despite the success of practical solvers in various NP-complete domains such
as SAT and CSP as well as using deep reinforcement learning to tackle
two-player games such as Go, certain classes of PSPACE-hard planning problems
have remained out of reach. Even carefully designed domain-specialized solvers
can fail quickly due to the exponential search space on hard instances. Recent
works that combine traditional search methods, such as best-first search and
Monte Carlo tree search, with Deep Neural Networks' (DNN) heuristics have shown
promising progress and can solve a significant number of hard planning
instances beyond specialized solvers. To better understand why these approaches
work, we studied the interplay of the policy and value networks of DNN-based
best-first search on Sokoban and show the surprising effectiveness of the
policy network, further enhanced by the value network, as a guiding heuristic
for the search. To further understand the phenomena, we studied the cost
distribution of the search algorithms and found that Sokoban instances can have
heavy-tailed runtime distributions, with tails both on the left and right-hand
sides. In particular, for the first time, we show the existence of \textit{left
heavy tails} and propose an abstract tree model that can empirically explain
the appearance of these tails. The experiments show the critical role of the
policy network as a powerful heuristic guiding the search, which can lead to
left heavy tails with polynomial scaling by avoiding exploring exponentially
sized subtrees. Our results also demonstrate the importance of random restarts,
as are widely used in traditional combinatorial solvers, for DNN-based search
methods to avoid left and right heavy tails.",0.17554927,0.15626228,-0.19087344,C
8186,"To further study why the policy network is more effective,

we studied the performance of both networks in detecting Table 4: Dead-end detection accuracy
dead-end states.","With extra properly added depth and value terms, the performance of Pure
Policy can further increase to obtain our best strategies.","Detecting dead-end states is crucial to

avoid exponential run times because the search has to                                                                                                                    Train Test Hard
recover from exploring those states.",2022-06-28 21:48:54+00:00,Left Heavy Tails and the Effectiveness of the Policy and Value Networks in DNN-based best-first search for Sokoban Planning,cs.AI,['cs.AI'],"[arxiv.Result.Author('Dieqiao Feng'), arxiv.Result.Author('Carla Gomes'), arxiv.Result.Author('Bart Selman')]","Despite the success of practical solvers in various NP-complete domains such
as SAT and CSP as well as using deep reinforcement learning to tackle
two-player games such as Go, certain classes of PSPACE-hard planning problems
have remained out of reach. Even carefully designed domain-specialized solvers
can fail quickly due to the exponential search space on hard instances. Recent
works that combine traditional search methods, such as best-first search and
Monte Carlo tree search, with Deep Neural Networks' (DNN) heuristics have shown
promising progress and can solve a significant number of hard planning
instances beyond specialized solvers. To better understand why these approaches
work, we studied the interplay of the policy and value networks of DNN-based
best-first search on Sokoban and show the surprising effectiveness of the
policy network, further enhanced by the value network, as a guiding heuristic
for the search. To further understand the phenomena, we studied the cost
distribution of the search algorithms and found that Sokoban instances can have
heavy-tailed runtime distributions, with tails both on the left and right-hand
sides. In particular, for the first time, we show the existence of \textit{left
heavy tails} and propose an abstract tree model that can empirically explain
the appearance of these tails. The experiments show the critical role of the
policy network as a powerful heuristic guiding the search, which can lead to
left heavy tails with polynomial scaling by avoiding exploring exponentially
sized subtrees. Our results also demonstrate the importance of random restarts,
as are widely used in traditional combinatorial solvers, for DNN-based search
methods to avoid left and right heavy tails.",0.1777331,0.09672531,-0.038355313,C
8258,driving may merit further study.,"Here we showed
or useful in more complex driving tasks such as highway           that among sufÔ¨Åciently capable models, the whiteness, i.e.","smoothness of generated commands on an appropriate val-
                                                                  idation set predicted driving ability equally well as the
   The beneÔ¨Åts of LiDAR-based driving become apparent             magnitude of errors.",2022-06-30 10:06:49+00:00,LiDAR-as-Camera for End-to-End Driving,cs.AI,"['cs.AI', 'cs.CV', 'cs.RO', '68T07, 68T40', 'I.2.9']","[arxiv.Result.Author('Ardi Tampuu'), arxiv.Result.Author('Romet Aidla'), arxiv.Result.Author('Jan Are van Gent'), arxiv.Result.Author('Tambet Matiisen')]","The core task of any autonomous driving system is to transform sensory inputs
into driving commands. In end-to-end driving, this is achieved via a neural
network, with one or multiple cameras as the most commonly used input and
low-level driving command, e.g. steering angle, as output. However,
depth-sensing has been shown in simulation to make the end-to-end driving task
easier. On a real car, combining depth and visual information can be
challenging, due to the difficulty of obtaining good spatial and temporal
alignment of the sensors. To alleviate alignment problems, Ouster LiDARs can
output surround-view LiDAR-images with depth, intensity, and ambient radiation
channels. These measurements originate from the same sensor, rendering them
perfectly aligned in time and space. We demonstrate that such LiDAR-images are
sufficient for the real-car road-following task and perform at least equally to
camera-based models in the tested conditions, with the difference increasing
when needing to generalize to new weather conditions. In the second direction
of study, we reveal that the temporal smoothness of off-policy prediction
sequences correlates equally well with actual on-policy driving ability as the
commonly used mean absolute error.",0.0131618,0.05328823,0.04180142,A
8387,"(1) The transition time was constant and can be calculated according to the location of the
     ground target in advance, which may be reasonable for problem analysis, but is significantly
     not suitable for further research.","Though adopting three pieces of knowledge into

the greedy algorithm proposed in our previous research improved the algorithm to some extent,

the previous research was too theoretical.","Frankly speaking, the transition time for AEOSs is time-
     dependent (Liu et al., 2017).",2022-07-04 08:18:54+00:00,Three multi-objective memtic algorithms for observation scheduling problem of active-imaging AEOS,cs.AI,['cs.AI'],"[arxiv.Result.Author('Zhongxiang Chang'), arxiv.Result.Author('Zhongbao Zhou')]","Observation scheduling problem for agile earth observation satellites
(OSPFAS) plays a critical role in management of agile earth observation
satellites (AEOSs). Active imaging enriches the extension of OSPFAS, we call
the novel problem as observation scheduling problem for AEOS with variable
image duration (OSWVID). A cumulative image quality and a detailed energy
consumption is proposed to build OSWVID as a bi-objective optimization model.
Three multi-objective memetic algorithms, PD+NSGA-II, LA+NSGA-II and
ALNS+NSGA-II, are then designed to solve OSWVID. Considering the heuristic
knowledge summarized in our previous research, several operators are designed
for improving these three algorithms respectively. Based on existing instances,
we analyze the critical parameters optimization, operators evolution, and
efficiency of these three algorithms according to extensive simulation
experiments.",0.07075648,0.41285527,-0.09848948,B
8388,"To further research, energy consumption should be considered more
     practically.","We assumed the
     power is enough.","A definition of detailed energy consumption then will be also proposed in
     section 3.3.",2022-07-04 08:18:54+00:00,Three multi-objective memtic algorithms for observation scheduling problem of active-imaging AEOS,cs.AI,['cs.AI'],"[arxiv.Result.Author('Zhongxiang Chang'), arxiv.Result.Author('Zhongbao Zhou')]","Observation scheduling problem for agile earth observation satellites
(OSPFAS) plays a critical role in management of agile earth observation
satellites (AEOSs). Active imaging enriches the extension of OSPFAS, we call
the novel problem as observation scheduling problem for AEOS with variable
image duration (OSWVID). A cumulative image quality and a detailed energy
consumption is proposed to build OSWVID as a bi-objective optimization model.
Three multi-objective memetic algorithms, PD+NSGA-II, LA+NSGA-II and
ALNS+NSGA-II, are then designed to solve OSWVID. Considering the heuristic
knowledge summarized in our previous research, several operators are designed
for improving these three algorithms respectively. Based on existing instances,
we analyze the critical parameters optimization, operators evolution, and
efficiency of these three algorithms according to extensive simulation
experiments.",-0.27853912,0.16667598,0.09782076,B
8418,"Finally, Section 5 provides a summary
of the main conclusions to be drawn from this work, appointing further research
lines.","Section 4 presents the obtained results performs a
comparison between the diÔ¨Äerent models.","2 Related Work

The employment of ML is not a new endeavor in historical energy forecasting,
with several works exploring interesting approaches to this domain, starting
with simple model implementations, such as Random Forest (RF) in [9] to more
sophisticated multi-model ensembles [10].",2022-07-04 17:27:03+00:00,Deep Learning for Short-term Instant Energy Consumption Forecasting in the Manufacturing Sector,cs.AI,"['cs.AI', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Nuno Oliveira'), arxiv.Result.Author('Norberto Sousa'), arxiv.Result.Author('Isabel Pra√ßa')]","Electricity is a volatile power source that requires great planning and
resource management for both short and long term. More specifically, in the
short-term, accurate instant energy consumption forecasting contributes greatly
to improve the efficiency of buildings, opening new avenues for the adoption of
renewable energy. In that regard, data-driven approaches, namely the ones based
on machine learning, are begin to be preferred over more traditional ones since
they provide not only more simplified ways of deployment but also state of the
art results. In that sense, this work applies and compares the performance of
several deep learning algorithms, LSTM, CNN, mixed CNN-LSTM and TCN, in a real
testbed within the manufacturing sector. The experimental results suggest that
the TCN is the most reliable method for predicting instant energy consumption
in the short-term.",-0.011858377,0.13252759,-0.13408934,B
8633,"In addition, most neu-
ral network approaches to disease progression only predict one to a few metrics of disease,
highlighting an area that requires further research.","One Transformer model under the broad umbrella of disease progression models has been
proposed; [28] predicts the development of knee osteoarthritis with a Transformer model
designed for multi-agent decision-making but relies on imaging data.","Many works use neural networks as Seq2Seq models for machine translation using feed-
forward networks [29], recurrent neural networks [30], and long short-term memories [31].",2022-07-09 07:00:17+00:00,SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Bhishma Dedhia'), arxiv.Result.Author('Roshini Balasubramanian'), arxiv.Result.Author('Niraj K. Jha')]","The Synthetic Control method has pioneered a class of powerful data-driven
techniques to estimate the counterfactual reality of a unit from donor units.
At its core, the technique involves a linear model fitted on the
pre-intervention period that combines donor outcomes to yield the
counterfactual. However, linearly combining spatial information at each time
instance using time-agnostic weights fails to capture important inter-unit and
intra-unit temporal contexts and complex nonlinear dynamics of real data. We
instead propose an approach to use local spatiotemporal information before the
onset of the intervention as a promising way to estimate the counterfactual
sequence. To this end, we suggest a Transformer model that leverages particular
positional embeddings, a modified decoder attention mask, and a novel
pre-training task to perform spatiotemporal sequence-to-sequence modeling. Our
experiments on synthetic data demonstrate the efficacy of our method in the
typical small donor pool setting and its robustness against noise. We also
generate actionable healthcare insights at the population and patient levels by
simulating a state-wide public health policy to evaluate its effectiveness, an
in silico trial for asthma medications to support randomized controlled trials,
and a medical intervention for patients with Friedreich's ataxia to improve
clinical decision-making and promote personalized therapy.",0.24129403,-0.14776273,-0.15018955,C
8634,"In addition, most neu-

                                                                5
                                        Dedhia, Balasubramanian, & Jha

ral network approaches to disease progression only predict one to a few metrics of disease,
highlighting an area that requires further research.","One Transformer model under the broad umbrella of disease progression models has been
proposed; [28] predicts the development of knee osteoarthritis with a Transformer model
designed for multi-agent decision-making but relies on imaging data.","Many works use neural networks as Seq2Seq models for machine translation using feed-
forward networks [29], recurrent neural networks [30], and long short-term memories [31].",2022-07-09 07:00:17+00:00,SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Bhishma Dedhia'), arxiv.Result.Author('Roshini Balasubramanian'), arxiv.Result.Author('Niraj K. Jha')]","The Synthetic Control method has pioneered a class of powerful data-driven
techniques to estimate the counterfactual reality of a unit from donor units.
At its core, the technique involves a linear model fitted on the
pre-intervention period that combines donor outcomes to yield the
counterfactual. However, linearly combining spatial information at each time
instance using time-agnostic weights fails to capture important inter-unit and
intra-unit temporal contexts and complex nonlinear dynamics of real data. We
instead propose an approach to use local spatiotemporal information before the
onset of the intervention as a promising way to estimate the counterfactual
sequence. To this end, we suggest a Transformer model that leverages particular
positional embeddings, a modified decoder attention mask, and a novel
pre-training task to perform spatiotemporal sequence-to-sequence modeling. Our
experiments on synthetic data demonstrate the efficacy of our method in the
typical small donor pool setting and its robustness against noise. We also
generate actionable healthcare insights at the population and patient levels by
simulating a state-wide public health policy to evaluate its effectiveness, an
in silico trial for asthma medications to support randomized controlled trials,
and a medical intervention for patients with Friedreich's ataxia to improve
clinical decision-making and promote personalized therapy.",0.22625378,-0.14481325,-0.12327578,C
8636,Either removing                  retrieval task and beneÔ¨Åt further study of vision and language.,"We hope our BOSS can
compositional representation over both the local- and global-                  provide a complement for existing literature of multi-modal
levels obtain the best retrieval performance.","each of them will result in a performance decay, which proves
the further effectiveness of our composition module.",2022-07-09 07:14:44+00:00,BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid Counterfactual Training for Robust Content-based Image Retrieval,cs.AI,"['cs.AI', 'cs.CV', 'cs.IR', 'cs.LG', 'eess.IV']","[arxiv.Result.Author('Wenqiao Zhang'), arxiv.Result.Author('Jiannan Guo'), arxiv.Result.Author('Mengze Li'), arxiv.Result.Author('Haochen Shi'), arxiv.Result.Author('Shengyu Zhang'), arxiv.Result.Author('Juncheng Li'), arxiv.Result.Author('Siliang Tang'), arxiv.Result.Author('Yueting Zhuang')]","Content-Based Image Retrieval (CIR) aims to search for a target image by
concurrently comprehending the composition of an example image and a
complementary text, which potentially impacts a wide variety of real-world
applications, such as internet search and fashion retrieval. In this scenario,
the input image serves as an intuitive context and background for the search,
while the corresponding language expressly requests new traits on how specific
characteristics of the query image should be modified in order to get the
intended target image. This task is challenging since it necessitates learning
and understanding the composite image-text representation by incorporating
cross-granular semantic updates. In this paper, we tackle this task by a novel
\underline{\textbf{B}}ottom-up cr\underline{\textbf{O}}ss-modal
\underline{\textbf{S}}emantic compo\underline{\textbf{S}}ition (\textbf{BOSS})
with Hybrid Counterfactual Training framework, which sheds new light on the CIR
task by studying it from two previously overlooked perspectives:
\emph{implicitly bottom-up composition of visiolinguistic representation} and
\emph{explicitly fine-grained correspondence of query-target construction}. On
the one hand, we leverage the implicit interaction and composition of
cross-modal embeddings from the bottom local characteristics to the top global
semantics, preserving and transforming the visual representation conditioned on
language semantics in several continuous steps for effective target image
search. On the other hand, we devise a hybrid counterfactual training strategy
that can reduce the model's ambiguity for similar queries.",0.060236946,-0.22082587,-0.1595028,C
8658,"In turn, this combination could
offer an stronger baseline for further research on DRL.","For instance, one could start with a trained policy where
states are partially symbolic, and associate that part of the   Acknowledgements
state to an STRIPS model.","We would like to thank William Shen and Florian Gei√üer for
                                                                sharing the code of their implementation of the hypergraph
   As future work, there are many directions worth pursuing.",2022-07-10 14:55:16+00:00,Scaling up ML-based Black-box Planning with Partial STRIPS Models,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Author('Matias Greco'), arxiv.Result.Author('√Ålvaro Torralba'), arxiv.Result.Author('Jorge A. Baier'), arxiv.Result.Author('Hector Palacios')]","A popular approach for sequential decision-making is to perform
simulator-based search guided with Machine Learning (ML) methods like policy
learning. On the other hand, model-relaxation heuristics can guide the search
effectively if a full declarative model is available. In this work, we consider
how a practitioner can improve ML-based black-box planning on settings where a
complete symbolic model is not available. We show that specifying an incomplete
STRIPS model that describes only part of the problem enables the use of
relaxation heuristics. Our findings on several planning domains suggest that
this is an effective way to improve ML-based black-box planning beyond
collecting more data or tuning ML architectures.",-0.008105862,0.028505035,-0.02508931,A
8908,"These challenges target priorities by making large, AI-ready datasets
                                                   publicly available, incentivizing open-source solutions, and creating a demand
                                                   signal for dual use technologies that can stimulate further research.","Several projects supported by the DAF-MIT AI Accelerator are
                                                   developing public challenge problems that address numerous Federal AI research
                                                   priorities.","In this article,
                                                  we describe these public challenges being developed and how their application
                                                   contributes to scientiÔ¨Åc advances.",2022-07-14 16:13:40+00:00,Developing a Series of AI Challenges for the United States Department of the Air Force,cs.AI,"['cs.AI', 'cs.CY']","[arxiv.Result.Author('Vijay Gadepally'), arxiv.Result.Author('Gregory Angelides'), arxiv.Result.Author('Andrei Barbu'), arxiv.Result.Author('Andrew Bowne'), arxiv.Result.Author('Laura J. Brattain'), arxiv.Result.Author('Tamara Broderick'), arxiv.Result.Author('Armando Cabrera'), arxiv.Result.Author('Glenn Carl'), arxiv.Result.Author('Ronisha Carter'), arxiv.Result.Author('Miriam Cha'), arxiv.Result.Author('Emilie Cowen'), arxiv.Result.Author('Jesse Cummings'), arxiv.Result.Author('Bill Freeman'), arxiv.Result.Author('James Glass'), arxiv.Result.Author('Sam Goldberg'), arxiv.Result.Author('Mark Hamilton'), arxiv.Result.Author('Thomas Heldt'), arxiv.Result.Author('Kuan Wei Huang'), arxiv.Result.Author('Phillip Isola'), arxiv.Result.Author('Boris Katz'), arxiv.Result.Author('Jamie Koerner'), arxiv.Result.Author('Yen-Chen Lin'), arxiv.Result.Author('David Mayo'), arxiv.Result.Author('Kyle McAlpin'), arxiv.Result.Author('Taylor Perron'), arxiv.Result.Author('Jean Piou'), arxiv.Result.Author('Hrishikesh M. Rao'), arxiv.Result.Author('Hayley Reynolds'), arxiv.Result.Author('Kaira Samuel'), arxiv.Result.Author('Siddharth Samsi'), arxiv.Result.Author('Morgan Schmidt'), arxiv.Result.Author('Leslie Shing'), arxiv.Result.Author('Olga Simek'), arxiv.Result.Author('Brandon Swenson'), arxiv.Result.Author('Vivienne Sze'), arxiv.Result.Author('Jonathan Taylor'), arxiv.Result.Author('Paul Tylkin'), arxiv.Result.Author('Mark Veillette'), arxiv.Result.Author('Matthew L Weiss'), arxiv.Result.Author('Allan Wollaber'), arxiv.Result.Author('Sophia Yuditskaya'), arxiv.Result.Author('Jeremy Kepner')]","Through a series of federal initiatives and orders, the U.S. Government has
been making a concerted effort to ensure American leadership in AI. These broad
strategy documents have influenced organizations such as the United States
Department of the Air Force (DAF). The DAF-MIT AI Accelerator is an initiative
between the DAF and MIT to bridge the gap between AI researchers and DAF
mission requirements. Several projects supported by the DAF-MIT AI Accelerator
are developing public challenge problems that address numerous Federal AI
research priorities. These challenges target priorities by making large,
AI-ready datasets publicly available, incentivizing open-source solutions, and
creating a demand signal for dual use technologies that can stimulate further
research. In this article, we describe these public challenges being developed
and how their application contributes to scientific advances.",0.17025006,-0.12790497,-0.030368418,C
9067,"In Sec-   explanations should be minimal, which means they should
tion 4 we lay the foundation for further research regarding       change as little in the original input as possible to cross the
alterfactual explanations by evaluating the potential of our ap-  decision boundary of the model between the fact and foil
proach in a user study.","Counterfactual
terfactual explanations is explained in further detail.","In this study, we used an imaginary AI    class [Keane et al., 2021b; Miller, 2021].",2022-07-19 16:20:37+00:00,Alterfactual Explanations -- The Relevance of Irrelevance for Explaining AI Systems,cs.AI,['cs.AI'],"[arxiv.Result.Author('Silvan Mertes'), arxiv.Result.Author('Christina Karle'), arxiv.Result.Author('Tobias Huber'), arxiv.Result.Author('Katharina Weitz'), arxiv.Result.Author('Ruben Schlagowski'), arxiv.Result.Author('Elisabeth Andr√©')]","Explanation mechanisms from the field of Counterfactual Thinking are a
widely-used paradigm for Explainable Artificial Intelligence (XAI), as they
follow a natural way of reasoning that humans are familiar with. However, all
common approaches from this field are based on communicating information about
features or characteristics that are especially important for an AI's decision.
We argue that in order to fully understand a decision, not only knowledge about
relevant features is needed, but that the awareness of irrelevant information
also highly contributes to the creation of a user's mental model of an AI
system. Therefore, we introduce a new way of explaining AI systems. Our
approach, which we call Alterfactual Explanations, is based on showing an
alternative reality where irrelevant features of an AI's input are altered. By
doing so, the user directly sees which characteristics of the input data can
change arbitrarily without influencing the AI's decision. We evaluate our
approach in an extensive user study, revealing that it is able to significantly
contribute to the participants' understanding of an AI. We show that
alterfactual explanations are suited to convey an understanding of different
aspects of the AI's reasoning than established counterfactual explanation
methods.",-0.18851098,-0.2512909,0.34847528,A
9068,"Therefore, the advantages and
cate this vast amount of information without overburdening      disadvantages of those two concepts have to be evaluated in
                                                                further research.",Future research has to Ô¨Ånd ways to communi-      and Semifactual explanations.,"References                                                       Ilia Stepin, Jose M Alonso, Alejandro Catala, and Mart¬¥ƒ±n
                                                                    Pereira-FarinÀúa.",2022-07-19 16:20:37+00:00,Alterfactual Explanations -- The Relevance of Irrelevance for Explaining AI Systems,cs.AI,['cs.AI'],"[arxiv.Result.Author('Silvan Mertes'), arxiv.Result.Author('Christina Karle'), arxiv.Result.Author('Tobias Huber'), arxiv.Result.Author('Katharina Weitz'), arxiv.Result.Author('Ruben Schlagowski'), arxiv.Result.Author('Elisabeth Andr√©')]","Explanation mechanisms from the field of Counterfactual Thinking are a
widely-used paradigm for Explainable Artificial Intelligence (XAI), as they
follow a natural way of reasoning that humans are familiar with. However, all
common approaches from this field are based on communicating information about
features or characteristics that are especially important for an AI's decision.
We argue that in order to fully understand a decision, not only knowledge about
relevant features is needed, but that the awareness of irrelevant information
also highly contributes to the creation of a user's mental model of an AI
system. Therefore, we introduce a new way of explaining AI systems. Our
approach, which we call Alterfactual Explanations, is based on showing an
alternative reality where irrelevant features of an AI's input are altered. By
doing so, the user directly sees which characteristics of the input data can
change arbitrarily without influencing the AI's decision. We evaluate our
approach in an extensive user study, revealing that it is able to significantly
contribute to the participants' understanding of an AI. We show that
alterfactual explanations are suited to convey an understanding of different
aspects of the AI's reasoning than established counterfactual explanation
methods.",-0.32231298,-0.16797777,0.17689767,A_centroid
9199,"To mitigate algorithmic bias in BA, further research will be
necessary along several directions.",Mitigating algorithmic bias.,"First, many of the above methods for algorithmic fairness have
been developed for predictive analytics and not for prescriptive models.",2022-07-22 10:21:38+00:00,Algorithmic Fairness in Business Analytics: Directions for Research and Practice,cs.AI,['cs.AI'],"[arxiv.Result.Author('Maria De-Arteaga'), arxiv.Result.Author('Stefan Feuerriegel'), arxiv.Result.Author('Maytal Saar-Tsechansky')]","The extensive adoption of business analytics (BA) has brought financial gains
and increased efficiencies. However, these advances have simultaneously drawn
attention to rising legal and ethical challenges when BA inform decisions with
fairness implications. As a response to these concerns, the emerging study of
algorithmic fairness deals with algorithmic outputs that may result in
disparate outcomes or other forms of injustices for subgroups of the
population, especially those who have been historically marginalized. Fairness
is relevant on the basis of legal compliance, social responsibility, and
utility; if not adequately and systematically addressed, unfair BA systems may
lead to societal harms and may also threaten an organization's own survival,
its competitiveness, and overall performance. This paper offers a
forward-looking, BA-focused review of algorithmic fairness. We first review the
state-of-the-art research on sources and measures of bias, as well as bias
mitigation algorithms. We then provide a detailed discussion of the
utility-fairness relationship, emphasizing that the frequent assumption of a
trade-off between these two constructs is often mistaken or short-sighted.
Finally, we chart a path forward by identifying opportunities for business
scholars to address impactful, open challenges that are key to the effective
and responsible deployment of BA.",-0.08581574,0.08549742,0.09475819,A
9247,"Such results may motivate further research on how to accu-
                                        rately evaluate the performance of different link prediction methods for knowledge
                                        graphs.","By analyzing the tail entity distribution
                                        and evaluation protocol of these two data sets, we attribute the unexpected success
                                        of AutoWeird on ogbl-wikikg2 to inappropriate evaluation and concentrated tail
                                        entity distribution.","1 Introduction

                                        Scoring function (SF), which measures the plausibility of triplets in knowledge graphs (KGs), plays
                                        an important role to learn from KGs [13, 7].",2022-07-24 06:43:06+00:00,AutoWeird: Weird Translational Scoring Function Identified by Random Search,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Hansi Yang'), arxiv.Result.Author('Yongqi Zhang'), arxiv.Result.Author('Quanming Yao')]","Scoring function (SF) measures the plausibility of triplets in knowledge
graphs. Different scoring functions can lead to huge differences in link
prediction performances on different knowledge graphs. In this report, we
describe a weird scoring function found by random search on the open graph
benchmark (OGB). This scoring function, called AutoWeird, only uses tail entity
and relation in a triplet to compute its plausibility score. Experimental
results show that AutoWeird achieves top-1 performance on ogbl-wikikg2 data
set, but has much worse performance than other methods on ogbl-biokg data set.
By analyzing the tail entity distribution and evaluation protocol of these two
data sets, we attribute the unexpected success of AutoWeird on ogbl-wikikg2 to
inappropriate evaluation and concentrated tail entity distribution. Such
results may motivate further research on how to accurately evaluate the
performance of different link prediction methods for knowledge graphs.",-0.15453541,0.022506174,-0.26374316,A
9257,"814-817, Jan. 2020.
the described problems, opening the way to further research
in the Ô¨Åeld of data-driven future system event prediction.","1, pp.",[11] M. Mokhtar et.,2022-07-24 20:24:27+00:00,Data-driven Models to Anticipate Critical Voltage Events in Power Systems,cs.AI,"['cs.AI', 'eess.SP']","[arxiv.Result.Author('Fabrizio De Caro'), arxiv.Result.Author('Adam J. Collin'), arxiv.Result.Author('Alfredo Vaccaro')]","This paper explores the effectiveness of data-driven models to predict
voltage excursion events in power systems using simple categorical labels. By
treating the prediction as a categorical classification task, the workflow is
characterized by a low computational and data burden. A proof-of-concept case
study on a real portion of the Italian 150 kV sub-transmission network, which
hosts a significant amount of wind power generation, demonstrates the general
validity of the proposal and offers insight into the strengths and weaknesses
of several widely utilized prediction models for this application.",-0.040469177,0.17605105,-0.07911515,B
9281,"Here
we present some of the discussion points stemming
from our work and further study directions.","Conclusion

In this paper we presented a corpus-driven experiment
to transform AMR annotations into UCCA-like repre-
sentations, the evaluation of our experiment and some
of the ambiguous cases we discovered through it.",would like to thank the anonymous reviewers for the          ing.,2022-07-25 13:13:34+00:00,How much of UCCA can be predicted from AMR?,cs.AI,['cs.AI'],"[arxiv.Result.Author('Siyana Pavlova'), arxiv.Result.Author('Maxime Amblard'), arxiv.Result.Author('Bruno Guillaume')]","In this paper, we consider two of the currently popular semantic frameworks:
Abstract Meaning Representation (AMR)a more abstract framework, and Universal
Conceptual Cognitive Annotation (UCCA)-an anchored framework. We use a
corpus-based approach to build two graph rewriting systems, a deterministic and
a non-deterministic one, from the former to the latter framework. We present
their evaluation and a number of ambiguities that we discovered while building
our rules. Finally, we provide a discussion and some future work directions in
relation to comparing semantic frameworks of different flavors.",-0.1524696,-0.25343287,-0.089963034,A
9284,be built for extending further research vision.,"introducing circuit/chip/architecture/system levels considerations     Their engineering opinions of heterogeneous system design could
on how to build and optimize deep learning computing systems.","The main teaching
                                                                       objectives of this course could be listed as following:
   Our course, named Intelligent Computing Architectures, mainly
focused on the architectures explorations for deep learning tasks     (1) Know some typical intelligent computing algorithms, including
since Fall 2017.",2022-06-22 11:48:04+00:00,Towards Systems Education for Artificial Intelligence: A Course Practice in Intelligent Computing Architectures,cs.AI,"['cs.AI', 'cs.AR', 'cs.CY']","[arxiv.Result.Author('Jianlei Yang'), arxiv.Result.Author('Xiaopeng Gao'), arxiv.Result.Author('Weisheng Zhao')]","With the rapid development of artificial intelligence (AI) community,
education in AI is receiving more and more attentions. There have been many AI
related courses in the respects of algorithms and applications, while not many
courses in system level are seriously taken into considerations. In order to
bridge the gap between AI and computing systems, we are trying to explore how
to conduct AI education from the perspective of computing systems. In this
paper, a course practice in intelligent computing architectures are provided to
demonstrate the system education in AI era. The motivation for this course
practice is first introduced as well as the learning orientations. The main
goal of this course aims to teach students for designing AI accelerators on
FPGA platforms. The elaborated course contents include lecture notes and
related technical materials. Especially several practical labs and projects are
detailed illustrated. Finally, some teaching experiences and effects are
discussed as well as some potential improvements in the future.",0.25672433,-0.06731949,-0.01499765,C
9385,"For further research, multi-class classiÔ¨Åcation is considered.","We infer that binary classiÔ¨Åcation is easy due to the
binary performance feedback.",The cart-pole balancing task was successfully solved without any hidden neurons.,2022-07-27 15:30:50+00:00,Towards the Neuroevolution of Low-level Artificial General Intelligence,cs.AI,"['cs.AI', 'cs.NE', '68T05', 'I.2.6']","[arxiv.Result.Author('Sidney Pontes-Filho'), arxiv.Result.Author('Kristoffer Olsen'), arxiv.Result.Author('Anis Yazidi'), arxiv.Result.Author('Michael A. Riegler'), arxiv.Result.Author('P√•l Halvorsen'), arxiv.Result.Author('Stefano Nichele')]","In this work, we argue that the search for Artificial General Intelligence
(AGI) should start from a much lower level than human-level intelligence. The
circumstances of intelligent behavior in nature resulted from an organism
interacting with its surrounding environment, which could change over time and
exert pressure on the organism to allow for learning of new behaviors or
environment models. Our hypothesis is that learning occurs through interpreting
sensory feedback when an agent acts in an environment. For that to happen, a
body and a reactive environment are needed. We evaluate a method to evolve a
biologically-inspired artificial neural network that learns from environment
reactions named Neuroevolution of Artificial General Intelligence (NAGI), a
framework for low-level AGI. This method allows the evolutionary
complexification of a randomly-initialized spiking neural network with adaptive
synapses, which controls agents instantiated in mutable environments. Such a
configuration allows us to benchmark the adaptivity and generality of the
controllers. The chosen tasks in the mutable environments are food foraging,
emulation of logic gates, and cart-pole balancing. The three tasks are
successfully solved with rather small network topologies and therefore it opens
up the possibility of experimenting with more complex tasks and scenarios where
curriculum learning is beneficial.",0.10007438,0.11914807,-0.030285284,B
9414,"While our investigation provides proof of structural complexities in ontologies,
further research is needed to qualify underlying design rationales.","shared substructures in many on-
tologies.","Supplemental Material Statement: Source code is available at
https://github.com/ckindermann/iswc-2022.",2022-07-28 14:33:00+00:00,A Survey of Syntactic Modelling Structures in Biomedical Ontologies,cs.AI,['cs.AI'],"[arxiv.Result.Author('Christian Kindermann'), arxiv.Result.Author('Martin G. Skj√¶veland')]","Despite the large-scale uptake of semantic technologies in the biomedical
domain, little is known about common modelling practices in published
ontologies. OWL ontologies are often published only in the crude form of sets
of axioms leaving the underlying design opaque. However, a principled and
systematic ontology development life cycle is likely to be reflected in
regularities of the ontology's emergent syntactic structure. To develop an
understanding of this emergent structure, we propose to reverse-engineer
ontologies taking a syntax-directed approach for identifying and analysing
regularities for axioms and sets of axioms. We survey BioPortal in terms of
syntactic modelling trends and common practices for OWL axioms and class
frames. Our findings suggest that biomedical ontologies only share simple
syntactic structures in which OWL constructors are not deeply nested or
combined in a complex manner. While such simple structures often account for
large proportions of axioms in a given ontology, many ontologies also contain
non-trivial amounts of more complex syntactic structures that are not common
across ontologies.",-0.3225385,0.09441863,-0.20275468,A
9636,"Moreover, recent Ô¨Ånalized projects such as APACHE [17]
                                        targeting the analysis of the interdependencies between the different KPAs by capturing the Pareto-front of ATM, still
                                        claims that further research is needed to uncover the inter-dependencies between the different KPA‚Äôs [18].","In [22] authors claim
                                        as a result of early SESAR projects such as STREAM [21] that the exact relationship among these KPAs is still not well
                                        understood and should be further studied in future research.","An important
                                        challenge that must be overcome to reach such a Pareto-front of ATM KPAs is the lack of an effective coordination
                                        mechanism (i.e., system behaviour) among ATM subsystems and corresponding Decision Support Systems (DSS).",2022-07-15 21:21:13+00:00,From Single Aircraft to Communities: A Neutral Interpretation of Air Traffic Complexity Dynamics,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Ralvi Isufaj'), arxiv.Result.Author('Marsel Omeri'), arxiv.Result.Author('Miquel Angel Piera'), arxiv.Result.Author('Jaume Saez Valls'), arxiv.Result.Author('Christian Eduardo Verdonk Gallego')]","Present air traffic complexity metrics are defined considering the interests
of different management layers of ATM. These layers have different objectives
which in practice compete to maximize their own goals, which leads to
fragmented decision making. This fragmentation together with competing KPAs
requires transparent and neutral air traffic information to pave the way for an
explainable set of actions. In this paper, we introduce the concept of single
aircraft complexity, to determine the contribution of each aircraft to the
overall complexity of air traffic. Furthermore, we describe a methodology
extending this concept to define complex communities, which are groups of
interdependent aircraft that contribute the majority of the complexity in a
certain airspace. In order to showcase the methodology, a tool that visualizes
different outputs of the algorithm is developed. Through use-cases based on
synthetic and real historical traffic, we first show that the algorithm can
serve to formalize controller decisions as well as guide controllers to better
decisions. Further, we investigate how the provided information can be used to
increase transparency of the decision makers towards different airspace users,
which serves also to increase fairness and equity. Lastly, a sensitivity
analysis is conducted in order to systematically analyse how each input affects
the methodology.",-0.119808055,0.28461766,0.07662299,B
9729,"Quantifying the creativ-
munity to further study adaptive, personalized co-creativity     ity support of digital tools through the creativity support in-
systems using CREATIVE-WAND.","We leave
these research questions as future work and invite the com-      Cherry, E.; and Latulipe, C. 2014.",dex.,2022-08-04 20:56:40+00:00,Creative Wand: A System to Study Effects of Communications in Co-Creative Settings,cs.AI,"['cs.AI', 'cs.HC']","[arxiv.Result.Author('Zhiyu Lin'), arxiv.Result.Author('Rohan Agarwal'), arxiv.Result.Author('Mark Riedl')]","Recent neural generation systems have demonstrated the potential for
procedurally generating game content, images, stories, and more. However, most
neural generation algorithms are ""uncontrolled"" in the sense that the user has
little say in creative decisions beyond the initial prompt specification.
Co-creative, mixed-initiative systems require user-centric means of influencing
the algorithm, especially when users are unlikely to have machine learning
expertise. The key to co-creative systems is the ability to communicate ideas
and intent from the user to the agent, as well as from the agent to the user.
Key questions in co-creative AI include: How can users express their creative
intentions? How can creative AI systems communicate their beliefs, explain
their moves, or instruct users to act on their behalf? When should creative AI
systems take initiative? The answer to such questions and more will enable us
to develop better co-creative systems that make humans more capable of
expressing their creative intents. We introduce CREATIVE-WAND, a customizable
framework for investigating co-creative mixed-initiative generation.
CREATIVE-WAND enables plug-and-play injection of generative models and
human-agent communication channels into a chat-based interface. It provides a
number of dimensions along which an AI generator and humans can communicate
during the co-creative process. We illustrate the CREATIVE-WAND framework by
using it to study one dimension of co-creative communication-global versus
local creative intent specification by the user-in the context of storytelling.",-0.12324178,-0.06462538,0.17931789,A
9837,"His formal logic provides a framework for
competent scientific reasoning and a foundation for further research.","In
the fourth century B.C., Aristotle pioneered data abstraction.","His difference between matter and
form is still one of the essential principles in computer science today.",2022-07-23 22:37:22+00:00,A Historical Interaction between Artificial Intelligence and Philosophy,cs.AI,['cs.AI'],[arxiv.Result.Author('Youheng Zhang')],"This paper reviews the historical development of AI and representative
philosophical thinking from the perspective of the research paradigm.
Additionally, it considers the methodology and applications of AI from a
philosophical perspective and anticipates its continued advancement. In the
history of AI, Symbolism and connectionism are the two main paradigms in AI
research. Symbolism holds that the world can be explained by symbols and dealt
with through precise, logical processes, but connectionism believes this
process should be implemented through artificial neural networks. Regardless of
how intelligent machines or programs should achieve their smart goals, the
historical development of AI demonstrates the best answer at this time. Still,
it is not the final answer of AI research.",-0.17992625,0.031930022,0.069578916,A
9905,"We expect the approach we have proposed
will generalize to additional vehicle types but this could also             [14] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez,
be veriÔ¨Åed by further study.","In ICLR,
distribution p(k1T |O1:T , c, e) that automatically adapts to the                 2022.
given vehicle type.",and Vladlen Koltun.,2022-08-09 18:29:00+00:00,Vehicle Type Specific Waypoint Generation,cs.AI,['cs.AI'],"[arxiv.Result.Author('Yunpeng Liu'), arxiv.Result.Author('Jonathan Wilder Lavington'), arxiv.Result.Author('Adam Scibior'), arxiv.Result.Author('Frank Wood')]","We develop a generic mechanism for generating vehicle-type specific sequences
of waypoints from a probabilistic foundation model of driving behavior. Many
foundation behavior models are trained on data that does not include vehicle
information, which limits their utility in downstream applications such as
planning. Our novel methodology conditionally specializes such a behavior
predictive model to a vehicle-type by utilizing byproducts of the reinforcement
learning algorithms used to produce vehicle specific controllers. We show how
to compose a vehicle specific value function estimate with a generic
probabilistic behavior model to generate vehicle-type specific waypoint
sequences that are more likely to be physically plausible then their
vehicle-agnostic counterparts.",-0.105567425,0.21328208,-0.116130784,B
9972,"Furthermore, from a theoretical and empirical perspective,
the generality and practicality of the BSAC deserve further study.","The results demonstrate the potential and signiÔ¨Åcance of the
proposed BSAC architecture by achieving more efÔ¨Åcient sample learning and higher performance
against the state-of-the-art DRL methods.","Especially, we will investigate the
variations in BSAC performance for different action decomposition and provide suitable guidelines
for creating a BSN for a given domain.",2022-08-11 20:36:23+00:00,BSAC: Bayesian Strategy Network Based Soft Actor-Critic in Deep Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Qin Yang'), arxiv.Result.Author('Ramviyas Parasuraman')]","Adopting reasonable strategies is challenging but crucial for an intelligent
agent with limited resources working in hazardous, unstructured, and dynamic
environments to improve the system utility, decrease the overall cost, and
increase mission success probability. Deep Reinforcement Learning (DRL) helps
organize agents' behaviors and actions based on their state and represents
complex strategies (composition of actions). This paper proposes a novel
hierarchical strategy decomposition approach based on Bayesian chaining to
separate an intricate policy into several simple sub-policies and organize
their relationships as Bayesian strategy networks (BSN). We integrate this
approach into the state-of-the-art DRL method, soft actor-critic (SAC), and
build the corresponding Bayesian soft actor-critic (BSAC) model by organizing
several sub-policies as a joint policy. We compare the proposed BSAC method
with the SAC and other state-of-the-art approaches such as TD3, DDPG, and PPO
on the standard continuous control benchmarks -- Hopper-v2, Walker2d-v2, and
Humanoid-v2 -- in MuJoCo with the OpenAI Gym environment. The results
demonstrate that the promising potential of the BSAC method significantly
improves training efficiency. The open sourced codes for BSAC can be accessed
at https://github.com/herolab-uga/bsac.",0.15751973,0.101757064,-0.12696853,C
10006,"Therefore, a Ô¨Çexible case set sample still has enormous
as an invariant factor of the encoding map, although expand-     potential for further research.",Substantial universal is already expressed   card.,"Fourth, transformer‚Äôs success-
ing it to handle concept hierarchies based on inheritance re-    ful visual object recognition and spoken language recogni-
lations will be necessary.",2022-08-13 08:00:42+00:00,Recognition of All Categories of Entities by AI,cs.AI,"['cs.AI', '68T01', 'I.2.0']","[arxiv.Result.Author('Hiroshi Yamakawa'), arxiv.Result.Author('Yutaka Matsuo')]","Human-level AI will have significant impacts on human society. However,
estimates for the realization time are debatable. To arrive at human-level AI,
artificial general intelligence (AGI), as opposed to AI systems that are
specialized for a specific task, was set as a technically meaningful long-term
goal. But now, propelled by advances in deep learning, that achievement is
getting much closer. Considering the recent technological developments, it
would be meaningful to discuss the completion date of human-level AI through
the ""comprehensive technology map approach,"" wherein we map human-level
capabilities at a reasonable granularity, identify the current range of
technology, and discuss the technical challenges in traversing unexplored areas
and predict when all of them will be overcome. This paper presents a new
argumentative option to view the ontological sextet, which encompasses entities
in a way that is consistent with our everyday intuition and scientific
practice, as a comprehensive technological map. Because most of the modeling of
the world, in terms of how to interpret it, by an intelligent subject is the
recognition of distal entities and the prediction of their temporal evolution,
being able to handle all distal entities is a reasonable goal. Based on the
findings of philosophy and engineering cognitive technology, we predict that in
the relatively near future, AI will be able to recognize various entities to
the same degree as humans.",0.07371816,-0.2651323,-0.23229374,C
10007,"Therefore, a Ô¨Çexible case set sample still has enormous
as an invariant factor of the encoding map, although expand-     potential for further research.",Substantial universal is already expressed   card.,"Fourth, transformer‚Äôs success-
ing it to handle concept hierarchies based on inheritance re-    ful visual object recognition and spoken language recogni-
lations will be necessary.",2022-08-13 08:00:42+00:00,Recognition of All Categories of Entities by AI,cs.AI,"['cs.AI', '68T01', 'I.2.0']","[arxiv.Result.Author('Hiroshi Yamakawa'), arxiv.Result.Author('Yutaka Matsuo')]","Human-level AI will have significant impacts on human society. However,
estimates for the realization time are debatable. To arrive at human-level AI,
artificial general intelligence (AGI), as opposed to AI systems that are
specialized for a specific task, was set as a technically meaningful long-term
goal. But now, propelled by advances in deep learning, that achievement is
getting much closer. Considering the recent technological developments, it
would be meaningful to discuss the completion date of human-level AI through
the ""comprehensive technology map approach,"" wherein we map human-level
capabilities at a reasonable granularity, identify the current range of
technology, and discuss the technical challenges in traversing unexplored areas
and predict when all of them will be overcome. This paper presents a new
argumentative option to view the ontological sextet, which encompasses entities
in a way that is consistent with our everyday intuition and scientific
practice, as a comprehensive technological map. Because most of the modeling of
the world, in terms of how to interpret it, by an intelligent subject is the
recognition of distal entities and the prediction of their temporal evolution,
being able to handle all distal entities is a reasonable goal. Based on the
findings of philosophy and engineering cognitive technology, we predict that in
the relatively near future, AI will be able to recognize various entities to
the same degree as humans.",0.07371816,-0.2651323,-0.23229374,C
10037,"Thus,
the formal justiÔ¨Åcation of those conditions would require further research in statistics.","However,
there is no general method for justifying such empirical conditions rigorously.","In the present paper, the empirical conditions on the unknown population remain
to be assumptions from the viewpoint of formal logic.",2022-08-15 08:42:24+00:00,Sound and Relatively Complete Belief Hoare Logic for Statistical Hypothesis Testing Programs,cs.AI,['cs.AI'],"[arxiv.Result.Author('Yusuke Kawamoto'), arxiv.Result.Author('Tetsuya Sato'), arxiv.Result.Author('Kohei Suenaga')]","We propose a new approach to formally describing the requirement for
statistical inference and checking whether a program uses the statistical
method appropriately. Specifically, we define belief Hoare logic (BHL) for
formalizing and reasoning about the statistical beliefs acquired via hypothesis
testing. This program logic is sound and relatively complete with respect to a
Kripke model for hypothesis tests. We demonstrate by examples that BHL is
useful for reasoning about practical issues in hypothesis testing. In our
framework, we clarify the importance of prior beliefs in acquiring statistical
beliefs through hypothesis testing, and discuss the whole picture of the
justification of statistical inference inside and outside the program logic.",-0.39516228,0.18212445,0.06460543,B
10044,"Brains main objective, apart from central         of different sciences, where further research, namely in the
control of the body, is the modelling and subsequent pre-         Ô¨Åeld(s) of Cognitive Computational Neuroscience and AI, is
diction of immediate reality so as to allow for goal forma-       necessary.","Having limited resources
yields suboptimal solutions to computational problems in          Regardless of corrective pathways for this hereditary disease
the brain - this has been widely demonstrated by Daniel           we all suffer from, C-CB as a concept exists in the frontier
Kahneman et al.","To better understand human cognitive faults in a
tion, hypothesizing the set of possible solutions to reach said   predictive fashion, new experiments that enable modelling
goal, the search for these and their execution.",2022-08-15 12:33:29+00:00,"C-Causal Blindness An experimental computational framework on the isomorphic relationship between biological computation, artificial computation, and logic using weighted hidden Markov models",cs.AI,"['cs.AI', 'math.LO']",[arxiv.Result.Author('Gon√ßalo Hora de Carvalho')],"This text concerns a particular flavor of cognitive blindness referred to as
C-Causal Blindness, or C-CB. A blindness where the policy to obtain the
objective leads to the state to be avoided. A literal example of C-CB would be
Kurt G\""odel's decision to starve for ""fear of being poisoned"" - take this to
be premise A. The objective being ""to avoid being poisoned (so as to not die)"":
C, the plan or policy being ""don't eat"": B, and the actual outcome having been
""dying"": not C - the state that G\""odel wanted to avoid to begin with. Like
many, G\""odel pursued a strategy that caused the result he wanted to avoid. An
experimental computational framework is proposed to show the isomorphic
relationship between C-CB in brain computations, logic, and computer
computations using hidden Markov models.",0.09410273,-0.06378752,0.14353526,C
10045,"In: An-
ists, it does so in the frontier of different sciences, where              nals of the New York Academy of Sciences 985.1
further research, namely in the Ô¨Åelds of Cognitive Compu-                  (2003), pp.","ease we all might suffer from, C-CB as a concept, if it ex-                ‚ÄúRole of the Amygdala in Decision-Making‚Äù.",356‚Äì369.,2022-08-15 12:33:29+00:00,"C-Causal Blindness An experimental computational framework on the isomorphic relationship between biological computation, artificial computation, and logic using weighted hidden Markov models",cs.AI,"['cs.AI', 'math.LO']",[arxiv.Result.Author('Gon√ßalo Hora de Carvalho')],"This text is concerned with a hypothetical flavour of cognitive blindness
referred to in this paper as \textit{C-Causal Blindness} or C-CB. A cognitive
blindness where the policy to obtain the objective leads to the state to be
avoided. A literal example of C-CB would be \textit{Kurt G\""odel's} decision to
starve for \textit{""fear of being poisoned""} - take this to be premise
\textbf{A}. The objective being \textit{""to avoid being poisoned (so as to not
die)""}: \textbf{C}, the plan or policy being \textit{""don't eat""}: \textbf{B},
and the actual outcome having been \textit{""dying""}: $\lnot$\textbf{C} - the
state that G\""odel wanted to avoid to begin with. Like many, G\""odel pursued a
strategy that caused the result he wanted to avoid. An experimental
computational framework is proposed to show the isomorphic relationship between
C-CB in brain computations, logic, and computer computations using hidden
Markov models.",-0.21722364,-0.07534691,0.24628958,A
10108,"Implementation of EmoTER will               High-quality explanations should be informative, i.e., containing
                                                                                                                                          be released as an open-source toolkit to support further research.","models in terms of text quality, explainability, and consideration for
                                                                                                                                          fairness to emotion distribution.",factual information for users to understand.,2022-08-17 01:49:14+00:00,"Towards Generating Robust, Fair, and Emotion-Aware Explanations for Recommender Systems",cs.AI,['cs.AI'],"[arxiv.Result.Author('Bingbing Wen'), arxiv.Result.Author('Yunhe Feng'), arxiv.Result.Author('Yongfeng Zhang'), arxiv.Result.Author('Chirag Shah')]","As recommender systems become increasingly sophisticated and complex, they
often suffer from lack of fairness and transparency. Providing robust and
unbiased explanations for recommendations has been drawing more and more
attention as it can help address these issues and improve trustworthiness and
informativeness of recommender systems. However, despite the fact that such
explanations are generated for humans who respond more strongly to messages
with appropriate emotions, there is a lack of consideration for emotions when
generating explanations for recommendations. Current explanation generation
models are found to exaggerate certain emotions without accurately capturing
the underlying tone or the meaning. In this paper, we propose a novel method
based on a multi-head transformer, called Emotion-aware Transformer for
Explainable Recommendation (EmoTER), to generate more robust, fair, and
emotion-enhanced explanations. To measure the linguistic quality and emotion
fairness of the generated explanations, we adopt both automatic text metrics
and human perceptions for evaluation. Experiments on three widely-used
benchmark datasets with multiple evaluation metrics demonstrate that EmoTER
consistently outperforms the existing state-of-the-art explanation generation
models in terms of text quality, explainability, and consideration for fairness
to emotion distribution. Implementation of EmoTER will be released as an
open-source toolkit to support further research.",-0.22150256,-0.32773793,0.07450065,A
10213,"ConceptNet [38] allows the ex-
pression of negative statements using 6 pre-defined negative rela-       We release a large dataset as a resource for further research: Up
tions.","7 RESOURCES
Negation in knowledge bases.",We use these statements in our recall evaluation.,2022-08-19 12:14:02+00:00,UnCommonSense: Informative Negative Knowledge about Everyday,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Author('Hiba Arnaout'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum'), arxiv.Result.Author('Jeff Z. Pan')]","Commonsense knowledge about everyday concepts is an important asset for AI
applications, such as question answering and chatbots. Recently, we have seen
an increasing interest in the construction of structured commonsense knowledge
bases (CSKBs). An important part of human commonsense is about properties that
do not apply to concepts, yet existing CSKBs only store positive statements.
Moreover, since CSKBs operate under the open-world assumption, absent
statements are considered to have unknown truth rather than being invalid. This
paper presents the UNCOMMONSENSE framework for materializing informative
negative commonsense statements. Given a target concept, comparable concepts
are identified in the CSKB, for which a local closed-world assumption is
postulated. This way, positive statements about comparable concepts that are
absent for the target concept become seeds for negative statement candidates.
The large set of candidates is then scrutinized, pruned and ranked by
informativeness. Intrinsic and extrinsic evaluations show that our method
significantly outperforms the state-of-the-art. A large dataset of informative
negations is released as a resource for future research.",-0.115229055,-0.3395294,-0.14917001,A
10214,"ConceptNet [38] allows the ex-
pression of negative statements using 6 pre-defined negative rela-       We release a large dataset as a resource for further research: Up
tions.","7 RESOURCES
Negation in knowledge bases.",We use these statements in our recall evaluation.,2022-08-19 12:14:02+00:00,UnCommonSense: Informative Negative Knowledge about Everyday Concepts,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Author('Hiba Arnaout'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum'), arxiv.Result.Author('Jeff Z. Pan')]","Commonsense knowledge about everyday concepts is an important asset for AI
applications, such as question answering and chatbots. Recently, we have seen
an increasing interest in the construction of structured commonsense knowledge
bases (CSKBs). An important part of human commonsense is about properties that
do not apply to concepts, yet existing CSKBs only store positive statements.
Moreover, since CSKBs operate under the open-world assumption, absent
statements are considered to have unknown truth rather than being invalid. This
paper presents the UNCOMMONSENSE framework for materializing informative
negative commonsense statements. Given a target concept, comparable concepts
are identified in the CSKB, for which a local closed-world assumption is
postulated. This way, positive statements about comparable concepts that are
absent for the target concept become seeds for negative statement candidates.
The large set of candidates is then scrutinized, pruned and ranked by
informativeness. Intrinsic and extrinsic evaluations show that our method
significantly outperforms the state-of-the-art. A large dataset of informative
negations is released as a resource for future research.",-0.115229055,-0.3395294,-0.14917001,A
10215,"ConceptNet [38] allows the ex-              We release a large dataset as a resource for further research: Up
pression of negative statements using 6 pre-defined negative rela-       to7 top-1k negations for all primary concepts from Ascent [24],
tions.",Negation in knowledge bases.,We use these statements in our recall evaluation.,2022-08-19 12:14:02+00:00,UnCommonSense: Informative Negative Knowledge about Everyday Concepts,cs.AI,"['cs.AI', 'cs.IR']","[arxiv.Result.Author('Hiba Arnaout'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum'), arxiv.Result.Author('Jeff Z. Pan')]","Commonsense knowledge about everyday concepts is an important asset for AI
applications, such as question answering and chatbots. Recently, we have seen
an increasing interest in the construction of structured commonsense knowledge
bases (CSKBs). An important part of human commonsense is about properties that
do not apply to concepts, yet existing CSKBs only store positive statements.
Moreover, since CSKBs operate under the open-world assumption, absent
statements are considered to have unknown truth rather than being invalid. This
paper presents the UNCOMMONSENSE framework for materializing informative
negative commonsense statements. Given a target concept, comparable concepts
are identified in the CSKB, for which a local closed-world assumption is
postulated. This way, positive statements about comparable concepts that are
absent for the target concept become seeds for negative statement candidates.
The large set of candidates is then scrutinized, pruned and ranked by
informativeness. Intrinsic and extrinsic evaluations show that our method
significantly outperforms the state-of-the-art. A large dataset of informative
negations is released as a resource for future research.",-0.07020181,-0.34084836,-0.20938203,A
10219,"This highlights the need for further research and thought into the deÔ¨Ånition of positive dependence in a

                                                               9
                                                                                                          5 DISCUSSION

QPN to Ô¨Ånd a deÔ¨Ånition that matches the three intuitive properties.","It could even
lead to incorrect inferences because the elicited information might not match the mathematical deÔ¨Ånition
of the QPN.","Whether such a deÔ¨Ånition of positive
dependence even exists is still an open question.",2022-08-19 13:53:04+00:00,Positive dependence in qualitative probabilistic networks,cs.AI,"['cs.AI', 'math.ST', 'stat.ME', 'stat.TH']",[arxiv.Result.Author('Jack Storror Carter')],"Qualitative probabilistic networks (QPNs) combine the conditional
independence assumptions of Bayesian networks with the `qualitative' properties
of positive and negative dependence. They attempt to formalise various
intuitive properties of positive dependence to allow inferences over a large
network of variables. However, we highlight a key mistake in the QPN literature
which means that most inferences made by a QPN are not mathematically true. We
also discuss how to redefine a QPN in order to fix this issue.",-0.21784306,0.10024667,0.1037436,B
10353,"Better under-
standing of advanced forms of all of these algorithms are important areas for further research.","Perhaps the best understood parts of the base agent are the
learning algorithms for the value functions and reactive policies, but even here there is room
for improvement in their advanced forms, such as those involving average reward, oÔ¨Ä-policy
learning, and continual non-linear learning.1 Finally, the learning of the world model, given
the options, is conceptually clear but remains challenging and underexplored.",Some of these are discussed further in the next section.,2022-08-23 20:02:09+00:00,The Alberta Plan for AI Research,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Richard S. Sutton'), arxiv.Result.Author('Michael H. Bowling'), arxiv.Result.Author('Patrick M. Pilarski')]","Herein we describe our approach to artificial intelligence research, which we
call the Alberta Plan. The Alberta Plan is pursued within our research groups
in Alberta and by others who are like minded throughout the world. We welcome
all who would join us in this pursuit.",0.3435548,0.15261403,0.27174878,C
10354,"Better under-
standing of advanced forms of all of these algorithms are important areas for further research.","Perhaps the best understood parts of the base agent are the
learning algorithms for the value functions and reactive policies, but even here there is room
for improvement in their advanced forms, such as those involving average reward, oÔ¨Ä-policy
learning, and continual non-linear learning.1 Finally, the learning of the world model, given
the options, is conceptually clear but remains challenging and underexplored.",Some of these are discussed further in the next section.,2022-08-23 20:02:09+00:00,The Alberta Plan for AI Research,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Richard S. Sutton'), arxiv.Result.Author('Michael Bowling'), arxiv.Result.Author('Patrick M. Pilarski')]","Herein we describe our approach to artificial intelligence research, which we
call the Alberta Plan. The Alberta Plan is pursued within our research groups
in Alberta and by others who are like minded throughout the world. We welcome
all who would join us in this pursuit.",0.3435548,0.15261403,0.27174878,C
10372,"8 Conclusion

This thesis raises a list of further research questions, which is also reÔ¨Çected by the increasing interest of
treewidth2.","Our observations thereby conÔ¨Årm the study of the classiÔ¨Åcation
of Section 6, where problems are categorized according to their runtime dependence on the treewidth.","In the thesis we establish DG reductions, which serve as a key for proving both upper and

    2‚ÄúTreewidth‚Äù yields more than 22,000 results on Google Scholar (queried on March 18th, 2022).",2022-08-24 07:43:58+00:00,Advanced Tools and Methods for Treewidth-Based Problem Solving -- Extended Abstract,cs.AI,"['cs.AI', 'cs.CC', 'cs.DB', 'cs.DS', 'cs.LO']",[arxiv.Result.Author('Markus Hecher')],"Computer programs, so-called solvers, for solving the well-known Boolean
satisfiability problem (Sat) have been improving for decades. Among the
reasons, why these solvers are so fast, is the implicit usage of the formula's
structural properties during solving. One of such structural indicators is the
so-called treewidth, which tries to measure how close a formula instance is to
being easy (tree-like). This work focuses on logic-based problems and
treewidth-based methods and tools for solving them. Many of these problems are
also relevant for knowledge representation and reasoning (KR) as well as
artificial intelligence (AI) in general. We present a new type of problem
reduction, which is referred to by decomposition-guided (DG). This reduction
type forms the basis to solve a problem for quantified Boolean formulas (QBFs)
of bounded treewidth that has been open since 2004. The solution of this
problem then gives rise to a new methodology for proving precise lower bounds
for a range of further formalisms in logic, KR, and AI. Despite the established
lower bounds, we implement an algorithm for solving extensions of Sat
efficiently, by directly using treewidth. Our implementation is based on
finding abstractions of instances, which are then incrementally refined in the
process. Thereby, our observations confirm that treewidth is an important
measure that should be considered in the design of modern solvers.",-0.15950353,0.23571141,-0.2958748,B
10389,"The promising results provided by our architecture opens up multiple directions for further research that relax the
limitations of our current work and build on other work in our group on knowledge representation, reasoning, and
learning.","We demonstrated our architecture‚Äôs capabilities in the benchmark fort attack domain, In particular, our ad
hoc guard agent adapts to previously unseen teammates and opponents, rapidly revises the learned models, provides
substantially better performance than baselines that include a state of the art data-driven method, and supports trans-
parency in its decision making.","For example, the experiments reported in this paper focused on the FA domain with only one ad hoc (guard)
agent in most of the experiments.",2022-08-24 13:57:33+00:00,Toward a Reasoning and Learning Architecture for Ad Hoc Teamwork,cs.AI,"['cs.AI', 'cs.MA']","[arxiv.Result.Author('Hasra Dodampegama'), arxiv.Result.Author('Mohan Sridharan')]","We present an architecture for ad hoc teamwork, which refers to collaboration
in a team of agents without prior coordination. State of the art methods for
this problem often include a data-driven component that uses a long history of
prior observations to model the behaviour of other agents (or agent types) and
to determine the ad hoc agent's behavior. In many practical domains, it is
challenging to find large training datasets, and necessary to understand and
incrementally extend the existing models to account for changes in team
composition or domain attributes. Our architecture combines the principles of
knowledge-based and data-driven reasoning and learning. Specifically, we enable
an ad hoc agent to perform non-monotonic logical reasoning with prior
commonsense domain knowledge and incrementally-updated simple predictive models
of other agents' behaviour. We use the benchmark simulated multiagent
collaboration domain Fort Attack to demonstrate that our architecture supports
adaptation to unforeseen changes, incremental learning and revision of models
of other agents' behaviour from limited samples, transparency in the ad hoc
agent's decision making, and better performance than a data-driven baseline.",0.2287556,-0.051034257,0.10325798,C
10390,"The promising results provided by our architecture opens
 ‚Ä¢ Human: ‚ÄùWhy did you move to (3,14) in step 1?‚Äù                up multiple directions for further research that relax the lim-
                                                                 itations of our current work.",shows a relevant subset of its actions and the domain.,"The experiments reported in
 ‚Ä¢ Ad hoc Agent: ‚ÄùBecause attacker1 was not in range             this paper focused on the FA domain with only one ad hoc
   and I had to move to (4,14)‚Äù.",2022-08-24 13:57:33+00:00,Knowledge-based and Data-driven Reasoning and Learning for Ad Hoc Teamwork,cs.AI,"['cs.AI', 'cs.MA']","[arxiv.Result.Author('Hasra Dodampegama'), arxiv.Result.Author('Mohan Sridharan')]","We present an architecture for ad hoc teamwork, which refers to collaboration
in a team of agents without prior coordination. State of the art methods for
this problem often include a data-driven component that uses a long history of
prior observations to model the behaviour of other agents (or agent types) and
to determine the ad hoc agent's behaviour. In many practical domains, it is
challenging to find large training datasets, and necessary to understand and
incrementally extend the existing models to account for changes in team
composition or domain attributes. Our architecture combines the principles of
knowledge-based and data-driven reasoning and learning. Specifically, we enable
an ad hoc agent to perform non-monotonic logical reasoning with prior
commonsense domain knowledge and incrementally-updated simple predictive models
of other agents' behaviour. We use the benchmark simulated multi-agent
collaboration domain Fort Attack to demonstrate that our architecture supports
adaptation to unforeseen changes, incremental learning and revision of models
of other agents' behaviour from limited samples, transparency in the ad hoc
agent's decision making, and better performance than a data-driven baseline.",0.059076097,0.021348003,0.1893179,C
10465,We further study the performance over time by considering the evolution of average and individual sellers‚Äô prices.,Total rewards for sellers vs. network size.,"We
consider a smaller system of 5 sellers and 5 buyers for ease of representation of the results.",2022-08-26 16:45:40+00:00,Prospect Theory-inspired Automated P2P Energy Trading with Q-learning-based Dynamic Pricing,cs.AI,"['cs.AI', 'cs.LG', 'cs.NE']","[arxiv.Result.Author('Ashutosh Timilsina'), arxiv.Result.Author('Simone Silvestri')]","The widespread adoption of distributed energy resources, and the advent of
smart grid technologies, have allowed traditionally passive power system users
to become actively involved in energy trading. Recognizing the fact that the
traditional centralized grid-driven energy markets offer minimal profitability
to these users, recent research has shifted focus towards decentralized
peer-to-peer (P2P) energy markets. In these markets, users trade energy with
each other, with higher benefits than buying or selling to the grid. However,
most researches in P2P energy trading largely overlook the user perception in
the trading process, assuming constant availability, participation, and full
compliance. As a result, these approaches may result in negative attitudes and
reduced engagement over time. In this paper, we design an automated P2P energy
market that takes user perception into account. We employ prospect theory to
model the user perception and formulate an optimization framework to maximize
the buyer's perception while matching demand and production. Given the
non-linear and non-convex nature of the optimization problem, we propose
Differential Evolution-based Algorithm for Trading Energy called DEbATE.
Additionally, we introduce a risk-sensitive Q-learning algorithm, named Pricing
mechanism with Q-learning and Risk-sensitivity (PQR), which learns the optimal
price for sellers considering their perceived utility. Results based on real
traces of energy consumption and production, as well as realistic prospect
theory functions, show that our approach achieves a 26% higher perceived value
for buyers and generates 7% more reward for sellers, compared to a recent state
of the art approach.",-0.15489992,0.2969088,0.06780565,B
10672,"We believe that our paper will spur
cluding TabNet (Arik and PÔ¨Åster, 2021), TAPAS              further research on studying G-PlanET and contin-
(Herzig et al., 2020), TaBERT (Yin et al., 2020)           ual exploration for connecting LMs and embodied
and TAPEX (Liu et al., 2022b).","For the Ô¨Årst line of work, there is rich literature  for verifying their effectiveness and obtaining non-
focusing on modeling tabular representations, in-          trivial Ô¨Åndings.",We have explored            tasks in realistic environments.,2022-08-29 16:37:18+00:00,On Grounded Planning for Embodied Tasks with Language Models,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Bill Yuchen Lin'), arxiv.Result.Author('Chengsong Huang'), arxiv.Result.Author('Qian Liu'), arxiv.Result.Author('Wenda Gu'), arxiv.Result.Author('Sam Sommerer'), arxiv.Result.Author('Xiang Ren')]","Language models (LMs) are shown to have commonsense knowledge of the physical
world, which is fundamental for completing tasks in everyday situations.
However, it is still an open question whether LMs have the ability to generate
grounded, executable plans for embodied tasks. It is very challenging because
LMs do not have an ""eye"" or ""hand"" to perceive the realistic environment. In
this work, we show the first study on this important research question. We
first present a novel problem formulation named G-PlanET, which takes as input
a high-level goal and a table of objects in a specific environment. The
expected output is a plan consisting of step-by-step instructions for agents to
execute. To enable the study of this problem, we establish an evaluation
protocol and devise a dedicated metric for assessing the quality of plans. In
our extensive experiments, we show that adding flattened tables for encoding
environments and using an iterative decoding strategy can both improve the LMs'
ability for grounded planning. Our analysis of the results also leads to
interesting non-trivial findings.",0.110779695,0.004278456,-0.03859359,C
10747,"action
20                                                        0.5

                                                          0

0

    0  1  2  3 ¬∑106                                            0  1  2  3 ¬∑106

          Number of environment steps

TarMAC    TarMAC-BW LAURELoÔ¨Ä LAURELoÔ¨Ä-BW

Figure 5: Communication adapted to limited bandwidth

Adapting to Complicated Wireless Environment We further study the eÔ¨Äect of
bandwidth limit on agents‚Äô communication behaviors.",comm.,"In Figure 5, we consider two wireless
environments: one with more bandwidth resources and the other with fewer bandwidth
resources (achieved by reducing the number of time slots in slotted p-CSMA (Gai et al.,
2011)).",2022-09-02 22:18:43+00:00,Learning Practical Communication Strategies in Cooperative Multi-Agent Reinforcement Learning,cs.AI,"['cs.AI', 'cs.LG', 'cs.MA']","[arxiv.Result.Author('Diyi Hu'), arxiv.Result.Author('Chi Zhang'), arxiv.Result.Author('Viktor Prasanna'), arxiv.Result.Author('Bhaskar Krishnamachari')]","In Multi-Agent Reinforcement Learning, communication is critical to encourage
cooperation among agents. Communication in realistic wireless networks can be
highly unreliable due to network conditions varying with agents' mobility, and
stochasticity in the transmission process. We propose a framework to learn
practical communication strategies by addressing three fundamental questions:
(1) When: Agents learn the timing of communication based on not only message
importance but also wireless channel conditions. (2) What: Agents augment
message contents with wireless network measurements to better select the game
and communication actions. (3) How: Agents use a novel neural message encoder
to preserve all information from received messages, regardless of the number
and order of messages. Simulating standard benchmarks under realistic wireless
network settings, we show significant improvements in game performance,
convergence speed and communication efficiency compared with state-of-the-art.",-0.05260688,0.3378133,0.21300822,B
10771,"However, almost of all these studies focus on text,
images or speech modes rather than multimodal time-series which is a critical
ingredient across many domains, so how to eÔ¨Äectively process multimodal data
still need further study.","Neural Networks
is expected to tackle the multimodal fusion problem [18] and has been used
extensively to fuse information for text, image and audio [14, 15], gesture recog-
nition [17], and video or image description generation [21, 27], since the earliest
investigation of AVSR [20].","Many methods have been launched to process simple
single mode time-series data [1, 29], which have achieved the best result in their
respective Ô¨Åeld.",2022-09-05 02:27:12+00:00,Features Fusion Framework for Multimodal Irregular Time-series Events,cs.AI,['cs.AI'],"[arxiv.Result.Author('Peiwang Tang'), arxiv.Result.Author('Xianchao Zhang')]","Some data from multiple sources can be modeled as multimodal time-series
events which have different sampling frequencies, data compositions, temporal
relations and characteristics. Different types of events have complex nonlinear
relationships, and the time of each event is irregular. Neither the classical
Recurrent Neural Network (RNN) model nor the current state-of-the-art
Transformer model can deal with these features well. In this paper, a features
fusion framework for multimodal irregular time-series events is proposed based
on the Long Short-Term Memory networks (LSTM). Firstly, the complex features
are extracted according to the irregular patterns of different events.
Secondly, the nonlinear correlation and complex temporal dependencies
relationship between complex features are captured and fused into a tensor.
Finally, a feature gate are used to control the access frequency of different
tensors. Extensive experiments on MIMIC-III dataset demonstrate that the
proposed framework significantly outperforms to the existing methods in terms
of AUC (the area under Receiver Operating Characteristic curve) and AP (Average
Precision).",0.17701477,-0.18225904,-0.20904663,C
10829,"These issues can
   potentially be addressed with further research in the domain.","‚ñ™ Several technical challenges remain, for example, the large computational cost of multimodal
   learning, sample sparsity, instability of adversarial training, sparsity of the artist‚Äôs judgements,
   ambiguity of the reward function learning, error accumulation and propagation of long-
   sequence content generation, and uncontrollability of local object motion.","39

                                         Building Platform Technologies for Symbiotic Creativity in Hong Kong

8 AUG 2022
                                                                                                                     REPORT

System Function

The overall system operation is illustrated in Fig.",2022-08-18 15:12:02+00:00,Pathway to Future Symbiotic Creativity,cs.AI,"['cs.AI', 'cs.HC']","[arxiv.Result.Author('Yike Guo'), arxiv.Result.Author('Qifeng Liu'), arxiv.Result.Author('Jie Chen'), arxiv.Result.Author('Wei Xue'), arxiv.Result.Author('Henrik Jensen'), arxiv.Result.Author('Fernando Rosas'), arxiv.Result.Author('Jeffrey Shaw'), arxiv.Result.Author('Xing Wu'), arxiv.Result.Author('Jiji Zhang'), arxiv.Result.Author('Jianliang Xu')]","This report presents a comprehensive view of our vision on the development
path of the human-machine symbiotic art creation. We propose a classification
of the creative system with a hierarchy of 5 classes, showing the pathway of
creativity evolving from a mimic-human artist (Turing Artists) to a Machine
artist in its own right. We begin with an overview of the limitations of the
Turing Artists then focus on the top two-level systems, Machine Artists,
emphasizing machine-human communication in art creation. In art creation, it is
necessary for machines to understand humans' mental states, including desires,
appreciation, and emotions, humans also need to understand machines' creative
capabilities and limitations. The rapid development of immersive environment
and further evolution into the new concept of metaverse enable symbiotic art
creation through unprecedented flexibility of bi-directional communication
between artists and art manifestation environments. By examining the latest
sensor and XR technologies, we illustrate the novel way for art data collection
to constitute the base of a new form of human-machine bidirectional
communication and understanding in art creation. Based on such communication
and understanding mechanisms, we propose a novel framework for building future
Machine artists, which comes with the philosophy that a human-compatible AI
system should be based on the ""human-in-the-loop"" principle rather than the
traditional ""end-to-end"" dogma. By proposing a new form of inverse
reinforcement learning model, we outline the platform design of machine
artists, demonstrate its functions and showcase some examples of technologies
we have developed. We also provide a systematic exposition of the ecosystem for
AI-based symbiotic art form and community with an economic model built on NFT
technology. Ethical issues for the development of machine artists are also
discussed.",0.30488092,-0.16232142,0.07855262,C
10920,"We believe
further research is needed to investigate XAI in the presence of concerns about
model privacy, adversarial attacks, and gaming by agents.","For reasons such as these, firms may be less
inclined to offer XAI in order to protect the privacy of their model.","32
9.",2022-09-07 23:36:11+00:00,Sell Me the Blackbox! Why eXplainable Artificial Intelligence (XAI) May Hurt Customers,cs.AI,['cs.AI'],"[arxiv.Result.Author('Behnam Mohammadi'), arxiv.Result.Author('Nikhil Malik'), arxiv.Result.Author('Tim Derdenger'), arxiv.Result.Author('Kannan Srinivasan')]","Recent AI algorithms are blackbox models whose decisions are difficult to
interpret. eXplainable AI (XAI) seeks to address lack of AI interpretability
and trust by explaining to customers their AI decision, e.g., decision to
reject a loan application. The common wisdom is that regulating AI by mandating
fully transparent XAI leads to greater social welfare. This paper challenges
this notion through a game theoretic model for a policy-maker who maximizes
social welfare, firms in a duopoly competition that maximize profits, and
heterogenous consumers. The results show that XAI regulation may be redundant.
In fact, mandating fully transparent XAI may make firms and customers worse
off. This reveals a trade-off between maximizing welfare and receiving
explainable AI outputs. We also discuss managerial implications for
policy-maker and firms.",-0.06482828,-0.044215262,0.2732705,A
10921,"We believe
further research is needed to investigate XAI in the presence of concerns about
model privacy, adversarial attacks, and gaming by agents.","For reasons such as these, firms may be less
inclined to offer XAI in order to protect the privacy of their model.",5.,2022-09-07 23:36:11+00:00,Sell Me the Blackbox! Regulating eXplainable Artificial Intelligence (XAI) May Harm Consumers,cs.AI,['cs.AI'],"[arxiv.Result.Author('Behnam Mohammadi'), arxiv.Result.Author('Nikhil Malik'), arxiv.Result.Author('Tim Derdenger'), arxiv.Result.Author('Kannan Srinivasan')]","Recent AI algorithms are blackbox models whose decisions are difficult to
interpret. eXplainable AI (XAI) seeks to address lack of AI interpretability
and trust by explaining to customers their AI decision, e.g., decision to
reject a loan application. The common wisdom is that regulating AI by mandating
fully transparent XAI leads to greater social welfare. This paper challenges
this notion through a game theoretic model for a policy-maker who maximizes
social welfare, firms in a duopoly competition that maximize profits, and
heterogenous consumers. The results show that XAI regulation may be redundant.
In fact, mandating fully transparent XAI may make firms and customers worse
off. This reveals a trade-off between maximizing welfare and receiving
explainable AI outputs. We also discuss managerial implications for
policy-maker and firms.",-0.07367458,-0.04339843,0.29164514,A
10928,"While some
methods are modular to the speciÔ¨Åc conformal algorithm (such as choosing a scaled nonconformity
score), further research is needed for adaptability in the time series setting.",The adaptability techniques introduced above are developed for the exchangeable setting.,"Formalization of the
adaptive property and its implications are further discussed in section 4.2.",2022-09-08 06:08:48+00:00,Conformal Methods for Quantifying Uncertainty in Spatiotemporal Data: A Survey,cs.AI,['cs.AI'],[arxiv.Result.Author('Sophia Sun')],"Machine learning methods are increasingly widely used in high-risk settings
such as healthcare, transportation, and finance. In these settings, it is
important that a model produces calibrated uncertainty to reflect its own
confidence and avoid failures. In this paper we survey recent works on
uncertainty quantification (UQ) for deep learning, in particular
distribution-free Conformal Prediction method for its mathematical properties
and wide applicability. We will cover the theoretical guarantees of conformal
methods, introduce techniques that improve calibration and efficiency for UQ in
the context of spatiotemporal data, and discuss the role of UQ in the context
of safe decision making.",-0.14967516,0.3178898,-0.1357054,B
10983,"At the same time, due to the large action      task labels, as well as how to better connect self-supervised
pool, it may not be possible to pick an action that can be          learning with robot control, we will do further research in the
performed correctly for a long time.","How to
constraints, the prerequisites required for the action to perform   combine discontinuous exploration data and produce related
may not be satisÔ¨Åed.","Therefore, in order to         future.",2022-09-09 03:02:49+00:00,A Memory-Related Multi-Task Method Based on Task-Agnostic Exploration,cs.AI,['cs.AI'],"[arxiv.Result.Author('Xianqi Zhang'), arxiv.Result.Author('Xingtao Wang'), arxiv.Result.Author('Xu Liu'), arxiv.Result.Author('Xiaopeng Fan'), arxiv.Result.Author('Debin Zhao')]","We pose a new question: Can agents learn how to combine actions from previous
tasks to complete new tasks, just as humans? In contrast to imitation learning,
there is no expert data, only the data collected through environmental
exploration. Compared with offline reinforcement learning, the problem of data
distribution shift is more serious. Since the action sequence to solve the new
task may be the combination of trajectory segments of multiple training tasks,
in other words, the test task and the solving strategy do not exist directly in
the training data. This makes the problem more difficult. We propose a
Memory-related Multi-task Method (M3) to address this problem. The method
consists of three stages. First, task-agnostic exploration is carried out to
collect data. Different from previous methods, we organize the exploration data
into a knowledge graph. We design a model based on the exploration data to
extract action effect features and save them in memory, while an action
predictive model is trained. Secondly, for a new task, the action effect
features stored in memory are used to generate candidate actions by a feature
decomposition-based approach. Finally, a multi-scale candidate action pool and
the action predictive model are fused to generate a strategy to complete the
task. Experimental results show that the performance of our proposed method is
significantly improved compared with the baseline.",0.3437373,0.11669737,0.14542706,C
10984,The scatter part represents        further research is required.,"Although employing the
part of the Fig.7, only partial actions (less than the number         multi-scale candidate action pool can alleviate this problem,
of acts in the pool) are executed.",all items in the pool are used.,2022-09-09 03:02:49+00:00,A Memory-Related Multi-Task Method Based on Task-Agnostic Exploration,cs.AI,['cs.AI'],"[arxiv.Result.Author('Xianqi Zhang'), arxiv.Result.Author('Xingtao Wang'), arxiv.Result.Author('Xu Liu'), arxiv.Result.Author('Xiaopeng Fan'), arxiv.Result.Author('Debin Zhao')]","We pose a new question: Can agents learn how to combine actions from previous
tasks to complete new tasks, just as humans? In contrast to imitation learning,
there is no expert data, only the data collected through environmental
exploration. Compared with offline reinforcement learning, the problem of data
distribution shift is more serious. Since the action sequence to solve the new
task may be the combination of trajectory segments of multiple training tasks,
in other words, the test task and the solving strategy do not exist directly in
the training data. This makes the problem more difficult. We propose a
Memory-related Multi-task Method (M3) to address this problem. The method
consists of three stages. First, task-agnostic exploration is carried out to
collect data. Different from previous methods, we organize the exploration data
into a knowledge graph. We design a model based on the exploration data to
extract action effect features and save them in memory, while an action
predictive model is trained. Secondly, for a new task, the action effect
features stored in memory are used to generate candidate actions by a feature
decomposition-based approach. Finally, a multi-scale candidate action pool and
the action predictive model are fused to generate a strategy to complete the
task. Experimental results show that the performance of our proposed method is
significantly improved compared with the baseline.",0.07350083,0.17577934,-0.03634084,B
10985,"How to generate plans with          ent from previous methods, we organize the exploration data
less redundancy more efÔ¨Åciently requires further research.","Differ-
still a time-consuming problem.",2)       into a knowledge graph.,2022-09-09 03:02:49+00:00,A Memory-Related Multi-Task Method Based on Task-Agnostic Exploration,cs.AI,['cs.AI'],"[arxiv.Result.Author('Xianqi Zhang'), arxiv.Result.Author('Xingtao Wang'), arxiv.Result.Author('Xu Liu'), arxiv.Result.Author('Xiaopeng Fan'), arxiv.Result.Author('Debin Zhao')]","We pose a new question: Can agents learn how to combine actions from previous
tasks to complete new tasks, just as humans? In contrast to imitation learning,
there is no expert data, only the data collected through environmental
exploration. Compared with offline reinforcement learning, the problem of data
distribution shift is more serious. Since the action sequence to solve the new
task may be the combination of trajectory segments of multiple training tasks,
in other words, the test task and the solving strategy do not exist directly in
the training data. This makes the problem more difficult. We propose a
Memory-related Multi-task Method (M3) to address this problem. The method
consists of three stages. First, task-agnostic exploration is carried out to
collect data. Different from previous methods, we organize the exploration data
into a knowledge graph. We design a model based on the exploration data to
extract action effect features and save them in memory, while an action
predictive model is trained. Secondly, for a new task, the action effect
features stored in memory are used to generate candidate actions by a feature
decomposition-based approach. Finally, a multi-scale candidate action pool and
the action predictive model are fused to generate a strategy to complete the
task. Experimental results show that the performance of our proposed method is
significantly improved compared with the baseline.",0.05736858,0.11906354,-0.08736767,C
10994,"Since the proposed last-mile deliveries integrating customers' daily locations with MPLs is still a conceptual
model, more pilot studies and operational details are required for validity, and in particular, the collection and
protection of customer information requires further research.","In this regard, one of the biggest challenges facing the industry when integrating MPLs into their last-
mile distribution services is balancing deployment costs with increased delivery convenience and punctuality.","Further work will focus on increasing the complexity of the MPLP by introducing dynamic cases,
where more flexible route adjustment approaches are developed in response to demand changes and delay
issues.",2022-09-09 11:59:42+00:00,Location-Routing Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A Hybrid Q-Learning Network Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Yubin Liu'), arxiv.Result.Author('Qiming Ye'), arxiv.Result.Author('Jose Escribano-Macias'), arxiv.Result.Author('Yuxiang Feng'), arxiv.Result.Author('Panagiotis Angeloudis')]","Mobile parcel lockers (MPLs) have been recently proposed by logistics
operators as a technology that could help reduce traffic congestion and
operational costs in urban freight distribution. Given their ability to
relocate throughout their area of deployment, they hold the potential to
improve customer accessibility and convenience. In this study, we formulate the
Mobile Parcel Locker Problem (MPLP), a special case of the Location-Routing
Problem (LRP) which determines the optimal stopover location for MPLs
throughout the day and plans corresponding delivery routes. A Hybrid
Q-Learning-Network-based Method (HQM) is developed to resolve the computational
complexity of the resulting large problem instances while escaping local
optima. In addition, the HQM is integrated with global and local search
mechanisms to resolve the dilemma of exploration and exploitation faced by
classic reinforcement learning (RL) methods. We examine the performance of HQM
under different problem sizes (up to 200 nodes) and benchmarked it against the
Genetic Algorithm (GA). Our results indicate that the average reward obtained
by HQM is 1.96 times greater than GA, which demonstrates that HQM has a better
optimisation ability. Finally, we identify critical factors that contribute to
fleet size requirements, travel distances, and service delays. Our findings
outline that the efficiency of MPLs is mainly contingent on the length of time
windows and the deployment of MPL stopovers.",-0.20915915,0.371032,0.032521304,B
10995,"Since the proposed last-mile deliveries integrating customers' daily locations with MPLs is still a
conceptual model, more pilot studies and operational details are required for validity, and in particular, the
collection and protection of customer information requires further research.","From the perspective of urban planning and
sustainability, the deployment of MPLs in less congested areas (e.g., residential areas) allows lockers to stay
longer without disturbing traffic flow while the characteristic of their electric-powered mobility reduces gas
emissions.","Further work will focus on increasing the complexity of the MPLP by introducing dynamic cases,
where more flexible route adjustment approaches are developed in response to demand changes and delay
issues.",2022-09-09 11:59:42+00:00,Routing Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A Hybrid Q-Learning Network Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Yubin Liu'), arxiv.Result.Author('Qiming Ye'), arxiv.Result.Author('Jose Escribano-Macias'), arxiv.Result.Author('Yuxiang Feng'), arxiv.Result.Author('Eduardo Candela'), arxiv.Result.Author('Panagiotis Angeloudis')]","Mobile parcel lockers have been recently proposed by logistics operators as a
technology that could help reduce traffic congestion and operational costs in
urban freight distribution. Given their ability to relocate throughout their
area of deployment, they hold the potential to improve customer accessibility
and convenience. In this study, we formulate the Mobile Parcel Locker Problem
(MPLP) , a special case of the Location-Routing Problem (LRP) which determines
the optimal stopover location for MPLs throughout the day and plans
corresponding delivery routes. A Hybrid Q Learning Network based Method (HQM)
is developed to resolve the computational complexity of the resulting large
problem instances while escaping local optima. In addition, the HQM is
integrated with global and local search mechanisms to resolve the dilemma of
exploration and exploitation faced by classic reinforcement learning methods.
We examine the performance of HQM under different problem sizes (up to 200
nodes) and benchmarked it against the exact approach and Genetic Algorithm
(GA). Our results indicate that HQM achieves better optimisation performance
with shorter computation time than the exact approach solved by the Gurobi
solver in large problem instances. Additionally, the average reward obtained by
HQM is 1.96 times greater than GA, which demonstrates that HQM has a better
optimisation ability. Further, we identify critical factors that contribute to
fleet size requirements, travel distances, and service delays. Our findings
outline that the efficiency of MPLs is mainly contingent on the length of time
windows and the deployment of MPL stopovers. Finally, we highlight managerial
implications based on parametric analysis to provide guidance for logistics
operators in the context of efficient last-mile distribution operations.",-0.19585054,0.39200354,0.08933444,B
10999,Pending further research on the role of and methods        the process model from Fig.,"depends on the context of each case study and the conÔ¨Ådence
we have on the process model as the real representation of the      TABLE V: Alignment results for 2 probabilistic events and
process.","1.
to determine the appropriate value in each case, we select its
value based on (a) the developed intuition (higher values mean      (a) Result for p1,AnswerP hone = 0.2.
higher trust on the log), (b) the presented minimal models and
relations as rules of thumb, and (c) empirical exploration of         Event log    PickUpCup  DrinkFromCup  PutDownCup
the different values depending on the case study.",2022-09-09 14:07:37+00:00,Alignment-based conformance checking over probabilistic events,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jiawei Zheng'), arxiv.Result.Author('Petros Papapanagiotou')]","Conformance checking techniques allow us to evaluate how well some exhibited
behaviour, represented by a trace of monitored events, conforms to a specified
process model. Modern monitoring and activity recognition technologies, such as
those relying on sensors, the IoT, statistics and AI, can produce a wealth of
relevant event data. However, this data is typically characterised by noise and
uncertainty, in contrast to the assumption of a deterministic event log
required by conformance checking algorithms. In this paper, we extend
alignment-based conformance checking to function under a probabilistic event
log. We introduce a probabilistic trace model and alignment cost function, and
a custom threshold parameter that controls the level of trust on the event data
vs. the process model. The resulting algorithm yields an increased fitness
score in the presence of aligned events of sufficiently high probability
compared to traditional alignment, and thus fewer false positive deviations. We
explain the algorithm and its motivation both from a formal and intuitive
perspective, and demonstrate its functionality in comparison with deterministic
alignment using a set of theoretical examples.",-0.29350436,0.13134837,0.01740628,A
11236,"In general, there ex-
       ists a trade-oÔ¨Ä between utility-interpretability, utility-privacy, utility-
       fairness but further study is needed to reÔ¨Çect upon the relationship
       between data privacy, fairness and interpretability.","Very less work in the fuzz community
       concerns itself with the ethical concerns of AI.","FRBSs can be
       a candidate model to study the relationship between interpretability,
       fairness and data privacy.",2022-09-15 09:49:17+00:00,Literature Review of various Fuzzy Rule based Systems,cs.AI,['cs.AI'],"[arxiv.Result.Author('Ayush K. Varshney'), arxiv.Result.Author('Vicen√ß Torra')]","Fuzzy rule based systems (FRBSs) is a rule-based system which uses linguistic
fuzzy variables as antecedents and consequent to represent the human
understandable knowledge. They have been applied to various applications and
areas throughout the literature. However, FRBSs suffers from many drawbacks
such as uncertainty representation, high number of rules, interpretability
loss, high computational time for learning etc. To overcome these issues with
FRBSs, there exists many extentions of FRBSs. In this paper, we present an
overview and literature review for various types and prominent areas of fuzzy
systems (FRBSs) namely genetic fuzzy system (GFS), Hierarchical fuzzy system
(HFS), neuro fuzzy system (NFS), evolving fuzzy system (eFS), FRBSs for big
data, FRBSs for imbalanced data, interpretability in FRBSs and FRBSs which uses
cluster centroids as fuzzy rule, during the years 2010-2021. GFS uses
genetic/evolutionary approaches to improve the learning ability of FRBSs, HFS
solve the curse of dimensionality for FRBSs, NFS improves approximation ability
of FRBSs using neural networks and dynamic systems for streaming data is
considered in eFS. FRBSs are seen as good solutions for big data and imbalanced
data, in the recent years the interpretability in FRBSs has gained popularity
due to high dimensional and big data and rules are initialized with cluster
centroids to limit the number of rules in FRBSs. This paper also highlights
important contributions, publication statistics and current trends in the
field. The paper also addresses several open research areas which need further
attention from the FRBSs research community.",-0.2779231,-0.07641618,0.21400112,A
11237,"Genetic/evolutionary algorithms can help in par-
   allelization and improving the learning rate for MapReduce framework,
   further study in this regard can provide fast and good solutions.","Not much
   focus has been given for big data in other types of FRBSs such as
   GFS, NFS and HFS.","The
   complexity of NFS increases with big data which will require time
   consuming and costly solutions, an interesting direction can be dis-
   tributed/federated approaches for hybridization of NNs and FRBSs
   may present robust and fast solutions.",2022-09-15 09:49:17+00:00,Literature Review of various Fuzzy Rule based Systems,cs.AI,['cs.AI'],"[arxiv.Result.Author('Ayush K. Varshney'), arxiv.Result.Author('Vicen√ß Torra')]","Fuzzy rule based systems (FRBSs) is a rule-based system which uses linguistic
fuzzy variables as antecedents and consequent to represent the human
understandable knowledge. They have been applied to various applications and
areas throughout the literature. However, FRBSs suffers from many drawbacks
such as uncertainty representation, high number of rules, interpretability
loss, high computational time for learning etc. To overcome these issues with
FRBSs, there exists many extentions of FRBSs. In this paper, we present an
overview and literature review for various types and prominent areas of fuzzy
systems (FRBSs) namely genetic fuzzy system (GFS), Hierarchical fuzzy system
(HFS), neuro fuzzy system (NFS), evolving fuzzy system (eFS), FRBSs for big
data, FRBSs for imbalanced data, interpretability in FRBSs and FRBSs which uses
cluster centroids as fuzzy rule, during the years 2010-2021. GFS uses
genetic/evolutionary approaches to improve the learning ability of FRBSs, HFS
solve the curse of dimensionality for FRBSs, NFS improves approximation ability
of FRBSs using neural networks and dynamic systems for streaming data is
considered in eFS. FRBSs are seen as good solutions for big data and imbalanced
data, in the recent years the interpretability in FRBSs has gained popularity
due to high dimensional and big data and rules are initialized with cluster
centroids to limit the number of rules in FRBSs. This paper also highlights
important contributions, publication statistics and current trends in the
field. The paper also addresses several open research areas which need further
attention from the FRBSs research community.",0.015282497,0.13940331,-0.3457445,B
11446,"In addition, we also conduct experiments on N-puzzle
                                        problems to further study the quality of discovered plans.","In this paper, we focus on solving hard Sokoban instances that are challenging for general AI planners
                                        and even for domain-specialized solvers.","See Figure 1 for example instances for
                                        both domains.",2022-09-20 10:45:03+00:00,Graph Value Iteration,cs.AI,['cs.AI'],"[arxiv.Result.Author('Dieqiao Feng'), arxiv.Result.Author('Carla P. Gomes'), arxiv.Result.Author('Bart Selman')]","In recent years, deep Reinforcement Learning (RL) has been successful in
various combinatorial search domains, such as two-player games and scientific
discovery. However, directly applying deep RL in planning domains is still
challenging. One major difficulty is that without a human-crafted heuristic
function, reward signals remain zero unless the learning framework discovers
any solution plan. Search space becomes \emph{exponentially larger} as the
minimum length of plans grows, which is a serious limitation for planning
instances with a minimum plan length of hundreds to thousands of steps.
Previous learning frameworks that augment graph search with deep neural
networks and extra generated subgoals have achieved success in various
challenging planning domains. However, generating useful subgoals requires
extensive domain knowledge. We propose a domain-independent method that
augments graph search with graph value iteration to solve hard planning
instances that are out of reach for domain-specialized solvers. In particular,
instead of receiving learning signals only from discovered plans, our approach
also learns from failed search attempts where no goal state has been reached.
The graph value iteration component can exploit the graph structure of local
search space and provide more informative learning signals. We also show how we
use a curriculum strategy to smooth the learning process and perform a full
analysis of how graph value iteration scales and enables learning.",0.20352581,0.16580807,0.05501727,C
11452,"Still, this
approach needs further research on potential issues
with scalability and expressivity in comparison to al-
ternative constraint solving methods when applied in
real setups with complex capability descriptions on
large property sets.","This requires systematically including so-called clo-
sure axioms, which is presumably easy to achieve in a
factory environment, e.g., disjointness between sibling
capability classes from standard hierarchies.","4.2 Executing Skills using OPC UA

In recent years, the possibilities of implementing skills               Figure 2: OPC UA Skill Metamodel
have been investigated in various publications and re-           As shown in Figure 1, a distinction between the skill
search projects, such as DEVEKOS, BaSys4.0/4.2,               interface and the actual skill is necessary.",2022-09-15 20:45:00+00:00,A Reference Model for Common Understanding of Capabilities and Skills in Manufacturing,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Aljosha K√∂cher'), arxiv.Result.Author('Alexander Belyaev'), arxiv.Result.Author('Jesko Hermann'), arxiv.Result.Author('J√ºrgen Bock'), arxiv.Result.Author('Kristof Meixner'), arxiv.Result.Author('Magnus Volkmann'), arxiv.Result.Author('Michael Winter'), arxiv.Result.Author('Patrick Zimmermann'), arxiv.Result.Author('Stephan Grimm'), arxiv.Result.Author('Christian Diedrich')]","In manufacturing, many use cases of Industry 4.0 require vendor-neutral and
machine-readable information models to describe, implement and execute resource
functions. Such models have been researched under the terms capabilities and
skills. Standardization of such models is required, but currently not
available. This paper presents a reference model developed jointly by members
of various organizations in a working group of the Plattform Industrie 4.0.
This model covers definitions of most important aspects of capabilities and
skills. It can be seen as a basis for further standardization efforts.",-0.01908347,0.12829696,-0.08650674,A
11746,"The second inequality holds since

   We further study the relations among the inputs ùëã , ùëå , output ùëã^                      ùêº (ùëãÀú; ùëã, ùëå ) = ùêº (ùëãÀú; ùëã ) + ùêº (ùëãÀú; ùëå |ùëã ) and ùêº (ùëãÀú; ùëå |ùëã ) ‚â• 0.",‚ñ°         data processing inequality [17].,"‚ñ°
of the generation model ùëî, and the complete time series ùëãÀú based
on their dependencies shown in Figure 1.",2022-09-27 16:43:55+00:00,Retrieval Based Time Series Forecasting,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Baoyu Jing'), arxiv.Result.Author('Si Zhang'), arxiv.Result.Author('Yada Zhu'), arxiv.Result.Author('Bin Peng'), arxiv.Result.Author('Kaiyu Guan'), arxiv.Result.Author('Andrew Margenot'), arxiv.Result.Author('Hanghang Tong')]","Time series data appears in a variety of applications such as smart
transportation and environmental monitoring. One of the fundamental problems
for time series analysis is time series forecasting. Despite the success of
recent deep time series forecasting methods, they require sufficient
observation of historical values to make accurate forecasting. In other words,
the ratio of the output length (or forecasting horizon) to the sum of the input
and output lengths should be low enough (e.g., 0.3). As the ratio increases
(e.g., to 0.8), the uncertainty for the forecasting accuracy increases
significantly. In this paper, we show both theoretically and empirically that
the uncertainty could be effectively reduced by retrieving relevant time series
as references. In the theoretical analysis, we first quantify the uncertainty
and show its connections to the Mean Squared Error (MSE). Then we prove that
models with references are easier to learn than models without references since
the retrieved references could reduce the uncertainty. To empirically
demonstrate the effectiveness of the retrieval based time series forecasting
models, we introduce a simple yet effective two-stage method, called ReTime
consisting of a relational retrieval and a content synthesis. We also show that
ReTime can be easily adapted to the spatial-temporal time series and time
series imputation settings. Finally, we evaluate ReTime on real-world datasets
to demonstrate its effectiveness.",-0.21006536,0.18186182,-0.13878064,B
11749,"We conjecture that observing advice more frequently leads to habituation
in human responses, while scarce advice are perceived as more valuable, however further research
is needed in order to explain the behavioral source of this eÔ¨Äect.","Indeed, in a within-treatment analysis in the Random treatment, we Ô¨Ånd a clear connection
between the frequency in which the advice is provided and human responsiveness to the advice,
which we term the ‚Äúscarcity eÔ¨Äect‚Äù: When advice is given less frequently, it tends to be followed
by stronger responses.","More broadly, our study sug-
gests the importance of studying the eÔ¨Äect of partial or conditional advising on advice utilization,
which in contrast to various other factors (see, e.g., review in [9]) has not yet received attention in
behavioral literature.",2022-09-27 17:52:13+00:00,Learning When to Advise Human Decision Makers,cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']","[arxiv.Result.Author('Gali Noti'), arxiv.Result.Author('Yiling Chen')]","Artificial intelligence (AI) systems are increasingly used for providing
advice to facilitate human decision making. While a large body of work has
explored how AI systems can be optimized to produce accurate and fair advice
and how algorithmic advice should be presented to human decision makers, in
this work we ask a different basic question: When should algorithms provide
advice? Motivated by limitations of the current practice of constantly
providing algorithmic advice, we propose the design of AI systems that interact
with the human user in a two-sided manner and provide advice only when it is
likely to be beneficial to the human in making their decision. Our AI systems
learn advising policies using past human decisions. Then, for new cases, the
learned policies utilize input from the human to identify cases where
algorithmic advice would be useful, as well as those where the human is better
off deciding alone. We conduct a large-scale experiment to evaluate our
approach by using data from the US criminal justice system on pretrial-release
decisions. In our experiment, participants were asked to assess the risk of
defendants to violate their release terms if released and were advised by
different advising approaches. The results show that our interactive-advising
approach manages to provide advice at times of need and to significantly
improve human decision making compared to fixed, non-interactive advising
approaches. Our approach has additional advantages in facilitating human
learning, preserving complementary strengths of human decision makers, and
leading to more positive responsiveness to the advice.",-0.2535894,-0.06189768,0.39401037,A
11841,"However, it is still the early stage     [1] P. Spethmann, C. Herstatt, and S. H. Thomke, ‚ÄúCrash
of car-graph research, and further research is ongoing for                simulation evolution and its impact on R&D in the au-
empowering ML algorithms on CAE data that will extend this                tomotive applications,‚Äù International Journal of Product
graph modeling.","The engagement and
feedback of OEMs shall enrich the semantics, which would                                         REFERENCES
empower car-graph in exploring and predicting CAE data and
step toward safer vehicles.","Development, vol.",2022-09-29 16:16:23+00:00,Graph Modeling in Computer Assisted Automotive Development,cs.AI,"['cs.AI', 'cs.CE']","[arxiv.Result.Author('Anahita Pakiman'), arxiv.Result.Author('Jochen Garcke')]","We consider graph modeling for a knowledge graph for vehicle development,
with a focus on crash safety. An organized schema that incorporates information
from various structured and unstructured data sources is provided, which
includes relevant concepts within the domain. In particular, we propose
semantics for crash computer aided engineering (CAE) data, which enables
searchability, filtering, recommendation, and prediction for crash CAE data
during the development process. This graph modeling considers the CAE data in
the context of the R\&D development process and vehicle safety. Consequently,
we connect CAE data to the protocols that are used to assess vehicle safety
performances. The R\&D process includes CAD engineering and safety attributes,
with a focus on multidisciplinary problem-solving. We describe previous efforts
in graph modeling in comparison to our proposal, discuss its strengths and
limitations, and identify areas for future work.",-0.022596762,0.11131347,-0.09424704,B
11850,"Generalization of exist-
ing machine learning models still require further study, and research in this
area will continue to provide improvements as newer and more substantial
datasets become available for study.","There is a need
for a deÔ¨Ånitive device-use and setup protocol to enable consistent results
across tests with medical-grade wearable devices.","Keywords: Stress, Wearable sensor, Empatica E4, Machine learning
PACS: 07.05.Mh, 87.85.fk
2000 MSC: 68T01, 92C99

1.",2022-09-29 23:40:38+00:00,Machine Learning for Stress Monitoring from Wearable Devices: A Systematic Literature Review,cs.AI,"['cs.AI', 'I.1']","[arxiv.Result.Author('Gideon Vos'), arxiv.Result.Author('Kelly Trinh'), arxiv.Result.Author('Zoltan Sarnyai'), arxiv.Result.Author('Mostafa Rahimi Azghadi')]","Introduction. The stress response has both subjective, psychological and
objectively measurable, biological components. Both of them can be expressed
differently from person to person, complicating the development of a generic
stress measurement model. This is further compounded by the lack of large,
labeled datasets that can be utilized to build machine learning models for
accurately detecting periods and levels of stress. The aim of this review is to
provide an overview of the current state of stress detection and monitoring
using wearable devices, and where applicable, machine learning techniques
utilized.
  Methods. This study reviewed published works contributing and/or using
datasets designed for detecting stress and their associated machine learning
methods, with a systematic review and meta-analysis of those that utilized
wearable sensor data as stress biomarkers. The electronic databases of Google
Scholar, Crossref, DOAJ and PubMed were searched for relevant articles and a
total of 24 articles were identified and included in the final analysis. The
reviewed works were synthesized into three categories of publicly available
stress datasets, machine learning, and future research directions.
  Results. A wide variety of study-specific test and measurement protocols were
noted in the literature. A number of public datasets were identified that are
labeled for stress detection. In addition, we discuss that previous works show
shortcomings in areas such as their labeling protocols, lack of statistical
power, validity of stress biomarkers, and generalization ability.
  Conclusion. Generalization of existing machine learning models still require
further study, and research in this area will continue to provide improvements
as newer and more substantial datasets become available for study.",-0.025170818,-0.17338654,-0.030074531,A
11851,"To ensure consistent, comparable results, [12] utilized
only data recorded from the right hand of each test subject, leaving the im-
portant question of sensor placement unanswered, and needing further study
to conÔ¨Årm whether sensor placement on the dominant versus non-dominant
hand of a test subject could potentially aÔ¨Äect biomarker accuracy, and more
importantly for this review, correlation with increased levels of stress.","This dataset contains sensor recordings for both left and right hands

                                               37
of the test subjects.","Em-
patica note on their website ([2]) that newer studies have shown substantial
diÔ¨Äerences in the EDA signal between the dominant and non-dominant hand.",2022-09-29 23:40:38+00:00,Machine Learning for Stress Monitoring from Wearable Devices: A Systematic Literature Review,cs.AI,"['cs.AI', 'I.1']","[arxiv.Result.Author('Gideon Vos'), arxiv.Result.Author('Kelly Trinh'), arxiv.Result.Author('Zoltan Sarnyai'), arxiv.Result.Author('Mostafa Rahimi Azghadi')]","Introduction. The stress response has both subjective, psychological and
objectively measurable, biological components. Both of them can be expressed
differently from person to person, complicating the development of a generic
stress measurement model. This is further compounded by the lack of large,
labeled datasets that can be utilized to build machine learning models for
accurately detecting periods and levels of stress. The aim of this review is to
provide an overview of the current state of stress detection and monitoring
using wearable devices, and where applicable, machine learning techniques
utilized.
  Methods. This study reviewed published works contributing and/or using
datasets designed for detecting stress and their associated machine learning
methods, with a systematic review and meta-analysis of those that utilized
wearable sensor data as stress biomarkers. The electronic databases of Google
Scholar, Crossref, DOAJ and PubMed were searched for relevant articles and a
total of 24 articles were identified and included in the final analysis. The
reviewed works were synthesized into three categories of publicly available
stress datasets, machine learning, and future research directions.
  Results. A wide variety of study-specific test and measurement protocols were
noted in the literature. A number of public datasets were identified that are
labeled for stress detection. In addition, we discuss that previous works show
shortcomings in areas such as their labeling protocols, lack of statistical
power, validity of stress biomarkers, and generalization ability.
  Conclusion. Generalization of existing machine learning models still require
further study, and research in this area will continue to provide improvements
as newer and more substantial datasets become available for study.",-0.2524812,-0.04027302,-0.025775418,A
11860,"is distinguishable enough from closely related ones,
e.g., non-slip shoes, forCrowd, the elderly are        3 Open Resources: OpenBG
remarkable while thin and light shoes, forCrowd,
the elderly are not, because thin and light shoes      To promote further research in developing plausi-
are also suitable for young people.","(Duration is lower is better;
   (iii) Remarkability: Indicating whether a concept   GMV, CPM, CTR are all larger are better.)","ble KG representation solutions to real-world ap-
                                                       plications, we present the OpenBG Benchmark, a
   (iv) Salience: Indicating whether a concept is      challenging benchmark to facilitate reproducible,
representative and knowledge enough, so that in-       scalable, and multimodal KG research.",2022-09-30 04:03:26+00:00,Construction and Applications of Open Business Knowledge Graph,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Shumin Deng'), arxiv.Result.Author('Hui Chen'), arxiv.Result.Author('Zhoubo Li'), arxiv.Result.Author('Feiyu Xiong'), arxiv.Result.Author('Qiang Chen'), arxiv.Result.Author('Mosha Chen'), arxiv.Result.Author('Xiangwen Liu'), arxiv.Result.Author('Jiaoyan Chen'), arxiv.Result.Author('Jeff Z. Pan'), arxiv.Result.Author('Huajun Chen'), arxiv.Result.Author('Ningyu Zhang')]","Business Knowledge Graph is important to many enterprises today, providing
the factual knowledge and structured data that steer many products and make
them more intelligent. Despite the welcome outcome, building business KG brings
prohibitive issues of deficient structure, multiple modalities and unmanageable
quality. In this paper, we advance the practical challenges related to building
KG in non-trivial real-world systems. We introduce the process of building an
open business knowledge graph (OpenBG) derived from a well-known enterprise.
Specifically, we define a core ontology to cover various abstract products and
consumption demands, with fine-grained taxonomy and multi-modal facts in
deployed applications. OpenBG is ongoing, and the current version contains more
than 2.6 billion triples with more than 88 million entities and 2,681 types of
relations. We release all the open resources (OpenBG benchmark) derived from it
for the community. We also report benchmark results with best learned lessons
\url{https://github.com/OpenBGBenchmark/OpenBG}.",-0.017031014,-0.15112154,-0.13869113,A
11861,"OPENBG BENCHMARK: KG-CENTRIC APPLICATION                                                  Given OpenBG (full) with a full set of entities, relations,
                                                                                             triples, denoted by {E, R, T }, we utilize a three-stage method
   To promote further research in developing plausible KG                                    to build high-quality OpenBG benchmarks, including step 1:
representation solutions to real-world applications, we present                              selecting relations from R (relation reÔ¨Ånement); step 2: Ô¨Åltering
the OpenBG Benchmark, a challenging benchmark to facilitate                                  head entities from E (head entity Ô¨Åltering); step 3: sampling
reproducible, scalable, and multimodal KG research.","-         -
                                                                                             Wikidata5M                  4,594,485      822            20,614,279
                                                                                             OGB-LSC                    91,230,610    1,387           608,062,811    5,163     5,133
                                                                                                                                                                    15,000    10,000

 III.",We also                                  tail entities in triples T (tail entity sampling).,2022-09-30 04:03:26+00:00,Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Shumin Deng'), arxiv.Result.Author('Chengming Wang'), arxiv.Result.Author('Zhoubo Li'), arxiv.Result.Author('Ningyu Zhang'), arxiv.Result.Author('Zelin Dai'), arxiv.Result.Author('Hehong Chen'), arxiv.Result.Author('Feiyu Xiong'), arxiv.Result.Author('Ming Yan'), arxiv.Result.Author('Qiang Chen'), arxiv.Result.Author('Mosha Chen'), arxiv.Result.Author('Jiaoyan Chen'), arxiv.Result.Author('Jeff Z. Pan'), arxiv.Result.Author('Bryan Hooi'), arxiv.Result.Author('Huajun Chen')]","Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.",-0.024167333,0.025021622,-0.4468884,A
11862,"OPENBG BENCHMARK: KG-CENTRIC APPLICATION                                                  Given OpenBG (full) with a full set of entities, relations,
                                                                                             triples, denoted by {E, R, T }, we utilize a three-stage method
   To promote further research in developing plausible KG                                    to build high-quality OpenBG benchmarks, including step 1:
representation solutions to real-world applications, we present                              selecting relations from R (relation reÔ¨Ånement); step 2: Ô¨Åltering
the OpenBG Benchmark, a challenging benchmark to facilitate                                  head entities from E (head entity Ô¨Åltering); step 3: sampling
reproducible, scalable, and multimodal KG research.","-         -
                                                                                             Wikidata5M                  4,594,485      822            20,614,279
                                                                                             OGB-LSC                    91,230,610    1,387           608,062,811    5,163     5,133
                                                                                                                                                                    15,000    10,000

 III.",We also                                  tail entities in triples T (tail entity sampling).,2022-09-30 04:03:26+00:00,Construction and Applications of Billion-Scale Pre-trained Multimodal Business Knowledge Graph,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Shumin Deng'), arxiv.Result.Author('Chengming Wang'), arxiv.Result.Author('Zhoubo Li'), arxiv.Result.Author('Ningyu Zhang'), arxiv.Result.Author('Zelin Dai'), arxiv.Result.Author('Hehong Chen'), arxiv.Result.Author('Feiyu Xiong'), arxiv.Result.Author('Ming Yan'), arxiv.Result.Author('Qiang Chen'), arxiv.Result.Author('Mosha Chen'), arxiv.Result.Author('Jiaoyan Chen'), arxiv.Result.Author('Jeff Z. Pan'), arxiv.Result.Author('Bryan Hooi'), arxiv.Result.Author('Huajun Chen')]","Business Knowledge Graphs (KGs) are important to many enterprises today,
providing factual knowledge and structured data that steer many products and
make them more intelligent. Despite their promising benefits, building business
KG necessitates solving prohibitive issues of deficient structure and multiple
modalities. In this paper, we advance the understanding of the practical
challenges related to building KG in non-trivial real-world systems. We
introduce the process of building an open business knowledge graph (OpenBG)
derived from a well-known enterprise, Alibaba Group. Specifically, we define a
core ontology to cover various abstract products and consumption demands, with
fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is
an open business KG of unprecedented scale: 2.6 billion triples with more than
88 million entities covering over 1 million core classes/concepts and 2,681
types of relations. We release all the open resources (OpenBG benchmarks)
derived from it for the community and report experimental results of KG-centric
tasks. We also run up an online competition based on OpenBG benchmarks, and has
attracted thousands of teams. We further pre-train OpenBG and apply it to many
KG- enhanced downstream tasks in business scenarios, demonstrating the
effectiveness of billion-scale multimodal knowledge for e-commerce. All the
resources with codes have been released at
\url{https://github.com/OpenBGBenchmark/OpenBG}.",-0.024167333,0.025021622,-0.4468884,A
11868,"Therefore, subsequent research fo-
Based on the previous work, ST quantization10,            cuses on enhancing the binary network representa-
we further study the application of the attention         tion.",causes the decay.,"Firstly, Ref.",2022-09-30 08:48:31+00:00,Convolutional Neural Networks Quantization with Attention,cs.AI,"['cs.AI', 'cs.CV']","[arxiv.Result.Author('Binyi Wu'), arxiv.Result.Author('Bernd Waschneck'), arxiv.Result.Author('Christian Georg Mayr')]","It has been proven that, compared to using 32-bit floating-point numbers in
the training phase, Deep Convolutional Neural Networks (DCNNs) can operate with
low precision during inference, thereby saving memory space and power
consumption. However, quantizing networks is always accompanied by an accuracy
decrease. Here, we propose a method, double-stage Squeeze-and-Threshold
(double-stage ST). It uses the attention mechanism to quantize networks and
achieve state-of-art results. Using our method, the 3-bit model can achieve
accuracy that exceeds the accuracy of the full-precision baseline model. The
proposed double-stage ST activation quantization is easy to apply: inserting it
before the convolution.",0.026685312,-0.12947908,-0.22417812,C
11891,"advanced methods based on further studying the ensemble
                                                                       boosting effects are left for future work.","More
the core tensor Wk as its weights and rk: as its input.","The main novelties of MEIM are in better parameterization
                                                                          Note that MEI is easy to implement in common deep learn-
of the core tensor and mapping matrix, by looking from two             ing frameworks by using only matrix product.",2022-09-30 17:20:03+00:00,MEIM: Multi-partition Embedding Interaction Beyond Block Term Format for Efficient and Expressive Link Prediction,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Hung-Nghiep Tran'), arxiv.Result.Author('Atsuhiro Takasu')]","Knowledge graph embedding aims to predict the missing relations between
entities in knowledge graphs. Tensor-decomposition-based models, such as
ComplEx, provide a good trade-off between efficiency and expressiveness, that
is crucial because of the large size of real world knowledge graphs. The recent
multi-partition embedding interaction (MEI) model subsumes these models by
using the block term tensor format and provides a systematic solution for the
trade-off. However, MEI has several drawbacks, some of which carried from its
subsumed tensor-decomposition-based models. In this paper, we address these
drawbacks and introduce the Multi-partition Embedding Interaction iMproved
beyond block term format (MEIM) model, with independent core tensor for
ensemble effects and soft orthogonality for max-rank mapping, in addition to
multi-partition embedding. MEIM improves expressiveness while still being
highly efficient, helping it to outperform strong baselines and achieve
state-of-the-art results on difficult link prediction benchmarks using fairly
small embedding sizes. The source code is released at
https://github.com/tranhungnghiep/MEIM-KGE.",0.19044232,-0.0062552,-0.21537891,C
11892,"advanced methods based on further studying the ensemble
                                                                       boosting effects are left for future work.","More
the core tensor Wk as its weights and rk: as its input.","The main novelties of MEIM are in better parameterization
                                                                          Note that MEI is easy to implement in common deep learn-
of the core tensor and mapping matrix, by looking from two             ing frameworks by using only matrix product.",2022-09-30 17:20:03+00:00,MEIM: Multi-partition Embedding Interaction Beyond Block Term Format for Efficient and Expressive Link Prediction,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Hung Nghiep Tran'), arxiv.Result.Author('Atsuhiro Takasu')]","Knowledge graph embedding aims to predict the missing relations between
entities in knowledge graphs. Tensor-decomposition-based models, such as
ComplEx, provide a good trade-off between efficiency and expressiveness, that
is crucial because of the large size of real world knowledge graphs. The recent
multi-partition embedding interaction (MEI) model subsumes these models by
using the block term tensor format and provides a systematic solution for the
trade-off. However, MEI has several drawbacks, some of which carried from its
subsumed tensor-decomposition-based models. In this paper, we address these
drawbacks and introduce the Multi-partition Embedding Interaction iMproved
beyond block term format (MEIM) model, with independent core tensor for
ensemble effects and soft orthogonality for max-rank mapping, in addition to
multi-partition embedding. MEIM improves expressiveness while still being
highly efficient, helping it to outperform strong baselines and achieve
state-of-the-art results on difficult link prediction benchmarks using fairly
small embedding sizes. The source code is released at
https://github.com/tranhungnghiep/MEIM-KGE.",0.19044232,-0.0062552,-0.21537891,C
11951,"of view, and formulate further research accordingly.","This allows us to
                                       and auditing it, and this should also feed into the perception      then identify and address the issue from that systemic point
                                       problem, as we illustrate with a self-driving car example.",We believe that this brings multiple beneÔ¨Åts.,2022-10-02 19:49:55+00:00,"Establishing Meta-Decision-Making for AI: An Ontology of Relevance, Representation and Reasoning",cs.AI,"['cs.AI', 'cs.CY', 'cs.LO', 'cs.MA']","[arxiv.Result.Author('Cosmin Badea'), arxiv.Result.Author('Leilani Gilpin')]","We propose an ontology of building decision-making systems, with the aim of
establishing Meta-Decision-Making for Artificial Intelligence (AI), improving
autonomy, and creating a framework to build metrics and benchmarks upon. To
this end, we propose the three parts of Relevance, Representation, and
Reasoning, and discuss their value in ensuring safety and mitigating risk in
the context of third wave cognitive systems. Our nomenclature reflects the
literature on decision-making, and our ontology allows researchers that adopt
it to frame their work in relation to one or more of these parts.",-0.2975012,-0.07366535,0.23610806,A
12130,"For future works, we aim to integrate stochasticity(such as job release time, machine
breakdown, and stochastic duration) into our environment for further study on the robustness
and adaptivity of RL solutions.","In addition, our solution has state-of-the-art
performance close to the best constraint solver (OR-Tools).","Adding stochasticity also helps with the simulation of practical
environments considering the unpredictability of scheduling problems in real life.",2022-10-07 16:31:01+00:00,Reinforcement Learning Approach for Multi-Agent Flexible Scheduling Problems,cs.AI,"['cs.AI', 'cs.MA', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Hongjian Zhou'), arxiv.Result.Author('Boyang Gu'), arxiv.Result.Author('Chenghao Jin')]","Scheduling plays an important role in automated production. Its impact can be
found in various fields such as the manufacturing industry, the service
industry and the technology industry. A scheduling problem (NP-hard) is a task
of finding a sequence of job assignments on a given set of machines with the
goal of optimizing the objective defined. Methods such as Operation Research,
Dispatching Rules, and Combinatorial Optimization have been applied to
scheduling problems but no solution guarantees to find the optimal solution.
The recent development of Reinforcement Learning has shown success in
sequential decision-making problems. This research presents a Reinforcement
Learning approach for scheduling problems. In particular, this study delivers
an OpenAI gym environment with search-space reduction for Job Shop Scheduling
Problems and provides a heuristic-guided Q-Learning solution with
state-of-the-art performance for Multi-agent Flexible Job Shop Problems.",-0.05611883,0.39537436,-0.10803969,B
12280,"A suitable assembly dataset
                                        generated a feasible and reasonable assembly sequence as a        composed of a moderate number of instances and containing
                                        benchmark for further research.","Meanwhile, we compared      than sequence assembly planning, so a dataset speciÔ¨Åcally
                                        the different effects of node features and edge features and      for ASP problem is demanded.","Our data set and code is          common block relationships would provide us with more
                                        available on https://github.com/AIR-DISCOVER/ICRA ASP.",2022-10-11 08:06:16+00:00,Planning Assembly Sequence with Graph Transformer,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Lin Ma'), arxiv.Result.Author('Jiangtao Gong'), arxiv.Result.Author('Hao Xu'), arxiv.Result.Author('Hao Chen'), arxiv.Result.Author('Hao Zhao'), arxiv.Result.Author('Wenbing Huang'), arxiv.Result.Author('Guyue Zhou')]","Assembly sequence planning (ASP) is the essential process for modern
manufacturing, proven to be NP-complete thus its effective and efficient
solution has been a challenge for researchers in the field. In this paper, we
present a graph-transformer based framework for the ASP problem which is
trained and demonstrated on a self-collected ASP database. The ASP database
contains a self-collected set of LEGO models. The LEGO model is abstracted to a
heterogeneous graph structure after a thorough analysis of the original
structure and feature extraction. The ground truth assembly sequence is first
generated by brute-force search and then adjusted manually to in line with
human rational habits. Based on this self-collected ASP dataset, we propose a
heterogeneous graph-transformer framework to learn the latent rules for
assembly planning. We evaluated the proposed framework in a series of
experiment. The results show that the similarity of the predicted and ground
truth sequences can reach 0.44, a medium correlation measured by Kendall's
$\tau$. Meanwhile, we compared the different effects of node features and edge
features and generated a feasible and reasonable assembly sequence as a
benchmark for further research. Our data set and code is available on
https://github.com/AIR-DISCOVER/ICRA\_ASP.",0.1031369,0.20306168,-0.36565346,C
12281,"A suitable assembly dataset
                                        generated a feasible and reasonable assembly sequence as a        composed of a moderate number of instances and containing
                                        benchmark for further research.","Meanwhile, we compared      than sequence assembly planning, so a dataset speciÔ¨Åcally
                                        the different effects of node features and edge features and      for ASP problem is demanded.","Our data set and code is          common block relationships would provide us with more
                                        available on https://github.com/AIR-DISCOVER/ICRA ASP             opportunities to establish universal solutions to the ASP
                                                                                                          problem.",2022-10-11 08:06:16+00:00,Planning Assembly Sequence with Graph Transformer,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Lin Ma'), arxiv.Result.Author('Jiangtao Gong'), arxiv.Result.Author('Hao Xu'), arxiv.Result.Author('Hao Chen'), arxiv.Result.Author('Hao Zhao'), arxiv.Result.Author('Wenbing Huang'), arxiv.Result.Author('Guyue Zhou')]","Assembly sequence planning (ASP) is the essential process for modern
manufacturing, proven to be NP-complete thus its effective and efficient
solution has been a challenge for researchers in the field. In this paper, we
present a graph-transformer based framework for the ASP problem which is
trained and demonstrated on a self-collected ASP database. The ASP database
contains a self-collected set of LEGO models. The LEGO model is abstracted to a
heterogeneous graph structure after a thorough analysis of the original
structure and feature extraction. The ground truth assembly sequence is first
generated by brute-force search and then adjusted manually to in line with
human rational habits. Based on this self-collected ASP dataset, we propose a
heterogeneous graph-transformer framework to learn the latent rules for
assembly planning. We evaluated the proposed framework in a series of
experiment. The results show that the similarity of the predicted and ground
truth sequences can reach 0.44, a medium correlation measured by Kendall's
$\tau$. Meanwhile, we compared the different effects of node features and edge
features and generated a feasible and reasonable assembly sequence as a
benchmark for further research. Our data set and code is available on
https://github.com/AIR-DISCOVER/ICRA\_ASP.",0.10292964,0.22418773,-0.34032157,C
12282,"A suitable assembly dataset
                                        generated a feasible and reasonable assembly sequence as a        composed of a moderate number of instances and containing
                                        benchmark for further research.","Meanwhile, we compared      than sequence assembly planning, so a dataset speciÔ¨Åcally
                                        the different effects of node features and edge features and      for ASP problem is demanded.","Our data set and code is          common block relationships would provide us with more
                                        available on https://github.com/AIR-DISCOVER/ICRA ASP.",2022-10-11 08:06:16+00:00,Planning Assembly Sequence with Graph Transformer,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Lin Ma'), arxiv.Result.Author('Jiangtao Gong'), arxiv.Result.Author('Hao Xu'), arxiv.Result.Author('Hao Chen'), arxiv.Result.Author('Hao Zhao'), arxiv.Result.Author('Wenbing Huang'), arxiv.Result.Author('Guyue Zhou')]","Assembly sequence planning (ASP) is the essential process for modern
manufacturing, proven to be NP-complete thus its effective and efficient
solution has been a challenge for researchers in the field. In this paper, we
present a graph-transformer based framework for the ASP problem which is
trained and demonstrated on a self-collected ASP database. The ASP database
contains a self-collected set of LEGO models. The LEGO model is abstracted to a
heterogeneous graph structure after a thorough analysis of the original
structure and feature extraction. The ground truth assembly sequence is first
generated by brute-force search and then adjusted manually to in line with
human rational habits. Based on this self-collected ASP dataset, we propose a
heterogeneous graph-transformer framework to learn the latent rules for
assembly planning. We evaluated the proposed framework in a series of
experiment. The results show that the similarity of the predicted and ground
truth sequences can reach 0.44, a medium correlation measured by Kendall's
$\tau$. Meanwhile, we compared the different effects of node features and edge
features and generated a feasible and reasonable assembly sequence as a
benchmark for further research. Our data set and code is available on
https://github.com/AIR-DISCOVER/ICRA\_ASP.",0.1031369,0.20306168,-0.36565346,C
12365,"The operation of NATL is premised on the existence of a knowledge base (KB) of logic terms (It is also
possible to simultaneously acquire knowledge and thinking skills, as in the development of a human child,
but this is an issue for further study in the future).",The outlook for this point will be discussed below.,"In order to perform meaningful veriÔ¨Åcation and evaluation
of a particular inference task toward the realization of a functioning reasoner, it is necessary to clarify that the
given problem can be solved by operating the KB.",2022-10-12 15:31:35+00:00,Non-Axiomatic Term Logic: A Computational Theory of Cognitive Symbolic Reasoning,cs.AI,"['cs.AI', 'cs.LO']",[arxiv.Result.Author('Kotaro Funakoshi')],"This paper presents Non-Axiomatic Term Logic (NATL) as a theoretical
computational framework of humanlike symbolic reasoning in artificial
intelligence. NATL unites a discrete syntactic system inspired from Aristotle's
term logic and a continuous semantic system based on the modern idea of
distributed representations, or embeddings. This paper positions the proposed
approach in the phylogeny and the literature of logic, and explains the
framework. As it is yet no more than a theory and it requires much further
elaboration to implement it, no quantitative evaluation is presented. Instead,
qualitative analyses of arguments using NATL, some applications to possible
cognitive science/robotics-related research, and remaining issues towards a
machinery implementation are discussed.",-0.18556662,-0.10748066,0.016522357,A
12571,"Hence, further research on
semantic, concept-based explanations acquired via human computation is needed [18, 91].","Yet, one might need
clear human concepts to reason over the alignment of the features [17].",Leveraging Literature on Knowledge Acquisition for Identifying Expected Features.,2022-10-17 10:00:51+00:00,A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities,cs.AI,['cs.AI'],"[arxiv.Result.Author('Andrea Tocchetti'), arxiv.Result.Author('Lorenzo Corti'), arxiv.Result.Author('Agathe Balayn'), arxiv.Result.Author('Mireia Yurrita'), arxiv.Result.Author('Philip Lippmann'), arxiv.Result.Author('Marco Brambilla'), arxiv.Result.Author('Jie Yang')]","Despite the impressive performance of Artificial Intelligence (AI) systems,
their robustness remains elusive and constitutes a key issue that impedes
large-scale adoption. Robustness has been studied in many domains of AI, yet
with different interpretations across domains and contexts. In this work, we
systematically survey the recent progress to provide a reconciled terminology
of concepts around AI robustness. We introduce three taxonomies to organize and
describe the literature both from a fundamental and applied point of view: 1)
robustness by methods and approaches in different phases of the machine
learning pipeline; 2) robustness for specific model architectures, tasks, and
systems; and in addition, 3) robustness assessment methodologies and insights,
particularly the trade-offs with other trustworthiness properties. Finally, we
identify and discuss research gaps and opportunities and give an outlook on the
field. We highlight the central role of humans in evaluating and enhancing AI
robustness, considering the necessary knowledge humans can provide, and discuss
the need for better understanding practices and developing supportive tools in
the future.",-0.08235628,-0.40893424,0.08106443,A
12572,"Hence, further research on
semantic, concept-based explanations acquired via human computation is needed [18, 91].","Yet, one might need
clear human concepts to reason over the alignment of the features [17].",Leveraging Literature on Knowledge Acquisition for Identifying Expected Features.,2022-10-17 10:00:51+00:00,A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities,cs.AI,['cs.AI'],"[arxiv.Result.Author('Andrea Tocchetti'), arxiv.Result.Author('Lorenzo Corti'), arxiv.Result.Author('Agathe Balayn'), arxiv.Result.Author('Mireia Yurrita'), arxiv.Result.Author('Philip Lippmann'), arxiv.Result.Author('Marco Brambilla'), arxiv.Result.Author('Jie Yang')]","Despite the impressive performance of Artificial Intelligence (AI) systems,
their robustness remains elusive and constitutes a key issue that impedes
large-scale adoption. Robustness has been studied in many domains of AI, yet
with different interpretations across domains and contexts. In this work, we
systematically survey the recent progress to provide a reconciled terminology
of concepts around AI robustness. We introduce three taxonomies to organize and
describe the literature both from a fundamental and applied point of view: 1)
robustness by methods and approaches in different phases of the machine
learning pipeline; 2) robustness for specific model architectures, tasks, and
systems; and in addition, 3) robustness assessment methodologies and insights,
particularly the trade-offs with other trustworthiness properties. Finally, we
identify and discuss research gaps and opportunities and give an outlook on the
field. We highlight the central role of humans in evaluating and enhancing AI
robustness, considering the necessary knowledge humans can provide, and discuss
the need for better understanding practices and developing supportive tools in
the future.",-0.08235628,-0.40893424,0.08106443,A
12625,"Another aspect for further research is the usage  Kwangsoo Kim: photograph and biography not available at the
of different data modalities.","replay using a generator [32], remains unknown and needs to
be investigated.","RL was validated using EHR data,     time of publication.",2022-10-17 19:54:38+00:00,Review Learning: Alleviating Catastrophic Forgetting with Generative Replay without Generator,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Jaesung Yoo'), arxiv.Result.Author('Sunghyuk Choi'), arxiv.Result.Author('Ye Seul Yang'), arxiv.Result.Author('Suhyeon Kim'), arxiv.Result.Author('Jieun Choi'), arxiv.Result.Author('Dongkyeong Lim'), arxiv.Result.Author('Yaeji Lim'), arxiv.Result.Author('Hyung Joon Joo'), arxiv.Result.Author('Dae Jung Kim'), arxiv.Result.Author('Rae Woong Park'), arxiv.Result.Author('Hyeong-Jin Yoon'), arxiv.Result.Author('Kwangsoo Kim')]","When a deep learning model is sequentially trained on different datasets, it
forgets the knowledge acquired from previous data, a phenomenon known as
catastrophic forgetting. It deteriorates performance of the deep learning model
on diverse datasets, which is critical in privacy-preserving deep learning
(PPDL) applications based on transfer learning (TL). To overcome this, we
propose review learning (RL), a generative-replay-based continual learning
technique that does not require a separate generator. Data samples are
generated from the memory stored within the synaptic weights of the deep
learning model which are used to review knowledge acquired from previous
datasets. The performance of RL was validated through PPDL experiments.
Simulations and real-world medical multi-institutional experiments were
conducted using three types of binary classification electronic health record
data. In the real-world experiments, the global area under the receiver
operating curve was 0.710 for RL and 0.655 for TL. Thus, RL was highly
effective in retaining previously learned knowledge.",-0.20454395,-0.16953132,-0.06487802,A
12650,"Especially on WIKI, the dataset with the       5.4 Comparative Study on Different GCNs
largest time granularity as mentioned in Section 5.2,
entities have more associations among each other       To further study the impact of different kinds
at each timestamp and thus contain rich behaviors.","date entities, which is helpful to select the correct
answer.","of GCNs in the candidate structure encoder and
                                                       the background knowledge encoder, we replace
   Impact of the Background Knowledge En-              CompGCN in these two encoders with CompGCN-
coder.",2022-10-18 09:39:26+00:00,HiSMatch: Historical Structure Matching based Temporal Knowledge Graph Reasoning,cs.AI,['cs.AI'],"[arxiv.Result.Author('Zixuan Li'), arxiv.Result.Author('Zhongni Hou'), arxiv.Result.Author('Saiping Guan'), arxiv.Result.Author('Xiaolong Jin'), arxiv.Result.Author('Weihua Peng'), arxiv.Result.Author('Long Bai'), arxiv.Result.Author('Yajuan Lyu'), arxiv.Result.Author('Wei Li'), arxiv.Result.Author('Jiafeng Guo'), arxiv.Result.Author('Xueqi Cheng')]","A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective
timestamps, which adopts quadruples in the form of (\emph{subject},
\emph{relation}, \emph{object}, \emph{timestamp}) to describe dynamic facts.
TKG reasoning has facilitated many real-world applications via answering such
queries as (\emph{query entity}, \emph{query relation}, \emph{?}, \emph{future
timestamp}) about future. This is actually a matching task between a query and
candidate entities based on their historical structures, which reflect
behavioral trends of the entities at different timestamps. In addition, recent
KGs provide background knowledge of all the entities, which is also helpful for
the matching. Thus, in this paper, we propose the \textbf{Hi}storical
\textbf{S}tructure \textbf{Match}ing (\textbf{HiSMatch}) model. It applies two
structure encoders to capture the semantic information contained in the
historical structures of the query and candidate entities. Besides, it adopts
another encoder to integrate the background knowledge into the model. TKG
reasoning experiments on six benchmark datasets demonstrate the significant
improvement of the proposed HiSMatch model, with up to 5.6\% performance
improvement in MRR, compared to the state-of-the-art baselines.",-0.023743497,-0.06653865,-0.24434526,A
12670,"ation (Keskar et al., 2019; Dathathri et al., 2020),
                                                                                                 story generation (Clark et al., 2018; Fan et al.,
                                        1 Introduction                                           2018), and text inÔ¨Ålling (Fedus et al., 2018; Don-
                                                                                                 ahue et al., 2020) further study how to leverage
                                        According to the statement of the U.S. Securities        LMs to generate content with desired attributes.","Sub-Ô¨Åelds such as controllable text gener-
                                             information and deceive adversaries.","and Exchange Commission, the scope and severity          However, few methods offer Ô¨Åne-grained control
                                        of cyber risks have dramatically increased, and con-     over concept levels or provide an efÔ¨Åcient, control-
                                        stant vigilance is needed to protect against intrusion   lable fake text generation strategy.",2022-10-18 14:59:38+00:00,Controllable Fake Document Infilling for Cyber Deception,cs.AI,"['cs.AI', 'cs.CR']","[arxiv.Result.Author('Yibo Hu'), arxiv.Result.Author('Yu Lin'), arxiv.Result.Author('Erick Skorupa Parolin'), arxiv.Result.Author('Latifur Khan'), arxiv.Result.Author('Kevin Hamlen')]","Recent works in cyber deception study how to deter malicious intrusion by
generating multiple fake versions of a critical document to impose costs on
adversaries who need to identify the correct information. However, existing
approaches are context-agnostic, resulting in sub-optimal and unvaried outputs.
We propose a novel context-aware model, Fake Document Infilling (FDI), by
converting the problem to a controllable mask-then-infill procedure. FDI masks
important concepts of varied lengths in the document, then infills a realistic
but fake alternative considering both the previous and future contexts. We
conduct comprehensive evaluations on technical documents and news stories.
Results show that FDI outperforms the baselines in generating highly believable
fakes with moderate modification to protect critical information and deceive
adversaries.",-0.16631056,-0.14887138,0.16744493,A
12671,"ation (Keskar et al., 2019; Dathathri et al., 2020),
                                                                                                 story generation (Clark et al., 2018; Fan et al.,
                                        1 Introduction                                           2018), and text inÔ¨Ålling (Fedus et al., 2018; Don-
                                                                                                 ahue et al., 2020) further study how to leverage
                                        According to the statement of the U.S. Securities        LMs to generate content with desired attributes.","Sub-Ô¨Åelds such as controllable text gener-
                                             information and deceive adversaries.","and Exchange Commission, the scope and severity          However, few methods offer Ô¨Åne-grained control
                                        of cyber risks have dramatically increased, and con-     over concept levels or provide an efÔ¨Åcient, control-
                                        stant vigilance is needed to protect against intrusion   lable fake text generation strategy.",2022-10-18 14:59:38+00:00,Controllable Fake Document Infilling for Cyber Deception,cs.AI,"['cs.AI', 'cs.CR']","[arxiv.Result.Author('Yibo Hu'), arxiv.Result.Author('Yu Lin'), arxiv.Result.Author('Erick Skorupa Parolin'), arxiv.Result.Author('Latifur Khan'), arxiv.Result.Author('Kevin Hamlen')]","Recent works in cyber deception study how to deter malicious intrusion by
generating multiple fake versions of a critical document to impose costs on
adversaries who need to identify the correct information. However, existing
approaches are context-agnostic, resulting in sub-optimal and unvaried outputs.
We propose a novel context-aware model, Fake Document Infilling (FDI), by
converting the problem to a controllable mask-then-infill procedure. FDI masks
important concepts of varied lengths in the document, then infills a realistic
but fake alternative considering both the previous and future contexts. We
conduct comprehensive evaluations on technical documents and news stories.
Results show that FDI outperforms the baselines in generating highly believable
fakes with moderate modification to protect critical information and deceive
adversaries.",-0.16631056,-0.14887138,0.16744493,A
12726,"Considering that google     5.1‚ÄÇLimitations and further research
scholar is only one of the available search engines, alterna-
tive data reciprocities were reviewed.","of AI in the metaverse, but there is not much in terms of
strong research studies on this topic.","The next search was         The limitation of the proposed design is primarily in the
on the Web of Science Core Collection, and included a very         area of limited functionality.",2022-10-17 09:31:51+00:00,Review of the state of the art in autonomous artificial intelligence,cs.AI,"['cs.AI', 'cs.HC', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Petar Radanliev'), arxiv.Result.Author('David De Roure')]","This article presents a new design for autonomous artificial intelligence
(AI), based on the state-of-the-art algorithms, and describes a new autonomous
AI system called AutoAI. The methodology is used to assemble the design founded
on self-improved algorithms that use new and emerging sources of data (NEFD).
The objective of the article is to conceptualise the design of a novel AutoAI
algorithm. The conceptual approach is used to advance into building new and
improved algorithms. The article integrates and consolidates the findings from
existing literature and advances the AutoAI design into (1) using new and
emerging sources of data for teaching and training AI algorithms and (2)
enabling AI algorithms to use automated tools for training new and improved
algorithms. This approach is going beyond the state-of-the-art in AI algorithms
and suggests a design that enables autonomous algorithms to self-optimise and
self-adapt, and on a higher level, be capable to self-procreate.",0.11231615,-0.07434872,0.022235027,C
12746,"Finally, in Section 7,
we conclude with recommendations for further research.",Section 6 describe the discussion of the paper.,"2 Literature Review

To address text classiÔ¨Åcation [7], several machine and deep learning-based approaches have been introduced.",2022-10-19 21:53:49+00:00,Machine and Deep Learning Methods with Manual and Automatic Labelling for News Classification in Bangla Language,cs.AI,['cs.AI'],"[arxiv.Result.Author('Istiak Ahmad'), arxiv.Result.Author('Fahad AlQurashi'), arxiv.Result.Author('Rashid Mehmood')]","Research in Natural Language Processing (NLP) has increasingly become
important due to applications such as text classification, text mining,
sentiment analysis, POS tagging, named entity recognition, textual entailment,
and many others. This paper introduces several machine and deep learning
methods with manual and automatic labelling for news classification in the
Bangla language. We implemented several machine (ML) and deep learning (DL)
algorithms. The ML algorithms are Logistic Regression (LR), Stochastic Gradient
Descent (SGD), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest
Neighbour (KNN), used with Bag of Words (BoW), Term Frequency-Inverse Document
Frequency (TF-IDF), and Doc2Vec embedding models. The DL algorithms are Long
Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit
(GRU), and Convolutional Neural Network (CNN), used with Word2vec, Glove, and
FastText word embedding models. We develop automatic labelling methods using
Latent Dirichlet Allocation (LDA) and investigate the performance of
single-label and multi-label article classification methods. To investigate
performance, we developed from scratch Potrika, the largest and the most
extensive dataset for news classification in the Bangla language, comprising
185.51 million words and 12.57 million sentences contained in 664,880 news
articles in eight distinct categories, curated from six popular online news
portals in Bangladesh for the period 2014-2020. GRU and Fasttext with 91.83%
achieve the highest accuracy for manually-labelled data. For the automatic
labelling case, KNN and Doc2Vec at 57.72% and 75% achieve the highest accuracy
for single-label and multi-label data, respectively. The methods developed in
this paper are expected to advance research in Bangla and other languages.",0.1415759,-0.27326173,-0.13958985,C
12768,"In further research, methods for stabilizing
the results at diÔ¨Äerent iterations of model training can be studied.","Such data can be very useful for engineers

                                               18
working with this equipment.","Figure 11: The sums of edge weights belonging to numbered sensors/nodes for diÔ¨Äerent 5
training iterations.",2022-10-20 11:03:21+00:00,Graph Neural Networks with Trainable Adjacency Matrices for Fault Diagnosis on Multivariate Sensor Data,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Alexander Kovalenko'), arxiv.Result.Author('Vitaliy Pozdnyakov'), arxiv.Result.Author('Ilya Makarov')]","Timely detected anomalies in the chemical technological processes, as well as
the earliest detection of the cause of the fault, significantly reduce the
production cost in the industrial factories. Data on the state of the
technological process and the operation of production equipment are received by
a large number of different sensors. To better predict the behavior of the
process and equipment, it is necessary not only to consider the behavior of the
signals in each sensor separately, but also to take into account their
correlation and hidden relationships with each other. Graph-based data
representation helps with this. The graph nodes can be represented as data from
the different sensors, and the edges can display the influence of these data on
each other. In this work, the possibility of applying graph neural networks to
the problem of fault diagnosis in a chemical process is studied. It was
proposed to construct a graph during the training of graph neural network. This
allows to train models on data where the dependencies between the sensors are
not known in advance. In this work, several methods for obtaining adjacency
matrices were considered, as well as their quality was studied. It has also
been proposed to use multiple adjacency matrices in one model. We showed
state-of-the-art performance on the fault diagnosis task with the Tennessee
Eastman Process dataset. The proposed graph neural networks outperformed the
results of recurrent neural networks.",0.1383777,0.19498,-0.116308436,B
12778,We believe that further research is needed w.r.t.,"We also see that DN NGAE
(GAE) and DN NGAT (GAT ) do not necessarily predict the same image based on
the given context.","investigating
how to best incorporate context in combination with image data.",2022-10-20 13:09:00+00:00,Context-driven Visual Object Recognition based on Knowledge Graphs,cs.AI,"['cs.AI', 'cs.CL', 'cs.CV', 'cs.LG', 'cs.SC']","[arxiv.Result.Author('Sebastian Monka'), arxiv.Result.Author('Lavdim Halilaj'), arxiv.Result.Author('Achim Rettinger')]","Current deep learning methods for object recognition are purely data-driven
and require a large number of training samples to achieve good results. Due to
their sole dependence on image data, these methods tend to fail when confronted
with new environments where even small deviations occur. Human perception,
however, has proven to be significantly more robust to such distribution
shifts. It is assumed that their ability to deal with unknown scenarios is
based on extensive incorporation of contextual knowledge. Context can be based
either on object co-occurrences in a scene or on memory of experience. In
accordance with the human visual cortex which uses context to form different
object representations for a seen image, we propose an approach that enhances
deep learning methods by using external contextual knowledge encoded in a
knowledge graph. Therefore, we extract different contextual views from a
generic knowledge graph, transform the views into vector space and infuse it
into a DNN. We conduct a series of experiments to investigate the impact of
different contextual views on the learned object representations for the same
image dataset. The experimental results provide evidence that the contextual
views influence the image representations in the DNN differently and therefore
lead to different predictions for the same images. We also show that context
helps to strengthen the robustness of object recognition models for
out-of-distribution images, usually occurring in transfer learning tasks or
real-world scenarios.",0.013149298,-0.19490203,-0.16257337,C
12807,"Therefore, we argue that further research is required to uncover the links
between current proxy tasks and on-task performance or to devise new proxy tasks with a verified connection to actual
tasks.","The results show that users trust different explanations in the proxy
task and the actual decision-making task.",Simulated evaluation as a cost-efficient solution?,2022-10-20 20:53:00+00:00,Towards Human-centered Explainable AI: User Studies for Model Explanations,cs.AI,"['cs.AI', 'cs.HC']","[arxiv.Result.Author('Yao Rong'), arxiv.Result.Author('Tobias Leemann'), arxiv.Result.Author('Thai-trang Nguyen'), arxiv.Result.Author('Lisa Fiedler'), arxiv.Result.Author('Tina Seidel'), arxiv.Result.Author('Gjergji Kasneci'), arxiv.Result.Author('Enkelejda Kasneci')]","Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI
research. A better understanding of the needs of XAI users, as well as
human-centered evaluations of explainable models are both a necessity and a
challenge. In this paper, we explore how HCI and AI researchers conduct user
studies in XAI applications based on a systematic literature review. After
identifying and thoroughly analyzing 85 core papers with human-based XAI
evaluations over the past five years, we categorize them along the measured
characteristics of explanatory methods, namely trust, understanding, fairness,
usability, and human-AI team performance. Our research shows that XAI is
spreading more rapidly in certain application domains, such as recommender
systems than in others, but that user evaluations are still rather sparse and
incorporate hardly any insights from cognitive or social sciences. Based on a
comprehensive discussion of best practices, i.e., common models, design
choices, and measures in user studies, we propose practical guidelines on
designing and conducting user studies for XAI researchers and practitioners.
Lastly, this survey also highlights several open research directions,
particularly linking psychological science and human-centered XAI.",-0.14814684,0.028367568,0.3385926,A
12808,"Therefore, we argue that further research is required to uncover the links between current proxy tasks and on-task
performance or to devise new proxy tasks with a verified connection to actual tasks.",The results show that users trust different explanations in the proxy task and the actual decision-making task.,Simulated evaluation as a cost-efficient solution?,2022-10-20 20:53:00+00:00,Towards Human-centered Explainable AI: User Studies for Model Explanations,cs.AI,"['cs.AI', 'cs.HC']","[arxiv.Result.Author('Yao Rong'), arxiv.Result.Author('Tobias Leemann'), arxiv.Result.Author('Thai-trang Nguyen'), arxiv.Result.Author('Lisa Fiedler'), arxiv.Result.Author('Peizhu Qian'), arxiv.Result.Author('Vaibhav Unhelkar'), arxiv.Result.Author('Tina Seidel'), arxiv.Result.Author('Gjergji Kasneci'), arxiv.Result.Author('Enkelejda Kasneci')]","Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI
research. A better understanding of the needs of XAI users, as well as
human-centered evaluations of explainable models are both a necessity and a
challenge. In this paper, we explore how HCI and AI researchers conduct user
studies in XAI applications based on a systematic literature review. After
identifying and thoroughly analyzing 85 core papers with human-based XAI
evaluations over the past five years, we categorize them along the measured
characteristics of explanatory methods, namely trust, understanding, fairness,
usability, and human-AI team performance. Our research shows that XAI is
spreading more rapidly in certain application domains, such as recommender
systems than in others, but that user evaluations are still rather sparse and
incorporate hardly any insights from cognitive or social sciences. Based on a
comprehensive discussion of best practices, i.e., common models, design
choices, and measures in user studies, we propose practical guidelines on
designing and conducting user studies for XAI researchers and practitioners.
Lastly, this survey also highlights several open research directions,
particularly linking psychological science and human-centered XAI.",-0.14814684,0.028367568,0.3385926,A
12840,"Additionally, for the counterfactual
explanations to reach their full potential as actionable explanations, further research is needed in developing causally-
correct counterfactuals and producing recourse.","For successful comparison and evaluation of counterfactual explanations, future research needs to ensure unified
metrics for counterfactual properties such as proximity and data manifold closeness.","6 COUNTERFACTUAL EXPLANATIONS IN REINFORCEMENT LEARNING

In the previous section we provided an overview of the state-of-the-art methods for generating counterfactual expla-
nations in supervised learning tasks.",2022-10-21 09:50:53+00:00,Counterfactual Explanations for Reinforcement Learning,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jasmina Gajcin'), arxiv.Result.Author('Ivana Dusparic')]","While AI algorithms have shown remarkable success in various fields, their
lack of transparency hinders their application to real-life tasks. Although
explanations targeted at non-experts are necessary for user trust and human-AI
collaboration, the majority of explanation methods for AI are focused on
developers and expert users. Counterfactual explanations are local explanations
that offer users advice on what can be changed in the input for the output of
the black-box model to change. Counterfactuals are user-friendly and provide
actionable advice for achieving the desired output from the AI system. While
extensively researched in supervised learning, there are few methods applying
them to reinforcement learning (RL). In this work, we explore the reasons for
the underrepresentation of a powerful explanation method in RL. We start by
reviewing the current work in counterfactual explanations in supervised
learning. Additionally, we explore the differences between counterfactual
explanations in supervised learning and RL and identify the main challenges
that prevent adoption of methods from supervised in reinforcement learning.
Finally, we redefine counterfactuals for RL and propose research directions for
implementing counterfactuals in RL.",0.056573283,-0.1499631,0.22341943,C
12841,"For this reason, further research in understanding how can the search space for counterfactual instances be defined is
needed.","However,
this counterfactual instance is unlikely to occur under the agent‚Äôs policy ùúã which is already following goal ùê¥ in state ùë†.",6.4.2 Categorical Variables.,2022-10-21 09:50:53+00:00,Counterfactual Explanations for Reinforcement Learning,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jasmina Gajcin'), arxiv.Result.Author('Ivana Dusparic')]","While AI algorithms have shown remarkable success in various fields, their
lack of transparency hinders their application to real-life tasks. Although
explanations targeted at non-experts are necessary for user trust and human-AI
collaboration, the majority of explanation methods for AI are focused on
developers and expert users. Counterfactual explanations are local explanations
that offer users advice on what can be changed in the input for the output of
the black-box model to change. Counterfactuals are user-friendly and provide
actionable advice for achieving the desired output from the AI system. While
extensively researched in supervised learning, there are few methods applying
them to reinforcement learning (RL). In this work, we explore the reasons for
the underrepresentation of a powerful explanation method in RL. We start by
reviewing the current work in counterfactual explanations in supervised
learning. Additionally, we explore the differences between counterfactual
explanations in supervised learning and RL and identify the main challenges
that prevent adoption of methods from supervised in reinforcement learning.
Finally, we redefine counterfactuals for RL and propose research directions for
implementing counterfactuals in RL.",-0.08053143,0.06135645,0.18873674,A
12890,"Future Work                                  The B3RTDP algorithm was evaluated against a state-of-the-
                                                                  art POMDP planner called SARSOP on two standard bench-
During the development of B3RTDP we identiÔ¨Åed several             mark domains and showed that it can aquire higher ADR
areas where it could be improved with further research and        with a shorter convergence time.","which serves to improve convergence time by taking advan-
                                                                  tage of convergence of early action selection in the policy.",development.,2022-10-22 21:42:59+00:00,B$^3$RTDP: A Belief Branch and Bound Real-Time Dynamic Programming Approach to Solving POMDPs,cs.AI,"['cs.AI', 'I.2.8; I.2.6']","[arxiv.Result.Author('Sigurdur Orn Adalgeirsson'), arxiv.Result.Author('Cynthia Breazeal')]","Partially Observable Markov Decision Processes (POMDPs) offer a promising
world representation for autonomous agents, as they can model both transitional
and perceptual uncertainties. Calculating the optimal solution to POMDP
problems can be computationally expensive as they require reasoning over the
(possibly infinite) space of beliefs. Several approaches have been proposed to
overcome this difficulty, such as discretizing the belief space, point-based
belief sampling, and Monte Carlo tree search. The Real-Time Dynamic Programming
approach of the RTDP-Bel algorithm approximates the value function by storing
it in a hashtable with discretized belief keys. We propose an extension to the
RTDP-Bel algorithm which we call Belief Branch and Bound RTDP (B$^3$RTDP). Our
algorithm uses a bounded value function representation and takes advantage of
this in two novel ways: a search-bounding technique based on action selection
convergence probabilities, and a method for leveraging early action convergence
called the \textit{Convergence Frontier}. Lastly, we empirically demonstrate
that B$^3$RTDP can achieve greater returns in less time than the
state-of-the-art SARSOP solver on known POMDP problems.",0.14607273,0.26901063,0.105119154,B
12904,"In International conference
complicated circumstance should be further researched.","Qmix: Monotonic value function factori-
or even deceive; how the relation network identities in the more                                 sation for deep multi-agent reinforcement learning.",Except for                                on machine learning.,2022-10-24 00:54:59+00:00,IDRL: Identifying Identities in Multi-Agent Reinforcement Learning with Ambiguous Identities,cs.AI,['cs.AI'],"[arxiv.Result.Author('Shijie Han'), arxiv.Result.Author('Peng liu'), arxiv.Result.Author('Siyuan Li')]","Multi-agent reinforcement learning(MARL) is a prevalent learning paradigm for
solving stochastic games. In previous studies, agents in a game are defined to
be teammates or enemies beforehand, and the relation of the agents is fixed
throughout the game. Those works can hardly work in the games where the
competitive and collaborative relationships are not public and dynamically
changing, which is decided by the \textit{identities} of the agents. How to
learn a successful policy in such a situation where the identities of agents
are ambiguous is still a problem. Focusing on this problem, in this work, we
develop a novel MARL framework: IDRL, which identifies the identities of the
agents dynamically and then chooses the corresponding policy to perform in the
task. In the IDRL framework, a relation network is constructed to deduce the
identities of the multi-agents through feeling the kindness and hostility
unleashed by other agents; a dangerous network is built to estimate the risk of
the identification. We also propose an intrinsic reward to help train the
relation network and the dangerous network to get a trade-off between the need
to maximize external reward and the accuracy of identification. After
identifying the cooperation-competition pattern among the agents, the proposed
method IDRL applies one of the off-the-shelf MARL methods to learn the policy.
Taking the poker game \textit{red-10} as the experiment environment,
experiments show that the IDRL can achieve superior performance compared to the
other MARL methods. Significantly, the relation network has the par performance
to identify the identities of agents with top human players; the dangerous
network reasonably avoids the risk of imperfect identification.",0.20684108,0.06680188,0.20116584,C
12906,"open-source our solution and the optimized feature parser
                                                                                                           for further research on multi-agent reinforcement learning
                                            *These authors contributed equally.","(3) We will
                                        environment, Flatland.",in MAPF problems.,2022-10-24 03:22:20+00:00,Multi-Agent Path Finding via Tree LSTM,cs.AI,"['cs.AI', 'cs.LG', 'cs.MA']","[arxiv.Result.Author('Yuhao Jiang'), arxiv.Result.Author('Kunjie Zhang'), arxiv.Result.Author('Qimai Li'), arxiv.Result.Author('Jiaxin Chen'), arxiv.Result.Author('Xiaolong Zhu')]","In recent years, Multi-Agent Path Finding (MAPF) has attracted attention from
the fields of both Operations Research (OR) and Reinforcement Learning (RL).
However, in the 2021 Flatland3 Challenge, a competition on MAPF, the best RL
method scored only 27.9, far less than the best OR method. This paper proposes
a new RL solution to Flatland3 Challenge, which scores 125.3, several times
higher than the best RL solution before. We creatively apply a novel network
architecture, TreeLSTM, to MAPF in our solution. Together with several other RL
techniques, including reward shaping, multiple-phase training, and centralized
control, our solution is comparable to the top 2-3 OR methods.",0.385001,0.16705142,0.02879245,C
12907,"sourced1our solution and the optimized feature parser for
                                                                                                           further research on multi-agent reinforcement learning in
                                            *These authors contributed equally.","(3) We open-
                                        environment, Flatland.",MAPF problems.,2022-10-24 03:22:20+00:00,Multi-Agent Path Finding via Tree LSTM,cs.AI,"['cs.AI', 'cs.LG', 'cs.MA']","[arxiv.Result.Author('Yuhao Jiang'), arxiv.Result.Author('Kunjie Zhang'), arxiv.Result.Author('Qimai Li'), arxiv.Result.Author('Jiaxin Chen'), arxiv.Result.Author('Xiaolong Zhu')]","In recent years, Multi-Agent Path Finding (MAPF) has attracted attention from
the fields of both Operations Research (OR) and Reinforcement Learning (RL).
However, in the 2021 Flatland3 Challenge, a competition on MAPF, the best RL
method scored only 27.9, far less than the best OR method. This paper proposes
a new RL solution to Flatland3 Challenge, which scores 125.3, several times
higher than the best RL solution before. We creatively apply a novel network
architecture, TreeLSTM, to MAPF in our solution. Together with several other RL
techniques, including reward shaping, multiple-phase training, and centralized
control, our solution is comparable to the top 2-3 OR methods.",0.37669802,0.14983717,0.05592782,C
12931,"Finally, we elaborate upon various   changer in terms of the impact of its potential applications
                                        open issues that require further research interest from the           due to the greater immersion, involvement, and personalization
                                        community.","Metaverse can be a game
                                        it through the adversarial lens.",possible due to AI-XR.,2022-10-24 14:26:59+00:00,Secure and Trustworthy Artificial Intelligence-Extended Reality (AI-XR) for Metaverses,cs.AI,"['cs.AI', 'cs.CR', 'cs.CY']","[arxiv.Result.Author('Adnan Qayyum'), arxiv.Result.Author('Muhammad Atif Butt'), arxiv.Result.Author('Hassan Ali'), arxiv.Result.Author('Muhammad Usman'), arxiv.Result.Author('Osama Halabi'), arxiv.Result.Author('Ala Al-Fuqaha'), arxiv.Result.Author('Qammer H. Abbasi'), arxiv.Result.Author('Muhammad Ali Imran'), arxiv.Result.Author('Junaid Qadir')]","Metaverse is expected to emerge as a new paradigm for the next-generation
Internet, providing fully immersive and personalised experiences to socialize,
work, and play in self-sustaining and hyper-spatio-temporal virtual world(s).
The advancements in different technologies like augmented reality, virtual
reality, extended reality (XR), artificial intelligence (AI), and 5G/6G
communication will be the key enablers behind the realization of AI-XR
metaverse applications. While AI itself has many potential applications in the
aforementioned technologies (e.g., avatar generation, network optimization,
etc.), ensuring the security of AI in critical applications like AI-XR
metaverse applications is profoundly crucial to avoid undesirable actions that
could undermine users' privacy and safety, consequently putting their lives in
danger. To this end, we attempt to analyze the security, privacy, and
trustworthiness aspects associated with the use of various AI techniques in
AI-XR metaverse applications. Specifically, we discuss numerous such challenges
and present a taxonomy of potential solutions that could be leveraged to
develop secure, private, robust, and trustworthy AI-XR applications. To
highlight the real implications of AI-associated adversarial threats, we
designed a metaverse-specific case study and analyzed it through the
adversarial lens. Finally, we elaborate upon various open issues that require
further research interest from the community.",0.13886103,-0.21142921,0.19675519,C
12932,"Some            issues that require further research attention are highlighted
speciÔ¨Åc concerns related to how AI-XR-based metaverse ap-          in Section VI.","Different potential
There are many ethical questions about privacy, security,          solutions that can ensure security, privacy, safety, and trust
transparency, accountability, democracy, freedom of speech,        in ML applications are discussed in Section V. Various open
and anonymity that technology alone cannot answer.","Finally, we conclude the paper in Section VII.",2022-10-24 14:26:59+00:00,Secure and Trustworthy Artificial Intelligence-Extended Reality (AI-XR) for Metaverses,cs.AI,"['cs.AI', 'cs.CR', 'cs.CY']","[arxiv.Result.Author('Adnan Qayyum'), arxiv.Result.Author('Muhammad Atif Butt'), arxiv.Result.Author('Hassan Ali'), arxiv.Result.Author('Muhammad Usman'), arxiv.Result.Author('Osama Halabi'), arxiv.Result.Author('Ala Al-Fuqaha'), arxiv.Result.Author('Qammer H. Abbasi'), arxiv.Result.Author('Muhammad Ali Imran'), arxiv.Result.Author('Junaid Qadir')]","Metaverse is expected to emerge as a new paradigm for the next-generation
Internet, providing fully immersive and personalised experiences to socialize,
work, and play in self-sustaining and hyper-spatio-temporal virtual world(s).
The advancements in different technologies like augmented reality, virtual
reality, extended reality (XR), artificial intelligence (AI), and 5G/6G
communication will be the key enablers behind the realization of AI-XR
metaverse applications. While AI itself has many potential applications in the
aforementioned technologies (e.g., avatar generation, network optimization,
etc.), ensuring the security of AI in critical applications like AI-XR
metaverse applications is profoundly crucial to avoid undesirable actions that
could undermine users' privacy and safety, consequently putting their lives in
danger. To this end, we attempt to analyze the security, privacy, and
trustworthiness aspects associated with the use of various AI techniques in
AI-XR metaverse applications. Specifically, we discuss numerous such challenges
and present a taxonomy of potential solutions that could be leveraged to
develop secure, private, robust, and trustworthy AI-XR applications. To
highlight the real implications of AI-associated adversarial threats, we
designed a metaverse-specific case study and analyzed it through the
adversarial lens. Finally, we elaborate upon various open issues that require
further research interest from the community.",-0.1243684,-0.10044785,0.2094383,A
12937,"This is consistent with the low
performance of the corresponding agents on the 15x15 online RL benchmark, and suggests that
Memory Maze can be a fruitful platform for further research, both in the online and ofÔ¨Çine settings.","The 15x15 Walls is an especially challenging benchmark,
where the models barely outperform the no-memory baseline.","Among the models, RSSM (TBTT) reaches the highest performance, outperforming RSSM and
VAE+GRU (TBTT).",2022-10-24 16:32:28+00:00,Evaluating Long-Term Memory in 3D Mazes,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Jurgis Pasukonis'), arxiv.Result.Author('Timothy Lillicrap'), arxiv.Result.Author('Danijar Hafner')]","Intelligent agents need to remember salient information to reason in
partially-observed environments. For example, agents with a first-person view
should remember the positions of relevant objects even if they go out of view.
Similarly, to effectively navigate through rooms agents need to remember the
floor plan of how rooms are connected. However, most benchmark tasks in
reinforcement learning do not test long-term memory in agents, slowing down
progress in this important research direction. In this paper, we introduce the
Memory Maze, a 3D domain of randomized mazes specifically designed for
evaluating long-term memory in agents. Unlike existing benchmarks, Memory Maze
measures long-term memory separate from confounding agent abilities and
requires the agent to localize itself by integrating information over time.
With Memory Maze, we propose an online reinforcement learning benchmark, a
diverse offline dataset, and an offline probing evaluation. Recording a human
player establishes a strong baseline and verifies the need to build up and
retain memories, which is reflected in their gradually increasing rewards
within each episode. We find that current algorithms benefit from training with
truncated backpropagation through time and succeed on small mazes, but fall
short of human performance on the large mazes, leaving room for future
algorithmic designs to be evaluated on the Memory Maze.",0.2888972,0.08836686,-0.13456652,C
12948,"While the discussion was extremely constructive, it also
revealed strong diÔ¨Äerences in opinion, methodology, and aims among the attendees, signalling the
need for further research and greater interdisciplinary engagement in this area.","Conclusion

    A number of common themes emerged during the workshop, acting as focal points of discussion
and debate for a diverse group of attendees.","Three broad themes
arose repeatedly throughout the workshop.",2022-10-24 20:24:30+00:00,"Embodied, Situated, and Grounded Intelligence: Implications for AI",cs.AI,"['cs.AI', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Tyler Millhouse'), arxiv.Result.Author('Melanie Moses'), arxiv.Result.Author('Melanie Mitchell')]","In April of 2022, the Santa Fe Institute hosted a workshop on embodied,
situated, and grounded intelligence as part of the Institute's Foundations of
Intelligence project. The workshop brought together computer scientists,
psychologists, philosophers, social scientists, and others to discuss the
science of embodiment and related issues in human intelligence, and its
implications for building robust, human-level AI. In this report, we summarize
each of the talks and the subsequent discussions. We also draw out a number of
key themes and identify important frontiers for future research.",-0.2254504,-0.09912264,0.2064783,A
13048,"We further study the effect made by logical rules on embedding-based models with more datasets
(i.e., UMLS and Kinship).","The reason is probably that ComplEx-NNE-
AER additionally injects the regularization terms on entity representations but RulE does not, and
ComplEx-NNE-AER is based on origin ComplEx, which performs better than ComplEx we use.","We rerun KALE (Guo et al., 2016) on UMLS and Kinship datasets.",2022-10-24 06:47:13+00:00,RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Xiaojuan Tang'), arxiv.Result.Author('Song-Chun Zhu'), arxiv.Result.Author('Yitao Liang'), arxiv.Result.Author('Muhan Zhang')]","Knowledge graph (KG) reasoning is an important problem for knowledge graphs.
It predicts missing links by reasoning on existing facts. Knowledge graph
embedding (KGE) is one of the most popular methods to address this problem. It
embeds entities and relations into low-dimensional vectors and uses the learned
entity/relation embeddings to predict missing facts. However, KGE only uses
zeroth-order (propositional) logic to encode existing triplets (e.g., ``Alice
is Bob's wife.""); it is unable to leverage first-order (predicate) logic to
represent generally applicable logical \textbf{rules} (e.g., ``$\forall x,y
\colon x ~\text{is}~ y\text{'s wife} \rightarrow y ~\text{is}~ x\text{'s
husband}$''). On the other hand, traditional rule-based KG reasoning methods
usually rely on hard logical rule inference, making it brittle and hardly
competitive with KGE. In this paper, we propose RulE, a novel and principled
framework to represent and model logical rules and triplets. RulE jointly
represents entities, relations and logical rules in a unified embedding space.
By learning an embedding for each logical rule, RulE can perform logical rule
inference in a soft way and give a confidence score to each grounded rule,
similar to how KGE gives each triplet a confidence score. Compared to KGE
alone, RulE allows injecting prior logical rule information into the embedding
space, which improves the generalization of knowledge graph embedding. Besides,
the learned confidence scores of rules improve the logical rule inference
process by softly controlling the contribution of each rule, which alleviates
the brittleness of logic. We evaluate our method with link prediction tasks.
Experimental results on multiple benchmark KGs demonstrate the effectiveness of
RulE.",-0.08826633,-0.19063526,-0.31941664,A
13069,"More interestingly, even though no
significant difference was detected in initial trust between expert and novice readers, the novice
readers reported both a significant increase in trust as well as a significantly higher final trust

4This is an effect that is not entirely trivial and calls for further study to understand its causes.","well over the average
accuracy of the readers, and thus likely to lead to a positive interaction for the study participants
and hence an increased sense of trust in the decision support.",than the expert readers.,2022-10-27 07:47:50+00:00,Painting the black box white: experimental findings from applying XAI to an ECG reading setting,cs.AI,"['cs.AI', 'I.2.1; H.5.2']","[arxiv.Result.Author('Federico Cabitza'), arxiv.Result.Author('Matteo Cameli'), arxiv.Result.Author('Andrea Campagner'), arxiv.Result.Author('Chiara Natali'), arxiv.Result.Author('Luca Ronzio')]","The shift from symbolic AI systems to black-box, sub-symbolic, and
statistical ones has motivated a rapid increase in the interest toward
explainable AI (XAI), i.e. approaches to make black-box AI systems explainable
to human decision makers with the aim of making these systems more acceptable
and more usable tools and supports. However, we make the point that, rather
than always making black boxes transparent, these approaches are at risk of
\emph{painting the black boxes white}, thus failing to provide a level of
transparency that would increase the system's usability and comprehensibility;
or, even, at risk of generating new errors, in what we termed the
\emph{white-box paradox}. To address these usability-related issues, in this
work we focus on the cognitive dimension of users' perception of explanations
and XAI systems. To this aim, we designed and conducted a questionnaire-based
experiment by which we involved 44 cardiology residents and specialists in an
AI-supported ECG reading task. In doing so, we investigated different research
questions concerning the relationship between users' characteristics (e.g.
expertise) and their perception of AI and XAI systems, including their trust,
the perceived explanations' quality and their tendency to defer the decision
process to automation (i.e. technology dominance), as well as the mutual
relationships among these different dimensions. Our findings provide a
contribution to the evaluation of AI-based support systems from a Human-AI
interaction-oriented perspective and lay the ground for further investigation
of XAI and its effects on decision making and user experience.",-0.31899017,-0.10944417,0.33600157,A
13070,"Despite the relevance of these results, we remark however that further research should address
whether this correlation also holds in the case of placebic information (i.e.","In turn, such an effect could motivate the
emergence of biases and cognitive effects associated with automation, and especially so with
those that are directly related to the role of XAI, as in the case of the white-box paradox [18, 19].","not semantically
sensible, nor structurally consistent) as described by Langer [17], translating this effort from
the interpersonal dimension to that of Human-Computer Interaction.",2022-10-27 07:47:50+00:00,Painting the black box white: experimental findings from applying XAI to an ECG reading setting,cs.AI,"['cs.AI', 'I.2.1; H.5.2']","[arxiv.Result.Author('Federico Cabitza'), arxiv.Result.Author('Matteo Cameli'), arxiv.Result.Author('Andrea Campagner'), arxiv.Result.Author('Chiara Natali'), arxiv.Result.Author('Luca Ronzio')]","The shift from symbolic AI systems to black-box, sub-symbolic, and
statistical ones has motivated a rapid increase in the interest toward
explainable AI (XAI), i.e. approaches to make black-box AI systems explainable
to human decision makers with the aim of making these systems more acceptable
and more usable tools and supports. However, we make the point that, rather
than always making black boxes transparent, these approaches are at risk of
\emph{painting the black boxes white}, thus failing to provide a level of
transparency that would increase the system's usability and comprehensibility;
or, even, at risk of generating new errors, in what we termed the
\emph{white-box paradox}. To address these usability-related issues, in this
work we focus on the cognitive dimension of users' perception of explanations
and XAI systems. To this aim, we designed and conducted a questionnaire-based
experiment by which we involved 44 cardiology residents and specialists in an
AI-supported ECG reading task. In doing so, we investigated different research
questions concerning the relationship between users' characteristics (e.g.
expertise) and their perception of AI and XAI systems, including their trust,
the perceived explanations' quality and their tendency to defer the decision
process to automation (i.e. technology dominance), as well as the mutual
relationships among these different dimensions. Our findings provide a
contribution to the evaluation of AI-based support systems from a Human-AI
interaction-oriented perspective and lay the ground for further investigation
of XAI and its effects on decision making and user experience.",-0.13562123,-0.1447191,0.3725078,A
13071,"That said, two main areas where further research could extend
similar studies regard the stratification by explanation types, and the analysis of the impact of
explanations on the readers‚Äô confidence.","However, the study regards a serious game where the doctors involved knew no harm could
be caused to real patients.","On one hand, explanations should be distinguished
according to a reference taxonomy, for instance those recently proposed in [34, 35, 36, 14], to see
if different types of explanations can have different effects on decision making: we recall that in
this study we focused on textual explanations of justificatory and causal kind [14].",2022-10-27 07:47:50+00:00,Painting the black box white: experimental findings from applying XAI to an ECG reading setting,cs.AI,"['cs.AI', 'I.2.1; H.5.2']","[arxiv.Result.Author('Federico Cabitza'), arxiv.Result.Author('Matteo Cameli'), arxiv.Result.Author('Andrea Campagner'), arxiv.Result.Author('Chiara Natali'), arxiv.Result.Author('Luca Ronzio')]","The shift from symbolic AI systems to black-box, sub-symbolic, and
statistical ones has motivated a rapid increase in the interest toward
explainable AI (XAI), i.e. approaches to make black-box AI systems explainable
to human decision makers with the aim of making these systems more acceptable
and more usable tools and supports. However, we make the point that, rather
than always making black boxes transparent, these approaches are at risk of
\emph{painting the black boxes white}, thus failing to provide a level of
transparency that would increase the system's usability and comprehensibility;
or, even, at risk of generating new errors, in what we termed the
\emph{white-box paradox}. To address these usability-related issues, in this
work we focus on the cognitive dimension of users' perception of explanations
and XAI systems. To this aim, we designed and conducted a questionnaire-based
experiment by which we involved 44 cardiology residents and specialists in an
AI-supported ECG reading task. In doing so, we investigated different research
questions concerning the relationship between users' characteristics (e.g.
expertise) and their perception of AI and XAI systems, including their trust,
the perceived explanations' quality and their tendency to defer the decision
process to automation (i.e. technology dominance), as well as the mutual
relationships among these different dimensions. Our findings provide a
contribution to the evaluation of AI-based support systems from a Human-AI
interaction-oriented perspective and lay the ground for further investigation
of XAI and its effects on decision making and user experience.",-0.41183463,-0.27422357,0.3454556,A
13072,"For this reason, further research should be aimed at investigating also the
confidence construct, and its relationship with perceived user experience and satisfaction.","], where preliminary results
suggest that (visual) explanations may paradoxically make users (slightly) less confident in
their final decision.",5.,2022-10-27 07:47:50+00:00,Painting the black box white: experimental findings from applying XAI to an ECG reading setting,cs.AI,"['cs.AI', 'I.2.1; H.5.2']","[arxiv.Result.Author('Federico Cabitza'), arxiv.Result.Author('Matteo Cameli'), arxiv.Result.Author('Andrea Campagner'), arxiv.Result.Author('Chiara Natali'), arxiv.Result.Author('Luca Ronzio')]","The shift from symbolic AI systems to black-box, sub-symbolic, and
statistical ones has motivated a rapid increase in the interest toward
explainable AI (XAI), i.e. approaches to make black-box AI systems explainable
to human decision makers with the aim of making these systems more acceptable
and more usable tools and supports. However, we make the point that, rather
than always making black boxes transparent, these approaches are at risk of
\emph{painting the black boxes white}, thus failing to provide a level of
transparency that would increase the system's usability and comprehensibility;
or, even, at risk of generating new errors, in what we termed the
\emph{white-box paradox}. To address these usability-related issues, in this
work we focus on the cognitive dimension of users' perception of explanations
and XAI systems. To this aim, we designed and conducted a questionnaire-based
experiment by which we involved 44 cardiology residents and specialists in an
AI-supported ECG reading task. In doing so, we investigated different research
questions concerning the relationship between users' characteristics (e.g.
expertise) and their perception of AI and XAI systems, including their trust,
the perceived explanations' quality and their tendency to defer the decision
process to automation (i.e. technology dominance), as well as the mutual
relationships among these different dimensions. Our findings provide a
contribution to the evaluation of AI-based support systems from a Human-AI
interaction-oriented perspective and lay the ground for further investigation
of XAI and its effects on decision making and user experience.",-0.3404649,-0.25960433,0.32922062,A
13096,"Though
super-ball-separation is clearly too idealistic, but in practice we encounter sit-
uations where in fact the datapoints outside of a strict cluster core are sparse
so that an extension of this concept to an approximated one seems to be an in-
teresting area of further research.","The super-ball-clustering is very rare case for real world applications and its
usefulness is Ô¨Årst of all of theoretical nature, that is to show that a sound ax-
iomatic system can be created, contrary to general opinion in literature.","The sound axiomatic crisp case, investigated
here, may be a good starting point for creating sound approximate deÔ¨Ånitions
for clustering function and clustering axioms.",2022-10-27 14:39:48+00:00,How To Overcome Richness Axiom Fallacy,cs.AI,['cs.AI'],"[arxiv.Result.Author('Mieczys≈Çaw A. K≈Çopotek'), arxiv.Result.Author('Robert A. K≈Çopotek')]","The paper points at the grieving problems implied by the richness axiom in
the Kleinberg's axiomatic system and suggests resolutions. The richness induces
learnability problem in general and leads to conflicts with consistency axiom.
As a resolution, learnability constraints and usage of centric consistency or
restriction of the domain of considered clusterings to super-ball-clusterings
is proposed.",-0.047193084,0.13350892,-0.15765063,B
13123,"Finally, Sections 6 and 7 present poten-    became apparent, NeSy has recently ushered in its
   tial valuable directions for further research and    renaissance in the research community.","Nevertheless, as the shortcomings of DNNs
   of NeSy.",conclude the survey.,2022-10-28 04:38:10+00:00,Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on Neuro-Symbolic Computing,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Wenguan Wang'), arxiv.Result.Author('Yi Yang')]","Neural-symbolic computing (NeSy), which pursues the integration of the
symbolic and statistical paradigms of cognition, has been an active research
area of Artificial Intelligence (AI) for many years. As NeSy shows promise of
reconciling the advantages of reasoning and interpretability of symbolic
representation and robust learning in neural networks, it may serve as a
catalyst for the next generation of AI. In the present paper, we provide a
systematic overview of the important and recent developments of research on
NeSy AI. Firstly, we introduce study history and background concepts of this
area. Afterward, we categorize recent approaches along several main
characteristics that underline this research paradigm, including
neural-symbolic interrelation, neural architecture, knowledge representation,
and functionality. Then, we briefly discuss the successful application of
modern NeSy approaches in several domains. Finally, we identify the open
problems together with potential future research directions.",0.02517178,-0.23800156,-0.08637199,C
13124,"valuable directions for further research and conclude the
                                                                 survey.","Finally, Sections 6 and 7 present potential
soning [22].","We hope that this survey will help newcomers and
    In order to facilitate readers to catch up on the rapidly-   practitioners to navigate in this massive Ô¨Åeld which gained
developing evolution of this Ô¨Åeld, this paper offers a system-   signiÔ¨Åcant momentum in the past few years, as well as
atical and timely collection of recent important literature on   provide AI community background in generating future
NeSy, with particular attention to the past Ô¨Åve years.",2022-10-28 04:38:10+00:00,Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on Neuro-Symbolic Computing,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Wenguan Wang'), arxiv.Result.Author('Yi Yang')]","Neural-symbolic computing (NeSy), which pursues the integration of the
symbolic and statistical paradigms of cognition, has been an active research
area of Artificial Intelligence (AI) for many years. As NeSy shows promise of
reconciling the advantages of reasoning and interpretability of symbolic
representation and robust learning in neural networks, it may serve as a
catalyst for the next generation of AI. In the present paper, we provide a
systematic overview of the important and recent developments of research on
NeSy AI. Firstly, we introduce study history of this area, covering early work
and foundations. We further discuss background concepts and identify key
driving factors behind the development of NeSy. Afterward, we categorize recent
landmark approaches along several main characteristics that underline this
research paradigm, including neural-symbolic integration, knowledge
representation, knowledge embedding, and functionality. Then, we briefly
discuss the successful application of modern NeSy approaches in several
domains. Finally, we identify the open problems together with potential future
research directions. This survey is expected to help new researchers enter this
rapidly-developing field and accelerate progress towards data-and
knowledge-driven AI.",0.27295148,-0.111269124,0.114685625,C
13125,"valuable directions for further research and conclude the
                                                                 survey.","Finally, Sections 6 and 7 present potential
soning [22].","We hope that this survey will help newcomers and
    In order to facilitate readers to catch up on the rapidly-   practitioners to navigate in this massive Ô¨Åeld which gained
developing evolution of this Ô¨Åeld, this paper offers a system-   signiÔ¨Åcant momentum in the past few years, as well as
atical and timely collection of recent important literature on   provide AI community background in generating future
NeSy, with particular attention to the past Ô¨Åve years.",2022-10-28 04:38:10+00:00,Towards Data-and Knowledge-Driven Artificial Intelligence: A Survey on Neuro-Symbolic Computing,cs.AI,"['cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Wenguan Wang'), arxiv.Result.Author('Yi Yang'), arxiv.Result.Author('Fei Wu')]","Neural-symbolic computing (NeSy), which pursues the integration of the
symbolic and statistical paradigms of cognition, has been an active research
area of Artificial Intelligence (AI) for many years. As NeSy shows promise of
reconciling the advantages of reasoning and interpretability of symbolic
representation and robust learning in neural networks, it may serve as a
catalyst for the next generation of AI. In the present paper, we provide a
systematic overview of the important and recent developments of research on
NeSy AI. Firstly, we introduce study history of this area, covering early work
and foundations. We further discuss background concepts and identify key
driving factors behind the development of NeSy. Afterward, we categorize recent
landmark approaches along several main characteristics that underline this
research paradigm, including neural-symbolic integration, knowledge
representation, knowledge embedding, and functionality. Then, we briefly
discuss the successful application of modern NeSy approaches in several
domains. Finally, we identify the open problems together with potential future
research directions. This survey is expected to help new researchers enter this
rapidly-developing field and accelerate progress towards data-and
knowledge-driven AI.",0.27295157,-0.111269,0.114685655,C
13239,"[130] proposed a stacking fusion algorithm framework fo
the early warning and diagnosis of offshore DFIG (as shown in Figure 11); a fault-tolerant operation is worthy
of further research.","Because of the lack of early warning time and faul
samples of the offshore SCADA system, Wei et al.",Zhang et al.,2022-11-01 02:09:51+00:00,"Review on Monitoring, Operation and Maintenance of Smart Offshore Wind Farms",cs.AI,"['cs.AI', 'cs.SY', 'eess.SY', '90B25', 'I.2']","[arxiv.Result.Author('Lei Kou'), arxiv.Result.Author('Yang Li'), arxiv.Result.Author('Fangfang Zhang'), arxiv.Result.Author('Xiaodong Gong'), arxiv.Result.Author('Yinghong Hu'), arxiv.Result.Author('Quande Yuan'), arxiv.Result.Author('Wende Ke')]","In recent years, with the development of wind energy, the number and scale of
wind farms are developing rapidly. Since offshore wind farm has the advantages
of stable wind speed, clean, renewable, non-polluting and no occupation of
cultivated land, which has gradually become a new trend of wind power industry
all over the world. The operation and maintenance mode of offshore wind power
is developing in the direction of digitization and intelligence. It is of great
significance to carry out the research on the monitoring, operation and
maintenance of offshore wind farm, which will be of benefits to reduce the
operation and maintenance cost, improve the power generation efficiency,
improve the stability of offshore wind farm system and build smart offshore
wind farm. This paper will mainly analyze and summarize the monitoring,
operation and maintenance of offshore wind farm, especially from the following
points: monitoring of ""offshore wind power engineering & biological &
environment"", the monitoring of power equipment and the operation & maintenance
of smart offshore wind farms. Finally, the future research challenges about
monitoring, operation and maintenance of smart offshore wind farm are proposed,
and the future research directions in this field are prospected.",-0.13894382,0.26597476,-0.1733312,B
13240,"In order to ensure the safe and efficient operation o
smart offshore wind farms, it is of great significance to conduct further research on state monitoring and faul
diagnosis for generators.","With large-scale wind turbines put into
operation, the number of generator faults increases.",Figure 11.,2022-11-01 02:09:51+00:00,"Review on Monitoring, Operation and Maintenance of Smart Offshore Wind Farms",cs.AI,"['cs.AI', 'cs.SY', 'eess.SY', '90B25', 'I.2']","[arxiv.Result.Author('Lei Kou'), arxiv.Result.Author('Yang Li'), arxiv.Result.Author('Fangfang Zhang'), arxiv.Result.Author('Xiaodong Gong'), arxiv.Result.Author('Yinghong Hu'), arxiv.Result.Author('Quande Yuan'), arxiv.Result.Author('Wende Ke')]","In recent years, with the development of wind energy, the number and scale of
wind farms are developing rapidly. Since offshore wind farm has the advantages
of stable wind speed, clean, renewable, non-polluting and no occupation of
cultivated land, which has gradually become a new trend of wind power industry
all over the world. The operation and maintenance mode of offshore wind power
is developing in the direction of digitization and intelligence. It is of great
significance to carry out the research on the monitoring, operation and
maintenance of offshore wind farm, which will be of benefits to reduce the
operation and maintenance cost, improve the power generation efficiency,
improve the stability of offshore wind farm system and build smart offshore
wind farm. This paper will mainly analyze and summarize the monitoring,
operation and maintenance of offshore wind farm, especially from the following
points: monitoring of ""offshore wind power engineering & biological &
environment"", the monitoring of power equipment and the operation & maintenance
of smart offshore wind farms. Finally, the future research challenges about
monitoring, operation and maintenance of smart offshore wind farm are proposed,
and the future research directions in this field are prospected.",-0.13821614,0.18676516,-0.07577306,B
13242,"https://doi.org/10.1109/BigData52589.2021.9671745

   Another open question left to further research is to take into                       [12] European Commission, Content Directorate-General for Communications Net-
account that the definition of explainability metrics may lead to                             works, and Technology.",2712‚Äì2720.,2019.,2022-11-01 03:04:25+00:00,Evaluation Metrics for Symbolic Knowledge Extracted from Machine Learning Black Boxes: A Discussion Paper,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Federico Sabbatini'), arxiv.Result.Author('Roberta Calegari')]","As opaque decision systems are being increasingly adopted in almost any
application field, issues about their lack of transparency and human
readability are a concrete concern for end-users. Amongst existing proposals to
associate human-interpretable knowledge with accurate predictions provided by
opaque models, there are rule extraction techniques, capable of extracting
symbolic knowledge out of an opaque model. However, how to assess the level of
readability of the extracted knowledge quantitatively is still an open issue.
Finding such a metric would be the key, for instance, to enable automatic
comparison between a set of different knowledge representations, paving the way
for the development of parameter autotuning algorithms for knowledge
extractors. In this paper we discuss the need for such a metric as well as the
criticalities of readability assessment and evaluation, taking into account the
most common knowledge representations while highlighting the most puzzling
issues.",-0.40143305,-0.11268802,0.06679216,A
13283,"The unstructured information in historical defect texts was transformed into
structured information, and defect components and attributes were extracted for further research.","proposed a deep semantic scheme of defect mining based on ‚ÄòSemantic Frame Slot
Filling‚Äô (SF-SF) [35].",Sheng et al.,2022-11-02 05:57:05+00:00,A survey on the development status and application prospects of knowledge graph in smart grids,cs.AI,"['cs.AI', '68T30', 'I.2']","[arxiv.Result.Author('Jian Wang'), arxiv.Result.Author('Xi Wang'), arxiv.Result.Author('Chaoqun Ma'), arxiv.Result.Author('Lei Kou')]","With the advent of the electric power big data era, semantic interoperability
and interconnection of power data have received extensive attention. Knowledge
graph technology is a new method describing the complex relationships between
concepts and entities in the objective world, which is widely concerned because
of its robust knowledge inference ability. Especially with the proliferation of
measurement devices and exponential growth of electric power data empowers,
electric power knowledge graph provides new opportunities to solve the
contradictions between the massive power resources and the continuously
increasing demands for intelligent applications. In an attempt to fulfil the
potential of knowledge graph and deal with the various challenges faced, as
well as to obtain insights to achieve business applications of smart grids,
this work first presents a holistic study of knowledge-driven intelligent
application integration. Specifically, a detailed overview of electric power
knowledge mining is provided. Then, the overview of the knowledge graph in
smart grids is introduced. Moreover, the architecture of the big knowledge
graph platform for smart grids and critical technologies are described.
Furthermore, this paper comprehensively elaborates on the application prospects
leveraged by knowledge graph oriented to smart grids, power consumer service,
decision-making in dispatching, and operation and maintenance of power
equipment. Finally, issues and challenges are summarised.",-0.10754349,-0.13241656,-0.24410951,A
13552,"Since only the aleatoric uncertainty is considered for the experiments,
capturing both the epistemic and the aleatoric uncertainty together serves as a
promising further research.","On the basis of the obtained results, a number of interesting findings invokes possible
future researches.","Another promising topic for a further analysis concerns
extracting more relevant information from the databases, as the corresponding results
showed that datasets that provide additional context or information layer to the data can
help forecasting model improve their performance.",2022-11-09 15:42:33+00:00,Workload Forecasting of a Logistic Node Using Bayesian Neural Networks,cs.AI,['cs.AI'],"[arxiv.Result.Author('Emin Nakilcioglu'), arxiv.Result.Author('Anisa Rizvanolli und Olaf Rendel')]","Purpose: Traffic volume in empty container depots has been highly volatile
due to external factors. Forecasting the expected container truck traffic along
with having a dynamic module to foresee the future workload plays a critical
role in improving the work efficiency. This paper studies the relevant
literature and designs a forecasting model addressing the aforementioned
issues. Methodology: The paper develops a forecasting model to predict hourly
work and traffic volume of container trucks in an empty container depot using a
Bayesian Neural Network based model. Furthermore, the paper experiments with
datasets with different characteristics to assess the model's forecasting range
for various data sources. Findings: The real data of an empty container depot
is utilized to develop a forecasting model and to later verify the capabilities
of the model. The findings show the performance validity of the model and
provide the groundwork to build an effective traffic and workload planning
system for the empty container depot in question. Originality: This paper
proposes a Bayesian deep learning-based forecasting model for traffic and
workload of an empty container depot using real-world data. This designed and
implemented forecasting model offers a solution with which every actor in the
container truck transportation benefits from the optimized workload.",-0.21675332,0.0050179902,0.033306006,A
13579,"As a future direction
for further study, we may work on a more promising mutation.","The obtained results on different real-world datasets and their statistical analysis
showed a significant improvement compared to state-of-the-art methods.","Moreover, to have a better
initialization for the proposed algorithm, it is a good idea if we firstly rank the features and
select the top-ranked ones as the current and candidate individuals.",2022-11-10 08:56:48+00:00,A metaheuristic multi-objective interaction-aware feature selection method,cs.AI,['cs.AI'],"[arxiv.Result.Author('Motahare Namakin'), arxiv.Result.Author('Modjtaba Rouhani'), arxiv.Result.Author('Mostafa Sabzekar')]","Multi-objective feature selection is one of the most significant issues in
the field of pattern recognition. It is challenging because it maximizes the
classification performance and, at the same time, minimizes the number of
selected features, and the mentioned two objectives are usually conflicting. To
achieve a better Pareto optimal solution, metaheuristic optimization methods
are widely used in many studies. However, the main drawback is the exploration
of a large search space. Another problem with multi-objective feature selection
approaches is the interaction between features. Selecting correlated features
has negative effect on classification performance. To tackle these problems, we
present a novel multi-objective feature selection method that has several
advantages. Firstly, it considers the interaction between features using an
advanced probability scheme. Secondly, it is based on the Pareto Archived
Evolution Strategy (PAES) method that has several advantages such as simplicity
and its speed in exploring the solution space. However, we improve the
structure of PAES in such a way that generates the offsprings, intelligently.
Thus, the proposed method utilizes the introduced probability scheme to produce
more promising offsprings. Finally, it is equipped with a novel strategy that
guides it to find the optimum number of features through the process of
evolution. The experimental results show a significant improvement in finding
the optimal Pareto front compared to state-of-the-art methods on different
real-world datasets.",0.10131412,0.023764096,-0.25330403,C
13588,"Finally, we discuss
the practical relevance of such an agent using the examples of day-ahead planning and real-time
remedial action recommendation, and outline promising further research directions.","We benchmark our topology agent on a 118 substation power grid and demonstrate how
to successfully combine it with traditional congestion management measures.","2 Environment Design and Interaction WorkÔ¨Çow

This section describes the power grid environment, its observation and action spaces, reward as well
as custom modules.",2022-11-10 14:39:28+00:00,Power Grid Congestion Management via Topology Optimization with AlphaZero,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Matthias Dorfer'), arxiv.Result.Author('Anton R. Fuxj√§ger'), arxiv.Result.Author('Kristian Kozak'), arxiv.Result.Author('Patrick M. Blies'), arxiv.Result.Author('Marcel Wasserer')]","The energy sector is facing rapid changes in the transition towards clean
renewable sources. However, the growing share of volatile, fluctuating
renewable generation such as wind or solar energy has already led to an
increase in power grid congestion and network security concerns. Grid operators
mitigate these by modifying either generation or demand (redispatching,
curtailment, flexible loads). Unfortunately, redispatching of fossil generators
leads to excessive grid operation costs and higher emissions, which is in
direct opposition to the decarbonization of the energy sector. In this paper,
we propose an AlphaZero-based grid topology optimization agent as a non-costly,
carbon-free congestion management alternative. Our experimental evaluation
confirms the potential of topology optimization for power grid operation,
achieves a reduction of the average amount of required redispatching by 60%,
and shows the interoperability with traditional congestion management methods.
Our approach also ranked 1st in the WCCI 2022 Learning to Run a Power Network
(L2RPN) competition. Based on our findings, we identify and discuss open
research problems as well as technical challenges for a productive system on a
real power grid.",0.12800092,0.35403365,0.20428254,B
13632,"Thus, we further study
whether DASBE can bind hierarchical features in time.","4.2.4 Hierarchical binding in DASBE
Features in both the brain and ANNs has a hierarchical organization.","To verify it in shape dataset, we realized a
spiking latent coding space (Fig.4c) in the DAE by making T a Bernoulli sampling process (Sec3.3;
Alg1).",2022-11-11 06:47:54+00:00,Dance of SNN and ANN: Solving binding problem by combining spike timing and reconstructive attention,cs.AI,"['cs.AI', 'cs.CV']","[arxiv.Result.Author('Hao Zheng'), arxiv.Result.Author('Hui Lin'), arxiv.Result.Author('Rong Zhao'), arxiv.Result.Author('Luping Shi')]","The binding problem is one of the fundamental challenges that prevent the
artificial neural network (ANNs) from a compositional understanding of the
world like human perception, because disentangled and distributed
representations of generative factors can interfere and lead to ambiguity when
complex data with multiple objects are presented. In this paper, we propose a
brain-inspired hybrid neural network (HNN) that introduces temporal binding
theory originated from neuroscience into ANNs by integrating spike timing
dynamics (via spiking neural networks, SNNs) with reconstructive attention (by
ANNs). Spike timing provides an additional dimension for grouping, while
reconstructive feedback coordinates the spikes into temporal coherent states.
Through iterative interaction of ANN and SNN, the model continuously binds
multiple objects at alternative synchronous firing times in the SNN coding
space. The effectiveness of the model is evaluated on synthetic datasets of
binary images. By visualization and analysis, we demonstrate that the binding
is explainable, soft, flexible, and hierarchical. Notably, the model is trained
on single object datasets without explicit supervision on grouping, but
successfully binds multiple objects on test datasets, showing its compositional
generalization capability. Further results show its binding ability in dynamic
situations.",0.13837484,-0.004449308,-0.21187986,C
13633,"4.2.5 Binding in moving situation
We further study whether the simple DASBE can bind in dynamic situation.","It is interesting
to note that a hierarchy tree of features of different levels can be readout by following such spiking
synchrony.","To verify, we generate
the moving shape dataset (Fig.5), where each object can move along a Ô¨Åxed direction during the
experiment with a constant speed (1 pixel per delay period) .",2022-11-11 06:47:54+00:00,Dance of SNN and ANN: Solving binding problem by combining spike timing and reconstructive attention,cs.AI,"['cs.AI', 'cs.CV']","[arxiv.Result.Author('Hao Zheng'), arxiv.Result.Author('Hui Lin'), arxiv.Result.Author('Rong Zhao'), arxiv.Result.Author('Luping Shi')]","The binding problem is one of the fundamental challenges that prevent the
artificial neural network (ANNs) from a compositional understanding of the
world like human perception, because disentangled and distributed
representations of generative factors can interfere and lead to ambiguity when
complex data with multiple objects are presented. In this paper, we propose a
brain-inspired hybrid neural network (HNN) that introduces temporal binding
theory originated from neuroscience into ANNs by integrating spike timing
dynamics (via spiking neural networks, SNNs) with reconstructive attention (by
ANNs). Spike timing provides an additional dimension for grouping, while
reconstructive feedback coordinates the spikes into temporal coherent states.
Through iterative interaction of ANN and SNN, the model continuously binds
multiple objects at alternative synchronous firing times in the SNN coding
space. The effectiveness of the model is evaluated on synthetic datasets of
binary images. By visualization and analysis, we demonstrate that the binding
is explainable, soft, flexible, and hierarchical. Notably, the model is trained
on single object datasets without explicit supervision on grouping, but
successfully binds multiple objects on test datasets, showing its compositional
generalization capability. Further results show its binding ability in dynamic
situations.",0.09270544,0.082945265,-0.19472483,C
13655,"We also mapped out the
approximated distances between each target domain and                                                       To more systematically use capabilities, further research
the source domain, using a proxy ùíú-distance [28].","Challenges and Opportunities
generalize to further domains.",As in                                                     is needed.,2022-11-11 18:50:21+00:00,Capabilities for Better ML Engineering,cs.AI,"['cs.AI', 'cs.SE']","[arxiv.Result.Author('Chenyang Yang'), arxiv.Result.Author('Rachel Brower-Sinning'), arxiv.Result.Author('Grace A. Lewis'), arxiv.Result.Author('Christian K√§stner'), arxiv.Result.Author('Tongshuang Wu')]","In spite of machine learning's rapid growth, its engineering support is
scattered in many forms, and tends to favor certain engineering stages,
stakeholders, and evaluation preferences. We envision a capability-based
framework, which uses fine-grained specifications for ML model behaviors to
unite existing efforts towards better ML engineering. We use concrete scenarios
(model design, debugging, and maintenance) to articulate capabilities' broad
applications across various different dimensions, and their impact on building
safer, more generalizable and more trustworthy models that reflect human needs.
Through preliminary experiments, we show capabilities' potential for reflecting
model generalizability, which can provide guidance for ML engineering process.
We discuss challenges and opportunities for capabilities' integration into ML
engineering.",-0.031227252,0.09848803,-0.1284158,A
13919,"Testing this approach com-
putationally is an interesting subject for further research, either in the context
of Wordle or more generally in the context of the adaptive control problem of
Section 4.","This can be done analytically or more likely by using
simulation-based methods such as particle Ô¨Åltering.","Bibliography

    [BeP22] Bertsimas D. and Paskov A., 2022.",2022-11-15 03:46:41+00:00,Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Siddhant Bhambri'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Dimitri Bertsekas')]","In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line.",0.0287629,0.4070443,0.087577455,B
13920,"Testing this approach com-
putationally is an interesting subject for further research, either in the context
of Wordle or more generally in the context of the adaptive control problem of
Section 4.","This can be done analytically or more likely by using
simulation-based methods such as particle Ô¨Åltering.","Bibliography

    [BeP22] Bertsimas D. and Paskov A., 2022.",2022-11-15 03:46:41+00:00,Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Siddhant Bhambri'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Dimitri Bertsekas')]","In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line.",0.0287629,0.4070443,0.087577455,B
13921,"Testing this approach com-
putationally is an interesting subject for further research, either in the context
of Wordle or more generally in the context of the adaptive control problem of
Section 4.","This can be done analytically or more likely by using
simulation-based methods such as particle Ô¨Åltering.","Bibliography

    [BeP22] Bertsimas D. and Paskov A., 2022.",2022-11-15 03:46:41+00:00,Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Siddhant Bhambri'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Dimitri Bertsekas')]","In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line.",0.0287629,0.4070443,0.087577455,B
13922,"Testing this approach com-
putationally is an interesting subject for further research, either in the context
of Wordle, or more generally in the context of the adaptive control problem of
Section 4.","This can be done analytically or more likely by using
simulation-based methods such as particle Ô¨Åltering.","An important direction for further research is the use of our methodology
in automated planning.",2022-11-15 03:46:41+00:00,Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Siddhant Bhambri'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Dimitri Bertsekas')]","In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line.",0.097507656,0.4375133,0.18612829,B_centroid
13923,"An important direction for further research is the use of our methodology
in automated planning.","Testing this approach com-
putationally is an interesting subject for further research, either in the context
of Wordle, or more generally in the context of the adaptive control problem of
Section 4.","For example, special types of POMDP involving a
fully observable state component, and a constant partially observable compo-
nent, have been investigated in a number of works on planning.",2022-11-15 03:46:41+00:00,Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control Approach,cs.AI,['cs.AI'],"[arxiv.Result.Author('Siddhant Bhambri'), arxiv.Result.Author('Amrita Bhattacharjee'), arxiv.Result.Author('Dimitri Bertsekas')]","In this paper we address the solution of the popular Wordle puzzle, using new
reinforcement learning methods, which apply more generally to adaptive control
of dynamic systems and to classes of Partially Observable Markov Decision
Process (POMDP) problems. These methods are based on approximation in value
space and the rollout approach, admit a straightforward implementation, and
provide improved performance over various heuristic approaches. For the Wordle
puzzle, they yield on-line solution strategies that are very close to optimal
at relatively modest computational cost. Our methods are viable for more
complex versions of Wordle and related search problems, for which an optimal
strategy would be impossible to compute. They are also applicable to a wide
range of adaptive sequential decision problems that involve an unknown or
frequently changing environment whose parameters are estimated on-line.",0.13471434,0.34856546,0.22477424,B
13934,"For
reproducibility and further research, our source code is public.6

4.2 Parameter Tuning

Our simulated annealing approach and our genetic algorithm require parame-
ters which we have to chosen carefully.","The experiments are
conducted on an Intel Xeon Gold 5122 CPU equipped with 300 GB RAM.","We provide recommendations based on

3 https://www.infosun.Ô¨Åm.uni-passau.de/~chris/down/MIP-1202.pdf
4 http://www.graphdrawing.org/data.html
5 http://minisat.se/MiniSat.html
6 https://github.com/domduerr/bipartite
8        D. D√ºrrschnabel et al.",2022-11-18 15:45:45+00:00,Discovering Locally Maximal Bipartite Subgraphs,cs.AI,"['cs.AI', 'math.CO', '90C27', 'G.2.1; F.2.2']","[arxiv.Result.Author('Dominik D√ºrrschnabel'), arxiv.Result.Author('Tom Hanika'), arxiv.Result.Author('Gerd Stumme')]","Induced bipartite subgraphs of maximal vertex cardinality are an essential
concept for the analysis of graphs. Yet, discovering them in large graphs is
known to be computationally hard. Therefore, we consider in this work a weaker
notion of this problem, where we discard the maximality constraint in favor of
inclusion maximality. Thus, we aim to discover locally maximal bipartite
subgraphs. For this, we present three heuristic approaches to extract such
subgraphs and compare their results to the solutions of the global problem. For
the latter, we employ the algorithmic strength of fast SAT-solvers. Our three
proposed heuristics are based on a greedy strategy, a simulated annealing
approach, and a genetic algorithm, respectively. We evaluate all four
algorithms with respect to their time requirement and the vertex cardinality of
the discovered bipartite subgraphs on several benchmark datasets",0.05110193,0.26222372,-0.2702659,B
13998,"Once this occurs, inactive molecules may be classiÔ¨Åed
as false positives, wasting time and important resources on further research.","Nevertheless, VS is imprecise and prone to producing inaccurate predictions,
much like several other in silico techniques.","Therefore, increasing
VS‚Äôs enrichment rates is still necessary.",2022-11-21 09:15:13+00:00,"Intelligent Computing: The Latest Advances, Challenges and Future",cs.AI,['cs.AI'],"[arxiv.Result.Author('Shiqiang Zhu'), arxiv.Result.Author('Ting Yu'), arxiv.Result.Author('Tao Xu'), arxiv.Result.Author('Hongyang Chen'), arxiv.Result.Author('Schahram Dustdar'), arxiv.Result.Author('Sylvain Gigan'), arxiv.Result.Author('Deniz Gunduz'), arxiv.Result.Author('Ekram Hossain'), arxiv.Result.Author('Yaochu Jin'), arxiv.Result.Author('Feng Lin'), arxiv.Result.Author('Bo Liu'), arxiv.Result.Author('Zhiguo Wan'), arxiv.Result.Author('Ji Zhang'), arxiv.Result.Author('Zhifeng Zhao'), arxiv.Result.Author('Wentao Zhu'), arxiv.Result.Author('Zuoning Chen'), arxiv.Result.Author('Tariq Durrani'), arxiv.Result.Author('Huaimin Wang'), arxiv.Result.Author('Jiangxing Wu'), arxiv.Result.Author('Tongyi Zhang'), arxiv.Result.Author('Yunhe Pan')]","Computing is a critical driving force in the development of human
civilization. In recent years, we have witnessed the emergence of intelligent
computing, a new computing paradigm that is reshaping traditional computing and
promoting digital revolution in the era of big data, artificial intelligence
and internet-of-things with new computing theories, architectures, methods,
systems, and applications. Intelligent computing has greatly broadened the
scope of computing, extending it from traditional computing on data to
increasingly diverse computing paradigms such as perceptual intelligence,
cognitive intelligence, autonomous intelligence, and human-computer fusion
intelligence. Intelligence and computing have undergone paths of different
evolution and development for a long time but have become increasingly
intertwined in recent years: intelligent computing is not only
intelligence-oriented but also intelligence-driven. Such cross-fertilization
has prompted the emergence and rapid advancement of intelligent computing.
Intelligent computing is still in its infancy and an abundance of innovations
in the theories, systems, and applications of intelligent computing are
expected to occur soon. We present the first comprehensive survey of literature
on intelligent computing, covering its theory fundamentals, the technological
fusion of intelligence and computing, important applications, challenges, and
future perspectives. We believe that this survey is highly timely and will
provide a comprehensive reference and cast valuable insights into intelligent
computing for academic and industrial researchers and practitioners.",-0.27287856,0.03545562,-0.067044705,A
14006,"The results obtained with the proposed
this definition, relations are often overlooked, i.e., they are usually           model on this challenging dataset are provided which could
assumed to be seen in the training set and hence are randomly                     be seen as a first attempt to facilitate further research in the
initialized or as in MLMLM [3], they could be encoded using their                 community on the topic of LP with unseen relations.",In               unseen relations.,"labels (corresponding text descriptions) but without learning repre-
sentations (embeddings) for them.",2022-11-21 12:35:30+00:00,RAILD: Towards Leveraging Relation Features for Inductive Link Prediction In Knowledge Graphs,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Genet Asefa Gesese'), arxiv.Result.Author('Harald Sack'), arxiv.Result.Author('Mehwish Alam')]","Due to the open world assumption, Knowledge Graphs (KGs) are never complete.
In order to address this issue, various Link Prediction (LP) methods are
proposed so far. Some of these methods are inductive LP models which are
capable of learning representations for entities not seen during training.
However, to the best of our knowledge, none of the existing inductive LP models
focus on learning representations for unseen relations. In this work, a novel
Relation Aware Inductive Link preDiction (RAILD) is proposed for KG completion
which learns representations for both unseen entities and unseen relations. In
addition to leveraging textual literals associated with both entities and
relations by employing language models, RAILD also introduces a novel
graph-based approach to generate features for relations. Experiments are
conducted with different existing and newly created challenging benchmark
datasets and the results indicate that RAILD leads to performance improvement
over the state-of-the-art models. Moreover, since there are no existing
inductive LP models which learn representations for unseen relations, we have
created our own baselines and the results obtained with RAILD also outperform
these baselines.",-0.06252794,-0.2615925,-0.2284455,A
14007,"As this is the first work, to the best
The models are trained for 40 epochs (80 epochs for models which          of our knowledge, to ever make an attempt to perform LP with un-
combine text and graph-based features for relations) with a batch         seen relations, it would facilitate further research in the community
size of 64 with WN18RR and FB15k-237, and 5 epochs with a batch           to redirect the focus to unseen relations as well as entities.",ing unseen graphs for training.,size of 128 with Wikidata5M.,2022-11-21 12:35:30+00:00,RAILD: Towards Leveraging Relation Features for Inductive Link Prediction In Knowledge Graphs,cs.AI,"['cs.AI', 'cs.CL']","[arxiv.Result.Author('Genet Asefa Gesese'), arxiv.Result.Author('Harald Sack'), arxiv.Result.Author('Mehwish Alam')]","Due to the open world assumption, Knowledge Graphs (KGs) are never complete.
In order to address this issue, various Link Prediction (LP) methods are
proposed so far. Some of these methods are inductive LP models which are
capable of learning representations for entities not seen during training.
However, to the best of our knowledge, none of the existing inductive LP models
focus on learning representations for unseen relations. In this work, a novel
Relation Aware Inductive Link preDiction (RAILD) is proposed for KG completion
which learns representations for both unseen entities and unseen relations. In
addition to leveraging textual literals associated with both entities and
relations by employing language models, RAILD also introduces a novel
graph-based approach to generate features for relations. Experiments are
conducted with different existing and newly created challenging benchmark
datasets and the results indicate that RAILD leads to performance improvement
over the state-of-the-art models. Moreover, since there are no existing
inductive LP models which learn representations for unseen relations, we have
created our own baselines and the results obtained with RAILD also outperform
these baselines.",0.0588006,-0.1581401,-0.36931577,C
14051,"We further study the failures in ‚ÄúFamily2‚Äù, and    kind of axiom depicts the part-of relation between types, e.g.","The Ô¨Årst
in ‚ÄúNifdys‚Äù.",‚àÉisPartOf.Chair ‚â° Seat Leg.,2022-11-22 04:54:20+00:00,Differentiable Fuzzy $\mathcal{ALC}$: A Neural-Symbolic Representation Language for Symbol Grounding,cs.AI,['cs.AI'],"[arxiv.Result.Author('Xuan Wu'), arxiv.Result.Author('Xinhao Zhu'), arxiv.Result.Author('Yizheng Zhao'), arxiv.Result.Author('Xinyu Dai')]","Neural-symbolic computing aims at integrating robust neural learning and
sound symbolic reasoning into a single framework, so as to leverage the
complementary strengths of both of these, seemingly unrelated (maybe even
contradictory) AI paradigms. The central challenge in neural-symbolic computing
is to unify the formulation of neural learning and symbolic reasoning into a
single framework with common semantics, that is, to seek a joint representation
between a neural model and a logical theory that can support the basic
grounding learned by the neural model and also stick to the semantics of the
logical theory. In this paper, we propose differentiable fuzzy $\mathcal{ALC}$
(DF-$\mathcal{ALC}$) for this role, as a neural-symbolic representation
language with the desired semantics. DF-$\mathcal{ALC}$ unifies the description
logic $\mathcal{ALC}$ and neural models for symbol grounding; in particular, it
infuses an $\mathcal{ALC}$ knowledge base into neural models through
differentiable concept and role embeddings. We define a hierarchical loss to
the constraint that the grounding learned by neural models must be semantically
consistent with $\mathcal{ALC}$ knowledge bases. And we find that capturing the
semantics in grounding solely by maximizing satisfiability cannot revise
grounding rationally. We further define a rule-based loss for DF adapting to
symbol grounding problems. The experiment results show that DF-$\mathcal{ALC}$
with rule-based loss can improve the performance of image object detectors in
an unsupervised learning way, even in low-resource situations.",-0.3184083,0.054379955,-0.09496039,A
14052,"We further study the failures in ‚ÄúFamily2‚Äù, and   both of them is to avoid the disturbance of unknown cases to
                                                               satisÔ¨Åability to knowledge.","The common and signiÔ¨Åcant problem for
in ‚ÄúNifdys‚Äù.",Ô¨Ånd that the failures are caused by unknown cases.,2022-11-22 04:54:20+00:00,Differentiable Fuzzy $\mathcal{ALC}$: A Neural-Symbolic Representation Language for Symbol Grounding,cs.AI,['cs.AI'],"[arxiv.Result.Author('Xuan Wu'), arxiv.Result.Author('Xinhao Zhu'), arxiv.Result.Author('Yizheng Zhao'), arxiv.Result.Author('Xinyu Dai')]","Neural-symbolic computing aims at integrating robust neural learning and
sound symbolic reasoning into a single framework, so as to leverage the
complementary strengths of both of these, seemingly unrelated (maybe even
contradictory) AI paradigms. The central challenge in neural-symbolic computing
is to unify the formulation of neural learning and symbolic reasoning into a
single framework with common semantics, that is, to seek a joint representation
between a neural model and a logical theory that can support the basic
grounding learned by the neural model and also stick to the semantics of the
logical theory. In this paper, we propose differentiable fuzzy $\mathcal{ALC}$
(DF-$\mathcal{ALC}$) for this role, as a neural-symbolic representation
language with the desired semantics. DF-$\mathcal{ALC}$ unifies the description
logic $\mathcal{ALC}$ and neural models for symbol grounding; in particular, it
infuses an $\mathcal{ALC}$ knowledge base into neural models through
differentiable concept and role embeddings. We define a hierarchical loss to
the constraint that the grounding learned by neural models must be semantically
consistent with $\mathcal{ALC}$ knowledge bases. And we find that capturing the
semantics in grounding solely by maximizing satisfiability cannot revise
grounding rationally. We further define a rule-based loss for DF adapting to
symbol grounding problems. The experiment results show that DF-$\mathcal{ALC}$
with rule-based loss can improve the performance of image object detectors in
an unsupervised learning way, even in low-resource situations.",-0.26083165,0.08902037,-0.10730019,A
14124,"We further study
two stronger methods of generating complete states: a model-based one that uses mutexes
and an ideal completion that only generates states that are reachable from the initial states
of interest.","Since it makes
no assumptions except the domains, we consider this strategy model-free.","The model-based method also assigns a random value s(v) ‚àà dom(v) to each undeÔ¨Åned
variable but excludes states that do not satisfy mutexes derived from the planning task.",2022-11-23 21:34:35+00:00,Understanding Sample Generation Strategies for Learning Heuristic Functions in Classical Planning,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('R. V. Bettker'), arxiv.Result.Author('P. P. Minini'), arxiv.Result.Author('A. G. Pereira'), arxiv.Result.Author('M. Ritt')]","We study the problem of learning good heuristic functions for classical
planning tasks with neural networks based on samples that are states with their
cost-to-goal estimates. It is well known that the learned model quality depends
on the training data quality. Our main goal is to understand better the
influence of sample generation strategies on the performance of a greedy
best-first heuristic search guided by a learned heuristic function. In a set of
controlled experiments, we find that two main factors determine the quality of
the learned heuristic: the regions of the state space included in the samples
and the quality of the cost-to-goal estimates. Also, these two factors are
interdependent: having perfect estimates of cost-to-goal is insufficient if an
unrepresentative part of the state space is included in the sample set.
Additionally, we study the effects of restricting samples to only include
states that could be evaluated when solving a given task and the effects of
adding samples with high-value estimates. Based on our findings, we propose
practical strategies to improve the quality of learned heuristics: three
strategies that aim to generate more representative states and two strategies
that improve the cost-to-goal estimates. Our resulting neural network heuristic
has higher coverage than a basic satisficing heuristic. Also, compared to a
baseline learned heuristic, our best neural network heuristic almost doubles
the mean coverage and can increase it for some domains by more than six times.",0.15628031,0.27983522,0.06035784,B
14164,"‚ÄúI am interested in writing forms and would one day like to learn some unusual scripts.‚Äù,
‚Äúinteresting learning to write another language‚Äù), but wished to learn more about the characters‚Äô
 meaning, motivating further research in making automatically-discovered skills (which may not
 necessarily be characters) more interpretable to students (e.g.","Meanwhile, students
 participating in the WRITING task students enjoyed the educational experience of learning a new
 script (e.g.","‚ÄúI would like to know what Balinese
 characters I‚Äôm tracing and their meaning‚Äù).",2022-11-25 10:18:29+00:00,Assistive Teaching of Motor Control Tasks to Humans,cs.AI,"['cs.AI', 'cs.HC', 'cs.RO']","[arxiv.Result.Author('Megha Srivastava'), arxiv.Result.Author('Erdem Biyik'), arxiv.Result.Author('Suvir Mirchandani'), arxiv.Result.Author('Noah Goodman'), arxiv.Result.Author('Dorsa Sadigh')]","Recent works on shared autonomy and assistive-AI technologies, such as
assistive robot teleoperation, seek to model and help human users with limited
ability in a fixed task. However, these approaches often fail to account for
humans' ability to adapt and eventually learn how to execute a control task
themselves. Furthermore, in applications where it may be desirable for a human
to intervene, these methods may inhibit their ability to learn how to succeed
with full self-control. In this paper, we focus on the problem of assistive
teaching of motor control tasks such as parking a car or landing an aircraft.
Despite their ubiquitous role in humans' daily activities and occupations,
motor tasks are rarely taught in a uniform way due to their high complexity and
variance. We propose an AI-assisted teaching algorithm that leverages skill
discovery methods from reinforcement learning (RL) to (i) break down any motor
control task into teachable skills, (ii) construct novel drill sequences, and
(iii) individualize curricula to students with different capabilities. Through
an extensive mix of synthetic and user studies on two motor control tasks --
parking a car with a joystick and writing characters from the Balinese alphabet
-- we show that assisted teaching with skills improves student performance by
around 40% compared to practicing full trajectories without skills, and
practicing with individualized drills can result in up to 25% further
improvement. Our source code is available at
https://github.com/Stanford-ILIAD/teaching",-0.030311635,-0.23721653,0.18622544,A
14394,"The introduction of disjunctive information in AFT points to a wealth of further research, such
as deÔ¨Åning three-valued and well-founded semantics for various disjunctive nonmonotonic formalisms
and studying on the basis of which operators various well-founded semantics for DLP can be repre-
sented in our framework.","The relations are
shown in Proposition 8 and Theorem 5.

    is thus at least twofold:

   1. allowing to deÔ¨Åne a family of semantics

       for non-monotonic reasoning with disjunctive information,

   2. clarifying similarities and diÔ¨Äerences between semantics stemming from the use of diÔ¨Äerent
       operators.","For example, our framework can potentially be used for deÔ¨Åning three-valued
and well-founded semantics for propositional theories [54], disjunctive logic programs with recursive
aggregates [26], logic programs with aggregates in the head [33], logic programs with forks [1], and
disjunctive default logics [32, 14].",2022-11-30 18:58:32+00:00,Non-Deterministic Approximation Fixpoint Theory and Its Application in Disjunctive Logic Programming,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jesse Heyninck'), arxiv.Result.Author('Ofer Arieli'), arxiv.Result.Author('Bart Bogaerts')]","Approximation fixpoint theory (AFT) is an abstract and general algebraic
framework for studying the semantics of nonmonotonic logics. It provides a
unifying study of the semantics of different formalisms for nonmonotonic
reasoning, such as logic programming, default logic and autoepistemic logic. In
this paper, we extend AFT to dealing with non-deterministic constructs that
allow to handle indefinite information, represented e.g. by disjunctive
formulas. This is done by generalizing the main constructions and corresponding
results of AFT to non-deterministic operators, whose ranges are sets of
elements rather than single elements. The applicability and usefulness of this
generalization is illustrated in the context of disjunctive logic programming.",-0.2934921,0.07106754,-0.1489144,A
14395,"The introduction of disjunctive information in AFT points to a wealth of further research, such
as deÔ¨Åning three-valued and well-founded semantics for various disjunctive nonmonotonic formalisms
and studying on the basis of which operators various well-founded semantics for DLP can be repre-
sented in our framework.","1. allowing to deÔ¨Åne a family of semantics for non-monotonic reasoning with disjunctive informa-
       tion,

   2. clarifying similarities and diÔ¨Äerences between semantics stemming from the use of diÔ¨Äerent
       operators.","For example, our framework can potentially be used for deÔ¨Åning three-valued
and well-founded semantics for propositional theories [54], disjunctive logic programs with recursive
aggregates [26], logic programs with aggregates in the head [33], logic programs with forks [1], and
disjunctive default logics [32, 14].",2022-11-30 18:58:32+00:00,Non-Deterministic Approximation Fixpoint Theory and Its Application in Disjunctive Logic Programming,cs.AI,['cs.AI'],"[arxiv.Result.Author('Jesse Heyninck'), arxiv.Result.Author('Ofer Arieli'), arxiv.Result.Author('Bart Bogaerts')]","Approximation fixpoint theory (AFT) is an abstract and general algebraic
framework for studying the semantics of nonmonotonic logics. It provides a
unifying study of the semantics of different formalisms for nonmonotonic
reasoning, such as logic programming, default logic and autoepistemic logic. In
this paper, we extend AFT to dealing with non-deterministic constructs that
allow to handle indefinite information, represented e.g. by disjunctive
formulas. This is done by generalizing the main constructions and corresponding
results of AFT to non-deterministic operators, whose ranges are sets of
elements rather than single elements. The applicability and usefulness of this
generalization is illustrated in the context of disjunctive logic programming.",-0.2659561,0.06752765,-0.15273423,A
14408,"Their other hypothesis was that, in cases where people voluntarily expose them-
selves to curiosity-inducing situations, they ‚Äúhave control over when they receive the missing
information‚Äù (Ruan et al., 2018, p. 560), which merits further study.","The very healthy industries producing puzzles, mysteries, and cliÔ¨Ä-
hanger-laden television series that we mentioned in Section 2.3 bring this hypothesis into
doubt.","Based on our computational case study, we suggest a novel hypothesis that voluntary
exposure might be learned via multiple experiences of curiosity being induced in similar
situations.",2022-12-01 00:18:56+00:00,Five Properties of Specific Curiosity You Didn't Know Curious Machines Should Have,cs.AI,"['cs.AI', 'cs.LG']","[arxiv.Result.Author('Nadia M. Ady'), arxiv.Result.Author('Roshan Shariff'), arxiv.Result.Author('Johannes G√ºnther'), arxiv.Result.Author('Patrick M. Pilarski')]","Curiosity for machine agents has been a focus of lively research activity.
The study of human and animal curiosity, particularly specific curiosity, has
unearthed several properties that would offer important benefits for machine
learners, but that have not yet been well-explored in machine intelligence. In
this work, we conduct a comprehensive, multidisciplinary survey of the field of
animal and machine curiosity. As a principal contribution of this work, we use
this survey as a foundation to introduce and define what we consider to be five
of the most important properties of specific curiosity: 1) directedness towards
inostensible referents, 2) cessation when satisfied, 3) voluntary exposure, 4)
transience, and 5) coherent long-term learning. As a second main contribution
of this work, we show how these properties may be implemented together in a
proof-of-concept reinforcement learning agent: we demonstrate how the
properties manifest in the behaviour of this agent in a simple non-episodic
grid-world environment that includes curiosity-inducing locations and induced
targets of curiosity. As we would hope, our example of a computational specific
curiosity agent exhibits short-term directed behaviour while updating long-term
preferences to adaptively seek out curiosity-inducing situations. This work,
therefore, presents a landmark synthesis and translation of specific curiosity
to the domain of machine learning and reinforcement learning and provides a
novel view into how specific curiosity operates and in the future might be
integrated into the behaviour of goal-seeking, decision-making computational
agents in complex environments.",-0.17308968,-0.16052474,0.39157808,A
14417,"Different from all above    subtree of RE2Tree(r) whose root is vertex t. Further, if
studies, we further study the one-to-one correspondence be-     vertex t represents a binary operator, we use Œ∑t to denote
tween parameters of a neural network and SOIREs.","Both of the above methods         tex t + 1 is the left child for any inner vertex t. We use
Ô¨Åne-tune initial regular expressions given from the expert      rt(1 ‚â§ t ‚â§ |r|) to denote the corresponding SOIRE of the
knowledge to obtain better results.",the sequential number of its right child.,2022-12-01 09:05:43+00:00,A Noise-tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving,cs.AI,['cs.AI'],"[arxiv.Result.Author('Rongzhen Ye'), arxiv.Result.Author('Tianqu Zhuang'), arxiv.Result.Author('Hai Wan'), arxiv.Result.Author('Jianfeng Du'), arxiv.Result.Author('Weilin Luo'), arxiv.Result.Author('Pingjia Liang')]","We examine the problem of learning a single occurrence regular expression
with interleaving (SOIRE) from a set of text strings with noise. SOIRE has
unrestricted support for interleaving and covers most of the regular
expressions in practice. Learning SOIREs is challenging because it needs heavy
computation and text strings usually contains noise in practice. Most of the
previous work only learns restricted SOIREs and is not robust on noisy data. To
tackle these issues, we proposea noise-tolerant differentiable learning
approach SOIREDL for SOIRE. We design a neural network to simulate SOIRE
matching of given text strings and theoretically prove that a class of the set
of parameters learnt by the neural network, called faithful encoding, is
one-to-one corresponding to SOIRE for a bounded size. Based on this
correspondence, we interpret the target SOIRE from the set of parameters of the
neural network by exploring nearest faithful encodings. Experimental results
show that SOIREDL outperforms the state-of-the-art approaches especially on
noisy data.",0.12645166,0.025740772,-0.387157,C
14418,"Different from all above    subtree of RE2Tree(r) whose root is vertex t. Further, if
studies, we further study the one-to-one correspondence be-     vertex t represents a binary operator, we use Œ∑t to denote
tween parameters of a neural network and SOIREs.","Both of the above methods         tex t + 1 is the left child for any inner vertex t. We use
Ô¨Åne-tune initial regular expressions given from the expert      rt(1 ‚â§ t ‚â§ |r|) to denote the corresponding SOIRE of the
knowledge to obtain better results.",the sequential number of its right child.,2022-12-01 09:05:43+00:00,A Noise-tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving,cs.AI,['cs.AI'],"[arxiv.Result.Author('Rongzhen Ye'), arxiv.Result.Author('Tianqu Zhuang'), arxiv.Result.Author('Hai Wan'), arxiv.Result.Author('Jianfeng Du'), arxiv.Result.Author('Weilin Luo'), arxiv.Result.Author('Pingjia Liang')]","We study the problem of learning a single occurrence regular expression with
interleaving (SOIRE) from a set of text strings possibly with noise. SOIRE
fully supports interleaving and covers a large portion of regular expressions
used in practice. Learning SOIREs is challenging because it requires heavy
computation and text strings usually contain noise in practice. Most of the
previous studies only learn restricted SOIREs and are not robust on noisy data.
To tackle these issues, we propose a noise-tolerant differentiable learning
approach SOIREDL for SOIRE. We design a neural network to simulate SOIRE
matching and theoretically prove that certain assignments of the set of
parameters learnt by the neural network, called faithful encodings, are
one-to-one corresponding to SOIREs for a bounded size. Based on this
correspondence, we interpret the target SOIRE from an assignment of the set of
parameters of the neural network by exploring the nearest faithful encodings.
Experimental results show that SOIREDL outperforms the state-of-the-art
approaches, especially on noisy data.",0.12645166,0.025740772,-0.387157,C
14640,"These
issues call for further research in the future.","While the system can gen-
erally respond to a simple question based on a single knowledge snippet, it often
makes mistakes given a context that requires sophisticated reasoning [102].","58
Chapter 5

Improving the computational
eÔ¨Éciency of large-scale response
retrieval

Large neural networks have been the state-of-the-art machine learning models in
recent years.",2022-11-14 17:27:07+00:00,From Knowledge Augmentation to Multi-tasking: Towards Human-like Dialogue Systems,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']",[arxiv.Result.Author('Tianji Yang')],"The goal of building dialogue agents that can converse with humans naturally
has been a long-standing dream of researchers since the early days of
artificial intelligence. The well-known Turing Test proposed to judge the
ultimate validity of an artificial intelligence agent on the
indistinguishability of its dialogues from humans'. It should come as no
surprise that human-level dialogue systems are very challenging to build. But,
while early effort on rule-based systems found limited success, the emergence
of deep learning enabled great advance on this topic.
  In this thesis, we focus on methods that address the numerous issues that
have been imposing the gap between artificial conversational agents and
human-level interlocutors. These methods were proposed and experimented with in
ways that were inspired by general state-of-the-art AI methodologies. But they
also targeted the characteristics that dialogue systems possess.",0.15164131,-0.2979022,-0.105098166,C
14641,"These
issues call for further research in the future.","While the system can gen-
erally respond to a simple question based on a single knowledge snippet, it often
makes mistakes given a context that requires sophisticated reasoning [102].","58
Chapter 5

Improving the computational
eÔ¨Éciency of large-scale response
retrieval

Large neural networks have been the state-of-the-art machine learning models in
recent years.",2022-11-14 17:27:07+00:00,From Knowledge Augmentation to Multi-tasking: Towards Human-like Dialogue Systems,cs.AI,"['cs.AI', 'cs.CL', 'cs.LG']",[arxiv.Result.Author('Tom Young')],"The goal of building dialogue agents that can converse with humans naturally
has been a long-standing dream of researchers since the early days of
artificial intelligence. The well-known Turing Test proposed to judge the
ultimate validity of an artificial intelligence agent on the
indistinguishability of its dialogues from humans'. It should come as no
surprise that human-level dialogue systems are very challenging to build. But,
while early effort on rule-based systems found limited success, the emergence
of deep learning enabled great advance on this topic.
  In this thesis, we focus on methods that address the numerous issues that
have been imposing the gap between artificial conversational agents and
human-level interlocutors. These methods were proposed and experimented with in
ways that were inspired by general state-of-the-art AI methodologies. But they
also targeted the characteristics that dialogue systems possess.",0.15164131,-0.2979022,-0.105098166,C
14738,"Then, we show how this problem cannot be solved
with common metaheuristics or techniques such as vanilla Bayesian op-
timization [11] and introduce a random search algorithm to solve the
problem that can be used as a baseline for further research.","2 Proposed Methodology

In this section, we begin formally deÔ¨Åning integrated information and the
problem of optimizing integrated information in the space of transition
probability matrices.","2.1 Integrated information

Throughout this paper, we use the deÔ¨Ånitions of integrated information
employed in [17].",2022-12-08 22:34:00+00:00,Optimizing Integrated Information with a Prior Guided Random Search Algorithm,cs.AI,['cs.AI'],"[arxiv.Result.Author('Eduardo C. Garrido-Merch√°n'), arxiv.Result.Author('Javier S√°nchez-Ca√±izares')]","Integrated information theory (IIT) is a theoretical framework that provides
a quantitative measure to estimate when a physical system is conscious, its
degree of consciousness, and the complexity of the qualia space that the system
is experiencing. Formally, IIT rests on the assumption that if a surrogate
physical system can fully embed the phenomenological properties of
consciousness, then the system properties must be constrained by the properties
of the qualia being experienced. Following this assumption, IIT represents the
physical system as a network of interconnected elements that can be thought of
as a probabilistic causal graph, $\mathcal{G}$, where each node has an
input-output function and all the graph is encoded in a transition probability
matrix. Consequently, IIT's quantitative measure of consciousness, $\Phi$, is
computed with respect to the transition probability matrix and the present
state of the graph. In this paper, we provide a random search algorithm that is
able to optimize $\Phi$ in order to investigate, as the number of nodes
increases, the structure of the graphs that have higher $\Phi$. We also provide
arguments that show the difficulties of applying more complex black-box search
algorithms, such as Bayesian optimization or metaheuristics, in this particular
problem. Additionally, we suggest specific research lines for these techniques
to enhance the search algorithm that guarantees maximal $\Phi$.",0.0059063327,0.17001626,-0.046011724,B
14936,"Since this initially theoretical Ô¨Ånding has also been con-
Ô¨Årmed in our synthetic data example, a next natural step for further research is
applications of our approach to real data situations.",theory can be pursued.,"Since for larger applications
also very large linear programs arise when checking the proposed dominance
criterion, it should also be explored to what extent the constraint sets of the lin-
ear programs can still be purged of redundancies (e.g., by explicitly exploiting
transitivity) or to what extent the optimal values can be approximated by less
complex linear programs.",2022-12-13 11:47:02+00:00,Multi-Target Decision Making under Conditions of Severe Uncertainty,cs.AI,"['cs.AI', 'econ.TH', 'stat.ME', '91-10', 'G.3']","[arxiv.Result.Author('Christoph Jansen'), arxiv.Result.Author('Georg Schollmeyer'), arxiv.Result.Author('Thomas Augustin')]","The quality of consequences in a decision making problem under (severe)
uncertainty must often be compared among different targets (goals, objectives)
simultaneously. In addition, the evaluations of a consequence's performance
under the various targets often differ in their scale of measurement,
classically being either purely ordinal or perfectly cardinal. In this paper,
we transfer recent developments from abstract decision theory with incomplete
preferential and probabilistic information to this multi-target setting and
show how -- by exploiting the (potentially) partial cardinal and partial
probabilistic information -- more informative orders for comparing decisions
can be given than the Pareto order. We discuss some interesting properties of
the proposed orders between decision options and show how they can be
concretely computed by linear optimization. We conclude the paper by
demonstrating our framework in an artificial (but quite real-world) example in
the context of comparing algorithms under different performance measures.",-0.0802337,0.2750612,-0.2372627,B
14943,"different ways that the ones proposed here,
                                                          however, the AI should be as non-intrusive as
   In general, it is not straightforward to model         possible, and further research is needed to capture
these atomic or sub-conditions and their logic            feedback from users as they build decision models
relations using the current computational linguistic      ‚Äì to use as ground truth for advancing legal
models, such as Rhetorical Structure Theory               document understanding and discourse, and
(Taboada and Mann, 2006).","AI techniques could be leveraged in
semantics of each sub-condition.","Moving forward, we              develop better techniques for cross-section and
need to develop representation models and build           cross-document capabilities (e.g., to identify rules
corresponding corpora to support developing AI            describing the same benefit across-paragraph and
models for eligibility policies.",2022-11-01 18:29:48+00:00,Envisioning a Human-AI collaborative system to transform policies into decision models,cs.AI,"['cs.AI', 'cs.CL', '68T30', 'H.4']","[arxiv.Result.Author('Vanessa Lopez'), arxiv.Result.Author('Gabriele Picco'), arxiv.Result.Author('Inge Vejsbjerg'), arxiv.Result.Author('Thanh Lam Hoang'), arxiv.Result.Author('Yufang Hou'), arxiv.Result.Author('Marco Luca Sbodio'), arxiv.Result.Author('John Segrave-Daly'), arxiv.Result.Author('Denisa Moga'), arxiv.Result.Author('Sean Swords'), arxiv.Result.Author('Miao Wei'), arxiv.Result.Author('Eoin Carroll')]","Regulations govern many aspects of citizens' daily lives. Governments and
businesses routinely automate these in the form of coded rules (e.g., to check
a citizen's eligibility for specific benefits). However, the path to automation
is long and challenging. To address this, recent global initiatives for digital
government, proposing to simultaneously express policy in natural language for
human consumption as well as computationally amenable rules or code, are
gathering broad public-sector interest. We introduce the problem of
semi-automatically building decision models from eligibility policies for
social services, and present an initial emerging approach to shorten the route
from policy documents to executable, interpretable and standardised decision
models using AI, NLP and Knowledge Graphs. Despite the many open domain
challenges, in this position paper we explore the enormous potential of AI to
assist government agencies and policy experts in scaling the production of both
human-readable and machine executable policy rules, while improving
transparency, interpretability, traceability and accountability of the decision
making.",-0.105182834,-0.19249174,-0.021694394,A
14944,"corpus of labelled data, linked to the policy text,
                                                          that we could leverage to promote further research
   A useful task is to detect text fragments              on AI-assisted policy automation.","For instance, the labeled condition        translate legal text into decision models that are
groups in Figure 5, representing relevant decisions       executable, even if a mostly manually process at
found within the text, are well aligned with the          first, might facilitate the creation of a consistent
decision boxes in the DMN structure diagram.","describing similar decision information and
calculations that can be reused in more than one             Advancements are needed in improving
place.",2022-11-01 18:29:48+00:00,Envisioning a Human-AI collaborative system to transform policies into decision models,cs.AI,"['cs.AI', 'cs.CL', '68T30', 'H.4']","[arxiv.Result.Author('Vanessa Lopez'), arxiv.Result.Author('Gabriele Picco'), arxiv.Result.Author('Inge Vejsbjerg'), arxiv.Result.Author('Thanh Lam Hoang'), arxiv.Result.Author('Yufang Hou'), arxiv.Result.Author('Marco Luca Sbodio'), arxiv.Result.Author('John Segrave-Daly'), arxiv.Result.Author('Denisa Moga'), arxiv.Result.Author('Sean Swords'), arxiv.Result.Author('Miao Wei'), arxiv.Result.Author('Eoin Carroll')]","Regulations govern many aspects of citizens' daily lives. Governments and
businesses routinely automate these in the form of coded rules (e.g., to check
a citizen's eligibility for specific benefits). However, the path to automation
is long and challenging. To address this, recent global initiatives for digital
government, proposing to simultaneously express policy in natural language for
human consumption as well as computationally amenable rules or code, are
gathering broad public-sector interest. We introduce the problem of
semi-automatically building decision models from eligibility policies for
social services, and present an initial emerging approach to shorten the route
from policy documents to executable, interpretable and standardised decision
models using AI, NLP and Knowledge Graphs. Despite the many open domain
challenges, in this position paper we explore the enormous potential of AI to
assist government agencies and policy experts in scaling the production of both
human-readable and machine executable policy rules, while improving
transparency, interpretability, traceability and accountability of the decision
making.",0.010505515,-0.13892674,-0.006891052,A
14986,"Finally, Section 7 concludes the article by summarizing the key contributions and discussing directions
of further research.","Section 6 discusses the outcomes and discussions of the experimental
results.","2 Related Work

Monte-Carlo tree-search has Ô¨Årst been developed for algorithms to play board games [9].",2022-12-14 23:01:53+00:00,Monte-Carlo Tree-Search for Leveraging Performance of Blackbox Job-Shop Scheduling Heuristics,cs.AI,"['cs.AI', 'math.OC', 'I.2.8; F.2.2']","[arxiv.Result.Author('Florian Wimmenauer'), arxiv.Result.Author('Mat√∫≈° Mihal√°k'), arxiv.Result.Author('Mark H. M. Winands')]","In manufacturing, the production is often done on out-of-the-shelf
manufacturing lines, whose underlying scheduling heuristics are not known due
to the intellectual property. We consider such a setting with a black-box
job-shop system and an unknown scheduling heuristic that, for a given
permutation of jobs, schedules the jobs for the black-box job-shop with the
goal of minimizing the makespan. Here, the jobs need to enter the job-shop in
the given order of the permutation, but may take different paths within the job
shop, which depends on the black-box heuristic. The performance of the
black-box heuristic depends on the order of the jobs, and the natural problem
for the manufacturer is to find an optimum ordering of the jobs.
  Facing a real-world scenario as described above, we engineer the Monte-Carlo
tree-search for finding a close-to-optimum ordering of jobs. To cope with a
large solutions-space in planning scenarios, a hierarchical Monte-Carlo tree
search (H-MCTS) is proposed based on abstraction of jobs. On synthetic and
real-life problems, H-MCTS with integrated abstraction significantly
outperforms pure heuristic-based techniques as well as other Monte-Carlo search
variants. We furthermore show that, by modifying the evaluation metric in
H-MCTS, it is possible to achieve other optimization objectives than what the
scheduling heuristics are designed for -- e.g., minimizing the total completion
time instead of the makespan. Our experimental observations have been also
validated in real-life cases, and our H-MCTS approach has been implemented in a
production plant's controller.",0.22144657,0.23263979,0.1673162,C
15015,"Implementations of multiagent
       rollout in the context of Bayesian optimization is an interesting subject for further research.","At the same time the theoretical cost improvement property of
       the rollout algorithm is preserved, while the empirical evidence suggests that great computational savings
       are achieved at the cost of relatively insigniÔ¨Åcant performance degradation.",4.,2022-12-15 17:50:23+00:00,Rollout Algorithms and Approximate Dynamic Programming for Bayesian Optimization and Sequential Estimation,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']",[arxiv.Result.Author('Dimitri Bertsekas')],"We provide a unifying approximate dynamic programming framework that applies
to a broad variety of problems involving sequential estimation. We consider
first the construction of surrogate cost functions for the purposes of
optimization, and we focus on the special case of Bayesian optimization, using
the rollout algorithm and some of its variations. We then discuss the more
general case of sequential estimation of a random vector using optimal
measurement selection, and its application to problems of stochastic and
adaptive control. We finally consider related search and sequential decoding
problems, and a rollout algorithm for the approximate solution of the Wordle
and Mastermind puzzles, recently developed in the paper [BBB22].",0.09903458,0.3907978,-0.009858112,B
15016,"Multiagent rollout in the context of Bayesian optimization
       has not been explored so far, and its implementation is an interesting subject for further research.","The book
       [Ber20a] and the paper [Ber21] discuss the use of distributed schemes, whereby the agents do not requite full
       knowledge of the choices of the preceding agents.",4.,2022-12-15 17:50:23+00:00,Rollout Algorithms and Approximate Dynamic Programming for Bayesian Optimization and Sequential Estimation,cs.AI,"['cs.AI', 'cs.SY', 'eess.SY']",[arxiv.Result.Author('Dimitri Bertsekas')],"We provide a unifying approximate dynamic programming framework that applies
to a broad variety of problems involving sequential estimation. We consider
first the construction of surrogate cost functions for the purposes of
optimization, and we focus on the special case of Bayesian optimization, using
the rollout algorithm and some of its variations. We then discuss the more
general case of sequential estimation of a random vector using optimal
measurement selection, and its application to problems of stochastic and
adaptive control. We distinguish between adaptive control of deterministic and
stochastic systems: the former are better suited for the use of rollout, while
the latter are well suited for the use of rollout with certainty equivalence
approximations. As an example of the deterministic case, we discuss sequential
decoding problems, and a rollout algorithm for the approximate solution of the
Wordle and Mastermind puzzles, recently developed in the paper [BBB22].",0.15922466,0.35392654,0.10816611,B
15063,"3.1.1 Planning dataset

We generate a PDDL-based dataset as a benchmark to Ô¨Ånetune pretrained CodeT5 and facilitate further research at
the intersection of LLMs and automated planning.","The
modeling phase of Figure 1 depicts the diÔ¨Äerent modules employed.","We use the domain model (in PDDL) to generate corresponding

                                                                    3
                     Figure 2: Snapshot of one instance of the plan dataset for blocksworld domain.",2022-12-16 19:06:49+00:00,Plansformer: Generating Symbolic Plans using Transformers,cs.AI,['cs.AI'],"[arxiv.Result.Author('Vishal Pallagani'), arxiv.Result.Author('Bharath Muppasani'), arxiv.Result.Author('Keerthiram Murugesan'), arxiv.Result.Author('Francesca Rossi'), arxiv.Result.Author('Lior Horesh'), arxiv.Result.Author('Biplav Srivastava'), arxiv.Result.Author('Francesco Fabiano'), arxiv.Result.Author('Andrea Loreggia')]","Large Language Models (LLMs) have been the subject of active research,
significantly advancing the field of Natural Language Processing (NLP). From
BERT to BLOOM, LLMs have surpassed state-of-the-art results in various natural
language tasks such as question answering, summarization, and text generation.
Many ongoing efforts focus on understanding LLMs' capabilities, including their
knowledge of the world, syntax, and semantics. However, extending the textual
prowess of LLMs to symbolic reasoning has been slow and predominantly focused
on tackling problems related to the mathematical field. In this paper, we
explore the use of LLMs for automated planning - a branch of AI concerned with
the realization of action sequences (plans) to achieve a goal, typically
executed by intelligent agents, autonomous robots, and unmanned vehicles. We
introduce Plansformer; an LLM fine-tuned on planning problems and capable of
generating plans with favorable behavior in terms of correctness and length
with reduced knowledge-engineering efforts. We also demonstrate the
adaptability of Plansformer in solving different planning domains with varying
complexities, owing to the transfer learning abilities of LLMs. For one
configuration of Plansformer, we achieve ~97% valid plans, out of which ~95%
are optimal for Towers of Hanoi - a puzzle-solving domain.",0.24754925,0.13293335,-0.23055744,C
15083,scenarios and expect to promote further researches.,"We will introduce common approaches to
We summarize most popular datasets in Table 4 considering different       implementing few-shot learning from the following two aspects.","5.2.1 Mini-batch Training
5 FUTURE DIRECTIONS                                                       Mini-batch training is commonly used to solve the training problem
                                                                          on large-scale graphs, and only a part of the graph nodes are selected
In this section, we conclude major trends and challenges, which are       for training each time.",2022-12-17 22:05:07+00:00,Graph Learning: A Comprehensive Survey and Future Directions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Shaopeng Wei'), arxiv.Result.Author('Yu Zhao')]","Graph learning aims to learn complex relationships among nodes and the
topological structure of graphs, such as social networks, academic networks and
e-commerce networks, which are common in the real world. Those relationships
make graphs special compared with traditional tabular data in which nodes are
dependent on non-Euclidean space and contain rich information to explore. Graph
learning developed from graph theory to graph data mining and now is empowered
with representation learning, making it achieve great performances in various
scenarios, even including text, image, chemistry, and biology. Due to the broad
application prospects in the real world, graph learning has become a popular
and promising area in machine learning. Thousands of works have been proposed
to solve various kinds of problems in graph learning and is appealing more and
more attention in academic community, which makes it pivotal to survey previous
valuable works. Although some of the researchers have noticed this phenomenon
and finished impressive surveys on graph learning. However, they failed to link
related objectives, methods and applications in a more logical way and cover
current ample scenarios as well as challenging problems due to the rapid
expansion of the graph learning.",0.23184045,-0.16073644,-0.24574262,C
15084,"[434] extract node-centric ego      and future challenges, which are vital to further research on graph
networks for heterogeneous message passing and incorporate node            learning.",You et al.,"To remedy this, we collect and analyze the latest works to
identity information into node features.",2022-12-17 22:05:07+00:00,Graph Learning: A Comprehensive Survey and Future Directions,cs.AI,['cs.AI'],"[arxiv.Result.Author('Shaopeng Wei'), arxiv.Result.Author('Yu Zhao')]","Graph learning aims to learn complex relationships among nodes and the
topological structure of graphs, such as social networks, academic networks and
e-commerce networks, which are common in the real world. Those relationships
make graphs special compared with traditional tabular data in which nodes are
dependent on non-Euclidean space and contain rich information to explore. Graph
learning developed from graph theory to graph data mining and now is empowered
with representation learning, making it achieve great performances in various
scenarios, even including text, image, chemistry, and biology. Due to the broad
application prospects in the real world, graph learning has become a popular
and promising area in machine learning. Thousands of works have been proposed
to solve various kinds of problems in graph learning and is appealing more and
more attention in academic community, which makes it pivotal to survey previous
valuable works. Although some of the researchers have noticed this phenomenon
and finished impressive surveys on graph learning. However, they failed to link
related objectives, methods and applications in a more logical way and cover
current ample scenarios as well as challenging problems due to the rapid
expansion of the graph learning.",0.06525712,-0.066783145,-0.15056309,C
15103,"The study concludes
by calling for further research on online examinations and the importance of designing
online examinations that are fair, valid, and reliable.","The authors identify the
limitations and challenges of online examinations, including cheating issues, together
with access to technology, and the lack of standardized approaches.","In a comprehensive report, Barber et al.",2022-12-19 08:15:16+00:00,ChatGPT: The End of Online Exam Integrity?,cs.AI,"['cs.AI', 'cs.CL']",[arxiv.Result.Author('Teo Susnjak')],"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students.",-0.31489748,-0.08324687,0.17970963,A
15104,"However,
these tools need further research.","There are some
indications that GPT-text output detectors already in existence5 have some potential
to identify AI-generated text due to an underlying signature in all the text.","With respect to the suggestion of using AI to improve the security and reliability of
the online exam platform and to detect and deter cheating may be ineÔ¨Äective.",2022-12-19 08:15:16+00:00,ChatGPT: The End of Online Exam Integrity?,cs.AI,"['cs.AI', 'cs.CL']",[arxiv.Result.Author('Teo Susnjak')],"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students.",-0.041529603,-0.20861813,0.029259719,A
15105,"While further research is needed to fully understand the
implications of these large language models and to develop strategies for addressing the
potential for cheating using these tools.","New
AI and machine learning tools capable of detecting text outputs from ChatGPT-like
models need to be researched.","It is important for educators and institutions
to be aware of the potential of this tool to facilitate cheating and to take steps to
combat it, in order to maintain the integrity of online exams and ensure fair and valid
assessments for all students.",2022-12-19 08:15:16+00:00,ChatGPT: The End of Online Exam Integrity?,cs.AI,"['cs.AI', 'cs.CL']",[arxiv.Result.Author('Teo Susnjak')],"This study evaluated the ability of ChatGPT, a recently developed artificial
intelligence (AI) agent, to perform high-level cognitive tasks and produce text
that is indistinguishable from human-generated text. This capacity raises
concerns about the potential use of ChatGPT as a tool for academic misconduct
in online exams. The study found that ChatGPT is capable of exhibiting critical
thinking skills and generating highly realistic text with minimal input, making
it a potential threat to the integrity of online exams, particularly in
tertiary education settings where such exams are becoming more prevalent.
Returning to invigilated and oral exams could form part of the solution, while
using advanced proctoring techniques and AI-text output detectors may be
effective in addressing this issue, they are not likely to be foolproof
solutions. Further research is needed to fully understand the implications of
large language models like ChatGPT and to devise strategies for combating the
risk of cheating using these tools. It is crucial for educators and
institutions to be aware of the possibility of ChatGPT being used for cheating
and to investigate measures to address it in order to maintain the fairness and
validity of online exams for all students.",-0.011401277,-0.26251054,0.0605267,A
15193,"De-
                                                       spite this growing interest, there are still many chal-
Although recent advances in language models            lenges and opportunities for further research in this
demonstrate the powerful capabilities of mathemat-     Ô¨Åeld.","as text, tables, natural images, and diagrams, to
                                                       solve mathematical problems (Kahou et al., 2017;
7.2 Trustworthy Reasoning                              KaÔ¨Çe et al., 2018; Lu et al., 2021b, 2022b).","Currently available datasets in this domain
ical reasoning, users cannot always trust the given    tend to be small (Zhao et al., 2022), generated from
answer predicted by the model, because language        templates (Kahou et al., 2017), or focus on speciÔ¨Åc
models can generate ungrounded answers that users      topics (Lu et al., 2021a; Chen et al., 2022a).",2022-12-20 18:46:16+00:00,A Survey of Deep Learning for Mathematical Reasoning,cs.AI,"['cs.AI', 'cs.CL', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Pan Lu'), arxiv.Result.Author('Liang Qiu'), arxiv.Result.Author('Wenhao Yu'), arxiv.Result.Author('Sean Welleck'), arxiv.Result.Author('Kai-Wei Chang')]","Mathematical reasoning is a fundamental aspect of human intelligence and is
applicable in various fields, including science, engineering, finance, and
everyday life. The development of artificial intelligence (AI) systems capable
of solving math problems and proving theorems has garnered significant interest
in the fields of machine learning and natural language processing. For example,
mathematics serves as a testbed for aspects of reasoning that are challenging
for powerful deep learning models, driving new algorithmic and modeling
advances. On the other hand, recent advances in large-scale neural language
models have opened up new benchmarks and opportunities to use deep learning for
mathematical reasoning. In this survey paper, we review the key tasks,
datasets, and methods at the intersection of mathematical reasoning and deep
learning over the past decade. We also evaluate existing benchmarks and
methods, and discuss future research directions in this domain.",-0.11824895,-0.21949375,-0.04295039,A
15209,"degree, and all shortlisted participants but one had competitive
forecasting methodologies (indicated by a MASE less than 1),                  In a follow-up work, Abolghasemi and Bean [52] further
it is a difÔ¨Åcult task and the interplay between forecasting and            explored certain aspects of the results of the competition and
optimization in such an integrated system still has ample room             generated several scenarios to investigate the association be-
for further research.","While this objective has been achieved to some               other things, on the forecast error measure used.",tween forecasting accuracy and optimization costs.,2022-12-21 02:34:12+00:00,Comparison and Evaluation of Methods for a Predict+Optimize Problem in Renewable Energy,cs.AI,['cs.AI'],"[arxiv.Result.Author('Christoph Bergmeir'), arxiv.Result.Author('Frits de Nijs'), arxiv.Result.Author('Abishek Sriramulu'), arxiv.Result.Author('Mahdi Abolghasemi'), arxiv.Result.Author('Richard Bean'), arxiv.Result.Author('John Betts'), arxiv.Result.Author('Quang Bui'), arxiv.Result.Author('Nam Trong Dinh'), arxiv.Result.Author('Nils Einecke'), arxiv.Result.Author('Rasul Esmaeilbeigi'), arxiv.Result.Author('Scott Ferraro'), arxiv.Result.Author('Priya Galketiya'), arxiv.Result.Author('Evgenii Genov'), arxiv.Result.Author('Robert Glasgow'), arxiv.Result.Author('Rakshitha Godahewa'), arxiv.Result.Author('Yanfei Kang'), arxiv.Result.Author('Steffen Limmer'), arxiv.Result.Author('Luis Magdalena'), arxiv.Result.Author('Pablo Montero-Manso'), arxiv.Result.Author('Daniel Peralta'), arxiv.Result.Author('Yogesh Pipada Sunil Kumar'), arxiv.Result.Author('Alejandro Rosales-P√©rez'), arxiv.Result.Author('Julian Ruddick'), arxiv.Result.Author('Akylas Stratigakos'), arxiv.Result.Author('Peter Stuckey'), arxiv.Result.Author('Guido Tack'), arxiv.Result.Author('Isaac Triguero'), arxiv.Result.Author('Rui Yuan')]","Algorithms that involve both forecasting and optimization are at the core of
solutions to many difficult real-world problems, such as in supply chains
(inventory optimization), traffic, and in the transition towards carbon-free
energy generation in battery/load/production scheduling in sustainable energy
systems. Typically, in these scenarios we want to solve an optimization problem
that depends on unknown future values, which therefore need to be forecast. As
both forecasting and optimization are difficult problems in their own right,
relatively few research has been done in this area. This paper presents the
findings of the ``IEEE-CIS Technical Challenge on Predict+Optimize for
Renewable Energy Scheduling,"" held in 2021. We present a comparison and
evaluation of the seven highest-ranked solutions in the competition, to provide
researchers with a benchmark problem and to establish the state of the art for
this benchmark, with the aim to foster and facilitate research in this area.
The competition used data from the Monash Microgrid, as well as weather data
and energy market data. It then focused on two main challenges: forecasting
renewable energy production and demand, and obtaining an optimal schedule for
the activities (lectures) and on-site batteries that lead to the lowest cost of
energy. The most accurate forecasts were obtained by gradient-boosted tree and
random forest models, and optimization was mostly performed using mixed integer
linear and quadratic programming. The winning method predicted different
scenarios and optimized over all scenarios jointly using a sample average
approximation method.",-0.09022433,0.20458978,0.028633408,B
15214,for overcoming these challenges also requires further research.,"entertainment, education, health and food industries would be
How intelligent agents at the edge handle partial observability                 the Ô¨Årst adopters of this alluring technology.","There are ongoing efforts to replicate scents and tastes
   In [3] and [9], the authors propose new solutions for                        digitally.",2022-12-21 03:37:38+00:00,The Internet of Senses: Building on Semantic Communications and Edge Intelligence,cs.AI,"['cs.AI', 'eess.SP']","[arxiv.Result.Author('Roghayeh Joda'), arxiv.Result.Author('Medhat Elsayed'), arxiv.Result.Author('Hatem Abou-zeid'), arxiv.Result.Author('Ramy Atawia'), arxiv.Result.Author('Akram Bin Sediq'), arxiv.Result.Author('Gary Boudreau'), arxiv.Result.Author('Melike Erol-Kantarci'), arxiv.Result.Author('Lajos Hanzo')]","The Internet of Senses (IoS) holds the promise of flawless telepresence-style
communication for all human `receptors' and therefore blurs the difference of
virtual and real environments. We commence by highlighting the compelling use
cases empowered by the IoS and also the key network requirements. We then
elaborate on how the emerging semantic communications and Artificial
Intelligence (AI)/Machine Learning (ML) paradigms along with 6G technologies
may satisfy the requirements of IoS use cases. On one hand, semantic
communications can be applied for extracting meaningful and significant
information and hence efficiently exploit the resources and for harnessing a
priori information at the receiver to satisfy IoS requirements. On the other
hand, AI/ML facilitates frugal network resource management by making use of the
enormous amount of data generated in IoS edge nodes and devices, as well as by
optimizing the IoS performance via intelligent agents. However, the intelligent
agents deployed at the edge are not completely aware of each others' decisions
and the environments of each other, hence they operate in a partially rather
than fully observable environment. Therefore, we present a case study of
Partially Observable Markov Decision Processes (POMDP) for improving the User
Equipment (UE) throughput and energy consumption, as they are imperative for
IoS use cases, using Reinforcement Learning for astutely activating and
deactivating the component carriers in carrier aggregation. Finally, we outline
the challenges and open issues of IoS implementations and employing semantic
communications, edge intelligence as well as learning under partial
observability in the IoS context.",0.013399609,-0.01638672,0.25232178,C
15215,"are highly correlated, hence they lend themselves to high
compression holographic encoding, which is in its infancy and          The above-mentioned requirements of IoS use cases are
requiring further research.","Naturally, the multiplicity of angular views          structing 3D images.",shown in Fig.,2022-12-21 03:37:38+00:00,The Internet of Senses: Building on Semantic Communications and Edge Intelligence,cs.AI,"['cs.AI', 'eess.SP']","[arxiv.Result.Author('Roghayeh Joda'), arxiv.Result.Author('Medhat Elsayed'), arxiv.Result.Author('Hatem Abou-zeid'), arxiv.Result.Author('Ramy Atawia'), arxiv.Result.Author('Akram Bin Sediq'), arxiv.Result.Author('Gary Boudreau'), arxiv.Result.Author('Melike Erol-Kantarci'), arxiv.Result.Author('Lajos Hanzo')]","The Internet of Senses (IoS) holds the promise of flawless telepresence-style
communication for all human `receptors' and therefore blurs the difference of
virtual and real environments. We commence by highlighting the compelling use
cases empowered by the IoS and also the key network requirements. We then
elaborate on how the emerging semantic communications and Artificial
Intelligence (AI)/Machine Learning (ML) paradigms along with 6G technologies
may satisfy the requirements of IoS use cases. On one hand, semantic
communications can be applied for extracting meaningful and significant
information and hence efficiently exploit the resources and for harnessing a
priori information at the receiver to satisfy IoS requirements. On the other
hand, AI/ML facilitates frugal network resource management by making use of the
enormous amount of data generated in IoS edge nodes and devices, as well as by
optimizing the IoS performance via intelligent agents. However, the intelligent
agents deployed at the edge are not completely aware of each others' decisions
and the environments of each other, hence they operate in a partially rather
than fully observable environment. Therefore, we present a case study of
Partially Observable Markov Decision Processes (POMDP) for improving the User
Equipment (UE) throughput and energy consumption, as they are imperative for
IoS use cases, using Reinforcement Learning for astutely activating and
deactivating the component carriers in carrier aggregation. Finally, we outline
the challenges and open issues of IoS implementations and employing semantic
communications, edge intelligence as well as learning under partial
observability in the IoS context.",-0.10895051,-0.089356065,-0.16552553,A
