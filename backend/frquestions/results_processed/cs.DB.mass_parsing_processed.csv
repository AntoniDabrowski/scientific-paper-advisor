Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
111,"To promote further research in this task,       Network (RNN) [41] or Long Short-Term Memory (LSTM).","The com-
ing task, Speech-to-SQL, that lowers the barriers of using SQL            mon choice of the encoder and decoder can be a Recurrent Neural
and relational databases.","The
                                                                          speech-to-SQL problem also enjoys a Seq2Seq structure and can
                                                                          also be considered to be a special case of Seq2Seq conversion.",2022-01-04 15:38:36+00:00,Speech-to-SQL: Towards Speech-driven SQL Query Generation From Natural Language Question,cs.DB,"['cs.DB', 'cs.AI', 'cs.CL']","[arxiv.Result.Author('Yuanfeng Song'), arxiv.Result.Author('Raymond Chi-Wing Wong'), arxiv.Result.Author('Xuefang Zhao'), arxiv.Result.Author('Di Jiang')]","Speech-based inputs have been gaining significant momentum with the
popularity of smartphones and tablets in our daily lives, since voice is the
most easiest and efficient way for human-computer interaction. This paper works
towards designing more effective speech-based interfaces to query the
structured data in relational databases. We first identify a new task named
Speech-to-SQL, which aims to understand the information conveyed by human
speech and directly translate it into structured query language (SQL)
statements. A naive solution to this problem can work in a cascaded manner,
that is, an automatic speech recognition (ASR) component followed by a
text-to-SQL component. However, it requires a high-quality ASR system and also
suffers from the error compounding problem between the two components,
resulting in limited performance. To handle these challenges, we further
propose a novel end-to-end neural architecture named SpeechSQLNet to directly
translate human speech into SQL queries without an external ASR step.
SpeechSQLNet has the advantage of making full use of the rich linguistic
information presented in speech. To the best of our knowledge, this is the
first attempt to directly synthesize SQL based on arbitrary natural language
questions, rather than a natural language-based version of SQL or its variants
with a limited SQL grammar. To validate the effectiveness of the proposed
problem and model, we further construct a dataset named SpeechQL, by
piggybacking the widely-used text-to-SQL datasets. Extensive experimental
evaluations on this dataset show that SpeechSQLNet can directly synthesize
high-quality SQL queries from human speech, outperforming various competitive
counterparts as well as the cascaded methods in terms of exact match
accuracies.",-0.16414773,-0.21932726,0.1372954,A
491,"A further study [13] has presented uncertain top-k queries (UTK) in which, instead of avoiding the
weighted approach, the provided algorithm takes into account the weight uncertainties.","This technique
consists in ranking queries with a particular scoring function which, considering a tuple t consists in the
count of tuples dominated by t. An optimized algorithm has been provided too.","The resulting query
works using the concept of dominance and tries to include in the result set also interesting results within a
certain range from the combination of weights.",2022-01-13 11:41:28+00:00,An outline of multi objective optimization in databases with focus on flexible skyline queries,cs.DB,['cs.DB'],[arxiv.Result.Author('Matteo Savino')],"The problem of optimizing across different, conceivably conflicting, criteria
is called multi-objective optimization and it is widely spread across many
fields. This is a recurring problem in database queries when there is the need
of obtaining the best objects from a very large data set. In this article, I
included a complete review of the main approaches typically used to achieve
multi-criteria optimization. Starting from ranking queries and skylines and
then proceeding to more advanced methods, this paper aims to define a clear
outline of multi-objective optimization in databases. In particular, the
flexible skyline paradigm is considered and thoroughly discussed as it
overcomes many of the critical issues that arise with other methods.",-0.12628266,0.16956383,-0.54369384,A
1470,"Top-k and Skyline queries are
starting points for ranking data, further research could focus on different search parameters for Top-k and
Skyline queries or could even try to find out new methods to query a dataset.","Feasible
solutions are available thanks to the latest technologies and algorithms.","References

[1] Akrivi Vlachou, Michalis Vazirgiannis.",2022-02-03 12:22:19+00:00,"Multi-Objective Optimization, different approach to query a database",cs.DB,['cs.DB'],[arxiv.Result.Author('Matteo Cordioli')],"The datasets available nowadays are very rich and complex, but how do we
reach the information we are looking for? In this survey, two different
approaches to query a dataset are analyzed and algorithms for each type are
explained. Specifically, the TA and NRA have been analyzed for the Top-K query
and the Basic Block Nested Loops has been examined for the skyline query.
Moreover, it's explained the core idea behind the Prioritized and Flexible
skyline. In the end, the pros and cons of each type of analyzed query have been
evaluated based on different criteria.",-0.20357451,0.3277252,-0.41816604,C
1763,"We further study the interplay of LSM tun-
Write Latency.",4.3.2 LSM Tuning.,Write latency is driven by the device bandwidth uti-                         ing and compaction strategies.,2022-02-09 15:34:57+00:00,Constructing and Analyzing the LSM Compaction Design Space,cs.DB,['cs.DB'],"[arxiv.Result.Author('Subhadeep Sarkar'), arxiv.Result.Author('Dimitris Staratzis'), arxiv.Result.Author('Zichen Zhu'), arxiv.Result.Author('Manos Athanassoulis')]","Log-structured merge (LSM) trees offer efficient ingestion by appending
incoming data, and thus, are widely used as the storage layer of production
NoSQL data stores. To enable competitive read performance, LSM-trees
periodically re-organize data to form a tree with levels of exponentially
increasing capacity, through iterative compactions. Compactions fundamentally
influence the performance of an LSM-engine in terms of write amplification,
write throughput, point and range lookup performance, space amplification, and
delete performance. Hence, choosing the appropriate compaction strategy is
crucial and, at the same time, hard as the LSM-compaction design space is vast,
largely unexplored, and has not been formally defined in the literature. As a
result, most LSM-based engines use a fixed compaction strategy, typically
hand-picked by an engineer, which decides how and when to compact data.
  In this paper, we present the design space of LSM-compactions, and evaluate
state-of-the-art compaction strategies with respect to key performance metrics.
Toward this goal, our first contribution is to introduce a set of four design
primitives that can formally define any compaction strategy: (i) the compaction
trigger, (ii) the data layout, (iii) the compaction granularity, and (iv) the
data movement policy. Together, these primitives can synthesize both existing
and completely new compaction strategies. Our second contribution is to
experimentally analyze 10 compaction strategies. We present 12 observations and
7 high-level takeaway messages, which show how LSM systems can navigate the
compaction design space.",-0.23086138,-0.09565571,0.7023469,C
1764,"We further study the interplay of LSM tun-
Write Latency.",4.3.2 LSM Tuning.,Write latency is driven by the device bandwidth uti-                         ing and compaction strategies.,2022-02-09 15:34:57+00:00,Constructing and Analyzing the LSM Compaction Design Space (Updated Version),cs.DB,['cs.DB'],"[arxiv.Result.Author('Subhadeep Sarkar'), arxiv.Result.Author('Dimitris Staratzis'), arxiv.Result.Author('Zichen Zhu'), arxiv.Result.Author('Manos Athanassoulis')]","Log-structured merge (LSM) trees offer efficient ingestion by appending
incoming data, and thus, are widely used as the storage layer of production
NoSQL data stores. To enable competitive read performance, LSM-trees
periodically re-organize data to form a tree with levels of exponentially
increasing capacity, through iterative compactions. Compactions fundamentally
influence the performance of an LSM-engine in terms of write amplification,
write throughput, point and range lookup performance, space amplification, and
delete performance. Hence, choosing the appropriate compaction strategy is
crucial and, at the same time, hard as the LSM-compaction design space is vast,
largely unexplored, and has not been formally defined in the literature. As a
result, most LSM-based engines use a fixed compaction strategy, typically
hand-picked by an engineer, which decides how and when to compact data.
  In this paper, we present the design space of LSM-compactions, and evaluate
state-of-the-art compaction strategies with respect to key performance metrics.
Toward this goal, our first contribution is to introduce a set of four design
primitives that can formally define any compaction strategy: (i) the compaction
trigger, (ii) the data layout, (iii) the compaction granularity, and (iv) the
data movement policy. Together, these primitives can synthesize both existing
and completely new compaction strategies. Our second contribution is to
experimentally analyze 10 compaction strategies. We present 12 observations and
7 high-level takeaway messages, which show how LSM systems can navigate the
compaction design space.",-0.23086138,-0.09565571,0.7023469,C
2247,"To validate and repair the RDF tuples efÔ¨Åciently, we further study
                                        the cold start problems for graph constraint processing.","To ensure dynamic repair and validation, we introduce implicit graph constraints, approximate graph
                                        matching, and linkage prediction based on localized graph patterns.","Experimental results on real datasets demonstrate that our proposed approach
                                        can capture and repair instances with wrong relation labels dynamically and effectively.",2022-02-21 11:37:27+00:00,Dynamic Relation Repairing for Knowledge Enhancement,cs.DB,['cs.DB'],"[arxiv.Result.Author('Rui Kang'), arxiv.Result.Author('Hongzhi Wang')]","Dynamic relation repair aims to efficiently validate and repair the instances
for knowledge graph enhancement (KGE), where KGE captures missing relations
from unstructured data and leads to noisy facts to the knowledge graph. With
the prosperity of unstructured data, an online approach is asked to clean the
new RDF tuples before adding them to the knowledge base. To clean the noisy RDF
tuples, graph constraint processing is a common but intractable approach. Plus,
when adding new tuples to the knowledge graph, new graph patterns would be
created, whereas the explicit discovery of graph constraints is also
intractable. Therefore, although the dynamic relation repair has an unfortunate
hardness, it is a necessary approach for enhancing knowledge graphs effectively
under the fast-growing unstructured data. Motivated by this, we establish a
dynamic repairing and enhancing structure to analyze its hardness on basic
operations. To ensure dynamic repair and validation, we introduce implicit
graph constraints, approximate graph matching, and linkage prediction based on
localized graph patterns. To validate and repair the RDF tuples efficiently, we
further study the cold start problems for graph constraint processing.
Experimental results on real datasets demonstrate that our proposed approach
can capture and repair instances with wrong relation labels dynamically and
effectively.",-0.23620754,-0.20416355,-0.085311025,C
2298,"To overcome these limitations further research focused on producing new frameworks that combine
some of the features of the classical approaches with other algorithms.","Top-k queries on the other hand require the user to provide his preferences and
he/she may not be able to properly state the weight to assign to every attribute.","This paper aims to analyse and propose a comparison of three of these new techniques: flexible skylines,
regret minimization and skyline ranking.",2022-02-22 10:15:29+00:00,"Comparing the latest ranking techniques: pros and cons of flexible skylines, regret minimization and skyline ranking queries",cs.DB,['cs.DB'],[arxiv.Result.Author('Davide Foini')],"Long-established ranking approaches, such as top-k and skyline queries, have
been thoroughly discussed and their drawbacks are well acknowledged. New
techniques have been developed in recent years that try to combine traditional
ones to overcome their limitations. In this paper we focus our attention on
some of them: flexible skylines, regret minimization and skyline ranking
queries, because, while these new methods are promising and have shown
interesting results, a comparison between them is still not available. After a
short introduction of each approach, we discuss analogies and differences
between them with the advantages and disadvantages of every technique debated.",-0.22318813,0.26530838,-0.524062,C
2299,"2.2 UtilityApprox [7]
   This algorithm is the result of further research following [6], in fact, it was developed with the enhancing

of interaction: the user is allowed to state his preferred tuple among the ones proposed to him.","It starts selecting the point with the best
value for the first coordinate and then it starts iterating, adding for every iteration the point that currently
maximizes the regret ratio to the result set.","The main
idea behind this algorithm is to approximate the utility function of the user minimizing the difference
between the one of the real user (denoted u) and the one of a virtual user (denoted v).",2022-02-22 10:15:29+00:00,"Comparing the latest ranking techniques: pros and cons of flexible skylines, regret minimization and skyline ranking queries",cs.DB,['cs.DB'],[arxiv.Result.Author('Davide Foini')],"Long-established ranking approaches, such as top-k and skyline queries, have
been thoroughly discussed and their drawbacks are well acknowledged. New
techniques have been developed in recent years that try to combine traditional
ones to overcome their limitations. In this paper we focus our attention on
some of them: flexible skylines, regret minimization and skyline ranking
queries, because, while these new methods are promising and have shown
interesting results, a comparison between them is still not available. After a
short introduction of each approach, we discuss analogies and differences
between them with the advantages and disadvantages of every technique debated.",-0.17347461,0.08327925,-0.24730694,C
4335,"For the future work, we plan to make further research on BB+tree
as a promising candidate for the PCM optimized index type.","We observe that PAM is about 20% faster than eAM in the databases where search queries
interleave with data modiÔ¨Åcations.","References

 [1] Idreos S, Kersten ML, Manegold S. Updating a Cracked Database.",2022-04-04 17:27:44+00:00,Adaptive Merging on Phase Change Memory,cs.DB,"['cs.DB', 'cs.ET']","[arxiv.Result.Author('Wojciech Macyna'), arxiv.Result.Author('Michal Kukowski')]","Indexing is a well-known database technique used to facilitate data access
and speed up query processing. Nevertheless, the construction and modification
of indexes are very expensive. In traditional approaches, all records in the
database table are equally covered by the index. It is not effective, since
some records may be queried very often and some never. To avoid this problem,
adaptive merging has been introduced. The key idea is to create index
adaptively and incrementally as a side-product of query processing. As a
result, the database table is indexed partially depending on the query
workload. This paper faces a problem of adaptive merging for phase change
memory (PCM). The most important features of this memory type are: limited
write endurance and high write latency. As a consequence, adaptive merging
should be investigated from the scratch. We solve this problem in two steps.
First, we apply several PCM optimization techniques to the traditional adaptive
merging approach. We prove that the proposed method (eAM) outperforms a
traditional approach by 60%. After that, we invent the framework for adaptive
merging (PAM) and a new PCM-optimized index. It further improves the system
performance by 20% for databases where search queries interleave with data
modifications.",-0.21558347,0.20521975,-0.035549436,C_centroid
4336,"For future work, we plan to make further research on BB+tree as a
promising candidate for the PCM-optimized index type.","We observe that PAM is about 20% faster than eAM in the databases where search queries
1022  W. Macyna, M. Kukowski / Adaptive Merging on Phase Change Memory

interleave with data modiÔ¨Åcations.","References

 [1] Idreos S, Kersten ML, Manegold S. Updating a Cracked Database.",2022-04-04 17:27:44+00:00,Adaptive Merging on Phase Change Memory,cs.DB,"['cs.DB', 'cs.ET']","[arxiv.Result.Author('Wojciech Macyna'), arxiv.Result.Author('Michal Kukowski')]","Indexing is a well-known database technique used to facilitate data access
and speed up query processing. Nevertheless, the construction and modification
of indexes are very expensive. In traditional approaches, all records in the
database table are equally covered by the index. It is not effective, since
some records may be queried very often and some never. To avoid this problem,
adaptive merging has been introduced. The key idea is to create index
adaptively and incrementally as a side-product of query processing. As a
result, the database table is indexed partially depending on the query
workload. This paper faces a problem of adaptive merging for phase change
memory (PCM). The most important features of this memory type are: limited
write endurance and high write latency. As a consequence, adaptive merging
should be investigated from the scratch. We solve this problem in two steps.
First, we apply several PCM optimization techniques to the traditional adaptive
merging approach. We prove that the proposed method (eAM) outperforms a
traditional approach by 60%. After that, we invent the framework for adaptive
merging (PAM) and a new PCM-optimized index. It further improves the system
performance by 20% for databases where search queries interleave with data
modifications.",-0.19100177,0.15195745,0.09658748,C
6347,"Identifying the cause of inconsistent          that are disconnected from the production data [6] is an option to
query results is still challenging because we can see only checksum      isolate the simulation traffic from the production system, but we
of the query results and query plans, but we can‚Äôt directly see          need further study to properly capture input-data specific issues in
the customer data and query results.","Building synthetic data sets
No Look Debug of Queries.","To locate where the error is        query engines while following various regulations under privacy
happening, we need to breakdown queries into tiny pieces.",2022-05-17 23:48:26+00:00,Journey of Migrating Millions of Queries on The Cloud,cs.DB,"['cs.DB', '68P20', 'H.2.4; D.2.9']","[arxiv.Result.Author('Taro L. Saito'), arxiv.Result.Author('Naoki Takezoe'), arxiv.Result.Author('Yukihiro Okada'), arxiv.Result.Author('Takako Shimamoto'), arxiv.Result.Author('Dongmin Yu'), arxiv.Result.Author('Suprith Chandrashekharachar'), arxiv.Result.Author('Kai Sasaki'), arxiv.Result.Author('Shohei Okumiya'), arxiv.Result.Author('Yan Wang'), arxiv.Result.Author('Takashi Kurihara'), arxiv.Result.Author('Ryu Kobayashi'), arxiv.Result.Author('Keisuke Suzuki'), arxiv.Result.Author('Zhenghong Yang'), arxiv.Result.Author('Makoto Onizuka')]","Treasure Data is processing millions of distributed SQL queries every day on
the cloud. Upgrading the query engine service at this scale is challenging
because we need to migrate all of the production queries of the customers to a
new version while preserving the correctness and performance of the data
processing pipelines. To ensure the quality of the query engines, we utilize
our query logs to build customer-specific benchmarks and replay these queries
with real customer data in a secure pre-production environment. To simulate
millions of queries, we need effective minimization of test query sets and
better reporting of the simulation results to proactively find incompatible
changes and performance regression of the new version. This paper describes the
overall design of our system and shares various challenges in maintaining the
quality of the query engine service on the cloud.",0.038660444,-0.20583841,-0.07375429,A
6836,"Extending our work to tempo-
DeÔ¨Ånition 2 (Basic graph pattern (BGP)) A BGP                    ral property graphs in which both nodes and edges are
is a tuple (C, X, Y, œÅ, Œª), where:                               associated with temporal information, and where the
                                                                 properties of nodes and edges can change over time [37],
 ‚Äì C, X and Y are pairwise disjoint Ô¨Ånite sets of node           is an interesting direction for further research.","which edges are associated with sets of timepoints, while
                                                                 nodes persist over time.","We as-
    constants, node variables, and edge variables, respec-       sume that timepoints are strictly positive real numbers
    tively;                                                      and deÔ¨Åne:

 ‚Äì œÅ : Y ‚Üí (C ‚à™ X) √ó (C ‚à™ X) indicates, for each edge            DeÔ¨Ånition 4 (Temporal graph) A temporal graph
    variable, its source and destination, which can be a         is a pair (G, Œæ), where G is a graph and Œæ assigns a Ô¨Ånite
    node constant or a node variable; and                        set of timepoints to each edge of G. When e is an edge
                                                                 and t ‚àà Œæ(e), we say that e is active at time t.
 ‚Äì Œª : X ‚à™ Y ‚Üí L is a partial function, assigning a
    label from L to some of the variables.",2022-05-27 23:09:09+00:00,Temporal graph patterns by timed automata,cs.DB,['cs.DB'],"[arxiv.Result.Author('Amir Pouya Aghasadeghi'), arxiv.Result.Author('Jan Van den Bussche'), arxiv.Result.Author('Julia Stoyanovich')]","Temporal graphs represent graph evolution over time, and have been receiving
considerable research attention. Work on expressing temporal graph patterns or
discovering temporal motifs typically assumes relatively simple temporal
constraints, such as journeys or, more generally, existential constraints,
possibly with finite delays. In this paper we propose to use timed automata to
express temporal constraints, leading to a general and powerful notion of
temporal basic graph pattern (BGP). The new difficulty is the evaluation of the
temporal constraint on a large set of matchings. An important benefit of timed
automata is that they support an iterative state assignment, which can be
useful for early detection of matches and pruning of non-matches. We introduce
algorithms to retrieve all instances of a temporal BGP match in a graph, and
present results of an extensive experimental evaluation, demonstrating
interesting performance trade-offs. We show that an on-demand algorithm that
processes total matchings incrementally over time is preferable when dealing
with cyclic patterns on sparse graphs. On acyclic patterns or dense graphs, and
when connectivity of partial matchings can be guaranteed, the best performance
is achieved by maintaining partial matchings over time and allowing automaton
evaluation to be fully incremental.",-0.39306042,-0.0708253,0.10299921,C
6837,"for further research is to determine the precise complex-
                                                            ity of the following problem:
    Consider a temporal BGP Q = (P, Œì ).","An interesting question
above hypothesis as follows.","As usual, let
Y be the set of edge variables of P .",2022-05-27 23:09:09+00:00,Temporal graph patterns by timed automata,cs.DB,['cs.DB'],"[arxiv.Result.Author('Amir Pouya Aghasadeghi'), arxiv.Result.Author('Jan Van den Bussche'), arxiv.Result.Author('Julia Stoyanovich')]","Temporal graphs represent graph evolution over time, and have been receiving
considerable research attention. Work on expressing temporal graph patterns or
discovering temporal motifs typically assumes relatively simple temporal
constraints, such as journeys or, more generally, existential constraints,
possibly with finite delays. In this paper we propose to use timed automata to
express temporal constraints, leading to a general and powerful notion of
temporal basic graph pattern (BGP). The new difficulty is the evaluation of the
temporal constraint on a large set of matchings. An important benefit of timed
automata is that they support an iterative state assignment, which can be
useful for early detection of matches and pruning of non-matches. We introduce
algorithms to retrieve all instances of a temporal BGP match in a graph, and
present results of an extensive experimental evaluation, demonstrating
interesting performance trade-offs. We show that an on-demand algorithm that
processes total matchings incrementally over time is preferable when dealing
with cyclic patterns on sparse graphs. On acyclic patterns or dense graphs, and
when connectivity of partial matchings can be guaranteed, the best performance
is achieved by maintaining partial matchings over time and allowing automaton
evaluation to be fully incremental.",-0.3981949,-0.085362025,0.15640879,C
6838,"It is an interesting topic
                                                                                                                            for further research to investigate when and how an
    baseline      partial  on-demand                                       baseline    partial      on-demand               interval-based approach can be encoded by a point-
        4                                                                      4      12            345                     based approach.",and so do not have a duration.,"This depends also on the considered
    time(sec)                                                                                                               graph model, and the considered class of queries and
        3                                                       time(sec)      3                                            temporal constraints.",2022-05-27 23:09:09+00:00,Temporal graph patterns by timed automata,cs.DB,['cs.DB'],"[arxiv.Result.Author('Amir Pouya Aghasadeghi'), arxiv.Result.Author('Jan Van den Bussche'), arxiv.Result.Author('Julia Stoyanovich')]","Temporal graphs represent graph evolution over time, and have been receiving
considerable research attention. Work on expressing temporal graph patterns or
discovering temporal motifs typically assumes relatively simple temporal
constraints, such as journeys or, more generally, existential constraints,
possibly with finite delays. In this paper we propose to use timed automata to
express temporal constraints, leading to a general and powerful notion of
temporal basic graph pattern (BGP). The new difficulty is the evaluation of the
temporal constraint on a large set of matchings. An important benefit of timed
automata is that they support an iterative state assignment, which can be
useful for early detection of matches and pruning of non-matches. We introduce
algorithms to retrieve all instances of a temporal BGP match in a graph, and
present results of an extensive experimental evaluation, demonstrating
interesting performance trade-offs. We show that an on-demand algorithm that
processes total matchings incrementally over time is preferable when dealing
with cyclic patterns on sparse graphs. On acyclic patterns or dense graphs, and
when connectivity of partial matchings can be guaranteed, the best performance
is achieved by maintaining partial matchings over time and allowing automaton
evaluation to be fully incremental.",-0.37841636,-0.05987209,0.00041617826,C
6839,"Communications of the ACM 26(11), 832‚Äì843
variables is an interesting direction for further research.",Extending our framework with path               tervals.,"(1983)

    An important aspect of pattern matching in graphs          2.",2022-05-27 23:09:09+00:00,Temporal graph patterns by timed automata,cs.DB,['cs.DB'],"[arxiv.Result.Author('Amir Pouya Aghasadeghi'), arxiv.Result.Author('Jan Van den Bussche'), arxiv.Result.Author('Julia Stoyanovich')]","Temporal graphs represent graph evolution over time, and have been receiving
considerable research attention. Work on expressing temporal graph patterns or
discovering temporal motifs typically assumes relatively simple temporal
constraints, such as journeys or, more generally, existential constraints,
possibly with finite delays. In this paper we propose to use timed automata to
express temporal constraints, leading to a general and powerful notion of
temporal basic graph pattern (BGP). The new difficulty is the evaluation of the
temporal constraint on a large set of matchings. An important benefit of timed
automata is that they support an iterative state assignment, which can be
useful for early detection of matches and pruning of non-matches. We introduce
algorithms to retrieve all instances of a temporal BGP match in a graph, and
present results of an extensive experimental evaluation, demonstrating
interesting performance trade-offs. We show that an on-demand algorithm that
processes total matchings incrementally over time is preferable when dealing
with cyclic patterns on sparse graphs. On acyclic patterns or dense graphs, and
when connectivity of partial matchings can be guaranteed, the best performance
is achieved by maintaining partial matchings over time and allowing automaton
evaluation to be fully incremental.",-0.18160194,-0.15964073,0.07491668,C
6983,"At the end of this discussion, we mention a few points for further research.","Hence, our approach
is more declarative.","Since there are some algorithms that are used to discover ISC from execution
logs [35], and these algorithms search for explicit patterns, one could deÔ¨Åne
a common language to report the results of those algorithms and use those
results to automatically write the SQL queries monitoring each of the reported
constraints.",2022-05-31 22:49:48+00:00,What Can Database Query Processing Do for Instance-Spanning Constraints?,cs.DB,['cs.DB'],"[arxiv.Result.Author('Heba Aamer'), arxiv.Result.Author('Marco Montali'), arxiv.Result.Author('Jan Van den Bussche')]","In the last decade, the term instance-spanning constraint has been introduced
in the process mining field to refer to constraints that span multiple process
instances of one or several processes. Of particular relevance, in this
setting, is checking whether process executions comply with constraints of
interest, which at runtime calls for suitable monitoring techniques. Even
though event data are often stored in some sort of database, there is a lack of
database-oriented approaches to tackle compliance checking and monitoring of
(instance-spanning) constraints. In this paper, we fill this gap by showing how
well-established technology from database query processing can be effectively
used for this purpose. We propose to define an instance-spanning constraint
through an ensemble of four database queries that retrieve the satisfying,
violating, pending-satisfying, and pending-violating cases of the constraint.
In this context, the problem of compliance monitoring then becomes an
application of techniques for incremental view maintenance, which is
well-developed in database query processing. In this paper, we argue for our
approach in detail, and, as a proof of concept, present an experimental
validation using the DBToaster incremental database query engine.",-0.2093337,-0.031939276,-0.013746299,C
8655,"The producer sends a potentially unbounded
                                        of applying and evaluating the method in real-life scenarios,             sequence of Resource Description Framework (RDF) [6] state-
                                        which will be the focus of further research.","Moreover, this study opens up the possibility         and the consumer.",ments (triples or quads) to the consumer over the network.,2022-07-10 11:21:22+00:00,Efficient RDF Streaming for the Edge-Cloud Continuum,cs.DB,"['cs.DB', 'cs.PF']","[arxiv.Result.Author('Piotr Sowinski'), arxiv.Result.Author('Katarzyna Wasielewska-Michniewska'), arxiv.Result.Author('Maria Ganzha'), arxiv.Result.Author('Wieslaw Pawlowski'), arxiv.Result.Author('Pawel Szmeja'), arxiv.Result.Author('Marcin Paprzycki')]","With the ongoing, gradual shift of large-scale distributed systems towards
the edge-cloud continuum, the need arises for software solutions that are
universal, scalable, practical, and grounded in well-established technologies.
Simultaneously, semantic technologies, especially in the streaming context, are
becoming increasingly important for enabling interoperability in edge-cloud
systems. However, in recent years, the field of semantic data streaming has
been stagnant, and there are no available solutions that would fit those
requirements. To fill this gap, in this contribution, a novel end-to-end RDF
streaming approach is proposed (named Jelly). The method is simple to
implement, yet very elastic, and designed to fit a wide variety of use cases.
Its practical performance is evaluated in a series of experiments, including
end-to-end throughput and latency measurements. It is shown that Jelly achieves
vastly superior performance to the currently available approaches. The
presented method makes significant progress towards enabling high-performance
semantic data processing in a wide variety of applications, including future
edge-cloud systems. Moreover, this study opens up the possibility of applying
and evaluating the method in real-life scenarios, which will be the focus of
further research.",-0.16548967,-0.2810395,-0.030632429,C
9272,"Therefore, further research is needed to improve the
       eÔ¨Éciency of the algorithm.","Compared with other state-of-the-art algorithms, such as e-NSP (51) and e-RNSP (52),
       ONP-Miner algorithm is less eÔ¨Écient in mining negative patterns when mining similar
       number of frequent positive patterns.","Acknowledgement

    This work was partly supported by National Natural Science Foundation of China (61976240,
52077056, 91746209, 62120106008), National Key Research and Development Program of
China (2016YFB1000901), and Natural Science Foundation of Hebei Province, China (Nos.",2022-07-25 07:37:13+00:00,One-off Negative Sequential Pattern Mining,cs.DB,['cs.DB'],"[arxiv.Result.Author('Youxi Wu'), arxiv.Result.Author('Mingjie Chen'), arxiv.Result.Author('Yan Li'), arxiv.Result.Author('Jing Liu'), arxiv.Result.Author('Zhao Li'), arxiv.Result.Author('Jinyan Li'), arxiv.Result.Author('Xindong Wu')]","Negative sequential pattern mining (SPM) is an important SPM research topic.
Unlike positive SPM, negative SPM can discover events that should have occurred
but have not occurred, and it can be used for financial risk management and
fraud detection. However, existing methods generally ignore the repetitions of
the pattern and do not consider gap constraints, which can lead to mining
results containing a large number of patterns that users are not interested in.
To solve this problem, this paper discovers frequent one-off negative
sequential patterns (ONPs). This problem has the following two characteristics.
First, the support is calculated under the one-off condition, which means that
any character in the sequence can only be used once at most. Second, the gap
constraint can be given by the user. To efficiently mine patterns, this paper
proposes the ONP-Miner algorithm, which employs depth-first and backtracking
strategies to calculate the support. Therefore, ONP-Miner can effectively avoid
creating redundant nodes and parent-child relationships. Moreover, to
effectively reduce the number of candidate patterns, ONP-Miner uses pattern
join and pruning strategies to generate and further prune the candidate
patterns, respectively. Experimental results show that ONP-Miner not only
improves the mining efficiency, but also has better mining performance than the
state-of-the-art algorithms. More importantly, ONP mining can find more
interesting patterns in traffic volume data to predict future traffic.",0.07786631,0.1611959,-0.08027478,B
9325,"Position-based value sort operator may be beneÔ¨Åcial for late materialization
(and therefore interesting for further research), since it sorts key-position pairs
similar to unclustered (tag) sorting, which is stated [24] to be more eÔ¨Écient on
SSD if tuples are big enough.","Since in PosDB tuple-based representation lacks
     positions, it is a value sort.","However, it is beyond the scope of this paper.",2022-07-26 08:00:15+00:00,Implementing the Comparison-Based External Sort,cs.DB,"['cs.DB', 'cs.DS', 'cs.PF', 'H.2; E.5']","[arxiv.Result.Author('Michael Polyntsov'), arxiv.Result.Author('Valentin Grigorev'), arxiv.Result.Author('Kirill Smirnov'), arxiv.Result.Author('George Chernishev')]","In the age of big data, sorting is an indispensable operation for DBMSes and
similar systems. Having data sorted can help produce query plans with
significantly lower run times. It also can provide other benefits like having
non-blocking operators which will produce data steadily (without bursts), or
operators with reduced memory footprint.
  Sorting may be required on any step of query processing, i.e., be it source
data or intermediate results. At the same time, the data to be sorted may not
fit into main memory. In this case, an external sort operator, which writes
intermediate results to disk, should be used.
  In this paper we consider an external sort operator of the comparison-based
sort type. We discuss its implementation and describe related design decisions.
Our aim is to study the impact on performance of a data structure used on the
merge step. For this, we have experimentally evaluated three data structures
implemented inside a DBMS.
  Results have shown that it is worthwhile to make an effort to implement an
efficient data structure for run merging, even on modern commodity computers
which are usually disk-bound. Moreover, we demonstrated that using a loser tree
is a more efficient approach than both the naive approach and the heap-based
one.",-0.18099515,0.0634395,-0.12663387,C
9453,"In addition, we raise several questions and point        conclude that label noise has diverse ramifications, including de-
        out possible directions for further research.","They
        scientists.","grading in classification accuracy, high complexity learning models,
                                                                             and difficulty in specifying relevant features.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on ML-Model Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity. We explore
empirically the correlation between six of the traditional data quality
dimensions and the performance of fifteen widely used ML algorithms covering
the tasks of classification, regression, and clustering, with the goal of
explaining ML results in terms of data quality. Our experiments distinguish
three scenarios based on the AI pipeline steps that were fed with polluted
data: polluted training data, test data, or both. We conclude the paper with an
extensive discussion of our observations and recommendations, alongside open
questions and future directions to be explored.",0.41343868,-0.35514086,-0.12104915,A
9454,"In        several sources of noise, discuss the potential ramifications, and cat-
        addition, we raise several questions and point out possible          egorize the methods into the classes label noise-robust, label noise
        directions for further research.","They distinguish
     ‚Ä¢ Practical insights and learned lessons for data scientists.","cleansing, and label noise-tolerant.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.4095109,-0.47238624,-0.22509766,A_centroid
9455,"Upon further research, we found that some combinations of the              We observed that the Gaussian Mixture algorithm assumes data
two categorical features dominate the data, with the combination

                                                                       21
(a) Houses dataset (Scenario 1)  (b) IMDB dataset (Scenario 1)               (c) Cars dataset (Scenario 1)

(d) Houses dataset (Scenario 2)  (e) IMDB dataset (Scenario 2)               (f) Cars dataset (Scenario 2)

(g) Houses dataset (Scenario 3)  (h) IMDB dataset (Scenario 3)               (i) Cars dataset (Scenario 3)

Figure 15: ùëÖ2 of the regression algorithms for target class balance.",be put into findings on Covertype and Letter.,"that follows a single distribution, i.e., the random peaks and drops         consistent representation pollution results that generated four addi-
in its performance are caused by its sensitivity to the distribution of      tional representations per categorical value, not those adding only
samples.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.57031786,-0.13881896,0.10566487,B
9456,"Secondly, clusters        on Covertype improves slightly around a feature accuracy quality
previously correctly identified in the original data are now merged           of about 0.6 requires further research.","now clusters of outliers that likely do not share any resemblance             To investigate why the performance of Gaussian Mixture clustering
to the original clusters in the algorithm‚Äôs output.","Here, we expected a behavior
as the number of clusters returned is fixed and are therefore no              more similar to that of the Agglomerative clustering approach.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.6417378,0.21710014,0.14094071,B_centroid
9457,"In        several sources of noise, discuss the potential ramifications, and cat-
        addition, we raise several questions and point out possible          egorize the methods into the classes label noise-robust, label noise
        directions for further research.","They distinguish
     ‚Ä¢ Practical insights and learned lessons for data scientists.","cleansing, and label noise-tolerant.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.4095109,-0.47238624,-0.22509766,A
9458,"Upon further research, we found that some combinations of the              We observed that the Gaussian Mixture algorithm assumes data
two categorical features dominate the data, with the combination

                                                                       21
(a) Houses dataset (Scenario 1)  (b) IMDB dataset (Scenario 1)               (c) Cars dataset (Scenario 1)

(d) Houses dataset (Scenario 2)  (e) IMDB dataset (Scenario 2)               (f) Cars dataset (Scenario 2)

(g) Houses dataset (Scenario 3)  (h) IMDB dataset (Scenario 3)               (i) Cars dataset (Scenario 3)

Figure 15: ùëÖ2 of the regression algorithms for target class balance.",be put into findings on Covertype and Letter.,"that follows a single distribution, i.e., the random peaks and drops         consistent representation pollution results that generated four addi-
in its performance are caused by its sensitivity to the distribution of      tional representations per categorical value, not those adding only
samples.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.57031786,-0.13881896,0.10566487,B
9459,"Secondly, clusters        on Covertype improves slightly around a feature accuracy quality
previously correctly identified in the original data are now merged           of about 0.6 requires further research.","now clusters of outliers that likely do not share any resemblance             To investigate why the performance of Gaussian Mixture clustering
to the original clusters in the algorithm‚Äôs output.","Here, we expected a behavior
as the number of clusters returned is fixed and are therefore no              more similar to that of the Agglomerative clustering approach.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Hazar Harmouch'), arxiv.Result.Author('Felix Naumann')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.6417378,0.21710014,0.14094071,B
9460,"In addition, we raise several questions and    setup similar to our experiments, which evaluates the
    point out possible directions for further research.","‚Äì Practical insights and learned lessons for data sci-     Their paper proposes a theoretical framework with a
    entists.","performance of a task given polluted datasets by vari-
                                                            ous kinds of generated systematic noise.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Felix Naumann'), arxiv.Result.Author('Hazar Harmouch')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.30832145,-0.25646335,-0.050689116,A
9461,"ical features degrading their accuracy in a gradually       tering on Covertype improves slightly around a feature
increasing fashion, continuously decreasing the distin-     accuracy quality of about 0.6 requires further research.",20: Average AMI score for target accuracy dimension and clustering algorithms.,"guishability of individual clusters by spreading out their  Here, we expected a behavior more similar to that of
points more and more.",2022-07-29 07:53:31+00:00,The Effects of Data Quality on Machine Learning Performance,cs.DB,['cs.DB'],"[arxiv.Result.Author('Lukas Budach'), arxiv.Result.Author('Moritz Feuerpfeil'), arxiv.Result.Author('Nina Ihde'), arxiv.Result.Author('Andrea Nathansen'), arxiv.Result.Author('Nele Noack'), arxiv.Result.Author('Hendrik Patzlaff'), arxiv.Result.Author('Felix Naumann'), arxiv.Result.Author('Hazar Harmouch')]","Modern artificial intelligence (AI) applications require large quantities of
training and test data. This need creates critical challenges not only
concerning the availability of such data, but also regarding its quality. For
example, incomplete, erroneous or inappropriate training data can lead to
unreliable models that produce ultimately poor decisions. Trustworthy AI
applications require high-quality training and test data along many dimensions,
such as accuracy, completeness, consistency, and uniformity.
  We explore empirically the relationship between six of the traditional data
quality dimensions and the performance of fifteen widely used machine learning
(ML) algorithms covering the tasks of classification, regression, and
clustering, with the goal of explaining their performance in terms of data
quality. Our experiments distinguish three scenarios based on the AI pipeline
steps that were fed with polluted data: polluted training data, test data, or
both. We conclude the paper with an extensive discussion of our observations.",0.37073696,0.09065391,0.042866006,B
9632,"This monograph is a Ô¨Årst attempt to integrate the spread-out results from
diÔ¨Äerent domains using the methodology of the well-established classical aggre-
gation framework, introduce researchers and practitioners to Aggregation 2.0, as
well as to point out the challenges and interesting directions for further research.","Instead, only carefully pre-processed and aggregated
data models are delivered to the customers.",It is organized as follows.,2022-08-02 10:04:28+00:00,"Data Fusion: Theory, Methods, and Applications",cs.DB,['cs.DB'],[arxiv.Result.Author('Marek Gagolewski')],"A proper fusion of complex data is of interest to many researchers in diverse
fields, including computational statistics, computational geometry,
bioinformatics, machine learning, pattern recognition, quality management,
engineering, statistics, finance, economics, etc. It plays a crucial role in:
synthetic description of data processes or whole domains, creation of rule
bases for approximate reasoning tasks, reaching consensus and selection of the
optimal strategy in decision support systems, imputation of missing values,
data deduplication and consolidation, record linkage across heterogeneous
databases, and clustering. This open-access research monograph integrates the
spread-out results from different domains using the methodology of the
well-established classical aggregation framework, introduces researchers and
practitioners to Aggregation 2.0, as well as points out the challenges and
interesting directions for further research.",0.05851792,-0.014269152,-0.25280923,A
10095,"On one hand, since there is no unique solution to assess the status of KGs,
further research is needed to evaluate the framework in speciÔ¨Åc use cases.","Furthermore, the develop-
ment of a KG assessment framework might be, to some extent, semi-automated,
i.e., implementing the metrics that can be quantitatively measured (which also
might reduce assessment costs), but it will still be a combination of human-
machine eÔ¨Äorts as necessary.","On the
other hand, a uniÔ¨Åed quality assessment approach would improve the applying
of quality assessment in KGs and increase the adoption of KGs to worldwide
application scenarios.",2022-08-16 14:41:42+00:00,Steps to Knowledge Graphs Quality Assessment,cs.DB,"['cs.DB', 'cs.IR', 'H.2']",[arxiv.Result.Author('Elwin Huaman')],"Knowledge Graphs (KGs) have been popularized during the last decade, for
instance, they are used widely in the context of the web. In 2012 Google has
presented the Google's Knowledge Graph that is used to improve their web search
services. The web also hosts different KGs, such as DBpedia and Wikidata, which
are used in various applications like personal assistants and
question-answering systems. Various web applications rely on KGs to provide
concise, complete, accurate, and fresh answer to users. However, what is the
quality of those KGs? In which cases should a Knowledge Graph (KG) be used? How
might they be evaluated? We reviewed the literature on quality assessment of
data, information, linked data, and KGs. We extended the current
state-of-the-art frameworks by adding various quality dimensions (QDs) and
quality metrics (QMs) that are specific to KGs. Furthermore, we propose a
general-purpose, customizable to a domain or task, and practical quality
assessment framework for assessing the quality of KGs.",0.045430895,-0.06637554,-0.08974033,A
10734,"Therefore, further research can be carried out to design
a generalized schema which can accommodate variation in data structure.","They may need a customized schema that serves other in-
dividual requirements.","Data
security in this multi-tenant schema is also an interesting area which can be
explored further.",2022-09-01 09:57:58+00:00,eDWaaS: A Scalable Educational Data Warehouse as a Service,cs.DB,['cs.DB'],"[arxiv.Result.Author('Anupam Khan'), arxiv.Result.Author('Sourav Ghosh'), arxiv.Result.Author('Soumya K. Ghosh')]","The university management is perpetually in the process of innovating
policies to improve the quality of service. Intellectual growth of the
students, the popularity of university are some of the major areas that
management strives to improve upon. Relevant historical data is needed in
support of taking any decision. Furthermore, providing data to various
university ranking frameworks is a frequent activity in recent years. The
format of such requirement changes frequently which requires efficient manual
effort. Maintaining a data warehouse can be a solution to this problem.
However, both in-house and outsourced implementation of a dedicated data
warehouse may not be a cost-effective and smart solution. This work proposes an
educational data warehouse as a service (eDWaaS) model to store historical data
for multiple universities. The proposed multi-tenant schema facilitates the
universities to maintain their data warehouse in a cost-effective solution. It
also addresses the scalability issues in implementing such data warehouse as a
service model.",-0.13611981,-0.19628125,-0.23932637,A
10885,"Therefore, if we
know a sequence pattern, we can Ô¨Ånd similar pattern in the new protein sequences by approximate pattern match-
ing with gap constraints, so as to further study and conÔ¨Årm the functional structure of the new protein sequence.","However, protein sequences may mutate.","To verify the matching eÔ¨Äect of the (Œ¥, Œ≥)-distance, we select two WormsTwoClass time series (S 9 ‚àº S 10), which
can be downloaded from https://www.cs.",2022-09-07 06:16:47+00:00,"Nonoverlapping (delta, gamma)-approximate pattern matching",cs.DB,['cs.DB'],"[arxiv.Result.Author('Youxi Wu'), arxiv.Result.Author('Bojing Jian'), arxiv.Result.Author('Yan Li'), arxiv.Result.Author('He Jiang'), arxiv.Result.Author('Xindong Wu')]","Pattern matching can be used to calculate the support of patterns, and is a
key issue in sequential pattern mining (or sequence pattern mining).
Nonoverlapping pattern matching means that two occurrences cannot use the same
character in the sequence at the same position. Approximate pattern matching
allows for some data noise, and is more general than exact pattern matching. At
present, nonoverlapping approximate pattern matching is based on Hamming
distance, which cannot be used to measure the local approximation between the
subsequence and pattern, resulting in large deviations in matching results. To
tackle this issue, we present a Nonoverlapping Delta and gamma approximate
Pattern matching (NDP) scheme that employs the (delta, gamma)-distance to give
an approximate pattern matching, where the local and the global distances do
not exceed delta and gamma, respectively. We first transform the NDP problem
into a local approximate Nettree and then construct an efficient algorithm,
called the local approximate Nettree for NDP (NetNDP). We propose a new
approach called the Minimal Root Distance which allows us to determine whether
or not a node has root paths that satisfy the global constraint and to prune
invalid nodes and parent-child relationships. NetNDP finds the rightmost
absolute leaf of the max root, searches for the rightmost occurrence from the
rightmost absolute leaf, and deletes this occurrence. We iterate the above
steps until there are no new occurrences. Numerous experiments are used to
verify the performance of the proposed algorithm.",-0.110066324,0.0142832,0.37175244,C
11372,"For a speciÔ¨Åc time series clustering problem,
       how to extract eÔ¨Äective features to achieve high-quality clustering performance is worthy of further study.","This result indicates that there
       is no clear relationship between top-k OPPs and strong OPRs.",5.7.2.,2022-09-19 11:29:40+00:00,OPR-Miner: Order-preserving rule mining for time series,cs.DB,['cs.DB'],"[arxiv.Result.Author('Youxi Wu'), arxiv.Result.Author('Xiaoqian Zhao'), arxiv.Result.Author('Yan Li'), arxiv.Result.Author('Lei Guo'), arxiv.Result.Author('Xingquan Zhu'), arxiv.Result.Author('Philippe Fournier-Viger'), arxiv.Result.Author('Xindong Wu')]","Discovering frequent trends in time series is a critical task in data mining.
Recently, order-preserving matching was proposed to find all occurrences of a
pattern in a time series, where the pattern is a relative order (regarded as a
trend) and an occurrence is a sub-time series whose relative order coincides
with the pattern. Inspired by the order-preserving matching, the existing
order-preserving pattern (OPP) mining algorithm employs order-preserving
matching to calculate the support, which leads to low efficiency. To address
this deficiency, this paper proposes an algorithm called efficient frequent OPP
miner (EFO-Miner) to find all frequent OPPs. EFO-Miner is composed of four
parts: a pattern fusion strategy to generate candidate patterns, a matching
process for the results of sub-patterns to calculate the support of
super-patterns, a screening strategy to dynamically reduce the size of prefix
and suffix arrays, and a pruning strategy to further dynamically prune
candidate patterns. Moreover, this paper explores the order-preserving rule
(OPR) mining and proposes an algorithm called OPR-Miner to discover strong
rules from all frequent OPPs using EFO-Miner. Experimental results verify that
OPR-Miner gives better performance than other competitive algorithms. More
importantly, clustering and classification experiments further validate that
OPR-Miner achieves good performance.",0.16857022,0.6703376,0.10328542,B
11373,"For a speciÔ¨Åc time series clustering problem, how to extract eÔ¨Äective features
to achieve high-quality clustering performance is worthy of further study.","This result indicates that there is no clear relationship
between top-k OPPs and strong OPRs.",5.7.2.,2022-09-19 11:29:40+00:00,OPR-Miner: Order-preserving rule mining for time series,cs.DB,['cs.DB'],"[arxiv.Result.Author('Youxi Wu'), arxiv.Result.Author('Xiaoqian Zhao'), arxiv.Result.Author('Yan Li'), arxiv.Result.Author('Lei Guo'), arxiv.Result.Author('Xingquan Zhu'), arxiv.Result.Author('Philippe Fournier-Viger'), arxiv.Result.Author('Xindong Wu')]","Discovering frequent trends in time series is a critical task in data mining.
Recently, order-preserving matching was proposed to find all occurrences of a
pattern in a time series, where the pattern is a relative order (regarded as a
trend) and an occurrence is a sub-time series whose relative order coincides
with the pattern. Inspired by the order-preserving matching, the existing
order-preserving pattern (OPP) mining algorithm employs order-preserving
matching to calculate the support, which leads to low efficiency. To address
this deficiency, this paper proposes an algorithm called efficient frequent OPP
miner (EFO-Miner) to find all frequent OPPs. EFO-Miner is composed of four
parts: a pattern fusion strategy to generate candidate patterns, a matching
process for the results of sub-patterns to calculate the support of
super-patterns, a screening strategy to dynamically reduce the size of prefix
and suffix arrays, and a pruning strategy to further dynamically prune
candidate patterns. Moreover, this paper explores the order-preserving rule
(OPR) mining and proposes an algorithm called OPR-Miner to discover strong
rules from all frequent OPPs using EFO-Miner. Experimental results verify that
OPR-Miner gives better performance than other competitive algorithms. More
importantly, clustering and classification experiments further validate that
OPR-Miner achieves good performance.",0.16857022,0.6703376,0.10328542,B
11374,"For a speciÔ¨Åc time series clustering problem, how to extract eÔ¨Äective features
to achieve high-quality clustering performance is worthy of further study.","This result indicates that there is no clear relationship
between top-k OPPs and strong OPRs.",5.7.2.,2022-09-19 11:29:40+00:00,OPR-Miner: Order-preserving rule mining for time series,cs.DB,['cs.DB'],"[arxiv.Result.Author('Youxi Wu'), arxiv.Result.Author('Xiaoqian Zhao'), arxiv.Result.Author('Yan Li'), arxiv.Result.Author('Lei Guo'), arxiv.Result.Author('Xingquan Zhu'), arxiv.Result.Author('Philippe Fournier-Viger'), arxiv.Result.Author('Xindong Wu')]","Discovering frequent trends in time series is a critical task in data mining.
Recently, order-preserving matching was proposed to find all occurrences of a
pattern in a time series, where the pattern is a relative order (regarded as a
trend) and an occurrence is a sub-time series whose relative order coincides
with the pattern. Inspired by the order-preserving matching, the existing
order-preserving pattern (OPP) mining algorithm employs order-preserving
matching to calculate the support, which leads to low efficiency. To address
this deficiency, this paper proposes an algorithm called efficient frequent OPP
miner (EFO-Miner) to find all frequent OPPs. EFO-Miner is composed of four
parts: a pattern fusion strategy to generate candidate patterns, a matching
process for the results of sub-patterns to calculate the support of
super-patterns, a screening strategy to dynamically reduce the size of prefix
and suffix arrays, and a pruning strategy to further dynamically prune
candidate patterns. Moreover, this paper explores the order-preserving rule
(OPR) mining and proposes an algorithm called OPR-Miner to discover strong
rules from all frequent OPPs using EFO-Miner. Experimental results verify that
OPR-Miner gives better performance than other competitive algorithms. More
importantly, clustering and classification experiments further validate that
OPR-Miner achieves good performance.",0.16857022,0.6703376,0.10328542,B
12273,"1.051.030 1.015
                                                                                                                                                                        1.00 512 1024
G. Parameter Study                                                                                                                                                                                                                          0.49 512 1024 2048 4096 8192
                                                                                                                                                                              (a) No Ô¨Åne-tuning ( )
   We further study the impact of model parameters using the                                                                                                                                                                                               | neg|
same experimental setup as Section V-F.
                                                                                                                                                                                                                                               (b) With Ô¨Åne-tuning ( )
   Impact of the embedding dimensionality d. We vary d
from 64 to 1,024.","denote no augmen-                                                                                                  Mean rank  1.15                1.118  1.069      1.011 1.010        Hit ratio
                                                                                                                                                                                                   1.007      4096 8192
tation, point shifting, point masking, trajectory truncating and                                                                                                        1.10                                                                0.500.498
                                                                                                                                                                                                   |20n4e8g|
trajectory simpliÔ¨Åcation, respectively.)",As Fig.,2022-10-11 05:25:14+00:00,Contrastive Trajectory Similarity Learning with Dual-Feature Attention,cs.DB,"['cs.DB', 'cs.LG']","[arxiv.Result.Author('Yanchuan Chang'), arxiv.Result.Author('Jianzhong Qi'), arxiv.Result.Author('Yuxuan Liang'), arxiv.Result.Author('Egemen Tanin')]","Trajectory similarity measures act as query predicates in trajectory
databases, making them the key player in determining the query results. They
also have a heavy impact on the query efficiency. An ideal measure should have
the capability to accurately evaluate the similarity between any two
trajectories in a very short amount of time. However, existing heuristic
measures are mainly based on pointwise comparisons following hand-crafted
rules, thus resulting in either poor quality results or low efficiency in many
cases. Although several deep learning-based measures have recently aimed at
these problems, their improvements are limited by the difficulties to learn the
fine-grained spatial patterns of trajectories.
  To address these issues, we propose a contrastive learning-based trajectory
modelling method named TrajCL, which is robust in application scenarios where
the data set contains low-quality trajectories. Specifically, we present four
trajectory augmentation methods and a novel dual-feature self-attention-based
trajectory backbone encoder. The resultant model can jointly learn both the
spatial and the structural patterns of trajectories. Our model does not involve
any recurrent structures and thus has a high efficiency. Besides, our
pre-trained backbone encoder can be fine-tuned towards other computationally
expensive measures with minimal supervision data. Experimental results show
that TrajCL is consistently and significantly more accurate and faster than the
state-of-the-art trajectory similarity measures. After fine-tuning, i.e., when
being used as an estimator for heuristic measures, TrajCL can even outperform
the state-of-the-art supervised method by up to 32% in the accuracy for
processing trajectory similarity queries.",-0.0035920795,-0.006596939,0.24017131,C
12850,"more than two CQs, and to further study the unbalanced triangle
                                                                           detection problem.","Natural next steps are to try and prove a dichotomy for unions of
in 1 on which we can apply our reduction.","By combining Lemma 5.8 with the Reduction Lemma, we get
                                                                           ACKNOWLEDGMENTS
that free-connex union extensions capture all UCQs in DelayClin
that contain one free-connex CQ and one diÔ¨Écult CQ.",2022-10-21 14:38:44+00:00,Unbalanced Triangle Detection and Enumeration Hardness for Unions of Conjunctive Queries,cs.DB,"['cs.DB', 'cs.DS']","[arxiv.Result.Author('Karl Bringmann'), arxiv.Result.Author('Nofar Carmeli')]","We study the enumeration of answers to Unions of Conjunctive Queries (UCQs)
with optimal time guarantees. More precisely, we wish to identify the queries
that can be solved with linear preprocessing time and constant delay. Despite
the basic nature of this problem, it was shown only recently that UCQs can be
solved within these time bounds if they admit free-connex union extensions,
even if all individual CQs in the union are intractable with respect to the
same complexity measure. Our goal is to understand whether there exist
additional tractable UCQs, not covered by the currently known algorithms.
  As a first step, we show that some previously unclassified UCQs are hard
using the classic 3SUM hypothesis, via a known reduction from 3SUM to triangle
listing in graphs. As a second step, we identify a question about a variant of
this graph task which is unavoidable if we want to classify all self-join free
UCQs: is it possible to decide the existence of a triangle in a
vertex-unbalanced tripartite graph in linear time? We prove that this task is
equivalent in hardness to some family of UCQs. Finally, we show a dichotomy for
unions of two self-join-free CQs if we assume the answer to this question is
negative.
  As a result, to reason about a class of enumeration problems defined by UCQs,
it is enough to study the single decision problem of detecting triangles in
unbalanced graphs. As of today, we know of no algorithm that comes close to
solving this decision problem within the required time bounds. Our conclusion
is that, without a breakthrough for triangle detection, we have no hope to find
an efficient algorithm for additional unions of two self-join free CQs. On the
other hand, if we will one day have such a triangle detection algorithm, we
will immediately obtain an efficient algorithm for a family of UCQs that are
currently not known to be tractable.",-0.18868154,-0.0028537586,0.09836534,C
13157,"features of GQL and SQL/PGQ pattern matching by means of
several examples and thus hardly serves the purpose of introduc-                                         Other features of patterns are those in regular languages: con-
ing a pattern matching calculus to form the basis of further study                                    catenation, disjunction, repetition; they can be applied on top of
of graph querying.","It outlines the main                                         larly about properties of , as they are bound to a list.","Such a calculus should judiciously choose the                                      already existing patterns, similarly to [25].",2022-10-29 11:56:20+00:00,GPC: A Pattern Calculus for Property Graphs,cs.DB,['cs.DB'],"[arxiv.Result.Author('Nadime Francis'), arxiv.Result.Author('Am√©lie Gheerbrant'), arxiv.Result.Author('Paolo Guagliardo'), arxiv.Result.Author('Leonid Libkin'), arxiv.Result.Author('Victor Marsault'), arxiv.Result.Author('Wim Martens'), arxiv.Result.Author('Filip Murlak'), arxiv.Result.Author('Liat Peterfreund'), arxiv.Result.Author('Alexandra Rogova'), arxiv.Result.Author('Domagoj Vrgoƒç')]","The development of practical query languages for graph databases runs well
ahead of the underlying theory. The ISO committee in charge of database query
languages is currently developing a new standard called Graph Query Language
(GQL) as well as an extension of the SQL Standard for querying property graphs
represented by a relational schema, called SQL/PGQ. The main component of both
is the pattern matching facility, which is shared by the two standards. In many
aspects, it goes well beyond RPQs, CRPQs, and similar queries on which the
research community has focused for years. Our main contribution is to distill
the lengthy standard specification into a simple Graph Pattern Calculus (GPC)
that reflects all the key pattern matching features of GQL and SQL/PGQ, and at
the same time lends itself to rigorous theoretical investigation. We describe
the syntax and semantics of GPC, along with the typing rules that ensure its
expressions are well-defined, and state some basic properties of the language.
With this paper we provide the community a tool to embark on a study of query
languages that will soon be widely adopted by industry.",-0.19847526,-0.058302015,-0.03074436,C
13966,"To                                     c‚à•2 ‚â§ r) can be done similar to proof of Theorem 3.5 (only finding
utilize the theoretical framework for other query functions, we need                                 range predicate‚Äôs VC-dimension needs further study).","with COUNT, SUM or AVG aggregation functions but different range
Theorem 3.4, which bounds the approximation error, is independent                                    predicates (e.g., circular predicate (c, r) matching points p, ‚à•p ‚àí
of the aggregation function used and applies to any function.","However,
to bound the corresponding sampling error (Theorem 3.5 is specific
to SUM and COUNT).",2022-11-20 00:53:03+00:00,NeuroSketch: Fast and Approximate Evaluation of Range Aggregate Queries with Neural Networks,cs.DB,['cs.DB'],"[arxiv.Result.Author('Sepanta Zeighami'), arxiv.Result.Author('Cyrus Shahabi'), arxiv.Result.Author('Vatsal Sharan')]","Range aggregate queries (RAQs) are an integral part of many real-world
applications, where, often, fast and approximate answers for the queries are
desired. Recent work has studied answering RAQs using machine learning (ML)
models, where a model of the data is learned to answer the queries. However,
there is no theoretical understanding of why and when the ML based approaches
perform well. Furthermore, since the ML approaches model the data, they fail to
capitalize on any query specific information to improve performance in
practice. In this paper, we focus on modeling ``queries'' rather than data and
train neural networks to learn the query answers. This change of focus allows
us to theoretically study our ML approach to provide a distribution and query
dependent error bound for neural networks when answering RAQs. We confirm our
theoretical results by developing NeuroSketch, a neural network framework to
answer RAQs in practice. Extensive experimental study on real-world,
TPC-benchmark and synthetic datasets show that NeuroSketch answers RAQs
multiple orders of magnitude faster than state-of-the-art and with better
accuracy.",-0.2631256,0.032144878,-0.17984751,C
14568,"However, the GPS data
is so Ô¨Åne-grained that further study is required to understand how to process it.","By
comparing the truck path to a preset truck route based on domain knowledge,
we may assess whether there are operational deviations in the process, such as
whether the truck emptied the Ô¨Åller at a port location.","Hence, in this analysis scenario, we do not consider including the truck route as
a case attribute in the event log.",2022-12-05 07:35:35+00:00,AMORETTO: A Method for Deriving IoT-enriched Event Logs,cs.DB,['cs.DB'],"[arxiv.Result.Author('Jia Wei'), arxiv.Result.Author('Chun Ouyang'), arxiv.Result.Author('Arthur H. M. ter Hofstede'), arxiv.Result.Author('Catarina Moreira')]","Process analytics aims to gain insights into the behaviour and performance of
business processes through the analysis of event logs, which record the
execution of processes. With the widespread use of the Internet of Things
(IoT), IoT data has become readily available and can provide valuable context
information about business processes. As such, process analytics can benefit
from incorporating IoT data into event logs to support more comprehensive,
context-aware analyses. However, most existing studies focus on enhancing
business process models with IoT data, whereas little attention has been paid
to incorporating IoT data into event logs for process analytics. Hence, this
paper aims to systematically integrate IoT data into event logs to support
context-aware process analytics. To this end, we propose AMORETTO - a method
for deriving IoT-enriched event logs. Firstly, we provide a classification of
context data, referred to as the IoT-Pro context classification, which
encompasses two context dimensions: IoT context and process context. Next, we
present a method for integrating IoT data with event logs, guided by IoT-Pro,
to yield IoT-enriched event logs. To demonstrate the applicability of AMORETTO,
we applied it to a real-life use case and examined whether the derived
IoT-enriched event log sufficed to address certain specific analytical
questions.",-0.12187694,-0.15932934,0.06846941,C
15362,"However, these approaches are in their nascent stage
and further research is needed to explore these hybrid approaches.","As discussed in Section 3.3, there exist a few hybrid
approaches that attempt to leverage the best from both worlds to build
eÔ¨Äective NLIs.",Training examples.,2022-12-26 10:24:09+00:00,Natural Language Interfaces to Data,cs.DB,['cs.DB'],"[arxiv.Result.Author('Abdul Quamar'), arxiv.Result.Author('Vasilis Efthymiou'), arxiv.Result.Author('Chuan Lei'), arxiv.Result.Author('Fatma √ñzcan')]","Recent advances in NLU and NLP have resulted in renewed interest in natural
language interfaces to data, which provide an easy mechanism for non-technical
users to access and query the data. While early systems evolved from keyword
search and focused on simple factual queries, the complexity of both the input
sentences as well as the generated SQL queries has evolved over time. More
recently, there has also been a lot of focus on using conversational interfaces
for data analytics, empowering a line of non-technical users with quick
insights into the data. There are three main challenges in natural language
querying (NLQ): (1) identifying the entities involved in the user utterance,
(2) connecting the different entities in a meaningful way over the underlying
data source to interpret user intents, and (3) generating a structured query in
the form of SQL or SPARQL.
  There are two main approaches for interpreting a user's NLQ. Rule-based
systems make use of semantic indices, ontologies, and KGs to identify the
entities in the query, understand the intended relationships between those
entities, and utilize grammars to generate the target queries. With the
advances in deep learning (DL)-based language models, there have been many
text-to-SQL approaches that try to interpret the query holistically using DL
models. Hybrid approaches that utilize both rule-based techniques as well as DL
models are also emerging by combining the strengths of both approaches.
Conversational interfaces are the next natural step to one-shot NLQ by
exploiting query context between multiple turns of conversation for
disambiguation. In this article, we review the background technologies that are
used in natural language interfaces, and survey the different approaches to
NLQ. We also describe conversational interfaces for data analytics and discuss
several benchmarks used for NLQ research and evaluation.",-0.13760355,-0.16264239,-0.004476995,A
