Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
152,"This paper only considers OpenMP and CUDA implementations for the proposed
parallel GS algorithm and further research will be conducted for MPI parallelism.","In the future,
parallel performance of the adaptive SETUP multi-stage preconditioners needs to be further
Li Zhao, Chunsheng Feng, Chensong Zhang and Shi Shu  17

improved.",Acknowledgments.,2022-01-06 08:38:13+00:00,Parallel Multi-Stage Preconditioners with Adaptive Setup for the Black Oil Model,math.NA,"['math.NA', 'cs.NA', 'math-ph', 'math.MP', '49M20, 65F10, 68W10, 76S05', 'F.2.1']","[arxiv.Result.Author('Li Zhao'), arxiv.Result.Author('Chunsheng Feng'), arxiv.Result.Author('Chensong Zhang'), arxiv.Result.Author('Shi Shu')]","The black oil model is widely used to describe multiphase porous media flow
in the petroleum industry. The fully implicit method features strong stability
and weak constraints on time step-sizes; hence, commonly used in the current
mainstream commercial reservoir simulators. In this paper, a CPR-type
preconditioner with an adaptive ""setup phase"" is developed to improve parallel
efficiency of petroleum reservoir simulation. Furthermore, we propose a
multi-color Gauss-Seidel (GS) algorithm for algebraic multigrid method based on
the coefficient matrix of strong connections. Numerical experiments show that
the proposed preconditioner can improve the parallel performance for both
OpenMP and CUDA implements. Moreover, the proposed algorithm yields good
parallel speedup as well as same convergence behavior as the corresponding
single-threaded algorithm. In particular, for a three-phase benchmark problem,
the parallel speedup of the OpenMP version is over 6.5 with 16 threads and the
CUDA version reaches more than 9.5.",-0.27382523,0.11585212,-0.22205521,A
153,"This paper
only considered OpenMP and CUDA implementations for the proposed parallel GS algorithm,
so further research will be conducted for MPI parallelism.","In the future, the parallel performance of
the adaptive SETUP multi-stage preconditioners needs to be further improved.",Acknowledgments.,2022-01-06 08:38:13+00:00,Parallel Multi-Stage Preconditioners with Adaptive Setup for the Black Oil Model,math.NA,"['math.NA', 'cs.NA', 'math-ph', 'math.MP', '49M20, 65F10, 68W10, 76S05', 'F.2.1']","[arxiv.Result.Author('Li Zhao'), arxiv.Result.Author('Chunsheng Feng'), arxiv.Result.Author('Chensong Zhang'), arxiv.Result.Author('Shi Shu')]","The black oil model is widely used to describe multiphase porous media flow
in the petroleum industry. The fully implicit method features strong stability
and weak constraints on time step-sizes; hence, commonly used in the current
mainstream commercial reservoir simulators. In this paper, a CPR-type
preconditioner with an adaptive ""setup phase"" is developed to improve parallel
efficiency of petroleum reservoir simulation. Furthermore, we propose a
multi-color Gauss-Seidel (GS) algorithm for algebraic multigrid method based on
the coefficient matrix of strong connections. Numerical experiments show that
the proposed preconditioner can improve the parallel performance for both
OpenMP and CUDA implements. Moreover, the proposed algorithm yields good
parallel speedup as well as same convergence behavior as the corresponding
single-threaded algorithm. In particular, for a three-phase benchmark problem,
the parallel speedup of the OpenMP version is over 6.5 with 16 threads and the
CUDA version reaches more than 9.5.",-0.2866565,0.12241782,-0.21980877,A
322,"In this case, maybe manually tuning the Robin parameter αROB to achieve optimal
convergence can be a better idea, in order to drop the dependence on ∆T : further research
in this direction needs to be carried out.","This idea is presented for example in [64] for a monolithic
scheme, but it represents an interesting starting point for a future work within partitioned
schemes.","Acknowledgements

   We acknowledge the support by European Union Funding for Research and Innovation –
Horizon 2020 Program – in the framework of European Research Council Executive Agency:
Consolidator Grant H2020 ERC CoG 2015 AROMA-CFD project 681447 “Advanced Reduced
Order Methods with Applications in Computational Fluid Dynamics” (PI Prof. Gianluigi
Rozza).",2022-01-10 09:40:28+00:00,Projection based semi--implicit partitioned Reduced Basis Method for non parametrized and parametrized Fluid--Structure Interaction problems,math.NA,"['math.NA', 'cs.NA', '65Z05, 65Y9, 65M99']","[arxiv.Result.Author('Monica Nonino'), arxiv.Result.Author('Francesco Ballarin'), arxiv.Result.Author('Gianluigi Rozza'), arxiv.Result.Author('Yvon Maday')]","We present a partitioned Model Order Reduction method for multiphysics
problems, that is based on a semi-implicit treatment of the coupling
conditions, and on a projection scheme. The proposed Reduced Order Method is
based on the Proper Orthogonal Decomposition and on a Galerkin projection onto
the reduced basis spaces; we aim of addressing both time-dependent and
time-dependent, parametrized Fluid-Structure Interaction problems, where the
fluid is incompressible and the structure is linear, elastic and two
dimensional.",-0.009409146,-0.09791213,-0.2394964,C
391,"However, it there
is not an obvious relation between and k, so further research may be necessary to ﬁnd a more eﬃcient
doubly adaptive algorithm.","An algorithm that adapts and k

                                                                                       20
independently may be inferior to one that relates the step size to the penalty parameter.","The pressure recovered directly from the continuity equation, ∇ · u + p = 0
(1.2) is not good estimate to the pressure from coupled system.",2022-01-11 14:44:43+00:00,A Doubly Adaptive Penalty Method for the Navier Stokes Equations,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Xihui Xie'), arxiv.Result.Author('Kiera Kean'), arxiv.Result.Author('Shuxian Xu')]","We develop, analyze and test adaptive penalty parameter methods. We prove
unconditional stability for velocity when adapting the penalty parameter,
$\epsilon,$ and stability of the velocity time derivative under a condition on
the change of the penalty parameter, $\epsilon(t_{n+1})-\epsilon(t_n)$. The
analysis and tests show that adapting $\epsilon(t_{n+1})$ in response to
$\nabla\cdot u(t_n)$ removes the problem of picking $\epsilon$ and yields good
approximations for the velocity. We provide error analysis and numerical tests
to support these results. We supplement the adaptive-$\epsilon$ method by also
adapting the time-step. The penalty parameter $\epsilon$ and time-step are
adapted independently. We further compare first, second and variable order
time-step algorithms. Accurate recovery of pressure remains an open problem.",0.099708326,-0.014848412,-0.20200302,B
392,"The ﬁnite element
discretization has a maximal mesh width of hmax = 0.0347224.

is not an obvious relation between and k, so further research may be necessary to ﬁnd a more eﬃcient
doubly adaptive algorithm.","Tests
without penalty use 320 mesh points around the outer circle and 80 mesh points around the inner circle.","The pressure recovered directly from the continuity equation, ∇ · u + p = 0
(1.2) is not good estimate to the pressure from coupled system.",2022-01-11 14:44:43+00:00,A Doubly Adaptive Penalty Method for the Navier Stokes Equations,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Kiera Kean'), arxiv.Result.Author('Xihui Xie'), arxiv.Result.Author('Shuxian Xu')]","We develop, analyze and test adaptive penalty parameter methods. We prove
unconditional stability for velocity when adapting the penalty parameter,
$\epsilon,$ and stability of the velocity time derivative under a condition on
the change of the penalty parameter, $\epsilon(t_{n+1})-\epsilon(t_n)$. The
analysis and tests show that adapting $\epsilon(t_{n+1})$ in response to
$\nabla\cdot u(t_n)$ removes the problem of picking $\epsilon$ and yields good
approximations for the velocity. We provide error analysis and numerical tests
to support these results. We supplement the adaptive-$\epsilon$ method by also
adapting the time-step. The penalty parameter $\epsilon$ and time-step are
adapted independently. We further compare first, second and variable order
time-step algorithms. Accurate recovery of pressure remains an open problem.",0.1380938,0.006370548,-0.09448609,B
442,"The
analysis of applicability of the iterative algorithm in such problems refers to prospects
for further research.","This is especially important in three-dimensional inverse prob-
lems, an example of which is the nonadiabatic mode tomography of ocean [17].","18

5 Acknowledgement

The reported study was funded by RFBR and CNRS, project number 20-51-15004.",2022-01-12 16:32:28+00:00,Numerical comparison of iterative and functional-analytical algorithms for inverse acoustic scattering,math.NA,"['math.NA', 'cs.NA', 'physics.comp-ph', 'physics.med-ph', '35R30, 65N21']",[arxiv.Result.Author('A. S. Shurup')],"In this work the numerical solution of acoustic tomography problem based on
the iterative and functional-analytical algorithms is considered. The
mathematical properties of these algorithms were previously described in works
of R.G.Novikov for the case of the Schr\""odinger equation. In the present work,
for the case of two-dimensional scalar Helmholtz equation, the efficiency of
the iterative algorithm in reconstruction of middle strength scatterers and
advantages of the functional-analytical approach in recovering strong
scatterers are demonstrated. A filtering procedure is considered in the space
of wave vectors, which additionally increases the convergence of the iterative
algorithm. Reconstruction results of sound speed perturbations demonstrate the
comparable noise immunity and resolution of the considered algorithms when
reconstructing middle strength scatterers. A comparative numerical
investigation of the iterative and functional-analytical algorithms in inverse
acoustic scattering problems is implemented in this work for the first time.",-0.0772559,0.04855641,0.0031528287,A
591,"The numerical results we present above make a strong case for further study of
the approach.","The use of SW-ELM as a surrogate in the context of variance based GSA
allows the user to completely eschew Monte Carlo integration which is a perennial bottleneck
in this ﬁeld.","In particular, there is in general very little known theoretically regarding the
link from (4.1) (accurate surrogate) to (4.2) (accurate GSA).",2022-01-14 18:16:23+00:00,Extreme learning machines for variance-based global sensitivity analysis,math.NA,"['math.NA', 'cs.NA', 'math.ST', 'stat.TH']","[arxiv.Result.Author('John Darges'), arxiv.Result.Author('Alen Alexanderian'), arxiv.Result.Author('Pierre Gremaud')]","Variance-based global sensitivity analysis (GSA) can provide a wealth of
information when applied to complex models. A well-known Achilles' heel of this
approach is its computational cost which often renders it unfeasible in
practice. An appealing alternative is to analyze instead the sensitivity of a
surrogate model with the goal of lowering computational costs while maintaining
sufficient accuracy. Should a surrogate be ""simple"" enough to be amenable to
the analytical calculations of its Sobol' indices, the cost of GSA is
essentially reduced to the construction of the surrogate. We propose a new
class of sparse weight Extreme Learning Machines (SW-ELMs) which, when
considered as surrogates in the context of GSA, admit analytical formulas for
their Sobol' indices and, unlike the standard ELMs, yield accurate
approximations of these indices. The effectiveness of this approach is
illustrated through both traditional benchmarks in the field and on a chemical
reaction network.",-0.16323544,0.103839226,0.111846216,C
1013,"In Section 6, we draw
conclusions and make suggestions for further research.","We then extend our formulation to a non-linear application in Section 5, and
study the impact of necessary simpliﬁcations on the solution quality.",2.,2022-01-25 17:20:24+00:00,Variationally consistent mass scaling for explicit time-integration schemes of lower- and higher-order finite element methods,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Stein K. F. Stoter'), arxiv.Result.Author('Thi-Hoa Nguyen'), arxiv.Result.Author('René R. Hiemstra'), arxiv.Result.Author('Dominik Schillinger')]","In this paper, we propose a variationally consistent technique for decreasing
the maximum eigenfrequencies of structural dynamics related finite element
formulations. Our approach is based on adding a symmetric positive-definite
term to the mass matrix that follows from the integral of the traction jump
across element boundaries. The added term is weighted by a small factor, for
which we derive a suitable, and simple, element-local parameter choice. For
linear problems, we show that our mass-scaling method produces no adverse
effects in terms of spatial accuracy and orders of convergence. We illustrate
these properties in one, two and three spatial dimension, for quadrilateral
elements and triangular elements, and for up to fourth order polynomials basis
functions. To extend the method to non-linear problems, we introduce a linear
approximation and show that a sizeable increase in critical time-step size can
be achieved while only causing minor (even beneficial) influences on the
dynamic response.",0.21685934,0.08529033,-0.09510255,C
1044,We further study the collapse of the localized EKI ensemble in this example.,"Moreover, localization accelerates the convergence
of EKI with respect to the ensemble size (at any ﬁxed dimension).","We now ﬁx the dimension to du = dy = 50 and consider the rate at which the
ensemble collapses and at which error is reduced during the iteration.",2022-01-26 08:53:12+00:00,Localized Ensemble Kalman inversion,math.NA,"['math.NA', 'cs.NA', 'stat.CO']","[arxiv.Result.Author('Xin T. Tong'), arxiv.Result.Author('Matthias Morzfeld')]","Ensemble Kalman inversion (EKI) is a technique for the numerical solution of
inverse problems. A great advantage of the EKI's ensemble approach is that
derivatives are not required in its implementation. But theoretically speaking,
EKI's ensemble size needs to surpass the dimension of the problem. This is
because of EKI's ""subspace property"", i.e., that the EKI solution is a linear
combination of the initial ensemble it starts off with. We show that the
ensemble can break out of this initial subspace when ``localization'' is
applied. In essence, localization enforces an assumed correlation structure
onto the problem, and is heavily used in ensemble Kalman filtering and data
assimilation. We describe and analyze how to apply localization to the EKI, and
how localization helps the EKI ensemble break out of the initial subspace.
Specifically, we show that the localized EKI (LEKI) ensemble will collapse to a
single point (as intended) and that the LEKI ensemble mean will converge to the
global optimum at a sublinear rate. Under strict assumptions on the
localization procedure and observation process, we further show that the data
misfit decays uniformly. We illustrate our ideas and theoretical developments
with numerical examples with simplified toy problems, a Lorenz model, and an
inversion of electromagnetic data, where some of our mathematical assumptions
may only be approximately valid.",0.12716478,-0.010457372,0.24795699,B
1045,We further study the collapse of the localized EKI ensemble in this example.,"Moreover, localization accelerates the convergence
of EKI with respect to the ensemble size (at any ﬁxed dimension).","We now ﬁx the dimension to du = dy = 50 and consider the rate at which the
ensemble collapses and at which error is reduced during the iteration.",2022-01-26 08:53:12+00:00,Localization in Ensemble Kalman inversion,math.NA,"['math.NA', 'cs.NA', 'stat.CO']","[arxiv.Result.Author('Xin T. Tong'), arxiv.Result.Author('Matthias Morzfeld')]","Ensemble Kalman inversion (EKI) is a technique for the numerical solution of
inverse problems. A great advantage of the EKI's ensemble approach is that
derivatives are not required in its implementation. But theoretically speaking,
EKI's ensemble size needs to surpass the dimension of the problem. This is
because of EKI's ""subspace property"", i.e., that the EKI solution is a linear
combination of the initial ensemble it starts off with. We show that the
ensemble can break out of this initial subspace when ""localization"" is applied.
In essence, localization enforces an assumed correlation structure onto the
problem, and is heavily used in ensemble Kalman filtering and data
assimilation. We describe and analyze how to apply localization to the EKI, and
how localization helps the EKI ensemble break out of the initial subspace.
Specifically, we show that the localized EKI (LEKI) ensemble will collapse to a
single point (as intended) and that the LEKI ensemble mean will converge to the
global optimum at a sublinear rate. Under strict assumptions on the
localization procedure and observation process, we further show that the data
misfit decays uniformly. We illustrate our ideas and theoretical developments
with numerical examples with simplified toy problems, a Lorenz model, and an
inversion of electromagnetic data, where some of our mathematical assumptions
may only be approximately valid.",0.12716478,-0.010457372,0.24795699,B
1133,"In addition to further study of collocation methods, we believe the framework of oversampling
could also prove advantageous in improving convergence properties of Nystr¨om methods for
Fredholm integral equations [15, Chapter 12].","Thus
we expect that further extensions of this result are possible and these will be explored in future
research.","Nystr¨om methods can in many cases be regarded
as a further level of discretisation from collocation methods, which suggests that some of the
favourable features of oversampling may be inherited in this setting [4].",2022-01-27 17:32:36+00:00,An analysis of least-squares oversampled collocation methods for compactly perturbed boundary integral equations in two dimensions,math.NA,"['math.NA', 'cs.NA', '45B05, 65N35']","[arxiv.Result.Author('Georg Maierhofer'), arxiv.Result.Author('Daan Huybrechs')]","In recent work (Maierhofer & Huybrechs, 2022, Adv. Comput. Math.), the
authors showed that least-squares oversampling can improve the convergence
properties of collocation methods for boundary integral equations involving
operators of certain pseudo-differential form. The underlying principle is that
the discrete method approximates a Bubnov$-$Galerkin method in a suitable
sense. In the present work, we extend this analysis to the case when the
integral operator is perturbed by a compact operator $\mathcal{K}$ which is
continuous as a map on Sobolev spaces on the boundary,
$\mathcal{K}:H^{p}\rightarrow H^{q}$ for all $p,q\in\mathbb{R}$.
  This study is complicated by the fact that both the test and trial functions
in the discrete Bubnov-Galerkin orthogonality conditions are modified over the
unperturbed setting. Our analysis guarantees that previous results concerning
optimal convergence rates and sufficient rates of oversampling are preserved in
the more general case. Indeed, for the first time, this analysis provides a
complete explanation of the advantages of least-squares oversampled collocation
for boundary integral formulations of the Laplace equation on arbitrary smooth
Jordan curves in 2D. Our theoretical results are shown to be in very good
agreement with numerical experiments.",0.022709176,-0.13469948,-0.09224121,C
1180,"This matter deserves further research, and we plan to investigate whether we can employ reasonably larger
data sets in ﬁne grids.","Although this metric has dropped below the previous system’s error in most cases, it increased by 15%
for η = 9.","Nevertheless, our strategy has outperformed the numerical baseline in all scenarios.",2022-01-22 05:14:40+00:00,Error-Correcting Neural Networks for Two-Dimensional Curvature Computation in the Level-Set Method,math.NA,"['math.NA', 'cs.LG', 'cs.NA', '68T99, 65Z05, 65N06', 'I.2.6; G.1.8']","[arxiv.Result.Author('Luis Ángel Larios-Cárdenas'), arxiv.Result.Author('Frédéric Gibou')]","We present an error-neural-modeling-based strategy for approximating
two-dimensional curvature in the level-set method. Our main contribution is a
redesigned hybrid solver (Larios-C\'{a}rdenas and Gibou (2021)[1]) that relies
on numerical schemes to enable machine-learning operations on demand. In
particular, our routine features double predicting to harness curvature
symmetry invariance in favor of precision and stability. As in [1], the core of
this solver is a multilayer perceptron trained on circular- and
sinusoidal-interface samples. Its role is to quantify the error in numerical
curvature approximations and emit corrected estimates for select grid vertices
along the free boundary. These corrections arise in response to preprocessed
context level-set, curvature, and gradient data. To promote neural capacity, we
have adopted sample negative-curvature normalization, reorientation, and
reflection-based augmentation. In the same manner, our system incorporates
dimensionality reduction, well-balancedness, and regularization to minimize
outlying effects. Our training approach is likewise scalable across mesh sizes.
For this purpose, we have introduced dimensionless parametrization and
probabilistic subsampling during data production. Together, all these elements
have improved the accuracy and efficiency of curvature calculations around
under-resolved regions. In most experiments, our strategy has outperformed the
numerical baseline at twice the number of redistancing steps while requiring
only a fraction of the cost.",-0.0887398,0.27816206,0.2849105,A
1181,"This matter deserves further research, and we plan to investigate whether we can employ reasonably larger
data sets in ﬁne grids.","Although this metric has dropped below the previous system’s error in most cases, it increased by 15%
for η = 9.","Nevertheless, our strategy has outperformed the numerical baseline in all scenarios.",2022-01-22 05:14:40+00:00,Error-Correcting Neural Networks for Two-Dimensional Curvature Computation in the Level-Set Method,math.NA,"['math.NA', 'cs.LG', 'cs.NA', '68T99, 65Z05, 65N06', 'I.2.6; G.1.8']","[arxiv.Result.Author('Luis Ángel Larios-Cárdenas'), arxiv.Result.Author('Frédéric Gibou')]","We present an error-neural-modeling-based strategy for approximating
two-dimensional curvature in the level-set method. Our main contribution is a
redesigned hybrid solver [Larios-C\'ardenas and Gibou, J. Comput. Phys. (May
2022), 10.1016/j.jcp.2022.111291] that relies on numerical schemes to enable
machine-learning operations on demand. In particular, our routine features
double predicting to harness curvature symmetry invariance in favor of
precision and stability. The core of this solver is a multilayer perceptron
trained on circular- and sinusoidal-interface samples. Its role is to quantify
the error in numerical curvature approximations and emit corrected estimates
for select grid vertices along the free boundary. These corrections arise in
response to preprocessed context level-set, curvature, and gradient data. To
promote neural capacity, we have adopted sample negative-curvature
normalization, reorientation, and reflection-based augmentation. In the same
manner, our system incorporates dimensionality reduction, well-balancedness,
and regularization to minimize outlying effects. Our training approach is
likewise scalable across mesh sizes. For this purpose, we have introduced
dimensionless parametrization and probabilistic subsampling during data
production. Together, all these elements have improved the accuracy and
efficiency of curvature calculations around under-resolved regions. In most
experiments, our strategy has outperformed the numerical baseline at twice the
number of redistancing steps while requiring only a fraction of the cost.",-0.0887398,0.27816206,0.2849105,A
1182,"This matter deserves further research, and we plan to investigate whether we can employ reasonably larger
data sets in ﬁne grids.","Although this metric has dropped below the previous system’s error in most cases, it increased by 15%
for η = 9.","Nevertheless, our strategy has outperformed the numerical baseline in all scenarios.",2022-01-22 05:14:40+00:00,Error-Correcting Neural Networks for Two-Dimensional Curvature Computation in the Level-Set Method,math.NA,"['math.NA', 'cs.LG', 'cs.NA', '68T99, 65Z05, 65N06', 'I.2.6; G.1.8']","[arxiv.Result.Author('Luis Ángel Larios-Cárdenas'), arxiv.Result.Author('Frédéric Gibou')]","We present an error-neural-modeling-based strategy for approximating
two-dimensional curvature in the level-set method. Our main contribution is a
redesigned hybrid solver [Larios-C\'ardenas and Gibou, J. Comput. Phys. (May
2022), 10.1016/j.jcp.2022.111291] that relies on numerical schemes to enable
machine-learning operations on demand. In particular, our routine features
double predicting to harness curvature symmetry invariance in favor of
precision and stability. The core of this solver is a multilayer perceptron
trained on circular- and sinusoidal-interface samples. Its role is to quantify
the error in numerical curvature approximations and emit corrected estimates
for select grid vertices along the free boundary. These corrections arise in
response to preprocessed context level-set, curvature, and gradient data. To
promote neural capacity, we have adopted sample negative-curvature
normalization, reorientation, and reflection-based augmentation. In the same
manner, our system incorporates dimensionality reduction, well-balancedness,
and regularization to minimize outlying effects. Our training approach is
likewise scalable across mesh sizes. For this purpose, we have introduced
dimensionless parametrization and probabilistic subsampling during data
production. Together, all these elements have improved the accuracy and
efficiency of curvature calculations around under-resolved regions. In most
experiments, our strategy has outperformed the numerical baseline at twice the
number of redistancing steps while requiring only a fraction of the cost.",-0.0887398,0.27816206,0.2849105,A
1490,"Summary of this paper is provided in section 4, as well
as directions for further research.","We also carry out numerical experiments
which illustrate theoretical ﬁndings.",1.,2022-02-03 16:49:49+00:00,On the properties of the exceptional set for the randomized Euler and Runge-Kutta schemes,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Tomasz Bochacik')],"We show that the probability of the exceptional set decays exponentially for
a broad class of randomized algorithms approximating solutions of ODEs,
admitting a certain error decomposition. This class includes randomized
explicit and implicit Euler schemes, and the randomized two-stage Runge-Kutta
scheme (under inexact information). We design a confidence interval for the
exact solution of an IVP and perform numerical experiments to illustrate the
theoretical results.",0.2232686,-0.13782607,0.058151964,B
1491,"Our future plans include further research related to the probabilistic distribution of the
error of randomized algorithms for ODEs, e.g.","Theorem 1 covers also the family of Taylor schemes under exact
information, which has been investigated in [6].",investigation of its asymptotic behaviour.,2022-02-03 16:49:49+00:00,On the properties of the exceptional set for the randomized Euler and Runge-Kutta schemes,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Tomasz Bochacik')],"We show that the probability of the exceptional set decays exponentially for
a broad class of randomized algorithms approximating solutions of ODEs,
admitting a certain error decomposition. This class includes randomized
explicit and implicit Euler schemes, and the randomized two-stage Runge-Kutta
scheme (under inexact information). We design a confidence interval for the
exact solution of an IVP and perform numerical experiments to illustrate the
theoretical results.",0.014636833,-0.10403712,0.12827992,B
2097,"The paper concludes with a
summary and some directions for further research in section 6.",Numerical testing is presented in section 5.,"The supplementary
material contains most proofs and additional algorithms, code, and numerical results.",2022-02-16 22:30:43+00:00,Vectorization of the Jacobi-type singular value decomposition method,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F15 (Primary) 65F25, 65Y05, 65Y10 (Secondary)', 'G.1.3; G.4']",[arxiv.Result.Author('Vedran Novaković')],"The eigenvalue decomposition (EVD) of (a batch of) Hermitian matrices of
order two has a role in many numerical algorithms, of which the one-sided
Jacobi method for the singular value decomposition (SVD) is the prime example.
In this paper the batched EVD is vectorized, with a vector-friendly data layout
and the AVX-512 SIMD instructions of Intel CPUs, alongside other key components
of a real and a complex OpenMP-parallel Jacobi-type SVD method, inspired by the
sequential xGESVJ routines from LAPACK. These vectorized building blocks should
be portable to other platforms, with unconditional reproducibility guaranteed
for the batched EVD and several others. No avoidable overflow of the results
can occur with the proposed EVD or SVD. The measured accuracy of the proposed
EVD often surpasses that of the xLAEV2 routines from LAPACK. While the batched
EVD outperforms the matching sequence of xLAEV2 calls, speedup of the parallel
SVD is modest but can be improved and is already beneficial with enough
threads. Regardless of their number, the proposed SVD method gives identical
results, but of somewhat lower accuracy than xGESVJ.",-0.1341294,-0.11154352,-0.12532562,A
2098,"The paper concludes with a
summary and some directions for further research in section 6.",Numerical testing is presented in section 5.,"The Appendix contains
most proofs and additional algorithms, code, and numerical results.",2022-02-16 22:30:43+00:00,Vectorization of a thread-parallel Jacobi singular value decomposition method,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F15 (Primary) 65F25, 65Y05, 65Y10 (Secondary)', 'G.1.3; G.4']",[arxiv.Result.Author('Vedran Novaković')],"The eigenvalue decomposition (EVD) of (a batch of) Hermitian matrices of
order two has a role in many numerical algorithms, of which the one-sided
Jacobi method for the singular value decomposition (SVD) is the prime example.
In this paper the batched EVD is vectorized, with a vector-friendly data layout
and the AVX-512 SIMD instructions of Intel CPUs, alongside other key components
of a real and a complex OpenMP-parallel Jacobi-type SVD method, inspired by the
sequential xGESVJ routines from LAPACK. These vectorized building blocks should
be portable to other platforms that support similar vector operations.
Unconditional numerical reproducibility is guaranteed for the batched EVD,
sequential or threaded, and for the column transformations, that are, like the
scaled dot-products, presently sequential but can be threaded if nested
parallelism is desired. No avoidable overflow of the results can occur with the
proposed EVD or the whole SVD. The measured accuracy of the proposed EVD often
surpasses that of the xLAEV2 routines from LAPACK. While the batched EVD
outperforms the matching sequence of xLAEV2 calls, speedup of the parallel SVD
is modest but can be improved and is already beneficial with enough threads.
Regardless of their number, the proposed SVD method gives identical results,
but of somewhat lower accuracy than xGESVJ.",-0.14788765,-0.07907878,-0.14034632,A
2099,"The paper concludes with
a summary and some directions for further research in section 6.",Numerical testing is presented in section 5.,"Appendix contains
most proofs and additional algorithms, code, and numerical results.",2022-02-16 22:30:43+00:00,Vectorization of a thread-parallel Jacobi singular value decomposition method,math.NA,"['math.NA', 'cs.MS', 'cs.NA', '65F15 (Primary) 65F25, 65Y05, 65Y10 (Secondary)', 'G.1.3; G.4']",[arxiv.Result.Author('Vedran Novaković')],"The eigenvalue decomposition (EVD) of (a batch of) Hermitian matrices of
order two has a role in many numerical algorithms, of which the one-sided
Jacobi method for the singular value decomposition (SVD) is the prime example.
In this paper the batched EVD is vectorized, with a vector-friendly data layout
and the AVX-512 SIMD instructions of Intel CPUs, alongside other key components
of a real and a complex OpenMP-parallel Jacobi-type SVD method, inspired by the
sequential xGESVJ routines from LAPACK. These vectorized building blocks should
be portable to other platforms that support similar vector operations.
Unconditional numerical reproducibility is guaranteed for the batched EVD,
sequential or threaded, and for the column transformations, that are, like the
scaled dot-products, presently sequential but can be threaded if nested
parallelism is desired. No avoidable overflow of the results can occur with the
proposed EVD or the whole SVD. The measured accuracy of the proposed EVD often
surpasses that of the xLAEV2 routines from LAPACK. While the batched EVD
outperforms the matching sequence of xLAEV2 calls, speedup of the parallel SVD
is modest but can be improved and is already beneficial with enough threads.
Regardless of their number, the proposed SVD method gives identical results,
but of somewhat lower accuracy than xGESVJ.",-0.14244553,-0.09078878,-0.13640982,A
2111,"This diﬀerent scaling in the velocities is fundamental for the further study, the rescaled
velocities v being now of the same order for ions and electrons, fact which is a considerable
advantage for numerical simulations.","To get the non-
dimensional system, let us perform the following change of variables in the starting model
(2.1)

                                            x = xx , t = tt ,

whereas the velocities (in the two diﬀerent kinetic equations) scale diﬀerently for ions and
electrons, namely

                                           vi = vi v , ve = vev .","Furthermore, in (2.2) we set

                                             E(t, x) = E E (t , x ) .",2022-02-17 09:33:45+00:00,Fokker-Planck multi-species equations in the adiabatic asymptotics,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Francis Filbet'), arxiv.Result.Author('Claudia Negulescu')]","The main concern of the present paper is the study of the multi-scale
dynamics of thermonuclear fusion plasmas via a multi-species Fokker-Planck
kinetic model. One of the goals is the generalization of the standard
Fokker-Planck collision operator to a multispecies one, conserving mass, total
momentum and energy, as well as satisfying Boltzmann's H-theorem. Secondly, the
paper investigates in more details the reduced model used for the electron
description in present simulations, and which considers the electrons in a
thermodynamic equilibrium (adiabatic regime), whereas the ions are kept
kinetic. On the one hand, we perform some mathematical asymptotic limits to
obtain in the electron/ion low mass ratio limit the above-mentioned electron
adiabatic regime. On the other hand, we develop a numerical scheme , based on a
Hermite spectral method, and perfom numerical simulations to illustrate and
investigate in more details this asymptotics.",0.35520184,-0.07158902,-0.040110134,B
2112,"Hence, the time-step ∆t is still ε-dependent since the induced linear

system is not well conditionned, an AP-scheme is further needed to cope with this problem

                                        22
and require a further study [15].","It is worth to emphasize that this time discretization is not necessarily uniformly stable

with respect to ε.","However the Crank-Nicolson scheme is well adapted to our
approach where the preservation of energy plays a key role.",2022-02-17 09:33:45+00:00,Fokker-Planck multi-species equations in the adiabatic asymptotics,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Francis Filbet'), arxiv.Result.Author('Claudia Negulescu')]","The main concern of the present paper is the study of the multi-scale
dynamics of thermonuclear fusion plasmas via a multi-species Fokker-Planck
kinetic model. One of the goals is the generalization of the standard
Fokker-Planck collision operator to a multispecies one, conserving mass, total
momentum and energy, as well as satisfying Boltzmann's H-theorem. Secondly, the
paper investigates in more details the reduced model used for the electron
description in present simulations, and which considers the electrons in a
thermodynamic equilibrium (adiabatic regime), whereas the ions are kept
kinetic. On the one hand, we perform some mathematical asymptotic limits to
obtain in the electron/ion low mass ratio limit the above-mentioned electron
adiabatic regime. On the other hand, we develop a numerical scheme , based on a
Hermite spectral method, and perfom numerical simulations to illustrate and
investigate in more details this asymptotics.",0.23841959,-0.25492156,-0.1938811,B
2113,"This diﬀerent scaling in the velocities is fundamental for the further study, the rescaled
velocities v being now of the same order for ions and electrons, fact which is a considerable
advantage for numerical simulations.","To get the non-
dimensional system, let us perform the following change of variables in the starting model
(2.1)

                                            x = xx , t = tt ,

whereas the velocities (in the two diﬀerent kinetic equations) scale diﬀerently for ions and
electrons, namely

                                           vi = vi v , ve = vev .","Furthermore, in (2.2) we set

                                             E(t, x) = E E (t , x ) .",2022-02-17 09:33:45+00:00,Fokker-planck Multi-species Equations In The Adiabatic Asymptotics,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Francis Filbet'), arxiv.Result.Author('Claudia Negulescu')]","The main concern of the present paper is the study of the multi-scale
dynamics of thermonuclear fusion plasmas via a multi-species Fokker-Planck
kinetic model. One of the goals is the generalization of the standard
Fokker-Planck collision operator to a multispecies one, conserving mass, total
momentum and energy, as well as satisfying Boltzmann's H-theorem. Secondly, the
paper investigates in more details the reduced model used for the electron
description in present simulations, and which considers the electrons in a
thermodynamic equilibrium (adiabatic regime), whereas the ions are kept
kinetic. On the one hand, we perform some mathematical asymptotic limits to
obtain in the electron/ion low mass ratio limit the above-mentioned electron
adiabatic regime. On the other hand, we develop a numerical scheme , based on a
Hermite spectral method, and perfom numerical simulations to illustrate and
investigate in more details this asymptotics.",0.35520184,-0.07158902,-0.040110134,B
2114,"An
AP-scheme is further needed to cope with this problem and this requires a further study [15].","In practice, to ensure the
convergence of the iterative method, the time-step ∆t is still dependent on ε and (h, NH).","However the Crank-Nicolson scheme is well adapted to our approach where the preservation
of energy plays a key role.",2022-02-17 09:33:45+00:00,Fokker-planck Multi-species Equations In The Adiabatic Asymptotics,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Francis Filbet'), arxiv.Result.Author('Claudia Negulescu')]","The main concern of the present paper is the study of the multi-scale
dynamics of thermonuclear fusion plasmas via a multi-species Fokker-Planck
kinetic model. One of the goals is the generalization of the standard
Fokker-Planck collision operator to a multispecies one, conserving mass, total
momentum and energy, as well as satisfying Boltzmann's H-theorem. Secondly, the
paper investigates in more details the reduced model used for the electron
description in present simulations, and which considers the electrons in a
thermodynamic equilibrium (adiabatic regime), whereas the ions are kept
kinetic. On the one hand, we perform some mathematical asymptotic limits to
obtain in the electron/ion low mass ratio limit the above-mentioned electron
adiabatic regime. On the other hand, we develop a numerical scheme , based on a
Hermite spectral method, and perfom numerical simulations to illustrate and
investigate in more details this asymptotics.",0.010065337,-0.24065268,-0.3272576,B
2362,"As a matter of further research, we aim to extend the proposed approach to the spatial case.","Beside of being easy to

                                                                  15
implement and simple to use in practice, the proposed method can be directly applied to a (local) construction of G2
continuous interpolating splines, as shown in the ﬁnal examples.","We believe the
extension is possible but not so straightforward.",2022-02-23 09:25:09+00:00,Construction of $G^2$ planar Hermite interpolants with prescribed arc lengths,math.NA,"['math.NA', 'cs.NA', 'math.DG', '65N38 (Primary) 65S05 (Secondary)']","[arxiv.Result.Author('Marjeta Knez'), arxiv.Result.Author('Francesca Pelosi'), arxiv.Result.Author('Maria Lucia Sampoli')]","In this paper we address the problem of constructing $G^2$ planar
Pythagorean--hodograph (PH) spline curves, that interpolate points, tangent
directions and curvatures, and have prescribed arc-length. The interpolation
scheme is completely local. Each spline segment is defined as a PH biarc curve
of degree $7$, which results in having a closed form solution of the $G^2$
interpolation equations depending on four free parameters. By fixing two of
them to zero, it is proven that the length constraint can be satisfied for any
data and any chosen ratio between the two boundary tangents. Length
interpolation equation reduces to one algebraic equation with four solutions in
general. To select the best one, the value of the bending energy is observed.
Several numerical examples are provided to illustrate the obtained theoretical
results and to numerically confirm that the approximation order is $5$.",0.07519186,0.23367162,0.05677296,C
2432,"It may be said that the works of these authors
                                          become a basis for further research on decomposition schemes.","A. Samarskii [34], [35]).","Decomposition schemes in view of numerical calculation can be divided into two groups:
                                          schemes of sequential account (see for example G. I. Marchuk [22], A.",2022-02-19 18:59:19+00:00,Parallel Type Decomposition Scheme for Quasi-Linear Abstract Hyperbolic Equation,math.NA,"['math.NA', 'cs.NA', 'math.AP', '65M12, 65M15, 65M55, 49M27', 'G.1.0; G.1.4; G.1.8']","[arxiv.Result.Author('Nana Dikhaminjia'), arxiv.Result.Author('Jemal Rogava'), arxiv.Result.Author('Mikheil Tsiklauri')]","Cauchy problem for an abstract hyperbolic equation with the Lipschitz
continuous operator is considered in the Hilbert space. The operator
corresponding to the elliptic part of the equation is a sum of operators
$A_{1},\,A_{2},\,\ldots,\,A_{m}$. Each addend is a self-adjoint and positive
definite operator. A parallel type decomposition scheme for an approximate
solution of the stated problem is constructed. The main idea of the scheme is
that on each local interval classic difference problems are solved in parallel
(independently from each other) respectively with the operators
$A_{1},\,A_{2},\,\ldots,\,A_{m}$. The weighted average of the received
solutions is announced as an approximate solution at the right end of the local
interval. Convergence of the proposed scheme is proved and the approximate
solution error is estimated, as well as the error of the difference analogue
for the first-order derivative for the case when the initial problem data
satisfy the natural sufficient conditions for solution existence.",-0.09421342,-0.009102399,-0.09984638,C
2434,"Ideas for further study

   In order to construct the iteration, one performs a partition of the
ﬁgure describing ω(t), Ω(t), or both of these, by repeating the geometric
construction shown before.",5.,"For instance, taking only the larger 8-angle
ﬁgure describing Ω(t), one can turn this ﬁgure by an angle θ = π/16
and overlay the new ﬁgure with the old one.",2022-02-22 09:19:35+00:00,Evaluation of the Gauss integral,math.NA,"['math.NA', 'cs.NA', 'math.PR', 'physics.data-an', '62E17, 60E15, 26D15']","[arxiv.Result.Author('Dmitri Martila'), arxiv.Result.Author('Stefan Groote')]","The normal or Gaussian distribution plays a prominent role in almost all
fields of science. However, it is well known that the Gauss (or Euler--Poisson)
integral over a finite boundary, as it is necessary for instance for the error
function or the cumulative distribution of the normal distribution, cannot be
expressed by analytic functions. This is proven by the Risch algorithm. Still,
there are proposals for approximate solutions. In this paper, we give a new
solution in terms of normal distributions by applying a geometric procedure
iteratively to the problem.",0.06905155,0.084071726,-0.1382304,C
2495,"Therefore, how

85 to improve the algorithm so that the optimal error estimate can be obtained for

    4
    any diﬀusion coeﬃcient needs further study.","But, the error anal-

    ysis of the methods is still based on the classical homogenization theory, which

    requires the assumption that the diﬀusion coeﬃcient is periodic.","We remark that in the past decade,

    there are many nice multiscale methods dealing with arbitrary oscillating coeﬃ-

    cients, such as the LODM, CEM-GMsFEM, MS-GFEM, and some numerical ho-

    mogenization methods mentioned above [16, 19, 20, 21, 26, 27, 28, 29, 30, 31, 32].",2022-02-26 02:54:59+00:00,A combined multiscale finite element method based on the LOD technique for the multiscale elliptic problems with singularities,math.NA,"['math.NA', 'cs.NA', '34E13, 65N12, 65N30']","[arxiv.Result.Author('Kuokuo Zhang'), arxiv.Result.Author('Weibing Deng'), arxiv.Result.Author('Haijun Wu')]","In this paper, we construct a combined multiscale finite element method
(MsFEM) using the Local Orthogonal Decomposition (LOD) technique to solve the
multiscale problems which may have singularities in some special portions of
the computational domain. For example, in the simulation of steady flow
transporting through highly heterogeneous porous media driven by extraction
wells, the singularities lie in the near-well regions. The basic idea of the
combined method is to utilize the traditional finite element method (FEM)
directly on a fine mesh of the problematic part of the domain and using the
LOD-based MsFEM on a coarse mesh of the other part. The key point is how to
define local correctors for the basis functions of the elements near the coarse
and fine mesh interface, which require meticulous treatment. The proposed
method takes advantages of the traditional FEM and the LOD-based MsFEM, which
uses much less DOFs than the standard FEM and may be more accurate than the
LOD-based MsFEM for problems with singularities. The error analysis is carried
out for highly varying coefficients, without any assumptions on scale
separation or periodicity. {Numerical examples with periodic and random highly
oscillating coefficients}, as well as the multiscale problems on the L-shaped
domain, and multiscale problems with high-contrast channels or
well-singularities are presented to demonstrate the efficiency and accuracy of
the proposed method.",-0.15461978,-0.07764981,-0.049265157,A
2553,"This ﬁnding

is worthy of further study.","Moreover, it is pretty

interesting that the hyperinterpolant L40f with the 50-point Clenshaw–Curtis quadrature performs
better than that using the 25-point Gauss–Legendre quadrature and the 186-point quadrature (4.1)

in equispaced points, though three quadrature rules have the same exactness degree 49.","To the authors’ best knowledge, the connection between the Clenshaw–

Curtis quadrature and the performance of hyperinterpolation has not been established.",2022-02-28 11:18:51+00:00,On the quadrature exactness in hyperinterpolation,math.NA,"['math.NA', 'cs.NA', '65D32, 41A10, 41A55']","[arxiv.Result.Author('Congpei An'), arxiv.Result.Author('Hao-Ning Wu')]","This paper investigates the role of quadrature exactness in the approximation
scheme of hyperinterpolation. Constructing a hyperinterpolant of degree $n$
requires a positive-weight quadrature rule with exactness degree $2n$. We
examine the behavior of such approximation when the required exactness degree
$2n$ is relaxed to $n+k$ with $0<k\leq n$. Aided by the Marcinkiewicz--Zygmund
inequality, we affirm that the $L^2$ norm of the exactness-relaxing
hyperinterpolation operator is bounded by a constant independent of $n$, and
this approximation scheme is convergent as $n\rightarrow\infty$ if $k$ is
positively correlated to $n$. Thus, the family of candidate quadrature rules
for constructing hyperinterpolants can be significantly enriched, and the
number of quadrature points can be considerably reduced. As a potential cost,
this relaxation may slow the convergence rate of hyperinterpolation in terms of
the reduced degrees of quadrature exactness. Our theoretical results are
asserted by numerical experiments on three of the best-known quadrature rules:
the Gauss quadrature, the Clenshaw--Curtis quadrature, and the spherical
$t$-designs.",-0.0799688,-0.044586632,0.18837127,A
2582,"While
this approach involves a lot of hand waving the numerical results are quite satisfactory
and further research could be centered around this issue.","u−  x≥0

By looking at their entropy dissipation snk when the Godunov scheme is applied one
ﬁnds a reference

                   sref = min min snk(u1(·, 0)), min snk(u2(·, 0))
                   k                                  k

for the entropy dissipation of a strong shock that could be present in the solution.","The values

                                             snk      
                                                   −a
                   rkn = Hsm  sref 
                                                   b

depend smoothly on snk but can still have extremely localized spikes as wide as only
a few cells.",2022-02-28 18:09:37+00:00,Using the Dafermos Entropy Rate Criterion in Numerical Schemes,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Simon-Christian Klein')],"The following work concerns the construction of an entropy dissipative finite
volume solver based on the convex combination of an entropy conservative and an
entropy dissipative flux. We aim to construct a semidiscrete scheme that is
entropy stable in the sense of the entropy criterion of Dafermos as well as in
the classical sense entropy dissipative. The proposed semidiscrete scheme shows
nice properties like $2p$ order accuracy in smooth regions as well as a
non-oscillatory behavior around shocks.",0.2585894,0.047712483,-0.0859112,B
2638,"Since for t > 0 and k ∈ Zn, both the exact solution u(t, kh) and the numerical solution
un(t, kh) admit densities, it is natural to further study whether the density of un(t, kh) con-
verges to that of u(t, kh) in some sense.","Then the property (ii) follows
                                        1
immediately  by  choosing  λ(s, t)   =  2  λmi  n  (s  ,  ω  )  >   0  for   s  ≤  t.    The      proof  is  completed.","In this section, we measure the error between pnT,kh
and pT,kh in L1(R), where pnT,kh and pT,kh are densities of un(T, kh) and u(T, kh), respectively,
and the main result is stated as follows.",2022-03-01 15:49:19+00:00,Finite difference method for stochastic Cahn--Hilliard equation: Strong convergence rate and density convergence,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Jialin Hong'), arxiv.Result.Author('Diancong Jin'), arxiv.Result.Author('Derui Sheng')]","This paper presents the strong convergence rate and density convergence of a
spatial finite difference method (FDM) when applied to numerically solve the
stochastic Cahn--Hilliard equation driven by multiplicative space-time white
noises. The main difficulty lies in the control of the drift coefficient that
is neither global Lipschitz nor one-sided Lipschitz. To handle this difficulty,
we first utilize an interpolation approach to derive the discrete
$H^1$-regularity of the numerical solution. This is the key to deriving the
optimal strong convergence order $1$ of the numerical solution. Further, we
propose a novel localization argument to estimate the total variation distance
between the exact and numerical solutions, which along with the existence of
the density of the numerical solution finally yields the convergence of density
in $L^1(\mathbb{R})$ of the numerical solution. This partially answers
positively to the open problem emerged in [9,Section 5] on computing the
density of the exact solution numerically.",0.37172168,-0.3196541,0.03766134,B
2735,"Since usually the hydraulic conductivity tensor K(x) is physically impossible to determine, we

will further study the random Stokes-Darcy model with a random hydraulic conductivity tensor
K(x, ω).","In particular, we assume

                         0 ≤ kmin ≤ λ(K−1(x)) ≤ kmax < ∞.","Let (Ω, F , P) be a complete probability space.",2022-03-03 03:09:26+00:00,Ensemble Domain Decomposition Algorithm for the Fully-mixed Random Stokes-Darcy Model with the Beavers-Joseph Interface Conditions,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Feng Shi'), arxiv.Result.Author('Yizhong Sun'), arxiv.Result.Author('Haibiao Zheng')]","In this paper, an efficient ensemble domain decomposition algorithm is
proposed for fast solving the fully-mixed random Stokes-Darcy model with the
physically realistic Beavers-Joseph (BJ) interface conditions. We utilize the
Monte Carlo method for the coupled model with random inputs to derive some
deterministic Stokes-Darcy numerical models and use the idea of the ensemble to
realize the fast computation of multiple problems. One remarkable feature of
the algorithm is that multiple linear systems share a common coefficient matrix
in each deterministic numerical model, which significantly reduces the
computational cost and achieves comparable accuracy with the traditional
methods. Moreover, by domain decomposition, we can decouple the Stokes-Darcy
system into two smaller sub-physics problems naturally. Both mesh-dependent and
mesh-independent convergence rates of the algorithm are rigorously derived by
choosing suitable Robin parameters. Especially, for small hydraulic
conductivity in practice, the almost optimal geometric convergence can be
obtained by finite element discretization. Finally, two groups of numerical
experiments are conducted to validate and illustrate the exclusive features of
the proposed algorithm.",0.36691433,0.06899948,0.2062971,B
2736,"In this section, we will further study the ﬁnite element
discretization of the Ensemble DDM algorithm.",Finite Element Approximations.,"Consider a regular, quasi-uniform triangulation
(d = 2) or tetrahedron (d = 3) Th with mesh scale h for the global domain Ω.",2022-03-03 03:09:26+00:00,Ensemble Domain Decomposition Algorithm for the Fully-mixed Random Stokes-Darcy Model with the Beavers-Joseph Interface Conditions,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Feng Shi'), arxiv.Result.Author('Yizhong Sun'), arxiv.Result.Author('Haibiao Zheng')]","In this paper, an efficient ensemble domain decomposition algorithm is
proposed for fast solving the fully-mixed random Stokes-Darcy model with the
physically realistic Beavers-Joseph (BJ) interface conditions. We utilize the
Monte Carlo method for the coupled model with random inputs to derive some
deterministic Stokes-Darcy numerical models and use the idea of the ensemble to
realize the fast computation of multiple problems. One remarkable feature of
the algorithm is that multiple linear systems share a common coefficient matrix
in each deterministic numerical model, which significantly reduces the
computational cost and achieves comparable accuracy with the traditional
methods. Moreover, by domain decomposition, we can decouple the Stokes-Darcy
system into two smaller sub-physics problems naturally. Both mesh-dependent and
mesh-independent convergence rates of the algorithm are rigorously derived by
choosing suitable Robin parameters. Especially, for small hydraulic
conductivity in practice, the almost optimal geometric convergence can be
obtained by finite element discretization. Finally, two groups of numerical
experiments are conducted to validate and illustrate the exclusive features of
the proposed algorithm.",0.034005336,0.010231553,0.10316669,A
2765,These observations induce several directions of further research.,"Therefore, as long as the tensor power iteration is used
without modiﬁcation, some eigenvectors may not be detectable numerically.","29
    On the one hand, maintaining the viewpoint of the orthodox tensor power
iteration, it would be a natural generalization to study symmetric tensors whose
symmetric decomposition (1) uses diﬀerent weights λk and/or is induced by a
set of more than n + 1 equiangular vectors vk or even a generic tight frame.",2022-03-03 17:21:45+00:00,Real eigenstructure of regular simplex tensors,math.NA,"['math.NA', 'cs.NA', 'math.AG', 'math.SP']","[arxiv.Result.Author('Adam Czaplinski'), arxiv.Result.Author('Thorsten Raasch'), arxiv.Result.Author('Jonathan Steinberg')]","We are concerned with the eigenstructure of supersymmetric tensors. Like in
the matrix case, normalized tensor eigenvectors are fixed points of the tensor
power iteration map. However, unless the given tensor is orthogonally
decomposable, some of these fixed points may be repelling and therefore be
undetectable by any numerical scheme. In this paper, we consider the case of
regular simplex tensors whose symmetric decomposition is induced by an
overcomplete, equiangular set of $n+1$ vectors from $\mathbb R^n$. We discuss
the full real eigenstructure of such tensors, including the robustness analysis
of all normalized eigenvectors. As it turns out, regular simplex tensors
exhibit robust as well as non-robust eigenvectors which, moreover, only partly
coincide with the generators from the symmetric tensor decomposition.",-0.2201518,-0.057918146,0.1766622,A
2791,"Fortunately, in the case when u ≡ 0 throughout the boundary, certain relation can
be exploited between ∂∂22nu and ∇Mu after further study on the shape of boundary.","The main diﬃculty to apply (2.4) into a nonlocal model is the need of handling
the term ∂∂22nu , which usually keep people away from improving the accuracy of model.","In
lemma 3.3 of section 3, we will prove the following equality

                    ∂2u                                ∂u         ∀ y ∈ ∂M
                    ∂2n (y) = ∆Mu(y) + κn(y) ∂n (y),                                       (2.5)

whenever u ∈ H4(M) and u ≡ 0 on ∂M.",2022-03-04 03:33:23+00:00,Truncation Error Analysis for an Accurate Nonlocal Manifold Poisson Model with Dirichlet Boundary,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yajie Zhang'), arxiv.Result.Author('Zuoqiang Shi')]","In this work, we introduced a class of nonlocal models to accurately
approximate the Poisson model on manifolds that are embedded in high
dimensional Euclid spaces with Dirichlet boundary. In comparison to the
existing nonlocal Poisson models, instead of utilizing volumetric boundary
constraint to reduce the truncation error to its local counterpart, we rely on
the Poisson equation itself along the boundary to explicitly express the second
order normal derivative by some geometry-based terms, so that to create a new
model with $\mathcal{O}(\delta)$ truncation error along the $2\delta-$boundary
layer and $\mathcal{O}(\delta^2)$ at interior, with $\delta$ be the nonlocal
interaction horizon. Our concentration is on the construction and the
truncation error analysis of such nonlocal model. The control on the truncation
error is currently optimal among all nonlocal models, and is sufficient to
attain second order localization rate that will be derived in our subsequent
work.",0.50871,-0.11886057,-0.03856951,B
2794,"In the future, we will further study
parameter selection and solving the low-rank large-scale CARE.","Therefore, the Newton-GADI and inexact Newton-GADI methods could be valid and attractive
algorithms to solve the ill-conditioned Riccati equation.","References

 [1] P. Lancaster, L. Rodman, Algebraic Riccati Equations, The Clarendon Press: Oxford, 1995.",2022-03-04 07:18:20+00:00,A general alternating-direction implicit Newton method for solving complex continuous-time algebraic Riccati matrix equation,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Shifeng Li'), arxiv.Result.Author('Kai Jiang Juan Zhang')]","In this paper, applying the Newton method, we transform the complex
continuous-time algebraic Riccati matrix equation into a Lyapunov equation.
Then, we introduce an efficient general alternating-direction implicit (GADI)
method to solve the Lyapunov equation. The inexact Newton-GADI method is
presented to save computational amount effectively. Moreover, we analyze the
convergence of the Newton-GADI method. The convergence rate of the Newton-GADI
and Newton-ADI methods is compared by analyzing their spectral radii.
Furthermore, we give a way to select the quasi-optimal parameter. Corresponding
numerical tests are shown to illustrate the effectiveness of the proposed
algorithms.",-0.11510117,0.062212188,-0.1916241,C
2865,"In the future, we will continue a further study of the adaptive randomized approach for
the case where the target rank is unknown or cannot be estimated in advance.","The accuracy of the RO-SVD is at least as good as the
randomized RT-SVD while showing great advantages in time cost.","References

 [1] B. W. Bader, G. K. Tamara, et al., Matlab tensor toolbox, version 3.2.1. https:
      //www.tensortoolbox.org, April 2017.",2022-03-05 14:31:12+00:00,A randomized singular value decomposition for third-order oriented tensors,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Minghui Ding'), arxiv.Result.Author('Pengpeng Xie')]","The oriented singular value decomposition (O-SVD) proposed in [Numer. Linear
Algebra Appl., 27(2020), e2290] provides a hybrid approach to the t-product
based third-order tensor singular value decomposition with the transform matrix
being a factor matrix of the higher order singular value decomposition.
Continuing along this vein, this paper gives a truncated O-SVD. Motivated by
the success of probabilistic algorithms, we develop a randomized version of the
O-SVD and present its detailed error analysis. The new algorithm has advantages
in efficiency while keeping good accuracy compared with the current tensor
decompositions. Our claims are supported by numerical experiments on several
oriented tensors from real applications.",-0.23742159,0.10406513,0.28103963,A
2866,"In the future, we will continue a further study of the adaptive randomized approach for the
case where the target rank is unknown or cannot be estimated in advance.","The performance of the RO-SVD is better than the RT-SVD for
the same compression ratio and better than the RHOSVD for the same size core tensor and
shows great advantages in time cost if the tensor is well-oriented.","One more potential
research direction is the use of updated SVD algorithms [3] to study dynamic video streaming.",2022-03-05 14:31:12+00:00,A randomized singular value decomposition for third-order oriented tensors,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Minghui Ding'), arxiv.Result.Author('Pengpeng Xie')]","The oriented singular value decomposition (O-SVD) proposed in [Numer. Linear
Algebra Appl., 27(2020), e2290] provides a hybrid approach to the t-product
based third-order tensor singular value decomposition with the transform matrix
being a factor matrix of the higher order singular value decomposition.
Continuing along this vein, this paper explores realizing the O-SVD more
efficiently by the tensor-train rank-1 decomposition and gives a truncated
O-SVD. Motivated by the success of probabilistic algorithms, we develop a
randomized version of the O-SVD and present its detailed error analysis. The
new algorithm has advantages in efficiency while keeping good accuracy compared
with the current tensor decompositions. Our claims are supported by numerical
experiments on several oriented tensors from real applications.",-0.16621795,0.12190668,0.26393774,A
2922,There are several interesting further research directions.,"Finally, we demonstrate that the minimizers of the Lipschitz
regularized empirical losses converge to the solution to the interface problem uniformly as the number of training
samples grows in H2 and conclude the main theorem.","The landscape of non-convex objective functions and the
stochastic gradient optimization process still remain open.",2022-03-07 13:59:50+00:00,On convergence of neural network methods for solving elliptic interface problems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Sidi Wu'), arxiv.Result.Author('Aiqing Zhu'), arxiv.Result.Author('Yifa Tang'), arxiv.Result.Author('Benzhuo Lu')]","With the remarkable empirical success of neural networks across diverse
scientific disciplines, rigorous error and convergence analysis are also being
developed and enriched. However, it still seems little theoretical work on
neural networks in solving interface problems. In this paper, we perform a
convergence analysis of neural network-based methods for solving second-order
elliptic interface problems. Specifically, we consider a neural network method
combined with domain decomposition technologies and gradient-enhanced
strategies. It is shown that the neural network sequence obtained by minimizing
a Lipschitz regularized loss function converges to the unique solution to the
interface problem in $H^2$ as the number of samples increases. Numerical
experiments are provided to demonstrate our analysis.",0.080685586,0.025909714,0.24303475,B
3067,"This impedes its actual
usage and further research in practice.","Despite the plethora of literature, many algorithms with low theoretical computational com-
plexity or high accuracy solutions are rather involved to implement.","To the best of our knowledge, there does not exist an
algorithm that fulﬁlls the following list of desiderata in the free-support setting:

    • simple to implement,

    • sharp theoretical error bounds,

    • sparse solutions, and

    • good numerical results in practice.",2022-03-10 09:57:37+00:00,Simple Approximative Algorithms for Free-Support Wasserstein Barycenters,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Johannes von Lindheim')],"Computing Wasserstein barycenters of discrete measures has recently attracted
considerable attention due to its wide variety of applications in data science.
In general, this problem is NP-hard, calling for practical approximative
algorithms. In this paper, we analyze a well-known simple framework for
approximating Wasserstein-$p$ barycenters, where we mainly consider the most
common case $p=2$ and $p=1$, which is not as well discussed. The framework
produces sparse support solutions and shows good numerical results in the
free-support setting. Depending on the desired level of accuracy, this requires
only $N-1$ or $N(N-1)/2$ standard two-marginal optimal transport (OT)
computations between the $N$ input measures, respectively, which is fast,
memory-efficient and easy to implement using any OT solver as a black box. What
is more, these methods yield a relative error of at most $N$ and $2$,
respectively, for both $p=1, 2$. We show that these bounds are practically
sharp. In light of the hardness of the problem, it is not surprising that such
guarantees cannot be close to optimality in general. Nevertheless, these error
bounds usually turn out to be drastically lower for a given particular problem
in practice and can be evaluated with almost no computational overhead, in
particular without knowledge of the optimal solution. In our numerical
experiments, this guaranteed errors of at most a few percent.",-0.37937889,0.12342337,0.043989323,A
3189,"The scheme has also been
the subject of further research: On the one hand, the works [Bar06, Cim09] incorporate
the inexact solution of the nonlinear system into the convergence result.","Besides introducing the method, the
work [BP06] proves unconditional convergence of the ﬁnite element approximation to-
wards a weak solution of LLG in the sense of [AS92] and proposes a ﬁxed-point iteration
to linearize the nonlinear problem arising from the scheme.","On the other
hand, the work [PRS18] focuses on the design and the analysis of eﬀective approaches to
treat the nonlocal ﬁeld contributions.",2022-03-12 14:33:42+00:00,The mass-lumped midpoint scheme for computational micromagnetics: Newton linearization and application to magnetic skyrmion dynamics,math.NA,"['math.NA', 'cs.NA', '35K55, 65M12, 65M22, 65M60, 65Z05']","[arxiv.Result.Author('Giovanni Di Fratta'), arxiv.Result.Author('Carl-Martin Pfeiler'), arxiv.Result.Author('Dirk Praetorius'), arxiv.Result.Author('Michele Ruggeri')]","We discuss a mass-lumped midpoint scheme for the numerical approximation of
the Landau-Lifshitz-Gilbert equation, which models the dynamics of the
magnetization in ferromagnetic materials. In addition to the classical
micromagnetic field contributions, our setting covers the non-standard
Dzyaloshinskii-Moriya interaction, which is the essential ingredient for the
enucleation and stabilization of magnetic skyrmions. Our analysis also includes
the inexact solution of the arising nonlinear systems, for which we discuss
both a constraint preserving fixed-point solver from the literature and a novel
approach based on the Newton method. We numerically compare the two
linearization techniques and show that the Newton solver leads to a
considerably lower number of nonlinear iterations. Moreover, in a numerical
study on magnetic skyrmions, we demonstrate that, for magnetization dynamics
that are very sensitive to energy perturbations, the midpoint scheme, due to
its conservation properties, is superior to the dissipative tangent plane
schemes from the literature.",-0.034603424,-0.14603885,-0.31607795,C
3190,This is subject of a further research.,"If the number of edges is huge, other technique for estimating the trace of a
matrix might be more appropriate, like the one proposed in [CK21] based on
randomization.","References

[ABC+22]      D. Altaﬁni, D.A.",2022-03-12 15:24:47+00:00,A centrality score of graph edges based on the Kemeny constant,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('D. Altafini'), arxiv.Result.Author('D. A. Bini'), arxiv.Result.Author('V. Cutini'), arxiv.Result.Author('B. Meini'), arxiv.Result.Author('F. Poloni')]","A new measure $c(e)$ of the centrality of an edge $e$ in an undirected graph
$G$ is introduced. It is based on the variation of the Kemeny constant of the
graph after removing the edge $e$. The new measure is designed in such a way
that the Braess paradox is avoided. A numerical method for computing $c(e)$ is
introduced and a regularization technique is designed in order to deal with
cut-edge and disconnected graphs. Numerical experiments performed on synthetic
tests and on real road networks show the effectiveness of this approach.",-0.25415182,0.18606405,0.4163774,A
3191,"This is
subject of further research.","If
the number of edges is huge, other techniques to estimate the trace of a matrix might
be more appropriate, like the one proposed in [10] based on randomization.","REFERENCES

 [1] D. Altafini, D. Bini, V. Cutini, B. Meini, and F. Poloni, Markov-chain based centralities
            and space syntax angular analysis: an initial overview and application, in Proc.",2022-03-12 15:24:47+00:00,An edge centrality measure based on the Kemeny constant,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('D. Altafini'), arxiv.Result.Author('D. A. Bini'), arxiv.Result.Author('V. Cutini'), arxiv.Result.Author('B. Meini'), arxiv.Result.Author('F. Poloni')]","A new measure $c(e)$ of the centrality of an edge $e$ in an undirected graph
$G$ is introduced. It is based on the variation of the Kemeny constant of the
graph after removing the edge $e$. The new measure is designed in such a way
that the Braess paradox is avoided. A numerical method for computing $c(e)$ is
introduced and a regularization technique is designed in order to deal with
cut-edges and disconnected graphs. Numerical experiments performed on synthetic
tests and on real road networks show that this measure is particularly
effective in revealing bottleneck roads whose removal would greatly reduce the
connectivity of the network.",-0.2614991,0.14168888,0.39633766,A
3316,"One interesting direction for further research is to apply similar
ideas to the present context of inverse state estimation.","Recent results obtained in [28] show that, in certain
relevant instances, ε-approximation nets can be replaced by random training sets of
smaller cardinality.","14
Optimization algorithms: As already brought up, the practical computation of

Awc consists in solving

         min               max PW ⊥u − c − BPW u 2,                          (4.11)

    (c,B)∈W ⊥×L(W,W ⊥) u∈M

                                            =F (c,B)

The numerical solution of this problem is challenging due to its lack of smoothness (the
objective function F is convex but non diﬀerentiable) and its high dimensionality (for a

given target accuracy εN , the cardinality of M might be large).",2022-03-15 10:42:06+00:00,Inverse Problems: A Deterministic Approach using Physics-Based Reduced Models,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Olga Mula')],"These lecture notes summarize various summer schools that I have given on the
topic of solving inverse problems (state and parameter estimation) by combining
optimally measurement observations and parametrized PDE models. After defining
a notion of optimal performance in terms of the smallest reconstruction error
that any reconstruction algorithm can achieve, the notes present practical
numerical algorithms based on nonlinear reduced models for which one can prove
that they can deliver a performance close to optimal. We also discuss
algorithms for sensor placement with the approach. The proposed concepts may be
viewed as exploring alternatives to Bayesian inversion in favor of more
deterministic notions of accuracy quantification.",-0.12865435,0.08992444,0.2726242,A
3322,"Finally, we present numerical experiments in Section 6, discuss directions for further research
on the use of artiﬁcial neural networks for generating locally reﬁned meshes in Section 7 and conclude
the paper in Section 8.","We describe our methods
for generating the training data in Section 4 and present the architecture of our neural network in
Section 5.","2 Problem formulation

Given a computational domain and corresponding boundary conditions, we want to obtain a quadrilateral
mesh over which we can deﬁne a ﬁnite element space to represent the solution of a linear elasticity
problem.",2022-03-15 12:59:37+00:00,Locally refined quad meshing for linear elasticity problems based on convolutional neural networks,math.NA,"['math.NA', 'cs.NA', '65N50']","[arxiv.Result.Author('Chiu Ling Chan'), arxiv.Result.Author('Felix Scholz'), arxiv.Result.Author('Thomas Takacs')]","In this paper we propose a method to generate suitably refined finite element
meshes using neural networks. As a model problem we consider a linear
elasticity problem on a planar domain (possibly with holes) having a polygonal
boundary. We impose boundary conditions by fixing the position of a part of the
boundary and applying a force on another part of the boundary. The resulting
displacement and distribution of stresses depend on the geometry of the domain
and on the boundary conditions. When applying a standard Galerkin
discretization using quadrilateral finite elements, one usually has to perform
adaptive refinement to properly resolve maxima of the stress distribution. Such
an adaptive scheme requires a local error estimator and a corresponding local
refinement strategy. The overall costs of such a strategy are high. We propose
to reduce the costs of obtaining a suitable discretization by training a neural
network whose evaluation replaces this adaptive refinement procedure. We set up
a single network for a large class of possible domains and boundary conditions
and not on a single domain of interest. The computational domain and boundary
conditions are interpreted as images, which are suitable inputs for convolution
neural networks. We use the U-net architecture and we devise training
strategies by dividing the possible inputs into different categories based on
their overall geometric complexity. Thus, we compare different training
strategies based on varying geometric complexity. One of the advantages of the
proposed approach is the interpretation of input and output as images, which do
not depend on the underlying discretization scheme. Another is the
generalizability and geometric flexibility. The network can be applied to
previously unseen geometries, even with different topology and level of detail.
Thus, training can easily be extended to other classes of geometries.",0.06990019,0.4035384,-0.0042400956,C
3422,"Conclusions
and further research directions are given in Section 7.",Section 6 presents the results of numerical experiments regarding the new method.,"2 Preliminaries

Following [27] and [33], we give some basic results regarding non-Euclidian scalar products.",2022-03-16 19:23:36+00:00,A Structure-Preserving Divide-and-Conquer Method for Pseudosymmetric Matrices,math.NA,"['math.NA', 'cs.NA', '65F15, 65F55', 'G.1.3']","[arxiv.Result.Author('Peter Benner'), arxiv.Result.Author('Yuji Nakatsukasa'), arxiv.Result.Author('Carolin Penke')]","We devise a spectral divide-and-conquer scheme for matrices that are
self-adjoint with respect to a given indefinite scalar product (i.e.
pseudosymmetic matrices). The pseudosymmetric structure of the matrix is
preserved in the spectral division, such that the method can be applied
recursively to achieve full diagonalization. The method is well-suited for
structured matrices that come up in computational quantum physics and
chemistry. In this application context, additional definiteness properties
guarantee a convergence of the matrix sign function iteration within two steps
when Zolotarev functions are used. The steps are easily parallelizable.
Furthermore, it is shown that the matrix decouples into symmetric definite
eigenvalue problems after just one step of spectral division.",-0.05635238,-0.21642283,-0.004065074,B
3532,"To keep this paper as short as possible, we leave this point as well as the
       Littlewood–Paley analysis of Hpr,,qsX(Rd) for further research.","However, Proposition 2.3 below and the analysis in [41] indicate that systems with
       similar properties most likely will lead to the same spaces (up to equivalent quasi-
       norms).","7
    The following important special cases can be identiﬁed.",2022-03-18 15:20:21+00:00,Rate-optimal sparse approximation of compact break-of-scale embeddings,math.NA,"['math.NA', 'cs.NA', 'math.FA', '42C40, 41A25, 46E35, 41A45, 41A46']","[arxiv.Result.Author('Glenn Byrenheid'), arxiv.Result.Author('Janina Hübner'), arxiv.Result.Author('Markus Weimar')]","The paper is concerned with the sparse approximation of functions having
hybrid regularity borrowed from the theory of solutions to electronic
Schr\""odinger equations due to Yserentant [43]. We use hyperbolic wavelets to
introduce corresponding new spaces of Besov- and Triebel-Lizorkin-type to
particularly cover the energy norm approximation of functions with dominating
mixed smoothness. Explicit (non-)adaptive algorithms are derived that yield
sharp dimension-independent rates of convergence.",0.40906724,-0.20340231,0.22155455,B
3533,"So, we leave the remaining cases open for further research.","However, our methods of proof seem to be limited to this most interesting situation; see
Remark 2.9(iii).","3.1 Lower bounds

In order to derive lower bounds for our quantities of interest, we use two diﬀerent arguments.",2022-03-18 15:20:21+00:00,Rate-optimal sparse approximation of compact break-of-scale embeddings,math.NA,"['math.NA', 'cs.NA', 'math.FA', '42C40, 41A25, 46E35, 41A45, 41A46']","[arxiv.Result.Author('Glenn Byrenheid'), arxiv.Result.Author('Janina Hübner'), arxiv.Result.Author('Markus Weimar')]","The paper is concerned with the sparse approximation of functions having
hybrid regularity borrowed from the theory of solutions to electronic
Schr\""odinger equations due to Yserentant [43]. We use hyperbolic wavelets to
introduce corresponding new spaces of Besov- and Triebel-Lizorkin-type to
particularly cover the energy norm approximation of functions with dominating
mixed smoothness. Explicit (non-)adaptive algorithms are derived that yield
sharp dimension-independent rates of convergence.",0.27516413,-0.23696567,0.2851388,B
3583,"Beyond wave equation, RSWR is potential to solve linear and nonlinear hyperbolic
partial diﬀerential equation distributedly, which requires further study.","Therefore, it would be meaningful to implement
RSWR on supercomputers to solve large physical problem.",Appendix A.,2022-03-20 07:26:18+00:00,A Non-iterative Overlapping Schwarz Waveform Relaxation Algorithm for Wave Equation,math.NA,"['math.NA', 'cs.NA', '65M55, 65M12, 65Y05']","[arxiv.Result.Author('Fei Wei'), arxiv.Result.Author('Anna Zhao')]","The Schwarz Waveform Relaxation algorithm (SWR) exchanges the waveform of
boundary value between neighbouring sub-domains, which provides a more
efficient way than the other Schwarz algorithms to realize distributed
computation. However, the convergence speed of the traditional SWR is slow, and
various optimization strategies have been brought in to accelerate the
convergence. In this paper, we propose a non-iterative overlapping variant of
SWR for wave equation, which is named Relative Schwarz Waveform Relaxation
algorithm (RSWR). RSWR is inspired by the physical observation that the
velocity of wave is limited, based on the Theory of Relativity. The change of
value at one space point will take time span $\Delta t$ to transmit to another
space point and vice versa. This $\Delta t$ could be utilized to design
distributed numerical algorithm, as we have done in RSWR. During each time
span, RSWR needs only 3 steps to achieve high accurate waveform, by using the
predict-select-update strategy. The key for this strategy is to find the
maximum time span for the waveform. The validation of RSWR could be proved
straightfowardly. Numerical experiments show that RSWR is accurate, and is
potential to be scalable and fast.",0.0048066867,0.18173668,-0.23683372,C
3742,"Equation (1.1)
has the signiﬁcant applications in the ﬁelds of engineering and science, and it is still worthy of our
further study.","In addition, problem (1.1)-(1.3) can model the physical phenom-
ena, which involves the viscoelastic forces, population dynamics, viscous plasticity problems, heat
transfer materials with memory, nuclear reaction theory and so on [6, 8, 10, 11].","However, there are no analytic solutions for the problem (1.1)-(1.3), thus we have
to yield its numerical solutions.",2022-03-23 06:45:00+00:00,Second-order accurate numerical scheme with graded meshes for the nonlinear partial integrodifferential equation arising from viscoelasticity,math.NA,"['math.NA', 'cs.NA', '26A33, 45K05, 65M12, 65M22, 65M60']","[arxiv.Result.Author('Wenlin Qiu'), arxiv.Result.Author('Xu Xiao'), arxiv.Result.Author('Kexin Li')]","This paper establishes and analyzes a second-order accurate numerical scheme
for the nonlinear partial integrodifferential equation with a weakly singular
kernel. In the time direction, we apply the Crank-Nicolson method for the time
derivative, and the product-integration (PI) rule is employed to deal with
Riemann-Liouville fractional integral. From which, the non-uniform meshes are
utilized to compensate for the singular behavior of the exact solution at $t=0$
so that our method can reach second-order convergence for time. In order to
formulate a fully discrete implicit difference scheme, we employ a standard
centered difference formula for the second-order spatial derivative, and the
Galerkin method based on piecewise linear test functions is used to approximate
the nonlinear convection term. Then we derive the existence and uniqueness of
numerical solutions for the proposed implicit difference scheme. Meanwhile,
stability and convergence are proved by means of the discrete energy method.
Furthermore, to demonstrate the effectiveness of the proposed method, we
utilize a fixed point iterative algorithm to calculate the discrete scheme.
Finally, numerical experiments illustrate the feasibility and efficiency of the
proposed scheme, in which numerical results are consistent with our theoretical
analysis.",0.38908195,0.08985664,-0.2654011,B
3743,"Finally, Section 8 summarizes our conclusions and points to further research directions.","Sections 5 and 6 demonstrate performance results for geometric
multigrid and polynomial multigrid, and in Section 7 the solver is applied to a challenging Stokes problem.","2
Algorithm 1: Multigrid V-cycle x ← MultigridVCycle(b) including the copy of b to and of x from
the multigrid level(s).",2022-03-23 09:31:59+00:00,Efficient distributed matrix-free multigrid methods on locally refined meshes for FEM computations,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.4']","[arxiv.Result.Author('Peter Munch'), arxiv.Result.Author('Timo Heister'), arxiv.Result.Author('Laura Prieto Saavedra'), arxiv.Result.Author('Martin Kronbichler')]","This work studies three multigrid variants for matrix-free finite-element
computations on locally refined meshes: geometric local smoothing, geometric
global coarsening, and polynomial global coarsening. We have integrated the
algorithms into the same framework-the open-source finite-element library
deal.II-, which allows us to make fair comparisons regarding their
implementation complexity, computational efficiency, and parallel scalability
as well as to compare the measurements with theoretically derived performance
models. Serial simulations and parallel weak and strong scaling on up to
147,456 CPU cores on 3,072 compute nodes are presented. The results obtained
indicate that global coarsening algorithms show a better parallel behavior for
comparable smoothers due to the better load balance particularly on the
expensive fine levels. In the serial case, the costs of applying hanging-node
constraints might be significant, leading to advantages of local smoothing,
even though the number of solver iterations needed is slightly higher.",-0.041041385,0.19444273,-0.0926154,A
3744,"Finally, Section 8 summarizes our conclusions and points to further research directions.","Sections 5 and 6 demonstrate performance results for geometric
multigrid and polynomial multigrid, and in Section 7 the solver is applied to a challenging Stokes problem.","2
Algorithm 1: Multigrid V-cycle x ← MultigridVCycle(b) including the copy of b to and of x from
the multigrid level(s).",2022-03-23 09:31:59+00:00,Efficient distributed matrix-free multigrid methods on locally refined meshes for FEM computations,math.NA,"['math.NA', 'cs.MS', 'cs.NA', 'G.4']","[arxiv.Result.Author('Peter Munch'), arxiv.Result.Author('Timo Heister'), arxiv.Result.Author('Laura Prieto Saavedra'), arxiv.Result.Author('Martin Kronbichler')]","This work studies three multigrid variants for matrix-free finite-element
computations on locally refined meshes: geometric local smoothing, geometric
global coarsening, and polynomial global coarsening. We have integrated the
algorithms into the same framework-the open-source finite-element library
deal.II-, which allows us to make fair comparisons regarding their
implementation complexity, computational efficiency, and parallel scalability
as well as to compare the measurements with theoretically derived performance
models. Serial simulations and parallel weak and strong scaling on up to
147,456 CPU cores on 3,072 compute nodes are presented. The results obtained
indicate that global coarsening algorithms show a better parallel behavior for
comparable smoothers due to the better load balance particularly on the
expensive fine levels. In the serial case, the costs of applying hanging-node
constraints might be significant, leading to advantages of local smoothing,
even though the number of solver iterations needed is slightly higher.",-0.041041385,0.19444273,-0.0926154,A
3787,"We summarize directions for further research in
Section 6 and present conclusions in Section 7.","We then exhibit the performance of this method in Section 5 with
a series of numerical examples.","Adaptive Regularization of B-Spline Models for Scientiﬁc Data  3

2 Related Work

Creating B-spline models to represent unstructured data sets is a particular ex-
ample of scattered data approximation (SDA), a broad area of study concerned
with deﬁning continuous functions that interpolate or approximate spatially scat-
tered inputs.",2022-03-23 21:25:21+00:00,Adaptive Regularization of B-Spline Models for Scientific Data,math.NA,"['math.NA', 'cs.NA', 'G.1.2']","[arxiv.Result.Author('David Lenz'), arxiv.Result.Author('Raine Yeh'), arxiv.Result.Author('Vijay Mahadevan'), arxiv.Result.Author('Iulian Grindeanu'), arxiv.Result.Author('Tom Peterka')]","B-spline models are a powerful way to represent scientific data sets with a
functional approximation. However, these models can suffer from spurious
oscillations when the data to be approximated are not uniformly distributed.
Model regularization (i.e., smoothing) has traditionally been used to minimize
these oscillations; unfortunately, it is sometimes impossible to sufficiently
remove unwanted artifacts without smoothing away key features of the data set.
In this article, we present a method of model regularization that preserves
significant features of a data set while minimizing artificial oscillations.
Our method varies the strength of a smoothing parameter throughout the domain
automatically, removing artifacts in poorly-constrained regions while leaving
other regions unchanged. The behavior of our method is validated on a
collection of two- and three-dimensional data sets produced by scientific
simulations.",-0.029432226,0.20449667,0.18209346,C
3872,There are a number of avenues for further research.,"As our numerical experiments conﬁrm, our algorithms are
practical, and actually perform better than the theory suggests.","First, this work has focused on Chebyshev
and Legendre polynomials on the hypercube [−1, 1]d. It is plausible that it can be extended to
general ultraspherical or Jacobi polynomials.",2022-03-25 20:56:07+00:00,"On efficient algorithms for computing near-best polynomial approximations to high-dimensional, Hilbert-valued functions from limited samples",math.NA,"['math.NA', 'cs.LG', 'cs.NA']","[arxiv.Result.Author('Ben Adcock'), arxiv.Result.Author('Simone Brugiapaglia'), arxiv.Result.Author('Nick Dexter'), arxiv.Result.Author('Sebastian Moraga')]","Sparse polynomial approximation has become indispensable for approximating
smooth, high- or infinite-dimensional functions from limited samples. This is a
key task in computational science and engineering, e.g., surrogate modelling in
UQ where the function is the solution map of a parametric or stochastic PDE.
Yet, sparse polynomial approximation lacks a complete theory. On the one hand,
there is a well-developed theory of best $s$-term polynomial approximation,
which asserts exponential or algebraic rates of convergence for holomorphic
functions. On the other hand, there are increasingly mature methods such as
(weighted) $\ell^1$-minimization for computing such approximations. While the
sample complexity of these methods has been analyzed in detail, the matter of
whether or not these methods achieve such rates is not well understood.
Furthermore, these methods are not algorithms per se, since they involve exact
minimizers of nonlinear optimization problems.
  This paper closes these gaps. Specifically, we pose and answer the following
question: are there robust, efficient algorithms for computing approximations
to finite- or infinite-dimensional, holomorphic and Hilbert-valued functions
from limited samples that achieve best $s$-term rates? We answer this in the
affirmative by introducing algorithms and theoretical guarantees that assert
exponential or algebraic rates of convergence, along with robustness to
sampling, algorithmic, and physical discretization errors. We tackle both
scalar- and Hilbert-valued functions, this being particularly relevant to
parametric and stochastic PDEs. Our work involves several significant
developments of existing techniques, including a novel restarted primal-dual
iteration for solving weighted $\ell^1$-minimization problems in Hilbert
spaces. Our theory is supplemented by numerical experiments demonstrating the
practical efficacy of these algorithms.",-0.0059340987,-0.10436413,0.14986616,B
4077,"Our GFM framework also opens up many further research directions to explore,
for example the study of multi-step block iterations like MGRIT with FCF-relaxation,
and more complex two-level methods without Assumption 2.7.","This
is also observed in our numerical experiments, which were produced with a Python
code that is publically available13.","Also an extension of
GFM to the multi-level versions of STMG, PFASST and MGRIT would be very
valuable.",2022-03-30 05:48:49+00:00,A unified analysis framework for iterative parallel-in-time algorithms,math.NA,"['math.NA', 'cs.CE', 'cs.NA']","[arxiv.Result.Author('M. J. Gander'), arxiv.Result.Author('T. Lunet'), arxiv.Result.Author('D. Ruprecht'), arxiv.Result.Author('R. Speck')]","Parallel-in-time integration has been the focus of intensive research efforts
over the past two decades due to the advent of massively parallel computer
architectures and the scaling limits of purely spatial parallelization. Various
iterative parallel-in-time (PinT) algorithms have been proposed, like Parareal,
PFASST, MGRIT, and Space-Time Multi-Grid (STMG). These methods have been
described using different notations and the convergence estimates that are
available for some of them are difficult to compare. We describe Parareal,
PFASST, MGRIT and STMG for the Dahlquist model problem using a common notation
and give precise convergence estimates using generating functions. This allows
us, for the first time, to directly compare their convergence. We prove that
all four methods eventually converge super-linearly and compare them directly
numerically. Our framework also allows us to find new methods.",-0.18437335,0.025010264,-0.20133975,A
4207,"Conclusions and discussions about further research
work are provided in Section 5.","Several physically relevant examples are demonstrated in Section 4 to
test the performance of the proposed method.",2.,2022-04-01 09:50:36+00:00,Deep neural networks for solving extremely large linear systems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yiqi Gu'), arxiv.Result.Author('Michael K. Ng')]","In this paper, we study deep neural networks for solving extremely large
linear systems arising from physically relevant problems. Because of the curse
of dimensionality, it is expensive to store both solution and right hand side
vectors in such extremely large linear systems. Our idea is to employ a neural
network to characterize the solution with parameters being much fewer than the
size of the solution. We present an error analysis of the proposed method
provided that the solution vector can be approximated by the continuous
quantity, which is in the Barron space. Several numerical examples arising from
partial differential equations, queueing problems and probabilistic Boolean
networks are presented to demonstrate that solutions of linear systems with
sizes ranging from septillion ($10^{24}$) to nonillion ($10^{30})$ can be
learned quite accurately.",-0.008259441,0.08764073,-0.086752005,C
4208,"Conclusions and discussions about further research
work are provided in Section 5.","Several examples of physical problems are demonstrated in Section 4 to
test the performance of the proposed method.",2.,2022-04-01 09:50:36+00:00,Deep neural networks for solving large linear systems arising from high-dimensional problems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yiqi Gu'), arxiv.Result.Author('Michael K. Ng')]","This paper studies deep neural networks for solving extremely large linear
systems arising from high-dimensional problems. Because of the curse of
dimensionality, it is expensive to store both the solution and right-hand side
vector in such extremely large linear systems. Our idea is to employ a neural
network to characterize the solution with much fewer parameters than the size
of the solution under a matrix-free setting. We present an error analysis of
the proposed method, indicating that the solution error is bounded by the
condition number of the matrix and the neural network approximation error.
Several numerical examples from partial differential equations, queueing
problems, and probabilistic Boolean networks are presented to demonstrate that
the solutions of linear systems can be learned quite accurately.",0.03758937,0.11817254,-0.17429152,C
4288,"We notice an interesting fact that ep 0,Ωh appears to have a better convergence rate than

 eu Vh , which awaits further study in the future.","Higher-order schemes
with j > 2 (we tested j up to 4) behave the same as the case of j = 2, and hence are omitted to save
space.","Approximation error                                                          Approximation error

                                ||e || : C h 0.53                                                        ||e || : C h 0.55

                                   uV 1                                                                        uV 1
                                           h                                                                               h

                                ||e || 2 : C h1.04                                                       ||e || 2 : C h1.99
                                pL 2
                           100                                                                                 pL 2
                     error
                                                                                       error  100

                                                     O(h)                                                            O(h2)

                        10-2                    10-1
                                        h
                                10-2                                                          10-2                                100

                                                                                                              h

         Figure 5.",2022-04-03 12:56:41+00:00,A Weak Galerkin Mixed Finite Element Method for second order elliptic equations on 2D Curved Domains,math.NA,"['math.NA', 'cs.NA', 'math.AP']","[arxiv.Result.Author('Yi Liu'), arxiv.Result.Author('Wenbin Chen'), arxiv.Result.Author('Yanqiu Wang')]","This article concerns the weak Galerkin mixed finite element method (WG-MFEM)
for second order elliptic equations on 2D domains with curved boundary. The
Neumann boundary condition is considered since it becomes the essential
boundary condition in this case. It is well-known that the discrepancy between
the curved physical domain and the polygonal approximation domain leads to a
loss of accuracy for discretization with polynomial order $\alpha>1$. The
purpose of this paper is two-fold. First, we present a detailed error analysis
of the original WG-MFEM for solving problems on curved domains, which exhibits
an $O(h^{1/2})$ convergence for all $\alpha\ge 1$. It is a little surprising to
see that even the lowest-order WG-MFEM ($\alpha=1$) experiences a loss of
accuracy. This is different from known results for the finite element method
(FEM) or the mixed FEM, and appears to be a combined effect of the WG-MFEM
design and the fact that the outward normal vector on the polygonal
approximation domain is different from the one on the curved domain. Second, we
propose a remedy to bring the approximation rate back to optimal by employing
two techniques. One is a specially designed boundary correction technique. The
other is to take full advantage of the nice feature that weak Galerkin
discretization can be defined on polygonal meshes, which allows the curved
boundary to be better approximated by multiple short edges without increasing
the total number of mesh elements. Rigorous analysis shows that a combination
of the above two techniques renders optimal convergence for all $\alpha$.
Numerical results further confirm this conclusion.",0.09639527,-0.22460932,-0.046068236,B
4368,"Approaches for adaptively ﬁnding the location of spikes would an interesting area
of further study.","However, if s is increased, the width of the spike is increased,
or the location of the estimate of the spike is oﬀset signiﬁcantly, then the existing oscillations
become large.","30
           4

           3

C (β )/kB  2

           1

           0

           10−4  10−3  10−2                10−1       100                                101  102

                                           kBT /|J |

Figure 8: Heat capacity as a function of temperature for a small spin system.",2022-04-05 02:23:54+00:00,Randomized matrix-free quadrature for spectrum and spectral sum approximation,math.NA,"['math.NA', 'cs.DS', 'cs.NA']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Thomas Trogdon'), arxiv.Result.Author('Shashanka Ubaru')]","We study randomized matrix-free quadrature algorithms for spectrum and
spectral sum approximation. The algorithms studied are characterized by the use
of a Krylov subspace method to approximate independent and identically
distributed samples of $\mathbf{v}^{\sf H}f[\mathbf{A}]\mathbf{v}$, where
$\mathbf{v}$ is an isotropic random vector, $\mathbf{A}$ is a Hermitian matrix,
and $f[\mathbf{A}]$ is a matrix function. This class of algorithms includes the
kernel polynomial method and stochastic Lanczos quadrature, two widely used
methods for approximating spectra and spectral sums. Our analysis, discussion,
and numerical examples provide a unified framework for understanding randomized
matrix-free quadrature and shed light on the commonalities and tradeoffs
between them. Moreover, this framework provides new insights into the practical
implementation and use of these algorithms, particularly with regards to
parameter selection in the kernel polynomial method.",0.27291554,0.0702887,0.061944272,B
4369,"While these heuristics are supported by the theory and numerical experiments above, there is
much potential for further theoretical and empirical study, and we believe further study into
spectrum dependent and a posteriori bounds would be very beneﬁcial in practice.","• The error bounds for Gaussian quadrature stated in this paper are often very pessimistic,

                                                             32
       but they still hold to close degree in ﬁnite precision arithmetic.","Likewise, a
more reﬁned analysis of the behavior of the algorithms in ﬁnite precision arithmetic might help
dispel with the misconception that the Lanczos algorithm requires the use of reorthgonalization
to be eﬀective.",2022-04-05 02:23:54+00:00,Randomized matrix-free quadrature for spectrum and spectral sum approximation,math.NA,"['math.NA', 'cs.DS', 'cs.NA']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Thomas Trogdon'), arxiv.Result.Author('Shashanka Ubaru')]","We study randomized matrix-free quadrature algorithms for spectrum and
spectral sum approximation. The algorithms studied are characterized by the use
of a Krylov subspace method to approximate independent and identically
distributed samples of $\mathbf{v}^{\sf H}f[\mathbf{A}]\mathbf{v}$, where
$\mathbf{v}$ is an isotropic random vector, $\mathbf{A}$ is a Hermitian matrix,
and $f[\mathbf{A}]$ is a matrix function. This class of algorithms includes the
kernel polynomial method and stochastic Lanczos quadrature, two widely used
methods for approximating spectra and spectral sums. Our analysis, discussion,
and numerical examples provide a unified framework for understanding randomized
matrix-free quadrature and shed light on the commonalities and tradeoffs
between them. Moreover, this framework provides new insights into the practical
implementation and use of these algorithms, particularly with regards to
parameter selection in the kernel polynomial method.",-0.33668202,-0.25101745,0.26872706,A
4370,"Approaches for adaptively ﬁnding the location of spikes would an interesting area
of further study.","However, if s is increased, the width of the spike is increased,
or the location of the estimate of the spike is oﬀset signiﬁcantly, then the existing oscillations
become large.","7.5 Energy spectra of spin systems

The quantum Heisenberg model can be used to study observables of magnetic systems [Wei+06;

SS10; SRS20; Sch+21].",2022-04-05 02:23:54+00:00,Randomized matrix-free quadrature for spectrum and spectral sum approximation,math.NA,"['math.NA', 'cs.DS', 'cs.NA']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Thomas Trogdon'), arxiv.Result.Author('Shashanka Ubaru')]","We study randomized matrix-free quadrature algorithms for spectrum and
spectral sum approximation. The algorithms studied are characterized by the use
of a Krylov subspace method to approximate independent and identically
distributed samples of $\mathbf{v}^{\mathsf{H}} f(\mathbf{A}) \mathbf{v}$,
where $\mathbf{v}$ is an isotropic random vector, $\mathbf{A}$ is a Hermitian
matrix, and $f(\mathbf{A})$ is a matrix function. This class of algorithms
includes the kernel polynomial method and stochastic Lanczos quadrature, two
widely used methods for approximating spectra and spectral sums. Our analysis,
discussion, and numerical examples provide a unified framework for
understanding randomized matrix-free quadrature algorithms and sheds light on
the commonalities and tradeoffs between them. Moreover, this framework provides
new insights into the practical implementation and use of these algorithms,
particularly with regards to parameter selection in the kernel polynomial
method.",0.14695284,0.06533101,0.19492695,B
4371,"While these heuristics are supported by the theory and numerical experiments above, there is
much potential for further theoretical and empirical study, and we believe further study into
spectrum dependent and a posteriori bounds would be very beneﬁcial in practice.","• The error bounds for Gaussian quadrature stated in this paper are often very pessimistic,
       but they still hold to close degree in ﬁnite precision arithmetic.","Likewise, a
more reﬁned analysis of the behavior of the algorithms in ﬁnite precision arithmetic might help
dispel with the misconception that the Lanczos algorithm requires the use of reorthgonalization
to be eﬀective.",2022-04-05 02:23:54+00:00,Randomized matrix-free quadrature for spectrum and spectral sum approximation,math.NA,"['math.NA', 'cs.DS', 'cs.NA']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Thomas Trogdon'), arxiv.Result.Author('Shashanka Ubaru')]","We study randomized matrix-free quadrature algorithms for spectrum and
spectral sum approximation. The algorithms studied are characterized by the use
of a Krylov subspace method to approximate independent and identically
distributed samples of $\mathbf{v}^{\mathsf{H}} f(\mathbf{A}) \mathbf{v}$,
where $\mathbf{v}$ is an isotropic random vector, $\mathbf{A}$ is a Hermitian
matrix, and $f(\mathbf{A})$ is a matrix function. This class of algorithms
includes the kernel polynomial method and stochastic Lanczos quadrature, two
widely used methods for approximating spectra and spectral sums. Our analysis,
discussion, and numerical examples provide a unified framework for
understanding randomized matrix-free quadrature algorithms and sheds light on
the commonalities and tradeoffs between them. Moreover, this framework provides
new insights into the practical implementation and use of these algorithms,
particularly with regards to parameter selection in the kernel polynomial
method.",-0.33523825,-0.2579232,0.27010995,A
4425,"The excellent performance of the neural network based algorithm motivates further research, for
which there are several interesting directions.","The performance and
distinct features of the proposed approach were illustrated on a wide range of numerical experiments.","First, the numerical ﬁndings suggest that the neural
network reconstruction is highly robust with respect to noise.",2022-04-05 18:31:03+00:00,Imaging Conductivity from Current Density Magnitude using Neural Networks,math.NA,"['math.NA', 'cs.LG', 'cs.NA', 'eess.IV']","[arxiv.Result.Author('Bangti Jin'), arxiv.Result.Author('Xiyao Li'), arxiv.Result.Author('Xiliang Lu')]","Conductivity imaging represents one of the most important tasks in medical
imaging. In this work we develop a neural network based reconstruction
technique for imaging the conductivity from the magnitude of the internal
current density. It is achieved by formulating the problem as a relaxed
weighted least-gradient problem, and then approximating its minimizer by
standard fully connected feedforward neural networks. We derive bounds on two
components of the generalization error, i.e., approximation error and
statistical error, explicitly in terms of properties of the neural networks
(e.g., depth, total number of parameters, and the bound of the network
parameters). We illustrate the performance and distinct features of the
approach on several numerical experiments. Numerically, it is observed that the
approach enjoys remarkable robustness with respect to the presence of data
noise.",-0.22912706,0.41677225,-0.063837335,C
4426,"The excellent performance of the neural network based algorithm motivates further research, for
which there are several interesting directions.","The performance and
distinct features of the proposed approach were illustrated on a wide range of numerical experiments.","First, the numerical ﬁndings suggest that the neural
network reconstruction is highly robust with respect to noise.",2022-04-05 18:31:03+00:00,Imaging Conductivity from Current Density Magnitude using Neural Networks,math.NA,"['math.NA', 'cs.LG', 'cs.NA', 'eess.IV']","[arxiv.Result.Author('Bangti Jin'), arxiv.Result.Author('Xiyao Li'), arxiv.Result.Author('Xiliang Lu')]","Conductivity imaging represents one of the most important tasks in medical
imaging. In this work we develop a neural network based reconstruction
technique for imaging the conductivity from the magnitude of the internal
current density. It is achieved by formulating the problem as a relaxed
weighted least-gradient problem, and then approximating its minimizer by
standard fully connected feedforward neural networks. We derive bounds on two
components of the generalization error, i.e., approximation error and
statistical error, explicitly in terms of properties of the neural networks
(e.g., depth, total number of parameters, and the bound of the network
parameters). We illustrate the performance and distinct features of the
approach on several numerical experiments. Numerically, it is observed that the
approach enjoys remarkable robustness with respect to the presence of data
noise.",-0.22912706,0.41677225,-0.063837335,C
4427,"The excellent performance of the neural network based algorithm motivates further research, for
which there are several interesting directions.","The performance and distinct features
of the proposed approach were illustrated on a wide range of numerical experiments.","First, the numerical ﬁndings suggest that the neural
network reconstruction is highly robust with respect to noise.",2022-04-05 18:31:03+00:00,Imaging Conductivity from Current Density Magnitude using Neural Networks,math.NA,"['math.NA', 'cs.LG', 'cs.NA', 'eess.IV']","[arxiv.Result.Author('Bangti Jin'), arxiv.Result.Author('Xiyao Li'), arxiv.Result.Author('Xiliang Lu')]","Conductivity imaging represents one of the most important tasks in medical
imaging. In this work we develop a neural network based reconstruction
technique for imaging the conductivity from the magnitude of the internal
current density. It is achieved by formulating the problem as a relaxed
weighted least-gradient problem, and then approximating its minimizer by
standard fully connected feedforward neural networks. We derive bounds on two
components of the generalization error, i.e., approximation error and
statistical error, explicitly in terms of properties of the neural networks
(e.g., depth, total number of parameters, and the bound of the network
parameters). We illustrate the performance and distinct features of the
approach on several numerical experiments. Numerically, it is observed that the
approach enjoys remarkable robustness with respect to the presence of data
noise.",-0.22912706,0.41677225,-0.063837335,C
5106,"We
       leave the question how to ﬁnd a good arrangement of the boundaries of V and W
       so that the map is bijective as an open problem for further study.","Many diﬀerent arrangements of the boundary map between V and W lead to the
       harmonic GBCC map F which is not bijective in our numerical experiment.",• 2.,2022-04-20 20:17:49+00:00,The Harmonic GBC Function Map is a Bijection if the Target Domain is Convex,math.NA,"['math.NA', 'cs.NA', '31A05, 35J25, 30C60, 53A10']","[arxiv.Result.Author('Chongyang Deng'), arxiv.Result.Author('Tsung-wei Hu'), arxiv.Result.Author('Ming-Jun Lai')]","Harmonic generalized barycentric coordinates (GBC) functions have been used
for cartoon animation since an early work in 2006\cite{JMDGS06}. A
computational procedure was further developed in \cite{SH15} for deformation
between any two polygons. The bijectivity of the map based on harmonic GBC
functions is still murky in the literature. In this paper, we present an
elementary proof of the bijection of the harmonic GBC map transforming from one
arbitrary polygonal domain $V$ to a convex polygonal domain $W$. This result is
further extended to a more general harmonic map from one simply connected
domain $V$ to a convex domain $W$ if the harmonic map preserves the orientation
of the boundary of the domain $V$. In addition, we shall point out that the
harmonic GBC map is also a diffeomorphism over the interior of $V$ to the
interior of $W$. Finally, we remark on how to construct a harmonic GBC map from
$V$ to $W$ when the number of vertices of $V$ is different from the number of
vertices of $W$ and how to construct harmonic GBC functions over a polygonal
domain with a hole or holes. We also point out that it is possible to use the
harmonic GBC map to deform a nonconvex polygon $V$ to another nonconvex polygon
$W$ by a good arrangement of the boundary map between $\partial V$ and
$\partial W$. Several numerical deformations based on images are presented to
show the effectiveness of the map based on bivariate spline approximation of
the harmonic GBC functions.",0.252319,0.029316345,0.12809637,B
5250,"Finally, some conclusions and lines for further research are stated in Section 5.","As a result, some favourable properties of the obtained method are
brought to light.","2 Numerical methods that preserve the Lyapunov function

In this section, we deﬁne and discuss key aspects of discrete gradient methods, after establishing the deﬁnitions that
will be used along the paper.",2022-04-24 09:37:29+00:00,Numerical methods that preserve a Lyapunov function for Ordinary Differential Equations,math.NA,"['math.NA', 'cs.NA', 'math.DS', '34K28 (Primary) 37M99, 65P40 (Secondary)']","[arxiv.Result.Author('Yadira Hernández-Solano'), arxiv.Result.Author('Miguel Atencia')]","The paper studies numerical methods that preserve a Lyapunov function of a
dynamical system, i.e. numerical approximations whose energy decreases, just
like in the original differential equation. With this aim, a discrete gradient
method is implemented for numerical integration of a system of ordinary
differential equations. In principle, this procedure yields first order
methods, but the analysis paves the way to the design of higher-order methods.
As a case in point, the proposed method is applied to the Duffing equation
without external forcing, considering that in this case, preserving the
Lyapunov function is more important than accuracy of particular trajectories.
Results are validated by means of numerical experiments, where the discrete
gradient method is compared to standard Runge-Kutta methods. As predicted by
the theory, discrete gradient methods preserve the Lyapunov function, whereas
conventional methods fail to do so, since either periodic solutions appear or
the energy does not decrease. Besides, the discrete gradient method outperforms
conventional schemes when these do preserve the Lyapunov function, in terms of
computational cost, thus the proposed method is promising.",0.055428386,-0.23288059,-0.19760615,B
5251,"As said above, order analysis of discrete gradient methods is an interesting avenue for further research.","Unexpectedly, DG-I turns out to be a second order method, even though the construction procedure has been identical.","The picture changes radically when the step size is increased, even modestly to h = 7 · 10−4.",2022-04-24 09:37:29+00:00,Numerical methods that preserve a Lyapunov function for Ordinary Differential Equations,math.NA,"['math.NA', 'cs.NA', 'math.DS', '34K28 (Primary) 37M99, 65P40 (Secondary)']","[arxiv.Result.Author('Yadira Hernández-Solano'), arxiv.Result.Author('Miguel Atencia')]","The paper studies numerical methods that preserve a Lyapunov function of a
dynamical system, i.e. numerical approximations whose energy decreases, just
like in the original differential equation. With this aim, a discrete gradient
method is implemented for numerical integration of a system of ordinary
differential equations. In principle, this procedure yields first order
methods, but the analysis paves the way to the design of higher-order methods.
As a case in point, the proposed method is applied to the Duffing equation
without external forcing, considering that in this case, preserving the
Lyapunov function is more important than accuracy of particular trajectories.
Results are validated by means of numerical experiments, where the discrete
gradient method is compared to standard Runge-Kutta methods. As predicted by
the theory, discrete gradient methods preserve the Lyapunov function, whereas
conventional methods fail to do so, since either periodic solutions appear or
the energy does not decrease. Besides, the discrete gradient method outperforms
conventional schemes when these do preserve the Lyapunov function, in terms of
computational cost, thus the proposed method is promising.",-0.027796166,-0.06566445,-0.25347534,C
5252,We are currently engaged in further research in order to extend the results of this paper in several directions.,"Numerical
experiments are also carried out to conﬁrm the ability of discrete gradient methods to preserve the Lyapunov function,
and the failure of standard Runge-Kutta codes for a wide range of step size values, since Lyapunov function increments
occur, thus stability is lost.","First,
we are developing order conditions to obtain higher-order methods.",2022-04-24 09:37:29+00:00,Numerical methods that preserve a Lyapunov function for Ordinary Differential Equations,math.NA,"['math.NA', 'cs.NA', 'math.DS', '34K28 (Primary) 37M99, 65P40 (Secondary)']","[arxiv.Result.Author('Yadira Hernández-Solano'), arxiv.Result.Author('Miguel Atencia')]","The paper studies numerical methods that preserve a Lyapunov function of a
dynamical system, i.e. numerical approximations whose energy decreases, just
like in the original differential equation. With this aim, a discrete gradient
method is implemented for numerical integration of a system of ordinary
differential equations. In principle, this procedure yields first order
methods, but the analysis paves the way to the design of higher-order methods.
As a case in point, the proposed method is applied to the Duffing equation
without external forcing, considering that in this case, preserving the
Lyapunov function is more important than accuracy of particular trajectories.
Results are validated by means of numerical experiments, where the discrete
gradient method is compared to standard Runge-Kutta methods. As predicted by
the theory, discrete gradient methods preserve the Lyapunov function, whereas
conventional methods fail to do so, since either periodic solutions appear or
the energy does not decrease. Besides, the discrete gradient method outperforms
conventional schemes when these do preserve the Lyapunov function, in terms of
computational cost, thus the proposed method is promising.",-0.028367992,-0.15972772,-0.272311,C
5388,"Despite this accomplishment, further research is needed to investigate under which circumstances the
presented approach can achieve consistent results.","Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with Grammar-Guided Genetic Programming 15

6 CONCLUSION AND FUTURE WORK
This work demonstrates how grammar-guided genetic programming (GGGP) can evolve multigrid preconditioners for
Helmholtz problems that outperform known methods for different wavenumbers and even handle problems for which
those methods fail.","We also aim to apply our approach to other multigrid variants, such
as algebraic multigrid methods [55], and the solution of more challenging and complicated PDEs, such as nonlinear [22]
and saddle point problems [3].",2022-04-27 11:13:34+00:00,Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with Grammar-Guided Genetic Programming,math.NA,"['math.NA', 'cs.AI', 'cs.MS', 'cs.NA', 'cs.NE']","[arxiv.Result.Author('Jonas Schmitt'), arxiv.Result.Author('Harald Köstler')]","Solving the indefinite Helmholtz equation is not only crucial for the
understanding of many physical phenomena but also represents an
outstandingly-difficult benchmark problem for the successful application of
numerical methods. Here we introduce a new approach for evolving efficient
preconditioned iterative solvers for Helmholtz problems with multi-objective
grammar-guided genetic programming. Our approach is based on a novel
context-free grammar, which enables the construction of multigrid
preconditioners that employ a tailored sequence of operations on each
discretization level. To find solvers that generalize well over the given
domain, we propose a custom method of successive problem difficulty adaption,
in which we evaluate a preconditioner's efficiency on increasingly
ill-conditioned problem instances. We demonstrate our approach's effectiveness
by evolving multigrid-based preconditioners for a two-dimensional indefinite
Helmholtz problem that outperform several human-designed methods for different
wavenumbers up to systems of linear equations with more than a million
unknowns.",-0.04138043,0.2057736,-0.33592963,C
5389,"Despite this accomplishment, further research is needed to investigate under which circumstances the
presented approach can achieve consistent results.","Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with Grammar-Guided Genetic Programming 15

6 CONCLUSION AND FUTURE WORK
This work demonstrates how grammar-guided genetic programming (GGGP) can evolve multigrid preconditioners for
Helmholtz problems that outperform known methods for different wavenumbers and even handle problems for which
those methods fail.","We also aim to apply our approach to other multigrid variants, such
as algebraic multigrid methods [55], and the solution of more challenging and complicated PDEs, such as nonlinear [22]
and saddle point problems [3].",2022-04-27 11:13:34+00:00,Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with Grammar-Guided Genetic Programming,math.NA,"['math.NA', 'cs.AI', 'cs.MS', 'cs.NA', 'cs.NE']","[arxiv.Result.Author('Jonas Schmitt'), arxiv.Result.Author('Harald Köstler')]","Solving the indefinite Helmholtz equation is not only crucial for the
understanding of many physical phenomena but also represents an
outstandingly-difficult benchmark problem for the successful application of
numerical methods. Here we introduce a new approach for evolving efficient
preconditioned iterative solvers for Helmholtz problems with multi-objective
grammar-guided genetic programming. Our approach is based on a novel
context-free grammar, which enables the construction of multigrid
preconditioners that employ a tailored sequence of operations on each
discretization level. To find solvers that generalize well over the given
domain, we propose a custom method of successive problem difficulty adaption,
in which we evaluate a preconditioner's efficiency on increasingly
ill-conditioned problem instances. We demonstrate our approach's effectiveness
by evolving multigrid-based preconditioners for a two-dimensional indefinite
Helmholtz problem that outperform several human-designed methods for different
wavenumbers up to systems of linear equations with more than a million
unknowns.",-0.04138043,0.2057736,-0.33592963,C
5428,"Modeling the
shelter network is an area of further research with great potential.","Youth crisis shelters form a complex network in NYC; RHY
                             Kaya, Mantell, Maass, Konrad, Trapp, Dimas, and Dank

may use resources from various shelters or move between shelters depending on availability.","Applying simulation and other analytical
tools to homelessness and human trafficking provides a new perspective on solutions that makes the best
use of humanitarian aid given the limited resources available.",2022-04-27 19:55:44+00:00,Discrete Event Simulation to Evaluate Shelter Capacity Expansion Options for LGBTQ+ Homeless Youth,math.NA,"['math.NA', 'cs.NA', 'math.OC']","[arxiv.Result.Author('Yaren Bilge Kaya'), arxiv.Result.Author('Sophia Mantell'), arxiv.Result.Author('Kayse Lee Maass'), arxiv.Result.Author('Renata Konrad'), arxiv.Result.Author('Andrew C. Trapp'), arxiv.Result.Author('Geri L. Dimas'), arxiv.Result.Author('Meredith Dank')]","The New York City (NYC) youth shelter system provides housing, counseling,
and other support services to runaway and homeless youth and young adults
(RHY). These resources reduce RHYs vulnerability to human trafficking, yet most
shelters are unable to meet demand. This paper presents a Discrete Event
Simulation (DES) model of a crisis-emergency and drop-in center for LGBTQ+
youth in NYC, which aims to analyze the current operations and test potential
capacity expansion interventions. The model uses data from publicly available
resources and interviews with service providers and key stakeholders. The
simulated shelter has 66 crisis-emergency beds, offers five different support
services, and serves on average 1,399 LGBTQ+ RHY per year. The capacity
expansion interventions examined in this paper are adding crisis-emergency beds
and psychiatric therapists. This application of DES serves as a tool to
communicate with policymakers, funders, and service providers potentially
having a strong humanitarian impact.",0.19182558,0.48316815,-0.035618473,C
5614,"Despite of the tremendous efforts to improve the performance of neural network
methods for solving PDEs, there are still issues that require further study.","Email addresses: hailong2019@iscas.ac.cn (H. Sheng), chao yang@pku.edu.cn
                                         (C. Yang)

                                         http://www.global-sci.com/  Global Science Preprint
2

enabled neural network methods to draw increasingly more attention with both early
studies using shallow neural networks [12–18] and recent works with the advent of deep
learning technology [5, 19–25].","The ﬁrst is-
sue is related to the accuracy of neural network methods.",2022-05-02 00:44:15+00:00,PFNN-2: A Domain Decomposed Penalty-Free Neural Network Method for Solving Partial Differential Equations,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Hailong Sheng'), arxiv.Result.Author('Chao Yang')]","A new penalty-free neural network method, PFNN-2, is presented for solving
partial differential equations, which is a subsequent improvement of our
previously proposed PFNN method [1]. PFNN-2 inherits all advantages of PFNN in
handling the smoothness constraints and essential boundary conditions of
self-adjoint problems with complex geometries, and extends the application to a
broader range of non-self-adjoint time-dependent differential equations. In
addition, PFNN-2 introduces an overlapping domain decomposition strategy to
substantially improve the training efficiency without sacrificing accuracy.
Experiments results on a series of partial differential equations are reported,
which demonstrate that PFNN-2 can outperform state-of-the-art neural network
methods in various aspects such as numerical accuracy, convergence speed, and
parallel scalability.",-0.0637197,0.25759658,-0.16281681,C
5673,"The continue work including of the dynamical
restarted strategies, relaxation and the randomized selection rule are deserved to further study
in the future.","Numerical experiments verify the proposed algorithms are eﬃcient
and outperform the existing method for overdetermined and underdetermined linear equations,
as well as in the application in image processing.","10  J.-F. Yin, N. Li and N. Zheng

References

 [1] Rainer Ansorge.",2022-05-03 09:30:42+00:00,Restarted randomized surrounding methods for solving large linear equations,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Junfeng Yin'), arxiv.Result.Author('Nan Li'), arxiv.Result.Author('Ning Zheng')]","A class of restarted randomized surrounding methods are presented to
accelerate the surrounding algorithms by restarted techniques for solving the
linear equations. Theoretical analysis prove that the proposed method converges
under the randomized row selection rule and the expectation convergence rate is
also addressed. Numerical experiments further demonstrate that the proposed
algorithms are efficient and outperform the existing method for over-determined
and under-determined linear equation, as well as in the application of image
processing.",-0.105940334,0.18821979,-0.048280794,C
5705,"We have analyzed the computation of coupled ADR equations by the conventional method [16], and
this paper makes a further study on the computation of the equations by the waveform relaxation method,
aiming to further understand the roles of transmission conditions as well as their algorithms.","Computation by a Schwarz
waveform relaxation method is studied for systems of ordinary differential equations resulting from RC type
circuits [26, 27], which seem different but are related to the discretization of coupled advection-diffusion re-
actions equations as shown in this paper.","Most earlier
investigations deal with the same linear equations in subdomains, and they are primarily conducted at the
continuous level.",2022-05-03 18:12:35+00:00,Convergence Analysis of Waveform Relaxation Method to Compute Coupled Advection-Diffusion-Reaction Equations,math.NA,"['math.NA', 'cs.NA', '65M55', 'G.1.8']","[arxiv.Result.Author('Wenbin Dong'), arxiv.Result.Author('Hansong Tang')]","We study the computation of coupled advection-diffusion-reaction equations by
the Schwarz waveform relaxation method. The study starts with linear equations,
and it analyzes the convergence of the computation with a Dirichlet condition,
a Robin condition, and a combination of them as the transmission conditions.
Then, an optimized algorithm for the Dirichlet condition is presented to
accelerate the convergence, and numerical examples show a substantial speedup
in the convergence. Furthermore, the optimized algorithm is extended to the
computation of nonlinear equations, including the viscous Burgers equation, and
numerical experiments indicate the algorithm may largely remain effective in
the speedup of convergence.",0.17616606,0.020414617,-0.3023225,C
5711,"A high-quality practical implementation for large-scale problems
will likely require further study in order to more eﬀectively balance the true
costs of the algorithm.","The eﬀect on the compu-
tational time is less clear, and depends both on the cost of maintaining the
orthonormal basis Q¯ and on how eﬃciently matvecs with A can be computed
in parallel.","For such a setting, we believe that the restarted variant
(Algorithm 5), in particular, merits further study.",2022-05-03 19:15:25+00:00,Krylov-aware stochastic trace estimation,math.NA,"['math.NA', 'cs.NA', '15A16, 65F50, 65F60, 68W25']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Eric Hallman')]","We introduce an algorithm for estimating the trace of a matrix function f(A)
using implicit products with a symmetric matrix A. Existing methods for
implicit trace estimation of a matrix function tend to treat matrix-vector
products with f(A) as a black-box to be computed by a Krylov subspace method.
Like other algorithms for implicit trace estimation, our approach is based on a
combination of deflation and stochastic trace estimation. However, we take a
closer look at how products with f(A) are integrated into these approaches
which enables several efficiencies not present in previously studied methods.",-0.43347436,-0.031981148,-0.016143262,A_centroid
5712,"For such a setting, we believe that the restarted variant
(Algorithm 5), in particular, merits further study.","A high-quality practical implementation for large-scale problems
will likely require further study in order to more eﬀectively balance the true
costs of the algorithm.","It is also worth considering the role of the approximation degree n in fur-
ther detail.",2022-05-03 19:15:25+00:00,Krylov-aware stochastic trace estimation,math.NA,"['math.NA', 'cs.NA', '15A16, 65F50, 65F60, 68W25']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Eric Hallman')]","We introduce an algorithm for estimating the trace of a matrix function f(A)
using implicit products with a symmetric matrix A. Existing methods for
implicit trace estimation of a matrix function tend to treat matrix-vector
products with f(A) as a black-box to be computed by a Krylov subspace method.
Like other algorithms for implicit trace estimation, our approach is based on a
combination of deflation and stochastic trace estimation. However, we take a
closer look at how products with f(A) are integrated into these approaches
which enables several efficiencies not present in previously studied methods.",-0.27860558,0.15246671,-0.0076597566,A
5713,"A high-quality practical implementation for large-scale prob-
lems will likely require further study in order to more eﬀectively balance the true
costs of the algorithm.","The eﬀect on the computational time is less clear, and depends both on the cost of
maintaining the orthonormal basis Q¯ and on how eﬃciently matvecs with A can be
computed in parallel.","For such a setting, we believe that the restarted variant (Al-
gorithm 4.2), in particular, merits further study.",2022-05-03 19:15:25+00:00,Krylov-aware stochastic trace estimation,math.NA,"['math.NA', 'cs.NA', '15A16, 65F50, 65F60, 68W25']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Eric Hallman')]","We introduce an algorithm for estimating the trace of a matrix function
$f(\mathbf{A})$ using implicit products with a symmetric matrix $\mathbf{A}$.
Existing methods for implicit trace estimation of a matrix function tend to
treat matrix-vector products with $f(\mathbf{A})$ as a black-box to be computed
by a Krylov subspace method. Like other algorithms for implicit trace
estimation, our approach is based on a combination of deflation and stochastic
trace estimation. However, we take a closer look at how products with
$f(\mathbf{A})$ are integrated into these approaches which enables several
efficiencies not present in previously studied methods. In particular, we
describe a Krylov subspace method for computing a low-rank approximation of a
matrix function by a computationally efficient projection onto Krylov subspace.",-0.36511523,-0.053468827,0.13315882,A
5714,"For such a setting, we believe that the restarted variant (Al-
gorithm 4.2), in particular, merits further study.","A high-quality practical implementation for large-scale prob-
lems will likely require further study in order to more eﬀectively balance the true
costs of the algorithm.","It is also worth considering the role of the approximation degree n in further
detail.",2022-05-03 19:15:25+00:00,Krylov-aware stochastic trace estimation,math.NA,"['math.NA', 'cs.NA', '15A16, 65F50, 65F60, 68W25']","[arxiv.Result.Author('Tyler Chen'), arxiv.Result.Author('Eric Hallman')]","We introduce an algorithm for estimating the trace of a matrix function
$f(\mathbf{A})$ using implicit products with a symmetric matrix $\mathbf{A}$.
Existing methods for implicit trace estimation of a matrix function tend to
treat matrix-vector products with $f(\mathbf{A})$ as a black-box to be computed
by a Krylov subspace method. Like other algorithms for implicit trace
estimation, our approach is based on a combination of deflation and stochastic
trace estimation. However, we take a closer look at how products with
$f(\mathbf{A})$ are integrated into these approaches which enables several
efficiencies not present in previously studied methods. In particular, we
describe a Krylov subspace method for computing a low-rank approximation of a
matrix function by a computationally efficient projection onto Krylov subspace.",-0.28184533,0.039728787,0.13969944,A
5726,"There were some
                                         further study about it, such as [18, 45, 46].","Another eﬀective eigenvalue
                                         solver is the two grid method proposed by Xu and Zhou in [42, 43].","Moreover, some methods based on correc-

                                             ∗Version of May 5, 2022.",2022-05-04 02:30:50+00:00,Convergence analysis of the Newton-Schur method for the symmetric elliptic eigenvalue problem,math.NA,"['math.NA', 'cs.NA', '65N25, 65N30, 65N55']","[arxiv.Result.Author('Nian Shao'), arxiv.Result.Author('Wenbin Chen')]","In this paper, we consider the Newton-Schur method in Hilbert space and
obtain quadratic convergence. For the symmetric elliptic eigenvalue problem
discretized by the standard finite element method and non-overlapping domain
decomposition method, we use the Steklov-Poincar\'e operator to reduce the
eigenvalue problem on the domain $\Omega$ into the nonlinear eigenvalue
subproblem on $\Gamma$, which is the union of subdomain boundaries. We prove
that the convergence rate for the Newton-Schur method is $\epsilon_{N}\leq
CH^{2}(1+\ln(H/h))^{2}\epsilon^{2}$, where the constant $C$ is independent of
the fine mesh size $h$ and coarse mesh size $H$, and $\epsilon_{N}$ and
$\epsilon$ are errors after and before one iteration step respectively.
Numerical experiments confirm our theoretical analysis.",-0.28406358,-0.1140904,-0.0840888,A
5776,"These trade-oﬀs warrant further study in the
context of the graph theoretic approach presented here.","13a – 13b
The reduced-order models with operator numbers in this range perhaps should be understood as
incorporating some of the physics with the oscillatory derivative operators, while relying on the
smoother algebraic terms to follow the mean trends.","Importantly, however, this treatment admits
these examinations of interpretability via explicit representation of non-local derivative terms.",2022-05-04 17:32:00+00:00,"Numerical analysis of non-local calculus on finite weighted graphs, with application to reduced-order modelling of dynamical systems",math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Matthew Duschenes'), arxiv.Result.Author('Siddhartha Srivastava'), arxiv.Result.Author('Krishna Garikipati')]","We present an approach to reduced-order modelling that builds off recent
graph-theoretic work for representation, exploration, and analysis of computed
states of physical systems (Banerjee et al., Comp. Meth. App. Mech. Eng., 351,
501-530, 2019). We extend a non-local calculus on finite weighted graphs to
build such models by exploiting polynomial expansions and Taylor series. In the
general framework for non-local calculus on graphs, the graph edge weights are
intricately linked to the embedding of the graph, and consequently to the
definition of the derivatives. In a previous communication (Duschenes and
Garikipati, arXiv:2105.01740), we have shown that radially symmetric,
continuous edge weights derived from, for example Gaussian functions, yield
inconsistent results in the resulting non-local derivatives when compared
against the corresponding local, differential derivative definitions. Taking
inspiration from finite difference methods, we algorithmically compute edge
weights, considering the embedding of the local neighborhood of each graph
vertex. Given this procedure, we ensure the consistency of the non-local
derivatives in this setting, a crucial requirement for numerical applications.
We show that we can achieve any desired orders of accuracy of derivatives, in a
chosen number of dimensions without symmetry assumptions in the underlying
data. Finally, we present two example applications of extracting reduced-order
models using this non-local calculus, in the form of ordinary differential
equations from parabolic partial differential equations of progressively
greater complexity.",0.26289004,-0.05300896,-0.047962867,B
5822,"Numerical examples
                                              in one-dimensional test cases illustrate the advantages and limitations of this approach and suggest
                                              further research directions that we intend to explore in the future.","In this work, we investigate an adaptation of the methodology proposed in [15], based
                                              on the use of Wasserstein barycenters [1], to the case of non-conservative problems.",Résumé.,2022-05-05 15:52:55+00:00,Waserstein model reduction approach for parametrized flow problems in porous media,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Beatrice Battisti'), arxiv.Result.Author('Tobias Blickhan'), arxiv.Result.Author('Guillaume Enchéry'), arxiv.Result.Author('Virginie Ehrlacher'), arxiv.Result.Author('Damiano Lombardi'), arxiv.Result.Author('Olga Mula')]","The aim of this work is to build a reduced-order model for parametrized
porous media equations. The main challenge of this type of problems is that the
Kolmogorov width of the solution manifold typically decays quite slowly and
thus makes usual linear model-order reduction methods inappropriate. In this
work, we investigate an adaptation of the methodology proposed in a previous
work, based on the use of Wasserstein barycenters, to the case of
non-conservative problems. Numerical examples in one-dimensional test cases
illustrate the advantages and limitations of this approach and suggest further
research directions that we intend to explore in the future.",0.12779352,-0.050167244,-0.06549251,B
6166,"random) search        Section 4 and discuss further research avenues in Section 5.
optimization [21].","quently, we conduct exhaustive numerical experiments in
Many approaches exist, such as grid (resp.","Still, the ﬁrst one suﬀers from the curse
of dimensionality, and the other can be very ineﬃcient.",2022-05-13 15:17:27+00:00,Hyper-parameter tuning of physics-informed neural networks: Application to Helmholtz problems,math.NA,"['math.NA', 'cs.AI', 'cs.NA']","[arxiv.Result.Author('Paul Escapil-Inchauspé'), arxiv.Result.Author('Gonzalo A. Ruz')]","We consider physics-informed neural networks [Raissi et al., J. Comput. Phys.
278 (2019) 686-707] for forward physical problems. In order to find optimal
PINNs configuration, we introduce a hyper-parameter tuning procedure via
Gaussian processes-based Bayesian optimization. We apply the procedure to
Helmholtz problems for bounded domains and conduct a thorough study, focusing
on: (i) performance, (ii) the collocation points density $r$ and (iii) the
frequency $\kappa$, confirming the applicability and necessity of the method.
Numerical experiments are performed in two and three dimensions, including
comparison to finite element methods.",-0.053885616,0.09050014,0.13909759,A
6309,"Earlier studies are devoted to the normal regime ε ≈ 1, comprising the well-known Boris method
[4] as well as some further researches on it [22, 26, 38], volume-preserving algorithms [27], symmetric
algorithms [23], symplectic algorithms [28, 42, 45, 46], variational integrators [24, 37], splitting
integrators [31] and energy-preserving algorithms [5, 6, 34].","Concerning the numerical algorithms for the CPD (1.4) or (1.5), two categories have
been in the center of research according to diﬀerent regimes of magnetic ﬁeld: normal magnetic
ﬁeld ε ≈ 1 and strong magnetic ﬁeld 0 < ε ≪ 1.","However, if those methods are applied
to CPD with a strong magnetic ﬁeld 0 < ε ≪ 1, this often adds a stringent restriction on the
time step used in the numerical algorithms.",2022-05-17 09:23:01+00:00,Semi-discretization and full-discretization with optimal accuracy for charged-particle dynamics in a strong nonuniform magnetic field,math.NA,"['math.NA', 'cs.NA', '65L05, 65L70, 78A35, 78M25']","[arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Yaolin Jiang')]","The aim of this paper is to formulate and analyze numerical discretizations
of charged-particle dynamics (CPD) in a strong nonuniform magnetic field. A
strategy is firstly performed for the two dimensional CPD to construct the
semi-discretization and full-discretization which have optimal accuracy. This
accuracy is improved in the position and in the velocity when the strength of
the magnetic field becomes stronger. This is a better feature than the usual so
called ""uniformly accurate methods"". To obtain this refined accuracy, some
reformulations of the problem and two-scale exponential integrators are
incorporated, and the optimal accuracy is derived from this new procedure. Then
based on the strategy given for the two dimensional case, a new class of
uniformly accurate methods with simple scheme is formulated for the three
dimensional CPD in maximal ordering case. All the theoretical results of the
accuracy are numerically illustrated by some numerical tests.",0.013082276,-0.123085305,-0.078529015,A
6523,"In further research we plan to
           study how to implement an adaptive global basis using butterﬂy matrices [Dao+19], which
           are known to be connected to fast special function transforms [OWR10].",Basis functions that we used are completely non-adaptive.,3.,2022-05-21 11:59:43+00:00,Spectral Neural Operators,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('V. Fanaskov'), arxiv.Result.Author('I. Oseledets')]","A plentitude of applications in scientific computing requires the
approximation of mappings between Banach spaces. Recently introduced Fourier
Neural Operator (FNO) and Deep Operator Network (DeepONet) can provide this
functionality. For both of these neural operators, the input function is
sampled on a given grid (uniform for FNO), and the output function is
parametrized by a neural network. We argue that this parametrization leads to
1) opaque output that is hard to analyze and 2) systematic bias caused by
aliasing errors in the case of FNO. The alternative, advocated in this article,
is to use Chebyshev and Fourier series for both domain and codomain. The
resulting Spectral Neural Operator (SNO) has transparent output, never suffers
from aliasing, and may include many exact (lossless) operations on functions.
The functionality is based on well-developed fast, and stable algorithms from
spectral methods. The implementation requires only standard numerical linear
algebra. Our benchmarks show that for many operators, SNO is superior to FNO
and DeepONet.",-0.17352533,0.093548216,0.04128069,A
6651,"For higher r-order (r ≥ 3) FVMs on tetrahedral meshes, the stability analysis is much more

complex and it needs further study.",These theoretical results are conﬁrmed by some numerical experiments.,"Appendix A: Some symbolic matrices

A.1 The symbolic matrix A in (29).",2022-05-24 13:39:19+00:00,Construction and analysis of the quadratic finite volume methods on tetrahedral meshes,math.NA,"['math.NA', 'cs.NA', '65N12, 65N08']","[arxiv.Result.Author('Peng Yang'), arxiv.Result.Author('Xiang Wang'), arxiv.Result.Author('Yonghai Li')]","A family of quadratic finite volume method (FVM) schemes are constructed and
analyzed over tetrahedral meshes. In order to prove stability and error
estimate, we propose the minimum V-angle condition on tetrahedral meshes, and
the surface and volume orthogonal conditions on dual meshes. Through the
element analysis technique, the local stability is equivalent to a positive
definiteness of a $9\times9$ element matrix, which is difficult to analyze
directly or even numerically. With the help of the surface orthogonal condition
and congruent transformation, this element matrix is reduced into a block
diagonal matrix, then we carry out the stability result under the minimum
V-angle condition. It is worth mentioning that the minimum V-angle condition of
the tetrahedral case is very different from a simple extension of the minimum
angle condition for triangular meshes, while it is also convenient to use in
practice. Based on the stability, we prove the optimal $ H^{1} $ and $L^2$
error estimates respectively, where the orthogonal conditions play an important
role in ensuring optimal $L^2$ convergence rate. Numerical experiments are
presented to illustrate our theoretical results.",0.016223725,0.016263597,-0.076007,A
7548,This opens doors to further research on this family of schemes.,"The authors still do not understand why the optimal order
of accuracy is not reached.","Note that we do not show results for Bernstein elements with SSPRK technique because they are identical to Basic
elements, but are more expensive because of the projection in the Bernstein element space and the interpolation in the
quadrature points.",2022-06-13 13:35:50+00:00,"Spectral analysis of high order continuous FEM for hyperbolic PDEs on triangular meshes: influence of approximation, stabilization, and time-stepping",math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Sixtine Michel'), arxiv.Result.Author('Davide Torlo'), arxiv.Result.Author('Mario Ricchiuto'), arxiv.Result.Author('Rémi Abgrall')]","In this work we study various continuous finite element discretization for
two dimensional hyperbolic partial differential equations, varying the
polynomial space (Lagrangian on equispaced, Lagrangian on quadrature points
(Cubature) and Bernstein), the stabilization techniques (streamline-upwind
Petrov-Galerkin, continuous interior penalty, orthogonal subscale
stabilization) and the time discretization (Runge-Kutta (RK), strong stability
preserving RK and deferred correction). This is an extension of the one
dimensional study by Michel S. et al J. Sci. Comput. (2021), whose results do
not hold in multi-dimensional frameworks. The study ranks these schemes based
on efficiency (most of them are mass-matrix free), stability and dispersion
error, providing the best CFL and stabilization coefficients. The challenges in
two-dimensions are related to the Fourier analysis. Here, we perform it on two
types of periodic triangular meshes varying the angle of the advection, and we
combine all the results for a general stability analysis. Furthermore, we
introduce additional high order viscosity to stabilize the discontinuities, in
order to show how to use these methods for tests of practical interest. All the
theoretical results are thoroughly validated numerically both on linear and
non-linear problems, and error-CPU time curves are provided. Our final
conclusions suggest that Cubature elements combined with SSPRK and OSS
stabilization is the most promising combination.",-0.14552549,-0.10288836,0.08865571,A
7896,"In the following experiments, we will further study the
computation of sparse matrices.","It must be pointed out that in
this experiment the maximum dimension is only 2000, hence the full matrix instead of sparse
matrix is used in the computation.","5.2 Changes of the sparse matrix bandwidth in iteration

    The second experiment focus on the change of the bandwidths of the matrices involved in
the proposed method by using the same matrix deﬁned by (74) with λ = −1 and n = 10000.",2022-06-21 13:03:53+00:00,A new stable and avoiding inversion iteration for computing matrix square root,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Li Zhu'), arxiv.Result.Author('Keqi Ye'), arxiv.Result.Author('Yuelin Zhao'), arxiv.Result.Author('Feng Wu'), arxiv.Result.Author('Jiqiang Hu'), arxiv.Result.Author('Wanxie Zhong')]","The objective of this research was to compute the principal matrix square
root with sparse approximation. A new stable iterative scheme avoiding fully
matrix inversion (SIAI) is provided. The analysis on the sparsity and error of
the matrices involved during the iterative process is given. Based on the
bandwidth and error analysis, a more efficient algorithm combining the SIAI
with the filtering technique is proposed. The high computational efficiency and
accuracy of the proposed method are demonstrated by computing the principal
square roots of different matrices to reveal its applicability over the
existing methods.",-0.2541444,-0.08097892,0.14040563,A
7905,"Finally, the question of how to best symmetrize the preconditioner when A is symmetric also
deserves further study.","Also, we plan to investigate the use of the preconditioner in the context of augmented Lagrangian
Preconditioning techniques for a class of linear systems  19

preconditioning of incompressible ﬂow problems, in order to determine how accurately one needs to
solve the system (15) at each appplication of the block triangular preconditioner (2) without adversely
impacting the performance of FGMRES.","References

[1] P. R. Amestoy, T. A. Davis, and I. S. Duﬀ, An approximate minimum degree ordering algorithm, SIAM J. Matrix
     Anal.",2022-06-21 14:48:32+00:00,"Solving linear systems of the form $(A + γUU^T)\, {\bf x} = {\bf b}$ by preconditioned iterative methods",math.NA,"['math.NA', 'cs.NA', '65F10']","[arxiv.Result.Author('Michele Benzi'), arxiv.Result.Author('Chiara Faccio')]","We consider the iterative solution of large linear systems of equations in
which the coefficient matrix is the sum of two terms, a sparse matrix $A$ and a
possibly dense, rank deficient matrix of the form $\gamma UU^T$, where $\gamma
> 0$ is a parameter which in some applications may be taken to be 1. The matrix
$A$ itself can be singular, but we assume that the symmetric part of $A$ is
positive semidefinite and that $A+\gamma UU^T$ is nonsingular. Linear systems
of this form arise frequently in fields like optimization, fluid mechanics,
computational statistics, and others. We investigate preconditioning strategies
based on an alternating splitting approach combined with the use of the
Sherman-Morrison-Woodbury matrix identity. The potential of the proposed
approach is demonstrated by means of numerical experiments on linear systems
from different application areas.",-0.27824432,-0.034109473,-0.17544328,A
8542,It opens up a wide range of applications and extensions for further research.,"D  O

   Thus, we provided a ﬂexible machine learning framework using simple FFNNs, geared toward high-

dimensional eigenvalues problem of diﬀusion operators, linear and nonlinear, that are beyond reach with

mesh-based methods.","For instance, in computer vision problems involving partial shape similarities, it is known that matching
similar regions in 3D can be formulated as an alignment of k eigenvalues of operators closely related to the
Laplace-Beltrami operator (LBO) [RTO+19].",2022-07-07 08:52:53+00:00,Deep spectral computations in linear and nonlinear diffusion problems,math.NA,"['math.NA', 'cs.NA', 'math-ph', 'math.MP', '68T07 (Primary), 65C99, 35P30, 35P99 (Secondary)']","[arxiv.Result.Author('Eric Simonnet'), arxiv.Result.Author('Mickaël D. Chekroun')]","We propose a flexible machine-learning framework for solving eigenvalue
problems of diffusion operators in moderately large dimension. We improve on
existing Neural Networks (NNs) eigensolvers by demonstrating our approach
ability to compute (i) eigensolutions for non-self adjoint operators with small
diffusion (ii) eigenpairs located deep within the spectrum (iii) computing
several eigenmodes at once (iv) handling nonlinear eigenvalue problems. To do
so, we adopt a variational approach consisting of minimizing a natural cost
functional involving Rayleigh quotients, by means of simple adiabatic technics
and multivalued feedforward neural parametrisation of the solutions. Compelling
successes are reported for a 10-dimensional eigenvalue problem corresponding to
a Kolmogorov operator associated with a mixing Stepanov flow. We moreover show
that the approach allows for providing accurate eigensolutions for a 5-D
Schr\""odinger operator having $32$ metastable states. In addition, we address
the so-called Gelfand superlinear problem having exponential nonlinearities, in
dimension $4$, and for nontrivial domains exhibiting cavities. In particular,
we obtain NN-approximations of high-energy solutions approaching singular ones.
We stress that each of these results are obtained using small-size neural
networks in situations where classical methods are hopeless due to the curse of
dimensionality. This work brings new perspectives for the study of
Ruelle-Pollicot resonances, dimension reduction, nonlinear eigenvalue problems,
and the study of metastability when the dynamics has no potential.",-0.099479035,0.19545662,0.18541671,A
8639,"Motivated by simple of the method and its successful numerical experiments, we
further study CANN method for more higher dimensional parabolic problems.","This method can relief from CFL
restrictions for explicit diﬀerence scheme and can adapt to any time size for neural networks
solver.","High-dimensional partial diﬀerential equations are used in physics, engineering, and ﬁ-
nance.",2022-07-09 13:53:48+00:00,Cell-average based neural network method for high dimensional parabolic differential equations,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Hong Zhang'), arxiv.Result.Author('Hongying Huang'), arxiv.Result.Author('Jue Yan')]","In this paper, we introduce cell-average based neural network (CANN) method
to solve high-dimensional parabolic partial differential equations. The method
is based on the integral or weak formulation of partial differential equations.
A feedforward network is considered to train the solution average of cells in
neighboring time. Initial values and approximate solution at $t=\Delta t$
obtained by high order numerical method are taken as the inputs and outputs of
network, respectively. We use supervised training combined with a simple
backpropagation algorithm to train the network parameters. We find that the
neural network has been trained to optimality for high-dimensional problems,
the CFL condition is not strictly limited for CANN method and the trained
network is used to solve the same problem with different initial values. For
the high-dimensional parabolic equations, the convergence is observed and the
errors are shown related to spatial mesh size but independent of time step
size.",0.070705056,0.10778743,-0.29068893,C
8924,"Since these studies
should include multidimensional test cases, we have not yet conducted further research in this direction.","Speciﬁcally, nonlinear
friction models should be considered and the parameters δ and σ may need to be adjusted.","6 Conclusions

We presented an extension of the bound-preserving and entropy-stable monolithic convex limiting strategy to
the inhomogeneous system of shallow water equations.",2022-07-15 02:38:03+00:00,Bound-preserving and entropy-stable algebraic flux correction schemes for the shallow water equations with topography,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Hennes Hajduk'), arxiv.Result.Author('Dmitri Kuzmin')]","A well-designed numerical method for the shallow water equations (SWE) should
ensure well-balancedness, nonnegativity of water heights, and entropy
stability. For a continuous finite element discretization of a nonlinear
hyperbolic system without source terms, positivity preservation and entropy
stability can be enforced using the framework of algebraic flux correction
(AFC). In this work, we develop a well-balanced AFC scheme for the SWE system
including a topography source term. Our method preserves the lake at rest
equilibrium up to machine precision. The low-order version represents a
generalization of existing finite volume approaches to the finite element
setting. The high-order extension is equipped with a property-preserving flux
limiter. Nonnegativity of water heights is guaranteed under a standard CFL
condition. Moreover, the flux-corrected space discretization satisfies a
semi-discrete entropy inequality. New algorithms are proposed for realistic
simulation of wetting and drying processes. Numerical examples for well-known
benchmarks are presented to evaluate the performance of the scheme.",0.4432562,0.045291282,-0.1451205,B
8927,"We conclude our discussion by pointing out possible limitations and suggestions for further research,

       • We have only focused on neural netwok approximations in the supervised learning paradigm.","These
clearly demonstrate how the training and generalization error only grow polynomially in terms of the
parameter dimension and how the gap between generalization and training error converges to zero, when
when the number of training samples is increased, as predicted by the theoretical results.","In
          this setting, for every parameter in the training set one needs to (approximately) solve the con-
          servation law, e.g.",2022-07-15 09:21:09+00:00,Error analysis for deep neural network approximations of parametric hyperbolic conservation laws,math.NA,"['math.NA', 'cs.LG', 'cs.NA']","[arxiv.Result.Author('Tim De Ryck'), arxiv.Result.Author('Siddhartha Mishra')]","We derive rigorous bounds on the error resulting from the approximation of
the solution of parametric hyperbolic scalar conservation laws with ReLU neural
networks. We show that the approximation error can be made as small as desired
with ReLU neural networks that overcome the curse of dimensionality. In
addition, we provide an explicit upper bound on the generalization error in
terms of the training error, number of training samples and the neural network
size. The theoretical results are illustrated by numerical experiments.",0.023089422,0.1569137,0.18938455,B
9101,"Strong assumptions
      on the separability are however currently needed for this approach to
      be successful, and further research should be very fruitful into this
      direction.","A ﬁrst
   fundamental contribution into this direction is the recent PhD thesis
   Preuss (2021) on learned inﬁnite elements, which construct transmis-
                                                        123

      sion conditions based on approximating the symbol of the Dirichlet to
      Neumann operator for the layered outer medium.","• Finally, the research on more general decompositions including cross
      points is today largely open: is it possible to get a precise convergence
      factor in a checkerboard decomposition, and to optimize transmission
      conditions in this case, or estimate the PML depth needed for good
      performance?",2022-07-20 10:09:28+00:00,Schwarz methods by domain truncation,math.NA,"['math.NA', 'cs.NA', '65Y05']","[arxiv.Result.Author('Martin J. Gander'), arxiv.Result.Author('Hui Zhang')]","Schwarz methods use a decomposition of the computational domain into
subdomains and need to put boundary conditions on the subdomain boundaries. In
domain truncation one restricts the unbounded domain to a bounded computational
domain and also needs to put boundary conditions on the computational domain
boundaries. It turns out to be fruitful to think of the domain decomposition in
Schwarz methods as truncation of the domain onto subdomains. The first truly
optimal Schwarz method that converges in a finite number of steps was proposed
in 1994 and used precisely transparent boundary conditions as transmission
conditions between subdomains. Approximating these transparent boundary
conditions for fast convergence of Schwarz methods led to the development of
optimized Schwarz methods -- a name that has become common for Schwarz methods
based on domain truncation. Compared to classical Schwarz methods which use
simple Dirichlet transmission conditions and have been successfully used in a
wide range of applications, optimized Schwarz methods are much less well
understood, mainly due to their more sophisticated transmission conditions.
This present situation is the motivation for our survey: to give a
comprehensive review and precise exploration of convergence behaviors of
optimized Schwarz methods based on Fourier analysis taking into account the
original boundary conditions, many subdomain decompositions and layered media.
The transmission conditions we study include the lowest order absorbing
conditions (Robin), and also more advanced perfectly matched layers (PML), both
developed first for domain truncation.",0.06392227,0.08825612,0.13003635,A
9258,"It does seem that further research
about avoiding unwanted poles in AAA approximation is called for, but fortunately,
in a practical setting, such poles are immediately detectable and thus pose no risk of
inaccuracy without warning to the user.","by an implementation in extended precision arithmetic as in Figure 4.4 or by simply
raising the AAA convergence tolerance to 10−11.",Acknowledgments.,2022-07-24 20:33:06+00:00,AAA interpolation of equispaced data,math.NA,"['math.NA', 'cs.NA', '41A20, 65D05, 65D15']","[arxiv.Result.Author('Daan Huybrechs'), arxiv.Result.Author('Lloyd N. Trefethen')]","We propose AAA rational approximation as a method for interpolating or
approximating smooth functions from equispaced data samples. Although it is
always better to approximate from large numbers of samples if they are
available, whether equispaced or not, this method often performs impressively
even when the sampling grid is fairly coarse. In most cases it gives more
accurate approximations than other methods.",-0.0802677,-0.02858862,0.11355904,A
9573,"Before detailing the results, let us state that all of these questions can be answered with promis-
ing results, although the question of small approximation errors needs further research.",• Does the added dissipation reduce or enlarge the possible time step?,"The
tested methods, i.e.",2022-08-01 15:40:59+00:00,Stabilizing discontinuous Galerkin methods using Dafermos' entropy rate criterion,math.NA,"['math.NA', 'cs.NA', 'math.AP']",[arxiv.Result.Author('Simon-Christian Klein')],"A novel approach for the stabilization of the discontinuous Galerkin method
based on the Dafermos entropy rate crition is presented. The approach is
centered around the efficient solution of linear or nonlinear optimization
problems in every timestep as a correction to the basic discontinuous Galerkin
scheme. The thereby enforced Dafermos criterion results in improved stability
compared to the basic method while retaining the order of the method in
numerical experiments. Further modification of the optimization problem allows
also to enforce classical entropy inequalities for the scheme. The proposed
stabilization is therefore an alternative to flux-differencing, finite-volume
subcells, artificial viscosity, modal filtering, and other shock capturing
procedures.",0.099546365,-0.10374424,-0.10882604,B
9603,"In this paper, which is a sequel to Part I [9], we further study the computation of
                                         eigenvalues of singular matrix pencils.",Introduction.,"Whereas in [9] a method based on a rank-completing perturbation
                                         has been introduced (i.e., an update by a pencil of a rank that is precisely suﬃcient to render the updated
                                         pencil regular), we propose in this paper a scheme based on rank projection (i.e., a projection of the pencil
                                         onto a subspace of maximal possible size such that the projected pencil is generically regular), as well as
                                         an augmentation method, as two alternative techniques.",2022-08-02 11:05:58+00:00,Solving singular generalized eigenvalue problems. Part II: projection and augmentation,math.NA,"['math.NA', 'cs.NA', '65F15, 65F50, 15A18, 15A22, 15A21, 47A55, 65F22']","[arxiv.Result.Author('Michiel E. Hochstenbach'), arxiv.Result.Author('Christian Mehl'), arxiv.Result.Author('Bor Plestenjak')]","Generalized eigenvalue problems involving a singular pencil may be very
challenging to solve, both with respect to accuracy and efficiency. While Part
I presented a rank-completing addition to a singular pencil, we now develop two
alternative methods. The first technique is based on a projection onto
subspaces with dimension equal to the normal rank of the pencil while the
second approach exploits an augmented matrix pencil. The projection approach
seems to be the most attractive version for generic singular pencils because of
its efficiency, while the augmented pencil approach may be suitable for
applications where a linear system with the augmented pencil can be solved
efficiently.",-0.24277301,-0.07028946,0.23079108,A
9873,"Even though a structured low-rank matrix framework for the piecewise smooth functions
are proposed in [11], further researches are required as the estimation of annihilating sub-
spaces is involved with the blind deconvolutions.","This
means that, neither piecewise smooth images nor textures may not be suitable for (25).","In addition, noting that the structured
low-rank matrices in the image domain can reﬂect the textures [28, 59], we may be able
to jointly adopt the structured low-rank matrix framework in diﬀerent domains for the
cartoon-texture decomposition.",2022-08-09 11:55:49+00:00,Two Stage Continuous Domain Regularization for Piecewise Constant Image Restoration,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Jian-Feng Cai'), arxiv.Result.Author('Jae Kyu Choi'), arxiv.Result.Author('Chenchuan Zhou')]","The finite-rate-of-innovation (FRI) framework which corresponds a
signal/image to a structured low-rank matrix is emerging as an alternative to
the traditional sparse regularization. This is because such an off-the-grid
approach is able to alleviate the basis mismatch between the true support in
the continuous domain and the discrete grid. In this paper, we propose a
two-stage off-the-grid regularization model for the image restoration. Given
that the discontinuities/edges of the image lie in the zero level set of a
band-limited periodic function, we can derive that the Fourier samples of the
gradient of the image satisfy an annihilation relation, resulting in a low-rank
two-fold Hankel matrix. In addition, since the singular value decomposition of
a low-rank Hankel matrix corresponds to an adaptive tight frame system which
can represent the image with sparse canonical coefficients, our approach
consists of the following two stages. The first stage learns the tight wavelet
frame system from a given measurement, and the second stage restores the image
via the analysis approach based sparse regularization. The numerical results
are presented to demonstrate that the proposed approach is compared favorably
against several popular discrete regularization approaches and structured
low-rank matrix approaches.",-0.10124838,0.092890784,0.1843443,A
9874,"Finally, to further study the improvements over the conventional sparse
regularizations, we compare with the total variation (TV) model [58]

    min 1 Au − f 2 + γ · ∇u ,               2          1                         (54)
    u2

and the wavelet frame model (e.g.","2                0                      (53)
    v2

In (53), Z 0 is the Schatten 0-norm of a matrix Z deﬁned as

    Z 0 = ln det (Z∗ Z)1/2 + εI

with a small ε > 0.","[15])

         1  Au − f                       2+2   γ · Wu  1  .",2022-08-09 11:55:49+00:00,Two Stage Continuous Domain Regularization for Piecewise Constant Image Restoration,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Jian-Feng Cai'), arxiv.Result.Author('Jae Kyu Choi'), arxiv.Result.Author('Chenchuan Zhou')]","The finite-rate-of-innovation (FRI) framework which corresponds a
signal/image to a structured low-rank matrix is emerging as an alternative to
the traditional sparse regularization. This is because such an off-the-grid
approach is able to alleviate the basis mismatch between the true support in
the continuous domain and the discrete grid. In this paper, we propose a
two-stage off-the-grid regularization model for the image restoration. Given
that the discontinuities/edges of the image lie in the zero level set of a
band-limited periodic function, we can derive that the Fourier samples of the
gradient of the image satisfy an annihilation relation, resulting in a low-rank
two-fold Hankel matrix. In addition, since the singular value decomposition of
a low-rank Hankel matrix corresponds to an adaptive tight frame system which
can represent the image with sparse canonical coefficients, our approach
consists of the following two stages. The first stage learns the tight wavelet
frame system from a given measurement, and the second stage restores the image
via the analysis approach based sparse regularization. The numerical results
are presented to demonstrate that the proposed approach is compared favorably
against several popular discrete regularization approaches and structured
low-rank matrix approaches.",-0.013621003,-0.10905197,0.2466646,B
9953,"More accurate and easy to calculate estimates
need further research.","For some specific matrix functions, such as the matrix inversion and the matrix exponential, there
are some theoretical estimates about their localization and bandwidths, and these evaluations are
often too conservative and difficult to calculate.",Readers interested in this issue can read [4] which provided a good review.,2022-08-11 08:00:50+00:00,A filtering technique for the matrix power series being near-sparse,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Feng Wu'), arxiv.Result.Author('Li Zhu'), arxiv.Result.Author('Yuelin Zhao'), arxiv.Result.Author('Kailing Zhang')]","This work presents a new algorithm for matrix power series which is
near-sparse, that is, there are a large number of near-zero elements in it. The
proposed algorithm uses a filtering technique to improve the sparsity of the
matrices involved in the calculation process of the Paterson-Stockmeyer (PS)
scheme. Based on the error analysis considering the transaction error and the
error introduced by filtering, the proposed algorithm can obtain similar
accuracy as the original PS scheme but is more efficient than it. For the
near-sparse matrix power series, the proposed method is also more efficient
than the MATLAB built-in codes.",-0.17152077,-0.1282681,0.28020126,A
10060,This answered question warrants further research.,"One
such fundamental question is: Does the temperature always vary monotonically (either increasing
or decreasing) along the vasculature?",7.,2022-08-15 18:26:42+00:00,Modeling thermal regulation in thin vascular systems: A mathematical analysis,math.NA,"['math.NA', 'cs.NA', 'q-bio.TO']",[arxiv.Result.Author('Kalyana B. Nakshatrala')],"Mimicking vascular systems in living beings, designers have realized
microvascular composites to achieve thermal regulation and other
functionalities, such as electromagnetic modulation, sensing, and healing. Such
material systems with mentioned functionalities benefit various aerospace,
military, and civilian applications. Although heat transfer is a mature field,
control of thermal characteristics in synthetic microvascular systems is new,
and the fundamental comprehension is hazy. What will benefit designers are
predictive mathematical models and an in-depth qualitative understanding of
vasculature-based active cooling/heating. So, the central focus of this paper
is to address the remarked knowledge gap. First, we present a reduced-order
model with broad applicability, allowing the inlet temperature to differ from
the ambient temperature. Second, we use mathematical analysis tools for this
reduced-order model and reveal many heat transfer properties in
fluid-sequestered vasculature systems. We derive point-wise properties
(minimum, maximum, and comparison principles) and global properties (such as
bounds on performance metrics such as the mean surface temperature and cooling
efficiency). These newfound results deepen our understanding of active
cooling/heating and propel the perfecting of thermal regulation systems.",0.5483143,0.092129625,0.04394867,B
10061,This answered question warrants further research.,"One
such fundamental question is: Does the temperature always vary monotonically (either increasing
or decreasing) along the vasculature?",7.,2022-08-15 18:26:42+00:00,Modeling thermal regulation in thin vascular systems: A mathematical analysis,math.NA,"['math.NA', 'cs.NA', 'q-bio.TO']",[arxiv.Result.Author('Kalyana B. Nakshatrala')],"Mimicking vascular systems in living beings, designers have realized
microvascular composites to achieve thermal regulation and other
functionalities, such as electromagnetic modulation, sensing, and healing. Such
material systems avail circulating fluids through embedded vasculatures to
accomplish the mentioned functionalities that benefit various aerospace,
military, and civilian applications. Although heat transfer is a mature field,
control of thermal characteristics in synthetic microvascular systems via
circulating fluids is new, and a theoretical underpinning is lacking. What will
benefit designers are predictive mathematical models and an in-depth
qualitative understanding of vascular-based active cooling/heating. So, the
central focus of this paper is to address the remarked knowledge gap. First, we
present a reduced-order model with broad applicability, allowing the inlet
temperature to differ from the ambient temperature. Second, we apply
mathematical analysis tools to this reduced-order model and reveal many heat
transfer properties of fluid-sequestered vascular systems. We derive point-wise
properties (minimum, maximum, and comparison principles) and global properties
(e.g., bounds on performance metrics such as the mean surface temperature and
thermal efficiency). These newfound results deepen our understanding of active
cooling/heating and propel the perfecting of thermal regulation systems.",0.5483142,0.0921296,0.043948714,B
10090,"It is unclear to us where the problems with the iterative formulations of
the SOAR and TOAR are and requires further study.","This means the Arnoldi iterative formulation is better

than the iterative formulations of the SOAR and TOAR, and can generate the more accurate
orthonormal basis of Q1m.","In addition, due to our proposed three new

methods all use the Arnoldi iteration formulation, and then they can generate the more accurate
orthonormal basis of Q1m, Q2m and G˜2m−1.",2022-08-16 13:29:48+00:00,Three New Arnoldi-Type Methods for the Quadratic Eigenvalue Problem in Rotor Dynamics,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Dong Li'), arxiv.Result.Author('Li-fang Chen')]","Three new Arnoldi-type methods are presented to accelerate the modal analysis
and critical speed analysis of the damped rotor dynamics finite element (FE)
model. They are the linearized quadratic eigenvalue problem (QEP) Arnoldi
method, the QEP Arnoldi method, and the truncated generalized standard
eigenvalue problem (SEP) Arnoldi method. And, they correspond to three
reduction subspaces, including the linearized QEP Krylov subspace, the QEP
Krylov subspace, and the truncated generalized SEP Krylov subspace, where the
first subspace is also used in the existing Arnoldi-type methods. The numerical
examples constructed by a turbofan engine low-pressure (LP) rotor demonstrate
that our proposed three Arnoldi-type methods are more accurate than the
existing Arnoldi-type methods.",-0.2136591,-0.15829735,-0.09708761,A
10251,"Some
concluding remarks and the plans for further research are found in Section 5.",In Section 4 we comment on implementation of our procedure and present some numerical examples.,2.,2022-08-21 18:19:51+00:00,Efficient numerical method for reliable upper and lower bounds on homogenized parameters,math.NA,"['math.NA', 'cs.NA', '35B27, 65N15, 49N15, 65F10']","[arxiv.Result.Author('Liya Gaynutdinova'), arxiv.Result.Author('Martin Ladecký'), arxiv.Result.Author('Aleš Nekvinda'), arxiv.Result.Author('Ivana Pultarová'), arxiv.Result.Author('Jan Zeman')]","A numerical procedure providing guaranteed two-sided bounds on the effective
coefficients of elliptic partial differential operators is presented. The upper
bounds are obtained in a standard manner through the variational formulation of
the problem and by applying the finite element method. To obtain the lower
bounds we formulate the dual variational problem and introduce appropriate
approximation spaces employing the finite element method as well. We deal with
the 3D setting, which has been rarely considered in the literature so far. The
theoretical justification of the procedure is presented and supported with
illustrative examples.",-0.028470641,-0.17177494,-0.008366572,B_centroid
10438,"To further study the diﬀerences between these methods at predicting the cor-
rect geodesic curves, we decrease their time step size and compare their long term
trajectories and error in conserved quantities.","Moreover, Figure 6 illustrates the geodesic curves of the Implicit
Midpoint method predicts entirely wrong long term trajectory, while RK4 predicts
a nonphysical outcome of ending inside the black hole.","In Figure 7 and Figure 8 with τ = 1/3 × 2−3, we see that both the Implicit
Midpoint method and RK4 method does not preserve conserved quantities up to
machine precision, with RK4 still predicting nonphysical results.",2022-08-25 22:07:29+00:00,Minimal $\ell^2$ Norm Discrete Multiplier Method,math.NA,"['math.NA', 'cs.NA', 'math.DS', '65L05, 65L12, 65P10, 65Z05, 37M05, 37M15, 37N20']","[arxiv.Result.Author('Erick Schulz'), arxiv.Result.Author('Andy T. S. Wan')]","We introduce an extension to the Discrete Multiplier Method (DMM), called
Minimal $\ell_2$ Norm Discrete Multiplier Method (MN-DMM), where conservative
finite difference schemes for dynamical systems with multiple conserved
quantities are constructed procedurally, instead of analytically as in the
original DMM. For large dynamical systems with multiple conserved quantities,
MN-DMM alleviates difficulties that can arise with the original DMM at
constructing conservative schemes which satisfies the discrete multiplier
conditions. In particular, MN-DMM utilizes the right Moore-Penrose
pseudoinverse of the discrete multiplier matrix to solve an underdetermined
least-square problem associated with the discrete multiplier conditions. We
prove consistency and conservative properties of the MN-DMM schemes. We also
introduce two variants - Mixed MN-DMM and MN-DMM using Singular Value
Decomposition - and discuss their usage in practice. Moreover, numerical
examples on various problems arising from the mathematical sciences are shown
to demonstrate the wide applicability of MN-DMM and its relative ease of
implementation compared to the original DMM.",0.101393424,0.045638986,-0.05862721,C
10573,"[Fan17], further research is required for
hyperbolic systems in multiple spatial dimensions that is beyond the scope of the present
paper.","Despite promising eﬀorts towards approximate evolution operators
for the multi-dimensional Euler equations in e.g.","2.2 Limiting

Limiting is necessary for Active Flux because it is a high order method, and because it is
linear when applied to linear problems.",2022-08-30 18:03:57+00:00,Extensions of Active Flux to arbitrary order of accuracy,math.NA,"['math.NA', 'cs.NA', '65M06, 65M08, 65M60, 76N99']","[arxiv.Result.Author('Rémi Abgrall'), arxiv.Result.Author('Wasilij Barsukow')]","Active Flux is a recently developed numerical method for hyperbolic
conservation laws. Its classical degrees of freedom are cell averages and point
values at cell interfaces. These latter are shared between adjacent cells,
leading to a globally continuous reconstruction. The update of the point values
includes upwinding, but without solving a Riemann Problem. The update of the
cell average requires a flux quadrature at the cell interface, which can be
immediately performed using the point values. This paper explores different
extensions of Active Flux to arbitrarily high order of accuracy, while
maintaining the idea of global continuity. We propose to either increase the
stencil while keeping the same degrees of freedom, or to increase the number of
point values, or to include higher moments as new degrees of freedom. These
extensions have different properties, and reflect different views upon the
relation of Active Flux to the families of Finite Volume, Finite Difference and
Finite Element methods.",0.30865043,-0.077909574,-0.17161855,B
10581,There are still lots of works worthy of our further study.,"Especially for solving the differential Sylvester matrix equation, the
speedup ratio can reach tens to hundreds of times when the scale of the system is larger
than one hundred thousand.","For instance, the ﬁrst one
is to give the convergence rate analysis of ADI methods.",2022-08-31 01:39:32+00:00,Multitask kernel-learning parameter prediction method for solving time-dependent linear systems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Kai Jiang'), arxiv.Result.Author('Juan Zhang'), arxiv.Result.Author('Qi Zhou')]","Matrix splitting iteration methods play a vital role in solving large sparse
linear systems. Their performance heavily depends on the splitting parameters,
however, the approach of selecting optimal splitting parameters has not been
well developed. In this paper, we present a multitask kernel-learning parameter
prediction method to automatically obtain relatively optimal splitting
parameters, which contains simultaneous multiple parameters prediction and a
data-driven kernel learning. For solving time-dependent linear systems,
including linear differential systems and linear matrix systems, we give a new
matrix splitting Kronecker product method, as well as its convergence analysis
and preconditioning strategy. Numerical results illustrate our methods can save
an enormous amount of time in selecting the relatively optimal splitting
parameters compared with the exists methods. Moreover, our iteration method as
a preconditioner can effectively accelerate GMRES. As the dimension of systems
increases, all the advantages of our approaches becomes significantly.
Especially, for solving the differential Sylvester matrix equation, the speedup
ratio can reach tens to hundreds of times when the scale of the system is
larger than one hundred thousand.",-0.10243578,-0.083795115,-0.0609586,A
10793,These important issues motivate further research on the agent-based model for swarming.,A recent review on crowd models can be seen in [4].,"Inside
the swarm, agents with similar size and shape interact with each other, cooperate to accomplish a
given task and move to destinations by following the same rules.",2022-09-05 14:06:39+00:00,A new collision avoidance model with random batch resolution strategy,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Tianlu Chen'), arxiv.Result.Author('Chang Yang'), arxiv.Result.Author('Léon Matar Tine'), arxiv.Result.Author('Zhichang Guo')]","Research on crowd simulation has important and wide range of applications.
The main difficulty is how to lead all particles with a same and simple rule,
especially when particles are numerous. In this paper, we firstly propose a two
dimensional agent-based collision avoidance model, which is a $N$-particles
Newtonian system. The collision interaction force, imminent interaction force
and following interaction force are designed, so that particles can be guided
to their respective destinations while avoiding collisions. The proposed
agent-based model is then extended to the corresponding mean field limit model
as $N\to\infty$. Secondly, notice that direct simulation of the $N$-particles
Newtonian system is very time-consuming, since the complexity is equal to
$\mathcal{O}(N^2)$. In contrast, we propose an efficient hybrid resolution
strategy to reduce computational cost. It is a combination of the Random Batch
method (Shi Jin, Lei Li, and Jian-Guo Liu. Random batch methods (RBM) for
interacting particle systems. Journal of Computational Physics, 400:108877,
2020.) and the method based on local particles Newtonian system. Thanks to this
hybrid resolution strategy, the complexity is reduced to $\mathcal{O}(N)$.
Finally, various tests are presented to show robustness and efficiency of our
collision avoidance model and the hybrid resolution strategy.",0.2069712,0.56213224,0.055133946,C
10794,These important issues motivate further research on the agent-based model for swarming.,A recent review on crowd models can be seen in [4].,"Inside
the swarm, agents with similar size and shape interact with each other, cooperate to accomplish a
given task and move to destinations by following the same rules.",2022-09-05 14:06:39+00:00,A new collision avoidance model with random batch resolution strategy,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Tianlu Chen'), arxiv.Result.Author('Chang Yang'), arxiv.Result.Author('Léon Matar Tine'), arxiv.Result.Author('Zhichang Guo')]","Research on crowd simulation has important and wide range of applications.
The main difficulty is how to lead all particles with a same and simple rule,
especially when particles are numerous. In this paper, we firstly propose a two
dimensional agent-based collision avoidance model, which is a $N$-particles
Newtonian system. The collision interaction force, imminent interaction force
and following interaction force are designed, so that particles can be guided
to their respective destinations without collisions. The proposed agent-based
model is then extended to the corresponding mean field limit model as
$N\to\infty$. Secondly, notice that direct simulation of the $N$-particles
Newtonian system is very time-consuming, since the computational complexity is
of order $\mathcal{O}(N^2)$. In contrast, we propose an efficient hybrid
resolution strategy to reduce the computational complexity. It is a combination
of the Random Batch method (Shi Jin, Lei Li, and Jian-Guo Liu. Random batch
methods (RBM) for interacting particle systems. Journal of Computational
Physics, 400:108877, 2020.) and the method based on local particles Newtonian
system. Thanks to this hybrid resolution strategy, the computational complexity
is reduced to $\mathcal{O}(N)$. Finally, various tests are presented to show
robustness and efficiency of our collision avoidance model and the hybrid
resolution strategy.",0.2069712,0.56213224,0.055133946,C
10913,"Topics for further study include “implicit
deﬂation” versions of the LOBPCG and various Davidson methods as well as practical settings
of shifts and block sizes.","A more general analysis for eﬀectively positive deﬁnite preconditioners
is enabled by recent progress for the BPSD from [18].","References

 [1] J.H.",2022-09-07 18:18:10+00:00,Convergence analysis of a block preconditioned steepest descent eigensolver with implicit deflation,math.NA,"['math.NA', 'cs.NA', '65F15, 65N12, 65N25']","[arxiv.Result.Author('Ming Zhou'), arxiv.Result.Author('Zhaojun Bai'), arxiv.Result.Author('Yunfeng Cai'), arxiv.Result.Author('Klaus Neymeyr')]","Gradient-type iterative methods for solving Hermitian eigenvalue problems can
be accelerated by using preconditioning and deflation techniques. A
preconditioned steepest descent iteration with implicit deflation (PSD-id) is
one of such methods. The convergence behavior of the PSD-id is recently
investigated based on the pioneering work of Samokish on the preconditioned
steepest descent method (PSD). The resulting non-asymptotic estimates indicate
a superlinear convergence of the PSD-id under strong assumptions on the initial
guess. The present paper utilizes an alternative convergence analysis of the
PSD by Neymeyr under much weaker assumptions. We embed Neymeyr's approach into
the analysis of the PSD-id using a restricted formulation of the PSD-id. More
importantly, we extend the new convergence analysis of the PSD-id to a
practically preferred block version of the PSD-id, or BPSD-id, and show the
cluster robustness of the BPSD-id. Numerical examples are provided to validate
the theoretical estimates.",-0.038711175,-0.09537267,-0.13276288,A
11109,"For the Stokes equations, it has been studied the mixed DGFEM using Pk − Pk−1 element
(see [19, 35–38]) and Qk − Qk−1 element (see [39, 40, 43]), which laid a foundation for us to
further study the Stokes eigenvalue problem.","It can be seen that solving the Stokes eigenvalue problem by DGFEM has attracted
extensive attention of scholars .","Based on the above work, in this paper, we
study the residual type a posteriori error estimate of the mixed DGFEM using Pk − Pk−1
element (k = 1, 2, 3, · · · ) for velocity-pressure formulation of the Stokes eigenvalue problem
on shape-regular simplex meshes in Rd(d = 2, 3).",2022-09-13 03:51:48+00:00,A posteriori error estimates of mixed discontinuous Galerkin method for the Stokes eigenvalue problem,math.NA,"['math.NA', 'cs.NA', '65N25']","[arxiv.Result.Author('L. L. Sun'), arxiv.Result.Author('H. Bi'), arxiv.Result.Author('Y. D. Yang')]","In this paper, for the Stokes eigenvalue problem in $d$-dimensional case
$(d=2,3)$, we present an a posteriori error estimate of residual type of the
mixed discontinuous Galerkin finite element method using $P_{k}-P_{k-1}$
element $(k\geq 1)$. We give the a posteriori error estimators for approximate
eigenpairs, prove their reliability and efficiency for eigenfunctions, and also
analyze their reliability for eigenvalues. We implement adaptive calculation,
and the numerical results confirm our theoretical predictions and show that our
method can achieve the optimal convergence order $O(dof^{-2k/d})$.",0.1286051,-0.08311102,0.09021892,B
11192,"Finally,
Section 7 summarizes our findings and points to further research directions.","Sections 5–6 demonstrate performance results for the solution of a time-dependent
heat equation discretized by low- and high-order FEM with different stage-parallel solution
procedures and compares them to results of non-stage-parallel versions of the solvers.","1We define “optimal” as solver with high node-level performance whose number of iterations is independent
of the number of DoFs and of the number of processes.",2022-09-14 15:07:33+00:00,Stage-parallel fully implicit Runge-Kutta implementations with optimal multilevel preconditioners at the scaling limit,math.NA,"['math.NA', 'cs.NA', '65Y05, 65M55, 68W10']","[arxiv.Result.Author('Peter Munch'), arxiv.Result.Author('Ivo Dravins'), arxiv.Result.Author('Martin Kronbichler'), arxiv.Result.Author('Maya Neytcheva')]","We present an implementation of a fully stage-parallel preconditioner for
Radau IIA type fully implicit Runge--Kutta methods, which approximates the
inverse of $A_Q$ from the Butcher tableau by the lower triangular matrix
resulting from an LU decomposition and diagonalizes the system with as many
blocks as stages. For the transformed system, we employ a block preconditioner
where each block is distributed and solved by a subgroup of processes in
parallel. For combination of partial results, we either use a communication
pattern resembling Cannon's algorithm or shared memory. A performance model and
a large set of performance studies (including strong scaling runs with up to
150k processes on 3k compute nodes) conducted for a time-dependent heat
problem, using matrix-free finite element methods, indicate that the
stage-parallel implementation can reach higher throughputs when the block
solvers operate at lower parallel efficiencies, which occurs near the scaling
limit. Achievable speedup increases linearly with number of stages and are
bounded by the number of stages. Furthermore, we show that the presented
stage-parallel concepts are also applicable to the case that $A_Q$ is directly
diagonalized, which requires complex arithmetic or the solution of two-by-two
blocks and sequentializes parts of the algorithm. Alternatively to distributing
stages and assigning them to distinct processes, we discuss the possibility of
batching operations from different stages together.",-0.0041728783,0.060300842,-0.3680577,C
11248,"Finally, in Section 3.7 we collect
points of departure for further research.","Afterwards in Sections 3.4, 3.5 and
3.6 we explain the methods behind the proofs, essentially covering topics ranging from
asymptotic geometric analysis to sparse approximation.","3.1 Introduction and motivation

Consider the m-dimensional approximation problem from Section 2.2, where linear infor-
mation is used to recover vectors in the m2 -norm from the unit ball of an m-dimensional
normed space, which is a symmetric convex body K. Motivated by Question 2.2, we study
the radius of Gaussian information which is equivalent to the radius of the intersection
of K with a random subspace of codimension n. We will be interested in the case of m
being much larger than n, say at least m > 2n.",2022-09-15 13:01:08+00:00,The power of random information for numerical approximation and integration,math.NA,"['math.NA', 'cs.NA', 'math.PR', '11K38, 41A25, 41A63, 52A23, 52A39, 60G15, 62C05, 65D15, 65D30, 65Y20']",[arxiv.Result.Author('Mathias Sonnleitner')],"This thesis investigates the quality of randomly collected data by employing
a framework built on information-based complexity, a field related to the
numerical analysis of abstract problems. The quality or power of gathered
information is measured by its radius which is the uniform error obtainable by
the best possible algorithm using it. The main aim is to present progress
towards understanding the power of random information for approximation and
integration problems.",0.022886045,-0.16726306,0.50534844,B
11311,"Therefore, the limiting process in (1.6) is meaningless;

   (iii) for τ = τ∗, the existence of a limit function ητ∗ in (1.6) is not clear and needs further study.","Therefore, all the
         information in {vn}∞ n=1 is lost and the limiting process in (1.6) is degenerate and trivial;

    (ii) for all τ > τ∗, the limit in (1.6) is divergent and there does not exist a continuous function ητ
         satisfying (1.6).","The above simple observation shows that for the convergence of {vn}∞ n=1 to a nontrivial continuous
function in (1.6), the original data sequence {vn}∞ n=1 should be properly rescaled by a unique scaling
exponent τ∗, which is uniquely determined by the data {vn}∞ n=1.",2022-09-16 19:08:00+00:00,Vector Subdivision Schemes for Arbitrary Matrix Masks,math.NA,"['math.NA', 'cs.NA', '65T60, 42C40, 65D17']",[arxiv.Result.Author('Bin Han')],"Employing a matrix mask, a vector subdivision scheme is a fast iterative
averaging algorithm to compute refinable vector functions for wavelet methods
in numerical PDEs and to produce smooth curves in CAGD. In sharp contrast to
the well-studied scalar subdivision schemes, vector subdivision schemes are
much less well understood, e.g., Lagrange and (generalized) Hermite subdivision
schemes are the only studied vector subdivision schemes in the literature.
Because many wavelets used in numerical PDEs are derived from refinable vector
functions whose matrix masks are not from Hermite subdivision schemes, it is
necessary to introduce and study vector subdivision schemes for any general
matrix masks in order to compute wavelets and refinable vector functions
efficiently. For a general matrix mask, we show that there is only one
meaningful way of defining a vector subdivision scheme. Motivated by vector
cascade algorithms and recent study on Hermite subdivision schemes, we shall
define a vector subdivision scheme for any arbitrary matrix mask and then we
prove that the convergence of the newly defined vector subdivision scheme is
equivalent to the convergence of its associated vector cascade algorithm. We
also study convergence rates of vector subdivision schemes. The results of this
paper not only bridge the gaps and establish intrinsic links between vector
subdivision schemes and vector cascade algorithms but also strengthen and
generalize current known results on Lagrange and (generalized) Hermite
subdivision schemes. Several examples are provided to illustrate the results in
this paper on various types of vector subdivision schemes with convergence
rates.",0.33644938,-0.21693972,0.13933666,B
11332,"On this basis, we can further study
the convergence of one-point LDRFs of full discretizations for SPDEs.",This paper deals with the case of spatial semi-discretizations for SPDEs.,"On one hand, it is possible to use our
technical route to show that one-point LDRFs of full discretizations converge to those of the corresponding
spatial semi-discretizations.",2022-09-17 14:43:42+00:00,Convergence analysis of one-point large deviations rate functions of numerical discretizations for stochastic wave equations with small noise,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Diancong Jin'), arxiv.Result.Author('Jialin Hong'), arxiv.Result.Author('Derui Sheng')]","In this work, we present the convergence analysis of one-point large
deviations rate functions (LDRFs) of the spatial finite difference method (FDM)
for stochastic wave equations with small noise, which is essentially about the
asymptotical limit of minimization problems and not a trivial task for the
nonlinear cases. In order to overcome the difficulty that objective functions
for the original equation and the spatial FDM have different effective domains,
we propose a new technical route for analyzing the pointwise convergence of the
one-point LDRFs of the spatial FDM, based on the $\Gamma$-convergence of
objective functions. Based on the new technical route, the intractable
convergence analysis of one-point LDRFs boils down to the qualitative analysis
of skeleton equations of the original equation and its numerical
discretizations.",0.08339134,-0.18653429,0.09118836,B
11366,"Finally, in Section 6, we draw some
conclusions, and give some outlook on further research work.","The ﬁrst part of Section 5 is devoted to numerical
studies of the error u h − u L2(Ω) for benchmark problems with discontinuous tar-
gets u, whereas the second part provides numerical studies of the proposed iterative
solvers in the three-dimensional case n = 3.","2 Distributed optimal control problems with
     variable energy regularization

To give a motivation for the optimization problem to be solved, let us consider an

alternative representation of the energy norm, still using a constant regularization

parameter :  z 2H−1(Ω) = √ z 2H−1(Ω) = √ z , w Ω,

where w ∈ H01(Ω) is the weak solution of the Dirichlet boundary value problem

                          √                                     (2.1)
             − ∆w = z in Ω, w = 0 on ∂Ω.",2022-09-19 07:51:11+00:00,An adaptive finite element method for distributed elliptic optimal control problems with variable energy regularization,math.NA,"['math.NA', 'cs.NA', 'math.OC', '49J20, 49M05, 35J05, 65M60, 65M15, 65N22']","[arxiv.Result.Author('Ulrich Langer'), arxiv.Result.Author('Richard Löscher'), arxiv.Result.Author('Olaf Steinbach'), arxiv.Result.Author('Huidong Yang')]","We analyze the finite element discretization of distributed elliptic optimal
control problems with variable energy regularization, where the usual
$L^2(\Omega)$ norm regularization term with a constant regularization parameter
$\varrho$ is replaced by a suitable representation of the energy norm in
$H^{-1}(\Omega)$ involving a variable, mesh-dependent regularization parameter
$\varrho(x)$. It turns out that the error between the computed finite element
state $\widetilde{u}_{\varrho h}$ and the desired state $\bar{u}$ (target) is
optimal in the $L^2(\Omega)$ norm provided that $\varrho(x)$ behaves like the
local mesh size squared. This is especially important when adaptive meshes are
used in order to approximate discontinuous target functions. The adaptive
scheme can be driven by the computable and localizable error norm $\|
\widetilde{u}_{\varrho h} - \bar{u}\|_{L^2(\Omega)}$ between the finite element
state $\widetilde{u}_{\varrho h}$ and the target $\bar{u}$. The numerical
results not only illustrate our theoretical findings, but also show that the
iterative solvers for the discretized reduced optimality system are very
efficient and robust.",0.12768511,-0.16094476,-0.08937955,B
11387,"The application of DNNI on Galerkin methods for both temporal and spatial domains
and using higher order polynomial basis functions is also an area of further research.","DNNI
can also be applied to full-scale engineering problems where repeated or non-elementary integrals are required for
obtaining substantial speedup.","DNNI can also be applied to
compute the closed-form expressions of non-elementary integrals appearing in various areas of science.",2022-09-19 15:16:47+00:00,Computing Anti-Derivatives using Deep Neural Networks,math.NA,"['math.NA', 'cs.LG', 'cs.NA']","[arxiv.Result.Author('D. Chakraborty'), arxiv.Result.Author('S. Gopalakrishnan')]","This paper presents a novel algorithm to obtain the closed-form
anti-derivative of a function using Deep Neural Network architecture. In the
past, mathematicians have developed several numerical techniques to approximate
the values of definite integrals, but primitives or indefinite integrals are
often non-elementary. Anti-derivatives are necessarily required when there are
several parameters in an integrand and the integral obtained is a function of
those parameters. There is no theoretical method that can do this for any given
function. Some existing ways to get around this are primarily based on either
curve fitting or infinite series approximation of the integrand, which is then
integrated theoretically. Curve fitting approximations are inaccurate for
highly non-linear functions and require a different approach for every problem.
On the other hand, the infinite series approach does not give a closed-form
solution, and their truncated forms are often inaccurate. We claim that using a
single method for all integrals, our algorithm can approximate anti-derivatives
to any required accuracy. We have used this algorithm to obtain the
anti-derivatives of several functions, including non-elementary and oscillatory
integrals. This paper also shows the applications of our method to get the
closed-form expressions of elliptic integrals, Fermi-Dirac integrals, and
cumulative distribution functions and decrease the computation time of the
Galerkin method for differential equations.",0.0734512,0.031293225,-0.22732094,C
11420,"We cannot explain yet why this takes place, and this should

be a subject of our further research.","On

                                     2,h
                                  HN (Ωh)

the other hand, we see in our numerical experiments that our method does not perform well

without the regularization term.","We note that since the regularization term represents a
strictly convex functional Yβ : HN2,h Ωh → R,

                           Yβ W h = β W h 2H2,h(Ωh) ,
                                                                                 N

then an obvious analog of Theorem 3.1 implies that the functional Jλ,β W h : K2h (R) → R is

strictly convex on the set K2h (R), where K2h (R) is obtained from the set Kh (R) in (2.44) via
replacing in (2.44) HN1,h Ωh with HN2,h Ωh .",2022-09-20 02:31:56+00:00,Numerical Solution of the 3-D Travel Time Tomography Problem,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Michael V. Klibanova Jingzhi Li'), arxiv.Result.Author('Wenlong Zhang')]","The first numerical solution of the 3-D travel time tomography problem is
presented. The globally convergent convexification numerical method is applied.",0.16876054,-0.30178648,0.06846641,B
11421,"The numerical results also imply that there may exists more precise criteria,
which needs further research in the future.","This characterize an exact relation between the
spectral radius and the maximum eigenvalue of the saddle point matrices.","Acknowledgements

   This work was supported by the State Key Laboratory of Synthetical
Automation for Process Industries Fundamental Research Funds, China,
no.",2022-09-20 03:09:49+00:00,Quasi-Perron-Frobenius property of a class of saddle point matrices,math.NA,"['math.NA', 'cs.NA', '65F15, 65F10']","[arxiv.Result.Author('Zheng Li'), arxiv.Result.Author('Tie Zhang'), arxiv.Result.Author('Chang-Jun Li')]","The saddle point matrices arising from many scientific computing fields have
block structure $ W= \left(\begin{array}{cc} A & B\\ B^T & C \end{array}
\right) $, where the sub-block $A$ is symmetric and positive definite, and $C$
is symmetric and semi-nonnegative definite. In this article we report a
unobtrusive but potentially theoretically valuable conclusion that under some
conditions, especially when $C$ is a zero matrix, the spectral radius of $W$
must be the maximum eigenvalue of $W$. This characterization approximates to
the famous Perron-Frobenius property, and is called quasi-Perron-Frobenius
property in this paper. In numerical tests we observe the saddle point matrices
derived from some mixed finite element methods for computing the stationary
Stokes equation. The numerical results confirm the theoretical analysis, and
also indicate that the assumed condition to make the saddle point matrices
possess quasi-Perron-Frobenius property is only sufficient rather than
necessary.",-0.01052645,-0.16549337,0.09416044,B
11470,"Here we ﬁrst look at the basic ZNN method for a time-varying matrix square root problem and recreate [8, Figure
1] for further study.","Use Matlab’s sqrtm.m ﬁle for computing X.

Computing time-varying matrix square root ﬂows X(t) for time-varying matrix ﬂows A(t) requires more effort.","In Figure 1 below, the two graphs show the error function value at the start-up to full j s =
4 5 switching point displayed by a red square and the 1000th iterate’s error function value displayed by a blue
circle around a star ∗j; on the left hand side with η = 1.35 as in [8, Figure 1], and on the right side with η = 2.6
but for the higher truncation order ﬁnite difference formula of type j s = 4 5.",2022-09-20 21:12:28+00:00,Adapted AZNN Methods for Time-Varying and Static Matrix Problems,math.NA,"['math.NA', 'cs.NA', '15A99, 15B99, 65F99, 65F45, 15A21']",[arxiv.Result.Author('Frank Uhlig')],"We present adapted Zhang Neural Networks (AZNN) in which the parameter
settings for the exponential decay constant $\eta$ and the length of the
start-up phase of basic ZNN are adapted to the problem at hand. Specifically we
study experiments with AZNN for time-varying square matrix factorizations as a
product of time-varying symmetric matrices and for the time-varying matrix
square roots problem. Differing from generally used small $\eta$ values and
minimal start-up length phases in ZNN, we adapt the basic ZNN method to work
with large or even gigantic $\eta$ settings and arbitrary length start-ups
using Euler's low accuracy finite difference formula. These adaptations improve
the speed of AZNN's convergence and lower its solution error bounds for our
chosen problems significantly to near machine constant or even lower levels.
  Parameter-varying AZNN also allows us to find full rank symmetrizers of
static matrices reliably, for example for the Kahan and Frank matrices and for
matrices with highly ill-conditioned eigenvalues and complicated Jordan
structures of dimensions from $n = 2$ on up. This helps in cases where full
rank static matrix symmetrizers have never been successfully computed before.",-0.22819278,-0.19813848,-0.06818641,A
11588,"We further study the property of
                                                energy conservation for the fully-discrete system.","We carry out the stability and convergence analysis in the energy norm for the semi-discrete problem
                                                showing optimal rate of convergence with respect to the mesh size.","Finally, we present some veriﬁcation tests as well as
                                                engineering application of the method.",2022-09-23 14:17:36+00:00,Mixed Virtual Element approximation of linear acoustic wave equation,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Franco Dassi'), arxiv.Result.Author('Alessio Fumagalli'), arxiv.Result.Author('Ilario Mazzieri'), arxiv.Result.Author('Giuseppe Vacca')]","We design a Mixed Virtual Element Method for the approximated solution to the
first-order form of the acoustic wave equation. In absence of external load,
the semi-discrete method exactly conserves the system energy. To integrate in
time the semi-discrete problem we consider a classical theta-method scheme. We
carry out the stability and convergence analysis in the energy norm for the
semi-discrete problem showing optimal rate of convergence with respect to the
mesh size. We further study the property of energy conservation for the
fully-discrete system. Finally, we present some verification tests as well as
engineering application of the method.",0.24824703,-0.10555128,0.00018007468,B
11815,"Besides being more general than the original formulation of Forsythe, we hope
that our translation of the theory in the context of the conjecture into more mod-
ern notation based on projection processes is more transparent, and therefore will
motivate further research beyond this paper.","Another new result in
this paper is the proof of the limiting behavior of the Arnoldi cross iteration for s = 1
and orthogonal matrices with eigenvalues having only positive (or only negative) real
parts.",The paper is organized as follows.,2022-09-29 06:43:31+00:00,On the Forsythe conjecture,math.NA,"['math.NA', 'cs.NA', '65F10']","[arxiv.Result.Author('Vance Faber'), arxiv.Result.Author('Jörg Liesen'), arxiv.Result.Author('Petr Tichý')]","Forsythe formulated a conjecture about the asymptotic behavior of the
restarted conjugate gradient method in 1968. We translate several of his
results into modern terms, and generalize the conjecture (originally formulated
only for symmetric positive definite matrices) to symmetric and nonsymmetric
matrices. Our generalization is based on a two-sided or cross iteration with
the given matrix and its transpose, which is based on the projection process
used in the Arnoldi (or for symmetric matrices the Lanczos) algorithm. We prove
several new results about the limiting behavior of this iteration, but the
conjecture still remains largely open.",-0.026131194,-0.3178142,0.13655129,B
11816,"Working out the exact relations between the iterations studied in the con-
text of the Forsythe conjecture and the Rayleigh quotient based iterations remains a
subject of further research.","The mono-
tonic residual norms ultimately yield the global convergence of these iterations; see,
e.g., [15].","Also, the Forsythe conjecture and its generalization to the ACI(s) still remain
largely open.",2022-09-29 06:43:31+00:00,On the Forsythe conjecture,math.NA,"['math.NA', 'cs.NA', '65F10']","[arxiv.Result.Author('Vance Faber'), arxiv.Result.Author('Jörg Liesen'), arxiv.Result.Author('Petr Tichý')]","Forsythe formulated a conjecture about the asymptotic behavior of the
restarted conjugate gradient method in 1968. We translate several of his
results into modern terms, and generalize the conjecture (originally formulated
only for symmetric positive definite matrices) to symmetric and nonsymmetric
matrices. Our generalization is based on a two-sided or cross iteration with
the given matrix and its transpose, which is based on the projection process
used in the Arnoldi (or for symmetric matrices the Lanczos) algorithm. We prove
several new results about the limiting behavior of this iteration, but the
conjecture still remains largely open.",0.05770596,-0.25421783,0.039619826,B
11955,"Conclusions and further research

    As we have known, exponential integrators are very promising for solving semi-linear sys-
tems whose linear part generates the dominant stiﬀness or high oscillation of the underlying
                                                             B. Wang, X. Hu and X. Wu                                                                                                                                                       20

          The accuracy of first order methods                         The accuracy of second order methods                                                                                   The accuracy of third order methods
-0.5                                                           -1                                                                                                                    -1

            EEuler                                                        ERK2                                                                                                                 ERK3
            MVERK1                                                        MVERK2-1
            slope 1                                                       MVERK2-2                                                                                                   -2      MVERK3-1
 -1                                                            -2 SVERK2-1
                                                                          SVERK2-2                                                                                                           MVERK3-2
-1.5                                                                      slope 2
                                                                                                                                                                                     -3      SVERK3-1
                                                               -3
                                                                                                                                                                                             SVERK3-2

log10(GE)                                                                                                                                                                                      slope 3
                                                                                     log10(GE)                                                                                       -4
                                                                                                                                                                          log10(GE)
                                                                                                                                                                                     -5

-2                                                           -4                                                                                                                      -6

                                                                                                                                                                                     -7

-2.5                                                         -5                                                                                                                      -8

      -2  -1.5      -1                         -0.5                -2             -1.5        -1             -0.5                                                                        -2             -1.5            -1                  -0.5

          log10(h)                                                                log10(h)                                                                                                                    log10(h)

          (a)                                                                     (b)                                                                                                                         (c)

          Figure 5: Results for accuracy of Problem 3: The log-log plots of global errors against h.

         The efficiency of first order methods                       The efficiency of second order methods                                                                                  The efficiency of third order methods
-0.5 EEuler                                                  -1.5                                                                                                                    -3

                                                     MVERK1                                                                                                                                                                           ERK3
 -1
                                                             -2                                                                                                                                                                   MVERK3-1
-1.5
                                                                                                                                                                                     -4                                           MVERK3-2
 -2
                                                             -2.5                                                                                                                                                                 SVERK3-1
-2.5
      -2 -1.8 -1.6 -1.4 -1.2 -1                                                                                                                                                                                                   SVERK3-2
                   log10(CPU time)

                  (a)
log10(GE)                                                    -3                                                                                                                      -5
                                                                                    log10(GE)
                                                                                                                                                                          log10(GE)-3.5-6

                                                             -4 ERK2
                                                                      MVERK2-1

                                                                        MVERK2-2                                                                                                     -7
                                                             -4.5 SVERK2-1

                                                                      SVERK2-2                                                                                                       -8
                                                             -5

                                                             -2.5      -2               -1.5       -1        -0.5                                                                    -2      -1.5             -1            -0.5            0

                                                                                  log10(CPU time)                                                                                                       log10(CPU time)

                                                                                    (b)                                                                                                                    (c)

      Figure 6: Results for eﬃciency of Problem 3: The log-log plots of global errors against the CPU time.",7.,problem.,2022-10-03 02:28:01+00:00,Two new classes of exponential Runge-Kutta integrators for efficiently solving stiff systems or highly oscillatory problems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Bin Wang'), arxiv.Result.Author('Xianfa Hu'), arxiv.Result.Author('Xinyuan Wu')]","We study two new classes of exponential Runge-Kutta (ERK) integrators for
efficiently solving stiff systems or highly oscillatory problems. We first
present a novel class of explicit modified version of exponential Runge-Kutta
(MVERK) methods based on the order conditions. Furthermore, we consider a class
of explicit simplified version of exponential Runge-Kutta (SVERK) methods.
Numerical results demonstrate the high efficiency of the explicit MVERK
integrators and SVERK methods derived in this paper compared with the
well-known explicit ERK integrators for stiff systems or highly oscillatory
problems in the literature.",-0.107494995,-0.07556112,-0.28406543,C
12052,"Second, we further study the stabilization methods’ eﬀects on the qualitative ﬁeld devel-
opment via a scenario in which a strong horizontal ﬂow vortex twists vertically aligned magnetic
ﬁeld lines.","In particular, we will use this test case to demonstrate the conservation properties and convergence
rates, and to examine the qualitative ﬁeld development depending on the choice of stabilization
method.","The meshes, ﬁnite element discretization, and solver were implemented using the automated ﬁ-
nite element toolkit Firedrake [35], which relies heavily on PETSc [4].",2022-10-05 15:51:31+00:00,Structure preserving transport stabilized compatible finite element methods for magnetohydrodynamics,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Golo A. Wimmer'), arxiv.Result.Author('Xianzhu Tang')]","We present compatible finite element space discretizations for the ideal
compressible magnetohydrodynamic equations. The magnetic field is considered
both in div- and curl-conforming spaces, leading to a strongly or weakly
preserved zero-divergence condition, respectively. The equations are
discretized in space such that transfers between the kinetic, internal, and
magnetic energies are consistent, leading to a preserved total energy. We also
discuss further adjustments to the discretization required to additionally
achieve magnetic helicity preservation. Finally, we describe new transport
stabilization methods for the magnetic field equation which maintain the
zero-divergence and energy conservation properties, including one method which
also preserves magnetic helicity. The methods' preservation and improved
stability properties are confirmed numerically using a steady state and a
magnetic dynamo test case.",0.13047889,0.14889592,-0.16633806,C
12172,"This is an interesting topic in regularization problems,
for further study, we may consider the method in [11, 12, 17, 18, 19].","How to
choose a proper regularization parameter λ?","References

 [1] An, C., and Wu, H.-N. Tikhonov regularization for polynomial approximation problems in
      Gauss quadrature points.",2022-10-09 09:12:05+00:00,Lasso trigonometric polynomial approximation for periodic function recovery in equidistant points,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Congpei An'), arxiv.Result.Author('Mou Cai')]","In this paper, we propose a fully discrete soft thresholding trigonometric
polynomial approximation on $[-\pi,\pi],$ named Lasso trigonometric
interpolation. This approximation is an $\ell_1$-regularized discrete least
squares approximation under the same conditions of classical trigonometric
interpolation on an equidistant grid. Lasso trigonometric interpolation is
sparse and meanwhile it is an efficient tool to deal with noisy data. We
theoretically analyze Lasso trigonometric interpolation for continuous periodic
function. The principal results show that the $L_2$ error bound of Lasso
trigonometric interpolation is less than that of classical trigonometric
interpolation, which improved the robustness of trigonometric interpolation.
This paper also presents numerical results on Lasso trigonometric interpolation
on $[-\pi,\pi]$, with or without the presence of data errors.",-0.14092171,-0.23097017,0.20862088,B
12173,"This is an interesting topic in regularization problems,
for further study, we may consider the method in [11, 12, 17, 18, 19].","How to
choose a proper regularization parameter λ?","References

 [1] An, C., and Wu, H.-N. Tikhonov regularization for polynomial approximation problems in
      Gauss quadrature points.",2022-10-09 09:12:05+00:00,Lasso trigonometric polynomial approximation for periodic function recovery in equidistant points,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Congpei An'), arxiv.Result.Author('Mou Cai')]","In this paper, we propose a fully discrete soft thresholding trigonometric
polynomial approximation on $[-\pi,\pi],$ named Lasso trigonometric
interpolation. This approximation is an $\ell_1$-regularized discrete least
squares approximation under the same conditions of classical trigonometric
interpolation on an equidistant grid. Lasso trigonometric interpolation is
sparse and meanwhile it is an efficient tool to deal with noisy data. We
theoretically analyze Lasso trigonometric interpolation for continuous periodic
function. The principal results show that the $L_2$ error bound of Lasso
trigonometric interpolation is less than that of classical trigonometric
interpolation, which improved the robustness of trigonometric interpolation.
This paper also presents numerical results on Lasso trigonometric interpolation
on $[-\pi,\pi]$, with or without the presence of data errors.",-0.14092171,-0.23097017,0.20862088,B
12286,"The parameter ρ is therefore a design parameter,
and further research is required on how to choose it optimally for speciﬁc problem
classes.","On the other hand, setting ρ = 0 means that we always choose
all the sub-domains and thereby do more computations than if we would simply
solve the full problem directly.","Regardless of the choice, however, we still have O(h1/2)-convergence.",2022-10-11 11:58:44+00:00,A randomized operator splitting scheme inspired by stochastic optimization methods,math.NA,"['math.NA', 'cs.NA', '65M12 (Primary) 65C99, 90C15, 65M55 (Secondary)']","[arxiv.Result.Author('Monika Eisenmann'), arxiv.Result.Author('Tony Stillfjord')]","In this paper, we combine the operator splitting methodology for abstract
evolution equations with that of stochastic methods for large-scale
optimization problems. The combination results in a randomized splitting
scheme, which in a given time step does not necessarily use all the parts of
the split operator. This is in contrast to deterministic splitting schemes
which always use every part at least once, and often several times. As a
result, the computational cost can be significantly decreased in comparison to
such methods. We rigorously define a randomized operator splitting scheme in an
abstract setting and provide an error analysis where we prove that the temporal
convergence order of the scheme is at least 1/2. We illustrate the theory by
numerical experiments on both linear and quasilinear diffusion problems, using
a randomized domain decomposition approach. We conclude that choosing the
randomization in certain ways may improve the order to 1. This is as accurate
as applying e.g. backward (implicit) Euler to the full problem, without
splitting.",0.17023411,-0.07177847,0.0067980736,B
12370,"The only exception are the maximal regularity results in Theorem 2 which, to
our knowledge, do not exist for discrete approximations of the p-Laplacian and
motivates further research.","A review of the proofs in Section 3–5 shows that most results remain valid
without any changes in the proofs if we replace Wq(div= f, Ω) by P0(divh= f, T ).",10                  A. KH.,2022-10-12 17:00:00+00:00,Relaxed Kacanov scheme for the p-Laplacian with large p,math.NA,"['math.NA', 'cs.NA', '35J70, 65N22, 65N30']","[arxiv.Result.Author('Anna Kh. Balci'), arxiv.Result.Author('Lars Diening'), arxiv.Result.Author('Johannes Storn')]","We introduce a globally convergent relaxed Kacanov scheme for the computation
of the discrete minimizer to the $p$-Laplace problem with $2 \leq p < \infty$.
The iterative scheme is easy to implement since each iterate results only from
the solve of a weighted, linear Poisson problem. It neither requires an
additional line search nor involves unknown constants for the step length. The
rate of convergence is independent of the underlying mesh.",0.39927232,-0.2574377,0.1271899,B
12380,"Undoubtedly, the influence of the proposed convergence factors on the approximate properties of trigo-

     nometric splines requires further research.",11.,"List of references

    1.",2022-10-12 18:04:13+00:00,About some generalizations trigonometric splines,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('V. Denysiuk')],"Methods of constructing trigonometric fundamental splines with constant sign
and sign-changing convergence factors are given. An example and graphics
illustrating the concepts of convergence and interpolation grids are given.
Some methods of constructing constant-sign and sign-changing coefficients of
convergence of trigonometric splines are considered.",0.14685927,-0.00997964,0.023423053,B
12410,"Similar to two-body problems, to further study

the performance of softFEM and softIGA, Figure 4.11 presents the eigenvalue errors with meshes of 30 to
80 non-uniform elements.","The eigenstate solution shapes match well with the ones obtained using

the BO approximation in Figure 4 of [12] and Figure 7 in [7].","The eigenvalue errors of softFEM reach 10−3.8 while the errors of softIGA are
around 10−9.",2022-10-13 08:28:59+00:00,Soft isogeometric analysis of the Bound States of a Quantum Three-Body Problem in 1D,math.NA,"['math.NA', 'cs.NA', 'physics.comp-ph']","[arxiv.Result.Author('Danyang Li'), arxiv.Result.Author('Quanling Deng')]","The study of quantum three-body problems has been centered on low-energy
states that rely on accurate numerical approximation. Recently, isogeometric
analysis (IGA) has been adopted to solve the problem as an alternative but more
robust (with respect to atom mass ratios) method that outperforms the classical
Born-Oppenheimer (BO) approximation. In this paper, we focus on the performance
of IGA and apply the recently-developed softIGA to reduce the spectral errors
of the low-energy bound states. The main idea is to add high-order
derivative-jump terms with a penalty parameter to the IGA bilinear forms. With
an optimal choice of the penalty parameter, we observe eigenvalue error
superconvergence. We focus on linear (finite elements) and quadratic elements
and demonstrate the outperformance of softIGA over IGA through a variety of
examples including both two- and three-body problems in 1D.",-0.10905541,-0.016010443,0.055216167,A
12424,"Instead, further research is simply limited to suﬃciently large domains so

that this observation does not represent an issue.","While we could have forced at least one node in the neighbourhood of the source, we do

not use any special techniques in this work.","Moreover, the behaviour of the IMEX error indicator is studied on the right side of Figure 7.",2022-10-13 15:00:02+00:00,Strong form mesh-free $hp$-adaptive solution of linear elasticity problem,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Mitja Jančič'), arxiv.Result.Author('Gregor Kosec')]","We present an algorithm for $hp$-adaptive collocation-based mesh-free
numerical analysis of partial differential equations. Our solution procedure
follows a well-established iterative solve-estimate-mark-refine paradigm. The
solve phase relies on the Radial Basis Function-generated Finite Differences
(RBF-FD) using point clouds generated by advancing front node positioning
algorithm that supports variable node density. In the estimate phase, we
introduce an Implicit-Explicit (IMEX) error indicator, which assumes that the
error relates to the difference between the implicitly obtained solution (from
the solve phase) and a local explicit re-evaluation of the PDE at hand using a
higher order approximation. Based on the IMEX error indicator, the modified
Texas Three Step marking strategy is used to mark the computational nodes for
$h$-, $p$- or $hp$-(de-)refinement. Finally, in the refine phase, nodes are
repositioned and the order of the method is locally redefined using the
variable order of the augmenting monomials according to the instructions from
the mark phase.
  The performance of the introduced $hp$-adaptive method is first investigated
on a two-dimensional Peak problem and further applied to two- and
three-dimensional contact problems. We show that the proposed IMEX error
indicator adequately captures the global behaviour of the error in all cases
considered and that the proposed $hp$-adaptive solution procedure significantly
outperforms the non-adaptive approach. The proposed $hp$-adaptive method stands
for another important step towards a fully autonomous numerical method capable
of solving complex problems in realistic geometries without the user
intervention.",0.020431371,0.088727124,0.29517156,A
12452,"Only the primal-dual FE versions of the KE wedge product (straightforward) and the Gij
Hodge star on arbitrary grids (tricky) would require further research.","Most of these options have already been developed, just not studied in the context of TRiSK-type
schemes.","These alternative choices do not
expand the stencil of the general scheme beyond nearest-neighbor (although the Hodge star is no longer
diagonal) and keep the topological properties of the scheme.",2022-10-14 02:54:51+00:00,An interpretation of TRiSK-type schemes from a discrete exterior calculus perspective,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Christopher Eldred'), arxiv.Result.Author('Werner Bauer')]","TRiSK-type numerical schemes are widely used in both atmospheric and oceanic
dynamical cores, due to their discrete analogues of important properties such
as energy conservation and steady geostrophic modes. In this work, we show that
these numerical methods are best understood as a discrete exterior calculus
(DEC) scheme applied to a Hamiltonian formulation of the rotating shallow water
equations based on split exterior calculus. This comprehensive description of
the differential geometric underpinnings of TRiSK-type schemes completes the
one started in \cite{Thuburn2012,Eldred2017}, and provides a new understanding
of certain operators in TRiSK-type schemes as discrete wedge products and
topological pairings from split exterior calculus. All known TRiSK-type schemes
in the literature are shown to fit inside this general framework, by
identifying the (implicit) choices made for various DEC operators by the
different schemes. In doing so, unexplored choices and combinations are
identified that might offer the possibility of fixing known issues with
TRiSK-type schemes such as operator accuracy and Hollingsworth instability.",0.03155607,0.15206514,0.06603989,A
12474,"As future work, a few interesting topics deserve further study: (a) curvature continuity analysis of PN C2 subdivi-
sion surfaces with arbitrary topology control meshes; (b) computation of convex hulls or limit points of PN subdivision

                                                                     28
curves and surfaces; (c) exploring surface subdivision schemes that preserve other geometric primitives such as toruses
or cyclides.","Particularly, PN subdivision schemes can be simple solutions to modeling fair C2
subdivision surfaces with arbitrary topology control meshes by adapting linear C2 subdivision schemes that only
generate subdivision surfaces with ﬂat extraordinary points.","Acknowledgment

    This work was supported by the National Natural Science Foundation of China under Grant No.",2022-10-14 17:11:37+00:00,Point-Normal Subdivision Curves and Surfaces,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Xunnian Yang')],"This paper proposes to generalize linear subdivision schemes to nonlinear
subdivision schemes for curve and surface modeling by refining vertex positions
together with refinement of unit control normals at the vertices. For each
round of subdivision, new control normals are obtained by projections of
linearly subdivided normals onto unit circle or sphere while new vertex
positions are obtained by updating linearly subdivided vertices along the
directions of the newly subdivided normals. Particularly, the new position of
each linearly subdivided vertex is computed by weighted averages of end points
of circular or helical arcs that interpolate the positions and normals at the
old vertices at one ends and the newly subdivided normal at the other ends.
  The main features of the proposed subdivision schemes are three folds:
  (1) The point-normal (PN) subdivision schemes can reproduce circles, circular
cylinders and spheres using control points and control normals;
  (2) PN subdivision schemes generalized from convergent linear subdivision
schemes converge and can have the same smoothness orders as the linear schemes;
  (3) PN $C^2$ subdivision schemes generalizing linear subdivision schemes that
generate $C^2$ subdivision surfaces with flat extraordinary points can generate
visually $C^2$ subdivision surfaces with non-flat extraordinary points.
  Experimental examples have been given to show the effectiveness of the
proposed techniques for curve and surface modeling.",0.23581848,0.28425038,0.094279975,B
12475,"As future work, a few interesting topics deserve further study: (a) curvature continuity analysis of PN C2 subdivi-
sion surfaces with arbitrary topology control meshes; (b) computation of convex hulls or limit points of PN subdivision
curves and surfaces; (c) construction of PN subdivision curves and surfaces that have prescribed normals or curvatures
at selected points or curves; (d) exploring surface subdivision schemes that preserve other geometric primitives such
as toruses or cyclides.","Particularly, PN subdivision schemes can be simple solutions to modeling fair C2
subdivision surfaces with arbitrary topology control meshes by adapting linear C2 subdivision schemes that only
generate subdivision surfaces with ﬂat extraordinary points.","Acknowledgment

    This work was supported by the National Natural Science Foundation of China under Grant No.",2022-10-14 17:11:37+00:00,Point-Normal Subdivision Curves and Surfaces,math.NA,"['math.NA', 'cs.NA']",[arxiv.Result.Author('Xunnian Yang')],"This paper proposes to generalize linear subdivision schemes to nonlinear
subdivision schemes for curve and surface modeling by refining vertex positions
together with refinement of unit control normals at the vertices. For each
round of subdivision, new control normals are obtained by projections of
linearly subdivided normals onto unit circle or sphere while new vertex
positions are obtained by updating linearly subdivided vertices along the
directions of the newly subdivided normals. Particularly, the new position of
each linearly subdivided vertex is computed by weighted averages of end points
of circular or helical arcs that interpolate the positions and normals at the
old vertices at one ends and the newly subdivided normal at the other ends.
  The main features of the proposed subdivision schemes are three folds:
  (1) The point-normal (PN) subdivision schemes can reproduce circles, circular
cylinders and spheres using control points and control normals;
  (2) PN subdivision schemes generalized from convergent linear subdivision
schemes converge and can have the same smoothness orders as the linear schemes;
  (3) PN $C^2$ subdivision schemes generalizing linear subdivision schemes that
generate $C^2$ subdivision surfaces with flat extraordinary points can generate
visually $C^2$ subdivision surfaces with non-flat extraordinary points.
  Experimental examples have been given to show the effectiveness of the
proposed techniques for curve and surface modeling.",0.24266037,0.2814384,0.09387794,B
12812,"We conclude with a discussion of this phenomenon
                                                  and potential directions for further research.","Our ﬁndings indicate that the volumetric approach is more robust, even though the number of
                                                  degrees of freedom is signiﬁcantly larger.","Keywords: Inverse scattering, transmission problem, Helmholtz equation, boundary integral
                                          equations, recursive linearization.",2022-10-20 21:47:57+00:00,"On the robustness of inverse scattering for penetrable, homogeneous objects with complicated boundary",math.NA,"['math.NA', 'cs.NA', '65NA21, 45Q05']","[arxiv.Result.Author('Carlos Borges'), arxiv.Result.Author('Manas Rachh'), arxiv.Result.Author('Leslie Greengard')]","The acoustic inverse obstacle scattering problem consists of determining the
shape of a domain from measurements of the scattered far field due to some set
of incident fields (probes). For a penetrable object with known sound speed,
this can be accomplished by treating the boundary alone as an unknown curve.
Alternatively, one can treat the entire object as unknown and use a more
general volumetric representation, without making use of the known sound speed.
Both lead to strongly nonlinear and nonconvex optimization problems for which
recursive linearization provides a useful framework for numerical analysis.
After extending our shape optimization approach developed earlier for
impenetrable bodies, we carry out a systematic study of both methods and
compare their performance on a variety of examples. Our findings indicate that
the volumetric approach is more robust, even though the number of degrees of
freedom is significantly larger. We conclude with a discussion of this
phenomenon and potential directions for further research.",0.17684902,0.055764955,0.01433309,B
12813,"We conclude
with a discussion of these results and opportunities for further research in section 5.","An interesting discovery is that there are clear cases where the volumetric
approach is able to obtain high quality reconstruction while the obstacle approach fails.",Remark 1.2.,2022-10-20 21:47:57+00:00,"On the robustness of inverse scattering for penetrable, homogeneous objects with complicated boundary",math.NA,"['math.NA', 'cs.NA', '65NA21, 45Q05']","[arxiv.Result.Author('Carlos Borges'), arxiv.Result.Author('Manas Rachh'), arxiv.Result.Author('Leslie Greengard')]","The acoustic inverse obstacle scattering problem consists of determining the
shape of a domain from measurements of the scattered far field due to some set
of incident fields (probes). For a penetrable object with known sound speed,
this can be accomplished by treating the boundary alone as an unknown curve.
Alternatively, one can treat the entire object as unknown and use a more
general volumetric representation, without making use of the known sound speed.
Both lead to strongly nonlinear and nonconvex optimization problems for which
recursive linearization provides a useful framework for numerical analysis.
After extending our shape optimization approach developed earlier for
impenetrable bodies, we carry out a systematic study of both methods and
compare their performance on a variety of examples. Our findings indicate that
the volumetric approach is more robust, even though the number of degrees of
freedom is significantly larger. We conclude with a discussion of this
phenomenon and potential directions for further research.",0.1331738,0.25714362,0.15857935,B
12991,"We further study
this operator in Section 3 where we recall a relation of JTSZ to the Clément interpolation
operator with 0-th order moments.","In particular, QT = QCT l can be used in the modiﬁed schemes (4), (5).","This relation is also of practical interest as it simpliﬁes
the calculation of QCT l.

2.3.",2022-10-25 14:44:32+00:00,On a mixed FEM and a FOSLS with $H^{-1}$ loads,math.NA,"['math.NA', 'cs.NA', '65N30, 65N12']",[arxiv.Result.Author('Thomas Führer')],"We study variants of the mixed finite element method (mixed FEM) and the
first-order system least-squares finite element (FOSLS) for the Poisson problem
where we replace the load by a suitable regularization which permits to use
$H^{-1}$ loads. We prove that any bounded $H^{-1}$ projector onto piecewise
constants can be used to define the regularization and yields quasi-optimality
of the lowest-order mixed FEM resp. FOSLS in weaker norms. Examples for the
construction of such projectors are given. One is based on the adjoint of a
weighted Cl\'ement quasi-interpolator. We prove that this Cl\'ement operator
has second-order approximation properties. For the modified mixed method we
show optimal convergence rates of a postprocessed solution under minimal
regularity assumptions -- a result not valid for the lowest-order mixed FEM
without regularization. Numerical examples conclude this work.",0.037895735,-0.31163856,0.09714187,B
13167,"So a key question deserving
further study both theoretically and computationally which is addressed in our paper
is how to identify and solve such degenerated systems.","Such a degeneration is of potentially great importance in designing control
parameters in architecture, aviation and biochemistry.","In summary, we aim to solve the following problems in this paper:
      • To detect at least one initial point on each real component of a polynomially
         nonlinear dae.",2022-10-29 23:04:52+00:00,Index Reduction for Degenerated Differential-Algebraic Equations by Embedding,math.NA,"['math.NA', 'cs.NA', 'cs.SC']","[arxiv.Result.Author('Wenqiang Yang'), arxiv.Result.Author('Wenyuan Wu'), arxiv.Result.Author('Greg Reid')]","To find consistent initial data points for a system of differential-algebraic
equations, requires the identification of its missing constraints. An efficient
class of structural methods exploiting a dependency graph for this task was
initiated by Pantiledes. More complete methods rely on differential-algebraic
geometry but suffer from other issues (e.g. high complexity). In this paper we
give a new class of efficient structural methods combined with new tools from
numerical real algebraic geometry that has much improved completeness
properties. Existing structural methods may fail for a system of
differential-algebraic equations if its Jacobian matrix after differentiation
is still singular due to symbolic cancellation or numerical degeneration.
Existing structural methods can only handle degenerated cases caused by
symbolic cancellation. However, if a system has parameters, then its parametric
Jacobian matrix may be still singular after application of the structural
method for certain values of the parameters. This case is called numerical
degeneration.
  For polynomially nonlinear systems of differential-algebraic equations,
numerical methods are given to solve both degenerated cases using numerical
real algebraic geometry. First, we introduce a witness point method, which
produces at least one witness point on every constraint component. This can
help to ensure constant rank and detection of degeneration on all components of
such systems. Secondly, we present a Constant Rank Embedding Lemma, and based
on it propose an Index Reduction by Embedding (IRE) method which can construct
an equivalent system with a full rank Jacobian matrix. Thirdly, IRE leads to a
global structural differentiation method, to solve degenerated
differential-algebraic equations on all components numerically. Application
examples from circuits, mechanics, are used to demonstrate our method.",0.113876015,0.11224988,-0.19922715,C
13168,"In other words, IRE method has the possibility of regularizing the structure
method, but further research is needed.","In this example, the IRE method can also ﬁnd n − r hidden constraint equations
at once.","From the perspective of hidden constraints,
we can redeﬁne the optimal value as #var − rank(F ), where #var is the number of
variables.",2022-10-29 23:04:52+00:00,Index Reduction for Degenerated Differential-Algebraic Equations by Embedding,math.NA,"['math.NA', 'cs.NA', 'cs.SC']","[arxiv.Result.Author('Wenqiang Yang'), arxiv.Result.Author('Wenyuan Wu'), arxiv.Result.Author('Greg Reid')]","To find consistent initial data points for a system of differential-algebraic
equations, requires the identification of its missing constraints. An efficient
class of structural methods exploiting a dependency graph for this task was
initiated by Pantiledes. More complete methods rely on differential-algebraic
geometry but suffer from other issues (e.g. high complexity). In this paper we
give a new class of efficient structural methods combined with new tools from
numerical real algebraic geometry that has much improved completeness
properties. Existing structural methods may fail for a system of
differential-algebraic equations if its Jacobian matrix after differentiation
is still singular due to symbolic cancellation or numerical degeneration.
Existing structural methods can only handle degenerated cases caused by
symbolic cancellation. However, if a system has parameters, then its parametric
Jacobian matrix may be still singular after application of the structural
method for certain values of the parameters. This case is called numerical
degeneration.
  For polynomially nonlinear systems of differential-algebraic equations,
numerical methods are given to solve both degenerated cases using numerical
real algebraic geometry. First, we introduce a witness point method, which
produces at least one witness point on every constraint component. This can
help to ensure constant rank and detection of degeneration on all components of
such systems. Secondly, we present a Constant Rank Embedding Lemma, and based
on it propose an Index Reduction by Embedding (IRE) method which can construct
an equivalent system with a full rank Jacobian matrix. Thirdly, IRE leads to a
global structural differentiation method, to solve degenerated
differential-algebraic equations on all components numerically. Application
examples from circuits, mechanics, are used to demonstrate our method.",-0.18162975,0.20696935,-0.12617189,C
13241,"Our
further research will be focused on proposing a more suitable partitioned neural network
approximation that can resolve the optimization error behaviors in the neural network ap-
proximation and the convergence problem in the two-level method.","Such unsatisfactory two-level method result
Additive Schwarz methods for neural network approximation  36

is related to the optimization error behaviors in the neural network approximation.","References

 [1] L. BADEA AND J. WANG, An additive Schwarz method for variational inequalities,
      Mathematics of Computation, 69 (2000), pp.",2022-11-01 02:31:43+00:00,Additive Schwarz algorithms for neural network approximate solutions,math.NA,"['math.NA', 'cs.NA', '65F10, 65N30, 65N55']","[arxiv.Result.Author('Hee Jun Yang'), arxiv.Result.Author('Hyea Hyun Kim')]","Additive Schwarz algorithms are proposed as an iterative procedure for neural
network approximate solutions of partial differential equations. Based on the
convergence analysis of the additive Schwarz algorithms in a general Hilbert
space setting, the convergence of the neural network approximate solutions is
analyzed for the one-level and two-level iterative schemes. Numerical results
of the proposed methods are presented for test examples.",-0.05590071,0.017113097,-0.06331675,C
13248,"In fact, (1.5) has some improvement compared
with the traditional iterative scheme of Kaczmarz-Tanabe method, see [14, 15], but As is the compound of Qi
and ai, which brings many obstacles for the further research, especially the regularization theory, etc.","Compared with Kaczmarz’s iteration, Kaczmarz-Tanabe’s iteration has good approximate stability (i.e.,

iterative error is not ﬂuctuate as violently as Kaczmarz’s iteration (see [13]), which may provide convenience for
people to study the regularization theory of Kaczmarz method).","In this
paper, we mainly consider the standard form of (1.5), and the corresponding iterative matrix can be calculated
by blocking and parallelization, and the algorithm can be used to generate the symmetric linear system of
equations for CGMN method (see [10]).",2022-11-01 08:31:08+00:00,The standard forms of the Kaczmarz-Tanabe type methods and their convergence theory,math.NA,"['math.NA', 'cs.NA', '65F10, 65F08, 65N22, 65J20']",[arxiv.Result.Author('Chuan-gang Kang')],"In this paper, we consider the standard form of two kinds of Kaczmarz-Tanabe
type methods, one derived from the Kaczmarz method and the other derived from
the symmetric Kaczmarz method. As a famous image reconstruction method in
computed tomography, the Kaczmarz method has both advantage and disadvantage.
The advantage are simple and easy to implement, while the disadvantages are
slow convergence speed, and the symmetric Kaczmarz method is the same. For the
standard form of this method, once the iterative matrix is generated, it can be
used continuously in the subsequent iterations. Moreover, the iterative matrix
can be stored in the image reconstructive devices, which makes the Kaczmarz
method and the symmetric Kaczmarz method can be used like the simultaneous
iterative reconstructive techniques (SIRT). Meanwhile, theoretical analysis
shows that the convergence rate of symmetric Kaczmarz method is better than the
Kaczmarz method but is slightly worse than that of two iterations Kaczmarz
method, which is verified numerically. Numerical experiments also show that the
convergence rates of the Kaczmarz method and the symmetric Kaczmarz method are
better than the SIRT methods and slightly worse than CGMN method in some cases.
However, the Kaczmarz Tanabe type methods have better problem adaptability.",-0.39624575,-0.13438419,-0.2032423,C_centroid
13249,"6 Conclusion

    The Kaczmarz-Tanabe method is the further research of the Kaczmarz method.","18
(a) Kaczmarz-Tanabe method  (b) Symmetric Kaczmarz-Tanabe  (c) DROP method
                            method

(d) SART method             (e) CAV method                 (f) Cimmino method

                                                                             (g) CGMN method

        Figure 5.4: Numerical images of the Kaczmarz-Tanabe method, symmetric Kaczmarz-Tanabe method and the SIRT
        type methods for solving Headphantom problem, including DROP, SART, CAV, Cimmino and CGMN methods.","Due to the row to row iter-
ative characteristic of the Kaczmarz method, Kaczmarz’s iteration generally converges slowly and has volatility
for perturbed linear systems.",2022-11-01 08:31:08+00:00,The standard forms of the Kaczmarz-Tanabe type methods and their convergence theory,math.NA,"['math.NA', 'cs.NA', '65F10, 65F08, 65N22, 65J20']",[arxiv.Result.Author('Chuan-gang Kang')],"In this paper, we consider the standard form of two kinds of Kaczmarz-Tanabe
type methods, one derived from the Kaczmarz method and the other derived from
the symmetric Kaczmarz method. As a famous image reconstruction method in
computed tomography, the Kaczmarz method has both advantage and disadvantage.
The advantage are simple and easy to implement, while the disadvantages are
slow convergence speed, and the symmetric Kaczmarz method is the same. For the
standard form of this method, once the iterative matrix is generated, it can be
used continuously in the subsequent iterations. Moreover, the iterative matrix
can be stored in the image reconstructive devices, which makes the Kaczmarz
method and the symmetric Kaczmarz method can be used like the simultaneous
iterative reconstructive techniques (SIRT). Meanwhile, theoretical analysis
shows that the convergence rate of symmetric Kaczmarz method is better than the
Kaczmarz method but is slightly worse than that of two iterations Kaczmarz
method, which is verified numerically. Numerical experiments also show that the
convergence rates of the Kaczmarz method and the symmetric Kaczmarz method are
better than the SIRT methods and slightly worse than CGMN method in some cases.
However, the Kaczmarz Tanabe type methods have better problem adaptability.",-0.19382659,-0.18588245,-0.31665158,C
13250,"The Kaczmarz-Tanabe method overcomes the volatility of Kaczmarz’s method
and can smoothly approach the ’pseudo-inverse solution’ when solving the perturbation problem, which lays a
foundation for us to further study the minimum norm least squares solution.","Due to the row to row iter-
ative characteristic of the Kaczmarz method, Kaczmarz’s iteration generally converges slowly and has volatility
for perturbed linear systems.","In addition, as a comparison, we also consider the more popular symmetric Kaczmarz-Tanabe method and
derive its standard form.",2022-11-01 08:31:08+00:00,The standard forms of the Kaczmarz-Tanabe type methods and their convergence theory,math.NA,"['math.NA', 'cs.NA', '65F10, 65F08, 65N22, 65J20']",[arxiv.Result.Author('Chuan-gang Kang')],"In this paper, we consider the standard form of two kinds of Kaczmarz-Tanabe
type methods, one derived from the Kaczmarz method and the other derived from
the symmetric Kaczmarz method. As a famous image reconstruction method in
computed tomography, the Kaczmarz method has both advantage and disadvantage.
The advantage are simple and easy to implement, while the disadvantages are
slow convergence speed, and the symmetric Kaczmarz method is the same. For the
standard form of this method, once the iterative matrix is generated, it can be
used continuously in the subsequent iterations. Moreover, the iterative matrix
can be stored in the image reconstructive devices, which makes the Kaczmarz
method and the symmetric Kaczmarz method can be used like the simultaneous
iterative reconstructive techniques (SIRT). Meanwhile, theoretical analysis
shows that the convergence rate of symmetric Kaczmarz method is better than the
Kaczmarz method but is slightly worse than that of two iterations Kaczmarz
method, which is verified numerically. Numerical experiments also show that the
convergence rates of the Kaczmarz method and the symmetric Kaczmarz method are
better than the SIRT methods and slightly worse than CGMN method in some cases.
However, the Kaczmarz Tanabe type methods have better problem adaptability.",-0.23868726,-0.18862082,-0.23263647,C
13347,"10, we further study instabilities for a wide range of shear-modulus ratios and
coating thicknesses ω ∈ {0.02, 0.03, 0.04, 0.05} mm.","When the shear-modulus ratio exceeds the value of γc/γm = 30, diamond-plate patterns
with smooth internal boundaries as in case of the single-phase hydrogel structures are
observed.8

    In Fig.","The graphs describe the critical time
tcrit and the eﬀective ﬁrst Piola-Kirchhoﬀ stress P 11 depending on the shear-modulus ratio

    8We note that while the Bloch–Floquet analysis indicated a long-wavelength instability for the shear-
modulus ratio γc/γm = 5.0 (see black bullet in Fig.",2022-11-03 16:06:27+00:00,Swelling-induced pattern transformations of periodic hydrogels -- from the wrinkling of internal surfaces to the buckling of thin films,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Elten Polukhov'), arxiv.Result.Author('Laura Pytel'), arxiv.Result.Author('Marc-Andre Keip')]","We investigate pattern transformations of periodic hydrogel systems that are
triggered by swelling-induced structural instabilities. The types of
microstructures considered in the present work include single-phase and
two-phase voided hydrogel structures as well as reinforced hydrogel thin films.
While the observed transformations of the single-phase structures show good
agreement with experimental findings, the two-phase materials provide novel
patterns associated with wrinkling of internal surfaces. Furthermore, an
extensive parametric study on the reinforced hydrogel thin films reveals new
opportunities for the design of complex out-of-plane surface modes caused by
swelling-induced instabilities. Next to the mentioned buckling-type
instabilities, we encountered the development of micro-creases at the internal
surfaces of periodic media before the loss of strong ellipticity of effective
moduli.",0.33714512,0.014354326,0.10774694,B
13426,"In the further study, although the condition f (x)  0 is unnecessary, the derivative in the
iterative scheme makes it difficult to solve and increase the calculation cost greatly in some
problems.","References [10-
11] proposed a predictor corrector iterative scheme for finding the solutions of nonlinear
equations by using the improved Newton like method as predictor, and proved at least second-
order convergence.","For this reason, literature [9] uses difference quotient scheme to replace the
derivative.",2022-11-07 02:25:29+00:00,Newton Like Iterative Method without Derivative for Solving Nonlinear Equations Based on Dynamical Systems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yonglong Liao'), arxiv.Result.Author('Limin Cui')]","The iterative problem of solving nonlinear equations is studied. A new Newton
like iterative method with adjustable parameters is designed based on the
dynamic system theory. In order to avoid the derivative function in the
iterative scheme, the difference quotient is used instead of the derivative.
Different from the existing methods, the difference quotient scheme in this
paper has higher accuracy. Thus, the new iterative method is suitable for a
wider range of initial values. Finally, several numerical examples are given to
verify the practicability and superiority of the method.",-0.1430064,-0.0041692927,-0.46917957,C
13427,"In the further study, although the condition f (x)  0 is unnecessary, the derivative in the
iterative scheme makes it difficult to solve and increase the calculation cost greatly in some
problems.","References [10-
11] proposed a predictor corrector iterative scheme for finding the solutions of nonlinear
equations by using the improved Newton like method as predictor, and proved at least second-
order convergence.","For this reason, literature [9] uses difference quotient scheme to replace the
derivative.",2022-11-07 02:25:29+00:00,Newton Like Iterative Method without Derivative for Solving Nonlinear Equations Based on Dynamical Systems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yonglong Liao'), arxiv.Result.Author('Limin Cui')]","The iterative problem of solving nonlinear equations is studied. A new Newton
like iterative method with adjustable parameters is designed based on the
dynamic system theory. In order to avoid the derivative function in the
iterative scheme, the difference quotient is used instead of the derivative.
Different from the existing methods, the difference quotient scheme in this
paper has higher accuracy. Thus, the new iterative method is suitable for a
wider range of initial values. Finally, several numerical examples are given to
verify the practicability and superiority of the method.",-0.1430064,-0.0041692927,-0.46917957,C
13429,"It is expected that further research will be conducted on datasets
with driver characteristics.","The parameters of the proposed model are calibrated based on the minimum error of
the naturalistic driving dataset.","The corresponding parameters of speciﬁc categories of drivers will be
calibrated.",2022-11-07 04:49:24+00:00,A Driving Risk Surrogate and Its Application in Car-Following Scenario at Expressway,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Renfei Wu'), arxiv.Result.Author('Linheng Li'), arxiv.Result.Author('Haotian Shi'), arxiv.Result.Author('Yikang Rui'), arxiv.Result.Author('Dong Ngoduy'), arxiv.Result.Author('Bin Ran')]","Traffic safety is important in reducing death and building a harmonious
society. In addition to studies of accident incidences, the perception of
driving risk is significant in guiding the implementation of appropriate
driving countermeasures. Risk assessment can be conducted in real-time for
traffic safety due to the rapid development of communication technology and
computing capabilities. This paper aims at the problems of difficult
calibration and inconsistent thresholds in the existing risk assessment
methods. It proposes a risk assessment model based on the potential field to
quantify the driving risk of vehicles. Firstly, virtual energy is proposed as
an attribute considering vehicle sizes and velocity. Secondly, the driving risk
surrogate(DRS) is proposed based on potential field theory to describe the risk
degree of vehicles. Risk factors are quantified by establishing submodels,
including an interactive vehicle risk surrogate, a restrictions risk surrogate,
and a speed risk surrogate. To unify the risk threshold, acceleration for
implementation guidance is derived from the risk field strength. Finally, a
naturalistic driving dataset in Nanjing, China, is selected, and 3063 pairs of
following naturalistic trajectories are screened out. Based on that, the
proposed model and other models use for comparisons are calibrated through the
improved particle optimization algorithm. Simulations prove that the proposed
model performs better than other algorithms in risk perception and response,
car-following trajectory, and velocity estimation. In addition, the proposed
model exhibits better car-following ability than existing car-following models.",0.15317707,0.41929397,0.117325634,C
13430,"In further research, we will calibrate parameters in new scenarios and verify the car-following
performance in more complex traﬃc scenarios.","Secondly,
the traﬃc elements considered in this paper are relatively simple and have not been veriﬁed on urban
roads.","Nonetheless, we believe that the application of DRS
and car-following in this paper may open a new perspective for many tasks to advance the development
of micro-behavioral models and traﬃc ﬂow models.",2022-11-07 04:49:24+00:00,A Driving Risk Surrogate and Its Application in Car-Following Scenario at Expressway,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Renfei Wu'), arxiv.Result.Author('Linheng Li'), arxiv.Result.Author('Haotian Shi'), arxiv.Result.Author('Yikang Rui'), arxiv.Result.Author('Dong Ngoduy'), arxiv.Result.Author('Bin Ran')]","Traffic safety is important in reducing death and building a harmonious
society. In addition to studies of accident incidences, the perception of
driving risk is significant in guiding the implementation of appropriate
driving countermeasures. Risk assessment can be conducted in real-time for
traffic safety due to the rapid development of communication technology and
computing capabilities. This paper aims at the problems of difficult
calibration and inconsistent thresholds in the existing risk assessment
methods. It proposes a risk assessment model based on the potential field to
quantify the driving risk of vehicles. Firstly, virtual energy is proposed as
an attribute considering vehicle sizes and velocity. Secondly, the driving risk
surrogate(DRS) is proposed based on potential field theory to describe the risk
degree of vehicles. Risk factors are quantified by establishing submodels,
including an interactive vehicle risk surrogate, a restrictions risk surrogate,
and a speed risk surrogate. To unify the risk threshold, acceleration for
implementation guidance is derived from the risk field strength. Finally, a
naturalistic driving dataset in Nanjing, China, is selected, and 3063 pairs of
following naturalistic trajectories are screened out. Based on that, the
proposed model and other models use for comparisons are calibrated through the
improved particle optimization algorithm. Simulations prove that the proposed
model performs better than other algorithms in risk perception and response,
car-following trajectory, and velocity estimation. In addition, the proposed
model exhibits better car-following ability than existing car-following models.",0.22797434,0.38532412,-0.0825053,C
13431,This needs further study.,"An
interesting question is how to develop a mixed precision method for the generalized eigenvalue
problem.","References

 [1] IEEE Standard for Floating-Point Arithmetic, IEEE Std 754-2008 (Revision of IEEE 754-1985),
      Institute of Electrical and Electronics Engineers, 2008.",2022-11-07 07:10:00+00:00,A mixed precision Jacobi method for the symmetric eigenvalue problem,math.NA,"['math.NA', 'cs.NA', '65F15, 15A18']","[arxiv.Result.Author('Zhiyuan Zhang'), arxiv.Result.Author('Zheng-Jian Bai')]","The eigenvalue problem is a fundamental problem in scientific computing. In
this paper, we propose a mixed precision Jacobi method for the symmetric
eigenvalue problem. We first compute the eigenvalue decomposition of a real
symmetric matrix by an eigensolver at low precision and we obtain a
low-precision matrix of eigenvectors. Then by using the modified Gram-Schmidt
orthogonalization process to the low-precision eigenvector matrix in high
precision, a high-precision orthogonal matrix is obtained, which is used as an
initial guess for the Jacobi method. We give the rounding error analysis for
the proposed method and the quadratic convergence of the proposed method is
established under some sufficient conditions. We also present a mixed precision
one-side Jacobi method for the singular value problem and the corresponding
rounding error analysis and quadratic convergence are discussed. Numerical
experiments on CPUs and GPUs are conducted to illustrate the efficiency of the
proposed mixed precision Jacobi method over the original Jacobi method.",-0.30672666,-0.22406706,0.046116143,A
13500,"According to the ﬁnite horizon assumption (1.4) of kernel, the coefﬁcient am satisﬁes

                                am = 0, |m|∞ L.

For further study, the following equivalent form of the Lδ,h is needed

          Lδ ,huk = ∑ cmuk+m,                      k ∈ Zd                                  (2.4)

                          |m|∞ L

with

                                                  m = 0,
                                 −am,             m = 0,

                                ∑ cm =       am ,                                          (2.5)

                                 m∈Zd ,m=0

where the property am = a−m is used.","w(xk − y)
Let uk be the approximation of u(xk), Φk,p(x) be the pth-degree (1D) or bipth-degree (2D) Lagrange

polynomial at point xk on each divided small domain Tik, then one obtains the discretization for (2.1) as

         ∑ L ,huk =    uk − um                      Φm,p(y)w(xk − y)γ(xk − y)dy

         δ     m∈Zd,m=k w(xk − xm)           Bδ (xk )

            ∑ =        uk − um                     Φm−k , p (s )w(s )γ (s )d s   (2.2)

               m∈Zd,m=k w(xk − xm)           Bδ (0)

            = ∑ ak−m(uk − um),

                m∈Zd
       STABILITY AND CONVERGENCE ANALYSIS FOR NONLOCAL WAVE EQUATIONS                      5 of 26

where

       1                          Φm, p (s )w(s )γ (s )d s ,        m = 0,
                                                                    m = 0.

       am = w(hm) B (0)                                                                    (2.3)
                                δ

                                  0,

It is obvious that am = a−m.","On the truncation error of quadrature-based FD approximation (2.2), we have the following lemma.",2022-11-08 15:19:19+00:00,Stability and convergence analysis of high-order numerical schemes with DtN-type absorbing boundary conditions for nonlocal wave equations,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Jihong Wang'), arxiv.Result.Author('Jerry Zhijian Yang'), arxiv.Result.Author('Jiwei Zhang')]","The stability and convergence analysis of high-order numerical approximations
for the one- and two-dimensional nonlocal wave equations on unbounded spatial
domains are considered. We first use the quadrature-based finite difference
schemes to discretize the spatially nonlocal operator, and apply the explicit
difference scheme to approximate the temporal derivative to achieve a fully
discrete infinity system. After that, we construct the Dirichlet-to-Neumann
(DtN)-type absorbing boundary conditions (ABCs) to reduce the infinite discrete
system into a finite discrete system. To do so, we first adopt the idea in [Du,
Zhang and Zheng, \emph{Commun. Comput. Phys.}, 24(4):1049--1072, 2018 and Du,
Han, Zhang and Zheng, \emph{SIAM J. Sci. Comp.}, 40(3):A1430--A1445, 2018] to
derive the Dirichlet-to-Dirichlet (DtD)-type mappings for one- and
two-dimensional cases, respectively. We then use the discrete nonlocal Green's
first identity to achieve the discrete DtN-type mappings from the DtD-type
mappings. The resulting DtN-type mappings make it possible to perform the
stability and convergence analysis of the reduced problem. Numerical
experiments are provided to demonstrate the accuracy and effectiveness of the
proposed approach.",0.18719208,-0.32647532,-0.03896346,B
13858,Concluding remarks and an outlook to further research perspectives are given in Chapter 6.,"While
we ﬁrst formulate these methods in a general way, we describe the particular instance of a
TR-LRB algorithm based on the RB-based reduced formulations of the LOD and show numerical
experiments.","10
             2 Chapter

Mathematical background

In this chapter, we introduce the mathematical background of this thesis with the primary
intention to provide a more mathematical view of the concepts discussed in Chapter 1.",2022-11-17 15:57:18+00:00,Adaptive Reduced Basis Methods for Multiscale Problems and Large-scale PDE-constrained Optimization,math.NA,"['math.NA', 'cs.NA', '65N15, 65N30, 49M20, 49K20, 35J20, 90C06']",[arxiv.Result.Author('Tim Keil')],"This thesis presents recent advances in model order reduction methods with
the primary aim to construct online-efficient reduced surrogate models for
parameterized multiscale phenomena and accelerate large-scale PDE-constrained
parameter optimization methods. In particular, we present several different
adaptive RB approaches that can be used in an error-aware trust-region
framework for progressive construction of a surrogate model used during a
certified outer optimization loop. In addition, we elaborate on several
different enhancements for the trust-region reduced basis (TR-RB) algorithm and
generalize it for parameter constraints. Thanks to the a posteriori error
estimation of the reduced model, the resulting algorithm can be considered
certified with respect to the high-fidelity model. Moreover, we use the
first-optimize-then-discretize approach in order to take maximum advantage of
the underlying optimality system of the problem. In the first part of this
thesis, the theory is based on global RB techniques that use an accurate FEM
discretization as the high-fidelity model. In the second part, we focus on
localized model order reduction methods and develop a novel online efficient
reduced model for the localized orthogonal decomposition (LOD) multiscale
method. The reduced model is internally based on a two-scale formulation of the
LOD and, in particular, is independent of the coarse and fine discretization of
the LOD. The last part of this thesis is devoted to combining both results on
TR-RB methods and localized RB approaches for the LOD. To this end, we present
an algorithm that uses adaptive localized reduced basis methods in the
framework of a trust-region localized reduced basis (TR-LRB) algorithm. The
basic ideas from the TR-RB are followed, but FEM evaluations of the involved
systems are entirely avoided.",-0.2633448,-0.05627578,0.007753864,A
13859,"Importantly, further research perspectives of MOR-informed TR methods are usually unaf-
fected by the choice of the (localized) full- and reduced-order model since these methods can be
interpreted as a black-box reduced approach as long as the models can be trusted concerning
their approximation qualities.","Concerning the continued development
of the speciﬁc TR-RB algorithm, as also concluded above, further hints towards more involved
algorithms were given in Section 3.6, e.g., coarsening of the RB spaces or more FOM-cost
oriented procedures.","Indeed, TR methods are also applicable to many other problem
classes or other types of parameter optimization.",2022-11-17 15:57:18+00:00,Adaptive Reduced Basis Methods for Multiscale Problems and Large-scale PDE-constrained Optimization,math.NA,"['math.NA', 'cs.NA', '65N15, 65N30, 49M20, 49K20, 35J20, 90C06']",[arxiv.Result.Author('Tim Keil')],"This thesis presents recent advances in model order reduction methods with
the primary aim to construct online-efficient reduced surrogate models for
parameterized multiscale phenomena and accelerate large-scale PDE-constrained
parameter optimization methods. In particular, we present several different
adaptive RB approaches that can be used in an error-aware trust-region
framework for progressive construction of a surrogate model used during a
certified outer optimization loop. In addition, we elaborate on several
different enhancements for the trust-region reduced basis (TR-RB) algorithm and
generalize it for parameter constraints. Thanks to the a posteriori error
estimation of the reduced model, the resulting algorithm can be considered
certified with respect to the high-fidelity model. Moreover, we use the
first-optimize-then-discretize approach in order to take maximum advantage of
the underlying optimality system of the problem. In the first part of this
thesis, the theory is based on global RB techniques that use an accurate FEM
discretization as the high-fidelity model. In the second part, we focus on
localized model order reduction methods and develop a novel online efficient
reduced model for the localized orthogonal decomposition (LOD) multiscale
method. The reduced model is internally based on a two-scale formulation of the
LOD and, in particular, is independent of the coarse and fine discretization of
the LOD. The last part of this thesis is devoted to combining both results on
TR-RB methods and localized RB approaches for the LOD. To this end, we present
an algorithm that uses adaptive localized reduced basis methods in the
framework of a trust-region localized reduced basis (TR-LRB) algorithm. The
basic ideas from the TR-RB are followed, but FEM evaluations of the involved
systems are entirely avoided.",-0.2809448,0.109006464,-0.08635722,C
13899,"Although the generic convergence

frameworks for analyzing the convergence of the ATG method [17, 19, 20, 4, 5, 14]

are also applicable for the PCTL algorithm and could prove the convergence of the

PCTL algorithm, our goal in this section is to characterize the speciﬁc convergence

properties of the PCTL algorithm, expecting to be helpful for further research on the

PCTL algorithm, such as improving its performance and analysing which problems it

is eﬀective.",Convergence of the PCTL algorithm.,"Before it, we ﬁrst introduce some studies on the convergence estimation

of the ATG method.",2022-11-18 08:14:03+00:00,Convergence of the PCTL algorithm for solving the discretized 3T energy equations in RHD problems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yue Hao'), arxiv.Result.Author('Silu Huang'), arxiv.Result.Author('Xiaowen Xu')]","For solving the three-temperature linear system arising from the radiation
hydrodynamics (RHD) problem, Xu et. proposed a physical-variable based
coarsening algebraic two level (PCTL) iterative method and verified its
efficiency by numerical experiments. However, there is still a lack of
quantitative evaluation of the performance of PCTL algorithm, thus we aim to
fill in this blank in this paper. By theoretical analysis, we give an
estimation on the convergence factor of the PCTL algorithm and show it is
independent of the problem size, which provides a theoretical guarantee for
solving large-scale problems. Moreover, we also discuss the factors that affect
the efficiency of PCTL algorithm and provide a direction for the efficient
application of the PCTL algorithm.",-0.1987183,-0.03217096,-0.1235836,C
13900,"In
this section, we discuss the factors that aﬀect the convergence bound κ, and expect it
could provide a guidance for further research on the PCTL algorithm, such as which
kind of problems PCTL algorithm is eﬀective and how to improve its performance.",Analysis of factors aﬀecting the performance of PCTL algorithm.,"The convergence bound in Theorem 3.10 shows that the bound κ decreases with
the decreasing of the parameter β.",2022-11-18 08:14:03+00:00,Convergence of the PCTL algorithm for solving the discretized 3T energy equations in RHD problems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Yue Hao'), arxiv.Result.Author('Silu Huang'), arxiv.Result.Author('Xiaowen Xu')]","For solving the three-temperature linear system arising from the radiation
hydrodynamics (RHD) problem, Xu et. proposed a physical-variable based
coarsening algebraic two level (PCTL) iterative method and verified its
efficiency by numerical experiments. However, there is still a lack of
quantitative evaluation of the performance of PCTL algorithm, thus we aim to
fill in this blank in this paper. By theoretical analysis, we give an
estimation on the convergence factor of the PCTL algorithm and show it is
independent of the problem size, which provides a theoretical guarantee for
solving large-scale problems. Moreover, we also discuss the factors that affect
the efficiency of PCTL algorithm and provide a direction for the efficient
application of the PCTL algorithm.",-0.1873962,-0.04220677,-0.012007982,C
14090,"This leaves several interesting options
for further research, such as the extension of the analysis to 2D and higher-dimensional
problems and to other kinds of radial basis functions.","7 Concluding remarks

The analysis and numerical results of this paper have conﬁrmed the possibility of accurate and
stable approximations using the Gaussian RBF in 1D.","An interesting computational challenge
is the rapid solution of the rectangular linear systems.",2022-11-22 21:54:46+00:00,Stable and accurate least squares radial basis function approximations on bounded domains,math.NA,"['math.NA', 'cs.NA', '65D15, 65F22, 15A12, 42A10']","[arxiv.Result.Author('Ben Adcock'), arxiv.Result.Author('Daan Huybrechs'), arxiv.Result.Author('Cécile Piret')]","The computation of global radial basis function (RBF) approximations requires
the solution of a linear system which, depending on the choice of RBF
parameters, may be ill-conditioned. We study the stability and accuracy of
approximation methods using the Gaussian RBF in all scaling regimes of the
associated shape parameter. The approximation is based on discrete least
squares with function samples on a bounded domain, using RBF centers both
inside and outside the domain. This results in a rectangular linear system. We
show for one-dimensional approximations that linear scaling of the shape
parameter with the degrees of freedom is optimal, resulting in constant overlap
between neighbouring RBF's regardless of their number, and we propose an
explicit suitable choice of the proportionality constant. We show numerically
that highly accurate approximations to smooth functions can also be obtained on
bounded domains in several dimensions, using a linear scaling with the degrees
of freedom per dimension. We extend the least squares approach to a
collocation-based method for the solution of elliptic boundary value problems
and illustrate that the combination of centers outside the domain, oversampling
and optimal scaling can result in accuracy close to machine precision in spite
of having to solve very ill-conditioned linear systems.",-0.11278016,-0.109825715,0.036032863,C
14357,"However, further research is required to establish the DLDC as viable method to solve for
general problems in science and engineering.","The proposed integral equation solver potentially avoids large number of training parameters that was the bottleneck for
using graph kernel network.","Acknowledgements The authors would like to acknowledge the support of National Science Foundation (NSF, USA) grants CMMI-1762035
and CMMI-1934367 and AFOSR, USA grant FA9550-18-1-0381.",2022-11-29 22:07:50+00:00,Deep Learning Discrete Calculus (DLDC): A Family of Discrete Numerical Methods by Universal Approximation for STEM Education to Frontier Research,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Sourav Saha'), arxiv.Result.Author('Chanwook Park'), arxiv.Result.Author('Stefan Knapik'), arxiv.Result.Author('Jiachen Guo'), arxiv.Result.Author('Owen Huang'), arxiv.Result.Author('Wing Kam Liu')]","The article proposes formulating and codifying a set of applied numerical
methods, coined as Deep Learning Discrete Calculus (DLDC), that uses the
knowledge from discrete numerical methods to interpret the deep learning
algorithms through the lens of applied mathematics. The DLDC methods aim to
leverage the flexibility and ever increasing resources of deep learning and
rich literature of numerical analysis to formulate a general class of numerical
method that can directly use data with uncertainty to predict the behavior of
an unknown system as well as elevate the speed and accuracy of numerical
solution of the governing equations for known systems. The article is
structured in two major sections. In the first section, the building blocks of
the DLDC methods are presented and deep learning structures analogous to
traditional numerical methods such as finite difference and finite element
methods are constructed with a view to incorporate these techniques in Science,
Technology, Engineering, Mathematics (STEM) syllabus for K-12 students. The
second section builds upon the building blocks of the previous discussion,and
proposes new solution schemes for differential and integral equations pertinent
to multiscale mechanics. Each section is accompanied with mathematical
formulation of the numerical methods, analogous DLDC formulation, and suitable
examples.",-0.12472862,0.20071915,-0.101603016,C
14561,"To further study the asymptotic behavior of the proposed adaptive time-stepping fully

discrete scheme, we establish the LDP for the numerical solution.","Based on this H1-exponential integrability and the

Hj (j = 1, 2)-regularity estimates, it is shown that this fully discrete scheme is convergent with

strong  orders  1  in  time  and  2  in  space,  which  are  optimal  in  the  sense  that  the  orders  coincide
                2
with the optimal temporal H¨older regularity and spatial Sobolev regularity, respectively.","The LDP for the SPDE

with small noise is also called the Freidlin–Wentzell LDP, which characterizes the exponential

decay probabilities that sample paths of the SPDE deviate from that of the corresponding

deterministic equation as the intensity of the noise tends to zero, and has received much

attention in recent years (see e.g.",2022-12-05 02:42:31+00:00,An adaptive time-stepping fully discrete scheme for stochastic NLS equation: Strong convergence and numerical asymptotics,math.NA,"['math.NA', 'cs.NA', 'math.PR']","[arxiv.Result.Author('Chuchu Chen'), arxiv.Result.Author('Tonghe Dang'), arxiv.Result.Author('Jialin Hong')]","In this paper, we propose and analyze an adaptive time-stepping fully
discrete scheme which possesses the optimal strong convergence order for the
stochastic nonlinear Schr\""odinger equation with multiplicative noise. Based on
the splitting skill and the adaptive strategy, the $H^1$-exponential
integrability of the numerical solution is obtained, which is a key ingredient
to derive the strong convergence order. We show that the proposed scheme
converges strongly with orders $\frac12$ in time and $2$ in space. To
investigate the numerical asymptotic behavior, we establish the large deviation
principle for the numerical solution. This is the first result on the study of
the large deviation principle for the numerical scheme of stochastic partial
differential equations with superlinearly growing drift. And as a byproduct,
the error of the masses between the numerical and exact solutions is finally
obtained.",0.19834828,-0.26543167,0.04128183,B
14596,"Perturbation analysis on hard case is much more complicated and deserves
further study.","For instance, we only consider the situations that TRS is in easy case or in nearly
hard case.","REFERENCES

[1] S. Adachi, S. Iwata, Y. Nakatsukasa, and A. Takeda, Solving the trust-region subproblem
           by a generalized eigenvalue problem, SIAM J.",2022-12-06 04:24:01+00:00,First-order perturbation theory of trust-region subproblems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Feng Bo'), arxiv.Result.Author('Wu Gang')]","Trust-region subproblem (TRS) is an important problem arising in many
applications such as numerical optimization, Tikhonov regularization of
ill-posed problems, and constrained eigenvalue problems. In recent decades,
extensive works focus on how to solve the trust-region subproblem efficiently.
To the best of our knowledge, there are few results on perturbation analysis of
the trust-region subproblem. In order to fill in this gap, we focus on
first-order perturbation theory of the trust-region subproblem. The main
contributions of this paper are three-fold. First, suppose that the TRS is in
easy case, we give a sufficient condition under which the perturbed TRS is
still in easy case. Second, with the help of the structure of the TRS and the
classical eigenproblem perturbation theory, we perform first-order perturbation
analysis on the Lagrange multiplier and the solution of the TRS, and define the
condition numbers of them. Third, we point out that the solution and the
Lagrange multiplier could be well-conditioned even if TRS is in nearly hard
case. The established results are computable, and are helpful to evaluate
ill-conditioning of the TRS problem beforehand. Numerical experiments show the
sharpness of the established bounds and the effectiveness of the proposed
strategies.",-0.019166652,-0.17567304,-0.027571417,C
14597,"Perturbation analysis on hard case is much more complicated and deserves
further study.","For instance, we only consider the situations that TRS is in easy case or in nearly
hard case.","REFERENCES

[1] S. Adachi, S. Iwata, Y. Nakatsukasa, and A. Takeda, Solving the trust-region subproblem
           by a generalized eigenvalue problem, SIAM J.",2022-12-06 04:24:01+00:00,First-order perturbation theory of trust-region subproblems,math.NA,"['math.NA', 'cs.NA']","[arxiv.Result.Author('Bo Feng'), arxiv.Result.Author('Gang Wu')]","Trust-region subproblem (TRS) is an important problem arising in many
applications such as numerical optimization, Tikhonov regularization of
ill-posed problems, and constrained eigenvalue problems. In recent decades,
extensive works focus on how to solve the trust-region subproblem efficiently.
To the best of our knowledge, there are few results on perturbation analysis of
the trust-region subproblem. In order to fill in this gap, we focus on
first-order perturbation theory of the trust-region subproblem. The main
contributions of this paper are three-fold. First, suppose that the TRS is in
easy case, we give a sufficient condition under which the perturbed TRS is
still in easy case. Second, with the help of the structure of the TRS and the
classical eigenproblem perturbation theory, we perform first-order perturbation
analysis on the Lagrange multiplier and the solution of the TRS, and define the
condition numbers of them. Third, we point out that the solution and the
Lagrange multiplier could be well-conditioned even if TRS is in nearly hard
case. The established results are computable, and are helpful to evaluate
ill-conditioning of the TRS problem beforehand. Numerical experiments show the
sharpness of the established bounds and the effectiveness of the proposed
strategies.",-0.019166652,-0.17567304,-0.027571417,C
14794,"Although further research is needed here, the results would seem to suggest that
    ( ) = O(1/ 2), i.e., there is also second order of convergence with respect to when
  ∈ [0.5, 2), whereas, when ∈ (0, 0.5], ( ) = O(1/ 1.5+ ).",", 1.99}; and in Figure 5, the corresponding values of

    ( ).","It is a well known fact that some types of diﬀerentiation matrices (like Chebyshev

diﬀerentiation matrices, see, e.g., [15]) are severely ill-conditioned.",2022-12-09 23:05:21+00:00,A fast convolution method for the fractional Laplacian in $\mathbb{R}$,math.NA,"['math.NA', 'cs.NA', '26A33, 35R11, 65D32']","[arxiv.Result.Author('Jorge Cayama'), arxiv.Result.Author('Carlota M. Cuesta'), arxiv.Result.Author('Francisco de la Hoz'), arxiv.Result.Author('Carlos J. Garcia-Cervera')]","In this article, we develop a new method to approximate numerically the
fractional Laplacian of functions defined on $\mathbb R$, as well as some more
general singular integrals. After mapping $\mathbb R$ into a finite interval,
we discretize the integral operator using a modified midpoint rule. The result
of this procedure can be cast as a discrete convolution, which can be evaluated
efficiently using the Fast-Fourier Transform (FFT). The method provides an
efficient, second order accurate, approximation to the fractional Laplacian,
without the need to truncate the domain.
  We first prove that the method gives a second-order approximation for the
fractional Laplacian and other related singular integrals; then, we detail the
implementation of the method using the fast convolution, and give numerical
examples that support its efficacy and efficiency; finally, as an example of
its applicability to an evolution problem, we employ the method for the
discretization of the nonlocal part of the one-dimensional cubic fractional
Schr\""odinger equation in the focusing case.",-0.024481818,-0.3212879,0.14893484,B
14795,"In our opinion, this point is the main caveat
of the method and requires further research.","On the other
hand, in the right-hand side of Figure 6, we have plotted the discrete ∞ norm of the errors,
for = 128, and = 216 = 65536, and similar conclusions can be drawn, except that the
worst results happen only when is close to 2.","However, to the best of our knowledge, as of
now, there seems to be no other numerical method capable of approximating the fractional
Laplacian at such large amounts of nodes (and let alone doing it in just a few seconds), so,
even in the worst cases, we think that the accuracy is still remarkably high.",2022-12-09 23:05:21+00:00,A fast convolution method for the fractional Laplacian in $\mathbb{R}$,math.NA,"['math.NA', 'cs.NA', '26A33, 35R11, 65D32']","[arxiv.Result.Author('Jorge Cayama'), arxiv.Result.Author('Carlota M. Cuesta'), arxiv.Result.Author('Francisco de la Hoz'), arxiv.Result.Author('Carlos J. Garcia-Cervera')]","In this article, we develop a new method to approximate numerically the
fractional Laplacian of functions defined on $\mathbb R$, as well as some more
general singular integrals. After mapping $\mathbb R$ into a finite interval,
we discretize the integral operator using a modified midpoint rule. The result
of this procedure can be cast as a discrete convolution, which can be evaluated
efficiently using the Fast-Fourier Transform (FFT). The method provides an
efficient, second order accurate, approximation to the fractional Laplacian,
without the need to truncate the domain.
  We first prove that the method gives a second-order approximation for the
fractional Laplacian and other related singular integrals; then, we detail the
implementation of the method using the fast convolution, and give numerical
examples that support its efficacy and efficiency; finally, as an example of
its applicability to an evolution problem, we employ the method for the
discretization of the nonlocal part of the one-dimensional cubic fractional
Schr\""odinger equation in the focusing case.",-0.15848213,-0.06727132,0.19392133,A
14991,"After this analysis several computational and
                                          theoretical aspects remain open, and we will outline possible further research directions in a concluding section.","Finally, we will show how to employ an eﬃcient stable algorithm to these kernels to obtain accurate
                                          interpolants, and we will test them in some numerical experiment.","This work builds some bridges between kernel and polynomial interpolation, two topics to which the authors,
                                          to diﬀerent extents, have been introduced under the supervision or through the work of Stefano De Marchi.",2022-12-15 08:30:23+00:00,Interpolation with the polynomial kernels,math.NA,"['math.NA', 'cs.LG', 'cs.NA']","[arxiv.Result.Author('Giacomo Elefante'), arxiv.Result.Author('Wolfgang Erb'), arxiv.Result.Author('Francesco Marchetti'), arxiv.Result.Author('Emma Perracchione'), arxiv.Result.Author('Davide Poggiali'), arxiv.Result.Author('Gabriele Santin')]","The polynomial kernels are widely used in machine learning and they are one
of the default choices to develop kernel-based classification and regression
models. However, they are rarely used and considered in numerical analysis due
to their lack of strict positive definiteness. In particular they do not enjoy
the usual property of unisolvency for arbitrary point sets, which is one of the
key properties used to build kernel-based interpolation methods. This paper is
devoted to establish some initial results for the study of these kernels, and
their related interpolation algorithms, in the context of approximation theory.
We will first prove necessary and sufficient conditions on point sets which
guarantee the existence and uniqueness of an interpolant. We will then study
the Reproducing Kernel Hilbert Spaces (or native spaces) of these kernels and
their norms, and provide inclusion relations between spaces corresponding to
different kernel parameters. With these spaces at hand, it will be further
possible to derive generic error estimates which apply to sufficiently smooth
functions, thus escaping the native space. Finally, we will show how to employ
an efficient stable algorithm to these kernels to obtain accurate interpolants,
and we will test them in some numerical experiment. After this analysis several
computational and theoretical aspects remain open, and we will outline possible
further research directions in a concluding section. This work builds some
bridges between kernel and polynomial interpolation, two topics to which the
authors, to different extents, have been introduced under the supervision or
through the work of Stefano De Marchi. For this reason, they wish to dedicate
this work to him in the occasion of his 60th birthday.",-0.038279973,-0.10788852,0.071982324,B
15107,"The proofs of the claims seem be more complicated, however, these will be an interesting
analysis works for the further study.","2             2

          Then we claim that by suitably choosing the parameter N , this new time-splitting
          method presents a higher-order convergence rate than the standard Strang splitting
          or Lie splitting method under the same regularity condition.","5

1.3.",2022-12-19 08:48:02+00:00,A modified splitting method for the cubic nonlinear Schrödinger equation,math.NA,"['math.NA', 'cs.NA', 'math.AP', '65M12, 65M15, 35Q55']",[arxiv.Result.Author('Yifei Wu')],"As a classical time-stepping method, it is well-known that the Strang
splitting method reaches the first-order accuracy by losing two spatial
derivatives. In this paper, we propose a modified splitting method for the 1D
cubic nonlinear Schr\""odinger equation: \begin{align*}
u^{n+1}=\mathrm{e}^{i\frac\tau2\partial_x^2}{\mathcal N}_\tau
\left[\mathrm{e}^{i\frac\tau2\partial_x^2}\big(\Pi_\tau +\mathrm{e}^{-2\pi
i\lambda M_0\tau}\Pi^\tau \big)u^n\right], \end{align*} with ${\mathcal
N}_t(\phi)=\mathrm{e}^{-i\lambda t|\Pi_\tau\phi|^2}\phi,$ and $M_0$ is the mass
of the initial data. Suitably choosing the filters $\Pi_\tau$ and $\Pi^\tau$,
it is shown rigorously that it reaches the first-order accuracy by only losing
$\frac32$-spatial derivatives. Moreover, if $\gamma\in (0,1)$, the new method
presents the convergence rate of $\tau^{\frac{4\gamma}{4+\gamma}}$ in
$L^2$-norm for the $H^\gamma$-data; if $\gamma\in [1,2]$, it presents the
convergence rate of $\tau^{\frac25(1+\gamma)-}$ in $L^2$-norm for the
$H^\gamma$-data. %In particular, the regularity requirement of the initial data
for the first-order convergence in $L^2$-norm is only $H^{\frac32+}$. These
results are better than the expected ones for the standard (filtered) Strang
splitting methods. Moreover, the mass is conserved: $$\frac1{2\pi}\int_{\mathbb
T} |u^n(x)|^2\,d x\equiv M_0, \quad n=0,1,\ldots, L . $$ The key idea is based
on the observation that the low frequency and high frequency components of
solutions are almost separated (up to some smooth components). Then the
algorithm is constructed by tracking the solution behavior at the low and high
frequency components separately.",-0.06173772,-0.26250556,-0.044088952,B
15296,"To further study
the higher order methods, we present more detailed space-time convergence results
for the case k = 3 in Tables 4.1 and 4.2.",Section 4.1.,"We observe optimal order convergence on the
space-time diagonal.",2022-12-22 20:44:26+00:00,An Accurate and Robust Eulerian Finite Element Method for Partial Differential Equations on Evolving Surfaces,math.NA,"['math.NA', 'cs.NA', '65M60, 65M12', 'G.1.8']","[arxiv.Result.Author('Hauke Sass'), arxiv.Result.Author('Arnold Reusken')]","In this paper we present a new Eulerian finite element method for the
discretization of scalar partial differential equations on evolving surfaces.
In this method we use the restriction of standard space-time finite element
spaces on a fixed bulk mesh to the space-time surface. The structure of the
method is such that it naturally fits to a level set representation of the
evolving surface. The higher order version of the method is based on a
space-time variant of a mesh deformation that has been developed in the
literature for stationary surfaces. The discretization method that we present
is of (optimal) higher order accuracy for smoothly varying surfaces with
sufficiently smooth solutions. Without any modifications the method can be used
for the discretization of problems with topological singularities. A numerical
study demonstrates both the higher order accuracy for smooth cases and the
robustness with respect to toplogical singularities.",-0.08456521,-0.2762283,-0.04635518,B
