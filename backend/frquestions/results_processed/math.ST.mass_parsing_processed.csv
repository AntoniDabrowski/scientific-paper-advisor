Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
408,We discuss now possible avenues for further research.,"We stress that the present work is to be considered only
as the ﬁrst step towards using the tools from TDA to develop statistical tests for slice-based datasets.","First, motivated by the shape of the speciﬁc dataset, we established the asymptotic normality for
domains that are largein the x- and y-direction but are ﬁxed in the z-direction.",2022-01-11 17:26:41+00:00,Topology-based goodness-of-fit tests for sliced spatial data,math.ST,"['math.ST', 'cs.CG', 'math.AT', 'stat.TH', '60F05']","[arxiv.Result.Author('Alessandra Cipriani'), arxiv.Result.Author('Christian Hirsch'), arxiv.Result.Author('Martina Vittorietti')]","In materials science and many other application domains, 3D information can
often only be extrapolated by taking 2D slices. In topological data analysis,
persistence vineyards have emerged as a powerful tool to take into account
topological features stretching over several slices. In the present paper, we
illustrate how persistence vineyards can be used to design rigorous statistical
hypothesis tests for 3D microstructure models based on data from 2D slices.
More precisely, by establishing the asymptotic normality of suitable
longitudinal and cross-sectional summary statistics, we devise goodness-of-fit
tests that become asymptotically exact in large sampling windows. We illustrate
the testing methodology through a detailed simulation study and provide a
prototypical example from materials science.",-0.12730187,-0.021145023,-0.14307755,B
1204,"But it can be

reasonably conjectured and deserves further study.","Thus the optimal rate of divergence of p is

still unknown for our weighted residual empirical process with random design.",Remark 1.,2022-01-29 09:31:45+00:00,"Weighted residual empirical processes, martingale transformations and model checking for regressions",math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Falong Tan'), arxiv.Result.Author('Xu Guo'), arxiv.Result.Author('Lixing Zhu')]","In this paper we propose a new methodology for testing the parametric forms
of the mean and variance functions based on weighted residual empirical
processes and their martingale transformations in regression models. The
dimensions of the parameter vectors can be divergent as the sample size goes to
infinity. We then study the convergence of weighted residual empirical
processes and their martingale transformation under the null and alternative
hypotheses in the diverging dimension setting. The proposed tests based on
weighted residual empirical processes can detect local alternatives distinct
from the null at the fastest possible rate of order $n^{-1/2}$ but are not
asymptotically distribution-free. While the tests based on martingale
transformed weighted residual empirical processes can be asymptotically
distribution-free, yet, unexpectedly, can only detect the local alternatives
converging to the null at a much slower rate of order $n^{-1/4}$, which is
somewhat different from existing asymptotically distribution-free tests based
on martingale transformations. As the tests based on the residual empirical
process are not distribution-free, we propose a smooth residual bootstrap and
verify the validity of its approximation in diverging dimension settings.
Simulation studies and a real data example are conducted to illustrate the
effectiveness of our tests.",-0.31980526,-0.09356468,-0.023768917,B
1205,"This is beyond the scope of this paper and
deserves further research.","Thus we conjecture that the classic residual bootstrap is still valid when
the dimension of the parameter vector diverges.","22
Table 1: Empirical sizes and powers of T CvMnd and T CvMn for H11 with diﬀerent bandwidths.",2022-01-29 09:31:45+00:00,"Weighted residual empirical processes, martingale transformations and model checking for regressions",math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Falong Tan'), arxiv.Result.Author('Xu Guo'), arxiv.Result.Author('Lixing Zhu')]","In this paper we propose a new methodology for testing the parametric forms
of the mean and variance functions based on weighted residual empirical
processes and their martingale transformations in regression models. The
dimensions of the parameter vectors can be divergent as the sample size goes to
infinity. We then study the convergence of weighted residual empirical
processes and their martingale transformation under the null and alternative
hypotheses in the diverging dimension setting. The proposed tests based on
weighted residual empirical processes can detect local alternatives distinct
from the null at the fastest possible rate of order $n^{-1/2}$ but are not
asymptotically distribution-free. While the tests based on martingale
transformed weighted residual empirical processes can be asymptotically
distribution-free, yet, unexpectedly, can only detect the local alternatives
converging to the null at a much slower rate of order $n^{-1/4}$, which is
somewhat different from existing asymptotically distribution-free tests based
on martingale transformations. As the tests based on the residual empirical
process are not distribution-free, we propose a smooth residual bootstrap and
verify the validity of its approximation in diverging dimension settings.
Simulation studies and a real data example are conducted to illustrate the
effectiveness of our tests.",-0.291547,0.014308221,0.07913581,C
1378,"A lead for further research would be to consider such wider classes
of algorithms, for which various stability hypotheses replace advantageously the assumption
of ﬁnite VC dimension (see e.g.","2013, where the variance of the K-fold CV is shown to be K-times smaller than
that of the empirical risk.","Kearns and Ron 1999; Bousquet and Elisseeﬀ 2001, 2002).",2022-02-01 15:40:53+00:00,Cross Validation for Rare Events,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Anass Aghbalou'), arxiv.Result.Author('Patrice Bertail'), arxiv.Result.Author('François Portier'), arxiv.Result.Author('Anne Sabourin')]","We derive sanity-check bounds for the cross-validation (CV) estimate of the
generalization risk for learning algorithms dedicated to extreme or rare
events. We consider classification on extreme regions of the covariate space, a
problem analyzed in Jalalzai et al. 2018. The risk is then a probability of
error conditional to the norm of the covariate vector exceeding a high
quantile. Establishing sanity-check bounds consist in recovering bounds
regarding the CV estimate that are of the same nature as the ones regarding the
empirical risk. We achieve this goal both for K-fold CV with an exponential
bound and for leave-p-out CV with a polynomial bound, thus extending the
state-of-the-art results to the modified version of the risk which is adapted
to extreme value analysis.",-0.21160804,0.036540687,-0.0180655,C
1392,"It is interesting to further study the above posterior distributions for the particular
cases where the mixing density (i.e., V or K) of the MMN model is of the form

                                        g(k) ∝ e−c1k2/2−c2k I(0,∞)(k),                         (3.22)

with c1 > 0, c2 ∈ R or c1 = 0, c2 > 0.",Example 3.3.,"Several of these distributions were presented in Example 2.1,
but we recall that the cases c1 > 0 for instance, which correspond to truncated normal distributions
on (0, ∞), lead to skew-normal densities (2.4) for c2 = 0.",2022-02-01 18:22:37+00:00,Bayesian inference and prediction for mean-mixtures of normal distributions,math.ST,"['math.ST', 'stat.TH', '62C20, 62C25 (Primary), 62C10 (Secondary)']","[arxiv.Result.Author('Pankaj Bhagwat'), arxiv.Result.Author('Eric Marchand')]","We study frequentist risk properties of predictive density estimators for
mean mixtures of multivariate normal distributions, involving an unknown
location parameter $\theta \in \mathbb{R}^d$, and which include multivariate
skew normal distributions. We provide explicit representations for Bayesian
posterior and predictive densities, including the benchmark minimum risk
equivariant (MRE) density, which is minimax and generalized Bayes with respect
to an improper uniform density for $\theta$. For four dimensions or more, we
obtain Bayesian densities that improve uniformly on the MRE density under
Kullback-Leibler loss. We also provide plug-in type improvements, investigate
implications for certain type of parametric restrictions on $\theta$, and
illustrate and comment the findings based on numerical evaluations.",-0.2572877,0.042684108,-0.2742389,B
1564,"As supported by both
theoretical guarantees and empirical supports, we believe that the (M, k)-NN rules, especially for k = 1, can
be widely deployed in practical systems and deserve further study including an optimally weighted version of
the classiﬁer as studied in (Duan et al., 2020).","We also removed the logarithmic factors by the distance-selective aggregation and exhibited some
level of performance boost in experimental results; it is an open question whether the logarithmic factor is
fundamental for the vanilla (M, k)-NN rules or can be removed by a tighter analysis.","We conclude with remarks on a seeming connection between the proposed distance-selective aggregation
and the k-NN based outlier detection methods.",2022-02-05 01:59:09+00:00,One-Nearest-Neighbor Search is All You Need for Minimax Optimal Regression and Classification,math.ST,"['math.ST', 'cs.DC', 'cs.IT', 'cs.LG', 'math.IT', 'stat.TH']","[arxiv.Result.Author('J. Jon Ryu'), arxiv.Result.Author('Young-Han Kim')]","Recently, Qiao, Duan, and Cheng~(2019) proposed a distributed
nearest-neighbor classification method, in which a massive dataset is split
into smaller groups, each processed with a $k$-nearest-neighbor classifier, and
the final class label is predicted by a majority vote among these groupwise
class labels. This paper shows that the distributed algorithm with $k=1$ over a
sufficiently large number of groups attains a minimax optimal error rate up to
a multiplicative logarithmic factor under some regularity conditions, for both
regression and classification problems. Roughly speaking, distributed
1-nearest-neighbor rules with $M$ groups has a performance comparable to
standard $\Theta(M)$-nearest-neighbor rules. In the analysis, alternative rules
with a refined aggregation method are proposed and shown to attain exact
minimax optimal rates.",-0.09418697,-0.04011397,-0.007357989,C
1565,"As supported by both theoretical guarantees
and empirical supports, we believe that the (M, k)-NN rules, especially for k = 1, can be widely deployed
in practical systems and deserve further study including an optimally weighted version of the classiﬁer as
studied in (Duan et al., 2020).","We also
removed the logarithmic factors by the distance-selective aggregation and exhibited some level of performance
boost in experimental results; it is an open question whether the logarithmic factor is fundamental for the
vanilla (M, k)-NN rules or can be removed by a tighter analysis.","It would be also interesting if the current divide-and-conquer framework
can be modiﬁed to be universally consistent for any general metric space, whenever such a consistent rule
exists (Hanneke et al., 2020; Gy¨orﬁ & Weiss, 2021).",2022-02-05 01:59:09+00:00,One-Nearest-Neighbor Search is All You Need for Minimax Optimal Regression and Classification,math.ST,"['math.ST', 'cs.DC', 'cs.IT', 'cs.LG', 'math.IT', 'stat.TH']","[arxiv.Result.Author('J. Jon Ryu'), arxiv.Result.Author('Young-Han Kim')]","Recently, Qiao, Duan, and Cheng~(2019) proposed a distributed
nearest-neighbor classification method, in which a massive dataset is split
into smaller groups, each processed with a $k$-nearest-neighbor classifier, and
the final class label is predicted by a majority vote among these groupwise
class labels. This paper shows that the distributed algorithm with $k=1$ over a
sufficiently large number of groups attains a minimax optimal error rate up to
a multiplicative logarithmic factor under some regularity conditions, for both
regression and classification problems. Roughly speaking, distributed
1-nearest-neighbor rules with $M$ groups has a performance comparable to
standard $\Theta(M)$-nearest-neighbor rules. In the analysis, alternative rules
with a refined aggregation method are proposed and shown to attain exact
minimax optimal rates.",-0.020439822,0.07364541,0.09698608,C
2731,The spectrahedra we have identiﬁed deserve further study.,"These include linear
concentration models such as Gaussian models on undirected graphs as well as Gaussian
models on DAGs.","The case of bivariate correlation models is quite interesting since they provide the ﬁrst small
instance where logarithmic Voronoi cells need not have to be semi-algebraic.",2022-03-03 02:24:21+00:00,Logarithmic Voronoi Cells for Gaussian Models,math.ST,"['math.ST', 'math.AG', 'math.MG', 'stat.TH', '62R01, 52A40']","[arxiv.Result.Author('Yulia Alexandr'), arxiv.Result.Author('Serkan Hoşten')]","We extend the theory of logarithmic Voronoi cells to Gaussian statistical
models. In general, a logarithmic Voronoi cell at a point on a Gaussian model
is a convex set contained in its log-normal spectrahedron. We show that for
models of ML degree one and linear covariance models the two sets coincide. In
particular, they are equal for both directed and undirected graphical models.
We introduce decomposition theory of logarithmic Voronoi cells for the latter
family. We also study covariance models, for which logarithmic Voronoi cells
are, in general, strictly contained in log-normal spectrahedra. We give an
explicit description of logarithmic Voronoi cells for the bivariate correlation
model and show that they are semi-algebraic sets. Finally, we state a
conjecture that logarithmic Voronoi cells for unrestricted correlation models
are not semi-algebraic.",-0.23335004,0.5547707,-0.25268734,C
2732,The spectrahedra we have identiﬁed deserve further study.,"These include linear
concentration models such as Gaussian models on undirected graphs as well as Gaussian
models on DAGs.","The case of bivariate correlation models is quite interesting since they provide the ﬁrst small
instance where logarithmic Voronoi cells need not have to be semi-algebraic.",2022-03-03 02:24:21+00:00,Logarithmic Voronoi Cells for Gaussian Models,math.ST,"['math.ST', 'math.AG', 'math.MG', 'stat.TH', '62R01, 52A40']","[arxiv.Result.Author('Yulia Alexandr'), arxiv.Result.Author('Serkan Hoşten')]","We extend the theory of logarithmic Voronoi cells to Gaussian statistical
models. In general, a logarithmic Voronoi cell at a point on a Gaussian model
is a convex set contained in its log-normal spectrahedron. We show that for
models of ML degree one and linear covariance models the two sets coincide. In
particular, they are equal for both directed and undirected graphical models.
We introduce decomposition theory of logarithmic Voronoi cells for the latter
family. We also study covariance models, for which logarithmic Voronoi cells
are, in general, strictly contained in log-normal spectrahedra. We give an
explicit description of logarithmic Voronoi cells for the bivariate correlation
model and show that they are semi-algebraic sets. Finally, we state a
conjecture that logarithmic Voronoi cells for unrestricted correlation models
are not semi-algebraic.",-0.23335004,0.5547707,-0.25268734,C
2733,The spectrahedra we have identiﬁed deserve further study.,"These include linear
concentration models such as Gaussian models on undirected graphs as well as Gaussian
models on DAGs.","The case of bivariate correlation models is quite interesting since they provide the ﬁrst small
instance where logarithmic Voronoi cells need not have to be semi-algebraic.",2022-03-03 02:24:21+00:00,Logarithmic Voronoi Cells for Gaussian Models,math.ST,"['math.ST', 'math.AG', 'math.MG', 'stat.TH', '62R01, 52A40']","[arxiv.Result.Author('Yulia Alexandr'), arxiv.Result.Author('Serkan Hoşten')]","We extend the theory of logarithmic Voronoi cells to Gaussian statistical
models. In general, a logarithmic Voronoi cell at a point on a Gaussian model
is a convex set contained in its log-normal spectrahedron. We show that for
models of ML degree one and linear covariance models the two sets coincide. In
particular, they are equal for both directed and undirected graphical models.
We introduce decomposition theory of logarithmic Voronoi cells for the latter
family. We also study covariance models, for which logarithmic Voronoi cells
are, in general, strictly contained in log-normal spectrahedra. We give an
explicit description of logarithmic Voronoi cells for the bivariate correlation
model and show that they are semi-algebraic sets. Finally, we prove that
boundaries of logarithmic Voronoi cells for unrestricted correlation models
cannot be described by polynomials over $\bar{\mathbb{Q}}$.",-0.23335004,0.5547707,-0.25268734,C
2734,The spectrahedra we have identiﬁed deserve further study.,"These include linear
concentration models such as Gaussian models on undirected graphs as well as Gaussian
models on DAGs.","The case of bivariate correlation models is quite interesting since they provide the ﬁrst small
instance where logarithmic Voronoi cells need not have to be semi-algebraic.",2022-03-03 02:24:21+00:00,Logarithmic Voronoi Cells for Gaussian Models,math.ST,"['math.ST', 'math.AG', 'math.MG', 'stat.TH', '62R01, 52A40']","[arxiv.Result.Author('Yulia Alexandr'), arxiv.Result.Author('Serkan Hoşten')]","We extend the theory of logarithmic Voronoi cells to Gaussian statistical
models. In general, a logarithmic Voronoi cell at a point on a Gaussian model
is a convex set contained in its log-normal spectrahedron. We show that for
models of ML degree one and linear covariance models the two sets coincide. In
particular, they are equal for both directed and undirected graphical models.
We introduce decomposition theory of logarithmic Voronoi cells for the latter
family. We also study covariance models, for which logarithmic Voronoi cells
are, in general, strictly contained in log-normal spectrahedra. We give an
explicit description of logarithmic Voronoi cells for the bivariate correlation
model and show that they are semi-algebraic sets. Finally, we state a
conjecture that logarithmic Voronoi cells for unrestricted correlation models
are not semi-algebraic.",-0.23335004,0.5547707,-0.25268734,C
2983,"In addition

to the 2-norm statistic, we ﬁnd that the obtained results can be easily extended towards alternative forms

of the statistic, e.g., by using a diﬀerent norm, which would reduce the problem to manipulating variance-

gamma distribution, thus suggesting possible further research cases and useful extensions.","In our paper we

approach the problem following an observation by Gaunt (2013), that the distribution of product of Gaussian

random variables admits a variance-gamma distribution, resulting in a set of attractive properties.","Additionally, we examine a speciﬁc case of parameter β by considering βj = j−1, j ≥ 1.",2022-03-08 15:30:56+00:00,Asymptotic normality in linear regression with approximately sparse structure,math.ST,"['math.ST', 'math.PR', 'stat.TH', '60F05, 62E20, 62J99']","[arxiv.Result.Author('Saulius Jokubaitis'), arxiv.Result.Author('Remigijus Leipus')]","In this paper we study the asymptotic normality in high-dimensional linear
regression. We focus on the case where the covariance matrix of the regression
variables has a KMS structure, in asymptotic settings where the number of
predictors, $p$, is proportional to the number of observations, $n$. The main
result of the paper is the derivation of the exact asymptotic distribution for
the suitably centered and normalized squared norm of the product between
predictor matrix, $\mathbb{X}$, and outcome variable, $Y$, i.e. the statistic
$\|\mathbb{X}'Y\|_{2}^{2}$. Additionally, we consider a specific case of
approximate sparsity of the model parameter vector $\beta$ and perform a
Monte-Carlo simulation study. The simulation results suggest that the statistic
approaches the limiting distribution fairly quickly even under high variable
multi-correlation and relatively small number of observations, suggesting
possible applications to the construction of statistical testing procedures for
the real-world data and related problems.",-0.20823719,-0.19268852,-0.17393284,B
3168,"The search for such criteria will be the
subject of further research by the authors.","On the one hand, this restrictiveness limits the practical applica-
bility of the obtained academic results; on the other, it suggests the that better criteria,
applicable in more cases, may be determined.",6.,2022-03-11 19:55:29+00:00,Some Notes on the Similarity of Priority Vectors Derived by the Eigenvalue Method and the Geometric Mean Method,math.ST,"['math.ST', 'cs.DM', 'stat.TH']","[arxiv.Result.Author('Jiří Mazurek'), arxiv.Result.Author('Konrad Kułakowski'), arxiv.Result.Author('Sebastian Ernst'), arxiv.Result.Author('Michał Strada')]","The aim of this paper is to examine the differences in ordinal rankings
obtained from a pairwise comparison matrix using the eigenvalue method and the
geometric mean method. We introduce several propositions on the (dis)similarity
of both rankings with respect to the matrix size and its inconsistency
expressed by the Koczkodaj's inconsistency index. Further on, we examine the
relationship between differences in both rankings and Kendall's rank
correlation coefficient \(\tau\) and Spearman's rank coefficient \(\rho\).
Apart from theoretical results, intuitive numerical examples and Monte Carlo
simulations are provided as well.",-0.0068609696,0.06250743,0.099606544,B
3169,"The search for such
criteria will be the subject of further research by the authors.","This restrictiveness limits the
practical applicability of the obtained academic results; on the other, it suggests the
that better criteria, applicable in more cases, may be determined.","Acknowledgements

Jiří Mazurek was supported by the Czech Grant Agency (GACR) no.",2022-03-11 19:55:29+00:00,Some Notes on the Similarity of Priority Vectors Derived by the Eigenvalue Method and the Geometric Mean Method,math.ST,"['math.ST', 'cs.DM', 'stat.TH']","[arxiv.Result.Author('Jiří Mazurek'), arxiv.Result.Author('Konrad Kułakowski'), arxiv.Result.Author('Sebastian Ernst'), arxiv.Result.Author('Michał Strada')]","This paper examines the differences in ordinal rankings obtained from a
pairwise comparison matrix using the eigenvalue method and the geometric mean
method. First, we introduce several propositions on the (dis)similarity of both
rankings concerning the matrix size and its inconsistency expressed by the
Koczkodaj's inconsistency index. Further on, we examine the relationship
between differences in both rankings and Kendall's rank correlation coefficient
$\tau$ and Spearman's rank coefficient $\rho$. Apart from theoretical results,
intuitive numerical examples and Monte Carlo simulations are also provided.",-0.00022927299,0.10249391,0.0045712832,B
3381,"Because the family of GP(γ) with γ ∈ R is not in the

exponential class this question is left to further research.","Since the estimator Un3,∗ is
also a function of the entire sample, it is an open question whether the estimator
Un3,∗ is the uniformly minimum variance unbiased estimator (UMVUE) for γ of
the GP(γ) distribution.","Finally, note that a U-statistic may also be calculated based on all exceedances

over a high threshold.",2022-03-16 09:58:12+00:00,Tail inference using extreme U-statistics,math.ST,"['math.ST', 'stat.TH', '62G32']","[arxiv.Result.Author('Jochem Oorschot'), arxiv.Result.Author('Johan Segers'), arxiv.Result.Author('Chen Zhou')]","Extreme U-statistics arise when the kernel of a U-statistic has a high degree
but depends only on its arguments through a small number of top order
statistics. As the kernel degree of the U-statistic grows to infinity with the
sample size, estimators built out of such statistics form an intermediate
family in between those constructed in the block maxima and
peaks-over-threshold frameworks in extreme value analysis. The asymptotic
normality of extreme U-statistics based on location-scale invariant kernels is
established. Although the asymptotic variance corresponds with the one of the
H\'ajek projection, the proof goes beyond considering the first term in
Hoeffding's variance decomposition; instead, a growing number of terms needs to
be incorporated in the proof.
  To show the usefulness of extreme U-statistics, we propose a kernel depending
on the three highest order statistics leading to an unbiased estimator of the
shape parameter of the generalized Pareto distribution. When applied to samples
in the max-domain of attraction of an extreme value distribution, the extreme
U-statistic based on this kernel produces a location-scale invariant estimator
of the extreme value index which is asymptotically normal and whose
finite-sample performance is competitive with that of the pseudo-maximum
likelihood estimator.",-0.14300972,-0.1512298,-0.025070999,B
3561,"Classic results in matrix perturbation include Weyl’s and Lidskii inequalities [81, 122] for

eigenvalues and singular values, and the Davis–Kahan Theorem and Wedin’s Theorem [38,

121, 128] for subspaces; these results make minimal assumptions on the perturbation matrices

E. The last decade has witnessed further study of matrix perturbations from more statistical

perspectives through the introduction of additional minor assumptions on E and M such as

the entries of E are independent random variables and/or the leading singular vectors of M

has bounded coherence.","As Mˆ
is a noisy realization of M, Uˆ is a noisy estimate of U, the leading singular vectors of M.
Under this perspective, the main aim is now to understand the relationship between Uˆ g and
U, and we thus need to balance between the approximation error of Uˆ g and the estimation
error of Uˆ , i.e., it is neither necessary nor beneﬁcial to make the approximation error between
Uˆ g and Uˆ much smaller than the estimation error between Uˆ and U.

   Estimation errors between Uˆ and U is a fundamental topic in matrix perturbation theory.","Examples include more reﬁned matrix concentration inequalities [5,

94, 105, 114], rate-optimal unilateral singular subspace perturbation bound [17], and 2→∞
singular subspace perturbation bounds [3, 21, 22, 46, 51, 76, 85].",2022-03-19 07:26:45+00:00,Perturbation Analysis of Randomized SVD and its Applications to High-dimensional Statistics,math.ST,"['math.ST', 'cs.NA', 'math.NA', 'stat.CO', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Yichi Zhang'), arxiv.Result.Author('Minh Tang')]","Randomized singular value decomposition (RSVD) is a class of computationally
efficient algorithms for computing the truncated SVD of large data matrices.
Given a $n \times n$ symmetric matrix $\mathbf{M}$, the prototypical RSVD
algorithm outputs an approximation of the $k$ leading singular vectors of
$\mathbf{M}$ by computing the SVD of $\mathbf{M}^{g} \mathbf{G}$; here $g \geq
1$ is an integer and $\mathbf{G} \in \mathbb{R}^{n \times k}$ is a random
Gaussian sketching matrix. In this paper we study the statistical properties of
RSVD under a general ""signal-plus-noise"" framework, i.e., the observed matrix
$\hat{\mathbf{M}}$ is assumed to be an additive perturbation of some true but
unknown signal matrix $\mathbf{M}$. We first derive upper bounds for the
$\ell_2$ (spectral norm) and $\ell_{2\to\infty}$ (maximum row-wise $\ell_2$
norm) distances between the approximate singular vectors of $\hat{\mathbf{M}}$
and the true singular vectors of the signal matrix $\mathbf{M}$. These upper
bounds depend on the signal-to-noise ratio (SNR) and the number of power
iterations $g$. A phase transition phenomenon is observed in which a smaller
SNR requires larger values of $g$ to guarantee convergence of the $\ell_2$ and
$\ell_{2\to\infty}$ distances. We also show that the thresholds for $g$ where
these phase transitions occur are sharp whenever the noise matrices satisfy a
certain trace growth condition. Finally, we derive normal approximations for
the row-wise fluctuations of the approximate singular vectors and the entrywise
fluctuations of the approximate matrix. We illustrate our theoretical results
by deriving nearly-optimal performance guarantees for RSVD when applied to
three statistical inference problems, namely, community detection, matrix
completion, and principal component analysis with missing data.",-0.31875905,0.1462015,0.085954085,C
3562,"Classic results in matrix perturbation include Weyl’s and Lidskii’s inequalities [80, 123] for
4

eigenvalues and singular values, and the Davis–Kahan Theorem and Wedin’s Theorem [38,

122, 129] for subspaces; these results make minimal assumptions on the perturbation matrices

E. The last decade has witnessed further study of matrix perturbations from more statistical

perspectives through the introduction of additional minor assumptions on E and M such as

the entries of E are independent random variables and/or the leading singular vectors of M

has bounded coherence.","As Mˆ is a noisy realization
of M, Uˆ is a noisy estimate of U, the leading singular vectors of M. Under this perspective,
the main aim is now to understand the relationship between Uˆ g and U, and we thus need
to balance between the approximation error of Uˆ g and the estimation error of Uˆ , i.e., it is
neither necessary nor beneﬁcial to make the approximation error between Uˆ g and Uˆ much
smaller than the estimation error between Uˆ and U.

   Estimation errors between Uˆ and U is a fundamental topic in matrix perturbation theory.","Examples include more reﬁned matrix concentration inequalities [5,

93, 104, 115], rate-optimal unilateral singular subspace perturbation bound [17], and 2→∞
singular subspace perturbation bounds [3, 21, 22, 46, 51, 75, 84].",2022-03-19 07:26:45+00:00,Perturbation Analysis of Randomized SVD and its Applications to High-dimensional Statistics,math.ST,"['math.ST', 'cs.NA', 'math.NA', 'stat.CO', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Yichi Zhang'), arxiv.Result.Author('Minh Tang')]","Randomized singular value decomposition (RSVD) is a class of computationally
efficient algorithms for computing the truncated SVD of large data matrices.
Given a $n \times n$ symmetric matrix $\mathbf{M}$, the prototypical RSVD
algorithm outputs an approximation of the $k$ leading singular vectors of
$\mathbf{M}$ by computing the SVD of $\mathbf{M}^{g} \mathbf{G}$; here $g \geq
1$ is an integer and $\mathbf{G} \in \mathbb{R}^{n \times k}$ is a random
Gaussian sketching matrix. In this paper we study the statistical properties of
RSVD under a general ""signal-plus-noise"" framework, i.e., the observed matrix
$\hat{\mathbf{M}}$ is assumed to be an additive perturbation of some true but
unknown signal matrix $\mathbf{M}$. We first derive upper bounds for the
$\ell_2$ (spectral norm) and $\ell_{2\to\infty}$ (maximum row-wise $\ell_2$
norm) distances between the approximate singular vectors of $\hat{\mathbf{M}}$
and the true singular vectors of the signal matrix $\mathbf{M}$. These upper
bounds depend on the signal-to-noise ratio (SNR) and the number of power
iterations $g$. A phase transition phenomenon is observed in which a smaller
SNR requires larger values of $g$ to guarantee convergence of the $\ell_2$ and
$\ell_{2\to\infty}$ distances. We also show that the thresholds for $g$ where
these phase transitions occur are sharp whenever the noise matrices satisfy a
certain trace growth condition. Finally, we derive normal approximations for
the row-wise fluctuations of the approximate singular vectors and the entrywise
fluctuations of the approximate matrix. We illustrate our theoretical results
by deriving nearly-optimal performance guarantees for RSVD when applied to
three statistical inference problems, namely, community detection, matrix
completion, and principal component analysis with missing data.",-0.31350714,0.13670585,0.08014603,C
3576,Results and further research.,4.2.,"We provide p-values in the four tables on the next
page.",2022-03-19 22:59:23+00:00,IID Time Series Testing,math.ST,"['math.ST', 'stat.TH', '62G10, 62M10']",[arxiv.Result.Author('Andrey Sarantsev')],"Traditional white noise testing, for example the Ljung-Box test, studies only
the autocorrelation function. If its values are sufficiently close to zero, we
fail to reject the white noise hypothesis. This is often sufficient for classic
theory of linear time series models: autoregressions and moving averages.
However, condition of being independent identically distributed random
variables with fourth finite moment is stronger than white noise. Sometimes, it
is assumed in the models that the sequence is IID but it is tested only for
white noise. For example, heteroscedasticity in financial time series means
periods of high variance (financial crises) can alternate with periods of low
variance (calm times). Time series can be heteroscedastic and therefore not IID
but still white noise. Examples include stochastic volatility or GARCH models.
Indeed, in this case, absolute values or squares of time series terms are not
white noise. Classic white noise tests thus can fail to identify that the
sequence is not IID In this article we propose a new construction method for
tests which can capture heteroscedasticity. We create a flexible framework
generalizing Box-Pierce and Ljung-Box omnibus tests. We apply tests to
simulated data, both autoregressive and heteroscedastic.",-0.097840115,-0.18648858,0.026265556,B
3772,"Hence, further study of e-CIs would improve the utility of the e-BY procedure.","[21] have shown that e-CIs are nearly
admissible.","Acknowledgements We would like to thank Umashanthi Pavalanathan and Luke Sonnet for
insightful discussions about the application of post-selection inference to A/B testing and their help
in gathering and releasing the data from Twitter used in our experiments.",2022-03-23 17:32:35+00:00,Post-selection inference for e-value based confidence intervals,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Ziyu Xu'), arxiv.Result.Author('Ruodu Wang'), arxiv.Result.Author('Aaditya Ramdas')]","Suppose that one can construct a valid $(1-\delta)$-confidence interval (CI)
for each of $K$ parameters of potential interest. If a data analyst uses an
arbitrary data-dependent criterion to select some subset $\mathcal{S}$ of
parameters, then the aforementioned CIs for the selected parameters are no
longer valid due to selection bias. We design a new method to adjust the
intervals in order to control the false coverage rate (FCR). The main
established method is the ""BY procedure"" by Benjamini and Yekutieli (JASA,
2005). Unfortunately, the BY guarantees require certain restrictions on the the
selection criterion and on the dependence between the CIs. We propose a natural
and much simpler method which is valid under any dependence structure between
the original CIs, and any (unknown) selection criterion, but which only applies
to a special, yet broad, class of CIs. Our procedure reports
$(1-\delta|\mathcal{S}|/K)$-CIs for the selected parameters, and we prove that
it controls the FCR at $\delta$ for confidence intervals that implicitly invert
e-values; examples include those constructed via supermartingale methods, or
via universal inference, or via Chernoff-style bounds on the moment generating
function, among others. The e-BY procedure is admissible, and recovers the BY
procedure as a special case via calibration. Our work also has implications for
post-selection inference in sequential settings, since it applies at stopping
times, to continuously-monitored confidence sequences, and under bandit
sampling.",0.15884781,-0.18921816,-0.09011188,B
4458,"To further study an inﬂuence of the kernel rule, we consider the Gaussian kernel.",The red vertical line displays the point c0 = 0.04.,"The associated numerical
illustrations are provided in Figure 4 for X ∼ U ([−5, 5]) and for X ∼ N (0, 1.5).",2022-04-06 11:01:10+00:00,Adaptive warped kernel estimation for nonparametric regression with circular responses,math.ST,"['math.ST', 'stat.TH', '62G05, 62G08, 62H11']","[arxiv.Result.Author('Tien Dat Nguyen'), arxiv.Result.Author('Thanh Mai Pham Ngoc'), arxiv.Result.Author('Vincent Rivoirard')]","In this paper, we deal with nonparametric regression for circular data,
meaning that observations are represented by points lying on the unit circle.
We propose a kernel estimation procedure with data-driven selection of the
bandwidth parameter. For this purpose, we use a warping strategy combined with
a Goldenshluger-Lepski type estimator. To study optimality of our methodology,
we consider the minimax setting and prove, by establishing upper and lower
bounds, that our procedure is nearly optimal on anisotropic Holder classes of
functions for pointwise estimation. The obtained rates also reveal the specific
nature of regression for circular responses. Finally, a numerical study is
conducted, illustrating the good performances of our approach.",-0.3377643,0.14027463,0.052833635,C
4743,Section 5 concludes the main text by discussing further research directions.,"Next, we apply the results to three exam-
ples in Section 4.",The proofs of the high-level results and their suﬃcient conditions are in the Appendix.,2022-04-12 13:19:34+00:00,High-dimensional nonconvex lasso-type $M$-estimators,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Jad Beyhum'), arxiv.Result.Author('François Portier')]","This paper proposes a theory for $\ell_1$-norm penalized high-dimensional
$M$-estimators, with nonconvex risk and unrestricted domain. Under high-level
conditions, the estimators are shown to attain the rate of convergence
$s_0\sqrt{\log(nd)/n}$, where $s_0$ is the number of nonzero coefficients of
the parameter of interest. Sufficient conditions for our main assumptions are
then developed and finally used in several examples including robust linear
regression, binary classification and nonlinear least squares.",-0.029297197,-0.16758622,0.23916239,C
4744,Section 5 concludes the main text by discussing further research directions.,"Next, we apply the results to three exam-
ples in Section 4.",The proofs of the high-level results and their suﬃcient conditions are in the Appendix.,2022-04-12 13:19:34+00:00,High-dimensional nonconvex lasso-type $M$-estimators,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Jad Beyhum'), arxiv.Result.Author('François Portier')]","This paper proposes a theory for $\ell_1$-norm penalized high-dimensional
$M$-estimators, with nonconvex risk and unrestricted domain. Under high-level
conditions, the estimators are shown to attain the rate of convergence
$s_0\sqrt{\log(nd)/n}$, where $s_0$ is the number of nonzero coefficients of
the parameter of interest. Sufficient conditions for our main assumptions are
then developed and finally used in several examples including robust linear
regression, binary classification and nonlinear least squares.",-0.029297197,-0.16758622,0.23916239,C
5176,"We summarize our results and discuss further research questions in
Section 4.","In Section 2.3 we provide simple
suﬃcient conditions that we can be used to apply our general theorems to the examples
presented in Section 3.","The proofs for the minimax lower and upper bounds are presented in Section 5,
while in Section 6 we demonstrate the validity of our suﬃcient conditions.",2022-04-21 19:04:50+00:00,Distributed Nonparametric Estimation under Communication Constraints,math.ST,"['math.ST', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Azeem Zaman'), arxiv.Result.Author('Botond Szabó')]","In the era of big data, it is necessary to split extremely large data sets
across multiple computing nodes and construct estimators using the distributed
data. When designing distributed estimators, it is desirable to minimize the
amount of communication across the network because transmission between
computers is slow in comparison to computations in a single computer. Our work
provides a general framework for understanding the behavior of distributed
estimation under communication constraints for nonparametric problems. We
provide results for a broad class of models, moving beyond the Gaussian
framework that dominates the literature. As concrete examples we derive minimax
lower and matching upper bounds in the distributed regression, density
estimation, classification, Poisson regression and volatility estimation models
under communication constraints. To assist with this, we provide sufficient
conditions that can be easily verified in all of our examples.",-0.20797324,-0.057795156,0.15904173,C
5553,"Some further researches may include providing the other estimators for the
reﬂected stochastic processes and investigating the statistical inference for the
other reﬂected diﬀusions.",Numerical results show that the NLSE works well with diﬀerent settings.,"References

  [1] Amemiya, T., 1973.",2022-04-30 03:18:46+00:00,Nonlinear Least Squares Estimator for Discretely Observed Reflected Stochastic Processes,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Han Yuecai'), arxiv.Result.Author('Zhang Dingwen')]","We study the problem of parameter estimation for reflected stochastic
processes driven by a standard Brownian motion. The estimator is obtained using
nonlinear least squares method based on discretely observed processes. Under
some certain conditions, we obtain the consistency and give the asymptotic
distribution of the estimator. Moreover, we briefly remark that our method can
be extended to the one-sided reflected stochastic processes spontaneously.
Numerical studies show that the proposed estimator is adequate for practical
use.",-0.2534022,-0.15281063,-0.20339862,B
5647,"Some further researches may include providing the other estimators for the
reﬂected stochastic processes and investigating the statistical inference for the
other reﬂected diﬀusions.","A simulation study is presented
to show that our estimators are adequate for practical use.","References

  [1] Amemiya, T., 1973.",2022-04-30 03:25:17+00:00,Drift parameter estimation for nonlinear reflected stochastic differential equations,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Han Yuecai'), arxiv.Result.Author('Zhang Dingwen')]","We study the maximum likehood estimator and least squares estimator for drift
parameters of nonlinear reflected stochastic differential equations based on
continuous observations. Under some regular conditions, we obtain the
consistency and give the asymptotic distributions of the two estimators. We
briefly remark that our methods could be applied the the reflected stochastic
processes with only one-sided reflecting barrier spontaneously. Numerical
studies show that the proposed estimators are adequate for practical use.",-0.23863888,-0.2642108,-0.26224765,B
5913,"Thus, in this section, we further study the behavior of the QF-CUSUM test Tn(t) under the context

of temporal dependence.","If b
is a suﬃciently small constant, we have

                                     lim inf inf sup E0(ψ) + EP (1 − ψ) → 1,

                                                   n,p→∞ ψ P ∈P1(b)

where P1(b) denotes the class of distributions satisfying Ha(b), E0(ψ) gives the type-I error of ψ
under H0 and EP (1 − ψ) gives the power of ψ when the observations are generated according to P.

3 QF-CUSUM under Temporal Dependence

In practice, temporal dependence is the norm rather than exception for sequentially observed data.","Speciﬁcally, we follow the β-mixing framework in Wong et al.",2022-05-08 14:19:19+00:00,Optimal Change-point Testing for High-dimensional Linear Models with Temporal Dependence,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Daren Wang'), arxiv.Result.Author('Zifeng Zhao')]","This paper studies change-point testing for high-dimensional linear models,
an important problem that is not well explored in the literature. Specifically,
we propose a quadratic-form-based cumulative sum~(CUSUM) test to inspect the
stability of the regression coefficients in a high-dimensional linear model.
The proposed test is able to control the type-I error at any desired level and
is theoretically sound for temporally dependent observations. We establish the
asymptotic distribution of the proposed test under both the null and
alternative hypotheses. Furthermore, we show that our test is asymptotically
powerful against multiple-change-point alternative hypotheses and achieves the
optimal detection boundary for a wide class of high-dimensional linear models.
Extensive numerical experiments and a real data application in macroeconomics
are conducted to demonstrate the promising performance and practical utility of
the proposed test. In addition, some new consistency results of the
Lasso~\citep{Tibshirani1996} are established under the change-point setting
with the presence of temporal dependence, which may be of independent interest.",-0.057580274,-0.028054535,-0.1513631,B
6019,"A rigorous proof
of this statement for MCAR/MCARMA processes is a topic for further research.","That is, as stated in G´omez (2019),
for p large enough, the VAR(p) model approaches a VARMA(p, q) model.","The
argument for assuming this to hold for MCAR/MCARMA processes as well, is that the
direct transformation relation between VARMA/MCARMA processes (see Theorem 1) is
derived by introducing no structural changes going from the discretized MCARMA process
to the VARMA process.",2022-05-10 12:05:30+00:00,The multivariate ARMA/CARMA transformation relation,math.ST,"['math.ST', 'math.PR', 'stat.TH']",[arxiv.Result.Author('Mari Dahl Eggen')],"A transformation relation between multivariate ARMA and CARMA processes is
derived through a discretization procedure. This gives a direct relationship
between the discrete time and continuous time analogues, serving as the basis
for an estimation method for multivariate CARMA models. We will see that the
autoregressive coefficients, making up the deterministic part of a multivariate
CARMA model, are entirely given by the transformation relation. An Euler
discretization convergence rate of jump diffusions is found for the case of
small jumps of infinite variation. This substantiates applying the
transformation relation for estimation of multivariate CARMA models driven by
NIG-L\'evy processes. A two-dimensional CAR model is fit to stratospheric
temperature and wind data, as an example of how to apply the transformation
relation in estimation methods.",-0.010727296,-0.055037796,-0.12102184,B
6276,Section 12 presents some topics for further research at the interface between Logic and Statistics.,"Section 11 considers the philosoph-
ical consequences of the aforementioned developments by brieﬂy commenting the Objective cognitive
constructivism epistemological framework, that was speciﬁcally developed to accomodate the formal
properties of the e-value and the FBST, and renders a naturalized approach to ontology and metaphysics.","One
of the objectives of this paper is to foster work at areas of interface or overlap between Logic and Statis-
tics and to stimulate greater cooperation between the two communities.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.675905,-0.11964773,0.029538479,A
6277,"During this workshop we discussed several topics for further research, most of them
motivated by areas of common interest that, nevertheless, are usually approached quite differently by
the communities of Logic and Statistics.","12 Future Research and Final Remarks

In December 2018, at CLE-UNICAMP, Walter Carnielli organized the workshop Induction, Probability
and their Dilemmas, where the ﬁrst author gave the presentation The Problem of Induction in Statis-
tical Science.",This section presents three of these topics.,2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.40147364,-0.40915865,0.12004979,A
6278,"In this context, it is a topic for further research to explore how much of this theory and
its applications can be expressed using the sentential probability approach, either by expanding the un-
derlying languages (like inﬁnitary, second order, or ﬁxed-point logics), see [62, 80, 81, 91, 92, 94, 96],
or by exploring relevant properties in speciﬁc statistical models (including topological properties, like
countability and compactness, and regularity conditions of constraints and distributions, like bounded
continuity and differentiability), see [26, 59, 72, 119, 132, 190].","Sections 6 and 7 sowed how the statistical deﬁnitions of the e-value and the GFBST characterize
their logical properties, and hinted on how arguments of mathematical analysis enable one to travel the
other way around.","Functional Compositionality Structures

As already noticed in Section 6, the compositional structure of e-values can be characterized as a pos-
sibilistic abstract belief calculus, as analyzed in [26, 26, 46, 47, 55, 57, 120, 206, 217].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.50311613,0.26561546,-0.07460351,A
6279,"Although this topic of further research can potentially beneﬁt of the all the sophisticated technical
developments and approaches to complexity theory already mentioned, it also requires a healthy dose
of critical thinking applied to the human condition in daily life, yet another area of interest of Walter’s
research group, see [37].","Na¨ıve adaptations of complexity mea-
sures artiﬁcially borrowed from other areas often fail to capture relevant aspects of the legal environ-
ment.","Acknowledgments

The authors take this opportunity to thank Prof. Walter Carnielli for, along the years, inviting, wel-
coming and stimulating investigations, discussions and interactions at the borders or areas of overlap
between logic, probability, statistics, formal methods in science, philosophy of science and general
philosophy.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.48194653,0.052827694,0.36728966,A
6280,"Section 12 presents some topics for further research at the interface between Logic
and Statistics.","Section 11 considers the philo-
sophical consequences of the aforementioned developments by brieﬂy commenting on the Objective
cognitive constructivism epistemological framework, which was speciﬁcally developed to accommo-
date the formal properties of the e-value and the FBST, and renders a naturalized approach to ontology
and metaphysics.","One of the objectives of this paper is to foster work in areas of interface or overlap be-
tween Logic and Statistics and to stimulate greater cooperation between the two communities.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.6732097,-0.10435495,0.02184017,A
6281,"During this workshop, we discussed several topics for further research, most of them
motivated by areas of common interest that, nevertheless, are usually approached quite differently by
the communities of Logic and Statistics.","12 Future Research and Final Remarks

In December 2018, at CLE-UNICAMP, Walter Carnielli organized the workshop Induction, Probability
and their Dilemmas, where the ﬁrst author gave the presentation The Problem of Induction in Statis-

                                                            13
tical Science.",This section presents four of these topics.,2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.38841927,-0.41857144,0.1183429,A
6282,"In this context, it is a topic for further research to explore how much of this theory and
its applications can be expressed using the sentential probability approach, either by expanding the un-
derlying languages (like inﬁnitary, second order, or ﬁxed-point logics), see [64, 82, 83, 93, 94, 96, 98],
or by exploring relevant properties in speciﬁc statistical models (including topological properties, like
countability and compactness, and regularity conditions of constraints and distributions, like bounded
continuity and differentiability), see [27, 61, 74, 121, 135, 192].","Sections 6 and 7 sowed how the statistical deﬁnitions of the e-value and the GFBST characterize
their logical properties, and hinted at how arguments of mathematical analysis enable one to travel the
other way around.","Functional Compositionality Structures

As already noticed in Section 6, the compositional structure of e-values can be characterized as a pos-
sibilistic abstract belief calculus, as analyzed in [27, 27, 47, 48, 56, 59, 122, 208, 219].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.50073576,0.27256376,-0.07090795,A
6283,"In this context, the tools of category theory or other formal abstraction
methods, see [36, 37, 77, 132, 204], offer an opportunity for further research in the study of basic log-
ical properties of the aforementioned systems, specially concerning the investigation of their essential
compositionality structures and possible generalizations.","While the many theoretical results
already obtained in this research program justify (in our opinion) the analogies we made and the con-
ceptual links we established between fragments of formal structures used in distinct (and often faraway)
research areas, we believe that these intuitive connections deserve and can beneﬁt from an even more
rigorous and general setting.","Rough and Fuzzy Sets

Essential logical properties of the GFBST can be explained regarding the e-value as a transformation
between probability and possibility measures, see [219].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.561407,0.25776756,-0.092163146,A
6284,"The underlying interconnections between
alternative representations of uncertainty at the core of this theory provide a general motivation to more
speciﬁc topics of further research presented in this section.","Rough and Fuzzy Sets

Essential logical properties of the GFBST can be explained regarding the e-value as a transformation
between probability and possibility measures, see [219].","In the GFBST framework, a sharp hypothesis can be either rejected or remain undecided, but can
never be accepted, see Section 7.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.53415096,0.17221862,-0.17115052,A
6285,"Although this topic of further research can potentially beneﬁt from all the sophisticated technical
developments and approaches to complexity theory already mentioned, it also requires a healthy dose

                                                            15
of critical thinking applied to the human condition in daily life, yet another area of interest of Walter’s
research group, see [38].","Na¨ıve
adaptations of complexity measures artiﬁcially borrowed from other areas often fail to capture relevant
aspects of the legal environment.","Acknowledgments

The authors take this opportunity to thank Prof. Walter Carnielli for, along the years, inviting, wel-
coming, and stimulating investigations, discussions, and interactions at the borders or areas of overlap
between logic, probability, statistics, formal methods in science, philosophy of science and general
philosophy.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.46874148,0.051101834,0.354106,A
6286,"Section 12 presents some topics for further research at the interface between Logic
and Statistics.","Section 11 considers the philo-
sophical consequences of the aforementioned developments by brieﬂy commenting on the Objective
cognitive constructivism epistemological framework, which was speciﬁcally developed to accommo-
date the formal properties of the e-value and the FBST, and renders a naturalized approach to ontology
and metaphysics.","One of the objectives of this paper is to foster work in areas of interface or overlap be-
tween Logic and Statistics and to stimulate greater cooperation between the two communities.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.6732097,-0.10435495,0.02184017,A
6287,"During this workshop, we discussed several topics for further research, most of them
motivated by areas of common interest that, nevertheless, are usually approached quite differently by
the communities of Logic and Statistics.","12 Future Research and Final Remarks

In December 2018, at CLE-UNICAMP, Walter Carnielli organized the workshop Induction, Probability
and their Dilemmas, where the ﬁrst author gave the presentation The Problem of Induction in Statis-

                                                            13
tical Science.",This section presents four of these topics.,2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.38841927,-0.41857144,0.1183429,A
6288,"In this context, it is a topic for further research to explore how much of this theory
and its applications can be expressed using the sentential probability approach, either by expanding
the underlying languages (like inﬁnitary, second order, or ﬁxed-point logics), see [138, 150, 151, 156,
157, 159, 161], or by exploring relevant properties in speciﬁc statistical models (including topological
properties, like countability and compactness, and regularity conditions of constraints and distributions,
like bounded continuity and differentiability), see [2, 10, 136, 145, 176, 199].","Sections 6 and 7 sowed how the statistical deﬁnitions of the e-value and the GFBST characterize
their logical properties, and hinted at how arguments of mathematical analysis enable one to travel the
other way around.","Functional Compositionality Structures

As already noticed in Section 6, the compositional structure of e-values can be characterized as a pos-
sibilistic abstract belief calculus, as analyzed in [2, 2, 24, 34, 127, 128, 131, 134, 171].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.49825358,0.27717087,-0.077098355,A
6289,"In this context, the tools of category theory or other formal abstraction
methods, see [122, 123, 147, 174, 205], offer an opportunity for further research in the study of ba-
sic logical properties of the aforementioned systems, specially concerning the investigation of their
essential compositionality structures and possible generalizations.","While the many theoretical results
already obtained in this research program justify (in our opinion) the analogies we made and the con-
ceptual links we established between fragments of formal structures used in distinct (and often faraway)
research areas, we believe that these intuitive connections deserve and can beneﬁt from an even more
rigorous and general setting.","Rough and Fuzzy Sets

Essential logical properties of the GFBST can be explained regarding the e-value as a transformation
between probability and possibility measures, see [34].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.6211046,0.23490956,-0.12662694,A
6290,"The underlying interconnections between al-
ternative representations of uncertainty at the core of this theory provide a general motivation to more
speciﬁc topics of further research presented in this section.","Rough and Fuzzy Sets

Essential logical properties of the GFBST can be explained regarding the e-value as a transformation
between probability and possibility measures, see [34].","In the GFBST framework, a sharp hypothesis can be either rejected or remain undecided, but can
never be accepted, see Section 7.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.5360943,0.19822186,-0.15860118,A
6291,"Although this topic of further research can potentially beneﬁt from all the sophisticated technical
developments and approaches to complexity theory already mentioned, it also requires a healthy dose

                                                            15
of critical thinking applied to the human condition in daily life, yet another area of interest of Walter’s
research group, see [124].","Na¨ıve
adaptations of complexity measures artiﬁcially borrowed from other areas often fail to capture relevant
aspects of the legal environment.","Acknowledgments

The authors take this opportunity to thank Prof. Walter Carnielli for, along the years, inviting, wel-
coming, and stimulating investigations, discussions, and interactions at the borders or areas of overlap
between logic, probability, statistics, formal methods in science, philosophy of science and general
philosophy.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.46889085,0.049530294,0.35288352,A
6292,"Section 12 presents some topics for further research at the interface between Logic
and Statistics.","Section 11 considers the philo-
sophical consequences of the aforementioned developments by brieﬂy commenting on the Objective
cognitive constructivism epistemological framework, which was speciﬁcally developed to accommo-
date the formal properties of the e-value and the FBST, and renders a naturalized approach to ontology
and metaphysics.","One of the objectives of this paper is to foster work in areas of interface or overlap be-
tween Logic and Statistics and to stimulate greater cooperation between the two communities.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.6732097,-0.10435495,0.02184017,A
6293,"During this workshop, we discussed several topics for further research, most of them
motivated by areas of common interest that, nevertheless, are usually approached quite differently by
the communities of Logic and Statistics.","12 Future Research and Final Remarks

In December 2018, at CLE-UNICAMP, Walter Carnielli organized the workshop Induction, Probability
and their Dilemmas, where the ﬁrst author gave the presentation The Problem of Induction in Statis-

                                                            13
tical Science.",This section presents four of these topics.,2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.38841927,-0.41857144,0.1183429,A
6294,"In this context, it is a topic for further research to explore how much of this theory
and its applications can be expressed using the sentential probability approach, either by expanding
the underlying languages (like inﬁnitary, second order, or ﬁxed-point logics), see [139, 151, 152, 157,
158, 160, 162], or by exploring relevant properties in speciﬁc statistical models (including topological
properties, like countability and compactness, and regularity conditions of constraints and distributions,
like bounded continuity and differentiability), see [2, 10, 137, 146, 177, 200].","Sections 6 and 7 sowed how the statistical deﬁnitions of the e-value and the GFBST characterize
their logical properties, and hinted at how arguments of mathematical analysis enable one to travel the
other way around.","Functional Compositionality Structures

As already noticed in Section 6, the compositional structure of e-values can be characterized as a pos-
sibilistic abstract belief calculus, as analyzed in [2, 2, 24, 34, 128, 129, 132, 135, 172].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.49813402,0.27773497,-0.07694257,A_centroid
6295,"In this context, the tools of category theory or other formal abstraction
methods, see [123, 124, 148, 175, 206], offer an opportunity for further research in the study of ba-
sic logical properties of the aforementioned systems, specially concerning the investigation of their
essential compositionality structures and possible generalizations.","While the many theoretical results
already obtained in this research program justify (in our opinion) the analogies we made and the con-
ceptual links we established between fragments of formal structures used in distinct (and often faraway)
research areas, we believe that these intuitive connections deserve and can beneﬁt from an even more
rigorous and general setting.","Rough and Fuzzy Sets

Essential logical properties of the GFBST can be explained regarding the e-value as a transformation
between probability and possibility measures, see [34].",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.6203952,0.2375898,-0.1274749,A
6296,"The underlying interconnections between al-
ternative representations of uncertainty at the core of this theory provide a general motivation to more
speciﬁc topics of further research presented in this section.","Rough and Fuzzy Sets

Essential logical properties of the GFBST can be explained regarding the e-value as a transformation
between probability and possibility measures, see [34].","In the GFBST framework, a sharp hypothesis can be either rejected or remain undecided, but can
never be accepted, see Section 7.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.5360943,0.19822186,-0.15860118,A
6297,"Although this topic of further research can potentially beneﬁt from all the sophisticated technical

                                                            15
developments and approaches to complexity theory already mentioned, it also requires a healthy dose
of critical thinking applied to the human condition in daily life, yet another area of interest of Walter’s
research group, see [125].","Na¨ıve
adaptations of complexity measures artiﬁcially borrowed from other areas often fail to capture relevant
aspects of the legal environment.","Acknowledgments

The authors take this opportunity to thank Prof. Walter Carnielli for, along the years, inviting, wel-
coming, and stimulating investigations, discussions, and interactions at the borders or areas of overlap
between logic, probability, statistics, formal methods in science, philosophy of science and general
philosophy.",2022-05-16 22:43:31+00:00,The e-value and the Full Bayesian Significance Test: Logical Properties and Philosophical Consequences,math.ST,"['math.ST', 'stat.TH', '62A01, 62F15']","[arxiv.Result.Author('Julio Michael Stern'), arxiv.Result.Author('Carlos Alberto de Braganca Pereira'), arxiv.Result.Author('Marcelo de Souza Lauretto'), arxiv.Result.Author('Luis Gustavo Esteves'), arxiv.Result.Author('Rafael Izbicki'), arxiv.Result.Author('Rafael Bassi Stern'), arxiv.Result.Author('Marcio Alves Diniz')]","This article gives a conceptual review of the e-value, ev(H|X) -- the
epistemic value of hypothesis H given observations X. This statistical
significance measure was developed in order to allow logically coherent and
consistent tests of hypotheses, including sharp or precise hypotheses, via the
Full Bayesian Significance Test (FBST). Arguments of analysis allow a full
characterization of this statistical test by its logical or compositional
properties, showing a mutual complementarity between results of mathematical
statistics and the logical desiderata lying at the foundations of this theory.",0.4722883,0.05047462,0.3524449,A
6427,"Several problems deserve further study in
the future.","We have focused on estimating the conditional hazards and survival functions for con-
structing prediction intervals of survival times.","For example, it would be interesting to study ways for estimating treatment ef-
fects by including a semiparametric component in the proposed framework.",2022-05-19 15:48:57+00:00,Deep Generative Survival Analysis: Nonparametric Estimation of Conditional Survival Function,math.ST,"['math.ST', 'stat.TH', '62N02, 62G05, 62G20']","[arxiv.Result.Author('Xingyu Zhou'), arxiv.Result.Author('Wen Su'), arxiv.Result.Author('Changyu Liu'), arxiv.Result.Author('Yuling Jiao'), arxiv.Result.Author('Xingqiu Zhao'), arxiv.Result.Author('Jian Huang')]","We propose a deep generative approach to nonparametric estimation of
conditional survival and hazard functions with right-censored data. The key
idea of the proposed method is to first learn a conditional generator for the
joint conditional distribution of the observed time and censoring indicator
given the covariates, and then construct the Kaplan-Meier and Nelson-Aalen
estimators based on this conditional generator for the conditional hazard and
survival functions. Our method combines ideas from the recently developed deep
generative learning and classical nonparametric estimation in survival
analysis. We analyze the convergence properties of the proposed method and
establish the consistency of the generative nonparametric estimators of the
conditional survival and hazard functions. Our numerical experiments validate
the proposed method and demonstrate its superior performance in a range of
simulated models. We also illustrate the applications of the proposed method in
constructing prediction intervals for survival times with the PBC (Primary
Biliary Cholangitis) and SUPPORT (Study to Understand Prognoses and Preferences
for Outcomes and Risks of Treatments) datasets.",-0.00039014965,0.0008923253,-0.3344174,B
6488,"In Section 4, we further study the
effects of regularized estimation of the propensity scores (Theorem 4).","We discuss the possibilities of rigorously quantifying an
analogous CLT for the trimmed estimator in Section 6.",4.,2022-05-20 14:17:53+00:00,"A New Central Limit Theorem for the Augmented IPW Estimator: Variance Inflation, Cross-Fit Covariance and Beyond",math.ST,"['math.ST', 'econ.EM', 'stat.ME', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Kuanhao Jiang'), arxiv.Result.Author('Rajarshi Mukherjee'), arxiv.Result.Author('Subhabrata Sen'), arxiv.Result.Author('Pragya Sur')]","Estimation of the average treatment effect (ATE) is a central problem in
causal inference. In recent times, inference for the ATE in the presence of
high-dimensional covariates has been extensively studied. Among the diverse
approaches that have been proposed, augmented inverse probability weighting
(AIPW) with cross-fitting has emerged as a popular choice in practice. In this
work, we study this cross-fit AIPW estimator under well-specified outcome
regression and propensity score models in a high-dimensional regime where the
number of features and samples are both large and comparable. Under assumptions
on the covariate distribution, we establish a new CLT for the suitably scaled
cross-fit AIPW that applies without any sparsity assumptions on the underlying
high-dimensional parameters. Our CLT uncovers two crucial phenomena among
others: (i) the AIPW exhibits a substantial variance inflation that can be
precisely quantified in terms of the signal-to-noise ratio and other problem
parameters, (ii) the asymptotic covariance between the pre-cross-fit estimates
is non-negligible even on the root-n scale. In fact, these cross-covariances
turn out to be negative in our setting. These findings are strikingly different
from their classical counterparts. On the technical front, our work utilizes a
novel interplay between three distinct tools--approximate message passing
theory, the theory of deterministic equivalents, and the leave-one-out
approach. We believe our proof techniques should be useful for analyzing other
two-stage estimators in this high-dimensional regime. Finally, we complement
our theoretical results with simulations that demonstrate both the finite
sample efficacy of our CLT and its robustness to our assumptions.",-0.11300343,-0.40502524,-0.30523932,B
6489,"In Section 4, we

further study the effects of regularized estimation of the propensity scores (Theorem 3.4).","We discuss the possibilities of rigorously

quantifying an analogous CLT for the winsorized estimator in Section 6.",4.,2022-05-20 14:17:53+00:00,"A New Central Limit Theorem for the Augmented IPW Estimator: Variance Inflation, Cross-Fit Covariance and Beyond",math.ST,"['math.ST', 'econ.EM', 'stat.ME', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Kuanhao Jiang'), arxiv.Result.Author('Rajarshi Mukherjee'), arxiv.Result.Author('Subhabrata Sen'), arxiv.Result.Author('Pragya Sur')]","Estimation of the average treatment effect (ATE) is a central problem in
causal inference. In recent times, inference for the ATE in the presence of
high-dimensional covariates has been extensively studied. Among the diverse
approaches that have been proposed, augmented inverse probability weighting
(AIPW) with cross-fitting has emerged a popular choice in practice. In this
work, we study this cross-fit AIPW estimator under well-specified outcome
regression and propensity score models in a high-dimensional regime where the
number of features and samples are both large and comparable. Under assumptions
on the covariate distribution, we establish a new central limit theorem for the
suitably scaled cross-fit AIPW that applies without any sparsity assumptions on
the underlying high-dimensional parameters. Our CLT uncovers two crucial
phenomena among others: (i) the AIPW exhibits a substantial variance inflation
that can be precisely quantified in terms of the signal-to-noise ratio and
other problem parameters, (ii) the asymptotic covariance between the
pre-cross-fit estimators is non-negligible even on the root-n scale. These
findings are strikingly different from their classical counterparts. On the
technical front, our work utilizes a novel interplay between three distinct
tools--approximate message passing theory, the theory of deterministic
equivalents, and the leave-one-out approach. We believe our proof techniques
should be useful for analyzing other two-stage estimators in this
high-dimensional regime. Finally, we complement our theoretical results with
simulations that demonstrate both the finite sample efficacy of our CLT and its
robustness to our assumptions.",-0.08284497,-0.43322092,-0.29377848,B
6490,"In Section 4, we

further study the effects of regularized estimation of the propensity scores (Theorem 3.4).","We discuss the possibilities of rigorously

quantifying an analogous CLT for the winsorized estimator in Section 6.",4.,2022-05-20 14:17:53+00:00,"A New Central Limit Theorem for the Augmented IPW Estimator: Variance Inflation, Cross-Fit Covariance and Beyond",math.ST,"['math.ST', 'econ.EM', 'stat.ME', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Kuanhao Jiang'), arxiv.Result.Author('Rajarshi Mukherjee'), arxiv.Result.Author('Subhabrata Sen'), arxiv.Result.Author('Pragya Sur')]","Estimation of the average treatment effect (ATE) is a central problem in
causal inference. In recent times, inference for the ATE in the presence of
high-dimensional covariates has been extensively studied. Among the diverse
approaches that have been proposed, augmented inverse probability weighting
(AIPW) with cross-fitting has emerged a popular choice in practice. In this
work, we study this cross-fit AIPW estimator under well-specified outcome
regression and propensity score models in a high-dimensional regime where the
number of features and samples are both large and comparable. Under assumptions
on the covariate distribution, we establish a new central limit theorem for the
suitably scaled cross-fit AIPW that applies without any sparsity assumptions on
the underlying high-dimensional parameters. Our CLT uncovers two crucial
phenomena among others: (i) the AIPW exhibits a substantial variance inflation
that can be precisely quantified in terms of the signal-to-noise ratio and
other problem parameters, (ii) the asymptotic covariance between the
pre-cross-fit estimators is non-negligible even on the root-n scale. These
findings are strikingly different from their classical counterparts. On the
technical front, our work utilizes a novel interplay between three distinct
tools--approximate message passing theory, the theory of deterministic
equivalents, and the leave-one-out approach. We believe our proof techniques
should be useful for analyzing other two-stage estimators in this
high-dimensional regime. Finally, we complement our theoretical results with
simulations that demonstrate both the finite sample efficacy of our CLT and its
robustness to our assumptions.",-0.08284497,-0.43322092,-0.29377848,B
7134,"In any case the computation of h (x, r), or a good upper
bound thereof, remains an interesting problem for further research.","The generation of candidate subsequences could be further accelerated
as they have to satisfy r < d (xi, xj) ≤ 2r.","2.3 The Good-Turing estimator

For the remainder of this section we take the radius r as ﬁxed and omit it from all expressions unless
explicitly speciﬁed otherwise.",2022-06-04 15:17:22+00:00,Concentration of the missing mass in metric spaces,math.ST,"['math.ST', 'math.PR', 'stat.TH', '60E15']",[arxiv.Result.Author('Andreas Maurer')],"We study the estimation of the probability to observe data further than a
specified distance from a given iid sample in a metric space. The problem
extends the classical problem of estimation of the missing mass in discrete
spaces. We show that estimation is difficult in general and identify conditions
on the distribution, under which the Good-Turing estimator and the conditional
missing mass concentrate on their expectations. Applications to supervised
learning are sketched.",-0.23698184,0.14412169,0.5847362,C
7135,"In any case the computation of h (x, r), or a good upper
bound thereof, remains an interesting problem for further research.","The generation of candidate subsequences could be further accelerated
as they have to satisfy r < d (xi, xj) ≤ 2r.","5
2.3 The Good-Turing estimator

For the remainder of this section we take the radius r as ﬁxed and omit it from all expressions unless
explicitly speciﬁed otherwise.",2022-06-04 15:17:22+00:00,Concentration of the missing mass in metric spaces,math.ST,"['math.ST', 'math.PR', 'stat.TH', '60E15']",[arxiv.Result.Author('Andreas Maurer')],"We study the estimation of the probability to observe data further than a
specified distance from a given iid sample in a metric space. The problem
extends the classical problem of estimation of the missing mass in discrete
spaces. We show that estimation is difficult in general and identify conditions
on the distribution, under which the Good-Turing estimator and the conditional
missing mass concentrate on their expectations. Applications to supervised
learning are sketched.",-0.24125668,0.14154336,0.5892891,C
7136,"In any case the computation of h (x, r), or a good upper bound
thereof, remains an interesting problem for further research.","In this case an
efﬁcient algorithm is given in [24].","7
3 Applications

Since h (x) = 1 in the discrete case, many of the applications of the discrete case are covered by
Theorem 2.6, albeit with larger constants.",2022-06-04 15:17:22+00:00,Concentration of the missing mass in metric spaces,math.ST,"['math.ST', 'math.PR', 'stat.TH', '60E15']",[arxiv.Result.Author('Andreas Maurer')],"We study the estimation and concentration on its expectation of the
probability to observe data further than a specified distance from a given iid
sample in a metric space. The problem extends the classical problem of
estimation of the missing mass in discrete spaces. We give some estimators for
the conditional missing mass and show that estimation of the expected missing
mass is difficult in general. Conditions on the distribution, under which the
Good-Turing estimator and the conditional missing mass concentrate on their
expectations are identified. Applications to anomaly detection, coding, the
Wasserstein distance between true and empirical measure and simple learning
bounds are sketched.",-0.17238975,0.25426874,0.56432676,C
7137,"In any case the computation of h (x, r), or a good upper bound
thereof, remains an interesting problem for further research.","In this case an
efﬁcient algorithm is given in [24].","7
3 Applications

Since h (x) = 1 in the discrete case, many of the applications of the discrete case are covered by
Theorem 2.7, albeit with larger constants.",2022-06-04 15:17:22+00:00,Concentration of the missing mass in metric spaces,math.ST,"['math.ST', 'math.PR', 'stat.TH', '60E15']",[arxiv.Result.Author('Andreas Maurer')],"We study the estimation and concentration on its expectation of the
probability to observe data further than a specified distance from a given iid
sample in a metric space. The problem extends the classical problem of
estimation of the missing mass in discrete spaces. We give some estimators for
the conditional missing mass and show that estimation of the expected missing
mass is difficult in general. Conditions on the distribution, under which the
Good-Turing estimator and the conditional missing mass concentrate on their
expectations are identified. Applications to anomaly detection, coding, the
Wasserstein distance between true and empirical measure and simple learning
bounds are sketched.",-0.1686056,0.25159955,0.56362885,C
7598,We close this article by pointing out open and related problems for further research.,"The latter
outperform the hitherto best known methods for some alternatives, while providing solid power performances in most
cases.","If we replace the estimators

(λn, kn) by the unknown parameters (λ, k) in the deﬁnition of Tn in (4) and minimize with respect to the parameter
space, we obtain new estimators

               ∞1 n 1           Xj k                     1 − e−tXn,j  − t n e−tXj 2w(t)dt,
(λn, kn) = argmin(λ,k) 0 n Xj k λ − k + 1                                n j=1
                           j=1

of minimum distance type for the parameters of W (λ0, k0), whenever X1, .",2022-06-14 07:15:54+00:00,Weibull or not Weibull?,math.ST,"['math.ST', 'stat.TH', '62G20, 62E10']","[arxiv.Result.Author('Bruno Ebner'), arxiv.Result.Author('Adrian Fischer'), arxiv.Result.Author('Norbert Henze'), arxiv.Result.Author('Celeste Mayer')]","We propose novel goodness-of-fit tests for the Weibull distribution with
unknown parameters. These tests are based on an alternative characterizing
representation of the Laplace transform related to the density approach in the
context of Stein's method. Asymptotic theory of the tests is derived, including
the limit null distribution, the behaviour under contiguous alternatives, the
validity of the parametric bootstrap procedure, and consistency of the tests
against a large class of alternatives. A Monte Carlo simulation study shows the
competitiveness of the new procedure. Finally, the procedure is applied to real
data examples taken from the materials science.",-0.34142643,-0.056285847,0.16655695,C
7641,"The full convergence in distribution requires tightness and we would need
to focus on speciﬁc spaces; we leave this question to further research.","From Theorem 3.7 we have convergence in ﬁnite-dimensional
distributions.","However, there are
cases where the convergence in ﬁnite-dimensional distributions implies the convergence in
distributions.",2022-06-14 17:14:33+00:00,"On quantiles, continuity and robustness",math.ST,"['math.ST', 'math.PR', 'stat.TH']","[arxiv.Result.Author('Riccardo Passeggeri'), arxiv.Result.Author('Nancy Reid')]","We consider the geometric quantile and various definitions of the
component-wise quantile in infinite dimensions and show their existence,
uniqueness and continuity. Building on these results, we introduce and study
the properties of the Quantile-of-Estimates (QoE) estimator, a robustification
procedure for a large class of estimators. For example, given an estimator that
is asymptotically normal, the QoE estimator is asymptotically normal even in
the presence of contaminated data.",-0.17117973,0.10483509,-0.11595014,B
8283,"Finally, there are many open questions and directions for further research, such as a more
precise description of the optimal performance, the proof of stronger optimality properties,
asymptotic regimes where the number of sources also goes to inﬁnity as the error probabilities
vanish, modeling the data streams using spatial models, e.g., a Markov random ﬁeld, where
the special underlying dependence can lead to further insights, closed-form expressions for
the thresholds that are less conservative than the ones we obtain in this work, more efﬁcient
design of subsystems, etc.","Moreover, we can extend the
results of the current work to the case that the distribution of each unit under each hypothesis
belongs to a parametric family, working similarly to [35, Section 6].","Finally, another direction of interest is to allow for the sampling
to be terminated at a different time in each data stream, as in [4, 7, 29].",2022-06-30 22:32:44+00:00,Joint Sequential Detection and Isolation for Dependent Data Streams,math.ST,"['math.ST', 'stat.ME', 'stat.TH', 'Primary 62L10, 62L05, secondary 62J15']","[arxiv.Result.Author('Anamitra Chaudhuri'), arxiv.Result.Author('Georgios Fellouris')]","The problem of joint sequential detection and isolation is considered in the
context of multiple, not necessarily independent, data streams. A multiple
testing framework is proposed, where each hypothesis corresponds to a different
subset of data streams, the sample size is a stopping time of the observations,
and the probabilities of four kinds of error are controlled below distinct,
user-specified levels. Two of these errors reflect the detection component of
the formulation, whereas the other two the isolation component. The optimal
expected sample size is characterized to a first-order asymptotic approximation
as the error probabilities go to 0. Different asymptotic regimes, expressing
different prioritizations of the detection and isolation tasks, are considered.
A novel, versatile family of testing procedures is proposed, in which two
distinct, in general, statistics are computed for each hypothesis, one
addressing the detection task and the other the isolation task. Tests in this
family, of various computational complexities, are shown to be asymptotically
optimal under different setups. The general theory is applied to the detection
and isolation of anomalous, not necessarily independent, data streams, as well
as to the detection and isolation of an unknown dependence structure.",-0.20390792,0.003427475,-0.04069782,C
8324,"♦

2.2 A framework for proving existence of MAP estimators

While we use the proof strategy described above to prove Theorems 2.4 and 2.5,
it paves the way for further research.","Further, remarkably, while

Condition 2.7 (C1)—(C4) are stated in terms of the prior measure µ, the conclusions
are drawn for MAP estimators of µy, with Assumption 2.1 providing the sufﬁcient

conditions for comparability between prior and posterior in order to make this

possible.","Note that Theorem 2.8 is applicable to any
separable Banach space, so this approach can be followed to prove Conjecture 2.3
for other classes of Banach spaces.",2022-07-01 19:30:43+00:00,Maximum a posteriori estimators in $\ell^p$ are well-defined for diagonal Gaussian priors,math.ST,"['math.ST', 'math.PR', 'stat.TH', '62F15, 62F99, 60H99']","[arxiv.Result.Author('Ilja Klebanov'), arxiv.Result.Author('Philipp Wacker')]","We prove that maximum a posteriori estimators are well-defined for diagonal
Gaussian priors $\mu$ on $\ell^p$ under common assumptions on the potential
$\Phi$. Further, we show connections to the Onsager--Machlup functional and
provide a corrected and strongly simplified proof in the Hilbert space case
$p=2$, previously established by Dashti et al (2013) and Kretschmann (2019).",-0.10894638,-0.19025092,-0.019987134,C
8325,"♦

                                9
2.2 A framework for proving existence of MAP estimators

While we use the proof strategy described above to prove Theorems 2.4 and 2.5,
it paves the way for further research.","Further, remarkably, while

Condition 2.7 (C1)—(C4) are stated in terms of the prior measure µ, the conclusions
are drawn for MAP estimators of µy, with Assumption 2.1 providing the sufﬁcient

conditions for comparability between prior and posterior in order to make this

possible.","Note that Theorem 2.8 is applicable to any
separable Banach space, so this approach can be followed to prove Conjecture 2.3
for other classes of Banach spaces.",2022-07-01 19:30:43+00:00,Maximum a posteriori estimators in $\ell^p$ are well-defined for diagonal Gaussian priors,math.ST,"['math.ST', 'math.PR', 'stat.TH', '62F15, 62F99, 60H99']","[arxiv.Result.Author('Ilja Klebanov'), arxiv.Result.Author('Philipp Wacker')]","We prove that maximum a posteriori estimators are well-defined for diagonal
Gaussian priors $\mu$ on $\ell^p$ under common assumptions on the potential
$\Phi$. Further, we show connections to the Onsager--Machlup functional and
provide a corrected and strongly simplified proof in the Hilbert space case
$p=2$, previously established by Dashti et al (2013) and Kretschmann (2019).
  These corrections do not generalize to the setting $1 \leq p < \infty$, which
requires a novel convexification result for the difference between the
Cameron--Martin norm and the $p$-norm.",-0.10229765,-0.18430808,-0.014232425,C
9140,"Recently Bolin
and Kirchner (2021) have shown that for any d ≥ 4, two Gaussian measures are equivalent if
and only if they have the same parameters (σ2, α, ν), though ﬁnding the consistent estimators
of (σ2, α) for d = 4 under ﬁxed-domain asymptotics requires further study.","On the other hand, when d ≥ 5, Anderes (2010) has proposed consistent moment
estimators for both σ2 and α with a given ν under ﬁxed-domain asymptotics.","A direct consequence of the theory on equivalence of Gaussian processes is that for the
domain dimension d = 1, 2, 3, which is of primary interest to spatial statistics, only the microer-
godic parameter θ = σ2α2ν and continuous functions of θ can be consistently estimated from
the data under ﬁxed-domain asymptotics.",2022-07-21 00:34:32+00:00,Fixed-domain Posterior Contraction Rates for Spatial Gaussian Process Model with Nugget,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Cheng Li'), arxiv.Result.Author('Saifei Sun'), arxiv.Result.Author('Yichen Zhu')]","Spatial Gaussian process regression models typically contain finite
dimensional covariance parameters that need to be estimated from the data. We
study the Bayesian estimation of covariance parameters including the nugget
parameter in a general class of stationary covariance functions under
fixed-domain asymptotics, which is theoretically challenging due to the
increasingly strong dependence among spatial observations. We propose a novel
adaptation of the Schwartz's consistency theorem for showing posterior
contraction rates of the covariance parameters including the nugget. We derive
a new polynomial evidence lower bound, and propose consistent higher-order
quadratic variation estimators that satisfy concentration inequalities with
exponentially small tails. Our Bayesian fixed-domain asymptotics theory leads
to explicit posterior contraction rates for the microergodic and nugget
parameters in the isotropic Matern covariance function under a general
stratified sampling design. We verify our theory and the Bayesian predictive
performance in simulation studies and an application to sea surface temperature
data.",-0.18168098,-0.0013268748,-0.16889541,B
9141,"It requires further study whether we can include ν as part of the unknown parameters
in the current Bayesian framework, and establish the posterior contraction for ν based on the
new estimators in Loh (2015) and Loh et al.","(2021) when ν is assumed to be
known.",(2021).,2022-07-21 00:34:32+00:00,Fixed-domain Posterior Contraction Rates for Spatial Gaussian Process Model with Nugget,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Cheng Li'), arxiv.Result.Author('Saifei Sun'), arxiv.Result.Author('Yichen Zhu')]","Spatial Gaussian process regression models typically contain finite
dimensional covariance parameters that need to be estimated from the data. We
study the Bayesian estimation of covariance parameters including the nugget
parameter in a general class of stationary covariance functions under
fixed-domain asymptotics, which is theoretically challenging due to the
increasingly strong dependence among spatial observations. We propose a novel
adaptation of the Schwartz's consistency theorem for showing posterior
contraction rates of the covariance parameters including the nugget. We derive
a new polynomial evidence lower bound, and propose consistent higher-order
quadratic variation estimators that satisfy concentration inequalities with
exponentially small tails. Our Bayesian fixed-domain asymptotics theory leads
to explicit posterior contraction rates for the microergodic and nugget
parameters in the isotropic Matern covariance function under a general
stratified sampling design. We verify our theory and the Bayesian predictive
performance in simulation studies and an application to sea surface temperature
data.",-0.10887957,-0.16843349,-0.1036083,B
9147,There still exist challenges that need further research.,"Our
approach works well in both simulation and the real-world applications.","One interesting extension is to
consider scenarios where the cluster-speciﬁc covariance matrices have some structures, such
as sparsity structures (Cai et al., 2016) or spiked structures (Johnstone and Lu, 2009).",2022-07-21 04:43:16+00:00,Bayesian Sparse Gaussian Mixture Model in High Dimensions,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Dapeng Yao'), arxiv.Result.Author('Fangzheng Xie'), arxiv.Result.Author('Yanxun Xu')]","We study the sparse high-dimensional Gaussian mixture model when the number
of clusters is allowed to grow with the sample size. A minimax lower bound for
parameter estimation is established, and we show that a constrained maximum
likelihood estimator achieves the minimax lower bound. However, this
optimization-based estimator is computationally intractable because the
objective function is highly nonconvex and the feasible set involves discrete
structures. To address the computational challenge, we propose a Bayesian
approach to estimate high-dimensional Gaussian mixtures whose cluster centers
exhibit sparsity using a continuous spike-and-slab prior. Posterior inference
can be efficiently computed using an easy-to-implement Gibbs sampler. We
further prove that the posterior contraction rate of the proposed Bayesian
method is minimax optimal. The mis-clustering rate is obtained as a by-product
using tools from matrix perturbation theory. The proposed Bayesian sparse
Gaussian mixture model does not require pre-specifying the number of clusters,
which can be adaptively estimated via the Gibbs sampler. The validity and
usefulness of the proposed method is demonstrated through simulation studies
and the analysis of a real-world single-cell RNA sequencing dataset.",-0.14855613,0.29408336,-0.094148524,C
9368,We further study harmonic mean divergence and chi-square divergence.,Some properties are discussed.,"In Section 3, we
study Shannon entropy of CRT distribution.",2022-07-27 10:39:15+00:00,Informational properties of the family of cubic rank transmuted distributions,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Shital Saha'), arxiv.Result.Author('Suchandan Kayal')]","Recently, cubic rank transmuted (CRT) distribution was introduced and studied
by Granzotto et al. (2017). In this work, we consider CRT distribution and
establish some of its information theoretic properties. First, divergence
measures between CRT distribution and each of its components have been studied.
In this regard, we consider Kullback-Leibler, harmonic mean and chi-square
divergence measures. Further, we derive Shannon entropy, CRT Shannon entropy,
Gini information, CRT Gini information and Fisher information matrix for CRT
distribution.",-0.13078023,0.016079701,0.011820231,B
9369,We further study harmonic mean divergence and chi-square divergence.,Some properties are discussed.,"In Section 3, we
study Shannon entropy of CRT distribution.",2022-07-27 10:39:15+00:00,Informational properties of the family of cubic rank transmuted distributions,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Shital Saha'), arxiv.Result.Author('Suchandan Kayal')]","Recently, cubic rank transmuted (CRT) distribution was introduced and studied
by Granzotto et al. (2017). In this work, we consider CRT distribution and
establish some of its information theoretic properties. First, divergence
measures between CRT distribution and each of its components have been studied.
In this regard, we consider Kullback-Leibler, harmonic mean and chi-square
divergence measures. Further, we derive Shannon entropy, CRT Shannon entropy,
Gini information, CRT Gini information and Fisher information matrix for CRT
distribution.",-0.13078032,0.016079674,0.011820279,B
9473,"In Section 9, we discuss the results and
present some openings to further research.","Section 8 discusses TVaR-based
risk allocation when the marginals are mixed Erlang rvs.","2 Preliminaries

We begin by introducing general notation.",2022-07-29 14:01:17+00:00,Risk aggregation with FGM copulas,math.ST,"['math.ST', 'stat.AP', 'stat.TH']","[arxiv.Result.Author('Christopher Blier-Wong'), arxiv.Result.Author('Hélène Cossette'), arxiv.Result.Author('Etienne Marceau')]","We offer a new perspective on risk aggregation with FGM copulas. Along the
way, we discover new results and revisit existing ones, providing simpler
formulas than one can find in the existing literature. This paper builds on two
novel representations of FGM copulas based on symmetric multivariate Bernoulli
distributions and order statistics. First, we detail families of multivariate
distributions with closed-form solutions for the cumulative distribution
function or moments of the aggregate random variables. We order aggregate
random variables under the convex order and provide methods to compute the
cumulative distribution function of aggregate rvs when the marginals are
discrete. Finally, we discuss risk-sharing and capital allocation, providing
numerical examples for each.",-0.025499823,0.006583452,-0.23844528,B
9652,"This phenomenon becomes

interesting and deserves further research, in light of the results of [16], where the authors show that

homophily aﬀects the curvature of the degree distribution under the preferential attachment evolutionary

mechanism.","We

have shown that γpGq, encodes the covariance structure of the random outcome of the random coloring

model and reﬂects the dispersion of the degree distribution of G. If G is a network with over-dispersed

degree distribution, such as a scale-free network, then γpGq is nonpositive.","Recall from Section 1 that what we have so far understood by homophily is actually what we have

called edge density homophily, which is obtained by considering the density of the edges of a graph as a

measure of correlation between the coloring f and the network G. Other notions of homophily are possible

by choosing a diﬀerent correlation measure.",2022-08-03 08:34:35+00:00,Network homophily via multi-dimensional extensions of Cantelli's inequality,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Nicola Apollonio'), arxiv.Result.Author('Paolo G. Franciosa'), arxiv.Result.Author('Daniele Santoni')]","Homophily is the principle whereby ""similarity breeds connections"". We give a
quantitative formulation of this principle within networks. We say that a
network is homophillic with respect to a given labeled partition of its
vertices, when the classes of the partition induce subgraphs that are
significantly denser than what we expect under a random labeled partition into
classes maintaining the same cardinalities (type). This is the recently
introduced \emph{random coloring model} for network homophily. In this
perspective, the vector whose entries are the sizes of the subgraphs induced by
the corresponding classes, is viewed as the observed outcome of the random
vector described by picking labeled partitions at random among partitions with
the same type.\,Consequently, the input network is homophillic at the
significance level $\alpha$ whenever the one-sided tail probability of
observing an outcome at least as extreme as the observed one, is smaller than
$\alpha$. Clearly, $\alpha$ can also be thought of as a quantifier of homophily
in the scale $[0,1]$. Since, as we show, even approximating this tail
probability is an NP-hard problem, we resort multidimensional extensions of
classical Cantelli's inequality to bound $\alpha$ from above. This upper bound
is the homophily index we propose. It requires the knowledge of the covariance
matrix of the random vector, which was not previously known within the random
coloring model. In this paper we close this gap by computing the covariance
matrix of subgraph sizes under the random coloring model. Interestingly, the
matrix depends on the input partition only through its type and on the network
only through its degrees. Furthermore all the covariances have the same sign
and this sign is a graph invariant. Plugging this structure into Cantelli's
bound yields a meaningful, easy to compute index for measuring network
homophily.",0.048238095,0.090084314,-0.121387914,B
9990,"In Section 5 we state three open problems, hoping to inspire further research on
commutative algebra of Bayesian networks.","Moreover, we show in Theorem
4.4 that for the two ideals to be equal it is necessary that G does not contain
an induced cycle of length greater than three.","2 Preliminaries

2.1 Staged trees

Consider a directed tree T = (V, E) with a distinguished root, such that every
edge is directed away from the root.",2022-08-12 14:27:45+00:00,Toric and non-toric Bayesian networks,math.ST,"['math.ST', 'math.AC', 'stat.TH', '62R01, 62A09, 13F65, 13C70']",[arxiv.Result.Author('Lisa Nicklasson')],"In this paper we study Bayesian networks from a commutative algebra
perspective. We characterize a class of toric Bayesian nets, and provide the
first example of a Bayesian net which is proved non-toric under any linear
change of variables. Concerning the class of toric Bayesian nets, we study
their quadratic relations and prove a conjecture by Garcia, Stillman, and
Sturmfels for this class. In addition, we give a necessary condition on the
underlying directed acyclic graph for when all relations are quadratic.",0.18838751,-0.027799554,0.12582603,A
10043,"Section 5 concludes
with a suggestion for potential further research.","We used a few examples in
section 4 to demonstrate the results of the previous sections.","2 Results based on cumulative residual (past) Extropy

The following lemma due to Fashandi and Ahmadi (2012) will be used to develop
different characterization of symmetric distribution.",2022-08-15 11:05:56+00:00,Some characterizations of continuous symmetric distributions based on extropy of record values,math.ST,"['math.ST', 'stat.TH', '62E10, 62E05, 62G30']","[arxiv.Result.Author('Nitin Gupta'), arxiv.Result.Author('Santosh Kumar Chaudhary')]","Using different extropies of k record values various characterizations are
provided for continuous symmetric distributions. The results are in addition to
the results of Ahmadi, J. (Statistical Papers, 2021, 62:2603-2626). These
include cumulative residual (past) extropy, generalised cumulative residual
(past) extropy, also some common Kerridge inaccuracy measures. Using inaccuracy
extropy measures, it is demonstrated that continuous symmetric distributions
are characterised by an equality of information in upper and lower k-records.",-0.19996089,-0.1460567,-0.16729319,B_centroid
10188,"Of course, this is just a ﬁrst step, and in Section 5 we list natural
directions of further research.","Our results agree perfectly with the classi-
cal results.","2 Nonparametric e-tests

Let Z1, .",2022-08-18 15:48:58+00:00,Efficiency of nonparametric e-tests,math.ST,"['math.ST', 'stat.ME', 'stat.TH', '62G10 (Primary) 62A01 (Secondary)']","[arxiv.Result.Author('Vladimir Vovk'), arxiv.Result.Author('Ruodu Wang')]","The notion of an e-value has been recently proposed as a possible alternative
to critical regions and p-values in statistical hypothesis testing. In this
note we introduce a simple analogue for e-values of Pitman's asymptotic
relative efficiency and apply it to three popular nonparametric tests.",0.012313875,-0.1973497,-0.05415295,B
10189,"5 Conclusion

There are many possible directions of further research, including:

                                               8
    • Our notion of e-power is crude in that it depends only on the expectation
       of log E, as explained in Remark 3.1.","In practical application we
should use (5) with C given by, e.g., (6).","This crudeness is inherited by our
       deﬁnition of the ARE of e-tests.",2022-08-18 15:48:58+00:00,Efficiency of nonparametric e-tests,math.ST,"['math.ST', 'stat.ME', 'stat.TH', '62G10 (Primary) 62A01 (Secondary)']","[arxiv.Result.Author('Vladimir Vovk'), arxiv.Result.Author('Ruodu Wang')]","The notion of an e-value has been recently proposed as a possible alternative
to critical regions and p-values in statistical hypothesis testing. In this
note we introduce a simple analogue for e-values of Pitman's asymptotic
relative efficiency and apply it to three popular nonparametric tests.",0.06492634,-0.017450122,0.17911562,B
10206,We complete this paper with some discussion on its limitations and possible directions of further research.,"From this theoretical perspective, we insist that the information criteria we provide in this paper
should be favorable to existing model selection methods like the GIC even though their performances are
similar.","14
First, we cannot apply our proof of consistency to non-normal models as they stand, although the basic idea
of the derivation of our information criteria remains valid.",2022-08-19 05:29:44+00:00,Consistent Bayesian Information Criterion Based on a Mixture Prior for Possibly High-Dimensional Multivariate Linear Regression Models,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Haruki Kono'), arxiv.Result.Author('Tatsuya Kubokawa')]","In the problem of selecting variables in a multivariate linear regression
model, we derive new Bayesian information criteria based on a prior mixing a
smooth distribution and a delta distribution. Each of them can be interpreted
as a fusion of the Akaike information criterion (AIC) and the Bayesian
information criterion (BIC). Inheriting their asymptotic properties, our
information criteria are consistent in variable selection in both the
large-sample and the high-dimensional asymptotic frameworks. In numerical
simulations, variable selection methods based on our information criteria
choose the true set of variables with high probability in most cases.",-0.029014356,0.01271192,-0.23033036,B
11057,"We leave this investigation
open for further research.","This effect might be controlled by
implementing a data dependent choice of the tuning parameter due to Tenreiro (2019).",We ﬁnish the article by pointing out other related open questions.,2022-09-12 11:17:21+00:00,More asymptotic theory for the test of exponentiality based on the mean residual life function,math.ST,"['math.ST', 'stat.TH', 'Primary 62G10 Secondary 62E20']",[arxiv.Result.Author('Bruno Ebner')],"We revisit the family of goodness-of-fit tests for exponentiality based on
the mean residual life time proposed by Baringhaus & Henze (2008). We motivate
the test statistic by a characterisation of Shanbhag (1970) and provide an
alternative representation, which leads to simple and short proofs for the
known theory and an easy to access covariance structure of the limiting
Gaussian process under the null hypothesis. Explicit formulas for the
eigenvalues and eigenfunctions of the operator associated with the limit
covariance are derived using results on weighted Brownian bridges. In addition
we provide further asymptotic theory under fixed alternatives and derive
approximate Bahadur efficiencies, which provide an insight into the choice of
the tuning parameter with regard to the power performance of the tests.",-0.2624669,-0.04041025,-0.13593403,B
11066,"In turn, these enable a rigorous analysis of
the topology of wald space, such as Theorem 3.3.5 about its stratiﬁed structure, in
addition to providing a foundation for further research on this space.","The proof involves three essential characterisations of the
elements of wald space (as graph-theoretic forests; as split systems; and as certain
symmetric positive deﬁnite matrices).",The remainder of the paper is structured as follows.,2022-09-12 15:41:02+00:00,Foundations of the Wald Space for Phylogenetic Trees,math.ST,"['math.ST', 'math.DG', 'stat.TH', '30L05, 57N80, 53A35']","[arxiv.Result.Author('Jonas Lueg'), arxiv.Result.Author('Maryam K. Garba'), arxiv.Result.Author('Tom M. W. Nye'), arxiv.Result.Author('Stephan F. Huckemann')]","Evolutionary relationships between species are represented by phylogenetic
trees, but these relationships are subject to uncertainty due to the random
nature of evolution. A geometry for the space of phylogenetic trees is
necessary in order to properly quantify this uncertainty during the statistical
analysis of collections of possible evolutionary trees inferred from biological
data. Recently, the wald space has been introduced: a length space for trees
which is a certain subset of the manifold of symmetric positive definite
matrices. In this work, the wald space is introduced formally and its topology
and structure is studied in detail. In particular, we show that wald space has
the topology of a disjoint union of open cubes, it is contractible, and by
careful characterization of cube boundaries, we demonstrate that wald space is
a Whitney stratified space of type (A). Imposing the metric induced by the
affine invariant metric on symmetric positive definite matrices, we prove that
wald space is a geodesic Riemann stratified space. A new numerical method is
proposed and investigated for construction of geodesics, computation of
Fr\'echet means and calculation of curvature in wald space. This work is
intended to serve as a mathematical foundation for further geometric and
statistical research on this space.",-0.08363419,0.19523603,0.13787138,C
11640,"Therefore, further research should focus on determining what the eﬀect that
inaccurately solving the optimization problems has on the distribution of the samples.","The computational cost of solving these optimization
problems accurately can be very high, yet it is still unknown to what extent accurate solutions
are necessary.","Another topic of further study is identifying more techniques for eﬃcient post-processing of
posteriors beyond constraints.",2022-09-26 07:46:19+00:00,Bayesian Inference with Projected Densities,math.ST,"['math.ST', 'stat.TH', '62F15, 65C05, 90C25']","[arxiv.Result.Author('Jasper Marijn Everink'), arxiv.Result.Author('Yiqiu Dong'), arxiv.Result.Author('Martin Skovgaard Andersen')]","Constraints are a natural choice for prior information in Bayesian inference.
In various applications, the parameters of interest lie on the boundary of the
constraint set. In this paper, we use a method that implicitly defines a
constrained prior such that the posterior assigns positive probability to the
boundary of the constraint set. We show that by projecting posterior mass onto
the constraint set, we obtain a new posterior with a rich probabilistic
structure on the boundary of that set. If the original posterior is a Gaussian,
then such a projection can be done efficiently. We apply the method to Bayesian
linear inverse problems, in which case samples can be obtained by repeatedly
solving constrained least squares problems, similar to a MAP estimate, but with
perturbations in the data. When combined into a Bayesian hierarchical model and
the constraint set is a polyhedral cone, we can derive a Gibbs sampler to
efficiently sample from the hierarchical model. To show the effect of
projecting the posterior, we applied the method to deblurring and computed
tomography examples.",-0.1387352,-0.096983336,0.16427208,C
11641,"Another topic of further study is identifying more techniques for eﬃcient post-processing of
posteriors beyond constraints.","Therefore, further research should focus on determining what the eﬀect that
inaccurately solving the optimization problems has on the distribution of the samples.","For example, adding penalization functions to the randomized
least squares problems results in new modiﬁed posteriors.",2022-09-26 07:46:19+00:00,Bayesian Inference with Projected Densities,math.ST,"['math.ST', 'stat.TH', '62F15, 65C05, 90C25']","[arxiv.Result.Author('Jasper Marijn Everink'), arxiv.Result.Author('Yiqiu Dong'), arxiv.Result.Author('Martin Skovgaard Andersen')]","Constraints are a natural choice for prior information in Bayesian inference.
In various applications, the parameters of interest lie on the boundary of the
constraint set. In this paper, we use a method that implicitly defines a
constrained prior such that the posterior assigns positive probability to the
boundary of the constraint set. We show that by projecting posterior mass onto
the constraint set, we obtain a new posterior with a rich probabilistic
structure on the boundary of that set. If the original posterior is a Gaussian,
then such a projection can be done efficiently. We apply the method to Bayesian
linear inverse problems, in which case samples can be obtained by repeatedly
solving constrained least squares problems, similar to a MAP estimate, but with
perturbations in the data. When combined into a Bayesian hierarchical model and
the constraint set is a polyhedral cone, we can derive a Gibbs sampler to
efficiently sample from the hierarchical model. To show the effect of
projecting the posterior, we applied the method to deblurring and computed
tomography examples.",-0.17818274,-0.115451105,0.069482535,C
11757,"Just as

Bernstein copulas extend FGM copulas, further research involves extending the copula proposed in
this paper to more general phase-type distributions.",Coxian-2 distributions are special cases of phase-type distributions with two phases.,"7 Acknowledgments

This work was partially supported by the Natural Sciences and Engineering Research Council of
Canada (Blier-Wong: 559169, Cossette: 04273; Marceau: 05605).",2022-09-27 20:27:47+00:00,A new method to construct high-dimensional copulas with Bernoulli and Coxian-2 distributions,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Christopher Blier-Wong'), arxiv.Result.Author('Hélène Cossette'), arxiv.Result.Author('Sébastien Legros'), arxiv.Result.Author('Etienne Marceau')]","We propose an approach to construct a new family of generalized
Farlie-Gumbel-Morgenstern (GFGM) copulas that naturally scales to high
dimensions. A GFGM copula can model moderate positive and negative dependence,
cover different types of asymmetries, and admits exact expressions for many
quantities of interest such as measures of association or risk measures in
actuarial science or quantitative risk management. More importantly, this paper
presents a new method to construct high-dimensional copulas based on mixtures
of power functions, and may be adapted to more general contexts to construct
broader families of copulas. We construct a family of copulas through a
stochastic representation based on multivariate Bernoulli distributions and
Coxian-2 distributions. This paper will cover the construction of a GFGM
copula, study its measures of multivariate association and dependence
properties. We explain how to sample random vectors from the new family of
copulas in high dimensions. Then, we study the bivariate case in detail and
find that our construction leads to an asymmetric modified Huang-Kotz FGM
copula. Finally, we study the exchangeable case and provide some insights into
the most negative dependence structure within this new class of
high-dimensional copulas.",-0.038102053,0.124668285,-0.21034002,B
11859,We further study a special case where the data is hierarchical in structure.,"We prove that the MMoE is dense in the space of generalized mixed effects models, which is a rich
class containing almost all models in the literature having independent random effects, in the sense of weak
convergence.","In this case, the
proposed nested MMoE is shown to be dense in the space of generalized nested mixed effects models where
the random effects can possibly be dependent.",2022-09-30 03:29:32+00:00,Mixture of experts models for multilevel data: modelling framework and approximation theory,math.ST,"['math.ST', 'cs.LG', 'cs.NE', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Tsz Chai Fung'), arxiv.Result.Author('Spark C. Tseung')]","Multilevel data are prevalent in many real-world applications. However, it
remains an open research problem to identify and justify a class of models that
flexibly capture a wide range of multilevel data. Motivated by the versatility
of the mixture of experts (MoE) models in fitting regression data, in this
article we extend upon the MoE and study a class of mixed MoE (MMoE) models for
multilevel data. Under some regularity conditions, we prove that the MMoE is
dense in the space of any continuous mixed effects models in the sense of weak
convergence. As a result, the MMoE has a potential to accurately resemble
almost all characteristics inherited in multilevel data, including the marginal
distributions, dependence structures, regression links, random intercepts and
random slopes. In a particular case where the multilevel data is hierarchical,
we further show that a nested version of the MMoE universally approximates a
broad range of dependence structures of the random effects among different
factor levels.",-0.06777435,0.06423062,-0.26533437,B
12036,"One can construct and continuously monitor a

CS for the eﬀect size of each treatment, decide when to stop adaptively, select any subset for further study, and report
corrected CIs using the stopped CSs at the e-BY adjusted level.","As before, the implications for bandit multiple testing are interesting.","As one example, one could run e-BH continually using
the underlying e-processes, decide when to stop based on its rejections; then the corrected CIs will be congruent with the
reported discoveries in the sense that all the corrected CIs will not contain the null parameter and both FDR and FCR will
be controlled at level α.",2022-10-04 22:50:14+00:00,Game-theoretic statistics and safe anytime-valid inference,math.ST,"['math.ST', 'cs.GT', 'cs.IT', 'math.IT', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Aaditya Ramdas'), arxiv.Result.Author('Peter Grünwald'), arxiv.Result.Author('Vladimir Vovk'), arxiv.Result.Author('Glenn Shafer')]","Safe anytime-valid inference (SAVI) provides measures of statistical evidence
and certainty -- e-processes for testing and confidence sequences for
estimation -- that remain valid at all stopping times, accommodating continuous
monitoring and analysis of accumulating data and optional stopping or
continuation for any reason. These measures are based on test martingales,
which are nonnegative martingales starting at one. Since a test martingale is
the wealth process of a player in a betting game, SAVI uses game-theoretic
intuition, language and mathematics. This survey reports some recent advances
in testing composite hypotheses and estimating functionals in nonparametric
settings, leading to new methods even for nonsequential problems.",0.025894057,-0.1735385,-0.008396892,B
12416,"However, the solution of each of
the remaining two problems requires further research, which is beyond the scope of this paper.","In this paper, to calculate the density, the authors propose to use
the series expansion of a strictly stable law in view of the parameter α.","Acknowledgements

    The project has been done under ﬁnancial support of the Russian Foundation for Basic Research
(grants №19-44-730005 and 20-07-00655)
24                                                                               V. V. Saenko

          100                          100

10-2                                   10-2

10-4                                   10-4

10-6                                   10-6

10-8                                   10-8

100            101  102   103     104  100   101                             102   103  104

                    FPKM                                                     FPKM

Fig.",2022-10-13 11:34:46+00:00,The calculation of the probability density and distribution function of a strictly stable law in the vicinity of zero,math.ST,"['math.ST', 'math.PR', 'stat.TH', '60E07']",[arxiv.Result.Author('Viacheslav V. Saenko')],"The problem of calculating the probability density and distribution function
of a strictly stable law is considered at $x\to0$. The expansions of these
values into power series were obtained to solve this problem. It was shown that
in the case $\alpha<1$ the obtained series were asymptotic at $x\to0$, in the
case $\alpha>1$ they were convergent and in the case $\alpha=1$ in the domain
$|x|<1$ these series converged to an asymmetric Cauchy distribution. It has
been shown that at $x\to0$ the obtained expansions can be successfully used to
calculate the probability density and distribution function of strictly stable
laws.",-0.30070293,-0.042445555,0.16843335,C
12469,"For our results, we only need that
Mn ≤ cCovn/ log p for n suﬃciently large, however, this could open up further research into the
setting where γ ∈ (1/2, 1), i.e., when m∗s,γ can be of order n/ log p, see also Barron et al.","Note that Lemma 2.4 (iii) and (iv) improve
the control to subsets J with cardinality of order up to n/ log p from Lemma A.2 in Ing and Lai
[13], where only subsets of order n/ log p could be handled.",[1].,2022-10-14 14:23:40+00:00,Early stopping for $ L^2 $-boosting in high-dimensional linear models,math.ST,"['math.ST', 'stat.TH', '62G05, 62J07 (Primary), 62F35 (Secondary)']",[arxiv.Result.Author('Bernhard Stankewitz')],"Increasingly high-dimensional data sets require that estimation methods do
not only satisfy statistical guarantees but also remain computationally
feasible. In this context, we consider $ L^{2} $-boosting via orthogonal
matching pursuit in a high-dimensional linear model and analyze a data-driven
early stopping time $ \tau $ of the algorithm, which is sequential in the sense
that its computation is based on the first $ \tau $ iterations only. This
approach is much less costly than established model selection criteria, that
require the computation of the full boosting path. We prove that sequential
early stopping preserves statistical optimality in this setting in terms of a
fully general oracle inequality for the empirical risk and recently established
optimal convergence rates for the population risk. Finally, an extensive
simulation study shows that at an immensely reduced computational cost, the
performance of these type of methods is on par with other state of the art
algorithms such as the cross-validated Lasso or model selection via a high
dimensional Akaike criterion based on the full boosting path.",-0.27909315,-0.1337981,0.19861498,C
12798,"They further study the best subsampling ratios for optimal asymptotic risk, but do not consider
the question of how to pick the best subsample size.","They also
study monotonicity of the asymptotic expected squared risk with respect to the number of bags, similar
to ours.","The most crucial diﬀerence between their work and
ours is that we subsample observations (not features) while they consider feature subsampling which is not
appropriate without isotopic covariance.",2022-10-20 17:45:58+00:00,Bagging in overparameterized learning: Risk characterization and risk monotonization,math.ST,"['math.ST', 'stat.ML', 'stat.TH']","[arxiv.Result.Author('Pratik Patil'), arxiv.Result.Author('Jin-Hong Du'), arxiv.Result.Author('Arun Kumar Kuchibhotla')]","Bagging is a commonly used ensemble technique in statistics and machine
learning to improve the performance of prediction procedures. In this paper, we
study the prediction risk of variants of bagged predictors in the proportional
asymptotics regime, in which the ratio of the number of features to the number
of observations converges to a constant. Specifically, we propose a general
strategy to analyze prediction risk under squared error loss of bagged
predictors using classical results on simple random sampling. Specializing the
strategy, we derive the exact asymptotic risk of the bagged ridge and ridgeless
predictors with an arbitrary number of bags under a well-specified linear model
with arbitrary feature covariance matrices and signal vectors. Furthermore, we
prescribe a generic cross-validation procedure to select the optimal subsample
size for bagging and discuss its utility to mitigate the non-monotonic behavior
of the limiting risk in the sample size (i.e., double or multiple descents). In
demonstrating the proposed procedure for bagged ridge and ridgeless predictors,
we thoroughly investigate oracle properties of the optimal subsample size, and
provide an in-depth comparison between different bagging variants.",-0.19819355,-0.01463113,-0.047111843,C
12916,"Ishigami model with a correlated exogenous input

    In order to further study the behavior of the PME, the Ishigami model, well-known in GSA (see,
e.g., [6]), is ﬁrst considered.",5.2.,"The Ishigami model is given by

                                G(X) = sin(X1) + 7 sin2(X2) + 0.1X34 sin(X1).",2022-10-24 09:33:21+00:00,Proportional marginal effects for global sensitivity analysis,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Margot Herin'), arxiv.Result.Author('Marouane Il Idrissi'), arxiv.Result.Author('Vincent Chabridon'), arxiv.Result.Author('Bertrand Iooss')]","Performing (variance-based) global sensitivity analysis (GSA) with dependent
inputs has recently benefited from cooperative game theory concepts.By using
this theory, despite the potential correlation between the inputs, meaningful
sensitivity indices can be defined via allocation shares of the model output's
variance to each input. The ``Shapley effects'', i.e., the Shapley values
transposed to variance-based GSA problems, allowed for this suitable solution.
However, these indices exhibit a particular behavior that can be undesirable:
an exogenous input (i.e., which is not explicitly included in the structural
equations of the model) can be associated with a strictly positive index when
it is correlated to endogenous inputs. In the present work, the use of a
different allocation, called the ``proportional values'' is investigated. A
first contribution is to propose an extension of this allocation, suitable for
variance-based GSA. Novel GSA indices are then proposed, called the
``proportional marginal effects'' (PME). The notion of exogeneity is formally
defined in the context of variance-based GSA, and it is shown that the PME
allow the distinction of exogenous variables, even when they are correlated to
endogenous inputs. Moreover, their behavior is compared to the Shapley effects
on analytical toy-cases and more realistic use-cases.",-0.12774803,0.0144947665,-0.01975397,C
13424,"j∈Λ2                        Π2
                    n
22                   DAMEK, MIKOSCH, ZHAO, ZIENKIEWICZ

We further study the expressions of ∂Fn(ω, Θ)/∂θs1 and ∂2Fn(ω, Θ)/(∂θs1∂θs2) for si ∈ {1, .","σ2n(Θ)                    σ2(Θ)

By Kolmogorov’s formula (see Brockwell and Davis [8], Theorem 5.8.1),

(8.3)                     log Fn(λj, Θ) = log F (ω, Θ) dω = 0 ,    Θ ∈Θ.",.,2022-11-07 01:54:32+00:00,Whittle estimation based on the extremal spectral density of a heavy-tailed random field,math.ST,"['math.ST', 'math.PR', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Ewa Damek'), arxiv.Result.Author('Thomas Mikosch'), arxiv.Result.Author('Yuwei Zhao'), arxiv.Result.Author('Jacek Zienkiewicz')]","We consider a strictly stationary random field on the two-dimensional integer
lattice with regularly varying marginal and finite-dimensional distributions.
Exploiting the regular variation, we define the spatial extremogram which takes
into account only the largest values in the random field. This extremogram is a
spatial autocovariance function. We define the corresponding extremal spectral
density and its estimator, the extremal periodogram. Based on the extremal
periodogram, we consider the Whittle estimator for suitable classes of
parametric random fields including the Brown-Resnick random field and regularly
varying max-moving averages.",-0.22918554,-0.08396313,0.12836668,C
13582,We further study some properties of Cs(X).,"They also discussed relative

cumulative residual information generating measure to study the closeness between two

survival function.","We also discuss the

nonparametric estimation of Cs(X).",2022-11-10 10:57:07+00:00,Dynamic Cumulative Residual Entropy Generating Function and its properties,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Smitha S.'), arxiv.Result.Author('Sudheesh K. K.'), arxiv.Result.Author('Sreedevi E. P.')]","In this work, we study the properties of cumulative residual entropy
generating function. We then introduce dynamic cumulative residual entropy
generating function (DCREGF). It is shown that the DCREGF determines the
distribution uniquely. We study some characterization results using the
relationship between DCREGF and hazard rate and mean residual life function. A
new class of life distribution based on decreasing DCREGF is introduced.
Finally we develop a test for decreasing DCREGF and study its performance.",-0.059672445,-0.13334182,-0.23967409,B
14205,"We can
further study lower bounds of this approximation error within speciﬁc families of approximations.","First, we have established upper
bounds for the approximation error to the original Gaussian process in Wasserstein-2 distance.","It will
be helpful to examine when the norm-controlled inversion bounds we have used in the proofs are tight, and
whether the derived conditions on the approximation radius ρ for various covariance functions in Corollary
1 can be made optimal for such families.",2022-11-27 00:57:29+00:00,Radial Neighbors for Provably Accurate Scalable Approximations of Gaussian Processes,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Yichen Zhu'), arxiv.Result.Author('Michele Peruzzi'), arxiv.Result.Author('Cheng Li'), arxiv.Result.Author('David. B. Dunson')]","In geostatistical problems with massive sample size, Gaussian processes (GP)
can be approximated using sparse directed acyclic graphs to achieve scalable
$O(n)$ computational complexity. In these models, data at each location are
typically assumed conditionally dependent on a small set of parents which
usually include a subset of the nearest neighbors. These methodologies often
exhibit excellent empirical performance, but the lack of theoretical validation
leads to unclear guidance in specifying the underlying graphical model and may
result in sensitivity to graph choice. We address these issues by introducing
radial neighbors Gaussian processes and corresponding theoretical guarantees.
We propose to approximate GPs using a sparse directed acyclic graph in which a
directed edge connects every location to all of its neighbors within a
predetermined radius. Using our novel construction, we show that one can
accurately approximate a Gaussian process in Wasserstein-2 distance, with an
error rate determined by the approximation radius, the spatial covariance
function, and the spatial dispersion of samples. Our method is also insensitive
to specific graphical model choice. We offer further empirical validation of
our approach via applications on simulated and real world data showing
state-of-the-art performance in posterior inference of spatial random effects.",-0.42400903,0.0845949,0.0937461,C_centroid
14206,"We can
further study lower bounds of this approximation error within speciﬁc families of approximations.","First, we have established upper

bounds for the approximation error to the original Gaussian process in Wasserstein-2 distance.","It will
be helpful to examine when the norm-controlled inversion bounds we have used in the proofs are tight, and
whether the derived conditions on the approximation radius ρ for various covariance functions in Corollary
1 can be made optimal for such families.",2022-11-27 00:57:29+00:00,Radial Neighbors for Provably Accurate Scalable Approximations of Gaussian Processes,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Yichen Zhu'), arxiv.Result.Author('Michele Peruzzi'), arxiv.Result.Author('Cheng Li'), arxiv.Result.Author('David. B. Dunson')]","In geostatistical problems with massive sample size, Gaussian processes (GP)
can be approximated using sparse directed acyclic graphs to achieve scalable
$O(n)$ computational complexity. In these models, data at each location are
typically assumed conditionally dependent on a small set of parents which
usually include a subset of the nearest neighbors. These methodologies often
exhibit excellent empirical performance, but the lack of theoretical validation
leads to unclear guidance in specifying the underlying graphical model and may
result in sensitivity to graph choice. We address these issues by introducing
radial neighbors Gaussian processes and corresponding theoretical guarantees.
We propose to approximate GPs using a sparse directed acyclic graph in which a
directed edge connects every location to all of its neighbors within a
predetermined radius. Using our novel construction, we show that one can
accurately approximate a Gaussian process in Wasserstein-2 distance, with an
error rate determined by the approximation radius, the spatial covariance
function, and the spatial dispersion of samples. Our method is also insensitive
to specific graphical model choice. We offer further empirical validation of
our approach via applications on simulated and real world data showing
state-of-the-art performance in posterior inference of spatial random effects.",-0.42400903,0.0845949,0.0937461,C
14207,"We can
further study lower bounds of this approximation error within speciﬁc families of approximations.","First, we have established upper
bounds for the approximation error to the original Gaussian process in Wasserstein-2 distance.","It will
be helpful to examine when the norm-controlled inversion bounds we have used in the proofs are tight, and
whether the derived conditions on the approximation radius ρ for various covariance functions in Corollary
1 can be made optimal for such families.",2022-11-27 00:57:29+00:00,Radial Neighbors for Provably Accurate Scalable Approximations of Gaussian Processes,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Yichen Zhu'), arxiv.Result.Author('Michele Peruzzi'), arxiv.Result.Author('Cheng Li'), arxiv.Result.Author('David B. Dunson')]","In geostatistical problems with massive sample size, Gaussian processes (GP)
can be approximated using sparse directed acyclic graphs to achieve scalable
$O(n)$ computational complexity. In these models, data at each location are
typically assumed conditionally dependent on a small set of parents which
usually include a subset of the nearest neighbors. These methodologies often
exhibit excellent empirical performance, but the lack of theoretical validation
leads to unclear guidance in specifying the underlying graphical model and may
result in sensitivity to graph choice. We address these issues by introducing
radial neighbors Gaussian processes and corresponding theoretical guarantees.
We propose to approximate GPs using a sparse directed acyclic graph in which a
directed edge connects every location to all of its neighbors within a
predetermined radius. Using our novel construction, we show that one can
accurately approximate a Gaussian process in Wasserstein-2 distance, with an
error rate determined by the approximation radius, the spatial covariance
function, and the spatial dispersion of samples. Our method is also insensitive
to specific graphical model choice. We offer further empirical validation of
our approach via applications on simulated and real world data showing
state-of-the-art performance in posterior inference of spatial random effects.",-0.42400903,0.0845949,0.0937461,C
14320,"In Section 7.3, we further study the empirical power of
RPT and RPTEM.","What’s more interesting, the size of RPTEM is also valid across all the simulation settings, even
with heavy-tailed noises and heavy-tailed design.","17
                            RPTEM                    RPT               dbLasso

n p X noise 0.01            0.005        0.01             0.005  0.01  0.005

300 100 Gauss.",2022-11-29 13:24:12+00:00,Residual Permutation Test for High-Dimensional Regression Coefficient Testing,math.ST,"['math.ST', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Kaiyue Wen'), arxiv.Result.Author('Tengyao Wang'), arxiv.Result.Author('Yuhao Wang')]","We consider the problem of testing whether a single coefficient is equal to
zero in high-dimensional fixed-design linear models. In the high-dimensional
setting where the dimension of covariates $p$ is allowed to be in the same
order of magnitude as sample size $n$, to achieve finite-population validity,
existing methods usually require strong distributional assumptions on the noise
vector (such as Gaussian or rotationally invariant), which limits their
applications in practice. In this paper, we propose a new method, called
\emph{residual permutation test} (RPT), which is constructed by projecting the
regression residuals onto the space orthogonal to the union of the column
spaces of the original and permuted design matrices. RPT can be proved to
achieve finite-population size validity under fixed design with just
exchangeable noises, whenever $p < n / 2$. Moreover, RPT is shown to be
asymptotically powerful for heavy tailed noises with bounded $(1+t)$-th order
moment when the true coefficient is at least of order $n^{-t/(1+t)}$ for $t \in
[0,1]$. We further proved that this signal size requirement is essentially
optimal in the minimax sense. Numerical studies confirm that RPT performs well
in a wide range of simulation settings with normal and heavy-tailed noise
distributions.",-0.28138083,-0.037824593,0.03017005,C
14804,"We hope these ﬁndings encourage further research into
                                                  robust validation of survival models and promote honest evaluation.","We further
                                                  prove that under a strict set of assumptions a class of scoring rules is strictly proper for, what
                                                  we term, ‘approximate’ survival losses.","1 Introduction

                                          Scoring rules evaluate probabilistic predictions and (attempt to) measure the overall predictive abil-
                                          ity of a model as a combination of calibration and discrimination [Gneiting and Raftery, 2007,
                                          Murphy, 1973].",2022-12-10 10:34:35+00:00,Scoring rules in survival analysis,math.ST,"['math.ST', 'cs.LG', 'stat.AP', 'stat.TH']",[arxiv.Result.Author('Raphael Sonabend')],"Scoring rules promote rational and good decision making and predictions by
models, this is increasingly important for automated procedures of `auto-ML'.
The Brier score and Log loss are well-established scoring rules for
classification and regression and possess the `strict properness' property that
encourages optimal predictions. In this paper we survey proposed scoring rules
for survival analysis, establish the first clear definition of `(strict)
properness' for survival scoring rules, and determine which losses are proper
and improper. We prove that commonly utilised scoring rules that are claimed to
be proper are in fact improper. We further prove that under a strict set of
assumptions a class of scoring rules is strictly proper for, what we term,
`approximate' survival losses. We hope these findings encourage further
research into robust validation of survival models and promote honest
evaluation.",0.082231395,-0.1244037,-0.2550273,B
14845,"Then comparing PW

with PR, we can imagine that when the number of spikes increases to inﬁnity, test W may

have better performance than test R. But it is not the focus of this paper, therefore, we decide

to leave it in our further research.","Then we ﬁnd PR tends to 1 whe√ther the spiked
           n
eigenvalues α1 are bounded or unbounded, and the convergence rate is α1 n. When the

largest population eigenvalue α1 is simple, that is, d1 = 1, therefore, the largest eigenvalue

turns out to be the only element of the GOE, a normal random variable.","We conclude the subsection by reporting a small Monte-Carlo experiment that demon-

strates our analysis of the power of U, W, V, R under the spiked model.",2022-12-12 13:52:47+00:00,A CLT for the LSS of large dimensional sample covariance matrices with diverging spikes,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Zhijun Liu'), arxiv.Result.Author('Jiang Hu'), arxiv.Result.Author('Zhidong Bai'), arxiv.Result.Author('Haiyan Song')]","In this paper, we establish the central limit theorem (CLT) for linear
spectral statistics (LSS) of large-dimensional sample covariance matrix when
the population covariance matrices are not uniformly bounded, which is a
nontrivial extension of the Bai-Silverstein theorem (BST) (2004). The latter
has strongly influenced the development of high-dimensional statistics,
especially in applications of random matrix theory to statistics. However, the
assumption of uniform boundedness of the population covariance matrices has
seriously limited the applications of the BST. The aim of this paper is to
remove the barriers for the applications of the BST. The new CLT, allows spiked
eigenvalues to exist, which may be bounded or tend to infinity. An important
feature of our result is that the roles of either spiked eigenvalues or the
bulk eigenvalues predominate in the CLT, depending on which variance is
nonnegligible in the summation of the variances. The CLT for LSS is then
applied to compare four linear hypothesis tests: The Wilk's likelihood ratio
test, the Lawly-Hotelling trace test, the Bartlett-Nanda-Pillai trace test, and
Roy's largest root test. We also derive and analyze their power function under
particular alternatives.",-0.23687255,-0.082930654,0.08840651,C
14846,"Then comparing PW

with PR, we can imagine that when the number of spikes increases to inﬁnity, test W may

have better performance than test R. But it is not the focus of this paper, therefore, we decide

to leave it in our further research.","Then we ﬁnd PR tends to 1 whe√ther the spiked
           n
eigenvalues α1 are bounded or unbounded, and the convergence rate is α1 n. When the

largest population eigenvalue α1 is simple, that is, d1 = 1, therefore, the largest eigenvalue

turns out to be the only element of the GOE, a normal random variable.","We conclude the subsection by reporting a small Monte-Carlo experiment that demon-

strates our analysis of the power of U, W, V, R under the spiked model.",2022-12-12 13:52:47+00:00,A CLT for the LSS of large dimensional sample covariance matrices with diverging spikes,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Zhijun Liu'), arxiv.Result.Author('Jiang Hu'), arxiv.Result.Author('Zhidong Bai'), arxiv.Result.Author('Haiyan Song')]","In this paper, we establish the central limit theorem (CLT) for linear
spectral statistics (LSS) of large-dimensional sample covariance matrix when
the population covariance matrices are not uniformly bounded, which is a
nontrivial extension of the Bai-Silverstein theorem (BST) (2004). The latter
has strongly influenced the development of high-dimensional statistics,
especially in applications of random matrix theory to statistics. However, the
assumption of uniform boundedness of the population covariance matrices has
seriously limited the applications of the BST. The aim of this paper is to
remove the barriers for the applications of the BST. The new CLT, allows spiked
eigenvalues to exist, which may be bounded or tend to infinity. An important
feature of our result is that the roles of either spiked eigenvalues or the
bulk eigenvalues predominate in the CLT, depending on which variance is
nonnegligible in the summation of the variances. The CLT for LSS is then
applied to compare four linear hypothesis tests: The Wilk's likelihood ratio
test, the Lawly-Hotelling trace test, the Bartlett-Nanda-Pillai trace test, and
Roy's largest root test. We also derive and analyze their power function under
particular alternatives.",-0.23687255,-0.082930654,0.08840651,C
15272,"Finally, further research will be devoted to investigate if the censoring could also be
used to introduce a general goodness-of-ﬁt test for count distributions (also without any
moments) as few proposals are available and many of them, being tailored to deal with
particular distributions, are of limited applicability.","are involved and they can be straightforwardly
obtained by means of Proposition 1.","Appendix A: Proof of Proposition 1

Since P (Tp ≤ n) = 1 − (1 − p)n, for n ≥ 1 it holds
                       P (Y = n) = P (X = n)P (Tp > n) = P (X = n)(1 − p)n.

Moreover, it must be pointed out that

                                                       ∞

                                           g(1 − p) = (1 − p)nP (X = n) = P (Tp > X).",2022-12-22 13:40:51+00:00,Censoring heavy-tail count distributions for parameters estimation with an application to stable distributions,math.ST,"['math.ST', 'stat.TH']","[arxiv.Result.Author('Antonio Di Noia'), arxiv.Result.Author('Marzia Marcheselli'), arxiv.Result.Author('Caterina Pisani'), arxiv.Result.Author('Luca Pratelli')]","Some families of count distributions do not have a closed form of the
probability mass function and/or finite moments and therefore parameter
estimation can not be performed with the classical methods. When the
probability generating function of the distribution is available, a new
approach based on censoring and moment criterion is introduced, where the
original distribution is replaced with that censored by using a Geometric
distribution. Consistency and asymptotic normality of the resulting estimators
are proven under suitable conditions. The crucial issue of selecting the
censoring parameter is addressed by means of a data-driven procedure. Finally,
this novel approach is applied to the discrete stable family and the finite
sample performance of the estimators is assessed by means of a Monte Carlo
simulation study.",0.02627381,-0.14900793,-0.092464596,B
15314,"For further study, we impose the following conditions:

C1.",", p2
are the eigenvalues of

                                         Ω n = Cov(w¯ 1 − w¯ 2) = Ω 1/n1 + Ω 2/n2,

and set cn,p,r = λn,p,r/ tr(Ω 2n).","As n → ∞, we have n1/n → τ ∈ (0, ∞).",2022-12-23 13:42:44+00:00,Two-Sample Test for High-Dimensional Covariance Matrices: a normal-reference approach,math.ST,"['math.ST', 'stat.CO', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Jin-Ting Zhang'), arxiv.Result.Author('Jingyi Wang'), arxiv.Result.Author('Tianming Zhu')]","Testing the equality of the covariance matrices of two high-dimensional
samples is a fundamental inference problem in statistics. Several tests have
been proposed but they are either too liberal or too conservative when the
required assumptions are not satisfied which attests that they are not always
applicable in real data analysis. To overcome this difficulty, a
normal-reference test is proposed and studied in this paper. It is shown that
under some regularity conditions and the null hypothesis, the proposed test
statistic and a chi-square-type mixture have the same limiting distribution. It
is then justified to approximate the null distribution of the proposed test
statistic using that of the chi-square-type mixture. The distribution of the
chi-square-type mixture can be well approximated using a three-cumulant matched
chi-square-approximation with its approximation parameters consistently
estimated from the data. The asymptotic power of the proposed test under a
local alternative is also established. Simulation studies and a real data
example demonstrate that in terms of size control, the proposed test
outperforms the existing competitors substantially.",-0.34988976,0.06960677,0.1777463,C
15315,"A further study on chen qin’s test for two-sample behrens–ﬁsher
   problems for high-dimensional data.","Zhang, J.-T. and Zhu, T. (2022).","Journal of Statistical Theory and Practice, 16:1.",2022-12-23 13:42:44+00:00,Two-Sample Test for High-Dimensional Covariance Matrices: a normal-reference approach,math.ST,"['math.ST', 'stat.CO', 'stat.ME', 'stat.TH']","[arxiv.Result.Author('Jin-Ting Zhang'), arxiv.Result.Author('Jingyi Wang'), arxiv.Result.Author('Tianming Zhu')]","Testing the equality of the covariance matrices of two high-dimensional
samples is a fundamental inference problem in statistics. Several tests have
been proposed but they are either too liberal or too conservative when the
required assumptions are not satisfied which attests that they are not always
applicable in real data analysis. To overcome this difficulty, a
normal-reference test is proposed and studied in this paper. It is shown that
under some regularity conditions and the null hypothesis, the proposed test
statistic and a chi-square-type mixture have the same limiting distribution. It
is then justified to approximate the null distribution of the proposed test
statistic using that of the chi-square-type mixture. The distribution of the
chi-square-type mixture can be well approximated using a three-cumulant matched
chi-square-approximation with its approximation parameters consistently
estimated from the data. The asymptotic power of the proposed test under a
local alternative is also established. Simulation studies and a real data
example demonstrate that in terms of size control, the proposed test
outperforms the existing competitors substantially.",-0.19925195,-0.06030911,0.094965115,C
15381,"For further study, we now derive the ﬁrst three cumulants (mean,
variance, and third central moment) of Tn∗,p,0, Sn∗,p,0, and Fn∗,p,0.","In what follows, we shall show that we can approximate the distribution of Fn,p,0 using the

distribution of Fn∗,p,0 asymptotically.","For simplicity, let Kl(X), l = 1, 2, 3
denote the ﬁrst three cumulants of a random variable X.",2022-12-27 06:14:17+00:00,Two-sample Behrens--Fisher problems for high-dimensional data: a normal reference F-type test,math.ST,"['math.ST', 'stat.CO', 'stat.TH']","[arxiv.Result.Author('Tianming Zhu'), arxiv.Result.Author('Pengfei Wang'), arxiv.Result.Author('Jin-Ting Zhang')]","The problem of testing the equality of mean vectors for high-dimensional data
has been intensively investigated in the literature. However, most of the
existing tests impose strong assumptions on the underlying group covariance
matrices which may not be satisfied or hardly be checked in practice. In this
article, an F-type test for two-sample Behrens--Fisher problems for
high-dimensional data is proposed and studied. When the two samples are
normally distributed and when the null hypothesis is valid, the proposed F-type
test statistic is shown to be an F-type mixture, a ratio of two independent
chi-square-type mixtures. Under some regularity conditions and the null
hypothesis, it is shown that the proposed F-type test statistic and the above
F-type mixture have the same normal and non-normal limits. It is then justified
to approximate the null distribution of the proposed F-type test statistic by
that of the F-type mixture, resulting in the so-called normal reference F-type
test. Since the F-type mixture is a ratio of two independent chi-square-type
mixtures, we employ the Welch--Satterthwaite chi-square-approximation to the
distributions of the numerator and the denominator of the F-type mixture
respectively, resulting in an approximation F-distribution whose degrees of
freedom can be consistently estimated from the data. The asymptotic power of
the proposed F-type test is established. Two simulation studies are conducted
and they show that in terms of size control, the proposed F-type test
outperforms two existing competitors. The proposed F-type test is also
illustrated by a real data example.",-0.14101788,-0.13091189,-0.075865254,B
