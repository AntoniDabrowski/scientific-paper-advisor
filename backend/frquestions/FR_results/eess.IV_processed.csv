url,title,further research,primary category,label,x,y,z
http://arxiv.org/pdf/2201.00163v1,Development of Diabetic Foot Ulcer Datasets: An Overview,"Other than DFU images, researchers have used
other imaging modalities such as infrared, Magnetic Resonance Imaging (MRI),
and Ô¨Çuorescence imaging for the management of DFU. However, there are no
such public datasets of other imaging modalities available for further research
and development of AI solutions for multi-modality datasets. In many research studies, thermal infrared imaging has been proven to be a
useful technique in the clinical management of DFU. ",eess.IV,C,-0.12344247,-0.133066,-0.20668122
http://arxiv.org/pdf/2201.00169v1,Dynamic Scene Video Deblurring using Non-Local Attention,"The proposed model performs favorably against state-of-
the-art methods while being efÔ¨Åcient. Such a system can be extended to existing video deblurring methods or other
video-processing tasks and will be explored in our future works. ReÔ¨Åned and complete version of this work appeared in
CVPR 2021. ",eess.IV,A,0.3561686,-0.045670286,0.14978172
http://arxiv.org/pdf/2201.00259v1,Subspace modeling for fast and high-sensitivity X-ray chemical imaging,"The pro-
                                                                  posed approach can be easily extended to 3D chemical
                                                                  imaging by rotating the sample [16]. Another direction of
                                                                  our future work is to adaptively select the energy points to
                                                                  further reduce the acquisition time and enable efÔ¨Åcient au-
                                                                  tonomous experiments [31]. Moreover, the proposed algo-
                                                                  rithm is not limited to X-ray imaging. ",eess.IV,A,0.1893746,-0.26425254,-0.19938469
http://arxiv.org/pdf/2201.00895v1,A Gradient Mapping Guided Explainable Deep Neural Network for Extracapsular Extension Identification in 3D Head and Neck Cancer Computed Tomography Images,"Data preparation and experimental results are
illustrated in Section 4. The research Ô¨Åndings and future work are concluded in
Section 5. 2. ",eess.IV,B,0.17792295,0.41689315,-0.1990717
http://arxiv.org/pdf/2201.00957v1,Stain Normalized Breast Histopathology Image Recognition using Convolutional Neural Networks for Cancer Detection,"With
accuracy attained on par with the state-of-the-art models in the literature, we can submit that our system
can reliably facilitate breast cancer detection by analysing biopsy images. As future work, devising
mechanisms to select most appropriate template images for stain normalization can enhance the whole
process significantly. To train and evaluate the system based on multiple datasets will enable better
evaluation of the effectiveness of the classification process. ",eess.IV,C,-0.34761488,-0.03380858,-0.1052475
http://arxiv.org/pdf/2201.01014v4,MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution,"change, the motion compensation by LSTAs in these cases
can be wrong and our approach may not be able to effectively                    [16] L. Wang, Y. Guo, Y. Wang, Z. Liang, Z. Lin, J. Yang, and W. An,
recover the targets. In future work, we aim to improve the                            ‚ÄúParallax attention for unsupervised stereo correspondence learning,‚Äù
robustness of our method to large motion and sudden change. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020. ",eess.IV,A,0.10344416,-0.12626812,0.18778782
http://arxiv.org/pdf/2201.01034v1,What Hinders Perceptual Quality of PSNR-oriented Methods?,"However, due to the hardware memory constraints, the                     on Computer Vision and Pattern Recognition, pages 6070‚Äì
patch size cannot be reduced inÔ¨Ånitely; thus, how to Ô¨Ånd                      6079, 2017. 1
this trade-off will be the key to our important future work. [13] Justin Johnson, Alexandre Alahi, and Li Fei-Fei. ",eess.IV,A,0.14427641,0.058104485,0.028305199
http://arxiv.org/pdf/2201.01426v1,Advancing 3D Medical Image Analysis with Variable Dimension Transform based Supervised 3D Pre-training,"Visual comparison of our proposed methods with competing pre-training methods and training from scratch on the LITS dataset. patches with a sliding stride of 12 √ó 128 √ó 128 to get the           To further study the impact of domain difference on the
prediction for the whole CT. Data augmentation in the training       performance of transfer learning, we conduct an ablation study
stage includes random cropping, Ô¨Çipping and re-scaling, and          on our proposed SVD-Net. SpeciÔ¨Åcally, by keeping the pre-
no test-time augmentation is implemented. ",eess.IV,C,-0.18113741,-0.15706742,0.116807446
http://arxiv.org/pdf/2201.01443v1,Neural KEM: A Kernel Method with Deep Coefficient Prior for PET Image Reconstruction,"advent of total-body PET scanners (e.g., [40]‚Äì[44]) has made
                                                                   it even more feasible to pursue low-dose dynamic imaging
C. Demonstration for Parametric Imaging                            and high-temporal resolution dynamic imaging, especially for
                                                                   the entire body simultaneously. Our future work will also
   Parametric imaging was also performed for the dynamic           implement and evaluate the proposed neural KEM on total-
images of the same subject. The descending aorta region            body PET for parametric imaging. ",eess.IV,C,-0.024479128,-0.25645718,-0.33463722
http://arxiv.org/pdf/2201.01443v2,Neural KEM: A Kernel Method with Deep Coefficient Prior for PET Image Reconstruction,"Computer
this paper can be also transferred into those methods that use    simulations and real patient data have demonstrated the im-
a modiÔ¨Åed or trained kernel. A detailed study will be reported    provement of the neural KEM over conventional KEM and
in our future work. DIP methods for dynamic PET imaging. ",eess.IV,C,-0.10033712,-0.17901406,-0.14371854
http://arxiv.org/pdf/2201.01586v1,Learning True Rate-Distortion-Optimization for End-To-End Image Compression,"This variant does not require
any RDO search. In future work, this approach can be extended to video compression, where adap-
tive block partitioning is Ô¨Årmly established in traditional coders. We therefore expect
similar gain in this Ô¨Åeld, in particular we can thereby take the spatially varying inter
prediction quality into account. ",eess.IV,A,0.28900087,0.004368739,0.17773266
http://arxiv.org/pdf/2201.02226v1,Second-Order Ultrasound Elastography with L1-norm Spatial Regularization,"515‚Äì534, 2013.
rameters related to imaging physics. Since this automatic
parameter estimation strategy demands extensive investigation,     [4] H. Rivaz, E. M. Boctor, M. A. Choti, and G. D. Hager, ‚ÄúReal-time
we postpone it as future work. regularized ultrasound elastography,‚Äù IEEE Transactions on Medical
                                                                        Imaging, vol. ",eess.IV,B,0.016068276,-0.10522515,-0.34240693
http://arxiv.org/pdf/2201.02242v1,A Keypoint Detection and Description Network Based on the Vessel Structure for Multi-Modal Retinal Image Registration,"Thus, our method can be very beneÔ¨Åcial to support the long time analysis of
       retinal disease progression. As future work, we will investigate deep learning
       methods inspired by known operators for our registration pipeline. References

        1. ",eess.IV,C,-0.26561892,-0.12766455,0.13387224
http://arxiv.org/pdf/2201.02295v1,Persistent Homology for Breast Tumor Classification using Mammogram Scans,"Future
work will also focus on using other texture methods as landmark selections such as
center-symmetric LBP. Furthermore, testing proposed ULBP based PH on other med-
ical image modalities such as ultrasounds and other types of disease is included in our
list of future works. 7 References

[1] G. Carlsson, ‚ÄúTOPOLOGY AND DATA,‚Äù Bull. ",eess.IV,C,-0.047946773,-0.047003567,-0.36993238
http://arxiv.org/pdf/2201.02295v2,Persistent Homology for Breast Tumor Classification using Mammogram Scans,"Future work will also focus on using other texture methods as landmark selec-
tion procedure such as center-symmetric LBP or small image patches of high density. Furthermore, testing proposed ULBP based PH on other medical image modalities such
as ultrasounds and other types of disease is included in our list of future works. References

[1] G. Carlsson, ‚ÄúTOPOLOGY AND DATA,‚Äù Bull. ",eess.IV,C,-0.028650869,-0.08251266,-0.39248517
http://arxiv.org/pdf/2201.02309v1,A three-dimensional dual-domain deep network for high-pitch and sparse helical CT reconstruction,"4173‚Äì4185, Nov. 2008.
memory and isn‚Äôt Ô¨Åt for deep learning. In our future work, we
will research how to solve this issue. [18] W. Yu and L. Zeng, ‚ÄúIterative image reconstruction for limited-angle
                                                                                      inverse helical cone-beam computed tomography,‚Äù Scanning, vol. ",eess.IV,A,0.048964925,-0.38552284,-0.031844407
http://arxiv.org/pdf/2201.02420v1,Auto-Weighted Layer Representation Based View Synthesis Distortion Estimation for 3-D Video Coding,"6, pp. D video coding in our future work, such as optimizing 3-D                        953‚Äì966, 2016.

coding by Ô¨Åguring out the exact contribution of S-VSDs to                        [20] T. Chen and C. Guestrin, ‚ÄúXgboost: A scalable tree boosting system,‚Äù

the VSD, building a more efÔ¨Åcient deep codec by increasing                       in Proceedings of the 22nd acm sigkdd international conference on

and decreasing different levels of depth changes to bring in                     knowledge discovery and data mining, 2016, pp. 785‚Äì794. ",eess.IV,A,0.1380151,0.07372652,0.36663938
http://arxiv.org/pdf/2201.02656v1,GPU-Net: Lightweight U-Net with more diverse features,"We test our method on three dataset
                                                                    and visualize several feature maps to proof the effectiveness
                                                                    and efÔ¨Åciency of our method. Our plug-and-play GP-module
                                                                    can also be applied to existing segmentation methods to fur-
                                                                    ther improve their performance with fewer parameters and
                                                                    fewer FLOPs, which shed the light on the further research. 4.3. ",eess.IV,C,-0.033890605,0.1430183,0.22749841
http://arxiv.org/pdf/2201.02771v1,A Sneak Attack on Segmentation of Medical Images Using Deep Neural Network Classifiers,"1201‚Äì1214,
Ô¨Åcation. In future works, we would test other techniques, such                 1995. [Online]. ",eess.IV,B,0.15532905,0.33663732,-0.17130482
http://arxiv.org/pdf/2201.02771v2,A Sneak Attack on Segmentation of Medical Images Using Deep Neural Network Classifiers,"Yang, and J. Emer, ‚ÄúEfÔ¨Åcient Processing
Ô¨Åcation. In future works, we would test other techniques, such          of Deep Neural Networks: A Tutorial and Survey,‚Äù arXiv:1703.09039
as Saliency map [9], SHAP [13], and Activation map [10],                [cs], Mar. 2017, arXiv: 1703.09039. ",eess.IV,A,0.029933516,-0.08742091,0.28151894
http://arxiv.org/pdf/2201.02867v1,Deep Generative Modeling for Volume Reconstruction in Cryo-Electron Microscop,"While this review covers the statistical foundations for modern
reconstruction methods in cryo-EM, it does not address other topics related to statistics such as validation metrics or connections
with statistical thermodynamics. We leave these topics for future work. 1 Generative Modeling for Cryo-EM

The objective of cryo-EM imaging algorithms       Figure 2. ",eess.IV,A,0.24756998,-0.1967045,-0.14419872
http://arxiv.org/pdf/2201.02867v2,Deep Generative Modeling for Volume Reconstruction in Cryo-Electron Microscopy,"While this review covers the statistical foundations for modern
reconstruction methods in cryo-EM, it does not address other topics related to statistics such as validation metrics or connections
with statistical thermodynamics. We leave these topics for future work. 1 Generative Modeling for Cryo-EM

The objective of cryo-EM imaging algorithms       Figure 2. ",eess.IV,A,0.24756998,-0.1967045,-0.14419872
http://arxiv.org/pdf/2201.02973v1,MAXIM: Multi-Axis MLP for Image Processing,"popular MLP-based global models. Our work suggests                 Our future work includes exploring more efÔ¨Åcient models
an effective and efÔ¨Åcient approach for applying gMLP to            for extremely high-resolution image processing, as well as
                                                                   training large models that can adapt on multiple tasks. Broader impacts. ",eess.IV,A,0.09026484,-0.09706768,0.2831995
http://arxiv.org/pdf/2201.02973v2,MAXIM: Multi-Axis MLP for Image Processing,"We demonstrate a few applications, but
                                                                   there are many more possibilities beyond the scope of this

                                                                8
work which could signiÔ¨Åcantly beneÔ¨Åt by using MAXIM. Task          Dataset              #Train    #Test   Test Dubname
Our future work includes exploring more efÔ¨Åcient models           Denoising
for extremely high-resolution image processing, as well as        Deblurring    SIDD [2]                 320      40   SIDD
training large models that can adapt on multiple tasks. DND [72]                    0     50   DND
Broader impacts. ",eess.IV,A_centroid,0.08937998,-0.14204717,0.17743057
http://arxiv.org/pdf/2201.02979v1,Enhanced total variation minimization for stable image reconstruction,"Finally, we make some conclusions in Section 6. 2 Preliminaries

We Ô¨Årst summarize some notation to be used for further analysis and recall some preliminary technical
backgrounds. 2.1 Notation

For any x, y ‚àà Rn, let x, y = xTy be their inner product, and x p (p ‚â• 1) be the usual ‚Ñìp norm of
x. ",eess.IV,B,0.18306537,0.19465883,0.019985849
http://arxiv.org/pdf/2201.03560v2,Iterative training of robust k-space interpolation networks for improved image reconstruction with limited scan specific training samples,"Limitations and Outlook
The performance of iRAKI was evaluated for standard 2D imaging so far. Its applicability for
3D imaging (36)(37), wave-encoding (38), or simultaneous multi-contrast reconstruction
(JVC-GRAPPA) (38) needs to be investigated in future works. One drawback of iRAKI is the increased reconstruction time. ",eess.IV,A,0.2096085,-0.32106274,-0.21058306
http://arxiv.org/pdf/2201.04363v1,ALTRUIST: Alternating Direction Method of Multipliers for Total Variation Regularization in Ultrasound Strain Imaging,"explicitly. Our future work involves incorporating PnP to
The optimal value of this parameter for each dataset will be                                                optimize a novel cost function consisting of L2 data norm
obtained using L-curve [48]. Once the continuity parameters                                                 and deep learning-based denoising prior. ",eess.IV,A,0.0663432,-0.05710666,0.060871962
http://arxiv.org/pdf/2201.04363v2,Ultrasound Strain Imaging using ADMM,"In addition, ALTRUIST is                                  librium instead of solving the inverse problem explicitly. Our
a fast strain imaging technique, where the runtime can be fur-                                future work involves incorporating PnP to optimize a novel cost
ther accelerated by optimizing its implementation on a GPU. function consisting of L2 data norm and deep learning-based
Finally, an appropriate motion pattern between the RF frames                                  denoising prior. ",eess.IV,A,0.11743501,-0.29254353,0.01603192
http://arxiv.org/pdf/2201.04485v1,Depth Estimation from Single-shot Monocular Endoscope Image Using Image Domain Adaptation And Edge-Aware Depth Estimation,"Also, in the experiment using the location identiÔ¨Åcation CNN,
use of the estimated depth image resulted in improvement of averaged identiÔ¨Åcation
accuracy, from 69.2% to 74.1%. Our future work will include investigation of net-
work structures for domain adaptation or depth estimation and applications to scene
understanding of other types of images. Disclosure statement

The authors report there are no competing interests to declare. ",eess.IV,A,-0.00030357763,-0.19161144,0.31781083
http://arxiv.org/pdf/2201.04584v1,ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation,"ECONet achieved 16% higher DICE score in 3√ó lesser time while
requiring around 9000 lesser scribble labelled voxels than DybaORF-Haar-Like. In our future work, we envision using ECONet in our interactive segmentation pipelines,
where it can assist in quick online adaption and learning based on user-scribbles and input
volume data. An extension of this work may also look into extending ECONet for multi-class
online likelihood learning segmentation problems. ",eess.IV,C,-0.18405548,0.10417378,0.39379013
http://arxiv.org/pdf/2201.04584v2,ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation,"ECONet achieved 16% higher DICE score in 3√ó lesser time while
requiring around 9000 lesser scribble labelled voxels than DybaORF-Haar-Like. In our future work, we envision using ECONet in our interactive segmentation pipelines,
where it can assist in quick online adaption and learning based on user-scribbles. In addition,
we will study the quality of annotations achieved by non-experts using ECONet. ",eess.IV,C,-0.21340516,0.14335117,0.4452514
http://arxiv.org/pdf/2201.04584v3,ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation,"ECONet achieved 16%
higher DICE score in 3√ó lesser time while requiring around 9000 lesser scribble labelled
voxels than DybaORF-Haar-Like. In our future work, we will use ECONet within interactive segmentation pipelines, where
it will enable quick online adaption based on user interactions. In addition, we will study the
quality of annotations achieved using ECONet and extend ECONet for multi-class online
likelihood based annotation problems. ",eess.IV,C,-0.20698853,0.2174614,0.4446553
http://arxiv.org/pdf/2201.04584v4,ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation,"ECONet achieved 16%
higher DICE score in 3√ó lesser time while requiring around 9000 lesser scribble labelled
voxels than DybaORF-Haar-Like. In our future work, we will use ECONet within interactive segmentation pipelines, where
it will enable quick online adaption based on user interactions. In addition, we will study the
quality of annotations achieved using ECONet and extend ECONet for multi-class online
likelihood based annotation problems. ",eess.IV,C,-0.20698853,0.2174614,0.4446553
http://arxiv.org/pdf/2201.04703v1,Detection of brain tumors using machine learning algorithms,"[Online]. Available: https:
    The possibility of carrying out future work using a           //www.nature.com/articles/s41598-020-74419-9
greater number of images for algorithm training and /
or images with higher resolution is opened. Likewise,         [7] R. Ranjbarzadeh, A. ",eess.IV,A,0.027251044,-0.051909544,0.07500118
http://arxiv.org/pdf/2201.04795v1,EMT-NET: Efficient multitask network for computer-aided diagnosis of breast cancer,"We compare its performance with a              model‚Äôs sensitivity by increasing the positive weight (ùëæ ). In
                                                                  future work, we will investigate the viability of the proposed
single-task classification (Single-CLF) and segmentation          multitask network on a variety of breast cancer imaging
model (Single-SGM), constructed by MobileNetV1 with the           modalities, and explore the further improvement of the
classification and segmentation branch, respectively. As          sensitivity and specificity of the proposed model. ",eess.IV,C,-0.24052238,0.09156862,0.14833203
http://arxiv.org/pdf/2201.05213v1,Parallel Neural Local Lossless Compression,"Local autoregressive models can also be combined with latent variable models to generate semantic-
coherent images [4]. In this case, the proposed parallelization scheme can be used to improve the
sampling efÔ¨Åciency, which we leave to future work. 3
References

 [1] R. v. d. Berg, A. ",eess.IV,A,0.11975239,-0.09634295,0.26168728
http://arxiv.org/pdf/2201.05213v2,Parallel Neural Local Lossless Compression,"Local autoregressive models can also be combined with latent variable models to generate semantic-
coherent images [4]. In this case, the proposed parallelization scheme can be used to improve the
sampling efÔ¨Åciency, which we leave to future work. 3
References

 [1] R. v. d. Berg, A. ",eess.IV,A,0.11975239,-0.09634295,0.26168728
http://arxiv.org/pdf/2201.05213v3,Parallel Neural Local Lossless Compression,"Local
autoregressive models can also be combined with latent variable models to generate semantically-
coherent images [7, 28]. In this case, the proposed parallelization schemes can be also used to
improve the sampling efÔ¨Åciency, which we leave to future work. 2The 1024√ó1024 images are provided in the repository, the corresponding result is averaged over 3 images. ",eess.IV,A,0.14619847,-0.13056797,0.2548114
http://arxiv.org/pdf/2201.05483v1,Adaptive Deep PnP Algorithm for Video Snapshot Compressive Imaging,"In: 2011 Inter-
more adaptive and faster for video SCI. Our future work                national Conference on Computer Vision, pp. 287‚Äì294. ",eess.IV,A,0.12479326,-0.05294462,0.27929258
http://arxiv.org/pdf/2201.05483v2,Adaptive Deep PnP Algorithm for Video Snapshot Compressive Imaging,"Guo, S., Liang, Z., Zhang, L.: Joint denoising and de-
other recent restoration algorithms [1, 8, 11] to make it                                     mosaicking with green channel prior for real-world burst
more adaptive and faster for video SCI. Our future work                                       images. arXiv preprint arXiv:2101.09870 (2021)

                                                                                        12. ",eess.IV,A,0.28420168,-0.318664,0.10537774
http://arxiv.org/pdf/2201.06250v1,Improving Clinical Diagnosis Performance with Automated X-ray Scan Quality Enhancement Algorithms,"Hence, acquiring good quality diagnostic images is
essential for analyzing and determining disease occurrence and progression. Due to
the technical restrictions and various economic and physical conditions, there exist
several challenges in obtaining a good quality diagnostic image like low resolution
(LR) images, under-exposure or over-exposure, occurrence of artifacts introduced by
faulty or older scanning equipment etc, which can often render diagnostic scans not
suitable for further analysis [2]. Due to this, methods that improve the spatial resolution of medical images are
gaining increasing importance in clinical workflow management systems. ",eess.IV,C,-0.07092479,-0.20064929,-0.31334502
http://arxiv.org/pdf/2201.06574v1,Neural Computed Tomography,"1041‚Äì1049, 2012.
motion and acquired CT data, we expect NeuralCT to improve
image quality in these scenarios. However, these extensions are                 [6] A. Pourmorteza, K. H. Schuleri, D. A. Herzka, A. C. Lardo, and E. R.
left for future work. McVeigh, ‚ÄúA new method for cardiac computed tomography regional
                                                                                     function assessment: stretch quantiÔ¨Åer for endocardial engraved zones
                         IX. ",eess.IV,C,-0.15355642,-0.25210407,-0.21553494
http://arxiv.org/pdf/2201.07219v1,Is Contrastive Learning Suitable for Left Ventricular Segmentation in Echocardiographic Images?,"For example, there is room for improvement on the
augmentation strategy used in the SimCLR paper because it was targeted at natural images
not medical images. Optimizing this choice should lead to more signiÔ¨Åcant improvements
and is a good direction for future work in this area. Additionally, both SimCLR and BYOL
are sensitive to batch sizes and require very large batch sizes for optimal performance. ",eess.IV,A,0.08075343,-0.055012546,-0.084234715
http://arxiv.org/pdf/2201.07219v2,Contrastive Pretraining for Echocardiography Segmentation with Limited Data,"For example, there is room for improvement on the augmentation strat-
egy used in the SimCLR paper because it targeted natural images not medical
images. Optimizing the choice of augmentations might lead to signiÔ¨Åcant im-
provements and is a good direction for future work in this area. Furthermore, it
was out of the scope of this paper to investigate diÔ¨Äerent UNet or DeeplabV3
variations such as nnUNet [11] and DeeplabV3+ [6] and hence this may be a
good research direction to investigate. ",eess.IV,C,-0.07708367,-0.074871704,0.085314594
http://arxiv.org/pdf/2201.07219v3,Contrastive Pretraining for Echocardiography Segmentation with Limited Data,"For example, there is room for improvement on the augmentation strat-
egy used in the SimCLR paper because it targeted natural images not medical
images. Optimizing the choice of augmentations might lead to signiÔ¨Åcant im-
provements and is a good direction for future work in this area. Furthermore, it
was out of the scope of this paper to investigate diÔ¨Äerent UNet or DeeplabV3
variations such as nnUNet [11] and DeeplabV3+ [6] and hence this may be a
good research direction to investigate. ",eess.IV,C,-0.07708367,-0.074871704,0.085314594
http://arxiv.org/pdf/2201.07231v1,AI-based Carcinoma Detection and Classification Using Histopathological Images: A Systematic Review,"The         performed morphometric analysis of microvessel density
extracted features were statistically analyzed using Wilcoxon    (MVD) and keratin pearls of three diÔ¨Äerent grades of OSCC
rank sum test to identify the top Ô¨Åve histomorphometry fea-      images, captured at 20X and 10X magniÔ¨Åcations. Morpho-
tures for further analysis. In [29], Das et al. ",eess.IV,C,-0.09228199,-0.016753867,-0.34954685
http://arxiv.org/pdf/2201.07404v1,Compressed Smooth Sparse Decomposition,"Its performance of the will be shown empirically in simulation study and case studies. The

theoretical discussion of the KronSSD framework is left for future work. For example, for a 2-D image ùíÄ ‚àà ‚Ñùùëõ1√óùëõ2, when adopting the SSD algorithm (Yan et al., 2017), the

problem formulation becomes:

                  min‚ÄñùíÄ‚Ä≤ ‚àí ùë®1ùë©1ùöØùë©2ùëáùë®2ùëá ‚àí ùë®1ùë©ùëé1ùöØùëéùë©ùëéùëá2ùë®2ùëá‚Äñ2 + ùúÜ‚Äñvec(ùöØùëé)‚Äñ12
                  ùöØ,ùöØùëé

where ùíÄ‚Ä≤ is the compressed image, i.e., ùíÄ‚Ä≤ = ùë®1ùíÄùë®2ùëá. ",eess.IV,A,0.36159483,-0.13629006,-0.091327086
http://arxiv.org/pdf/2201.07404v2,Compressed Smooth Sparse Decomposition,"Its performance will be shown empirically in simulation and case studies. The theoretical

discussion of the KronSSD framework is left for future work. For example, for a 2-D image ùíÄ ‚àà ‚Ñù! ",eess.IV,A,0.32018158,-0.06624058,-0.0059787147
http://arxiv.org/pdf/2201.07411v1,Accurate smartphone camera simulation using 3D scenes,"FUTURE WORK                                                   Properties      Parameters           Values(units)
The results that we report in this paper give us conÔ¨Ådence in      Geometric
our ability to accurately simulate a camera imaging complex,                       Pixel Size           [1.4, 1.4] (¬µm)
natural scenes. Some of the limitations in this work are a         Electronics     Fill Factor          100 (%)
good target for future work. Well Capacity        6000 (e‚àí)
                                                                   Noise Sources   Voltage Swing        0.4591 (volts)
   For example, ISETCam and ISET3d include the ability to          @Analog gain=1  Conversion Gain      0.1707(dv/e‚àí)
simulate microlens arrays. ",eess.IV,A,0.3975446,-0.15768725,-0.04547119
http://arxiv.org/pdf/2201.07411v2,Accurate smartphone camera simulation using 3D scenes,"Some of the limitations in this work are a         Appendix C). good target for future work. We estimated the dark signal nonuniformity (DSNU), pho-
   For example, ISETCam and ISET3d include the ability to          toresponse nonuniformity (PRNU), dark voltage and read
simulate microlens arrays. ",eess.IV,A,0.42503142,-0.023881493,-0.017509596
http://arxiv.org/pdf/2201.07562v1,Learned Cone-Beam CT Reconstruction Using Neural Ordinary Differential Equations,"It can suppress artifacts with non-local extent such as the
cone-beam artifacts while TV depends only on the local gradient information in the image. A detailed comparison of
our method to other learning-based approaches, such as [10], will be performed in future work. Once trained, the reconstruction time of the presented method is comparable to that of classical iterative algorithms. ",eess.IV,A,0.20635232,-0.3295341,0.069099374
http://arxiv.org/pdf/2201.08385v1,Improving Specificity in Mammography Using Cross-correlation between Wavelet and Fourier Transform,"It then searches for any abnormal areas
such as density and calciÔ¨Åcation that may indicate the pathology of breast cancer. These suspicious areas on the images will be marked out by the CAD system,
which could be a sign for the radiologist in further analysis. Generally, a mammographic image could have two basic views: craniocau-
dal (CC) view which is taken from above a horizontally-compressed breast and
mediolateral-oblique (MLO) view which is taken from the side and at an angle of
Rethinking Fairness: Fair Machine Learning Under Uncertainty  3

Fig. ",eess.IV,C,-0.24290526,-0.10662452,-0.26938117
http://arxiv.org/pdf/2201.08385v2,Improving Specificity in Mammography Using Cross-correlation between Wavelet and Fourier Transform,"It then searches for any abnormal areas
such as density and calciÔ¨Åcation that may indicate the pathology of breast cancer. These suspicious areas on the images will be marked out by the CAD system,
which could be a sign for the radiologist in further analysis. Generally, a mammographic image could have two basic views: craniocau-
dal (CC) view which is taken from above a horizontally-compressed breast and
mediolateral-oblique (MLO) view which is taken from the side and at an angle of
Improving SpeciÔ¨Åcity in Mammography  3

Fig. ",eess.IV,C,-0.20035416,-0.10431033,-0.30497956
http://arxiv.org/pdf/2201.08706v1,SparseAlign: A Super-Resolution Algorithm for Automatic Marker Localization and Deformation Estimation in Cryo-Electron Tomography,"These small weighted
markers were removed with a further thresholding step, where         Dt,z(r, P ) = (P0 + P1x + P2y + P3x2 + P4y2 + P5xy)t (31)
markers with weights less than 0.1 were discarded. Improving
marker localization might need changes to the forward model         Additionally, we set the x and y components of the deforma-
used, an aspect that needs further research; however, in our        tion Ô¨Åeld to zero. It is probable that our assumed deformation
experiments, marker localization did not have a signiÔ¨Åcant          Ô¨Åeld was insufÔ¨Åcient to model sample deformation in the
effect on deformation estimation accuracy, as seen from the         experimental data. ",eess.IV,B,0.020566886,0.06598705,-0.14176506
http://arxiv.org/pdf/2201.09360v1,POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection,"Thanks to training with small
patches, our method is less sensitive to the CBs. In future work, we will apply
our method with Vision Transformer (ViT) [26] on a large-scale CXR dataset to
improve the model generalisation with more complex lung disease classes. Acknowledgements

This work is supported in part by the European Union‚Äôs Horizon 2020 research and
innovation programme under grant agreement Sano No. ",eess.IV,C,-0.2532562,0.0118266875,-0.07697031
http://arxiv.org/pdf/2201.09360v2,POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection,"Thanks to training with small
patches, our method is less sensitive to the CBs. In future work, we will apply
our method with Vision Transformer (ViT) [26] on a large-scale CXR dataset to
improve the model generalisation with more complex lung disease classes. Acknowledgements

This work is supported in part by the European Union‚Äôs Horizon 2020 research and
innovation programme under grant agreement Sano No. ",eess.IV,C,-0.2532562,0.0118266875,-0.07697031
http://arxiv.org/pdf/2201.09360v3,POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection,"Thanks to training with small
patches, our method is less sensitive to the CBs. In future work, we will apply
our method with Vision Transformer (ViT) [26] on a large-scale CXR dataset to
improve the model generalisation with more complex lung disease classes. Acknowledgements

This work is supported in part by the European Union‚Äôs Horizon 2020 research
and innovation programme under grant agreement Sano No. ",eess.IV,C,-0.2532562,0.0118266875,-0.07697031
http://arxiv.org/pdf/2201.09360v4,POTHER: Patch-Voted Deep Learning-Based Chest X-ray Bias Analysis for COVID-19 Detection,"Thanks to training with small
patches, our method is less sensitive to the CBs. In future work, we will apply
our method with Vision Transformer (ViT) [26] on a large-scale CXR dataset to
improve the model generalisation with more complex lung disease classes. Acknowledgements

This work is supported in part by the European Union‚Äôs Horizon 2020 research
and innovation programme under grant agreement Sano No. ",eess.IV,C,-0.2532562,0.0118266875,-0.07697031
http://arxiv.org/pdf/2201.09360v5,POTHER: Patch-Voted Deep Learning-Based Chest X-ray Bias Analysis for COVID-19 Detection,"Thanks to training with small
patches, our method is less sensitive to the CBs. In future work, we will apply
our method with Vision Transformer (ViT) [26] on a large-scale CXR dataset to
improve the model generalisation with more complex lung disease classes. Acknowledgements

This work is supported in part by the European Union‚Äôs Horizon 2020 research
and innovation programme under grant agreement Sano No. ",eess.IV,C,-0.2532562,0.0118266875,-0.07697031
http://arxiv.org/pdf/2201.09579v1,AutoSeg -- Steering the Inductive Biases for Automatic Pathology Segmentation,"These
8       F. Meissen et al. Ô¨Åndings motivate us to search for better anomalies with characteristics closer to
real-world pathologies in future work. References

1. ",eess.IV,B,-0.07866511,0.3026571,-0.025897134
http://arxiv.org/pdf/2201.09693v1,Shape-consistent Generative Adversarial Networks for multi-modal Medical segmentation maps,"The good results and robustness           tor D for each domain. The volume to volume translation is
Cycle-GAN showed for many applications made it a popu-              based on CycleGAN U-Net architecture enhanced to 3D vol-
lar backbone in future works. Thus, many unpaired image             umes using 3D convolutions. ",eess.IV,A,0.146528,-0.29097354,0.18139458
http://arxiv.org/pdf/2201.09693v2,Shape-consistent Generative Adversarial Networks for multi-modal Medical segmentation maps,"The good results and robustness           adversarial networks using a generator G and a discrimina-
Cycle-GAN showed for many applications made it a popu-              tor D for each domain. The volume to volume translation is
lar backbone in future works. Thus, many unpaired image             based on CycleGAN U-Net architecture enhanced to 3D vol-
to image transformations are based on this framework with           umes using 3D convolutions. ",eess.IV,A,0.034194626,-0.28972834,0.27271342
http://arxiv.org/pdf/2201.10294v1,S2MS: Self-Supervised Learning Driven Multi-Spectral CT Image Enhancement,"No
                                                                                clean image needed makes the proposed S2MS has potential
                                                                                in practical application. In the future work, our S2MS will
                                                                                be regarded as a priori information to be combined with the
                                                                                material decomposition framework and the experimental data
                                                                                will be used to test the network. Fig. ",eess.IV,A,0.2987417,0.020733286,0.012316817
http://arxiv.org/pdf/2201.10294v2,S2MS: Self-Supervised Learning Driven Multi-Spectral CT Image Enhancement,"No
                                                                                clean image needed makes the proposed S2MS has potential
                                                                                in practical application. In the future work, our S2MS will
                                                                                be regarded as a priori information to be combined with the
                                                                                material decomposition framework and the experimental data
                                                                                will be used to test the network. Fig. ",eess.IV,A,0.2987417,0.020733286,0.012316817
http://arxiv.org/pdf/2201.10424v1,Plaque segmentation via masking of the artery wall,"This way, the improvement in plaque seg-
mentation would also be reÔ¨Çected in the wall segmentation. Such limitation of
the current study will be addressed in our future work. 4 Conclusions

In this paper, we propose a novel methodology for plaque segmentation that
‚Äúmasks‚Äù the input CCTA-CPR artery volume to remove unrelated voxels and
restrict the plaque detection to the artery wall. ",eess.IV,C,-0.09156473,-0.07342152,-0.2085703
http://arxiv.org/pdf/2201.10511v1,Initial Investigations Towards Non-invasive Monitoring of Chronic Wound Healing Using Deep Learning and Ultrasound Imaging,"Generally,
an increase in echogenicity indicates tissue regeneration and wound contraction [12]. This information about wound characteristics can help with automatic wound assessment
in future work. Based on our results, we identify the following challenges: US images are notoriously
diÔ¨Écult to interpret because they can have low contrast as well as imaging artifacts. ",eess.IV,C,-0.22560531,-0.097895265,-0.21439558
http://arxiv.org/pdf/2201.10776v1,DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction,"pairs. In future work, we will investigate reconstruction on
                                                                   pathological data with heterogeneous tissue appearance. Fully-supervised vs. Self-supervised DSFormer. ",eess.IV,C,-0.26444367,-0.11677698,-0.087349705
http://arxiv.org/pdf/2201.10910v1,A Bayesian Based Deep Unrolling Algorithm for Single-Photon Lidar Systems,"To
analyze the proposed network and evaluate the performance of
our method on simulated data as well as real data. Section VI     handle high noise in Lidar data, it is common to incorporate
presents the conclusions and future work. multiscale information, as is done in statistical methods [7],

                                                                  [21] as well as deep learning works [17], [18], [20]. ",eess.IV,A,0.07393596,-0.11969559,0.14348076
http://arxiv.org/pdf/2201.11037v1,RTNet: Relation Transformer Network for Diabetic Retinopathy Multi-lesion Segmentation,"5,
the inadequacy of our network. Therefore, in our future work,                         pp. 584‚Äì592, 2005.
we will further modify the vascular semi-supervised learning
strategy and keep improving the transformer structures to                       [17] S. H. M. Alipour, H. Rabbani, M. Akhlaghi, A. M. Dehnavi, and S. H.
achieve better performance in DR multi-lesion segmentation                            Javanmard, ‚ÄúAnalysis of foveal avascular zone for grading of diabetic
with less memory requirement. ",eess.IV,C,-0.34557217,0.004485926,-0.07657473
http://arxiv.org/pdf/2201.11318v1,Unmixing based PAN guided fusion network for hyperspectral imagery,"In addition,
AVERAGE TESTING TIME AND MODEL PARAMETERS ON                      this fusion network could be adapted to other ratios‚Äô fusion
                                                                  tasks for it achieved excellent generalization performance on
                          CHIKUSEI DATASET                        different fusion ratios‚Äô experiments. Although our method
                                                                  obtained excellent fusion performance, the generality of the
      Method   Time(s)(‚Üì)  Parameters(m)(‚Üì)                       already trained model on different hyperspectral datasets with
       GSA       4.7202             ‚Äî                             different spectral bands still needs further research. SFIM     17.9695             ‚Äî
                 4.3358             ‚Äî                             ACKNOWLEDGEMENT
     Wavelet    12.5180             ‚Äî                                The authors would like to thank Baidu AI Studio for
MTF GLP HPM     43.9069             ‚Äî
                 0.0048            0.13                           providing the computing power supports. ",eess.IV,B,0.20561275,0.24299332,-0.015686866
http://arxiv.org/pdf/2201.11389v1,Multi-Frame Quality Enhancement On Compressed Video Using Quantised Data of Deep Belief Networks,"It was noted that our
                                                                   version of the MFQE approach outperforms the MFQEv1 but it
                                                                   is outperformed by the MFQEv2 approach. For the purpose of
                                                                   future work, it may be necessary to investigte the performance
                                                                   of the MFQE approach for uncompressed video and make use
                                                                   of a vast number of video quality metrics to decide which ones
                                                                   frames are PQF and non-PQF. Figure 11: Relationship between bit-rate, frame-rate, resolu-                              ACKNOWLEDGMENT
tion and video quality
                                                                      I would like to thank Dr Xing, Department of Electronics In-
frame rate, resolution and the video quality. ",eess.IV,A,0.42601293,0.09215164,-0.015916552
http://arxiv.org/pdf/2201.11446v1,Pan-Tumor CAnine cuTaneous Cancer Histology (CATCH) Dataset,"We compensated this by ensuring a similar distribution of scanner
domains in our training and test split and observed similar performances on our test data with mean Jaccard scores of 0.7026
for the ScanScope CS2 and 0.6986 for the AT2. Nevertheless, we are currently creating a multi-scanner dataset of a subset of
the data presented in this work and future work will evaluate the transferability of trained models to unseen scanner domains
and the development of domain-invariant algorithms. Tumor ClassiÔ¨Åcation
Besides tissue segmentation, we trained an additional CNN for tumor subtype classiÔ¨Åcation. ",eess.IV,C,-0.3498961,-0.04370226,0.033076182
http://arxiv.org/pdf/2201.11446v2,Pan-tumor CAnine cuTaneous Cancer Histology (CATCH) dataset,"We compensated for this by ensuring a similar distribution of
scanner domains in our training and test split and observed similar performances on our test data with mean Jaccard coefÔ¨Åcients
of 0.7026 for the ScanScope CS2 and 0.6986 for the AT2. Nevertheless, we are currently creating a multi-scanner dataset of a
subset of the data presented in this work and future work will evaluate the transferability of trained models to unseen scanner
domains and the development of domain-invariant algorithms. Tumor classiÔ¨Åcation
Besides tissue segmentation, we trained an additional CNN for tumor subtype classiÔ¨Åcation. ",eess.IV,C,-0.34223753,-0.04058313,0.020853244
http://arxiv.org/pdf/2201.11630v1,Automatic Classification of Neuromuscular Diseases in Children Using Photoacoustic Imaging,"It can therefore be postulated that the disease progression also has
clear impact both on the measured US and PA signal. US and PA could potentially
be used to monitor treatment process and medication response to support personalized
treatment planning and assessment if further research conÔ¨Årms predictability of severity
for each disease. Despite the slightly lower performance of PA compared to US, PA‚Äôs
inherent properties will make it an interesting choice for future applications. ",eess.IV,B,-0.16207916,0.38265657,-0.31354177
http://arxiv.org/pdf/2201.11793v1,Denoising Diffusion Restoration Models,"To identify an ideal combination, we perform a hyperparameter search over Œ∑, Œ∑b ‚àà
{0.7, 0.8, 0.9, 1.0} for the task of deblurring with œÉy = 0.05 in 1000 ImageNet validation images, using the model trained
in (Dhariwal & Nichol, 2021). It is possible to also consider different Œ∑ values for si = 0 and œÉi < œÉy/si; we leave that as
future work. We report PSNR and KID results in Table 5. ",eess.IV,A,0.19026667,-0.0015899204,0.14966083
http://arxiv.org/pdf/2201.11793v2,Denoising Diffusion Restoration Models,"To identify an ideal combination, we perform a hyperparameter search over Œ∑, Œ∑b ‚àà
{0.7, 0.8, 0.9, 1.0} for the task of deblurring with œÉy = 0.05 in 1000 ImageNet validation images, using the model trained
in (Dhariwal & Nichol, 2021). It is possible to also consider different Œ∑ values for si = 0 and œÉi < œÉy/si; we leave that as
future work. We report PSNR and KID results in Table 5. ",eess.IV,A,0.19026667,-0.0015899204,0.14966083
http://arxiv.org/pdf/2201.11793v3,Denoising Diffusion Restoration Models,"To identify an ideal combination, we perform
a hyperparameter search over Œ∑, Œ∑b ‚àà {0.7, 0.8, 0.9, 1.0} for the task of deblurring with œÉy = 0.05
in 1000 ImageNet validation images, using the model trained in [13]. It is possible to also consider
different Œ∑ values for si = 0 and œÉi < œÉy/si; we leave that as future work. We report PSNR and KID results in Table 3. ",eess.IV,A,0.18046351,-0.005906229,0.17139348
http://arxiv.org/pdf/2201.11866v1,Calibrating Histopathology Image Classifiers using Label Smoothing,"As such, we do not consider
our encouraging empirical results as validation of our label smoothing methods for
all histopathology tasks. Instead, our paper has questioned the traditional practice of
assigning hard labels for histopathology image classiÔ¨Åcation and proposed a simple yet
effective alternative that invites further research in this direction. In this paper, we have proposed two well-motivated sets of label smoothing meth-
ods for improving the calibration and accuracy of histopathology image classiÔ¨Åers:
agreement-aware label smoothing, which uses annotator agreement data, and conÔ¨Ådence-
aware label smoothing, which uses model conÔ¨Ådence. ",eess.IV,C,-0.24691659,0.047077544,-0.004327286
http://arxiv.org/pdf/2201.12260v1,A Review on Deep-Learning Algorithms for Fetal Ultrasound-Image Analysis,"Only the work in [153]    to 0.83, 0.82, 0.70 and 0.69, respectively. proposes something similar, but further research is needed. 4) Pose estimation: In [164], fetal pose is estimated by
   A uniÔ¨Åed framework to biometry estimation from multiple        localizing 16 landmarks, including joints. ",eess.IV,B,-0.05384921,0.0107483305,-0.16697894
http://arxiv.org/pdf/2201.12348v1,End-to-End Optimization of Metasurfaces for Imaging with Compressed Sensing,"We leave more refined lower bound analyses for
hyperparameters ùõº and ùõΩ. In particular, ùõº varies significantly on a      future work. logarithmic scale (Fig. ",eess.IV,B,0.24191014,0.36825407,-0.020398624
http://arxiv.org/pdf/2201.12348v2,End-to-End Optimization of Metasurfaces for Imaging with Compressed Sensing,"But this could come at the expense of optimality on unphysical objects due to
reduced multiplexing of the object on the sensor, illustrating a tradeoÔ¨Ä between the two factors. We leave more reÔ¨Åned lower bound analyses for future work. For physical imaging situations, we emphasize the importance of sparsity of the measurement
matrix, which corresponds to lens-like PSFs in the convolutional model. ",eess.IV,A,0.26064807,-0.17721862,-0.09184782
http://arxiv.org/pdf/2201.13081v1,Unsupervised Anomaly Detection in 3D Brain MRI using Deep Learning with Multi-Task Brain Age Prediction,"So far, there is no public benchmark anomaly detection data set available, which would help our work and the
Ô¨Åeld of UAD in general.3, 15 Considering that our anomalies exclusively constitute brain tumors, our approach
and the additional age anomaly score could be even more promising for detecting neurodegenerative and neu-
ropsychiatric diseases, where brain age is more commonly used. Hence, studying our novel approach on a data
set with various pathologies that covers the entire age spectrum represents a promising direction for future work. Overall, our results conÔ¨Årm our hypothesis that additional brain age information helps the task of UAD in brain
MRI. ",eess.IV,C,-0.24265674,0.06711574,-0.20679045
http://arxiv.org/pdf/2201.13392v1,MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection,"MDev1      LR      72.57%   88.21%      84.66%  9.04          In conclusion, our method is promising to be used for the
  MDev2      SVM      72.41%    88.11%     84.88%  8.98          early detection and auxiliary diagnosis of lung cancers. For the
   MDev2     MLP      71.98%    87.71%     86.38%  9.95          future work, we will promote completely automatic end-to-end
   MDev2        /     76.48%    92.33%     94.92%  54.57         systems that integrate our methods with nodule classiÔ¨Åcation
  Baseline                                                       in clinical circumstances. use MDev2 to lower the FDR and ACS while keeping an                                      ACKNOWLEDGMENT
appropriate degree of the sensitivity and average FROC. ",eess.IV,C,-0.23902011,0.17581132,-0.32251447
http://arxiv.org/pdf/2201.13392v2,MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection,"MDev1      LR      72.57%   88.21%      84.66%  9.04          In conclusion, our method is promising to be used for the
  MDev2      SVM      72.41%    88.11%     84.88%  8.98          early detection and auxiliary diagnosis of lung cancers. For the
   MDev2     MLP      71.98%    87.71%     86.38%  9.95          future work, we will promote completely automatic end-to-end
   MDev2        /     76.48%    92.33%     94.92%  54.57         systems that integrate our methods with nodule classiÔ¨Åcation
  Baseline                                                       in clinical circumstances. use MDev2 to lower the FDR and ACS while keeping an                                      ACKNOWLEDGMENT
appropriate degree of the sensitivity and average FROC. ",eess.IV,C,-0.23902011,0.17581132,-0.32251447
http://arxiv.org/pdf/2201.13392v3,MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection,"MDev1      LR      72.57%   88.21%      84.66%  9.04          In conclusion, our method is promising to be used for the
  MDev2      SVM      72.41%    88.11%     84.88%  8.98          early detection and auxiliary diagnosis of lung cancers. For the
   MDev2     MLP      71.98%    87.71%     86.38%  9.95          future work, we will promote completely automatic end-to-end
   MDev2        /     76.48%    92.33%     94.92%  54.57         systems that integrate our methods with nodule classiÔ¨Åcation
  Baseline                                                       in clinical circumstances. use MDev2 to lower the FDR and ACS while keeping an                                      ACKNOWLEDGMENT
appropriate degree of the sensitivity and average FROC. ",eess.IV,C,-0.23902011,0.17581132,-0.32251447
http://arxiv.org/pdf/2201.13392v4,MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection,"MDev1      LR      72.57%   88.21%      84.66%  9.04          In conclusion, our method is promising to be used for the
  MDev2      SVM      72.41%    88.11%     84.88%  8.98          early detection and auxiliary diagnosis of lung cancers. For the
   MDev2     MLP      71.98%    87.71%     86.38%  9.95          future work, we will promote completely automatic end-to-end
   MDev2        /     76.48%    92.33%     94.92%  54.57         systems that integrate our methods with nodule classiÔ¨Åcation
  Baseline                                                       in clinical circumstances. use MDev2 to lower the FDR and ACS while keeping an                                      ACKNOWLEDGMENT
appropriate degree of the sensitivity and average FROC. ",eess.IV,C,-0.23902011,0.17581132,-0.32251447
http://arxiv.org/pdf/2201.13392v5,MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection,"MDev1      LR      72.57%   88.21%      84.66%  9.04          In conclusion, our method is promising to be used for the
  MDev2      SVM      72.41%    88.11%     84.88%  8.98          early detection and auxiliary diagnosis of lung cancers. For the
   MDev2     MLP      71.98%    87.71%     86.38%  9.95          future work, we will promote completely automatic end-to-end
   MDev2        /     76.48%    92.33%     94.92%  54.57         systems that integrate our methods with nodule classiÔ¨Åcation
  Baseline                                                       in clinical circumstances. use MDev2 to lower the FDR and ACS while keeping an                                      ACKNOWLEDGMENT
appropriate degree of the sensitivity and average FROC. ",eess.IV,C,-0.23902011,0.17581132,-0.32251447
http://arxiv.org/pdf/2201.13398v1,Spectral image clustering on dual-energy CT scans using functional regression mixtures,"Rather, a more clinically informative
                                                                  evaluation would determine the performance of the recovered
                                                                  clusters in predicting clinical outcome in a machine learning
                                                                  setting, compared to the same predictive algorithm applied
                                                                  with the manual tumor segmentations. Such an evaluation is
                                                                  missing from the present paper; it will be part of a subsequent
                                                                  paper in future work. Another limitation stems from the lack of
                                                                  an automated identiÔ¨Åcation of those clusters that are associated
                                                                  with the tumor region. ",eess.IV,C,-0.3763957,0.15997896,-0.09185593
http://arxiv.org/pdf/2202.00002v1,BREAK: Bronchi Reconstruction by gEodesic transformation And sKeleton embedding,"Ablation Study                                                better continuity in space and can produce results with fewer
                                                                   fractures than the Ô¨Ånetune branch. On the contrary, adopting
We perform several ablation experiments in the Binary Air-         the result of the geodesic distance branch to repair the result
way Segmentation Dataset to further study the effect of each       of the Ô¨Ånetune branch (G2F) is more appropriate. component in our segmentation framework. ",eess.IV,C,-0.023163263,0.035969533,-0.06743249
http://arxiv.org/pdf/2202.00011v1,Leveraging Bitstream Metadata for Fast and Accurate Video Compression Correction,"This
frames, so its usefulness as a perceptual similarity metric is
limited. Instead, we argue that future works should simply

                                                                 14
process is repeated for all subsequent groups of 6 P-frames,
eliminating the need for a periodic high-information frame. This comes at a small cost to restoration performance how-
ever it also greatly reduces the bitrate of the H.264 videos. ",eess.IV,A,0.31009004,0.11407396,0.27761066
http://arxiv.org/pdf/2202.00087v1,Holistic Fine-grained GGS Characterization: From Detection to Unbalanced Classification,"Since the data we
5, all of our classiÔ¨Åers had decent AUC scores in identifying    used has been labeled by a single renal pathologist, the study
non-glomerulus patches and ResNet101-BiT-M performed the         is limited by not capturing the inter-rater variability, which
best. Therefore, we used a trained ResNet101-BiT-M classiÔ¨Åer     would be valuable for future works. In the future, a following
to Ô¨Ålter detection results from CircleNet. ",eess.IV,C,-0.17583784,0.16041513,-0.042713024
http://arxiv.org/pdf/2202.00179v1,Blind Image Deconvolution Using Variational Deep Image Prior,"3, our                   graded image cannot provide enough information. In our
method can generate images of the highest quality based                    future work, we plan to adopt meta-learning [73] to train
on BRISQUE and PIQE among all compared methods. the networks on external datasets and Ô¨Åne-tune on each test
                                                                           image, which can take advantage of the information from
5.3 Optimization Time                                                      other images and obtain a image-speciÔ¨Åc model with only
                                                                           several iterations. ",eess.IV,A,-0.024718836,-0.11638657,0.19459099
http://arxiv.org/pdf/2202.00198v1,Recognition-Aware Learned Image Compression,"We demonstrate              [10] Oren Rippel and Lubomir Bourdev, ‚ÄúReal-time adaptive image com-
greater recognition accuracy results to those achieved by tradi-              pression,‚Äù arXiv e-prints 1705.05823, 2017.
tional methods like BPG, at equivalent bitrates. In future work
we aim to extend our results to higher bitrates while remaining         [11] Mohammad Akbari, Jie Liang, Jingning Han, and Chengjie Tu,
competitive with BPG in terms of accuracy. ‚ÄúGeneralized octave convolutions for learned multi-frequency im-
                                                                              age compression,‚Äù arXiv e-prints 2002.10032, 2020. ",eess.IV,A,0.16103993,-0.14102498,0.14322828
http://arxiv.org/pdf/2202.00416v1,CAESR: Conditional Autoencoder and Super-Resolution for Learned Spatial Scalability,"For visualisation, we adjust the QP of the
EDSR input to match the bitrate with our system. As future work, we plan to include the temporal aspect into
                                                                                                                               our model to ensure inter-coded frame processing. As depicted in Fig. ",eess.IV,A,0.35319334,0.10280244,0.043797683
http://arxiv.org/pdf/2202.00465v1,A generalizable approach based on U-Net model for automatic Intra retinal cyst segmentation in SD-OCT images,"It is expected that injecting more powerful channels included with the domain expertise such as weighted ROI

mask or a map with more effective information about the correlation between lesions and retinal layer structures to

the network, can provide a more helpful introduction of the cystoid features to the network. It will be investigated in

future work. References

Bogunovic, H., Venhuizen, F., Klimscha, S., Apostolopoulos, S., Bab-Hadiashar, A., Bagci, U., Beg, M. F., Bekalo,
       L., Chen, Q., Ciller, C., Gopinath, K., Gostar, A. K., Jeon, K., Ji, Z., Kang, S. H., Koozekanani, D. D., Lu, D.,
       Morley, D., Parhi, K. K., ‚Ä¶ Schmidt-Erfurth, U. ",eess.IV,C,-0.06253405,-0.014804085,-0.13074775
http://arxiv.org/pdf/2202.00678v1,Classification of Skin Cancer Images using Convolutional Neural Networks,"Hence with our model, we are not
     trying to replace a Dermatologist but merely aid with the predictions. 4.1 Future Scope

     This study can be understood and referred to as the basis for further analysis in the future. The elementary
     results explored here may just be the beginning of an exploratory analysis of the power of Machine Learning in
     the field of Cancer study. ",eess.IV,C,-0.37635595,0.27036917,-0.033096902
http://arxiv.org/pdf/2202.00719v1,Point Cloud Compression for Efficient Data Broadcasting: A Performance Comparison,"We showed that 2D algorithms, even though                                Eurographics Symposium on Point-Based Graphics, 2006.
requiring the raw point cloud to be Ô¨Årst transformed into its
two-dimensional representation, can achieve a high compres-                      [12] L. Huang, S. Wang, K. Wong, J. Liu, and R. Urtasun, ‚ÄúOctSqueeze:
sion rate and up to 20√ó faster compression than G-PCC, while                           Octree-Structured Entropy Model for LiDAR Compression,‚Äù in Confer-
guaranteeing a PNSR greater than 100 dB, thus supporting                               ence on Computer Vision and Pattern Recognition, 2020.
lossless compression. In our future work we will investigate whether more ad-                       [13] M. J. Weinberger, G. Seroussi, and G. Sapiro, ‚ÄúThe LOCO-I lossless
vanced solutions, e.g., other settings of G-PCC [21] or meth-                          image compression algorithm: principles and standardization into JPEG-
ods based on artiÔ¨Åcial intelligence, may improve compression                           LS,‚Äù IEEE Transactions on Image Processing, vol. 9, no. ",eess.IV,A,0.26602963,-0.12073626,0.13662761
http://arxiv.org/pdf/2202.00749v1,Towards Positive Jacobian: Learn to Postprocess Diffeomorphic Image Registration with Matrix Exponential,"VM      0.60 (0.10)
                             1.87 (0.20)                              The exponentiated Jacobian is not always integrable, but
             VM+Postprocess                                        under certain conditions it can give a valid Jacobian as
                                                                   explored in the Appendix and that will lead to a theoretical
D. Registration Performance                                        guarantee of strictly positive Jacobians. Thus, for future work,
                                                                   we hope to develop constrained registration Ô¨Åelds that can lead
   Table I shows the average dice score and the average per-       to a theoretically guaranteed, fully diffeomorphic registration. centage of voxels with non positive Jacobians for all subjects
in the test set for our experiments for different values of Œª and                  APPENDIX
Œªp. ",eess.IV,B,0.059466004,0.12848876,-0.12294649
http://arxiv.org/pdf/2202.00972v2,DCSAU-Net: A Deeper and More Compact Split-Attention U-Net for Medical Image Segmentation,"Based on the eÔ¨Éciency of depth-
In addition, we explore the impact of depthwise convolution      wise separable convolution, adding more such layers may
with diÔ¨Äerent number of kernel sizes on the performance,         improve the information capture capability of the PFC mod-
which is presented in Table 7. From the experiment results,      ule in the low-level semantic layer, which is worth exploring
we can observe that the DCSAU-Net model is able to achieve       in future work. We next establish the CSA block that not
a similar performance when using 3x3, 5x5 and 7x7 kernel         only enhances the connectivity across diÔ¨Äerent channels but
sizes. ",eess.IV,A,0.22478317,-0.0051260535,0.38791418
http://arxiv.org/pdf/2202.00990v1,Dictionary learning for clustering on hyperspectral images,"Dictionary learning provides a       circumstances. We end the paper in section V with concluding
                                         way to learn this representation of the latent structure of        remarks and describe some of the future work that could add
                                         the data. After a dictionary has been acquired, sparse coding      to the results shown here. ",eess.IV,A,0.05377557,0.1492343,0.30125698
http://arxiv.org/pdf/2202.01116v1,Unpaired Image Super-Resolution with Optimal Transport Maps,"Studying
for one version it is close to FSSR. It also outperforms FSSR  such applications is a promising avenue for the future work. in PSNR, SSIM and, importantly, LPIPS. ",eess.IV,B,0.21434546,0.3215153,-0.09368425
http://arxiv.org/pdf/2202.01116v2,An Optimal Transport Perspective on Unpaired Image Super-Resolution,"Besides, our method is generic and presumably can be applied to other
unpaired learning tasks as well. Studying such applications is a promising avenue for the future work. 9
Limitations. ",eess.IV,B,0.018819103,0.24817476,0.26004434
http://arxiv.org/pdf/2202.01208v1,Deep Learning for Ultrasound Speed-of-Sound Reconstruction: Impacts of Training Data Diversity on Stability and Robustness,"Currently, the exact GT for our measured data is not available. Moreover, although the new proposed setup improved the performance of the deep neural
network under investigation, further research is still required to design more generalized
simulation setups. For example, the presented setup is a 2D model, and therefore oÔ¨Ä-
axis reÔ¨Çections from z-direction are not modeled due to high computational eÔ¨Äort and
memory requirements. ",eess.IV,A,0.085800834,-0.08997769,0.19179147
http://arxiv.org/pdf/2202.01494v1,PARCEL: Physics-based unsupervised contrastive representation learning for parallel MR imaging,"In addition, from the experiments in section IV-B, we can                   information by two-dimensional random mask. In future work,
conclude that the results of two-dimensional random mask are                      we will try new optimization methods to solve the optimization
better than those of one-dimensional random mask, which may                       problems in equation (3) and explore more sample patterns. Table II

Quantitative comparison of reconstructed magnetic resonance imaging using PARCEL of different losses and two baseline model with two acceleration rate
                                                                                      (mean¬±std)

Acceleration rate  model                                                          PSNR/dB          SSIM

R=4                Single-Net                                                     45.58959¬±5.2523  0.9847¬±0.0096

                   Parallel-Net                                                   45.0090¬±2.4028   0.9819¬±0.0059

                   CL                                                             45.9615¬±3.0238   0.9852¬±0.0055

                   DC                                                             46.5590¬±4.2367   0.9891¬±0.0072

                   CL+DC                                                          46.5860¬±4.2046   0.9893¬±0.0070

R=8                Single-Net                                                     37.8671¬±3.5245   0.9329¬±0.0353

                   Parallel-Net                                                   39.5817¬±3.5850   0.9476¬±0.0291

                   CL                                                             39.6407¬±3.6367   0.9487¬±0.0296

                   DC                                                             39.6071¬±3.6558   0.9499¬±0.0301

                   CL+DC                                                          39.6025¬±3.6589   0.9501¬±0.0303

                            V. CONCLUSION                                         [6] K. P. Pruessmann, M. Weiger, P. Boesiger, ‚Äúadvances in sensitivity
                                                                                         encoding with arbitrary k-space trajectories,‚Äù Magnetic Resonance in
   In this paper, we propose a novel physics-based unsupervised                          Medicine., vol. ",eess.IV,B,0.24843283,-0.086569026,-0.30907518
http://arxiv.org/pdf/2202.01494v2,PARCEL: Physics-based unsupervised contrastive representation learning for parallel MR imaging,"better than one-dimensional random masks. In future work, we
                                                                                  will try new optimization methods to solve the optimization
   The experimental results show that, on both the PSNR and                       problems in (3) and explore a greater number of sample patterns. SSIM indicators, the MRI reconstruction model constructed by
unsupervised contrastive representation learning outperforms                                                  V. CONCLUSION
the classical compressed sensing algorithm and a newly
proposed self-supervised method [19] with improved model                             In this paper, we propose a physics-based unsupervised
stability while gradually approaching the performance of the                      contrastive representation learning method to speed up parallel
supervised method. ",eess.IV,A,0.08519103,-0.19337472,-0.06974346
http://arxiv.org/pdf/2202.01494v3,PARCEL: Physics-based Unsupervised Contrastive Representation Learning for Multi-coil MR Imaging,"Other optimization methods, such
as ISTA [44], can be employed to solve the optimization problem in (2). In the
future work, we can investigate new optimization methods to solve the problems
in (2). In addition, there are many eÔ¨Äective solutions for dealing with complex-
valued data [19], [20], [22]. ",eess.IV,B,0.24590927,0.072720855,-0.11908558
http://arxiv.org/pdf/2202.01564v1,Weakly Supervised Nuclei Segmentation via Instance Learning,"This shows the efÔ¨Åcacy of our            consistently outperforms previous state-of-the-art methods
design in decoupling and fusing semantic and instance seg-        with considerable margins. For future work exploration, our
mentation process, as well as the effectiveness of our learned    method can potentially extend to scenarios of inaccurate or
instance-aware representation. As shown in Fig. ",eess.IV,B,-0.07626559,0.29377064,0.286895
http://arxiv.org/pdf/2202.01564v2,Weakly Supervised Nuclei Segmentation via Instance Learning,"This shows the efÔ¨Åcacy of our            consistently outperforms previous state-of-the-art methods
design in decoupling and fusing semantic and instance seg-        with considerable margins. For future work exploration, our
mentation process, as well as the effectiveness of our learned    method can potentially extend to scenarios of inaccurate or
instance-aware representation. As shown in Fig. ",eess.IV,B,-0.07626559,0.29377064,0.286895
http://arxiv.org/pdf/2202.01863v1,Best Practices and Scoring System on Reviewing A.I. based Medical Imaging Papers: Part 1 Classification,"How does this current work fit in with field at present? [C-3] Recommendations for future work, if applicable. What would the authors propose for future studies building on the current work

[C-4] The conclusion is adequately supported by the results of the study. ",eess.IV,B,0.045011587,0.4472887,-0.17748562
http://arxiv.org/pdf/2202.01866v1,Enhancing Organ at Risk Segmentation with Improved Deep Neural Networks,"Our enhanced
segmentation model includes architectural changes in the loss function, optimization technique, and convolution
type that substantially improved accuracy while still delivering eÔ¨Äective training on data sets containing organs
of diÔ¨Äerent sizes. As future work, we are currently evaluating our models on an additional radiotherapy treatment planning
data set from a local partner hospital as part of a joint project to develop novel therapy tools. This additional
data set will allow us to further evaluate the generalizability of our model enhancement approach. ",eess.IV,C,-0.26522034,-0.09249292,0.033462122
http://arxiv.org/pdf/2202.02000v1,Cross-Modality Multi-Atlas Segmentation Using Deep Neural Networks,"SimNet are trained with anatomical labels in our framework, which
                                                                            limits the framework to the unlabelled datasets. Hence, one direction
   In the literature, several works have been proposed to use cross-        of future work is extending the framework with unsupervised registra-
modality atlases for segmentation. Iglesias et al. ",eess.IV,C,-0.38819796,-0.08338134,0.22708029
http://arxiv.org/pdf/2202.02000v2,Cross-Modality Multi-Atlas Segmentation via Deep Registration and Label Fusion,"SimNet are trained with anatomical labels in our framework, which
                                                                            limits the framework to the unlabelled datasets. Hence, one direction
   In the literature, several works have been proposed to use cross-        of future work is extending the framework with unsupervised registra-
modality atlases for segmentation. Iglesias et al. ",eess.IV,C,-0.38819796,-0.08338134,0.22708029
http://arxiv.org/pdf/2202.02000v3,Cross-Modality Multi-Atlas Segmentation via Deep Registration and Label Fusion,"SimNet are trained with anatomical labels in our framework, which
                                                                            limits the framework to the unlabelled datasets. Hence, one direction
   In the literature, several works have been proposed to use cross-        of future work is extending the framework with unsupervised registra-
modality atlases for segmentation. Iglesias et al. ",eess.IV,C,-0.38819796,-0.08338134,0.22708029
http://arxiv.org/pdf/2202.02277v1,Quality Assessment of Low Light Restored Images: A Subjective Study and an Unsupervised Model,"1, 10
perception of quality and the inter-play of these factors is          [6] Chen Chen, Qifeng Chen, Jia Xu, and Vladlen Koltun. an interesting area for future work, considering that crowd-               Learning to see in the dark. CoRR, abs/1805.01934, 2018.
sourced studies are becoming very popular in recent times. ",eess.IV,B,0.18361086,0.29026634,0.11702974
http://arxiv.org/pdf/2202.02382v2,Fully Automated Tree Topology Estimation and Artery-Vein Classification,"This is en-   diabetic retinopathy, and macular degeneration. We
couraging because it shows that our topology model        also intend to explore this form of automated diag-
accurately captures how vessels are distributed in the    nosis in future work. retina. ",eess.IV,C,-0.12672962,0.0010427693,-0.12082225
http://arxiv.org/pdf/2202.02606v1,ROMNet: Renovate the Old Memories,"Pattern Recognit. (CVPR),
available real-world old photo dataset that includes 200 pairs                        June 2019.
of authentic legacy photographs with corresponding ‚Äúground
truth‚Äù repaired by Photoshop experts, which we believe will                     [17] Z. Wan, B. Zhang, D. Chen, P. Zhang, D. Chen, J. Liao, and F. Wen,
facilitate further research on deep learning-based old photo                          ‚ÄúBringing old photos back to life,‚Äù in Proc. IEEE Conf. ",eess.IV,A,0.055056702,-0.19443685,0.2442379
http://arxiv.org/pdf/2202.02764v1,On Smart Gaze based Annotation of Histopathology Images for Training of Deep Convolutional Neural Networks,"However, this     gaze points invisible at the time of labeling was intentional since
can be overcome by developing adaptive thresholding approaches and      it became a source of distraction. The downside of these invisible
we plan to tackle it as part of our future work. Even in its current    data points was that it was somewhat challenging to get reassurance
state, the burden of the manual data clean up and post-processing lies  on whether or not labeling had been stored correctly. ",eess.IV,C,-0.07421127,0.15585943,0.08937989
http://arxiv.org/pdf/2202.02832v1,Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification,"5 Limitations and future work

ITA is an imperfect method for estimating skin tone, given its sensitivity to
lighting conditions. Augmentation of existing data or creation of new samples
using generative models to simulate more consistent lighting conditions may be
an option for future work. Further work may also collect dermatologist annot-
ated skin tone labels for dermoscopic datasets and evaluate the eÔ¨Äectiveness of
debiasing techniques using these human labels. ",eess.IV,C,-0.053646497,0.13304444,-0.08050833
http://arxiv.org/pdf/2202.02832v2,Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification,"5 Limitations and future work

ITA is an imperfect method for estimating skin tone, given its sensitivity to
lighting conditions. Augmentation of existing data or creation of new samples
using generative models to simulate more consistent lighting conditions may be
an option for future work. Further work may also collect dermatologist annot-
ated skin tone labels for dermoscopic datasets and evaluate the eÔ¨Äectiveness of
debiasing techniques using these human labels. ",eess.IV,C,-0.053646497,0.13304444,-0.08050833
http://arxiv.org/pdf/2202.02832v3,Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification,"5 Limitations and future work

ITA is an imperfect method for estimating skin tone, given its sensitivity to
lighting conditions. Augmentation of existing data or creation of new samples
using generative models to simulate more consistent lighting conditions may be
an option for future work. Further work may also collect dermatologist annot-
ated skin tone labels for dermoscopic datasets and evaluate the eÔ¨Äectiveness of
debiasing techniques using these human labels. ",eess.IV,C,-0.053646497,0.13304444,-0.08050833
http://arxiv.org/pdf/2202.02832v4,Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification,"Asterisk
(*) indicates ablation of gradient reversal). 5 Limitations and future work

As mentioned in section 4.2, the skin tone detection algorithm has a problem with
over-classifying type 6 skin which is a key limitation and should be addressed. Detecting Melanoma Fairly  9

ITA is an imperfect method for estimating skin tone, given its sensitivity to light-
ing conditions, and the Fitzpatrick conversion thresholds are tight and may not
generalise well. ",eess.IV,C,-0.14691135,0.123783976,-0.22040528
http://arxiv.org/pdf/2202.02833v1,CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI,"[7] Walter F Wiggins, Kirti Magudia, Teri M Sippel Schmidt, Stacy D O‚ÄôConnor, Christopher D Carr, Marc D Kohli,
      and Katherine P Andriole. Imaging ai in practice: A demonstration of future workÔ¨Çow using integration standards. Radiology: ArtiÔ¨Åcial Intelligence, 3(6):e210152, 2021. ",eess.IV,C,-0.20289001,-0.06833487,-0.15661728
http://arxiv.org/pdf/2202.02833v2,CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI,"[7] Walter F Wiggins, Kirti Magudia, Teri M Sippel Schmidt, Stacy D O‚ÄôConnor, Christopher D Carr, Marc D Kohli,
      and Katherine P Andriole. Imaging ai in practice: A demonstration of future workÔ¨Çow using integration standards. Radiology: ArtiÔ¨Åcial Intelligence, 3(6):e210152, 2021. ",eess.IV,C,-0.20289001,-0.06833487,-0.15661728
http://arxiv.org/pdf/2202.02952v1,SUD: Supervision by Denoising for Medical Image Segmentation,"could be used to expand the diversity of segmentations (for
                                                                 example, by changing a tumor‚Äôs shape and position within a
5.1 Extending SUD                                                structure). However, we defer discussions for task-speciÔ¨Åc
                                                                 denoiser training strategies to future work, focusing here on
One avenue for extending SUD is to substitute the temporal       the general semi-supervised segmentation framework. Our
averaging component of SUD with the mean teacher model           assumption of ‚ÄúsuÔ¨Éciently many and varied segmentation
[36], which averages network weights as opposed to pseudo        examples‚Äù is far from being unique to our work, and serves
targets (see Appendix A). ",eess.IV,C,-0.27169773,-0.057393357,0.13371848
http://arxiv.org/pdf/2202.03031v2,A comprehensive benchmark analysis for sand dust image reconstruction,"In Figures 1 and 5, the results of CIDC           may cause local information distorted in the reconstruction
[11] and TTFIO [1] still exist the issue of color distortion, that is           images. How to better preserve the detail information in sand
the reason why both of them have higher CIE94 and CIEDE2000                     dust removal task needs further research and discussion. metrics. ",eess.IV,A,0.220061,-0.009971181,-0.053595386
http://arxiv.org/pdf/2202.03342v1,"A Review of Landcover Classification with Very-High Resolution Remotely Sensed Optical Images-Analysis Unit,Model Scalability and Transferability","This
is fueled by the need to, (1) address the challenge of data sparsity, inaccuracy and incompleteness; (2) harness the ever-
growing number of sensors with different modality to achieve solutions free of moderation by experts. To this end, based on this review, we provide a few recommendations for the future works in this research line: (1)
Developing domain adaptation approaches taking advantage of the unique characteristics of RS data, such as their
diversity in land patterns of different geographical regions, the availability of low-resolution labels for semi-supervised
DA, available height information globally, as well as physics-based spectrum signatures in the RS world. (2) Exploring
the underlying mechanisms of spectrum diversity across different sensors, to achieve inter-sensor calibration prior to
classification. ",eess.IV,A,0.005573228,0.05738885,0.048766464
http://arxiv.org/pdf/2202.03373v2,LEDNet: Joint Low-light Enhancement and Deblurring in the Dark,"Sec. B presents further analysis and discussions
on our proposed LEDNet network, consisting of more analysis and results on
CurveNLU, and loss function. In Sec. ",eess.IV,A,0.23963107,0.15737154,0.17036107
http://arxiv.org/pdf/2202.03430v1,A Topology-Attention ConvLSTM Network and Its Application to EM Images,"We expect the performance to further improve on isotropic datasets,
because slices are closer (due to higher sampling rate in the z-dimension) with
more consistent topologies across slices. For the future work, we will apply
TACNet to datasets of other medical structures, such as cardiac and vascular
images, to prove its eÔ¨Écacy in a broader medical domain. References

 1. ",eess.IV,C,-0.11499052,-0.11174929,0.055583984
http://arxiv.org/pdf/2202.03434v1,Multi-modal data generation with a deep metric variational autoencoder,"VAEs [18, 19]. However, incorporating this into our
                                                           approach remains future work. The WBT is a simpler
   The generation of WBT measurements is summa-            type of data to generate, as it does not contain the
rized in Figure 5, where generated examples are shown      same level of detail as an image. ",eess.IV,B,0.19182776,0.13562998,-0.109366134
http://arxiv.org/pdf/2202.03563v1,Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning with Pairwise Alignment,"atlas building model is more robust than a backward model
because a forward model evaluates the atlas-to-image sim-                           5. Conclusion, limitations, and future work
ilarity difference in a Ô¨Åxed image space while a backward
model evaluates in the evolving atlas space. Rows E and F                              We introduced a joint atlas building and diffeomorphic
in Tab. ",eess.IV,A,0.12375376,-0.105339795,0.11397053
http://arxiv.org/pdf/2202.03563v2,Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning with Pairwise Alignment,"3, we hypothesized that a forward                           5. Conclusion, limitations, and future work
atlas building model is more robust than a backward model
because a forward model evaluates the atlas-to-image sim-                              We introduced a joint atlas building and diffeomorphic
ilarity difference in a fixed image space while a backward                          registration learning framework (Aladdin) that uses pair-
model evaluates in the evolving atlas space. Rows E and F                           wise image alignment losses to improve registration accu-
in Tab. ",eess.IV,A,-0.045939825,-0.10992296,0.16540284
http://arxiv.org/pdf/2202.03564v1,Accurate super-resolution low-field brain MRI,"This work demonstrates proof-of-principle post-
processing image enhancement from lower resolution LF-MRI sequences. These results lay the
foundation for future work to enhance the detection of normal and abnormal image findings at
LF and ultimately improve the diagnostic performance of LF-MRI. Our tools are publicly
available on FreeSurfer (surfer.nmr.mgh.harvard.edu/). ",eess.IV,C,-0.06866219,-0.25563738,-0.25624898
http://arxiv.org/pdf/2202.03737v1,A Survey of Breast Cancer Screening Techniques: Thermography and Electrical Impedance Tomography,"Is it enough the FP and FN
rate or the current models still lack performance? Those questions may bring new
insights in the future work that researchers would take. It is important to recall that
we presented the importance of machine learning techniques in the CAD systems. ",eess.IV,B,0.045143623,0.186454,0.22383136
http://arxiv.org/pdf/2202.03826v1,On the Pitfalls of Using the Residual Error as Anomaly Score,"Also, advanced post-processing of the residual maps as in MunÀúoz-
Ram¬¥ƒ±rez et al. (2021) can potentially alleviate this problem and presents an interesting
direction for further research. Lately, self-supervised methods that use artiÔ¨Åcial anomalies
for training became popular (Tan et al., 2020, 2021) and need further investigation. ",eess.IV,C,-0.21376023,0.0844533,0.10765592
http://arxiv.org/pdf/2202.04517v1,End-to-End Blind Quality Assessment for Laparoscopic Videos using Neural Networks,"In
observations made based on the correlation coefÔ¨Åcient values. future work, it would be interesting to enrich the database
                                                                                                                                                                                    with other videos of different organs and surgical scenarios. Comparison with different temporal pooling ap-                                                                                                                                   It would be also interesting to investigate new perceptual loss
proaches: In order to show the importance of the additional                                                                                                                         functions for training the overall architecture. ",eess.IV,C,-0.095997594,0.07587259,0.08802885
http://arxiv.org/pdf/2202.04517v2,A Neural Network based Framework for Effective Laparoscopic Video Quality Assessment,"In
                                                                                 [21] Z. Tu, C.-J. Chen, L.-H. Chen, N. Birkbeck, B. Adsumilli, and A. C.
future work, it would be interesting to enrich the database                            Bovik, ‚ÄúA comparative evaluation of temporal pooling methods for blind
                                                                                       video quality assessment,‚Äù in IEEE International Conference on Image
with other videos of different organs and surgical scenarios. Processing (ICIP), 2020, pp. ",eess.IV,A,0.08642503,-0.067872964,-0.0139650665
http://arxiv.org/pdf/2202.04595v1,Exploring Structural Sparsity in Neural Image Compression,"Even          acceleration and 1.5-7.1√ó parameter saving can be achieved
with the highest quality model, the FLOP can be reduced             with less than 1% performance drop. Potential future work
by nearly 2 times. Compared to ECG modules in [14], our             includes better joint optimization, complexity-rate control. ",eess.IV,B,0.4499773,0.31473288,-0.06209646
http://arxiv.org/pdf/2202.04595v2,Exploring Structural Sparsity in Neural Image Compression,"Even          acceleration and 1.5-7.1√ó parameter saving can be achieved
with the highest quality model, the FLOP can be reduced             with less than 1% performance drop. Potential future work
by nearly 2 times. Compared to ECG modules in [14], our             includes better joint optimization, complexity-rate control. ",eess.IV,B,0.4499773,0.31473288,-0.06209646
http://arxiv.org/pdf/2202.04595v3,Exploring Structural Sparsity in Neural Image Compression,"Even          acceleration and 1.5-7.1√ó parameter saving can be achieved
with the highest quality model, the FLOP can be reduced             with less than 1% performance drop. Potential future work
by nearly 2 times. Compared to ECG modules in [14], our             includes better joint optimization, complexity-rate control. ",eess.IV,B,0.4499773,0.31473288,-0.06209646
http://arxiv.org/pdf/2202.04595v4,Exploring Structural Sparsity in Neural Image Compression,"Even          acceleration and 1.5-7.1√ó parameter saving can be achieved
with the highest quality model, the FLOP can be reduced             with less than 1% performance drop. Potential future work
by nearly 2 times. Compared to ECG modules in [14], our             includes better joint optimization, complexity-rate control. ",eess.IV,B,0.4499773,0.31473288,-0.06209646
http://arxiv.org/pdf/2202.04644v1,On-the-fly 3D metrology of volumetric additive manufacturing,"Typical volume computation time is ~8-9s,
corresponding to approximately half of a vial rotation. In future work, these volumes may be used to update
projections on-the-fly, and the volume reconstruction time could be significantly reduced using a graphics
processing unit (GPU) and/or deep neural network techniques[34]. Fig. ",eess.IV,A,0.112573996,-0.1181355,-0.057301257
http://arxiv.org/pdf/2202.04645v1,FCM-DNN: diagnosing coronary artery disease by deep accuracy Fuzzy C-Means clustering model,"As a significant achievement,
no studies have been carried out for CAD diagnosis on the CMRI dataset so far. As future work, we
                                                                                                                                                 23

will study convolutional neural network and auto-encoder neural network algorithms on the CMRI
dataset to diagnose CAD. References

1. ",eess.IV,C,-0.23386458,-0.07173506,0.081709355
http://arxiv.org/pdf/2202.04645v2,FCM-DNN: diagnosing coronary artery disease by deep accuracy Fuzzy C-Means clustering model,"As a significant achievement, no studies
have been carried out for CAD diagnosis on the CMRI dataset so far. As future work, we will study

Mathematical Biosciences and Engineering                Volume 19, Issue 4, 3609‚Äì3635. 3631

convolutional neural network and auto-encoder neural network algorithms on the CMRI dataset to
diagnose CAD. ",eess.IV,C,-0.20832296,-0.09194237,0.06123727
http://arxiv.org/pdf/2202.04650v1,Semantic Segmentation of Anaemic RBCs Using Multilevel Deep Convolutional Encoder-Decoder Network,"work. Experimental work, results and discussion, conclusion
Concerning the characteristics and different processing           and future work are described in sections IV-VII. granularity, deep learning-based semantic segmentation is
                                                                                                                                                                  161327
VOLUME 9, 2021
                                                                                 M. Shahzad et al. ",eess.IV,C,-0.22355795,-0.022817733,0.32983232
http://arxiv.org/pdf/2202.04785v1,Multiclass histogram-based thresholding using kernel density estimation and scale-space representations,"Finally,
the regularization of the EM deconvolution makes the algorithm robust to the
high-frequency noise in the histogram shape. The future work includes the extension of the algorithm for a multivariate
histogram. This work requires the formulation of a new set of criteria that deÔ¨Åne
the thresholding surfaces. ",eess.IV,A,0.15737587,-0.16405961,-0.09524552
http://arxiv.org/pdf/2202.04961v1,Monotonically Convergent Regularization by Denoising,"Our numerical
results highlight the stability of MRED relative to the traditional RED-SD algorithm, which diverges
for our expansive denoiser. While our focus was on RED, the future work will look into the potential
of our strategy to be applicable to other related frameworks such as PnP and DEQ. Acknowledgement

This work was supported by the NSF award CCF-2043134. ",eess.IV,A,0.32857555,-0.20791134,-0.22836922
http://arxiv.org/pdf/2202.05336v1,Dynamic Background Subtraction by Generative Neural Networks,"[15] are not considered. In addition, CANDID algorithm
[35], that was speciÔ¨Åcally proposed for dynamic background               For the future work, we want to merge our previous frame-
subtraction, is also considered. work, NUMOD [30], that can cope with illumination changes
                                                                      and shadows, with DBSGen. ",eess.IV,A,0.27322555,-0.10323319,0.049080133
http://arxiv.org/pdf/2202.05382v1,"Give me a knee radiograph, I will tell you where the knee joint area is: a deep convolutional neural network adventure","In conclusion, this study demonstrates a successful application of YOLO v3 deep neural
network to reliably and precisely tackle the problem of knee joint area localization and clas-
siÔ¨Åcation in plain radiographs. As part of our future work, we are combining the knee joint
areas that are computationally identiÔ¨Åed from the plain knee radiographs to build further
deep learning predictive models with knee pathology, advancing knee imaging informatics
research. References

The osteoarthritis initiative. ",eess.IV,C,-0.29021794,-0.13188563,0.05379556
http://arxiv.org/pdf/2202.05492v1,Entroformer: A Transformer-based Entropy Model for Learned Image Compression,"For example, (1) Whether we could build a hierarchical
decoding framework to achieve a better balance between speed and RD performance, even beyond the raster-scan
mode; (2) Whether the Ô¨Åne-grained assignment of k to different images could increase performance; (3) Whether the
rate control module plays a more important role in the transformer-based entropy model than in the convolution-based
model. We would like to explore these issues in future work. References

Johannes Ball√©, Valero Laparra, and Eero P Simoncelli. ",eess.IV,A,0.29934543,-0.03155122,0.19097242
http://arxiv.org/pdf/2202.05492v2,Entroformer: A Transformer-based Entropy Model for Learned Image Compression,"For example, (1) Whether we could build a hierarchical
decoding framework to achieve a better balance between speed and RD performance, even beyond the raster-scan
mode; (2) Whether the Ô¨Åne-grained assignment of k to different images could increase performance; (3) Whether the
rate control module plays a more important role in the transformer-based entropy model than in the convolution-based
model. We would like to explore these issues in future work. References

Johannes Ball√©, Valero Laparra, and Eero P Simoncelli. ",eess.IV,A,0.29934543,-0.03155122,0.19097242
http://arxiv.org/pdf/2202.05623v1,A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation,"(1)
Section 4. The paper concludes with a discussion and outlook on
future work in Section 5. The discriminator d : RN √ó RN ‚Üí R aims to distinguish the distri-
                                                                         bution of the reconstruction with the known data as side information
        2. REVIEW: WASSERSTEIN GAN INPAINTING                            P(u|c, Cf ) from the original distribution P(f |c, Cf ), minimising

Among classical inpainting techniques, those that accurately approx-                         Ef‚àºPt,c‚àºPc (d(f , c) ‚àí Er‚àºPs d(u(r, c, Cf ), c)) . ",eess.IV,A,0.15021992,-0.18370101,0.0519344
http://arxiv.org/pdf/2202.05623v2,A Wasserstein GAN for Joint Learning of Inpainting and Spatial Optimisation,"1.3 Organisation of the Paper

After a brief review of Wasserstein GANs in Section 2 we introduce our deep
spatial optimisation approach in Section 3 and evaluate it in Section 4. The
paper concludes with a discussion and outlook on future work in Section 5. 2 Inpainting with Wasserstein GANs

For our data optimisation, we require deep inpainting that is suitable for sparse
known data. ",eess.IV,A,0.080158204,-0.24471962,0.2593071
http://arxiv.org/pdf/2202.06073v1,Classification of Microscopy Images of Breast Tissue: Region Duplication based Self-Supervision vs. Off-the Shelf Deep Representations,"1. Examples of microscopy images of size 2084 x 1536 from the BACH
Section V concludes the paper with directions for future work. dataset. ",eess.IV,A,0.03918616,-0.14581433,-0.10881303
http://arxiv.org/pdf/2202.06109v1,Breast Cancer Detection using Histopathological Images,"We have successfully detected
malignant tissues in histopathological images using CNN. Our   Fergus, and Y. LeCun, ‚ÄúOverFeat: Integrated
future work involves deploying a website where a user can put
his/her details and get a result based on image input. Recognition, Localization and Detection using

                                                               Convolutional Networks,‚Äù Dec. 2013. ",eess.IV,C,-0.3821909,-0.1774452,0.07862976
http://arxiv.org/pdf/2202.06142v1,Multi-task Deep Learning for Cerebrovascular Disease Classification and MRI-to-PET Translation,"Although the proposed model produces high-quality syn-
                                                                         thetic PET images, the neuroradiologists still need to spend
                                                                         substantial time examining 3D images trying to identify the
                                                                         area(s) of the brain affected by the cerebrovascular disease. In future work, we plan to add a third branch to automati-
                                                                         cally localize the brain regions with abnormally low cerebral
                                                                         blood Ô¨Çow. An expansion of this approach to other types of
                                                                         brain diseases (like certain types of dementia) could also be
                                                                         clinically valuable. ",eess.IV,C,-0.18134055,-0.24513116,-0.17067596
http://arxiv.org/pdf/2202.06465v1,A State-of-the-art Survey of U-Net in Microscopic Image Analysis: from Simple Usage to Structure Mortification,"Finally, only a few
researchers study the improved U-Net composed of multiple U-Nets, which
can better realize the Ô¨Çow of information. In the future, this improved U-Net
composed of multiple U-Nets will be a more potential and valuable research
direction, which is a key direction of our future work. Acknowledgements

This work is supported by the ‚ÄúNational Natural Science Foundation of China‚Äù
(No. ",eess.IV,B,0.17023727,0.16428727,0.22049864
http://arxiv.org/pdf/2202.06465v2,A State-of-the-art Survey of U-Net in Microscopic Image Analysis: from Simple Usage to Structure Mortification,"Finally, only a few
researchers study the improved U-Net composed of multiple U-Nets, which
can better realize the Ô¨Çow of information. In the future, this improved U-Net
composed of multiple U-Nets will be a more potential and valuable research
direction, which is a key direction of our future work. Acknowledgements

This work is supported by the ‚ÄúNational Natural Science Foundation of China‚Äù
(No. ",eess.IV,B,0.17023727,0.16428727,0.22049864
http://arxiv.org/pdf/2202.06590v1,A Pragmatic Machine Learning Approach to Quantify Tumor Infiltrating Lymphocytes in Whole Slide Images,"Limitations

           In our composed dataset, we manually extracted patches to test our models and
hypotheses. In future works, we plan to eliminate that flaw and automatically extract the region
of interest in a WSI. In this work, our aim was to provide an interactive graphical user interface for
pathologists able to test and evaluate different machine learning models for WSI analysis. ",eess.IV,C,-0.25022608,0.23010677,0.076913185
http://arxiv.org/pdf/2202.06599v1,Multi-Atlas Segmentation and Spatial Alignment of the Human Embryo in First Trimester 3D Ultrasound,"Having
the embryonic volume available during training might simplify Ô¨Ånding the embryo. Finally, another interesting topic for further research is applying our framework to other
problems. We created a Ô¨Çexible framework that easily can be adapted to work with or
without landmarks and with or without multiple atlas images. ",eess.IV,C,-0.17868873,-0.06902395,0.09482178
http://arxiv.org/pdf/2202.06599v2,Multi-Atlas Segmentation and Spatial Alignment of the Human Embryo in First Trimester 3D Ultrasound,"However, we used the
proposed framework to segment and spatially align the embryonic brain for the development
of a spatio-temporal model that can be used to explore correlations between maternal
periconceptional health and brain growth and development (Bastiaansen et al., 2022). Finally, another interesting topic for further research is applying our framework to other
problems. We created a Ô¨Çexible framework that easily can be adapted to work with or
without landmarks and with or without multiple atlas images. ",eess.IV,C,-0.14551839,-0.09777312,-0.043757267
http://arxiv.org/pdf/2202.06997v1,A Survey of Cross-Modality Brain Image Synthesis,"But             the misaligned neuroimaging data as a data augmentation
PET and MRI to PET have not received enough attention                   of self-supervised learning method and design an afÔ¨Åned
by unsupervised learning and semi-supervised learning algo-             transform loss to let the discriminator overcoming the over-
rithm. We expect future works could propose a uniform gen-              Ô¨Åtting problem. Furthermore, the authors in [Xie et al.,
erator to synthesize an arbitrary modality range among PET,             2022a]stimulate the severe misaligned neuroimaging data and
MRI to PET, MRI to CT in unsupervised learning manners or               Ô¨Ånd out that their methods perform better in severe mis-
semi-supervised learning manners. ",eess.IV,C,-0.21463937,-0.23798147,0.030967861
http://arxiv.org/pdf/2202.06997v2,A Survey of Cross-Modality Brain Image Synthesis,"But             the misaligned neuroimaging data as a data augmentation
PET and MRI to PET have not received enough attention                   of self-supervised learning method and design an afÔ¨Åned
by unsupervised learning and semi-supervised learning algo-             transform loss to let the discriminator overcoming the over-
rithm. We expect future works could propose a uniform gen-              Ô¨Åtting problem. Furthermore, the authors in [Xie et al.,
erator to synthesize an arbitrary modality range among PET,             2022a]stimulate the severe misaligned neuroimaging data and
MRI to PET, MRI to CT in unsupervised learning manners or               Ô¨Ånd out that their methods perform better in severe mis-
semi-supervised learning manners. ",eess.IV,C,-0.21463937,-0.23798147,0.030967861
http://arxiv.org/pdf/2202.06997v3,Cross-Modality Neuroimage Synthesis: A Survey,"But PET
and MRI to PET have not received enough attention by unsupervised learning and semi-supervised learning algorithm. We expect future works could propose a uniform generator to synthesize an arbitrary modality range among PET, MRI
to PET, MRI to CT in unsupervised learning manners or semi-supervised learning manners. According to the open challenges in Section 1.1, we try to answer them as follows:

   (1) From all the paper mentioned in this review, we find out that the works for jointly optimizing the synthesis task
        and their downstream task are very few [9, 32, 49, 59, 67]. ",eess.IV,C,-0.13871837,-0.2374429,0.036767606
http://arxiv.org/pdf/2202.06997v4,Cross-Modality Neuroimage Synthesis: A Survey,"This survey focuses on how to make an appropriate cross-modality brain image synthesis to correctly
        improve the downstream tasks, such as image segmentation, registration and diagnosis. ‚Ä¢ It summarizes the main issues and potential challenges in cross-modality brain image synthesis, which outlines
        the underlying research directions for future works. Organization. ",eess.IV,C,-0.073518746,-0.2788481,-0.01357737
http://arxiv.org/pdf/2202.07001v1,Handcrafted Histological Transformer (H2T): Unsupervised Representation of Whole Slide Images,"prototypical patterns are histologically meaningful. However,       The ‚ÄúFeatures‚Äù column in both tables denotes the encoders for
further research is necessary to accurately validate the biolog-    the patch-level representation: SUPERVISE-ResNet50, SWAV-
ical meaning of these sets of prototypical patterns. ResNet50 or Ô¨Åne-tuned/retrained a CNN (Tuned). ",eess.IV,C,-0.25242606,0.201884,0.07540715
http://arxiv.org/pdf/2202.07001v2,Handcrafted Histological Transformer (H2T): Unsupervised Representation of Whole Slide Images,"Using patch-level representations        prototypical patterns are histologically meaningful. However,
obtained from SWAV-ResNet50 [51], we extracted 16 proto-           further research is necessary to accurately validate the biolog-
typical patterns for each set. While the number of prototypical    ical meaning of these sets of prototypical patterns. ",eess.IV,C,-0.25739866,0.25590065,-0.019287102
http://arxiv.org/pdf/2202.07118v1,Multi-task UNet: Jointly Boosting Saliency Prediction and Disease Classification on Chest X-ray Images,"As
shown in Table 3, MT-UNet with the standard multi-task learning scheme may barely
outperform existing models for saliency prediction or image classiÔ¨Åcation. Several future work could be done to improve this study. The Ô¨Årst would be the ex-
pansion of the gaze tracking dataset for medical images. ",eess.IV,C,-0.10895809,0.022871528,0.10796736
http://arxiv.org/pdf/2202.07369v1,A Low-Parametric Model for Bit-Rate Estimation of VVC Residual Coding,"Additionally, we perform ablation studies to demonstrate the
descriptive power of each feature. The following experiments                                                                            In future work, the model accuracy could further be in-
were performed with a QP of 22. The results in Tab. ",eess.IV,B,-0.07756031,0.2344167,-0.25935677
http://arxiv.org/pdf/2202.07983v1,ADAM Challenge: Detecting Age-related Macular Degeneration from Fundus Images,"We speculated that the main reason was that different
datasets had inconsistent labeling standards for lesions. Therefore, in the future work, we need to collect a large size of
widely distributed data, which collected by different devices, with uniform labeling standards, and make more perfect
disease statistics of them, so as to provide support to study algorithms with strong generalization ability and to study
diagnostic methods of cases with multiple ocular disorders. 4.4 Clinical discussion

Although the approaches used by the participating teams were all based on the deep learning frameworks, many teams
considered clinical prior knowledge for speciÔ¨Åc tasks. ",eess.IV,C,-0.444461,0.03859747,0.08676811
http://arxiv.org/pdf/2202.07983v2,ADAM Challenge: Detecting Age-related Macular Degeneration from Fundus Images,"We speculated that the main reason was that different
datasets had inconsistent labeling standards for lesions. Therefore, in the future work, we need to collect a large size of
widely distributed data, which collected by different devices, with uniform labeling standards, and make more perfect
disease statistics of them, so as to provide support to study algorithms with strong generalization ability and to study
diagnostic methods of cases with multiple ocular disorders. 4.4 Clinical discussion

Although the approaches used by the participating teams were all based on the deep learning frameworks, many teams
considered clinical prior knowledge for speciÔ¨Åc tasks. ",eess.IV,C,-0.444461,0.03859747,0.08676811
http://arxiv.org/pdf/2202.07983v3,ADAM Challenge: Detecting Age-related Macular Degeneration from Fundus Images,"We speculated that the main reason was that different datasets had inconsistent
labeling standards for lesions. Therefore, in the future work, we need to collect a large size of widely distributed data,
collected by different devices, with uniform and consistent labeling standards, and make better clinical characterization
of them, to provide support to study algorithms with strong generalization ability and to study diagnostic methods for
cases with multiple ocular disorders. 4.4 Clinical domain knowledge incorporation

Although the approaches used by the participating teams were all based on deep learning frameworks, many teams
incorporated prior clinical domain knowledge for some speciÔ¨Åc tasks. ",eess.IV,C,-0.4482451,0.030590193,0.110936396
http://arxiv.org/pdf/2202.08195v1,Label Propagation for Annotation-Efficient Nuclei Segmentation from Pathology Images,"authors proposed a divergence loss to encourage the diversity      Third, the touched and overlapped nuclei in pathology images
between the two models, which however may consequently             are challenging to segment at the instance level, leaving for
hurting the performance of each model. On the contrary, we         future work to further develop methods for nuclei instance
propose a pseudo label generation method based on EMA              segmentation. And last but not least, we will try to adapt the
to periodically average the predictions to supervise the other     proposed method for interactive annotation to further reduce
model, which alleviates the problem of self-deception and          the annotation burden of pathologists, promoting the research
produces more robust pseudo labels. ",eess.IV,C,-0.40758556,0.047135923,0.051745735
http://arxiv.org/pdf/2202.08260v1,Low-Rank Phase Retrieval with Structured Tensor Models,"One important avenue
for future research can be to extend our algorithm but with theoretical guarantees on the sample
complexity required for accurate recovery. Our results show that there exist Tucker-structured
models with better performance; we believe that perhaps Ô¨Ånding a more principled approach for
choosing these ranks is an important challenge for future work. 8
A Factor Updates with CGLS

Tucker-Structured Phase Retrieval (TSPR) uses conjugate gradient least squares (CGLS) to update
the Tucker factors and core tensor. ",eess.IV,B,0.19286072,0.085303456,0.0068270294
http://arxiv.org/pdf/2202.08595v1,Deep VQA based on a Novel Hybrid Training Methodology,"Fi-                      in Fig. 2.
nally, Section 5 concludes the paper and outlines future work. 2. ",eess.IV,B,0.17904417,0.3022297,-0.062291868
http://arxiv.org/pdf/2202.08680v1,Synthetic data for unsupervised polyp segmentation,"We hope this study can help aligning
synthetic data and medical imaging in future. As future work, we will explore
how to include our synthetic annotations in the CycleGAN. References

 1. ",eess.IV,C,-0.18733357,-0.07100616,0.009675061
http://arxiv.org/pdf/2202.08880v1,Ray-transfer functions for camera simulation of 3D scenes with hidden lens design,"We will validate         pixels. In this case, the edge-spread function might not be fully
this approach in future work. dominated by the optics alone and a lower-degree polynomial Ô¨Åt
                                                                        might be satisfactory. ",eess.IV,A,0.26967484,-0.27564377,-0.12511969
http://arxiv.org/pdf/2202.08880v2,Ray-transfer functions for camera simulation of 3D scenes with hidden lens design,"We will validate         and a constructed three-dimensional scene [40]. this approach in future work. ACKNOWLEDGEMENTS
    The method illustrated here and implemented in the software
applies only to rotationally symmetric lenses. ",eess.IV,A,0.13705269,-0.19660613,-0.077995226
http://arxiv.org/pdf/2202.08994v1,REFUGE2 Challenge: Treasure for Multi-Domain Learning in Glaucoma Assessment,"From the Ô¨Ågure,
it can be seen that the localization results of the top 3 teams on online and onsite sets are near the ground truths on both
glaucoma and non-glaucoma samples. 5 Discussion

In this section, we discuss the Ô¨Åndings from the challenge results, and discuss the signiÔ¨Åcance of the REFUGE2
challenge to the AI technology and clinical applications in ophthalmology, as well as the future work. 5.1 Findings

Considering the results of the three sub-tasks, it can be seen that the prediction results of each team on the online set are
better than those on the onsite set. ",eess.IV,C,-0.15361327,0.18214953,0.014278639
http://arxiv.org/pdf/2202.08994v2,REFUGE2 Challenge: Treasure for Multi-Domain Learning in Glaucoma Assessment,"(A)
Glaucoma sample in the online dataset, (B) non-glaucoma sample in the online dataset, examples from the Ô¨Årst row to
the last are corresponding to the teams MAI, cheeron, and VUNO EYE TEAM; (C) glaucoma sample in the onsite
dataset, (D) non-glaucoma sample in the onsite dataset, examples from the Ô¨Årst row to the last are corresponding to the
teams cheeron, MAI, and VUNO EYE TEAM. 5 Discussion

In this section, we discuss the Ô¨Åndings from the challenge results, and discuss the signiÔ¨Åcance of the REFUGE2
challenge to the AI technology and clinical applications in ophthalmology, as well as the future work. 5.1 Findings

Considering the results of the three sub-tasks, it can be seen that the prediction results of each team on the online set are
better than those on the onsite set. ",eess.IV,C,-0.15223554,0.19938567,0.038165055
http://arxiv.org/pdf/2202.09059v1,Towards better understanding and better generalization of few-shot classification in histology images with contrastive learning,"However,
histology datasets usually lack enough diverse annotated classes that help to build a know-everything
FSP model. A topic we leave for future work is to explore whether CLP always generalizes better
than FSP when pre-training on a base dataset with limited number of annotated classes and if the
generalization gap would increase as the label diversity decreases. We point out that the visualization
results and the large generalization gap shown in our work still remains as empirical observations. ",eess.IV,C,-0.39695626,0.21071322,0.13754094
http://arxiv.org/pdf/2202.09199v1,OKVIS2: Realtime Scalable Visual-Inertial SLAM with Loop Closure,"A series of experiments
            2 0.81 0.32 2.01 0.74 0.16 0.49 0.16 299 ( )                                                  demonstrates that the method achieves competitive results
            3 4.68 0.89 2.44 2.51 0.14 0.47 0.13 383 ( )                                                  relative to state-of-the-art VI-SLAM systems. Avg 6.40 0.51 2.33 1.40 0.22 0.45 0.22 324                                                         As part of future work, we may want to address robust
                                                                                                          handling of the monocular VI-SLAM case, as well as inclu-
1 Results taken from [4]. sion of additional sensors, such as absolute positions. ",eess.IV,A,0.2109248,0.061269272,0.038129523
http://arxiv.org/pdf/2202.09199v2,OKVIS2: Realtime Scalable Visual-Inertial SLAM with Loop Closure,"A series of experiments
            2 0.81 0.32 2.01 1.37 0.16 0.49 0.16 299 ( )                                                  demonstrates that the method achieves competitive results
            3 4.68 0.89 2.44 1.62 1.35 0.47 1.35 383                                                      relative to state-of-the-art VI-SLAM systems. Avg 6.40 0.51 2.33 1.38 0.99 0.45 0.54 324                                                         As part of future work, we may want to address robust
                                                                                                          handling of the monocular VI-SLAM case, as well as inclu-
1 Results taken from [4]. sion of additional sensors, such as absolute positions. ",eess.IV,A,0.20662415,0.059333082,0.030120812
http://arxiv.org/pdf/2202.09258v1,Autoencoding Low-Resolution MRI for Semantically Smooth Interpolation of Anisotropic MRI,"This direction will be investigated in       space encodings of two spatially adjacent slices. The experi-
future work. ments using cardiac cine and brain MRIs demonstrated that the
                                                                     proposed approach outperforms cubic B-spline interpolation
                                                                    17

on cardiac cine and brain MRIs. ",eess.IV,B,0.03002048,-0.19172186,-0.27253932
http://arxiv.org/pdf/2202.09515v1,SPNet: A novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss,"However, we believe
that it can accurately and eÔ¨Éciently extract blood vessels in other structures and organs, which also suÔ¨Äer
from challenges of blurry boundaries and scale variation. How to extend the method to process more clinical
angiography data, as well as 3D OCT images, is our future work. 25
Acknowledgements

    This work is supported in part by the National Natural Science Foundation of China under Grants
61976229, 61906046. ",eess.IV,C,-0.046467885,-0.2298516,-0.31201646
http://arxiv.org/pdf/2202.09609v1,A Lightweight Dual-Domain Attention Framework for Sparse-View CT Reconstruction,"As a result, we succeed in acquiring
precise, detailed, and artifact-free sparse-view CT images through our pipeline. Moving forward, the architecture of CAGAN might be able to be applied to other image-to-image tasks, such as image
enhancing, and semantic segmentation, which is worthy of our further research. Also, extreme sparsity of projections
would lead to much loss of information and cause severe artifacts beyond any repairing algorithms. ",eess.IV,A,0.004139144,-0.41683856,0.11460368
http://arxiv.org/pdf/2202.09810v1,Alternative design of DeepPDNet in the context of image restoration,"We experimented with the proposed approach on BSD68 dataset, and obtain competitive
results that are encouraging as being comparable to state-of-the-art results. However, in
future work, on one hand, an end-to-end the CNN network can be combined into frame-
work to further improve the performance; on the other hand, deeper analysis on complete
reformulation (4), including the learning of Œ∏, will certainly help improve the restoration

                                                         10
performances. Additionally, the conclusion between PA-DeepPDNet and the learned Deep-
PDNet requires a deeper study as the boundary eÔ¨Äects are not dealt similarly. ",eess.IV,A,-0.016266985,-0.12790078,0.36287692
http://arxiv.org/pdf/2202.09988v1,Outlier-based Autism Detection using Longitudinal Structural MRI,"Table 8: SAGAN performance on cross-sectional data from different planes. S.No                             sMRI Modality       Accuracy   AUC

  1                                    Axial          60.86%    0.56
  2                                   Coronal         63.04%    0.64
  3                                   Sagittal        54.34%    0.52

5 Conclusion and future work

We employ a GAN-based encoder-decoder framework on longitudinal sMRI slices, where the error between the re-
constructed and actual adjacent three slice stacks is utilized to determine ASD samples as outliers. Three architectures,
namely, the UNet, GAN and SAGAN were examined for reconstruction quality and therefrom, ASD detection per-
formance. ",eess.IV,A,0.17441154,-0.1036187,-0.04575073
http://arxiv.org/pdf/2202.09988v2,Outlier-based Autism Detection using Longitudinal Structural MRI,"Table 8: SAGAN performance on cross-sectional data from different planes. S.No                             sMRI Modality       Accuracy   AUC

  1                                    Axial          60.86%    0.56
  2                                   Coronal         63.04%    0.64
  3                                   Sagittal        54.34%    0.52

5 Conclusion and future work

We employ a GAN-based encoder-decoder framework on longitudinal sMRI slices, where the error between the re-
constructed and actual adjacent three slice stacks is utilized to determine ASD samples as outliers. Three architectures,
namely, the UNet, GAN and SAGAN were examined for reconstruction quality and therefrom, ASD detection per-
formance. ",eess.IV,A,0.17441154,-0.1036187,-0.04575073
http://arxiv.org/pdf/2202.10396v1,MIST GAN: Modality Imputation Using Style Transfer for MRI,"We show that our
network is not only scalable to any number of input modalities, but also capable
of picking up style variations within each modality. Evaluation on the BraTS‚Äô18
multimodal brain MRI dataset suggests that the method is promising and opens
new avenues for further research. MIST GAN  9

References

 1. ",eess.IV,C,-0.09525399,-0.16609323,0.10082123
http://arxiv.org/pdf/2202.10572v1,Ghost projection. II. Beam shaping using realistic spatially-random masks,"Ghost projection formed via NNLS may be the op-
                                                                     timal random mask representation, but is not the
s(t) =  dt Œ¥x(t) + dt Œ¥y(t) , ti ‚â§ t ‚â§ tf (21)                       representation that is most robust to noise inclu-
                                                                     sions. An avenue for future work could be to write
at which each point on the path is traversed. Additional             an eÔ¨Écient optimization algorithm that has input
simplicity of implementation can arise from travers-                 parameters for noise inclusions and Ô¨Ånds the ran-
ing this mask-displacement path at constant speed. ",eess.IV,A,0.36750203,-0.1435706,0.02108486
http://arxiv.org/pdf/2202.10572v2,Ghost projection. II. Beam shaping using realistic spatially-random masks,"Ghost projection formed via NNLS may be the op-
   timal random mask representation, but is not the          (b) the shutter is then opened, and the speciÔ¨Åed
   representation that is most robust to noise inclu-              mask is illuminated for a speciÔ¨Åed time;
   sions. An avenue for future work could be to write
   an eÔ¨Écient optimization algorithm that has input           (c) the shutter is then closed;
   parameters for noise inclusions and Ô¨Ånds the ran-
   dom mask representation that achieves the best Ô¨Å-         (d) if more exposures are required, return to the
   nal SNR, as opposed to best initial SNR. Ô¨Årst step in the protocol, otherwise the ghost
                                                                   projection is complete. ",eess.IV,A,0.37580693,-0.13325591,-0.0061476966
http://arxiv.org/pdf/2202.10691v1,An Object Aware Hybrid U-Net for Breast Tumour Annotation,"The
initial active contours acted as object identiÔ¨Åers which helped to improve the network performance for heterogeneous
data. The future work would be to enhance the segmentation performance at WSI level so that the pathologist like
annotations could be done for both medical and educational purposes. Acknowledgement

This research was carried out in the Indian Institute of Information Technology, Allahabad and supported by the
Ministry of Human Resource and Development, Government of India. ",eess.IV,C,-0.23921382,0.06527138,-0.0044299727
http://arxiv.org/pdf/2202.10724v1,Feature reconstruction from incomplete tomographic data without detour,"A rigorous convergence analysis
of the presented scheme remains an open issue. Another directions of further research
may may include the extension of the proposed approach to non-sparse, non-convolutional
features and generalization to other types of tomography problems. Also, multiple feature
reconstruction (similar to the method [14, 34]) seems to be an interesting future research
direction. ",eess.IV,A,0.05404701,-0.3325011,-0.14105259
http://arxiv.org/pdf/2202.10847v1,UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography,"in Table 5. While we do not have a justiÔ¨Åcation for why the anisotropic approximation performs better, we
believe that regularization/prior exploration would be interesting future work. Table 5. ",eess.IV,A,0.21927704,0.026039742,0.022663034
http://arxiv.org/pdf/2202.10847v2,UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography,"The relative performance of these two regularizers for the
MCD UINR are presented in Table 4. While we do not have a justiÔ¨Åcation for why the anisotropic
approximation performs better, we believe that regularization/prior exploration would be interesting
future work. Table 4: The affect of using different approximations to the TV regularizer for MCD UINR perfor-
mance. ",eess.IV,A,0.30444896,-0.03611544,-0.07694242
http://arxiv.org/pdf/2202.10971v1,Improving Classification Model Performance on Chest X-Rays through Lung Segmentation,"The future scope of this study is to go one step further than CXR binary
classiÔ¨Åcation and evaluate our proposed approach facing diÔ¨Äerent types of lung
diseases, including COVID-19. Given the excellent performance of the MoCo
model in this study, we plan to conduct further analysis on the diÔ¨Äerent self-
supervised approaches (e.g., SimCLR [39]) to analyzing CXR images. Acknowledgements

Not applicable. ",eess.IV,C,-0.18754795,0.09766413,-0.123315185
http://arxiv.org/pdf/2202.11206v1,Functional Parcellation of fMRI data using multistage k-means clustering,"Using this technique, we were also able to replicate
the hemodynamic response corresponding to whole brain activation. As a future work, we wish to
expand the utility of multistage clustering algorithm for group level studies. For task fMRI data,
we plan to obtain hemodynamic response for different subjects, and investigate inter-subject
hemodynamic response variability along with variability in the spatial region. ",eess.IV,B,-0.119798094,0.13703655,-0.13322836
http://arxiv.org/pdf/2202.11401v1,Mixed-Block Neural Architecture Search for Medical Image Segmentation,"The experiments in this paper show the added
value of this approach. Overall, the results indicate that further research into search space reÔ¨Ånement, allowing
to exploit key features of what accounts for good deep learning performance, may yet push the boundaries of
what can be achieved with deep neural networks for medical image processing. REFERENCES

 [1] Bernard, O. et al., ‚ÄúDeep learning techniques for automatic MRI cardiac multi-structures segmentation and
      diagnosis,‚Äù IEEE Transactions on Medical Imaging 37(11), 2514‚Äì2525 (2018). ",eess.IV,C,-0.28517726,-0.23975866,0.051197298
http://arxiv.org/pdf/2202.11709v1,Co-occurring Diseases Heavily Influence the Performance of Weakly Supervised Learning Models for Classification of Chest CT,"Similar relationships can be observed between
atelectasis and effusion, where atelectasis performance is higher when co-occurring with effusion. Discussion and future work:

In this work, we have investigated the differences between binary and multi-label classifiers. In this comparison, the
binary classifier outperformed the multi-label classification for focal disease classes (e.g., nodule). ",eess.IV,C,-0.32091656,0.1498237,-0.036391143
http://arxiv.org/pdf/2202.12099v1,Data variation-aware medical image segmentation,"Our algorithm does not distinguish between types of variation,
and it only performs the partitioning to maximize segmentation quality. Making our approach insightful to end
users (e.g., explicitly showing diÔ¨Äerent types of variation in data) and validating the practical added value (i.e.,
reducing required time for scan delineation) is an interesting and important question for further research. As mentioned in Section 4, a larger number of produced segmentation variants leads to better performance
of our approach. ",eess.IV,C,-0.068486065,0.059861355,0.015484804
http://arxiv.org/pdf/2202.12267v2,Inflation of test accuracy due to data leakage in deep learning-based classification of OCT images,"For the other datasets, the p-values were much
larger. We conclude that using random labels during training can potentially be a way to automatically detect data leakage, but
that it requires further research. Discussion

Dataset split should be carefully designed to avoid overlap between training and testing sets. ",eess.IV,B,-0.14065926,0.41023844,0.1490849
http://arxiv.org/pdf/2202.12474v1,Structure-aware Unsupervised Tagged-to-Cine MRI Synthesis with Self Disentanglement,"Our approach can be a simple add-on module to CycleGAN, or the other cycle constrained translators‚Äîe.g.,
DiscoGAN and DualGAN. Additionally, our method can be applied to other modality synthesis tasks, including
MRI-to-CT synthesis, which is subject to our future work. ACKNOWLEDGMENTS
This work is supported by NIH R01DC014717, R01DC018511, and R01CA133015. ",eess.IV,A,0.035247505,-0.24001111,0.004504946
http://arxiv.org/pdf/2202.12515v1,Faithful learning with sure data for lung nodule diagnosis,"Statistical result of LIDC-IDRI re-labeling nodules (benign or ma-  6. Conclusion and future work
lignant) in terms of original average malignancy scores. In summary, we raised the vital issues that are commonly
5.7. ",eess.IV,C,-0.30212975,0.13067442,-0.28631917
http://arxiv.org/pdf/2202.12565v1,Beyond Bj√∏ntegaard: Limits of Video Compression Performance Comparisons,"(the marker close to an SSIM value of 0.98). In contrast, the
PCHIP algorithm returns a stable curve with a maximum er-             In future work, the same evaluations could be performed
ror below 10%. Still, Akima interpolation returns the closest     for further performance metrics such as subjective quality
approximation (visible at low bitrates) as the green curve is     scores or mean average precision scores in object detection
located closer to the markers than the other curves. ",eess.IV,B,0.24194059,0.20653181,-0.16140935
http://arxiv.org/pdf/2202.12565v2,Beyond Bj√∏ntegaard: Limits of Video Compression Performance Comparisons,"(the marker close to an SSIM value of 0.98). In contrast, the
PCHIP algorithm returns a stable curve with a maximum er-             In future work, the same evaluations could be performed
ror below 10%. Still, Akima interpolation returns the closest     for further performance metrics such as subjective quality
approximation (visible at low bitrates) as the green curve is     scores or mean average precision scores in object detection
located closer to the markers than the other curves. ",eess.IV,B,0.24194059,0.20653181,-0.16140935
http://arxiv.org/pdf/2202.12565v3,Beyond Bj√∏ntegaard: Limits of Video Compression Performance Comparisons,"that when comparing the compression performance of differ-
                                                                     ent codecs, useful results can be obtained when the BD-rate
    Apparently, the interpolation returned by CSI leads to an        difference is larger than 1.5%. overshoot of the interpolated curve, which causes the inter-
polated bitrate to be more than twice as high as measured                In future work, the same evaluations could be performed
(the marker close to an SSIM value of 0.98). In contrast, the        for further performance metrics such as subjective quality
PCHIP algorithm returns a stable curve with a maximum er-            scores or mean average precision scores in object detection
ror below 10%. ",eess.IV,B,0.30468878,0.18675506,-0.12131315
http://arxiv.org/pdf/2202.12628v1,Predicting 4D Liver MRI for MR-guided Interventions,"Additionally, in our method, one model is trained for each subject. In
future work, we want to investigate the possibility of having only one model
that abstracts not only beyond seen breathing states, but also beyond seen
subjects, or adapts quickly to new subjects. We believe that this is achiev-
able using transfer learning strategies which, in turn, will further reduce the
amount of necessary training data. ",eess.IV,B,-0.0845754,0.19882125,0.17466511
http://arxiv.org/pdf/2202.12852v1,A CNN-based Post-Processor for Perceptually-Optimized Immersive Media Compression,"Section 4 provides the comparison
                                          major challenge for all types of volumetric video, besides the cre-       results between the proposed method and the anchors on the test
                                          ation of the content, is its storage and distribution over existing and   content. Finally, conclusions and future work are outlined in Section
                                          future networks. To this end, standardization bodies have developed       5. ",eess.IV,A,0.18798499,0.010863657,0.007550085
http://arxiv.org/pdf/2202.12959v1,Image reconstruction algorithms in radio interferometry: from handcrafted to learned denoisers,"Tailoring AIRI denoisers for a PnP version of SARA for
                                                                        pure imaging, or for joint DDE calibration and imaging, are impor-
In what follows, we discuss current limitations of the AIRI frame-      tant directions for future work. work, and future work. This also includes considerations for further
developments of uSARA, which, we emphasize, was never proposed          ACKNOWLEDGEMENTS
before as a standalone RI imaging algorithm. ",eess.IV,A,0.27736703,-0.2895239,-0.3698628
http://arxiv.org/pdf/2202.12959v2,Image reconstruction algorithms in radio interferometry: from handcrafted to learned regularization denoisers,"We
over the 20 simulated observations. Error bars show the (very small and                                anticipate that future work, building a richer database from RI ob-
virtually invisible) 95% conÔ¨Ådence interval. For AIRI-‚Ñì2 and AIRI-‚Ñì1, all                              servation, and considering more advanced losses, such as adversarial
reconstruction times are reported for both GPU (solid red lines) and CPU                               losses (Wang et al. ",eess.IV,A,0.26132482,0.11546394,0.07178363
http://arxiv.org/pdf/2202.13209v1,Opening the Black Box of Learned Image Coders,"However, a rigorous
responses as the transform basis. To verify this, we measure        proof is nontrivial, and should be pursued in future work. dchannel and dspatial of various LICs on the Kodak image set and
present the results in Table 1, where dchannel is averaged over         The basis decomposition property of different LICs as
all images and dspatial is computed on the Ô¨Årst image due to its    well as linear coders also raises an interesting question: what
high computational complexity. ",eess.IV,A,0.3711887,-0.19400367,0.033348337
http://arxiv.org/pdf/2202.13209v2,Opening the Black Box of Learned Image Coders,"IV-B. Finally, we            but compute MSEspatial only on the Ô¨Årst image due to its high
discuss our results and future work in Sec. IV-C.                    computational complexity. ",eess.IV,A,0.2651615,-0.042020466,-0.09285985
http://arxiv.org/pdf/2202.13804v1,RestainNet: a self-supervised digital re-stainer for stain normalization,"However, there is still one challenge we have to tackle in                   [14] M. N. Gurcan, L. E. Boucheron, A. Can, A. Madabhushi, N. M.
future works. Since our model learns the color distribution                           Rajpoot, and B. Yener, ‚ÄúHistopathological image analysis: A review,‚Äù
of the speciÔ¨Åc domain. ",eess.IV,C,-0.14065601,-0.111889064,-0.0362882
http://arxiv.org/pdf/2202.14009v1,SUNet: Swin Transformer UNet for Image Denoising,"However, the potential of Swin Transformer still
observe the following three things: 1) Our SUNet has compet-    deserves to be expected in the future. Our future works are
itive SSIM values because Swin-Transformer is based on the      going to attempt more complex restoration tasks, such as real-
global information which makes the denoised images more
world noise and real-world blur, while the model is still based                   [20] Y.-Z. Su, T.-J. ",eess.IV,A,0.280954,0.089985795,-0.002433531
http://arxiv.org/pdf/2203.00077v1,One Model is All You Need: Multi-Task Learning Enables Simultaneous Histology Image Segmentation and Classification,"Despite this, the neutrophil performance is still rela-
tively low on the external test set. In future work, we would
like to explore why this is low and understand how we can
further improve the performance. Subtyping gland segmentation output

   The subtyping method that we described in Section 3.3.2
is not limited to nuclear classification. ",eess.IV,C,-0.1434886,0.16323343,-0.1590733
http://arxiv.org/pdf/2203.00077v2,One Model is All You Need: Multi-Task Learning Enables Simultaneous Histology Image Segmentation and Classification,"Despite this, the neutrophil performance is still rela-
tively low on the external test set. In future work, we would
like to explore why this is low and understand how we can
further improve the performance. Subtyping gland segmentation output

   The subtyping method that we described in Section 3.3.2
is not limited to nuclear classification. ",eess.IV,C,-0.1434886,0.16323343,-0.1590733
http://arxiv.org/pdf/2203.00129v1,BlazeNeo: Blazing fast polyp segmentation and neoplasm detection,"Red, green and blue markers denote INT8, FP16
and FP32 precisions, respectively. TABLE 6: Accuracy metrics on the NeoPolyp-Clean test set for BlazeNeo-DHA models in different precisions

             Model               Diceseg   IoUseg             Dicenon   IoUnon   Diceneo   IoUneo

PyTorch (w/o compression)           0.904    0.825               0.717    0.559     0.885    0.792
       TensorRT FP32                0.906    0.828               0.721    0.563     0.887    0.796
       TensorRT FP16                0.906    0.828               0.721    0.563     0.887    0.796
       TensorRT INT8                0.870    0.770               0.678    0.513     0.857    0.750

   In future works, we would like to exploit recent advance-  ments in Transformer-based architectures to improve the

VOLUME 10, 2021                                                                                                                                                    13
FIGURE 12: Qualitative comparison of BlazeNeo-DHA models in different precisions: (a) image, (b) ground truth, (c) Pytorch,
(d) TensorRT FP32, (e) TensorRT FP16, (f) TensorRT INT8. 14  VOLUME 10, 2021
TABLE 7: Latency metrics for BlazeNeo-DHA models in different precisions. ",eess.IV,B,0.18220115,0.28070843,-0.044092834
http://arxiv.org/pdf/2203.00327v1,Design Techniques for Incremental Non-Regular Image Sampling Patterns,"be shown in near real-time using linear interpolation or fast
                                                                   implementations of the FSR [18], [19]. Quarter mask from [10]            SEM     TECNICK
SOBOL pattern (25%)           LIN FSR    LIN FSR                      In future work, it is of interest to investigate our proposed
prop. GAUSS pattern (25%)     30.4 30.6  31.6 33.3                 patterns within feature adaptive approaches for scanning elec-
Monte Carlo pattern from [8]  30.0 30.3  30.7 32.7                 tron microscopy [20], [21]. ",eess.IV,A,0.1443094,-0.10683395,-0.14128901
http://arxiv.org/pdf/2203.00336v1,Enhanced Image Reconstruction From Quarter Sampling Measurements Using An Adapted Very Deep Super Resolution Network,"Best to be viewed enlarged on
In this paper, we transfer the concepts of Very Deep Super Resolu-     a monitor.) tion network (VDSR) to the special case of quarter sampling enhance
the reconstruction quality of image data acquired with a quarter sam-       For future work, we would like to transfer the advantages of
pling sensor. In doing so, we propose an adapted version of VDSR       VDSR-QS to other non-regular measurement scenarios such as
called VDSR-QS to incorporate the special property of the quarter      three-quarter sampling, where randomly oriented L-shaped pixels
sampling measurements that the exact value of some of the high-        are used resulting in higher reconstruction quality [18]. ",eess.IV,A,0.30943215,-0.2340312,-0.0075504966
http://arxiv.org/pdf/2203.00355v1,Tempera: Spatial Transformer Feature Pyramid Network for Cardiac MRI Segmentation,"By detecting a
small ROI which contains the RV, we can minimize erroneous segmentations,
minimize the network learning irrelevant background features and allow for a
smaller model. However, the detection may fail in the presence of pathology,
artefacted or low SNR images and, in future work, we plan to improve this heart
detection step. Short-term it can beneÔ¨Åt from restricting the detection within a
central region of the image. ",eess.IV,C,-0.20999625,-0.14866988,-0.003087137
http://arxiv.org/pdf/2203.00417v1,Beam-Shape Effects and Noise Removal from THz Time-Domain Images in Reflection Geometry in the 0.25-6 THz Range,"by such noise). The importance of applying image processing
The restoration procedure results in sharpening the bands                     strategies to HS images is most evident for applications that
corresponding to lower frequencies (e.g., 0.38-0.78 THz) and                  relies on the possibility of extension of the available frequency
fully removing severe noise from bands corresponding to                       range using far-infrared frequencies (spanning from few hun-
higher frequencies (e.g., 5.85-6.25 THz), thus expanding the                  dreds of GHz to 10 THz) enabling a more comprehensive
usable frequency range for further analysis. analysis. ",eess.IV,A,0.31540778,-0.13298596,-0.20645197
http://arxiv.org/pdf/2203.00466v1,Modeling the Energy Consumption of the HEVC Decoding Process,"values given in Table IV such that our evaluation method using
only three QP values is conÔ¨Årmed. In future work, we plan to validate, test, and adapt the model
                                                                  for speciÔ¨Åc hardware decoders like ASICs. Furthermore, we
   Next, we would like to discuss the results shown in Table      will utilize the feature based model inside the Rate-Distortion-
VIII. ",eess.IV,B,0.45961982,0.2908373,-0.035088673
http://arxiv.org/pdf/2203.00479v1,A Probabilistic Deep Image Prior for Computational Tomography,"Nonetheless, we emphasise that this condition is only sufÔ¨Åcient, but not necessary, since the kernel is only evaluated at
lattice points (instead of arbitrary scattered points). We leave a full investigation of the monotonicity to a future work, given
the compelling empirical evidence for monotonicity in both the NN and linearised settings. The next result collects the Fourier transforms of the associated kernel for the Gaussian and Matern-1/2 kernels. ",eess.IV,A,0.17795362,-0.009659302,-0.06937057
http://arxiv.org/pdf/2203.00479v2,Uncertainty Estimation for Computed Tomography with a Linearised Deep Image Prior,"Nonetheless, we
emphasise that this condition is only sufÔ¨Åcient, but not necessary, since the kernel is only evaluated at lattice points (instead
of arbitrary scattered points). We leave a full investigation of the monotonicity to a future work, given the compelling
empirical evidence for monotonicity in both the NN and linearised settings. The next result collects the Fourier transforms of the associated kernel for the Gaussian and Matern-1/2 kernels. ",eess.IV,A,0.17795362,-0.009659302,-0.06937057
http://arxiv.org/pdf/2203.00531v1,Towards deep learning-powered IVF: A large public benchmark for morphokinetic parameter prediction,"This highlights that our database allows the models to be trained with
16 phases without being biased when reducing the settings to what can be found
in the literature. 4 Discussion

In this study, we report the development and the respective performance of
popular deep learning models for the annotation of a large dataset of time-lapse
videos of embryo development that we propose to make publicly available for
the sake of facilitated and improved further research in the Ô¨Åeld. We chose three
architectures for our experiments. ",eess.IV,C,-0.2805557,0.055001304,0.38485372
http://arxiv.org/pdf/2203.00531v2,Towards deep learning-powered IVF: A large public benchmark for morphokinetic parameter prediction,"Also, the baseline models achieved good performance which demon-

                               13
strates that our dataset is suÔ¨Écient in size and quality to train and evaluate
deep learning models. 4 Discussion

In this study, we propose a large dataset of time-lapse videos of embryo devel-
opment and make it publicly available for the sake of facilitated and improved
further research in the Ô¨Åeld. This dataset is accompanied by detailed morpho-
kinetic annotations and custom metrics. ",eess.IV,C,-0.18543784,0.024686547,0.30484402
http://arxiv.org/pdf/2203.00899v1,Machine learning based lens-free imaging technique for field-portable cytometry,"The result for
depth and breadth optimization indicates that the average accuracy of the intermediate model is >0.85 (including all the
classes), whereas it is <0.85 for shallow and deep networks. Therefore, we proceed with this intermediate model as an
optimum model for further study. Considering the intermediate model has the optimum breadth and depth, the further
optimization of the parameters and the results are as shown in Figure 5a. ",eess.IV,A,0.035422422,0.0029703174,0.2461727
http://arxiv.org/pdf/2203.00899v2,Machine learning based lens-free imaging technique for field-portable cytometry,"The result for
depth and breadth optimization indicates that the average accuracy of the intermediate model is >0.85 (including all the
classes), whereas it is <0.85 for shallow and deep networks. Therefore, we proceed with this intermediate model as an
optimum model for further study. Considering the intermediate model has the optimum breadth and depth, the further
optimization of the parameters and the results are as shown in Figure 5a. ",eess.IV,A,0.035422422,0.0029703174,0.2461727
http://arxiv.org/pdf/2203.01089v1,Shape constrained CNN for segmentation guided prediction of myocardial shape and pose parameters in cardiac MRI,"Therefore,             concept can as well be applied to other segmentation tasks. Ex-
we believe that it is more valuable to direct further research          amples are joint modeling of myocardium, LV and RV, 3D car-
towards a 3D version of our approach. Since the parameter re-           diac segmentation or application of the method on other clinical
gression showed to be more sensitive to the number of samples,          data, e.g. ",eess.IV,C,-0.24515975,0.00094392,-0.1626572
http://arxiv.org/pdf/2203.01099v1,Decoding-Energy-Rate-Distortion Optimization for Video Coding,"[12] C. Herglotz, Y. Wen, B. Dai, M. Kra¬®nzler, and A. Kaup, ‚ÄúA bitstream
                                                                                feature based model for video decoding energy estimation,‚Äù in Proc. The proposed method of DERDO creates a vast amount                           Picture Coding Symposium (PCS), Nu¬®rnberg, Germany, Dec 2016.
of possible further research topics: Research can focus on
improving the decoding energy model or the training process               [13] E. Kalali, Y. Adibelli, and I. Hamzaoglu, ‚ÄúA high performance and low
of the speciÔ¨Åc energies. Furthermore, in the DERDO process,                     energy intra prediction hardware for HEVC video decoding,‚Äù in Con-
the transmission energy can be considered explicitly and new                    ference on Design and Architectures for Signal and Image Processing
encoder speed-up methods targeting the decoder energy con-                      (DASIP), Oct 2012, pp. ",eess.IV,A,0.38836837,-0.034434494,0.19104254
http://arxiv.org/pdf/2203.01186v1,Hybrid Model-based / Data-driven Graph Transform for Image Coding,"Hybrid-ADST (K = 4)    5.729    5.961     5.676
                       4.475    5.407     4.923                             While we have demonstrated the merits of a hybrid model-based
                                                                       / data-driven transform, the computation of the transform at both the
     Table 1 shows the variation of energy compaction for different    encoder and decoder is expensive. For future work, we will investi-
transforms. We see that Hybrid-ADST (K = 4) had lower average          gate reduction of computation complexity of such hybrid transform
                                                                       for practical image coding. ",eess.IV,A,0.37466368,-0.13006476,0.05040793
http://arxiv.org/pdf/2203.01296v1,Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement,"Moreover, the proposed
the proposed HWMNet achieves runner-up performance for      HWAB focuses on the features of wavelet domain which can
all metrics (PSNR, SSIM and LPIPS) on LOL testing dataset,  enrich the semantic information, too. In the future work,
which means that our enhanced images are more perceptu-     we are going to improve current model to handle different
restoration tasks such as image denoising and deblurring. [15] Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat,
                                                                                Fahad Shahbaz Khan, Ming-Hsuan Yang, and Ling Shao, ‚ÄúCy-
                               6. ",eess.IV,A,0.16013151,-0.0021805032,0.17354546
http://arxiv.org/pdf/2203.01325v1,Self-Supervised Learning for Real-World Super-Resolution from Dual Zoomed Observations,"8). will further study this issue in our future work. The pro-
                                                                    posed method can be embedded in imaging devices such as
5.3. ",eess.IV,A,0.28815633,-0.10006767,-0.25731266
http://arxiv.org/pdf/2203.01645v1,Selective Residual M-Net for Real Image Denoising,"Our
and validation, respectively. We randomly crop 100 patches         future works are going to focus on different restoration tasks
with size 256√ó256 for each training image and randomly add         such as image deblurring and image deraining. AWGN to the patches with noise level from œÉ = 5 to 50. ",eess.IV,A,0.08698766,-0.118087366,0.05116587
http://arxiv.org/pdf/2203.01668v1,Translational Lung Imaging Analysis Through Disentangled Representations,"Voxel-wise evaluation is not suitable for counterfactual images. Previous manual delim-
itation of comparable regions is needed, which is a priority for our future work. To illustrate similarities and diÔ¨Äerences in the HU scale, in Figure 7, we plot the HU
proÔ¨Åle belonging to the damaged regions shown in Figure 3. ",eess.IV,A,0.0161183,-0.021271707,-0.04646844
http://arxiv.org/pdf/2203.01782v1,Multi-Objective Design Space Exploration for the Optimization of the HEVC Mode Decision Process,"1593‚Äì1597. In future work, thanks to the actor-based model, a corre-         [10] J. Vanne, M. Viitanen, and T. Hamalainen, ‚ÄúEfÔ¨Åcient mode decision
sponding study could be performed for multi-core processors                schemes for HEVC inter prediction,‚Äù IEEE Trans. on Circuits and
where the optimal encoding order could change due to po-                   Systems for Video Technology, vol. ",eess.IV,A,0.37188298,0.18844122,0.08857782
http://arxiv.org/pdf/2203.01934v1,Quality or Quantity: Toward a Unified Approach for Multi-organ Segmentation in Body CT,"NEW & BREAKTHROUGH WORK

1) We directly compared two segmentation architectures used in prior work, namely 3D-UNet
    [4] and 3D DenseVNet [5] models on the XCAT [7] dataset. The better-performing 3D-UNet
    was picked for further analysis. 2) We trained the same architecture with the CT-ORG [9] dataset that was pseudo-labeled in a
    semi-supervised manner and the XCAT datasets and compared their segmentation
    comparison directly. ",eess.IV,C,-0.23396656,-0.17064744,0.2556833
http://arxiv.org/pdf/2203.01937v2,BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification,"ing) with a Ô¨Åxed mixup coefÔ¨Åcient of Œª = 0.6 (Ô¨Årst row
of Tab. 7), then we introduce y¬Ø with another Ô¨Åxed mixup             Limitations and future work. We identify three limi-
coefÔ¨Åcient of Œ≥ = 0.25 (second row of Tab. ",eess.IV,B,0.278045,0.2909216,-0.031343818
http://arxiv.org/pdf/2203.02042v1,Automatic Detection and Segmentation of Postoperative Cerebellar Damage Based on Normalization,"As
a result, its performance can not be improved by collecting more accurate labels
(manually edited masks). Our future work is to develop a deep learning based
model to further improve the performance by taking advantage of the inputs
from neuroradiologists. 5 Conclusions

In this paper, we present a fully automatic localization and measurement of post-
operative damage in the cerebellum in the atlas space using postoperative MRI. ",eess.IV,C,-0.27385333,-0.18797557,0.011130646
http://arxiv.org/pdf/2203.02048v1,Anomaly Detection-Inspired Few-Shot Medical Image Segmentation Through Self-Supervision With Supervoxels,"This is related to the nature of the supervoxels, which           volumes. We believe that fully exploiting the 3D nature of the
tend to follow the boundaries of the structures in the image;             medical images in this manner for few-shot segmentation rep-
Left-ventricle blood pool and left-ventricle myocardium will              resents an interesting line of research for future work. typically belong to diÔ¨Äerent supervoxels during training and
the network therefore learns to separate their feature representa-        Acknowledgements
tions into diÔ¨Äerent clusters. ",eess.IV,C,-0.1914132,-0.23356995,0.09168272
http://arxiv.org/pdf/2203.02166v1,Convolutional Analysis Operator Learning by End-To-End Training of Iterative Neural Networks,"cade of neural networks. In addition, in our method, the ex-
                                                                 act role of the regularizer is fully explainable and allows for
measure [17] (SSIM) and universal image quality index [18]       a theoretical analysis of the reconstruction algorithm which
(UIQ) which were calculated over a central squared ROI of        we leave for future work. Although we have presented the
160 √ó 160 pixels for all cardiac phases. ",eess.IV,A,0.10045413,-0.28340498,-0.100052066
http://arxiv.org/pdf/2203.02507v1,Parallel Fourier Ptychography reconstruction,"For instance, limited by the working
characteristic of GPU, it can only process one task each time, which means different subregions
are actually processed one by one, the processing speed is almost improved based on improving
the speed of FFT and iFFT. In the future work, multi-GPUs strategy can be implemented in
FPM reconstruction. The data can be prepared in CPU firstly, and then, different subregions‚Äô
data will be sent to different GPUs for data processing, thus, realizing parallel data processing. ",eess.IV,A,0.20223409,0.054707143,0.0061393455
http://arxiv.org/pdf/2203.02571v1,Improving the Energy Efficiency and Robustness of tinyML Computer Vision using Log-Gradient Input Images,"The quantization of CNN weights and activa-       three benefits. First, while the log ‚àá representation is not visually
        tions is not considered here and remains as future work. appealing, it should help in making the CNN classification more
                                                                        robust to global illumination changes. ",eess.IV,A,0.045417145,-0.042077545,0.27088833
http://arxiv.org/pdf/2203.02584v1,Virtual Histological Staining of Label-Free Total Absorption Photoacoustic Remote Sensing (TA-PARS),"This may potentially ease the
adoption of label-free tools since pathologists are trained to make diagnostic decisions on IHC stained
tissue samples. In addition, virtual staining allows limitless complementary IHC stains to be applied to the
same tissue sections, while concurrently preserving the unlabeled tissue for further analysis. In a clinical
setting this may substantially improve the diagnostic utility of small tissue specimens. ",eess.IV,C,-0.1852797,0.100697294,-0.19497235
http://arxiv.org/pdf/2203.02690v1,IDmUNet: A new image decomposition induced network for sparse feature segmentation,"Evaluation metrics, datasets and comparisons are given
in Section 6. Conclusions and future works are discussed in Section 7. 2. ",eess.IV,B_centroid,0.048424415,0.50193846,0.032824803
http://arxiv.org/pdf/2203.03622v1,Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement,"In table 3
and 4, it is evident that the performance is not hampered as even with low dice
score. Though in future work, it gives scope of improvement. Table 1: Comparison of diÔ¨Äerent models on infarct segmentation. ",eess.IV,B,0.0142607,0.35232675,-0.08552213
http://arxiv.org/pdf/2203.03622v3,Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement,"In table 3
and 4, it is evident that the performance is not hampered as even with low dice
score. Though in future work, it gives scope of improvement. Table 1: Comparison of diÔ¨Äerent models on infarct segmentation. ",eess.IV,B,0.0142607,0.35232675,-0.08552213
http://arxiv.org/pdf/2203.03638v1,Unsupervised Image Registration Towards Enhancing Performance and Explainability in Cardiac And Brain Image Analysis,"However, we
examined two organ areas (brain and heart), intra- and inter-modality registration, and investigated 2D, 3D
and 4D registrations frames. This has inspired our future work as we currently investigate model
generalisation frameworks, to allow further multi-organ and multi-modal applications. In conclusion, here we
show that our methodology demonstrated improved performance and efficiency against the current standard
Syn method thus, presenting a versatile image registration technique that may have merit in the clinical
setting. ",eess.IV,C,-0.13690545,-0.19220145,-0.08962078
http://arxiv.org/pdf/2203.03640v1,Conquering Data Variations in Resolution: A Slice-Aware Multi-Branch Decoder Network,"Besides, to further verify the effectiveness
framework demonstrates competitive computational complex-         of our proposed method in conquering data variations in
ity with the DeepLabV3+ [13] and H-DenseUNet [6] (Table I),       resolution, we plan to test our method on more organs/tumors
methodologies for more compact deep neural network designs        in other body parts and imaging modalities. (e.g., [39]) can be considered in future work. VI. ",eess.IV,C,-0.19338755,-0.14890717,0.052442912
http://arxiv.org/pdf/2203.04042v1,Learning to Erase the Bayer-Filter to See in the Dark,"Hence we train a model without amplifying the input       signals in each color channel, leading to those color arti-
raw images with the predeÔ¨Åned ratio. As a result, as shown      facts that commonly exist in both SoTA and ours methods
in Table 3, such a model can still achieve comparable per-      and require further study. formance, with only a slight decrease in PSNR and SSIM. ",eess.IV,A,0.260392,0.071968846,0.12341069
http://arxiv.org/pdf/2203.04042v2,Abandoning the Bayer-Filter to See in the Dark,"The dataset is
5. Limitations and future work                                collected in various scenes, and each colored raw image has
                                                              a corresponding monochrome raw image captured with the
   There are various aspects to improve in the future. The    same exposure settings. ",eess.IV,A,0.07787197,-0.0012624189,0.06643723
http://arxiv.org/pdf/2203.04290v1,Residual Aligner Network,"Applied to the segmentation of lungs in chest CT scans, the
         new network achieves results which were indistinguishable from the best-ranked
         networks (94%/3.0mm). Additionally, the theorem on predicted motion pattern
         and the design of MA structure are validated by further analysis. Keywords: Image alignment, Coarse-to-fine registration, Motion-Aware

1 Introduction

Alignment of two images, also known as image registration [23], is an important task in
computer vision applications. ",eess.IV,C,-0.14224455,-0.2444652,-0.080613084
http://arxiv.org/pdf/2203.04292v1,Towards performant and reliable undersampled MR reconstruction via diffusion model sampling,"The one-
time inference speed is comparable to UNet [16] at 20ms; however, DiÔ¨ÄuseRecon
performs 1000 inference steps. We note that 20s per slice still yields signiÔ¨Åcant
acceleration compared to raw acquisitions, and there exists much potential in
accelerating diÔ¨Äusion models [18,11] for future work. DiÔ¨ÄuseRecon can also be
used in conjunction with deterministic methods, e.g., when variance analysis is
needed only selectively, to balance speed to performance and reliability. ",eess.IV,B,0.28345188,0.30161178,0.13129531
http://arxiv.org/pdf/2203.04292v2,Towards performant and reliable undersampled MR reconstruction via diffusion model sampling,"The one-
time inference speed is comparable to UNet [16] at 20ms; however, DiÔ¨ÄuseRecon
performs 1000 inference steps. We note that 20s per slice still yields signiÔ¨Åcant
acceleration compared to raw acquisitions, and there exists much potential in
accelerating diÔ¨Äusion models [18,11] for future work. DiÔ¨ÄuseRecon can also be
used in conjunction with deterministic methods, e.g., when variance analysis is
needed only selectively, to balance speed to performance and reliability. ",eess.IV,B,0.28345188,0.30161178,0.13129531
http://arxiv.org/pdf/2203.04306v2,Diffusion Models for Medical Anomaly Detection,"It was shown that a simple method based on histogram equalization could
outperform neural networks and state that reconstruction quality does not cor-
relate well with the Dice score. As an alternative, anomaly scores of other types
of methods, i.e., the log-likelihood of density estimation models, will be explored
in future work. Hyperparameter Sensitivity Our method has two major hyperparameters,
the classiÔ¨Åer gradient scale s and the noise level L. We performed experiments to
evaluate the sensitivity of our method to changes of s and L. On the BRATS2020
dataset, we have pixel-wise ground truth labels, which enable us to calculate the
Dice score and the Area under the receiver operating statistics (AUROC) for
diseased slices. ",eess.IV,C,-0.10508354,0.047961988,0.057264186
http://arxiv.org/pdf/2203.04308v1,Breast cancer detection using artificial intelligence techniques: A systematic literature review,"So, this gives future
researchers an opportunity to use Attention to improve the accuracy of deep learning models. Recently researchers are focusing on the gene sequence data as it is a wide area and there is always room for further research
and results. There are several opportunities for future researchers to contribute by merging multiple gene sequencing datasets to predict
additional outcomes with larger dataset. ",eess.IV,C,-0.25900322,0.108421296,0.3110307
http://arxiv.org/pdf/2203.04614v1,Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification,"Our results also demonstrate the potential
of MIM for self-supervised pre-training in various medical image analyses. Our
Uni4Eye: UniÔ¨Åed 2D and 3D Ophthalmic Image Pre-training  9

future work will involve investigating the feasibility of our framework for other
types of medical images and exploring methods to further improve the eÔ¨Éciency
of our framework. 10  Cai et al. ",eess.IV,C,-0.22762474,-0.124953404,0.029569998
http://arxiv.org/pdf/2203.04614v2,Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification,"Our results also demonstrate the potential
of MIM for self-supervised pre-training in various medical image analyses. Our
Uni4Eye: UniÔ¨Åed 2D and 3D Ophthalmic Image Pre-training  9

future work will involve investigating the feasibility of our framework for other
types of medical images and exploring methods to further improve the eÔ¨Éciency
of our framework. 10  Cai et al. ",eess.IV,C,-0.22762474,-0.124953404,0.029569998
http://arxiv.org/pdf/2203.04752v2,Human Gaze Guided Attention for Surgical Activity Recognition,"second section of the paper, related studies are presented, in
the third section, details about the JIGSAWS, GTEA Gaze,             Inspired by the wide adoption of 3D CNNs and their out-
and GTEA Gaze+ datasets are shown, in the fourth section,         standing abilities in extracting both visual and temporal data
the proposed method is introduced, in the Ô¨Åfth section, exper-    from volumes of consecutive video frames, Ding et al. [20]
iments, implementation details, and results are discussed, in     proposed to use a two-stream network that jointly learns spatial
the sixth section, an analysis of the limitations and discussion  and temporal features from surgical videos for surgical phase
on future works are illustrated and in the seventh section, we    recognition. The proposed model, which is named a Two-
discuss the Ô¨Åndings of our study. ",eess.IV,C,-0.25449175,-0.16768336,0.23792906
http://arxiv.org/pdf/2203.04959v2,ModDrop++: A Dynamic Filter Network with Intra-subject Co-training for Multiple Sclerosis Lesion Segmentation with Missing Modalities,"One lim-
itation of our study is the dataset size, especially the ISBI dataset, where, even
though each subject has 4-5 time points, only 5 unique subjects are available. Validation in a larger cohort thus remains as future work. 5 Acknowledgements

This work was supported in part by the NIH grant R01-NS094456, in part by the
NIH and NIBIB grant T32EB021937, and by the Advanced Computing Center
for Research and Education (ACCRE) of Vanderbilt University. ",eess.IV,B,-0.11281601,0.46943843,-0.05297558
http://arxiv.org/pdf/2203.04961v1,Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification,"To further validate the beneÔ¨Åts of inter-centre generative model sharing, we recommend future work to test prediction
performance improvement on full mammograms apart from patches and on further datasets across (imaging and
non-imaging) modalities, organs, and standardised clinical tasks [18] with universal classiÔ¨Åcation objectives (e.g.,
benign/malignant apart from healthy/non-healthy classiÔ¨Åcation). We further propose future work to explore the effect of
initialisation of classiÔ¨Åcation models with pretrained weights alongside the effect of traditional preprocessing and data
augmentation techniques, such as histogram and intensity scale normalization techniques [11]. Apart from classiÔ¨Åcation,
validation on further downstream tasks such as object detection, semantic segmentation, and domain-adaptation can
reveal further insights into the advantages and limitations of generative model sharing. ",eess.IV,C_centroid,-0.3286329,-0.08328864,0.133209
http://arxiv.org/pdf/2203.04961v2,Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification,"To further validate the beneÔ¨Åts of inter-centre generative model sharing, we recommend future work to test prediction
performance improvement on full mammograms apart from patches and on further datasets across (imaging and
non-imaging) modalities, organs, and standardised clinical tasks [18] with universal classiÔ¨Åcation objectives (e.g.,
benign/malignant apart from healthy/non-healthy classiÔ¨Åcation). We further propose future work to explore the effect of
initialisation of classiÔ¨Åcation models with pretrained weights alongside the effect of traditional preprocessing and data
augmentation techniques, such as histogram and intensity scale normalization techniques [11]. Apart from classiÔ¨Åcation,
validation on further downstream tasks such as object detection, semantic segmentation, and domain-adaptation can
reveal further insights into the advantages and limitations of generative model sharing. ",eess.IV,C,-0.3286329,-0.08328864,0.133209
http://arxiv.org/pdf/2203.04962v1,Learning the Degradation Distribution for Blind Image Super-Resolution,"content-dependent. As we                         The second limitation is that the current version of PDM
have discussed in Sec 3.1, we assume that the blur ker-                does not consider the corruptions introduced by JPEG com-
nels are independent of the content of the image, the blur             pression, which will also inÔ¨Çuence the performance of SR.
kernels are generated only from randomly sampled vec-                  In future work, we may add an extra learnable JPEG com-
tors, i.e., k = netK(zk). To validate this assumption,                 pression module [33] in PDM, which could enable PDM to
two other experiments are performed: A) the blur kernels               simulate the JPEG corruptions. ",eess.IV,A,0.3330341,-0.10050463,0.028552258
http://arxiv.org/pdf/2203.05563v1,Artificial Intelligence Solution for Effective Treatment Planning for Glioblastoma Patients,"While 2D models performed better in training and validation, they suffered during testing. With
additional research, I determined that with 2D models, slices from the same study could be
present in both training and validation and consequently the model may achieve boosted training
and validation metrics. However, during field testing, such an advantage does not exist and
consequently 2D models suffered significantly during field testing. ",eess.IV,B,-0.012327252,0.15686452,-0.00042713666
http://arxiv.org/pdf/2203.05565v1,LiftReg: Limited Angle 2D/3D Deformable Registration,"This might not be true if we consider scat-
tering eÔ¨Äects, beam hardening, and veiling glare [15]. Interesting future work
would be to combine image translation with DRR generation to improve the
LiftReg: Limited Angle 2D/3D Deformable Registration  9

realism of DRRs with respect to real radiographs; to add support for dynamic
geometry where the emitter number N and emitter positions can vary; and to
explore more advanced statistical deformation models. Acknowledgements

Research reported in this publication was supported by the National Institutes
of Health (NIH) ) under award numbers NIH 1 R01 HL149877 and NIH 1 R01
EB028283. ",eess.IV,A,0.17195493,-0.11681713,-0.1923676
http://arxiv.org/pdf/2203.05567v1,Recovering medical images from CT film photos,"Then we propose a deep framework called Film
                                                   Image Recovery Network (FIReNet) to tackle geometric deformation
                                                   and illumination variation using the multiple maps extracted from the
                                                   CT Ô¨Ålms to collaboratively guide the recovery process. Finally, we con-
                                                   vert the dewarped images to DICOM Ô¨Åles with our cascade model for
                                                   further analysis such as radiomics feature extraction. Extensive experi-
                                                   ments demonstrate the superiority of our approach over the previous ap-
                                                   proaches. ",eess.IV,A,-0.067350835,-0.36208963,0.11332658
http://arxiv.org/pdf/2203.05569v1,Autofocusing+: Noise-Resilient Motion Correction in Magnetic Resonance Imaging,"Stemming from the baseline Autofocusing, and similarly to other optimization-
based methods, there is room to improve the inference time of Autofocusing+
which takes 7‚Äì9 minutes to process a batch of 10 images. Parallel computing and
the pertinent eÔ¨Écient acceleration of the gradients and the Fourier transforms
[27] should work well and will be the subject of future work. Likewise, the study
of diÔ¨Äerent neural network architectures should be conducted. ",eess.IV,A,0.10988511,-0.12736973,0.1737986
http://arxiv.org/pdf/2203.05573v1,Self Pre-training with Masked Autoencoders for Medical Image Analysis,"Together, these observations suggest that MAE can further improve
the already impressive performance of ViTs in medical imaging analysis tasks
including classiÔ¨Åcation and segmentation. In future work, we will test the eÔ¨Écacy
of MAE pretraining in prognosis and outcome prediction tasks [2]. References

 1. ",eess.IV,C,-0.21251473,0.07769443,-0.12382942
http://arxiv.org/pdf/2203.05784v1,AI-enabled Automatic Multimodal Fusion of Cone-Beam CT and Intraoral Scans for Intelligent 3D Tooth-Bone Reconstruction and Clinical Applications,"This brings the most mistakes
in the DDMA framework, i.e., both the jaw segmentation and registration method might
fail for 6% to 10% cases based on our statistics, implying manual correction is still
required for those complicated cases. We might design novel learning-based methods
in our future work for better jaw segmentation, 3D registration and fusion, such as
taking advantage of the z-values of CBCT slices for jaw segmentation or design novel
neural networks for 3D registration. Second, the segmentation performance for CBCT
can be further improved. ",eess.IV,C,-0.17851806,-0.12750904,0.018392678
http://arxiv.org/pdf/2203.05845v1,Flexible Amortized Variational Inference in qBOLD MRI,"Future work will consider integrating this approach with cerebral blood Ô¨Çow estimation from
arterial spin labelling data [Alsop et al., 2015], which will permit straightforward inference of the
cerebral metabolic rate of Oxygen [An et al., 2001]. Other directions of further research include
more principled ways to integrate spatial smoothness priors, and experimenting with diÔ¨Äerent com-
partment models to explain the data. Acknowledgments: We acknowledge funding from the University of Brighton Rising Stars
initiative and support from Brighton and Sussex Medical School. ",eess.IV,B,-0.068175435,0.050068375,-0.21015333
http://arxiv.org/pdf/2203.05845v2,Flexible Amortized Variational Inference in qBOLD MRI,"Future work will consider integrating this approach with cerebral blood Ô¨Çow estimation from
arterial spin labelling data [Alsop et al., 2015], which will permit straightforward inference of the
cerebral metabolic rate of Oxygen [An et al., 2001]. Other directions of further research include
more principled ways to integrate spatial smoothness priors, and experimenting with diÔ¨Äerent com-
partment models to explain the data. Acknowledgments: We acknowledge funding from the University of Brighton Rising Stars
initiative and support from Brighton and Sussex Medical School. ",eess.IV,B,-0.068175435,0.050068375,-0.21015333
http://arxiv.org/pdf/2203.05847v1,Automatic Fine-grained Glomerular Lesion Recognition in Kidney Pathology,"The proposed method provides a high-precision computational scheme
for fine-grained lesion identification of IgA nephropathy in whole slide images, which helps
pathologists make more objective and effective clinical diagnoses. For future work, it is of
note that the detected lesions are not specific for IgA nephropathy, and one of our future
research directions will be the transfer learning for the lesion‚Äôs detection to other
nephropathies with a similar presentation, e.g., lupus nephritis and diabetic nephropathy. 7. ",eess.IV,C,-0.21037626,-0.046349704,-0.13099357
http://arxiv.org/pdf/2203.05890v1,Video Coding for Machines with Feature-Based Rate-Distortion Optimization,"that differs from the Ô¨Ånal evaluation network in structure
and weights, indicates the universal applicability of FRDO. [13] Q. Wang, H. Yuan, J. Huo, and P. Li, ‚ÄúA Ô¨Ådelity-assured rate distortion
Nevertheless, it would be interesting in future work to create          optimization method for perceptual-based video coding,‚Äù in 2019 IEEE
the feature space for FRDO with the Ô¨Årst few layers of the              International Conference on Image Processing (ICIP), Aug. 2019, pp. evaluation network. ",eess.IV,A,0.27561152,-0.06894486,0.19344051
http://arxiv.org/pdf/2203.05927v1,On Intra Video Coding and In-loop Filtering for Neural Object Detection Networks,"5. Derived from the previous results, additional investigations
                                                                  are taken whether existing VVC tools are actually improving
    For object detection, the mAP does not signiÔ¨Åcantly de-       the mAP when coding for R-CNNs. To that extent, the inÔ¨Çu-
crease for input images compressed with a QP lower than 17        ence of the three VVC in-loop Ô¨Ålters on object detection is
compared to the uncompressed input data. ",eess.IV,A,0.11380657,-0.102642655,0.24645951
http://arxiv.org/pdf/2203.05968v1,Multi-Channel Convolutional Analysis Operator Learning for Dual-Energy CT Reconstruction,"Furthermore, MCAOL method can be exploited for other multimodal imaging
application such as PET/CT and PET/MRI. In the multimodal case, given the diÔ¨Äerent
intensity range on each channel, a further analysis on how to choose the NLL weights
Œ≥1 = Œ≥2 in (10) should be conducted to properly balancing the information coming from
the diÔ¨Äerent modalities. Finally, from a learning point of view, MCAOL training can be seen as a multi-
channel single layer unsupervised convolutional autoencoder (Chun & Fessler 2019,
Appendix A) which paves the way to extend this approach to deeper autoencoder
architectures to capture more complex features such as textures. ",eess.IV,A,-0.049133305,-0.28979102,0.059988283
http://arxiv.org/pdf/2203.06060v1,ROOD-MRI: Benchmarking the robustness of deep learning segmentation models to out-of-distribution and corrupted data in MRI,"4.6. Limitations and future work

    One of the main limitations of this work is regarding the degree to which the transforms and severity
levels included in our methodology cover the range of distribution shifts observed in practice from diÔ¨Äerent
sites and scanners. While we included a reasonably large set of transforms that we deemed most relevant
in practice from our experience, there could be other MRI transforms and corruptions that are relevant
and under-represented in our list. ",eess.IV,B,-0.03022528,-0.060354013,-0.31996936
http://arxiv.org/pdf/2203.06113v1,Detection of multiple retinal diseases in ultra-widefield fundus images using deep learning: data-driven identification of relevant regions,"This label allows the model to indicate that it is conÔ¨Ådent that a given image

is aÔ¨Äected by disease, whether it is conÔ¨Ådent in any disease in particular or not. Furthermore, this label is also

the most clinically relevant label if we want to decide if a patient needs to be referred to an ophthalmologist for

further examination. As our model, we use a convolutional neural network backbone which extracts a feature vector from an

image and a prediction head which maps this feature vector to the eight-dimensional output to which we then

apply element-wise sigmoid activations to obtain predicted probabilities for each label. ",eess.IV,C,-0.3582875,-0.0393635,0.16234896
http://arxiv.org/pdf/2203.06184v1,Semi-supervised classification of medical ultrasound images based on generative adversarial network,"Methods                               macc‚Üë iacc‚Üë

               DAGAN-based [6]        88.0%  14.0%
                  SSCE* (Ours)        97.9%  15.6%
                                      97.3%  15.6%
VGGNet + StyleGAN2-ADA + WD (Ours)    95.0%  21.6%
   MobileNet + StyleGAN2-ADA (Ours)   90.4%  21.4%

DenseNet + StyleGAN2-ADA + WD (Ours)

US images diagnoses. For future works, besides classiÔ¨Åcation, developing methods for segmentation, detection, and
other analysis tasks are necessary. Furthermore, proposing methods to analyze 3D medical US images is important. ",eess.IV,C,-0.21707696,-0.18829654,-0.09308238
http://arxiv.org/pdf/2203.06184v2,Semi-supervised classification of medical ultrasound images based on generative adversarial network,"With
the outstanding performance, We believe that our proposed state-of-the-art method can potentially be regarded as an
auxiliary tool for real-time medical US image diagnoses. For future works, besides classiÔ¨Åcation, developing methods for segmentation, detection, and other analysis tasks are
necessary. Furthermore, proposing methods to analyze 3D medical US images is also important. ",eess.IV,C,-0.23180875,-0.21113579,-0.18776363
http://arxiv.org/pdf/2203.06217v1,Medical Image Segmentation on MRI Images with Missing Modalities: A Review,"Radiopaedia.org (2005). and potential research direction for future work. https://doi.org/10.53347/rID-21760

   ACKNOWLEDGMENTS This work was funded by                         10. ",eess.IV,B,0.021594126,0.15767948,-0.1578998
http://arxiv.org/pdf/2203.06425v1,VAFO-Loss: VAscular Feature Optimised Loss Function for Retinal Artery/Vein Segmentation,"Feature optimised loss
function contributes to downstream clinical research, such as oculomics, and po-
tentially promotes the deployment of automated AI techniques in clinical ap-
plication. Further future work will evaluate VAFO-Loss on large-scale clinical
datasets and a wider range of disease diagnosis tasks. References

 1. ",eess.IV,C,-0.2694053,0.26547056,-0.086717725
http://arxiv.org/pdf/2203.06823v1,SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense Image Labels for Quantitative Clinical Evaluation,"bone, muscles), which are not densely annotated, but can help with
extracting other clinically-relevant biomarkers. In future work, we will look to curate data from a larger subject pool
and multi-vendor scanners and add annotations for these tissues. 8 Conclusion

In this work, we introduce SKM-TEA, a quantitative MRI knee dataset that enables clinically-relevant benchmarking of
the end-to-end MRI workÔ¨Çow. ",eess.IV,C,-0.27071673,0.100299194,-0.21535018
http://arxiv.org/pdf/2203.07114v1,WSSAMNet: Weakly Supervised Semantic Attentive Medical Image Registration Network,"We showed
the registration error between the follow-up scan (F) and the               the beneÔ¨Åt of training the network to give more attention to
preoperative scan (B) for a pair of scans (p) using the median              the regions around the landmarks in improving the robustness
absolute error of the landmarks, which is given by:                         and reducing the registration error. M AE = M edianl‚ààL(|xBl ‚àí xÀÜlB|)                            (6)      For future work, we are planning to test the performance
                                                                            of our proposed method on multi-modal image registration
where xBl , xFl are the coordinates of corresponding land-                  problems. marks of l ‚àà L the set of landmarks identiÔ¨Åed in both B and
F.                                                                                                  7. ",eess.IV,C,-0.038970277,-0.15166502,-0.052114174
http://arxiv.org/pdf/2203.07452v1,A deep learning pipeline for breast cancer ki-67 proliferation index scoring,"Future research
might extend the proposed approach to the automatic selection of regions of interest. Furthermore, future work will
focus on the evaluation of the proposed approach on different slides from different laboratories. Finally, while deep
learning approaches give good performance in DP, labeled data is required to train models; and we should mention that
a signiÔ¨Åcant factor in the development of more reliable and robust automated methods of DP image analysis will be
accelerated through the engagement of the community of expert pathologists in the process of deep learning models
development. ",eess.IV,C,-0.2553711,-0.11470383,0.19092622
http://arxiv.org/pdf/2203.07659v1,Breast Cancer Molecular Subtypes Prediction on Pathological Images with Discriminative Patch Selecting and Multi-Instance Learning,"The retrospective study design would have resulted in inevitable bias and all the data were collected
from a single center, thereby limiting the sample size of the study. In future work, we will combine
multi-center and multi-resolution information of pathological images to improve the accuracy and to
evaluate on larger datasets. 5 Conclusions

Molecular subtype prediction from H&E pathological slides is a challenging task. ",eess.IV,C,-0.34349203,0.11159915,-0.16860408
http://arxiv.org/pdf/2203.07677v1,Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning,"Extensive exper-
iments considerably show that the eÔ¨Äectiveness and scalability of our model. In
future work, we plan to explore the possibility of applying contrastive learning
for more complex factor disentangling problem in the the Ô¨Åeld of low-level vision. Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning  15

References

 1. ",eess.IV,A,0.09412022,-0.21811163,0.22800688
http://arxiv.org/pdf/2203.07677v2,Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning,"Extensive exper-
iments considerably show that the eÔ¨Äectiveness and scalability of our model. In
future work, we plan to explore the possibility of applying contrastive learning
for more complex factor disentangling problem in the the Ô¨Åeld of low-level vision. Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning  15

References

 1. ",eess.IV,A,0.09412022,-0.21811163,0.22800688
http://arxiv.org/pdf/2203.07707v1,Magnification Prior: A Self-Supervised Method for Learning Representations on Breast Cancer Histopathological Images,"Simple
                                                                  augmentations refer to one or more of the including rotation,
   5) Presents initial empirical support showing that reducing    Ô¨Çipping, cropping, shifting, and zooming. human prior leads to efÔ¨Åcient representation learning,
       which suggests promising further research                     Another learning paradigm to effectively counter earlier
                                                                  stated data scarcity challenges is self-supervised learning. 6) Empirical evidence on cross-magniÔ¨Åcation evaluation         It refers to methods that use pseudo-labels retrieved from
       to demonstrate magniÔ¨Åcation invariant representation       structural properties of data itself to learn representations. ",eess.IV,C,-0.1591773,-0.033158246,0.3259992
http://arxiv.org/pdf/2203.07809v1,Image Quality Assessment for Magnetic Resonance Imaging,"Towards
notated FastMRI dataset [26]. Another line of future work                                                                                                          Ultrafast MRI via Extreme k-Space Undersampling and Superresolution. could be ‚Äòborrowed‚Äô from the NI domain, where the abundance                                                                                                        In MICCAI 2021, pages 254‚Äì264, Cham, 2021.
of data has led to the emergence of several NR IQMs. ",eess.IV,B,0.035039432,-0.07395424,-0.25790337
http://arxiv.org/pdf/2203.07809v2,Image Quality Assessment for Magnetic Resonance Imaging,"(2021). Another
line of future work could be ‚Äòborrowed‚Äô from the NI domain,                     Allen, E., Triantaphillidou, S., Jacobson, R., 2007. Image quality of jpeg vs jpeg
where the abundance of data has led to the emergence of sev-                       2000 image compression schemes, part 1: Psychophysical measurements. ",eess.IV,A,0.2833389,-0.10994183,0.0017335312
http://arxiv.org/pdf/2203.07904v1,Unsupervised Learning Based Focal Stack Camera Depth Estimation,"We
additionally evaluated our proposed method‚Äôs performance using ground-truth all-in-focus images (row 3), instead
of those estimated from the Laplacian operator. It shows that a better all-in-focus image estimation could further
improve the depth accuracy, which is left as a future work. Figure 2. ",eess.IV,A,0.19941635,-0.24670851,0.072142415
http://arxiv.org/pdf/2203.07904v2,Unsupervised Learning Based Focal Stack Camera Depth Estimation,"We
additionally evaluated our proposed method‚Äôs performance using ground-truth all-in-focus images (row 3), instead
of those estimated from the Laplacian operator. It shows that a better all-in-focus image estimation could further
improve the depth accuracy, which is left as a future work. Figure 2. ",eess.IV,A,0.19941635,-0.24670851,0.072142415
http://arxiv.org/pdf/2203.08213v1,HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction,"We demonstrate the performance of our proposed method on two other MRI datasets and perform Ô¨Åne-grained
ablation studies to motivate our design choices and emphasize the compute and memory challenges of Transformer-
based architectures on low-level and dense computer vision tasks such as MRI reconstruction. This work opens the
door for the adoption of a multitude of promising techniques introduced recently in the literature for Transformers in
high-level vision tasks, which we leave for future work. References

Shaojie Bai, J Zico Kolter, and Vladlen Koltun. ",eess.IV,A,0.026472632,-0.33938342,-0.17193145
http://arxiv.org/pdf/2203.08812v1,Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography,": Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography  9

of concept that improvements in patch classification using                       [16] K. He, X. Chen, S. Xie et al., ‚ÄúMasked Autoencoders Are Scalable
unannotated data can substantially improve the performance of                          Vision Learners,‚Äù 2021/11//, 2021.
deep learning algorithms for the detection of breast cancer on
screening mammography. In future work, we will examine                           [17] J. Zbontar, L. Jing, I. Misra et al., ‚ÄúBarlow Twins: Self-Supervised
extending our SSL method to digital breast tomosynthesis,                              Learning via Redundancy Reduction,‚Äù 2021/3//, 2021.
which is rapidly increasing in use in the U.S.
                                                                                 [18] T. Chen, S. Kornblith, M. Norouzi et al., ‚ÄúA Simple Framework for
                       ACKNOWLEDGEMENTS                                                Contrastive Learning of Visual Representations,‚Äù arXiv:2002.05709 [cs,
                                                                                       stat], 2020/06/30/, 2020. This study was supported by grants from the National
Institutes of Health (R01CA264987, R01CA237541) and by                           [19] X. Chen, H. Fan, R. Girshick et al., ‚ÄúImproved Baselines with
the computational resources and staff expertise provided                               Momentum Contrastive Learning,‚Äù arXiv:2003.04297 [cs], 2020/03/09/,
by Scientific Computing at the Icahn School of Medicine at                             2020. ",eess.IV,C,-0.33357888,-0.1101227,0.18132526
http://arxiv.org/pdf/2203.08898v1,Neural network processing of holographic images,"For this reason, we are investigating less labor intensive methods for creating realistic
synthetic holograms. What can be done in future work? First, a one-step approach for predicting particle coordinates and their shapes using only
the reference hologram would provide the greatest beneÔ¨Åt in terms of processing speed. ",eess.IV,A,0.19738445,-0.08798338,0.00911665
http://arxiv.org/pdf/2203.08898v2,Neural network processing of holographic images,"For this reason, we are investigating less labor intensive methods for creating realistic
synthetic holograms. What can be done in future work? First, a one-step approach for predicting particle coordinates and their shapes using only
the reference hologram would provide the greatest beneÔ¨Åt in terms of processing speed. ",eess.IV,A,0.19738445,-0.08798338,0.00911665
http://arxiv.org/pdf/2203.08914v1,Automated Grading of Radiographic Knee Osteoarthritis Severity Combined with Joint Space Narrowing,"Thorough evaluation with
three datasets and a comparison to the performance of multiple experienced readers showed that our algorithm performs
at the level of radiologists. Our software has been made publicly available and easy to use for further research. 13
                    arXiv Template                                             A PREPRINT

References

Osteoarthritis (OA) | Arthritis | CDC. ",eess.IV,C,-0.19860616,0.19794719,-0.23675933
http://arxiv.org/pdf/2203.08914v2,Knee arthritis severity measurement using deep learning: a publicly available algorithm with a multi-institutional validation showing radiologist-level performance,"Thorough
evaluation with three datasets and a comparison to the performance of multiple experienced readers showed that our
algorithm performs at the level of radiologists. Our software has been made publicly available and easy to use for
further research. References

Osteoarthritis (OA) | Arthritis | CDC. ",eess.IV,C,-0.22683674,0.22870703,-0.27412766
http://arxiv.org/pdf/2203.08965v1,3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation,"Best view in zoom. Rotation invariance: To further study rotation equivariance and invariance
properties in our 3D-UCaps, we trained our network without any rotation data
augmentation. During testing, we choose an axis to rotate the volume, and apply
the rotation with angle values Ô¨Åxed to 5, 10, 15, .., 90 degrees. ",eess.IV,A,0.063781895,-0.11155604,0.116993174
http://arxiv.org/pdf/2203.09180v1,A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled Image Data Using Locally Fully Connected Layers,"We furthermore         VDSR     Very Deep Super-Resolution Network [14]
evaluate and discuss the results and provide visual examples. LFCR     Locally Fully Connected Reconstruction (ours)
In Section V, we summarize the paper and give an outlook on
future work. Fig. ",eess.IV,A,0.17189857,-0.24931559,0.119105
http://arxiv.org/pdf/2203.09180v2,A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled Image Data Using Locally Fully Connected Layers,"We furthermore         VDSR     Very Deep Super-Resolution Network [14]
evaluate and discuss the results and provide visual examples. LFCR     Locally Fully Connected Reconstruction (ours)
In Section V, we summarize the paper and give an outlook on
future work. Fig. ",eess.IV,A,0.17189857,-0.24931559,0.119105
http://arxiv.org/pdf/2203.09207v1,Simulation-Driven Training of Vision Transformers Enabling Metal Segmentation in X-Ray Images,"A limitation of this study is the reduction to the knee area as anatomical
background. This could be generalized to the whole body in future work to make
the network more robust. Another direction of research could be the fusion of
simulated metal with real high resolution X-ray images instead of using synthetic
images generated from CT volumes. ",eess.IV,C,-0.1339274,-0.16195688,-0.22123235
http://arxiv.org/pdf/2203.09268v1,Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI,"table 2. In future work, we could add an additional cost function to address the cost
of obtaining speciÔ¨Åc combination of measurements from sets of MRI acquisition
parameters; and develop a novel NAS algorithm to account for the concurrence of
the subsampling process and architecture optimization. Our approach extends to
many other quantitative MRI applications e.g. ",eess.IV,B,0.14009708,-0.07281924,-0.37935543
http://arxiv.org/pdf/2203.09268v2,Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI,"table 2. In future work, we could add an additional cost function to address the cost
of obtaining speciÔ¨Åc combination of measurements from sets of MRI acquisition
parameters; and develop a novel NAS algorithm to account for the concurrence of
the subsampling process and architecture optimization. Our approach extends to
many other quantitative MRI applications e.g. ",eess.IV,B,0.14009708,-0.07281924,-0.37935543
http://arxiv.org/pdf/2203.09268v3,Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI,"FA 0.006 - 0.004. Progressive Subsampling for Oversampled Data - Application to qMRI  9

5 Future Work

In future work, we could add an additional cost function to address the cost of
obtaining speciÔ¨Åc combination of measurements from sets of MRI acquisition
parameters; and develop a novel NAS algorithm to account for the concurrence
of the subsampling process and architecture optimization. Our approach extends
to many other quantitative MRI applicationse.g. ",eess.IV,B,0.15902007,-0.04855417,-0.36036038
http://arxiv.org/pdf/2203.09268v4,Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI,"FA: 0.006 - 0.004, on NODDI
parametric maps [33]: 0.022 - 0.007 FICVF, 0.023 - 0.005 FISO, 0.020 - 0.013 ODI. Progressive Subsampling for Oversampled Data - Application to qMRI  9

5 Future Work

In future work, we could add an additional cost function to address the cost of
obtaining speciÔ¨Åc combination of measurements from sets of MRI acquisition
parameters; and develop a novel NAS algorithm to account for the concurrence
of the subsampling process and architecture optimization. Our approach extends
to many other quantitative MRI applicationse.g. ",eess.IV,B,0.13787262,-0.10894588,-0.3994584
http://arxiv.org/pdf/2203.09268v5,Progressive Subsampling for Oversampled Data - Application to Quantitative MRI,"FA: 0.006 - 0.004, on NODDI
parametric maps [33]: 0.022 - 0.007 FICVF, 0.023 - 0.005 FISO, 0.020 - 0.013 ODI. Progressive Subsampling for Oversampled Data - Application to qMRI  9

5 Future Work

In future work, we could add an additional cost function to address the cost of
obtaining speciÔ¨Åc combination of measurements from sets of MRI acquisition
parameters; and develop a novel NAS algorithm to account for the concurrence
of the subsampling process and architecture optimization. Our approach extends
to many other quantitative MRI applicationse.g. ",eess.IV,B,0.13787262,-0.10894588,-0.3994584
http://arxiv.org/pdf/2203.09372v1,Using the Order of Tomographic Slices as a Prior for Neural Networks Pre-Training,"We also discuss important practical questions related to the proposed method. Finally, we conclude on our contribution and possible further research. 2 Related Work

In the last years there is a growing interest in self-supervised learning (SSL). ",eess.IV,B,-0.046435043,0.27392378,0.1340296
http://arxiv.org/pdf/2203.10091v1,Label conditioned segmentation,"For instance,
there might be better representations for the conditioned label and better ways to present
it as an input to the model. Also, we are interested in further studying the limits of the
generalization of LCS to previously unseen labels. 8
                                        Label conditioned segmentation

References

Mugahed A Al-Antari, Mohammed A Al-Masni, Mun-Taek Choi, Seung-Moo Han, and
   Tae-Seong Kim. ",eess.IV,C,-0.10391507,0.2157233,0.14623117
http://arxiv.org/pdf/2203.10417v3,Attri-VAE: attribute-based interpretable representations of medical images with variational autoencoders,"However, it is
worth noting that we did not evaluate the eÔ¨Äect of the size       The generated gradient-based attention maps con-
of the latent space and the position of regularized dimen-     tributed to locally identifying the cardiac regions where
sions. Therefore, future work is needed to analyze the size    the attributes were inÔ¨Çuencing, which was particularly
of the latent space and the importance of the position of      useful for global attributes and for complex features such
regularized dimensions by, for example, randomly replac-       as the texture ones. Additionally, we only employed the
ing them during inference. ",eess.IV,C,-0.18534276,0.046849065,0.09674683
http://arxiv.org/pdf/2203.10507v1,Soft-CP: A Credible and Effective Data Augmentation for Semantic Segmentation of Medical Lesions,"DSC  0.5
                                                              Moreover, offline data augmentation is a controllable
     0.4                                                   method to synthesize the images we need. In future works,
                                                           we will also try to use it in lesion detection and
     0.3                                                   classification tasks. 0.2

          0     0.2          0.4  0.6  0.8       1

                FRACTIONS OF KITS19 DATASET

Figure 6. ",eess.IV,C,-0.105490215,-0.11998288,-0.017413316
http://arxiv.org/pdf/2203.10596v1,Towards Clinical Practice: Design and Implementation of Convolutional Neural Network-Based Assistive Diagnosis System for COVID-19 Case Detection from Chest X-Ray Images,"2013) Shown baseline classiÔ¨Åer is deÔ¨Åned
as a classiÔ¨Åer that cannot distinguish between classes and would predict a random class or a
same class in all cases. (Brownlee 2018)

                                       6 Conclusion and future work

In many of the previous studies analyzed, it has been shown that having suÔ¨Écient clinically
annotated data is essential for training more complex CADe applications. (Lebre et al. ",eess.IV,C,-0.31197828,0.39355266,0.036307763
http://arxiv.org/pdf/2203.10645v1,Breast Cancer Induced Bone Osteolysis Prediction Using Temporal Variational Auto-Encoders,"In summary, our model sometimes cannot predict the lesion
in a very accurate way when the lesion occurs in the fourth week but there is no lesion in the Ô¨Årst
three weeks. We will address these challenging cases in our future work. 8
3 Discussion

In this study, we showed that bone lesions can be reasonably predicted and visualized by utilizing
deep learning models. ",eess.IV,C,-0.38098055,-0.083308876,0.05158251
http://arxiv.org/pdf/2203.10645v2,Breast Cancer Induced Bone Osteolysis Prediction Using Temporal Variational Auto-Encoders,"In summary, our model sometimes cannot predict the lesion
in a very accurate way when the lesion occurs in the fourth week but there is no lesion in the Ô¨Årst
three weeks. We will address these challenging cases in our future work. 8
3 Discussion

In this study, we showed that bone lesions can be reasonably predicted and visualized by utilizing
deep learning models. ",eess.IV,C,-0.38098055,-0.083308876,0.05158251
http://arxiv.org/pdf/2203.10667v1,A direct geometry processing cartilage generation method using segmented bone models from datasets with poor cartilage visibility,"In
contrast, other joints, such as the knee joint, are challenging. We leave other
joint types for future work. (a)                          (b)                          (c)

Fig. ",eess.IV,B,-0.03532152,0.2481766,-0.14487234
http://arxiv.org/pdf/2203.10773v1,Slice Imputation: Intermediate Slice Interpolation for Anisotropic 3D Medical Image Segmentation,"37,
directions. Domain adaptation can be used in our future work            no. 12, pp. ",eess.IV,B,0.049138803,0.21459615,0.18121344
http://arxiv.org/pdf/2203.11206v1,Phase Recognition in Contrast-Enhanced CT Scans based on Deep Learning and Random Sampling,"Future works
Multi-phase Recognition in CT Scans  page 11

predict images with clearer features. In addition, due to the performance drop in ‚ÄúOthers‚Äù,
future work includes applying techniques for reducing the impact of imbalanced data. For
example, weighted BCE losses32, which directly penalized the probabilistic false positives,
can be used. ",eess.IV,C,-0.1686461,-0.057957895,-0.07752329
http://arxiv.org/pdf/2203.11213v1,ME-Net: Multi-Encoder Net Framework for Brain Tumor Segmentation,"Andriy conducted experiments on the 2018 BraTS
dataset and found some data enhancement methods that can improve accuracy, namely by
applying random intensity offset and scaling and randomly flipping pictures on the input
channel (Andriy Myronenko, 2019). In future work, we should combine previous studies to
explore the impact of data enhancement on accuracy. 6. ",eess.IV,A,0.15886243,0.044971596,0.11339159
http://arxiv.org/pdf/2203.11692v3,Panoptic segmentation with highly imbalanced semantic labels,"abs/1905.11946, 2019.
dentifying rare cell types, segmenting even in densely clustered
regions and robust to stain and image quality variations. While   [11] Q. Xie, E. H. Hovy, M.-T. Luong, and Q. V. Le, ‚ÄúSelf-training with noisy
promising, future work should further expand data sources,              student improves imagenet classiÔ¨Åcation,‚Äù 2020 IEEE/CVF Conference
differentiate between more cell types and include more tissue           on Computer Vision and Pattern Recognition (CVPR), pp. 10 684‚Äì
variations. ",eess.IV,C,-0.21733342,-0.09932324,0.09882524
http://arxiv.org/pdf/2203.11692v4,Panoptic segmentation with highly imbalanced semantic labels,"10 684‚Äì
regions and robust to stain and image quality variations. While         10 695, 2020.
promising, future work should further expand data sources,
differentiate between more cell types and include more tissue     [11] O. Ronneberger, P. Fischer, and T. Brox, ‚ÄúU-net: Convolutional networks
variations. It may also be worth investigating the same issue           for biomedical image segmentation,‚Äù in MICCAI, 2015.
on higher resolution images to differentiate some cell types
as intra-nucleus hematoxylin pattern could be more easily         [12] A. C. Ruifrok and D. A. Johnston, ‚ÄúQuantiÔ¨Åcation of histochemical
distinguishable. ",eess.IV,C,-0.21446437,-0.17054528,-0.056247484
http://arxiv.org/pdf/2203.11722v1,Convolutional Neural Network to Restore Low-Dose Digital Breast Tomosynthesis Projections in a Variance Stabilization Domain,"In common training strategies, local patches are extracted from      cludes the work, states the limitations on the work and shows
the image and feeded in the network. This makes it hard for the      future works. network to know the spatial noise dependencies existing in the
mammography image. ",eess.IV,C,-0.16157451,-0.13612628,-0.020316578
http://arxiv.org/pdf/2203.11943v1,A Quantitative Comparison between Shannon and Tsallis Havrda Charvat Entropies Applied to Cancer Outcome Prediction,"This makes the Tsallis‚ÄìHavrda‚ÄìCharvat formula the best candidate for further
                       research on these datasets. For further research we might adapt Tsallis‚ÄìHavrda‚ÄìCharvat
                       binary cross-entropy to a categorical cross-entropy. This would allow for making multi-class
                       predictions, including estimating the time between the end of cancer treatment and recurrence. ",eess.IV,B,-0.134179,0.4119302,-0.073513456
http://arxiv.org/pdf/2203.12151v1,Semi-Supervised Hybrid Spine Network for Segmentation of Spine MR Images,"Moreover, a robust spine segmentation
framework is proposed in this study, where SE-ResNext50 is used as the backbone. Some other advanced network structures, such as Swin Transformer [28], can be in-
troduced to the proposed method in future work to potentially extract rich image
features and achieve excellent spine segmentation results. References

 [1] A. Neubert, J. Fripp, C. Engstrom, R. Schwarz, L. Lauer, O. Salvado, and
      S. Crozier, ‚ÄúAutomated detection, 3D segmentation and analysis of high resolu-
      tion spine MR images using statistical shape models,‚Äù Physics in Medicine and
      Biology, vol. ",eess.IV,C,-0.19586997,-0.19288889,-0.19447967
http://arxiv.org/pdf/2203.12197v1,Biceph-Net: A robust and lightweight framework for the diagnosis of Alzheimer's disease using 2D-MRI scans and deep similarity learning,"We keep further exploration on this as
baseline methods for the Axial and Coronal planes. It also       future work. performs almost as good as much more computationally inten-
sive baseline methods as it makes one extra misclassiÔ¨Åcation        We further perform a paired t-test on the classiÔ¨Åcation
than the baseline methods. ",eess.IV,B,0.095077425,0.16800836,-0.1305931
http://arxiv.org/pdf/2203.12476v1,Adaptively Re-weighting Multi-Loss Untrained Transformer for Sparse-View Cone-Beam CT Reconstruction,"On the other hand, our approach
can potentially extend to other tomographic imaging modalities, resulting in
speeding up the acquisition, reducing radiation exposure, and increasing the
patient throughput. In future work, we will evaluate the clinical viability of our
approach for CBCT imaging. Multi-Loss Untrained Transformer  9

Acknowledgements

This work was supported in part by Research Initiation Project of Zhejiang Lab
(No. ",eess.IV,A,-0.012737838,-0.23092681,-0.23804069
http://arxiv.org/pdf/2203.13856v1,Which Generative Adversarial Network Yields High-Quality Synthetic Medical Images: Investigation Using AMD Image Datasets,"The resultant images were submitted to a three-level manual quality
grading: ‚ÄúGood‚Äô, ‚ÄúUsable‚Äô and ‚ÄúReject‚Äô. Only those images graded with ‚ÄúGood"" and ‚ÄúUsable"" scores were used for
further analysis. As a result, the number of images positive to AMD decreased from 89 to 74, 280 to 227, and 100
to 79 images in the iChallenge-AMD, ODIR-2019, and RIADD datasets, respectively while the number of non-AMD
images decreased from 311 to 290, 6, 720 to 4, 993, and 1, 820 to 1, 143 images concerning the iChallenge-AMD,
ODIR-2019, and RIADD datasets, respectively. ",eess.IV,A,0.1790399,0.04938444,-0.13665701
http://arxiv.org/pdf/2203.13949v1,Ultrafast Ultrasound Imaging for 3D Shear Wave Absolute Vibro-Elastography,"Section 4 discusses
(Sonic Incytes). MRE has greater accuracy compared to the           some of the limitations in experiments and possible future work. other methods[43], however it is more expensive and time con-       Finally, our conclusions are presented in Section 5.
suming. ",eess.IV,B,0.19815186,0.26548928,-0.22753736
http://arxiv.org/pdf/2203.14258v1,Image quality assessment for machine learning tasks using meta-reinforcement learning,"If each MDP environment is deÔ¨Åned as Mk,

the joint image-label distribution and task predictor within the

environment can be deÔ¨Åned as PXY,k and fk(¬∑; wk), respectively. B

However, in further analysis, we omit k from these expressions,                                                  log œÄŒ∏(at|st) = h(xi,t; Œ∏)ai,t + (1 ‚àí h(xi,t; Œ∏)(1 ‚àí ai,t)) (12)

for notational convenience. i=1

2.2.2. ",eess.IV,B,0.1298061,0.11836853,0.046760768
http://arxiv.org/pdf/2203.14291v1,Video Polyp Segmentation: A Deep Learning Perspective,"Intuitively, we aim to build the pixel-                                           pathological category. Currently, we focus on the positive
                                                                                                     cases in our SUN-SEG dataset and left negative (no polyp)
wise similarities between the anchor and high-level short-term                                       cases as our future work. features, which could be viewed as the modeling of global                                               2) Training Details: We train our model using the SUN-
                                                                                                     SEG-Train dataset on the platform equipped with an Intel
spatial-temporal dependencies. ",eess.IV,C,-0.13536459,0.08670064,0.28861636
http://arxiv.org/pdf/2203.14291v2,Video Polyp Segmentation: A Deep Learning Perspective,"For a fair comparison, all the com-
                                                      petitors utilize the same dataset as our PNS+ and
We train our model using the SUN-SEG-Train            reach the convergence under their default training
dataset on the server platform equipped with          settings. Of note, this paper only focuses on the
an Intel Xeon (R) CPU E5-2690v4√ó24 and four           positive cases in our SUN-SEG dataset and left
NVIDIA Tesla V100 GPUs with 16 GB mem-                negative cases (no polyp) for future work. ory per one. ",eess.IV,B,0.2617327,0.26285422,0.18915555
http://arxiv.org/pdf/2203.14291v3,Video Polyp Segmentation: A Deep Learning Perspective,"Of note, this paper only focuses on the
takes about 5 hours to reach convergence after 15              positive cases in our SUN-SEG dataset and left
epochs. For each mini-batch of data, we select the             negative cases (no polyp) for future work. Ô¨Årst frame of a video clip as an anchor, randomly
sample Ô¨Åve consecutive frames (‚àÜ=5) from the                   5.1.2 Evaluation Metrics
same clip, and resize them to 256√ó448. ",eess.IV,A,0.2668109,0.10816148,0.21012843
http://arxiv.org/pdf/2203.14341v1,MFSNet: A Multi Focus Segmentation Network for Skin Lesion Segmentation,"Each pixel in an image is classiÔ¨Åed as part of the object class or background
class. This is beneÔ¨Åcial for localizing the region of interest (ROI) from the raw
images for further analysis and thus is a vital preprocessing step in automated
disease diagnosis. Figure 1(a) shows an example of a raw skin-lesion image. ",eess.IV,C,-0.2484757,-0.11930957,-0.024338339
http://arxiv.org/pdf/2203.14341v2,MFSNet: A Multi Focus Segmentation Network for Skin Lesion Segmentation,"Each pixel in an image is classiÔ¨Åed as part of the object class or background
class. This is beneÔ¨Åcial for localizing the region of interest (ROI) from the raw
images for further analysis and thus is a vital preprocessing step in automated
disease diagnosis. Figure 1(a) shows an example of a raw skin-lesion image. ",eess.IV,C,-0.2484757,-0.11930957,-0.024338339
http://arxiv.org/pdf/2203.14482v1,Leveraging Clinically Relevant Biometric Constraints To Supervise A Deep Learning Model For The Accurate Caliper Placement To Obtain Sonographic Measurements Of The Fetal Brain,"The problem of identifying the standard TV and
and 0.88 ¬± 0.59 mm, respectively. The intra-class correlation     TC planes will be studied in future works to ease the clinical
coefÔ¨Åcients (ICC) values of the DL measurements with the          translation of the proposed framework. clinicians‚Äô measurements were calculated based on two-way
random, absolute agreement, and average rater policy. ",eess.IV,B,0.025592554,0.21897022,-0.33782953
http://arxiv.org/pdf/2203.14482v2,Leveraging Clinically Relevant Biometric Constraints To Supervise A Deep Learning Model For The Accurate Caliper Placement To Obtain Sonographic Measurements Of The Fetal Brain,"The problem of identifying the standard TV and               Series Title: Lecture Notes in Computer Science. TC planes will be studied in future works to ease the clinical
translation of the proposed framework. [7] Runnan Chen, Yuexin Ma, Nenglun Chen, Daniel
                                                                      Lee, and Wenping Wang, ‚ÄúCephalometric Landmark
                6. ",eess.IV,B,-0.0463139,0.13825715,-0.06334446
http://arxiv.org/pdf/2203.14616v1,Adaptation to CT Reconstruction Kernels by Enforcing Cross-domain Feature Maps Consistency,"Therefore, we could train F-Consistency on the pairs of original and
augmented with FBPAug images to achieve even better results. We leave the
latter idea for future work. 6.1. ",eess.IV,A,0.16013998,-0.087861985,0.14247972
http://arxiv.org/pdf/2203.15163v2,CAT-Net: A Cross-Slice Attention Transformer Model for Prostate Zonal Segmentation in MRI,"8, pp. 151 817‚Äì151 828, 2020.
how to make it more memory efÔ¨Åcient would be interesting
directions for future works. [9] Y. Liu, G. Yang, S. A. Mirak, M. Hosseiny, A. Azadikhah, X. Zhong,
                                                                                       R. E. Reiter, Y. Lee, S. S. Raman, and K. Sung, ‚ÄúAutomatic prostate
                        VI. ",eess.IV,B,-0.051525608,0.20446385,-0.050186753
http://arxiv.org/pdf/2203.15383v1,Category Guided Attention Network for Brain Tumor Segmentation in MRI,"This work may consider dataset with larger number of categories
and conduct more detailed intra-class update experiments. The future work can also
include sensitivity analysis on the number of categories. In addition, this work may
consider more datasets such as the decathlon challenge to verify the generalization of
the method. ",eess.IV,B,-0.052503463,0.4204278,0.16692485
http://arxiv.org/pdf/2203.15434v1,Clean Implicit 3D Structure from Noisy 2D STEM Images,"G.1. WBP
We leave the investigation of these factors for future work. We investigate the influence of denoising the micro-
E. Defocus                                                                                                                                                        graphs before applying WBP for reconstruction. ",eess.IV,A,0.17177674,-0.057334516,-0.19487509
http://arxiv.org/pdf/2203.15598v1,Angular Super-Resolution in Diffusion MRI with a 3D Recurrent Convolutional Autoencoder,"When expanding this model, the eÔ¨Äect of the subsam-
pling ratio on multi-shell inference should be explored. Additionally, future work should
investigate the eÔ¨Äect of angular super-resolution on downstream single-shell and multi-shell
analyses that require high angular resolutions. Acknowledgments

This work was conducted at the Univeristy of SheÔ¨Éeld whilst authors Matthew Lyon and
Mauricio A A¬¥ lvarez were aÔ¨Éliated with the organisation. ",eess.IV,B,0.28663397,0.04243678,-0.20135161
http://arxiv.org/pdf/2203.16357v1,Practical Learned Lossless JPEG Recompression with Multi-Level Cross-Channel Entropy Model in the DCT Domain,"As       less recompression of JPEG images. For future work, we
                                                                 will explore the generalizability on very high quality levels. References                                                                 replacement for huffman coding. ",eess.IV,A,0.2961483,-0.13217954,0.1778976
http://arxiv.org/pdf/2203.16392v1,On learning adaptive acquisition policies for undersampled multi-coil MRI reconstruction,"In the E2E VarNet, sensitivity maps are estimated independently per slice, and this
may enable a form of adaptivity beyond the mask selection that we have explored here. However, the interaction between the sensitivity maps and the acquisition policies requires
further investigation and is left as future work (see Appendix B). We display some learned
sensitivity maps for all models in Appendix D.2.3. ",eess.IV,B,0.096604206,0.2276696,0.15475275
http://arxiv.org/pdf/2203.16398v1,Incorporating Gradient Similarity for Robust Time Delay Estimation in Ultrasound Elastography,"noise statistics as a reference to re-estimate the displacement
Ô¨Åeld with an adaptive distribution of regularization parameter                                 V. CONCLUSION
values. However, this framework aiming at maintaining a                A robust regularized optimization-based TDE scheme called
proper balance between motion continuity and discontinuity is       rGLUE for quasi-static ultrasound elastography has been
beyond the scope of this work and calls for further research. proposed. ",eess.IV,B,0.10105421,-0.067941666,-0.30699676
http://arxiv.org/pdf/2203.16557v1,COSMOS: Cross-Modality Unsupervised Domain Adaptation for 3D Medical Image Segmentation based on Target-aware Domain Translation and Iterative Self-Training,"We will develop COSMOS as
place in the Ô¨Årst Cross-Modality Domain Adaptation (cross-      a generalizable methodology in unsupervised medical seg-
MoDA) challenge [6] which aims to perform segmentation          mentation tasks by extending COSMOS to various medical
of VS and cochlea on hrT2 MR scans via UDA. Results             datasets through future work. of ours and three top-ranked methods [2, 4, 16] in the chal-
lenge are provided in Fig. ",eess.IV,C,-0.2170366,0.004612578,-0.10108822
http://arxiv.org/pdf/2203.16996v1,Measuring hand use in the home after cervical spinal cord injury using egocentric video,"The correlations with UEMS and GRASSP scores demonstrated that the
percentage of interaction time and number of functional interactions per hour may provide
important information on how UE motor functions translate into an increased UE usage
in daily life. This is an important finding towards proposing novel outcome measures of
hand function able to measure performance in addition to capacity according to the
terminology of the International Classification of Functioning, Disability and Health.12

4.3 Limitations and future work
Although we used the hand-object contact state for inferring functional interactions, its
meaning only approximates functional hand-object interactions and further reasoning will
be required to accurately predict the functional use of the hands from video-data. As an
example, we will explore the use of action and activity recognition algorithms30,31 not only
to detect the presence of interactions, but also to understand which actions require more
intervention during rehabilitation. ",eess.IV,B,-0.078731254,0.34362805,-0.0040289676
http://arxiv.org/pdf/2203.16996v2,Measuring hand use in the home after cervical spinal cord injury using egocentric video,"14
                                                                                      Measuring hand use in tetraplegia

         The correlations with UEMS and GRASSP scores demonstrated that the
percentage of interaction time and number of functional interactions per hour may provide
important information on how UE motor functions translate into an increased UE usage
in daily life. This is an important finding towards proposing novel outcome measures of
hand function able to measure performance in addition to capacity according to the
terminology of the International Classification of Functioning, Disability and Health.12

4.3 Limitations and future work
Although we used the hand-object contact state for inferring functional interactions, its
meaning only approximates functional hand-object interactions and further reasoning will
be required to accurately predict the functional use of the hands from video-data. As an
example, we will explore the use of action and activity recognition algorithms30,31 with two
goals in mind: (1) to develop interaction detection algorithms robust to the type of activities
conducted at home and (2) to understand which actions require more intervention during
rehabilitation. ",eess.IV,B,-0.07141236,0.33680373,0.008650863
http://arxiv.org/pdf/2203.16996v3,Measuring hand use in the home after cervical spinal cord injury using egocentric video,"14
                                                                                      Measuring hand use in tetraplegia

         The correlations with UEMS and GRASSP scores demonstrated that the
percentage of interaction time and number of functional interactions per hour may provide
important information on how UE motor functions translate into an increased UE usage
in daily life. This is an important finding towards proposing novel outcome measures of
hand function able to measure performance in addition to capacity according to the
terminology of the International Classification of Functioning, Disability and Health.12

4.3 Limitations and future work
Although we used the hand-object contact state for inferring functional interactions, its
meaning only approximates functional hand-object interactions and further reasoning will
be required to accurately predict the functional use of the hands from video-data. As an
example, we will explore the use of action and activity recognition algorithms30,31 with two
goals in mind: (1) to develop interaction detection algorithms robust to the type of activities
conducted at home and (2) to understand which actions require more intervention during
rehabilitation. ",eess.IV,B,-0.07141236,0.33680373,0.008650863
http://arxiv.org/pdf/2204.00068v1,Automatic Classification of Alzheimer's Disease using brain MRI data and deep Convolutional Neural Networks,"The data used in this paper are
described in Section 3, the proposed approach is introduced in Section 4. In Section 5, experimental
results are provided, the discussion is provided in section 6, and finally, in section 7, the conclusion
and future work is presented. Figure (2) illustrates the block diagram of the proposed methodology. ",eess.IV,B,0.383487,0.31015545,-0.15376943
http://arxiv.org/pdf/2204.00367v1,Learning to Deblur using Light Field Generated and Real Defocus Images,"Considering the overall performance and parameter           rial. Our future work will take these challenging cases into
number, kernel size 7 is chosen. consideration. ",eess.IV,B,0.2495084,0.26900434,0.015455982
http://arxiv.org/pdf/2204.00424v1,Comparison of convolutional neural networks for cloudy optical images reconstruction from single or multitemporal joint SAR and optical images,"Secondly, using a U-Net backbone instead of a ResNet
backbone enables input images at lower resolution that the 10m bands of Sentinel images: we have shown that a 20m
spacing DEM can be injected after the Ô¨Årst downsampling of the network without prior spatial re-sampling, improving
the reconstruction of optical images. However, we only have trained all single date based networks using the only the l1
loss, and future works could investigate other objective formulations. We have carried out the comparison of single date
networks and the multitemporal networks over the MSOP test dataset, which represents the nominal operational context
of both networks, e.g. ",eess.IV,A,0.09546292,-0.17065811,0.25350344
