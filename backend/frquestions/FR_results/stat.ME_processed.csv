url,title,further research,primary category,label,x,y,z
http://arxiv.org/pdf/2201.00281v1,Evidence synthesis with reconstructed survival data,"This consists of 36 studies reported log HRs
and corresponding standard errors. Finally, 12 additional studies provided only survival
rates at particular time points, which were still included as a type of supplemental survival
data in the meta-analysis. In total, we included 64 studies with 8,033 AML patients who
did not undergo transplantation to illustrate MARS (proposed in section 3) and to respond
to the FDA’s pertinent concerns. ",stat.ME,B,0.40636772,0.14860067,-0.14388943
http://arxiv.org/pdf/2201.00470v1,Estimating Rate of Change for nonlinear Trajectories in the Framework of Individual Measurement Occasions: A New Perspective of Growth Curves,"It can be seen from the table that the estimates of
the parameters related to the asymptotic slope and vertical distance were not ideal, but they were still acceptable. With
further examination, we noticed that the Jenss-Bayley LCSM performed better under the conditions with more repeated
measurements, the time structure of unequally-spaced study waves, and the larger sample size. 5.3 Model Comparison

This section compares the model performance between each parametric LCSM and the corresponding LGCM based on
the four measures and information criteria, including Akaike’s Information Criteria (AIC) and Bayesian Information
Criteria (BIC). ",stat.ME,C,0.11595291,0.038240872,0.08456891
http://arxiv.org/pdf/2201.00470v2,Estimating Rate of Change for nonlinear Trajectories in the Framework of Individual Measurement Occasions: A New Perspective of Growth Curves,"It can be seen from the table that the estimates of
the parameters related to the asymptotic slope and vertical distance were not ideal, but they were still acceptable. With
further examination, we noticed that the Jenss-Bayley LCSM performed better under the conditions with more repeated
measurements, the time structure of unequally-spaced study waves, and the larger sample size. 4.3 Model Comparison

This section compares the model performance between each parametric LCSM and the corresponding LGCM based on
the four measures and information criteria, including Akaike’s Information Criteria (AIC) and Bayesian Information
Criteria (BIC). ",stat.ME,C,0.11199655,0.036788706,0.08687879
http://arxiv.org/pdf/2201.00470v3,Estimating Rate of Change for nonlinear Trajectories in the Framework of Individual Measurement Occasions: A New Perspective of Growth Curves,"11
                                                                                                         A PREPRINT - MAY 17, 2022

the parameters related to the asymptotic slope and vertical distance were not ideal, but they were still acceptable. With
further examination, we noticed that the Jenss-Bayley LCSM performed better under the conditions with more repeated
measurements, the time structure of unequally-spaced study waves, and the larger sample size. 4.3 Model Comparison

This section compares the model performance between each parametric LCSM and the corresponding LGCM based on
the four measures and information criteria, including Akaike’s Information Criteria (AIC) and Bayesian Information
Criteria (BIC). ",stat.ME,C,0.13653342,0.03213317,0.06897574
http://arxiv.org/pdf/2201.00470v4,Estimating Rate of Change for nonlinear Trajectories in the Framework of Individual Measurement Occasions: A New Perspective of Growth Curves,"It can be seen from the table that the estimates of
the parameters related to the asymptotic slope and vertical distance were not ideal, but they were still acceptable. With
further examination, we noticed that the Jenss-Bayley LCSM performed better under the conditions with more repeated
measurements, the time structure of unequally-spaced study waves, and the larger sample size. C.2 Model Comparison

This section compares the model performance between each parametric LCSM and the corresponding LGCM based on
the four measures and information criteria, including Akaike’s Information Criteria (AIC) and Bayesian Information
Criteria (BIC). ",stat.ME,C,0.11575754,0.041656885,0.08479209
http://arxiv.org/pdf/2201.00470v5,Estimating Rate of Change for nonlinear Trajectories in the Framework of Individual Measurement Occasions: A New Perspective on Growth Curves,"It can be seen from the table that the estimates of
the parameters related to the asymptotic slope and vertical distance were not ideal, but they were still acceptable. With
further examination, we noticed that the Jenss-Bayley LCSM performed better under the conditions with more repeated
measurements, the time structure of unequally-spaced study waves, and the larger sample size. C.2 Model Comparison

This section compares the model performance between each parametric LCSM and the corresponding LGCM based on
the four measures and information criteria, including Akaike’s Information Criteria (AIC) and Bayesian Information
Criteria (BIC). ",stat.ME,C,0.11575754,0.041656885,0.08479209
http://arxiv.org/pdf/2201.00719v1,PowerGraph: Using neural networks and principal components to multivariate statistical power trade-offs,"P-
CLUSTER is a quick way of discarding low power regions
                                                                needed for a brute force approach. We want to explore strate-
                                                                gies to bridge the gap between unsupervised learning and
                                                                supervised methods in future work. Model          REG-3    REG-5       REG-7      RMANOVA-3

                                                                      Dataset Size       2376     2592        3888           1296
                                                                Collection Time (secs)    500      631        1027           5640
                                                                 Hypothesis (Zero β)    β1, β3  β1, β3, β5  β1, β3, β7        N/A

                                                                Table 3: Dataset properties for the various models. ",stat.ME,A,-0.110022515,0.085320376,-0.3229228
http://arxiv.org/pdf/2201.00719v2,PowerGraph: Using neural networks and principal components to determine multivariate statistical power trade-offs,"Furthermore, it requires much more data compared
         to the neural network. We, however, have not used any guidance for tuning this algorithm’s parameters, and
         we leave this aspect for future work. • Model Limitations: PNN provides excellent empirical performance and generalizes well over increasing
         model complexity while providing competitive performance even with only 10% of the data. ",stat.ME,A,-0.21704581,0.076636344,-0.29822233
http://arxiv.org/pdf/2201.01682v1,Functional-Input Gaussian Processes with Applications to Inverse Scattering Problems,"An interesting topic for future research is to explore the construction procedure
for eﬃcient space-ﬁlling designs with functional inputs. Apart from experimental designs,
another important future work is to explore systematic approaches to eﬃciently identify the
functional input given an observed far-ﬁeld pattern, which is the ultimate goal of inverse
scattering problems. Based on the proposed GP surrogate, we will explore a Bayesian
inverse framework and a calibration procedure that integrates computer experiments and
real observations. ",stat.ME,C,-0.27706426,-0.017462268,-0.011088379
http://arxiv.org/pdf/2201.01682v2,Functional-Input Gaussian Processes with Applications to Inverse Scattering Problems,"An interesting topic for future research is to explore the construction procedure
for eﬃcient space-ﬁlling designs with functional inputs. Apart from experimental designs,
another important future work is to explore systematic approaches to eﬃciently identify the
functional input given an observed far-ﬁeld pattern, which is the ultimate goal of inverse
scattering problems. Based on the proposed GP surrogate, we will explore a Bayesian
inverse framework and a calibration procedure that integrates computer experiments and
real observations. ",stat.ME,C,-0.27706426,-0.017462268,-0.011088379
http://arxiv.org/pdf/2201.01687v1,"Spatial modeling of day-within-year temperature time series: an examination of daily maximum temperatures in Aragón, Spain","The posterior probability that the mean in 1986-2015 is higher

                                            17
than in 1956-1985 is 0.94 in Olite and essentially 1 in Longares and Guara. 5 Summary and future work

We have proposed a very rich space-time mean model for daily maximum temperatures, ﬁtted
over a sixty year period for a region in Spain. Our speciﬁcation is continuous in space and
autoregressive in time. ",stat.ME,C,-0.06604805,-0.34943438,0.016170794
http://arxiv.org/pdf/2201.01687v2,"Spatial modeling of day-within-year temperature time series: an examination of daily maximum temperatures in Aragón, Spain","The posterior probability that the mean in 1986–2015 is higher
than in 1956–1985 is 0.94 in Olite and essentially 1 in Longares and Guara. 5 Summary and future work

We have proposed a very rich space-time mean model for daily maximum temperatures, ﬁtted
over a sixty year period for a region in Spain. Our speciﬁcation is continuous in space and
autoregressive in time. ",stat.ME,C,-0.07069703,-0.37021166,0.021959571
http://arxiv.org/pdf/2201.01879v1,Exponential family measurement error models for single-cell CRISPR screens,"We note that GLM-EIV and
the thresholding method in principle are compatible with any θ estimation procedure,
including those based on more sophisticated techniques, such as regularization (Hafemeister
and Satija 2019). We defer rigorous investigation of the impact of diﬀerent θ estimation
strategies on these methods to future work. 7 Data analysis

Leveraging our computational infrastructure, we applied GLM-EIV and the thresholding
method to analyze the entire Gasperini and Xie datasets. ",stat.ME,C,-0.052063074,-0.095113434,0.027395766
http://arxiv.org/pdf/2201.02244v1,Predictive Criteria for Prior Selection Using Shrinkage in Linear Models,"We believe a natural choice for fj(βj) might be something
like |βj|1−|corr(yi,xi)| because it is data driven. We have not done this here, and we leave it for future work. Here we focus on comparing existing methods and then using genetic algorithms to ﬁnd optimal choices for
the fj(βj)’s. ",stat.ME,A,-0.28290492,0.14951953,-0.07978214
http://arxiv.org/pdf/2201.02301v1,New designs for Bayesian adaptive cluster-randomized trials,"Inﬂation of false positive rate will
occur for imbalanced studies, and with the same sample size, imbalanced tri-
als may be underpowered compared with their balanced counterparts. Similar
impacts of unequal cluster sizes on power or false positive rate may also exist
for our Bayesian adaptive cluster-randomized trials, and this would need to
be determined in future work. Also, practical issues in planning a Bayesian
adaptive cluster-randomized trial are not taken into account in our paper. ",stat.ME,B,0.07225563,0.1665006,-0.04213661
http://arxiv.org/pdf/2201.02486v1,Power and Sample Size Calculations for Rerandomized Experiments,"For example, the asymptotic
distribution of the linear regression estimator after rerandomization has only recently been
established (Li & Ding, 2020). Thus, studying the asymptotic distribution of other estima-
tors after rerandomization is an important line of future work, because it will allow for a
better understanding of the precision and power beneﬁts of rerandomization. 20
A Proof of Theorem 1

We aim to compute the asymptotic power of the test (9), where we reject the null hypothesis
if |τˆ| > z1−α/2Vˆ 1/2N −1/2, where Vˆ is the estimator for the variance in (6). ",stat.ME,C,-0.07994724,0.05721081,0.5118259
http://arxiv.org/pdf/2201.02707v5,ALPHA: Audit that Learns from Previously Hand-Audited Ballots,"Since the performance of BBP is similar to that of BRAVO, one might expect that applying
ALPHA to Bernoulli samples would require lower sample sizes (i.e., lower selection prob-
abilities) than BBP. We do not perform any simulations here, but we plan to investigate the
efﬁciency of ALPHA/SHANGRLA versus BBP in future work. 7. ",stat.ME,C,-0.17380355,0.23167214,0.18944263
http://arxiv.org/pdf/2201.02707v6,ALPHA: Audit that Learns from Previously Hand-Audited Ballots,"Since the performance of BBP is similar to that of BRAVO, one might expect that applying
ALPHA to Bernoulli samples would require lower sample sizes (i.e., lower selection prob-
abilities) than BBP. We do not perform any simulations here, but we plan to investigate the
efﬁciency of ALPHA/SHANGRLA versus BBP in future work. 7. ",stat.ME,C,-0.17380355,0.23167214,0.18944263
http://arxiv.org/pdf/2201.02707v8,ALPHA: Audit that Learns from Previously Hand-Audited Ballots,"Since the performance
of BBP is similar to that of BRAVO, one might expect that applying ALPHA to Bernoulli
samples would require lower sample sizes (i.e., lower selection probabilities) than BBP. We do not perform any simulations here, but we plan to investigate the efﬁciency of AL-
PHA/SHANGRLA versus BBP in future work. 7. ",stat.ME,C,-0.17902459,0.21675417,0.20175669
http://arxiv.org/pdf/2201.02707v9,ALPHA: Audit that Learns from Previously Hand-Audited Ballots,"Since the performance
of BBP is similar to that of BRAVO, one might expect that applying ALPHA to Bernoulli
samples would require lower sample sizes (i.e., lower selection probabilities) than BBP. We do not perform any simulations here, but we plan to investigate the efﬁciency of AL-
PHA/SHANGRLA versus BBP in future work. 7. ",stat.ME,C,-0.17902459,0.21675417,0.20175669
http://arxiv.org/pdf/2201.02742v1,Bayesian Changepoint Estimation for Spatially Indexed Functional Time Series,"Finally, our method currently only focuses on the changepoint estimation, after the
rejection region of changepoint detection has been identiﬁed. In future work, we would like
to develop a more compact approach by incorporating detection and estimation in a single
model to remove dependence on auxiliary methods for detection. References

Aston, J. ",stat.ME,C,-0.13344577,-0.18746194,0.02624722
http://arxiv.org/pdf/2201.02743v1,Spatial Confidence Regions for Combinations of Excursion Sets in Image Analysis,"brain images, astrological maps). For this reason, we intend to investigate further the performance of the method in higher
dimensions in future work. Acknowledgment(s)

This work was partially supported by the NIH under Grant [R01EB026859] (A.S., T.M.,
T.N.). ",stat.ME,A,-0.26384032,0.09994519,-0.29339257
http://arxiv.org/pdf/2201.02926v1,Variational design for a structural family of CAD models,"However, such a mechanism still               in the case studies conducted, there are a few limitations (and
remains unknown, and further development is required. therefore future work) that should be noted here. The proposed
Fortunately, from our experience, a depth from 5 to 9 can balance        method, in its current form, requires that model families input
properly the optimums and running time. ",stat.ME,A,-0.101998776,0.16471243,-0.113235734
http://arxiv.org/pdf/2201.03065v1,Selecting the Best Optimizing System,"We then demonstrate

                                                                23
reliable algorithm performance through three numerical examples. In future work, we ﬁnd two lines that are interesting and relevant. The ﬁrst line concerns a

diﬀerent ﬁxed-precision (or ﬁxed-conﬁdence) framework for SBOS problems, which will have distinct
needs for algorithm design and analysis compared to the ﬁxed-budget setting in this work. ",stat.ME,A,-0.43134636,0.292989,-0.03824423
http://arxiv.org/pdf/2201.03616v1,A Statistical Analysis of Compositional Surveys,"Yet, scale reliant inference goes
beyond both microbiome systems and diﬀerential analysis. Overall, there are numerous
areas of fruitful future work. Acknowledgments and Funding Sources

We thank Rachel Silverman, Juan Jose Egozcue, and Vera Pawlosky-Glahn for their manuscript
comments. ",stat.ME,B,0.07656026,0.01651656,-0.1796827
http://arxiv.org/pdf/2201.03616v2,A Statistical Analysis of Compositional Surveys,"Third, we have focused our
examples on diﬀerential abundance in microbiome systems, but scale reliant inference goes
beyond both microbiome systems and diﬀerential analysis. Overall, there are many areas
for future work. 32
Acknowledgments and Funding Sources

We thank Rachel Silverman, Juan Jose Egozcue, Vera Pawlosky-Glahn, Gregory Gloor,
Michael Love, and James Morton for their manuscript comments. ",stat.ME,B,0.020177938,0.011912751,-0.15213156
http://arxiv.org/pdf/2201.05197v2,Aitchison's Compositional Data Analysis 40 Years On: A Reappraisal,"For a 5-component composition, for example, Fig. 13(a)
In other words, these Tellus compositional data can be
square-root transformed, renormalized, and then each part     shows  a                       graph  of  all  1  ×5×4  =  10  LRs,  where                           the  ar-
chi-square standardized by dividing by the square root of                                                    2
its (transformed) part mean, giving a quasi-coherent set
of transformed data for further analysis, with no need for    rows point to the denominators of the respective ratios. replacement of data zeros. ",stat.ME,A,-0.14234877,0.16121756,-0.21337926
http://arxiv.org/pdf/2201.05491v1,Robust Confidence Intervals for Meta-Regression with Correlated Moderators,"For a medium number of studies
HC3 might be the most suitable, since its intervals held the nominal conﬁdence level
in every situation with k ∈ {10, 20} and were shorter compares to the HC4- and
HC5-CIs. In further research it may also be of interest to analyze the situations
where highly inﬂated interval lengths of the HC3- and HC5-CIs occurred in detail,
because they cannot be explained by the results of this work. Concluding, meta-regression remains an important ﬁeld of statistical research. ",stat.ME,B,0.2916085,0.23935378,-0.048306532
http://arxiv.org/pdf/2201.05773v1,Automated causal inference in application to randomized controlled clinical trials,"6). We conclude that the function f = COMP(nn, CAT(FILTER(pred))) achieves the optimal JS score, e.g.,
91.9 ± 0.06%, and thus is used as the default function for further analysis. As pointed out in Valkov et al. ",stat.ME,A,-0.22022718,0.29302686,0.041345865
http://arxiv.org/pdf/2201.05773v2,Automated causal inference in application to randomized controlled clinical trials,"6). We conclude that the function f = COMP(nn, CAT(FILTER(pred))) achieves the optimal JS score, e.g.,
91.9 ± 0.06%, and thus is used as the default function for further analysis. As pointed out in Valkov et al. ",stat.ME,A,-0.22022718,0.29302686,0.041345865
http://arxiv.org/pdf/2201.05773v3,Automated causal inference in application to randomized controlled clinical trials,"6). We conclude that the function f = COMP(nn, CAT(FILTER(pred))) achieves the optimal JS score, e.g.,
91.9 ± 0.06%, and thus is used as the default function for further analysis. As pointed out in Valkov et al. ",stat.ME,A,-0.22022718,0.29302686,0.041345865
http://arxiv.org/pdf/2201.05893v1,Treatment Effect Risk: Bounds and Inference,"We avoid this route in order to focus on the best bounds given just by the CATE, which is the most

commonly used in practice to understand effect heterogeneity. Sharp bounds based on a data-combination perspective are left to future work. 5       are  also  tests  for  the  presence  of  heterogeneity  not  explained  by  𝑋  [16,  17]. ",stat.ME,A,0.037438564,0.15751174,0.22727533
http://arxiv.org/pdf/2201.06229v1,Targeted Optimal Treatment Regime Learning Using Summary Statistics,"In addition, empirical evidence shows
that the EB calibration method generally has better performance than the EL calibration
method since it tends to give more stable weight estimates. There are some extensions we consider in the future work. First, the current paper
focuses on linear ITRs. ",stat.ME,C,-0.14703251,0.11603567,0.029649112
http://arxiv.org/pdf/2201.06669v3,Individualized treatment rules under stochastic treatment cost constraints,"This motivates seeking ways to optimize the ﬁnite-sample performance of the nuisance function estimators
employed in future applications of the proposed method, possibly based on prior subject-matter expertise. The underestimation of standard errors in this simulation also motivates future work exploring whether
there are standard error estimators with better ﬁnite-sample performance, for example, estimators based
on the bootstrap. 6 Conclusion

There is an extensive literature on estimating optimal ITRs and evaluating their performance. ",stat.ME,B,0.06974329,0.06046503,0.20313013
http://arxiv.org/pdf/2201.06808v2,General P-Splines for Non-Uniform B-Splines,"Of course, this is only a toy example of a crude yet adaptive
speciﬁcation of a knots superset. How to automate such heuristic for an arbitrary problem
is worth further research. Appendix: Spline and B-Splines

An order-d spline f (x) deﬁned on domain [a, b] comprises smoothly connected polynomial
segments of degree d − 1, with d − 2 continuous derivatives at their interior knots (or
break points) a < s1 < s2 < . ",stat.ME,A,-0.26340324,0.106973745,-0.12147995
http://arxiv.org/pdf/2201.06994v1,Flexible clustering via hidden hierarchical Dirichlet priors,Canale et al. (2019) provide further analysis of the CPP data. The heatmap of the co-clustering posterior probability for the 12 hospitals is shown in Fig. ,stat.ME,C,-0.0143544525,-0.01261472,-0.20662038
http://arxiv.org/pdf/2201.07396v1,Ordinal Causal Discovery,"We remark
ACC     OCD           HCR       bQCD     CAM                that whether a categorical dataset is ordinal or not
AUC  0.73 (0.01)  0.44 (0.02)     0.70   0.58               is usually quite clear from the underlying application
CPU  0.76 (0.00)  0.56 (0.02)     0.72   0.58               whereas assumptions made by alternative categorical
     36s (1.7s)   12m (2.2m)       7m     11s               causal discovery methods are sometimes hard to verify. ACC                                     RESIT
AUC     IGCI        SLOPE      LiNGAM    0.53               There are several limitations of the current work which
CPU      0.66         0.76        0.42   0.56               we plan to address in our future work. First, the cur-
         0.51         0.84        0.59    12h               rent score-and-search algorithm outputs a point esti-
          1s          24m          3s                       mate of the causal graph with no uncertainty quantiﬁ-
                                                            cation. ",stat.ME,A,-0.0043133684,0.27305844,-0.09639708
http://arxiv.org/pdf/2201.07396v2,Ordinal Causal Discovery,"Table 3: Single-cell RNA-seq data. ACC  OCD                        HCR   bQCD   SLOPE
     CPU  0.61                       0.36   0.45    0.50
          19m                        22m    3.4h     2h

7 Conclusion

There are several limitations of the current work, which we plan to address in our future work. First, the current
score-and-search algorithm outputs a point estimate of the causal graph with no uncertainty quantiﬁcation. ",stat.ME,A,0.024834013,0.30734053,-0.12782423
http://arxiv.org/pdf/2201.07396v3,Ordinal Causal Discovery,"Table 3: Single-cell RNA-seq data. ACC  OCD                        HCR   bQCD   SLOPE
     CPU  0.61                       0.36   0.45    0.50
          19m                        22m    3.4h     2h

7 Conclusion

There are several limitations of the current work, which we plan to address in our future work. First, the current
score-and-search algorithm outputs a point estimate of the causal graph with no uncertainty quantiﬁcation. ",stat.ME,A,0.024834013,0.30734053,-0.12782423
http://arxiv.org/pdf/2201.07874v1,Bayesian Prediction with Covariates Subject to Detection Limits,"We assume that the detection limit, as determined by ∆, is known. However, this

is not always the case for interference problems, and future work should put efforts

to generalize the framework to unknown detection limits. This can be straightfor-

ward achieved in principle by adding a Metropolis-Hastings updating step for ∆ to

the Gibbs sampler, but issues of parameter identiﬁcation should be explored in detail. ",stat.ME,C,-0.2724275,-0.101880744,0.09337598
http://arxiv.org/pdf/2201.07896v1,Generative Models for Periodicity Detection in Noisy Signals,"This would allow GMPDA to adapt to non-                                            D(µ) =              1si+m −si =µ . (34)
stationary changes and remains for future work. i,m>0
APPENDIX A
GMPDA ALGORITHM                                                                                    One tempting method would be to select argmax D(µ) as

In the section the steps involved in the GMPDA algorithm                                                                                                                                µ
are outlined in very detail. ",stat.ME,C,-0.21033522,0.0063792393,-0.061195858
http://arxiv.org/pdf/2201.08012v1,Entropy Balancing for Generalizing Causal Estimation with Summary-level Information,"The distributions of lab results are right-skewed, so
we apply log transformations on these variables. All the continuous variables are then stan-
dardized for further analysis. We impute any missing values using MissForest (Stekhoven and
Bu¨hlmann, 2012), which is a ﬂexible non-parametric missing value imputation approach. ",stat.ME,B,0.14101073,0.11366088,-0.0638171
http://arxiv.org/pdf/2201.08012v2,Entropy Balancing for Causal Generalization with Target Sample Summary Information,"The distributions of lab results are right-skewed, so
we apply log transformations on these variables. All the continuous variables are then stan-
dardized for further analysis. We impute any missing values using MissForest (Stekhoven and
Bu¨hlmann, 2012), which is a ﬂexible non-parametric missing value imputation approach. ",stat.ME,B,0.14101073,0.11366088,-0.0638171
http://arxiv.org/pdf/2201.08053v1,Bayesian Fused Lasso Modeling via Horseshoe Prior,"Considering how to accelerate the convergence of the Gibbs sampling for our proposed
method would also be interesting. We leave these topics as future work. Acknowledgements
S. K. was supported by JSPS KAKENHI Grant Numbers JP19K11854 and
JP20H02227. ",stat.ME,C_centroid,-0.3932629,-0.21753906,0.0659494
http://arxiv.org/pdf/2201.08502v1,Curved factor analysis with the Ellipsoid-Gaussian distribution,"We also characterize various appealing properties of the distribution, such as that the marginal
                   distribution of any sub-vector still follows an Ellipsoid-Gaussian. There are a number of directions that would be interesting to pursue in future work. First, it
                   is conceptually appealing to place shrinkage priors on the loadings, such as in Kowal, 2021. ",stat.ME,C,-0.23394603,-0.15731835,0.2143679
http://arxiv.org/pdf/2201.08723v1,Statistical Inference on Explained Variation in High-dimensional Linear Model with Dense Effects,"The diﬃculty may be overcome with the help of supplementary covariate data. However,
this is beyond the scope of this paper and is a topic of further research. Acknowledgement
    This research is supported by a grant from the National Institute of Environmental Health
Sciences at the National Institute of Health. ",stat.ME,B,0.45309436,-0.06781022,-0.025112323
http://arxiv.org/pdf/2201.09033v1,Sample Size Considerations for Bayesian Multilevel Hidden Markov Models: A Simulation Study on Multivariate Continuous Data with highly overlapping Component Distributions based on Sleep Data,"However, hardware limitations did not
allow us to do so. Given that the chains have likely converged to the same posterior
distribution, we merge the posterior distributions of both chains for further analysis. 5.4. ",stat.ME,C,-0.26205412,-0.02059971,0.06598042
http://arxiv.org/pdf/2201.09194v1,Distributed Learning of Generalized Linear Causal Networks,"The primary focus of this paper is on big distributed data, with large n but moderate p. In
this setting, we established the convergence of the solution obtained by distributed optimization
to a global minimizer of the loss using the combined data, and the consistency of the global
minimizer as an estimate of the true DAG parameter. However, generalizing the convergence and
consistency results to allow diverging p is theoretically interesting and left as future work. References

Apple and Google (2021), “Explosure Notiﬁcation Privacy-preserving Analytics (ENPA) White
   Paper,” Tech. ",stat.ME,A,-0.23502204,0.046340805,0.041981723
http://arxiv.org/pdf/2201.09320v1,Robust Wavelet-based Assessment of Scaling with Applications,"Although the accuracy rates could be argued to be relatively
low, even classiﬁers that are “slightly better than ﬂipping a coin” can improve diagnostic
accuracy when added to a battery of other independent testing modalities. Finally, as future work, the authors plan to extend Ram´ırez-Cobo and Vidakovic
(2013), where the multifractal spectrum was used for diagnostic classiﬁcation in a sim-
ilar context. Some experiments in this direction were conducted in Ram´ırez-Cobo and
Vidakovic (2012), however, direct comparisons with the results in this paper were not
possible because of diﬀerent data sets used. ",stat.ME,A,0.054516546,0.23285727,-0.014131272
http://arxiv.org/pdf/2201.09585v1,The Coupled Rejection Sampler,"For example, suboptimal
Wasserstein-like couplings (for a review see, e.g., Villani, 2009) could be sampled eﬃciently from a
dominating optimal transport coupling of Gaussian. Studying the theoretical and empirical properties
of these diﬀerent extensions is left for future works. Individual contributions

The original idea, implementation, and redaction of this article are all due to Adrien Corenﬂos. ",stat.ME,C,-0.3221034,-0.20811287,0.15926282
http://arxiv.org/pdf/2201.09585v2,The Coupled Rejection Sampler,"For example using optimal transport coupling of the indices based on a
well-chosen metric may lead to faster converging algorithms at the cost of submaximality. Studying
the theoretical and empirical properties of these diﬀerent extensions is left for future works. Individual contributions

The original idea, implementation, and redaction of this article are all due to Adrien Corenﬂos. ",stat.ME,C,-0.34502822,-0.09525114,0.03872745
http://arxiv.org/pdf/2201.10014v1,Zero-Truncated Poisson Regression for Zero-Inflated Multiway Count Data,"On the other hand, when the
parametric values are small (e.g., β ≤ .01 and α ≤ 1), the eﬃciency of our approach is
degraded since such situations with sparse data generate an overwhelming amount of true
and false zeros. Several extensions remain to be explored as future work. The current work focuses on the
multi-parameter Poisson distribution. ",stat.ME,C,-0.13928384,-0.017248262,0.20141736
http://arxiv.org/pdf/2201.10096v1,Imputation Maximization Stochastic Approximation with Application to Generalized Linear Mixed Models,"We
also observe that IMSA yields better results when updating the variance components on the
original scale than on the log scale. For future work, it is desired to investigate in detail the
estimation of the variance of θ˜IMSA. Moreover, it is interesting to extend beyond GLMMs,
and apply IMSA to other suitable latent variable models. ",stat.ME,B,0.08000311,-0.15784988,0.06952375
http://arxiv.org/pdf/2201.10208v1,Semi-Supervised Quantile Estimation: Robust and Efficient Inference in High Dimensional Settings,"These numerical results substantiate the properties and
advantages of our approach stated in the previous sections. Finally, Section 6 ends the article with
a concluding remark as well as a brief discussion of possible future work. All technical details,
including auxiliary lemmas and proofs of all theoretical results, and extra numerical results can be
found in Appendices A–C. ",stat.ME,C,-0.45251516,0.11945331,0.22111759
http://arxiv.org/pdf/2201.10311v1,Multi-purpose open-end monitoring procedures for multivariate observations based on the empirical distribution function,"We end this section by stating a few remarks:

• An implementation of the studied multi-purpose open-end monitoring procedure will

                    be made available in the very near future in the R package npcp (Kojadinovic and

                    Verhoijsen, 2021). • For the monitoring of continuous multivariate observations, the strategy for choosing

                    the evaluation points proposed in Section 3.1 was not completely deﬁned and requires

                    further research. One possibility would be to choose the points according to the depth

                    of the observations (a concept initially proposed by Tukey, 1975, in the bivariate case

                    with numerous extensions since then) in the learning sample. ",stat.ME,A,0.013449114,-0.053995207,-0.20993555
http://arxiv.org/pdf/2201.10321v1,Compositional Cubes: A New Concept for Multi-factorial Compositions,"Moreover, this system can be constructed in a ﬂexible manner, basically according to the needs or
expert knowledge of the analyst: There might be a certain hypothesis on the relations between factors and/or factor
levels, and based on the principle of sequential binary partitions (SBPs), these combinations can be reﬂected by the
constructed coordinates. Even though the proposed coordinate representation allows to describe the overall relations
between factors, similar as in the case of the well developed theory for the analysis of vector compositional data, it is
also possible to use them for further analysis with standard statistical methods, or to perform statistical inference with
the coordinates, for example, by constructing bootstrap conﬁdence intervals for the mean, in order to determine if the
effect conveyed by the coordinate is signiﬁcant. A proper coordinate representation of the multi-factorial compositional
data can therefore be understood as a ﬁrst step in the analysis, possibly followed by other advanced statistical methods. ",stat.ME,A,-0.058974847,0.10158419,-0.20089546
http://arxiv.org/pdf/2201.10933v1,Flexible domain prediction using mixed effects random forests,"Regarding additional generalizations of the proposed method, we aim to extend the
use of MERFs towards the estimation of small area quantiles and other non-linear indicators,
such as Gini-coeﬃcients or Head Count Ratios. Furthermore, a generalization towards binary
or count data is possible and left to further research. The semi-parametric composite formula-
tion of model (1) allows for f () to adapt any functional form regarding the estimation of the
conditional mean of yi given Xi and technically transfers to other machine learning methods,
such as gradient-boosted trees or support vector machines. ",stat.ME,B,0.01130603,-0.119353086,-0.010050913
http://arxiv.org/pdf/2201.10933v2,Flexible domain prediction using mixed effects random forests,"Regarding
additional generalizations of the proposed method, we aim to extend the use of MERFs towards
the estimation of small area quantiles and other non-linear indicators, such as Gini-coeﬃcients
or Head Count Ratios. Furthermore, a generalization towards binary or count data is possible
and left to further research. The semi-parametric composite formulation of model (1) allows for
f () to adapt any functional form regarding the estimation of the conditional mean of yi given
Xi and technically transfers to other machine learning methods, such as gradient-boosted trees
or support vector machines. ",stat.ME,B,0.030947078,-0.15053439,-0.010075491
http://arxiv.org/pdf/2201.10993v1,Approximate Reference Prior for Gaussian Random Fields,"The combination of one of these with the approximate reference prior developed in
this work would make it feasible to carry out default Bayesian analyses of large geostatistical
data sets. This will be explored in future work. References

Abramowitz, M. and I. Stegun (1964). ",stat.ME,C,-0.13369592,-0.27210993,-0.02871391
http://arxiv.org/pdf/2201.11163v1,Sequential Bayesian Inference for Factor Analysis,"Scoring rules evaluated on out-of-
sample data are available as a direct output of the data tempering strategy adopted in this work, under the prequential
framework (Dawid and Musio, 2014). A formal comparison of Sequential Bayes Factors and such scoring rules is an
interesting ﬁeld of further research. 28
                                                                                                   A PREPRINT - JANUARY 28, 2022

References

Andrieu, C., A. Doucet, and R. Holenstein (2010). ",stat.ME,B,0.12744418,0.0015604347,-0.15609139
http://arxiv.org/pdf/2201.12016v1,Heterogeneous Treatment Effect Estimation based on a Partially Linear Nonparametric Bayes Model,"randomly generated linear functions. The coefﬁcients of the       Conducting a similar analysis for our model is future work. linear functions are generated from the standard Gaussian            The proposed method requires O(n3) of computation for a
distribution, and the other conditions are the same as in the     sample size n, and the computation becomes difﬁcult when
ﬁrst experiment. ",stat.ME,C,-0.30336574,-0.0010660631,0.18065855
http://arxiv.org/pdf/2201.12045v1,A loss discounting framework for model averaging and selection in time series models,"In Section 4, the performance
of the LDF approach is examined in a simulated example and applications to Eurozone
inﬂation forecasting using professional forecasts, and foreign exchange and US inﬂation
using time series models. We discuss the limitations of our approach and set out directions
for further research in Section 5. The code to reproduce our study is freely available via
the provided link2. ",stat.ME,C,-0.095638,-0.25085396,-0.010447803
http://arxiv.org/pdf/2201.12045v2,A loss discounting framework for model averaging and selection in time series models,"4
where pk(yt|yt−1) is the predictive likelihood at time t, given information available at time
t − 1 for model k (i.e., the likelihood calculated using the posterior predictive distribution
yt|yt−1 for model k given the actual realisation yt) and c is a small positive number intro-
duced to avoid model probability being brought to machine zero by aberrant observations4. The log-sum-exp trick is an alternative way of handling this numerical instability which
would, at least in part, eliminate the need for the constant c. We largely leave the role of
this parameter to further research. The recursions in (2.1) and (2.2) amount to a closed form algorithm to calculate the
probability that model k is the best model given information from the previous time step
t − 1, for forecasting at time t. A model receives a higher weight if it performed well in
the recent past. ",stat.ME,C,-0.22312233,-0.2839303,0.032794967
http://arxiv.org/pdf/2201.12387v2,Comparing trained and untrained probabilistic ensemble forecasts of COVID-19 cases and deaths in the United States,"Ensembles generally beneﬁt from combining diverse
component forecasters, and it could be helpful to encourage this —for example, by clustering
the forecasters and including a representative summary of the forecasts within each cluster as
the ensemble components. There are also related questions about the importance of diﬀerent
component forecasters to ensemble skill; we plan to explore this direction in future work by using
tools such as the Shapley value to describe the contribution of individual components to the full
ensemble. We have used the WIS and probabilistic calibration to measure the extent to which forecasts
are consistent with the eventually observed data. ",stat.ME,C,-0.07109345,-0.15996377,-0.3063622
http://arxiv.org/pdf/2201.12392v1,Causal Discovery with Heterogeneous Observational Data,"(2020) showed that the causal eﬀects in the presence of latent confounders
are identiﬁable with mild structure assumptions in the non-Gaussian setting. This paper focuses
on investigating causal structure identiﬁability; establishing causal eﬀect identiﬁability theory for
the causally insuﬃcient multivariate cyclic graphs will be an interesting future work. 3.3 Bayesian Structure Learning

We learn the causal structure through a Bayesian approach by assigning priors on the space of

graphs and model parameters. ",stat.ME,B,0.07223424,-0.164195,-0.09734914
http://arxiv.org/pdf/2201.12713v1,Multilevel Longitudinal Analysis of Social Networks,"They have been
available in beta versions since a few years, which already led to applications, e.g., Boda (2018). The MCMC algorithm proposed in this paper is a straightforward procedure, and future work
will be devoted to making it more efﬁcient. Multilevel Longitudinal Social Networks 21

Acknowledgements

This work was supported in part by award R01HD052887 from the US Eunice Kennedy Shriver
National Institute of Child Health and Human Development (John M. Light, Principal Investi-
gator). ",stat.ME,A,-0.023985194,-0.09891787,-0.33122742
http://arxiv.org/pdf/2201.12713v2,Multilevel Longitudinal Analysis of Social Networks,"They have been
available in beta versions since a few years, which already led to applications, e.g., Boda (2018). The MCMC algorithm proposed in this paper is a straightforward procedure, and future work
will be devoted to making it more efﬁcient. Multilevel Longitudinal Social Networks 21

Acknowledgements

This work was supported in part by award R01HD052887 from the US Eunice Kennedy Shriver
National Institute of Child Health and Human Development (John M. Light, Principal Investi-
gator). ",stat.ME,A,-0.023985194,-0.09891787,-0.33122742
http://arxiv.org/pdf/2201.12936v1,Stratifying Online Field Experiments Using the Pigeonhole Design,"We run simulation results to demonstrate the strength of the pigeonhole
design. Below we conclude by providing practical suggestions in using a pigeonhole design, and by
pointing out three limitations of our paper that could lead to further research directions. 8.1. ",stat.ME,A,-0.14477342,0.4613757,-0.12483492
http://arxiv.org/pdf/2201.12936v2,Stratifying Online Field Experiments Using the Pigeonhole Design,"We have run simulation results to demonstrate the strength of the pigeonhole design. Below we conclude by providing practical suggestions for using a pigeonhole design, and by pointing
out three limitations of our paper that suggest further research directions. 8.1. ",stat.ME,A,-0.14282283,0.47237128,-0.13408247
http://arxiv.org/pdf/2201.12936v3,Pigeonhole Design: Balancing Sequential Experiments from an Online Matching Perspective,"We have run simulation results to demonstrate the strength of the pigeonhole design. Below we conclude by providing practical suggestions for using a pigeonhole design, and by pointing
out three limitations of our paper that suggest further research directions. 8.1. ",stat.ME,A,-0.14282283,0.47237128,-0.13408247
http://arxiv.org/pdf/2201.13111v1,Statistical Downscaling of Model Projections with Multivariate Basis Graphical Lasso,"A hybrid dynamic-statistical downscaling framework also could also be developed
that includes global climate model output, regional climate model output, and obser-
vations in the downscaling (Walton et al., 2015). However, this would require a more
complicated statistical model to jointly model the three data resources and could be the
subject of future work. A possible extension is to generalize the current model to the
framework of autoregressive co-kriging for multi-ﬁdelity model output and then consider
the observations, regional climate model output, and global climate model output as the
high-, medium-, and low-ﬁdelity data, respectively. ",stat.ME,C,-0.010182388,-0.31920087,-0.17966321
http://arxiv.org/pdf/2201.13198v1,A subsampling approach for Bayesian model selection,"We however, keep this as a potential
subject for another article. Also, studying if the strategy that restarts the optimisation algorithm from the previous
estimates when revisiting a model (from Theorem 1) improves the convergence properties of the combined algorithm is
of interest for further research. Lastly, as an alternative to the Laplace approximation for models with latent Gaussian structures, Integrated Nested
Laplace Approximations (INLA) have emerged as an efﬁcient approximation method (Rue et al., 2009). ",stat.ME,C,-0.3189288,-0.26247185,0.034591414
http://arxiv.org/pdf/2201.13280v1,Hierarchical clustering of mixed-type data based on barycentric coding,"This variable was

25

26

27  used as an external (true) partition to evaluate the obtained clustering solutions. Six

28

29  observations that had missing values in any of the 13 variables analyzed were omitted from

30

31  further analysis, leaving 297 observations. 32

33

34  Credit Approval. ",stat.ME,A,0.023517959,0.2942996,-0.2919072
http://arxiv.org/pdf/2201.13280v2,Hierarchical clustering of mixed-type data based on barycentric coding,"This variable was
used as an external (true) partition to evaluate the obtained clustering solutions. Six

                                                                                                              16
observations that had missing values in any of the 13 variables analyzed were omitted from
further analysis, leaving 297 observations. Credit Approval. ",stat.ME,A,0.042557396,0.2587059,-0.30131385
http://arxiv.org/pdf/2202.00333v1,GenMarkov: Modeling Generalized Multivariate Markov Chains in R,"The main contributions of this work are the development of a package with functions for multivariate Markov chains,
addressing the statistical inference in these models and the inclusion of covariates. The limitations are related to the
implementation in R, speciﬁcally the optimization algorithm applied is not common for MMC models, in that sense,
it would be beneﬁcial to study new approaches to optimizing the maximum likelihood function as further research. Additionally, extending this generalization to the MTD-probit model proposed by Nicolau (2014) would also be relevant,
which removes the constraints of the model’s parameters and allows the model to detect negative effects. ",stat.ME,C,-0.05330044,-0.19997661,-0.05428413
http://arxiv.org/pdf/2202.00459v1,Partial Directed Coherence and the Vector Autoregressive Modelling Myth and a Caveat,"Whereas real data properties
cannot be made ‘designed’ as in man made systems, they are often nongaussian and this could in principle be exploited
to overcome the nonminimum phase generation limitation on GC inference we described here. The answer to (b) must thus await further analysis in what is a matter for further exciting research that may entail the
revision of many conclusions regarding formerly analysed real data. 6 Conclusion

The ﬁrst take home lesson is that PDC/DTF-type estimators of Granger connectivity/inﬂuentiability [Baccalá and
Sameshima, 2014b] even in their latest and most general total form (tPDC/tDTF), incorporating instantaneous Granger
effects, do not require vector autoregressive modelling as a mandatory step but can be obtained through any other means
of spectral factorization of the spectral density matrix into minimum phase factors. ",stat.ME,C,-0.06656068,-0.1217196,-0.018716661
http://arxiv.org/pdf/2202.00493v2,"Spectral Clustering, Bayesian Spanning Forest, and Forest Process","∝ (λαr/αf )K (0,i)∈T gr(yi; θ) (i,j)∈T gr(yi | yj; θ). Therefore,
one could choose an appropriate λ˜ = λαr/αf (equivalent to choosing some value of λ),
without knowing the value of αf or αr; nevertheless, how to calibrate λ˜ still requires
further study. A Model-based Extensions to Forest Model

A.1 Extension to High-dimensional Clustering Model

For clustering high dimensional data, good performances have been demonstrated through

ﬁnding a low-dimensional sparse representation zi for each yi (Vidal, 2011; Wu et al., 2014),

and then clustering zi instead of yi. ",stat.ME,A,-0.1895258,-0.039728608,-0.25752404
http://arxiv.org/pdf/2202.00618v1,Penalized Estimation of Frailty-Based Illness-Death Models for Semi-Competing Risks,"And while the theory and results of this paper have focused on the
framework’s estimation and model-selecting properties, additional research into measuring
and evaluating predictive performance for such time-varying, multi-category outcomes is
needed (Spitoni et al., 2018). Most importantly, this methodology enables future work
modeling semi-competing risks across a wide array of clinical domains, and leveraging data
sources with high-dimensional covariates from electronic health records to ’omic data. 22
Acknowledgments

The authors thank Drs. ",stat.ME,B,0.43151742,-0.13394749,-0.21850158
http://arxiv.org/pdf/2202.00618v2,Penalized Estimation of Frailty-Based Illness-Death Models for Semi-Competing Risks,"And while the theory and results of this paper have focused on the
framework’s estimation and model-selecting properties, additional research into measuring
and evaluating predictive performance for such time-varying, multi-category outcomes is
needed (Spitoni et al., 2018). Most importantly, this methodology enables future work
modeling semi-competing risks across a wide array of clinical domains, and leveraging data
sources with high-dimensional covariates from electronic health records to ’omic data. Acknowledgments

The authors thank Drs. ",stat.ME,B,0.43132192,-0.13386346,-0.21983624
http://arxiv.org/pdf/2202.00711v1,A fully Bayesian semi-parametric scalar-on-function regression (SoFR) with measurement error using instrumental variables,"Additionally, the MCMC pro-
posed here, although fast can be also be improved using a tailored variational approach. These points will be the subject of future work. Table 1: Estimated M ISE based on 500 replicates. ",stat.ME,C,-0.28217968,-0.10900162,0.008319741
http://arxiv.org/pdf/2202.00913v1,Invariant Ancestry Search,"We have validated our procedure both on simulated and real
data. Our proposed framework would beneﬁt from further research in the maximal number
of minimally invariant sets among graphs of a ﬁxed size, as this would provide larger ﬁnite
sample power for identifying ancestors. Further it is of interest to establish ﬁnite sample
guarantees or convergence rates for IAS, possibly by imposing additional assumptions on
the class of SCMs. ",stat.ME,A,-0.25078025,0.18448247,0.027456153
http://arxiv.org/pdf/2202.00913v2,Invariant Ancestry Search,"We have validated our procedure both on simulated and real
data. Our proposed framework would beneﬁt from further research in the maximal number

    8These results do not hold in the presence of hidden variables, because it is not guaranteed that an
invariant set exists among XO (e.g., consider a graph where all observed variables share a common, unobserved
confounder with Y ). However, if at least one minimally invariant set exists among the observed variables,
then all results stated in this paper hold. ",stat.ME,A,-0.010807248,0.10908896,0.007798452
http://arxiv.org/pdf/2202.00967v1,Faster Exact Permutation Testing: Using a Representative Subgroup,"In that case, constructing
near-oracle subgroups of a given size is more challenging than in case of sign-ﬂipping. We
plan to address this issue in future work. APPENDIX A: TWO-SAMPLE COMPARISON

   In this section, we explain how the two-sample comparison problem ﬁts into the location

model described in Section 2. ",stat.ME,A,-0.13083874,0.24814287,-0.0430021
http://arxiv.org/pdf/2202.00967v2,More Efficient Exact Group-Invariance Testing: using a Representative Subgroup,"In addition, the algorithm is not optimal in terms of time complexion, as
many of the expansions may be duplicates of each other, but it sufﬁces for our purposes. We
leave the improvement of the algorithm for future work. The performance of group-invariance
tests based on subgroups that were found using this algorithm is assessed in Section 9. ",stat.ME,A,-0.15032205,0.27798623,-0.13359597
http://arxiv.org/pdf/2202.00967v3,More Efficient Exact Group-Invariance Testing: using a Representative Subgroup,"In addition, the algorithm is not optimal in terms of time complexion, as many
of the expansions may be duplicates of each other, but it suﬃces for our purposes. We leave the
improvement of the algorithm for future work. The performance of group-invariance tests based on
subgroups that were found using this algorithm is assessed in Section 9. ",stat.ME,A,-0.16377729,0.27221105,-0.13419701
http://arxiv.org/pdf/2202.01180v1,A Nonlinear Hierarchical Model for Longitudinal Data on Manifolds,"As a ﬁrst application, we estimate a hierarchical model
for the HD group. We employ cubic Be´zier curves to model              A promising direction for future work is to extend the pre-
the individual trends. This choice is motivated by the ﬁndings     sented hierarchical model to account for subject-wise shifts
in [11], where cubic models were found to adequately cap-          in the stage of evolution. ",stat.ME,C,-0.017803311,-0.092705674,-0.07653285
http://arxiv.org/pdf/2202.01180v2,A Nonlinear Hierarchical Model for Longitudinal Data on Manifolds,"Time discrete com-     nor based on non-parametric designs. putations are performed based on 2-geodesics—employing
ﬁner discretizations have been found to provide no further            A promising direction for future work is to extend the
improvements for the dataset under study. The estimated           hierarchical model presented to account for subject-speciﬁc
group-level trend is visualized in Fig. ",stat.ME,C,-0.050160576,-0.047259152,-0.16934724
http://arxiv.org/pdf/2202.01697v1,Power logit regression for modeling bounded data,"Moreover, PLreg provides procedures for choosing the extra parameter, when needed. We conclude this paper by outlining some interesting directions for further research. The power
logit regression models may be extended to accomodate situations in which the data include obser-
vations at the boundaries. ",stat.ME,B,0.16568406,-0.03483898,0.003921168
http://arxiv.org/pdf/2202.01748v1,Sequential Learning of the Topological Ordering for the Linear Non-Gaussian Acyclic Model with Parametric Noise,"Paper Contribution and Outline                                 single-cell gene expression data. Finally, we conclude with
                                                                    a summary of our ﬁndings and discussion of future work. Estimation approaches for LiNGAM include Shimizu et al. ",stat.ME,C,0.0013241265,-0.0041904487,-0.08021403
http://arxiv.org/pdf/2202.01748v2,Sequentially learning the topological ordering of causal directed acyclic graphs with likelihood ratio scores,"Section 3 presents simulation results for our procedure for
small and large-sized Bayesian networks, along with an application to single-cell gene expression
data. Finally, we conclude with a summary of our ﬁndings and discussion of future work. 1.3 Review of LiNGAM

We follow closely here the deﬁnition of a LiNGAM given by Shimizu et al. ",stat.ME,C,-0.18053311,-0.11462496,-0.15171131
http://arxiv.org/pdf/2202.01947v1,Model Averaging for Generalized Linear Models in Fragmentary Data Prediction,"Third, we assume the overall
model belongs to an exponential family which is still restrictive. The extension to more
general models deserves further study. References

 Akaike, H. (1970). ",stat.ME,C,-0.0033461265,-0.17539594,0.27905953
http://arxiv.org/pdf/2202.01962v1,Population Calibration using Likelihood-Free Bayesian Inference,"(2020a) for an analogous approach
to ABC. Such methods could be adapted to the population calibration context, but we leave that for
further research. Population calibration problems make up a growing proportion of the biological literature, as the
need for mechanistic approaches to accommodate variability becomes better understood (see for ex-
ample Brown et al. ",stat.ME,B,0.068387344,0.104612544,-0.14350344
http://arxiv.org/pdf/2202.01970v1,Identification of prognostic and predictive biomarkers in high-dimensional data with PPLasso,"The current
method is only dedicated to the analysis of continuous responses through ANCOVA type
models. However, it will be the subject of a future work to extend it to other challenging
contexts, such as classiﬁcation or survival analysis. Funding
This work was supported by the Association Nationale Recherche Technologie (ANRT). ",stat.ME,B,0.3031589,-0.053254716,-0.043489963
http://arxiv.org/pdf/2202.01970v2,Identification of prognostic and predictive biomarkers in high-dimensional data with PPLasso,"The current
method is only dedicated to the analysis of continuous responses through ANCOVA type
models. However, it will be the subject of a future work to extend it to other challenging
contexts, such as classiﬁcation or survival analysis. Funding

   This work was supported by the Association Nationale de la Recherche et de la Tech-
nologie (ANRT). ",stat.ME,B,0.3172006,-0.063084476,-0.040162623
http://arxiv.org/pdf/2202.02102v1,Decision curve analysis for personalized treatment choice between multiple options,"We suggest that the examined range of threshold values is reasonable for the
safety concerns of each treatment. The issue of single-arm studies in the congruent dataset
should be subject of further research. Models that include single arm studies in the meta-
analysis could be considered, although the risk of bias in the estimates they provide is not to
be underestimated. ",stat.ME,B,0.5193268,0.17325464,0.03327614
http://arxiv.org/pdf/2202.02239v2,"Posterior Representations for Bayesian Context Trees: Sampling, Estimation and Convergence","Although the BCT framework was originally developed for modelling and inference of discrete-
valued time series, it was recently used to develop general mixture models for real-valued time se-
ries, along with a collection of associated algorithmic tools for inference (Papageorgiou and Kon-
toyiannis, 2021). Extending the results presented in this work to that setting presents an inter-
esting direction of further research, motivated by important and timely practical applications. Acknowledgments

We are grateful to Georgia Gregoriou for providing us the spike train data of Section 5.2. ",stat.ME,C,-0.12367326,-0.25795588,-0.102141105
http://arxiv.org/pdf/2202.02311v1,Graphical criteria for the identification of marginal causal effects in continuous-time survival and event-history analyses,"The criterion is thus sufﬁcient for identiﬁability, and we conjecture
that necessary conditions analogous to Shpitser and Pearl (2008) will be difﬁcult to derive for
the general continuous-time case. In future work it will be interesting to generalise our results
to the extended local independence graphs of Mogensen and Hansen (2020) which are closed
under marginalisation and which can be obtained by projecting over unobservable processes. We have further formalised, and characterised graphically, the notion of independent censor-
ing, where we argued that inference for the uncensored case additionally requires causal valid-
ity with regard to an intervention that prevents censoring. ",stat.ME,B,0.15672886,-0.15457493,0.24705493
http://arxiv.org/pdf/2202.03241v1,Uncertainty in Grid Data: A Theory and Comprehensive Robustness Test,"Is it because key variables are prone to measurement errors? Whether the
results remain robust or not, the comprehensive robustness test provides more statistical
information than a statistical model using the dataset of only one grid cell speciﬁcation,
to encourage further research. The following section exempliﬁes the use of the test. ",stat.ME,B,0.17329423,0.17181939,0.010448646
http://arxiv.org/pdf/2202.03408v1,Sensitivity Analysis in the Generalization of Experimental Results,"The proposed framework allows for a less conservative as-
sessment of sensitivity, and allows researchers to transparently include their substantive priors into
the sensitivity analysis. We leave exploring the more explicit relationship between the proposed
bias decomposition approach and marginal sensitivity models for future work. A.3 Relaxing Bounds on στ2

We will discuss two examples of assumptions that researchers may wish to impose. ",stat.ME,B,0.21268325,-0.0107640475,0.2514542
http://arxiv.org/pdf/2202.03513v1,Causal survival analysis under competing risks using longitudinal modified treatment policies,"4 Illustrative application

4.1 Background on motivating study and data

To illustrate the proposed methods, we aim to answer the following question: what is the effect of invasive mechanical
ventilation (IMV) on acute kidney injury (AKI) among COVID-19 patients? This question has been recently identiﬁed
by an expert panel on lung–kidney interactions in critically ill patients (Joannidis et al., 2020) as an area in need of
further research. AKI is a common condition in the ICU, complicating about 30% of ICU admissions, and causing
increased risk of in-hospital mortality and long-term morbidity and mortality (Kes & Jukic´, 2010). ",stat.ME,B,0.26009166,0.06135563,-0.08454825
http://arxiv.org/pdf/2202.03560v1,Constructing Large Nonstationary Spatio-Temporal Covariance Models via Compositional Warpings,"In general, we show that the spatial and temporal warpings
can accurately characterize the nonstationary behavior of the processes, and can provide better
probabilistic predictions than conventional stationary models. There are several directions that can be considered for future work. First, in the article, we
only consider warping space and time separately, and any nonseparability of the processes is

                                                           18
Figure 4: Prediction standard errors for the years 2012, 2013 and 2014 (left to right). ",stat.ME,C,-0.10178308,-0.35859546,-0.12231071
http://arxiv.org/pdf/2202.03685v1,A Tale of Two Datasets: Representativeness and Generalisability of Inference for Samples of Networks,"Notably, an omnibus test of all population density eﬀects in Model 2 is
not signiﬁcant at conventional level (χ2 = 7.4, df = 3, P -val. = 0.06), so
whether population density in fact has an eﬀect—or whether we had found
the best possible way to model it—is questionable; we leave these questions
for future work, except to suggest that type of housing should be considered
for future data collection. Substantive interpretation We discuss results primarily from Model 1,
though Model 2 yields the same conclusions. ",stat.ME,B,0.16632086,0.008969789,0.12226401
http://arxiv.org/pdf/2202.03685v2,A Tale of Two Datasets: Representativeness and Generalisability of Inference for Samples of Networks,"Notably, an omnibus test of all population density eﬀects in Model 2 is
not signiﬁcant at conventional level (χ2 = 7.4, df = 3, P -val. = 0.06), so
whether population density in fact has an eﬀect—or whether we had found
the best possible way to model it—is questionable; we leave these questions
for future work, except to suggest that type of housing should be considered
for future data collection. Substantive interpretation We discuss results primarily from Model 1,
though Model 2 yields the same conclusions. ",stat.ME,B,0.16632086,0.008969789,0.12226401
http://arxiv.org/pdf/2202.03876v2,Multilevel Delayed Acceptance MCMC,"We show that
when we utilize the error model, we can achieve high effective sample sizes on the ﬁnest level, even
when a very crude approximation is employed as the coarsest model. Conclusions and future work
are discussed in Section 4. 2 Multilevel Delayed Acceptance

In this section we ﬁrst outline the theoretical foundations of vanilla Metropolis–Hastings based
MCMC [37, 25] and the Delayed Acceptance (DA) method proposed by Christen and Fox [8]. ",stat.ME,C,-0.1160215,-0.14029779,0.088211104
http://arxiv.org/pdf/2202.03876v3,Multilevel Delayed Acceptance MCMC,"We show that
when we utilize the error model, we can achieve high effective sample sizes on the ﬁnest level, even
when a very crude approximation is employed as the coarsest model. Conclusions and future work
are discussed in Section 4. 2 Multilevel Delayed Acceptance

In this section we ﬁrst outline the theoretical foundations of vanilla Metropolis–Hastings based
MCMC [37, 25] and the Delayed Acceptance (DA) method proposed by Christen and Fox [8]. ",stat.ME,C,-0.1160215,-0.14029779,0.088211104
http://arxiv.org/pdf/2202.03897v1,Inference from Sampling with Response Probabilities Estimated via Calibration,"Some authors suggest to ﬁrst estimate the response probabilities via MLE in order to bypass
the problem of extreme weights and then calibrate to further improve the eﬃciency of the
NWA estimator, see Haziza and Beaumont (2017), p.222. This goes beyond the scope of this
research and is the subject of future work. 9 Funding

This research was supported by the Swiss Federal Statistical Oﬃce. ",stat.ME,C,0.012858469,-0.17416698,0.08660877
http://arxiv.org/pdf/2202.04179v1,A Framework for the Time- and Frequency-Domain Assessment of High-Order Interactions in Brain and Physiological Networks,"[11] J. T. Lizier, N. Bertschinger, J. Jost, and M. Wibral,
 [2] D. S. Bassett and O. Sporns, Nature neuroscience 20,             “Information decomposition of target eﬀects from multi-
      353 (2017). source interactions: Perspectives on previous, current
                                                                      and future work,” (2018). [3] A. Bashan, R. P. Bartsch, J. W. Kantelhardt, S. Havlin,    [12] L. Faes, A. Porta, G. Nollo, and M. Javorka, Entropy
      and P. C. Ivanov, Nature communications 3, 1 (2012). ",stat.ME,B,0.06557403,-0.007588856,-0.10399614
http://arxiv.org/pdf/2202.04455v1,Core-periphery structure in networks: a statistical exposition,"There are a litany of
works which show consistency for community detection algorithms (Zhao et al., 2012; Amini
et al., 2013; Riolo and Newman, 2020), so perhaps these methods can be (carefully) extended
to CP structure. This is a valuable area for future work. 3.5.3 Hypothesis testing

In this sub-section we discuss some of the general challenges of hypothesis testing in networks
as well as some particular shortcomings of the existing methods in the CP literature. ",stat.ME,A,-0.08700274,0.21073872,-0.12793234
http://arxiv.org/pdf/2202.04744v1,Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap,"each run, a new dataset was generated and B posterior
samples were obtained for θ. The average time for the   In future work, we would like to tackle the challenges
generation of B samples is recorded for each method. posed by the optimisation step. ",stat.ME,C,-0.34071648,0.030179337,-0.09737157
http://arxiv.org/pdf/2202.04744v2,Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap,"each run, a new dataset was generated and B posterior
samples were obtained for θ. The average time for the   In future work, we would like to tackle the challenges
generation of B samples is recorded for each method. posed by the optimisation step. ",stat.ME,C,-0.34071648,0.030179337,-0.09737157
http://arxiv.org/pdf/2202.04744v3,Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap,"ship courtesy of the Biometrika Trust. TD acknowl-
                                                           edges support from a UKRI Turing AI Fellowship
In future work, we would like to tackle the challenges     [EP/V02678X/1]. TD and FXB were supported by
Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap

the Lloyd’s Register Foundation Programme on Data-            Bonassi, F. V. and West, M. (2015). ",stat.ME,C,-0.13536474,-0.095748305,-0.0369432
http://arxiv.org/pdf/2202.05370v1,Bayesian learning of COVID-19 Vaccine safety while incorporating Adverse Events ontology,"Therefore, Ageusia and Anosmia might be related to the
underlying disease rather than COVID-19 vaccines. Large epidemiological studies are needed to further study these
signals. We didn’t identify any enriched AE groups as there were only 8 safety signals using the negative control
approach. ",stat.ME,B,0.32380658,0.13294566,-0.032109775
http://arxiv.org/pdf/2202.05401v1,Multivariate distance matrix regression for a manifold-valued response variable,"So far, post-hoc analysis of MDMR tends to be done
on a situational basis, so post-hoc analysis for geometric-MDMR has yet to be
explored. A plausible candidate would be something like geodesic regression
Fletcher (2013), so the conjunction of these two methods opens an avenue for
further research. References

Aine, C. J., Bockholt, H. J., Bustillo, J. R., Can˜ive, J. M., Caprihan, A., Gas-
   parovic, C., Hanlon, F. M., Houck, J. M., Jung, R. E., Lauriello, J., Liu, J.,
   Mayer, A. R., Perrone-Bizzozero, N. I., Posse, S., Stephen, J. M., Turner,
   J. ",stat.ME,C,-0.01231239,-0.049900737,-0.073435366
http://arxiv.org/pdf/2202.05495v1,Inference for Projection-Based Wasserstein Distances on Finite Spaces,"The appropriate choice of the replacement number of the rescaled bootstrap or projection
dimension of the PRW distance is important in practice. Developing data-driven methods
to choose their values is an interesting direction for further research. References

 [1] Heinz H Bauschke, Patrick L Combettes, et al. ",stat.ME,A,-0.07199364,0.095191196,-0.1259846
http://arxiv.org/pdf/2202.06636v1,Bayesian semi-parametric inference for clustered recurrent events with zero-inflation and a terminal event/4163305,"However, a practical issue
of multi-state modeling in our case comes from the growing number of unknown parameters,
since we would need an additional set of coeﬃcients as well as more random eﬀects. This
could induce computational and inferential challenges, especially with a small sample size,
and merits additional investigation. 23
Supplementary Materials

Detailed MCMC algorithms and additional results are available as supplementary materials. ",stat.ME,C,-0.21787351,-0.2615397,-0.124645054
http://arxiv.org/pdf/2202.06636v2,Bayesian semi-parametric inference for clustered recurrent events with zero-inflation and a terminal event/4163305,"However, a practical issue
of multi-state modeling in our case comes from the growing number of unknown parameters,
since we would need an additional set of coeﬃcients as well as more random eﬀects. This
could induce computational and inferential challenges, especially with a small sample size,
and merits additional investigation. Another potential limitation is that we have not distin-
guished the terminal event survival processes for the susceptible and unsusceptible patient
subpopulations. ",stat.ME,B,0.21259135,-0.19252732,-0.13149232
http://arxiv.org/pdf/2202.07010v1,Statistical inference for intrinsic wavelet estimators of SPD matrices in a log-Euclidean manifold,"Constructing conﬁdence sets for this type of non-linear estimator is already
a non-trivial task in the classical Euclidean set-up of ﬁrst-generation wavelets
for scalar curves, the related literature is sparse (e.g., Chau and von Sachs
[2016], using Robins and Van Der Vaart [2006]). So although we believe that
our approach based on the bootstrap sets can be successfully applied to the
threshold wavelet estimator, we decided to leave this and further investigations
on this question for future work. Note, however, that as a ﬁrst theoretical step
into this direction, we were able to derive a Central Limit Theorem, analogous
to our Theorem 4.2, for the (whitened) empirical wavelet coeﬃcients (3.10). ",stat.ME,C,-0.23740652,-0.0466963,0.25244272
http://arxiv.org/pdf/2202.07205v1,Probabilistic Modeling Using Tree Linear Cascades,"We conclude with a simple         The hypothesis of Lemma 5 corresponds to the conclusion
data-based example demonstrating that the quantities involved
are easy to compute. of Lemma 12.

      a) Limitations and future work: The upside of tree          Lemma 5: Let T be a tree on {1, 2, . . ",stat.ME,A,-0.010292085,0.20883894,0.11261667
http://arxiv.org/pdf/2202.07963v2,Self-Organizing Maps for Exploration of Partially Observed Data and Imputation of Missing Values,"A numerical study assesses the
good performance of missSOM regarding various criteria and in comparison to the state of the art. While this paper focuses on the standard Kohonen algorithm, in future work we may address the
transfer of our approach to other existing variants of self-organizing maps on more complex data
types such as mixed data to enable them to deal with missing data. 6. ",stat.ME,A,-0.13863218,0.1914146,-0.41380703
http://arxiv.org/pdf/2202.08062v1,"Where the Model Frequently Meets the Road: Combining Statistical, Formal, and Case Study Methods","Part of my message is that the specifics of how a central bank is
embedded in a larger political system matter a great deal, and for this reason my analysis is
unlikely to generalize to other countries in a straightforward way” (Lohmann, 1998:445). Lohman goes on to suggest specific reasons why her theory is more applicable to the developed
countries than to the developing countries, and calls for further research on this subject. She
arrives, in short, at a well-defined contingent generalization that identifies the scope conditions
of her theory and the population to which it best applies. ",stat.ME,B,0.020731702,0.027102198,0.064761356
http://arxiv.org/pdf/2202.08368v1,Posterior Predictive Propensity Scores and $p$-Values,"It ensures that
we can use PPPdr as a standard frequentist’s p-value for testing the weak null hypothesis
of τ = 0. We leave the proof of the conjecture to future work. 5.3 Epilogue: Did Rosenbaum and Rubin (1983) mention the Bayesian
      propensity score? ",stat.ME,B,0.08700276,0.060695425,0.2343829
http://arxiv.org/pdf/2202.08579v1,A note on switching eigenvalues under small perturbations,"Recommendations on
possible actions for when switching occurs are given in Section 5. Finally, a discussion and future work are considered
in Section 6. 2 Principal Component Analysis

The aim of dimension reduction methods, like PCA, is to explain most of the variability in high-dimensional data in just
a few summary measures, without much loss of information. ",stat.ME,A,-0.0055460706,0.029406592,-0.25935522
http://arxiv.org/pdf/2202.08728v1,Locally private nonparametric confidence intervals and sequences,"The pseudo-outcomes pftq8t“1 stem from inverse
probability weighting [44, 45] — a standard technique from causal inference. This section on A/B
testing can likely be adapted to a more thorough locally private causal setup with observational
(rather than experimental) data using the potential outcomes framework [46] but we leave this as an
interesting direction for future work. A/B testing the weak null. ",stat.ME,B,0.27947628,0.15270048,0.19828814
http://arxiv.org/pdf/2202.09164v1,"Triangulating Instrumental Variable, confounder adjustment and Difference-in-Difference methods for comparative effectiveness research in observational data","Our heterogeneity analysis showed good agreement
between all causal estimates except the PSM and CaT approaches. In future work, we plan
to apply the same causal framework to model alternative T2D outcomes such as HbA1c. We also plan to extend the approach to ﬁt alternative models that allow for causal eﬀect
heterogeneity, so that they may be used in personalised medicine. ",stat.ME,B,0.47263205,-0.072150536,-0.038065728
http://arxiv.org/pdf/2202.09164v2,"Triangulating Instrumental Variable, confounder adjustment and Difference-in-Difference methods for comparative effectiveness research in observational data","As future work we hope
to better understand when this will be the case. As further research, we plan to develop a rigorous hierarchical testing procedure for per-
forming a similarity analysis across an arbitrary number of estimates, whilst controlling the
overall family wise error rate. Another approach for combining IV and DiD approaches has
recently been proposed by Ye et al. ",stat.ME,A,0.050990622,0.254447,-0.046984583
http://arxiv.org/pdf/2202.09168v1,Preferential Sampling for Bivariate Spatial Data,"In this regard, recent work (Virhs et al., 2021) introduces spatial aggregation to a
Gibbs process using a GP and oﬀers the possibility of further PS investigation. Another path
for future work involves spatio-temporal response data collection, opening the potential of
spatial bias varying over time in the data collection. This would lead to space-time geosta-
tistical modeling and space-time point pattern intensities using shared space-time GPs. ",stat.ME,C,-0.1877369,-0.22818187,-0.32550836
http://arxiv.org/pdf/2202.09448v1,Monte Carlo Sensitivity Analysis for Unmeasured Confounding in Dynamic Treatment Regimes,"Direct-search or
value-search estimators are an alternative approach to estimating DTRs that our proposed
method could not be directly applied to (Orellana et al., 2010; Laber and Zhao, 2015). We
leave extensions to direct-search estimators as future work. Acknowledgments

This work was supported by the National Institute of Mental Health of the National Institutes
of Health under Award Number R01 MH114873. ",stat.ME,B,0.23998111,0.029178532,-0.031419806
http://arxiv.org/pdf/2202.09451v1,Using Pilot Data to Size Observational Studies for the Estimation of Dynamic Treatment Regimes,"Our proposed method is also reliant on having access to pilot data which are not always
available. Sizing a study without pilot data would require much stronger assumptions about
the underlying generative model, which we leave as future work. Acknowledgments

Research reported in this publication was supported by the National Institute of Mental
Health of the National Institutes of Health under Award Number R01 MH114873. ",stat.ME,B,0.28431612,0.14683789,-0.1805292
http://arxiv.org/pdf/2202.09611v1,Estimating Individualized Treatment Rules in Longitudinal Studies with Covariate-Driven Observation Times,"Finally, our method requires the standard assumptions for one-stage re-
peated measures ITRs, i.e., treatment eﬀects should be acute and there should be
no antagonistic or synergistic eﬀect due to previous treatments aﬀecting the current
one.9 Although it is not certain that these assumptions were met in our illustration
using CPRD data, most subsequent weight measurements were taken far apart in
time, reducing the chances of a carryover eﬀect from a previous treatment. In future work, we aim to extend the proposed methodology to the more complex
setting of the more traditional, multiple stage DTRs using dWOLS. In that setting,
dWOLS has great advantages as it can incorporate weights that are cumulated over
time (similarly to marginal structural models). ",stat.ME,B,0.18848753,-0.047142163,-0.09677276
http://arxiv.org/pdf/2202.09723v1,Smooth multi-period forecasting with application to prediction of COVID-19 cases,"We
illustrate the beneﬁts of smoothing in the context of multi-period forecasting through a small
simulation as well as on an example using county-level COVID-19 incident cases. There remains additional opportunity for future work. In the current study, we consider a limited
set of predictors: cases, estimated percentage of people experiencing COVID-like illness, and the
proportion of people reporting illness in their local community. ",stat.ME,B,0.22186562,-0.3012903,-0.119062506
http://arxiv.org/pdf/2202.09993v1,Weakly informative priors and prior-data conflict checking for likelihood-free inference,"Our approach to making the computations tractable in our conﬂict checks and in searching
for weakly informative priors uses Gaussian mixture approximations to posterior distributions
and this may be rather crude, particularly with high-dimenisonal parameters or summary
statistics. While rough calculations may be good enough for diagnostics and exploring al-
ternative prior speciﬁcations, an interesting direction for future work is to investigate better
approaches to the likelihood-free inference while still allowing the repeated calculation of
posterior densities for diﬀerent data that is necessary here. Acknowledgements

We thank Anne Presanis for her comments on an earlier version of this manuscript. ",stat.ME,C,-0.058754433,-0.19088057,0.06454774
http://arxiv.org/pdf/2202.10007v1,Statistical Inference for Genetic Relatedness Based on High-Dimensional Logistic Regression,"By carefully analyzing the logistic
Lasso estimator, we develop a novel weighted debiasing method and propose computationally
eﬃcient debiased estimators for these functionals. We further study their rates of convergence and
obtain their asymptotic normality under mild theoretical conditions. Moreover, conﬁdence intervals
and statistical tests for these functionals are constructed. ",stat.ME,C,-0.1206282,-0.09817098,0.22336397
http://arxiv.org/pdf/2202.10007v2,Statistical Inference for Genetic Relatedness Based on High-Dimensional Logistic Regression,"By carefully analyzing the logistic
Lasso estimator, we develop a novel weighted debiasing method and propose computationally
eﬃcient debiased estimators for these functionals. We further study their rates of convergence and
obtain their asymptotic normality under mild theoretical conditions. Moreover, conﬁdence intervals
and statistical tests for these functionals are constructed. ",stat.ME,C,-0.1206282,-0.09817098,0.22336397
http://arxiv.org/pdf/2202.10361v1,A Predictive Approach to Bayesian Nonparametric Survival Analysis,"However, the predictive distribution when
Yk+1:n is marginalized is not tractable, which is why we introduce the sequential Monte Carlo scheme in our
paper. Eliciting the marginalized predictive directly would be an interesting avenue of future work. Edwin Fong, Brieuc Lehmann

B METHODOLOGY

B.1 Predictive Resampling in the Uncensored Case

Predictive resampling for the uncensored case, as described in Fong et al. ",stat.ME,C,-0.09185809,-0.14130506,-0.0035046162
http://arxiv.org/pdf/2202.10513v1,Quantifying Uncertainty for Temporal Motif Estimation in Graph Streams under Sampling,"We also evaluate the true coverage probability of
the conﬁdence interval using real data for a variety of motifs. There are two interesting directions for future work. One is to study the asymp-
totics of the temporal motif estimator under other sampling models, e.g., the subwin-
dow sampling regime in [19] and [32], where smaller time intervals are sampled from
the graph streams, and exact motif counts in the sampled time intervals are used to
estimate the total counts. ",stat.ME,C,-0.12729594,0.010657949,0.048661005
http://arxiv.org/pdf/2202.10887v1,Policy Evaluation for Temporal and/or Spatial Dependent Experiments in Ride-sourcing Platforms,"Recently, Reich et al. (2020) gave a systematical review of various sta-
tistical models for spatial causal inference and pinpoint some areas of future work. In particular,
Reich et al. ",stat.ME,B,0.19863348,-0.20521304,0.0052522793
http://arxiv.org/pdf/2202.10887v4,Policy Evaluation for Temporal and/or Spatial Dependent Experiments in Ride-sourcing Platforms,"Finally, statistical inference for deep neural
networks remains an open problem. This would be a meaningful work that can pave the way of using
deep learning in causal inference which we leave as the future work. References

Alonso-Mora, J., Samaranayake, S., Wallar, A., Frazzoli, E. and Rus, D. (2017) On-demand high-
  capacity ride-sharing via dynamic trip-vehicle assignment. ",stat.ME,B,0.051066466,-0.16321968,-0.12065194
http://arxiv.org/pdf/2202.11031v2,A Unified Nonparametric Test of Transformations on Distribution Functions with Nuisance Parameters,"Finally, we apply the proposed test with the age data sets to demonstrate its applica-
tion in practice. Extensions of our uniﬁed framework to testing other problems with nuisance
parameters may deserve further study. References

Alba, M., Barrera, D., and Jim´enez, M. (2001). ",stat.ME,B,0.2062687,0.26953432,0.034863397
http://arxiv.org/pdf/2202.11258v1,"Many processors, little time: MCMC for partitions via optimal transport couplings","6 CONCLUSION

5.3 Faster Meeting With OT Couplings                         We demonstrated how to eﬃciently couple partition-
                                                             valued Gibbs samplers using optimal transport – to
Next we show that meeting times with our OT coupling         take advantage of parallelism for improved estimation. on partitions are faster than with label-based coupling      Multiple directions show promise for future work. E.g.,
using maximal [Jerrum, 1998] and common random               while we have used CPUs in our experiments here,
number generator (common RNG) [Gibbs, 2004]. ",stat.ME,C,-0.2953776,-0.11077981,-0.10525968
http://arxiv.org/pdf/2202.11557v1,Single Gaussian Process Method for Arbitrary Tokamak Regimes with a Statistical Analysis,"It is important to note

                                                        22
that even the worst ﬁts provided by our proposed methods result in smooth, reasonable ﬁts
to the data and are robust. In future work, we will continue to reﬁne these methods as we apply them to experimental
data in a similar statistical manor. When working with experimental data, however, we do
not have the luxury of knowing the nature of the true proﬁle. ",stat.ME,A_centroid,-0.13498658,0.13269638,0.159055
http://arxiv.org/pdf/2202.11612v1,Testing Granger Non-Causality in Panels with Cross-Sectional Dependencies,"Finally, we emphasize that the p-value aggregation method we employ is
a general approach and does not depend on the speciﬁc generation process. Therefore, this method could be applied in other applications or causal discovery
methods for panel data (e.g., on non-time series data), which remains an exciting
avenue for further research. References

C. Angermueller, T. Pärnamaa, L. Parts, and O. Stegle. ",stat.ME,B,0.10105604,-0.06314632,-0.018340696
http://arxiv.org/pdf/2202.12234v1,Policy Learning for Optimal Individualized Dose Intervals,"In order to do so, extra assumptions have to be
made. It would be an interesting future work if better rates under weaker assumptions can be achieved. Guanhua Chen, Xiaomao Li, Menggang Yu

Corollary C.0.3. ",stat.ME,C,-0.14835575,0.027987337,0.28796852
http://arxiv.org/pdf/2202.12263v1,Effect Identification in Cluster Causal Diagrams,"These results are critical in establishing the foundations
                                                              1  for C-DAGs and enabling their use in ways comparable
                                                                 to causal diagrams. Having introduced the proper deﬁni-
An additional example of identiﬁcation of causal effects in      tion and corresponding inferential machinery for C-DAGs,
C-DAGs with clustered treatments and outcomes is shown           some future work include the non-trivial task of develop-
in Appendix ? ?. ",stat.ME,B,0.30661616,0.039924487,-0.018739793
http://arxiv.org/pdf/2202.12346v1,Flexible multivariate spatio-temporal Hawkes process models of terrorism,"We believe that location errors are likely to vary across space and/or
time as a function of population, economic development, etc. As such, a more general model of the spatial
error is necessary for these applications and we leave this for our future work. Funding

The authors acknowledge support by NSF DMS-1925119 and DMS-2123247. ",stat.ME,C,-0.05615284,-0.020986907,-0.056088865
http://arxiv.org/pdf/2202.12346v2,Flexible multivariate spatio-temporal Hawkes process models of terrorism,"We believe that location errors are likely to vary across space and/or
time as a function of population, economic development, etc. As such, a more general model of the spatial
error is necessary for these applications and we leave this for our future work. 19
Funding

The authors acknowledge support by NSF DMS-1925119 and DMS-2123247. ",stat.ME,C,-0.05498881,-0.0175733,-0.054590974
http://arxiv.org/pdf/2202.12347v1,Multiple multi-sample testing under arbitrary covariance dependency,"In this way, we have provided a more detailed analysis for both lung cancer subtypes than previous
studies. There are several potential directions for further research. First, it might be captivating to consider diﬀerent supervised learning
methods (for instance, a neural network with more than one layer) instead of the multinomial regression model proposed in
this paper. ",stat.ME,B,0.13199559,-0.00014825165,-0.30618227
http://arxiv.org/pdf/2202.12352v1,Bayesian Model Averaging of Chain Event Graphs for Robust Explanatory Modelling,"the HAC algorithm in Cowell and Smith [2014]. In
the non-stratiﬁed example, the MAP CEG identiﬁed            The problem of eﬃcient model selection for CEGs
by the w-HAC algorithm was the CEG of the data           is an open one with further research needed. We hope
generating process, as was the case for HAC. ",stat.ME,C,-0.23034519,0.029410183,-0.09618774
http://arxiv.org/pdf/2202.12445v1,Ensemble Method for Estimating Individualized Treatment Effects,"Other factors to explore include the
role of sample size and the number of candidate models K; when the sample size is small
or the library of candidate models K is large, we suspect that the extra capacity control
in causal stacking will help to control overﬁtting the validation set. Another interesting
direction for future work is to explore more sophisticated ensembling techniques, including
causal variants of boosting and bagging. References

Ahmed Alaa and Mihaela Van Der Schaar. ",stat.ME,B,0.07227114,-0.027559288,-0.09372759
http://arxiv.org/pdf/2202.12445v2,Ensemble Method for Estimating Individualized Treatment Effects,"Other factors to explore include the
role of sample size and the number of candidate models K; when the sample size is small
or the library of candidate models K is large, we suspect that the extra capacity control
in causal stacking will help to control overﬁtting the validation set. Another interesting
direction for future work is to explore more sophisticated ensembling techniques, including
causal variants of boosting and bagging. References

Ahmed Alaa and Mihaela Van Der Schaar. ",stat.ME,B,0.07227114,-0.027559288,-0.09372759
http://arxiv.org/pdf/2202.12540v1,Familial Inference,"A test of hypotheses (4.2) is
necessarily more conservative than a test of (4.1) since the former null encompasses the latter. We do not pursue (4.2) further in this paper and leave it as the subject of future work. Testing either of these hypotheses requires bootstrapping the families of X and Y with
independently drawn weights. ",stat.ME,A,0.016364591,0.2181648,0.31063867
http://arxiv.org/pdf/2202.12851v1,Boosting Distributional Copula Regression,"Finally,
parameter shrinkage induced by boosting in particular suits prediction setups like in delivery
management scenarios. We conclude with a thorough discussion and further research ideas
concerning boosted copula regression models in the ’Conclusion’. 2 Distributional Copula Regression Models

In this section, we ﬁrst review structured additive distributional copula regression models
along the lines of Klein and Kneib (2016) and introduce speciﬁc examples of marginal distri-
butions and copula speciﬁcations that are relevant for our simulations and application in the
sections ’Simulations’ and ’Analysis of Fetal Ultrasound Data’. ",stat.ME,B,0.13583286,-0.2408,-0.020807195
http://arxiv.org/pdf/2202.13415v1,Conformal prediction beyond exchangeability,", tn+1),
       as in the distribution drift settings described above. We leave a detailed investigation of the pros and cons of data dependent weights as
an open question for future work. 6 Experiments

In this section, we will examine the empirical performance of non-exchangeable full
conformal prediction, adding the new weights and allowing for a non-symmetric
algorithm, against the original full conformal method.3 We will see that adding
weights enables robustness against changes in the data distribution (i.e., better
coverage), while allowing for a non-symmetric algorithm enables shorter prediction
intervals. ",stat.ME,C,-0.23657444,-0.10536036,0.07492938
http://arxiv.org/pdf/2202.13415v2,Conformal prediction beyond exchangeability,", tn+1),
       as in the distribution drift settings described above. We leave a detailed investigation of the pros and cons of data dependent weights as
an open question for future work. 6 Experiments

In this section, we will examine the empirical performance of non-exchangeable full
conformal prediction, adding the new weights and allowing for a non-symmetric
algorithm, against the original full conformal method.3 We will see that adding
weights enables robustness against changes in the data distribution (i.e., better
coverage), while allowing for a non-symmetric algorithm enables shorter prediction
intervals. ",stat.ME,C,-0.23657444,-0.10536036,0.07492938
http://arxiv.org/pdf/2202.13415v3,Conformal prediction beyond exchangeability,", tn+1 ,

                  i=1

                       22
where now the ith term on the right-hand side is the total variation distance between
the conditional distributions of Z and Zi, conditioning on the weights and tags. We
leave a more detailed investigation of data dependent weights for future work. Are these results assuming the data is approximately exchangeable? ",stat.ME,C,-0.08578882,-0.011861214,0.14546686
http://arxiv.org/pdf/2203.00053v1,Fast Bayesian estimation of brain activation with cortical surface and subcortical fMRI data using EM,"Results from a study of the HCP data are
shown in section 4. We end with conclusions and discussion of future work in section 5. 2 Methodology

Consider cs-fMRI or subcortical fMRI data from a scan, represented as Yt ∈ RN for times t = 1, . ",stat.ME,A,0.04114957,0.18597165,-0.059392363
http://arxiv.org/pdf/2203.00062v1,Robust Causal Inference of Drug-drug Interactions,43. Han P. A further study of propensity score calibration in missing data analysis. Stat Sin. ,stat.ME,B,0.3855286,0.09923074,-0.074875094
http://arxiv.org/pdf/2203.00062v2,Robust Causal Inference of Drug-drug Interactions,44. Han P. A further study of propensity score calibration in missing data analysis. Stat Sin. ,stat.ME,B,0.38088977,0.09771603,-0.06658938
http://arxiv.org/pdf/2203.00132v1,On Testability and Goodness of Fit Tests in Missing Data Models,"The following weighted      Rk ⊥⊥ X k | R≺k, X≺∗ k. Note however, that as we proceed
                                                                with the tests, we are restricted to fewer and fewer samples
estimating equation then yields an unbiased estimator for       which impacts the power of our tests. Although weighting
                                                                approaches are common in missing data models [Li et al.,
βra1 wrt the observed data law:                                 2013], an interesting direction for future work is to develop
                                                                semiparametric methods to use data more efﬁciently. Pn         R2 × R3                     × U (βra ) = 0,

       p(R2 | paG(R2)) × p(R3 | paG(R3))         1

where propensity score of R3, p(R3|R1, R2, X1∗, X2∗),           4.2 SEQUENTIAL MNAR MODELS
can be ﬁt using just observed data, denote it with
                                                                We call a missing data model a sequential MNAR model if
Wr3 (βr3 ). ",stat.ME,B,0.119516805,-0.052449577,0.059343025
http://arxiv.org/pdf/2203.00161v1,On Testability of the Front-Door Model via Verma Constraints,"We also include baseline co-                            for future work is to investigate whether the pre-tests them-
variates C containing age, sex, BMI, and past history of                             selves can be made doubly robust. We have also proposed
                                                                                     scenarios in which both the front-door and IV assumptions
     3The non-parametric test is evaluated with data sets where the                  hold, which we hope leads to future work on combining
relations between variables are non-linear. estimates between the two models. ",stat.ME,B,0.4413774,0.047957942,0.06617932
http://arxiv.org/pdf/2203.00161v2,On Testability of the Front-Door Model via Verma Constraints,"Bhattacharya et al. [2020]
have designed doubly robust semiparametric estimators for
the average causal effect in these scenarios – a direction
for future work is to investigate whether the pre-tests them-
References                                                      Isabel R. Fulcher, Ilya Shpitser, Stella Marealle, and Eric J.
                                                                  Tchetgen Tchetgen. Robust inference on population in-
Claudio Agostinelli and Marianthi Markatou. ",stat.ME,B,0.3065607,-0.089730725,0.28067678
http://arxiv.org/pdf/2203.00229v1,Fitting a Stochastic Model of Intensive Care Occupancy to Noisy Hospitalization Time Series,"In general, due to some level of underreporting in the data, it is safer to

                                                                     15
                                                                                                       A PREPRINT - MARCH 2, 2022

treat our results as slight underestimates of the average per-patient ICU stay. Nonetheless, our validation study using
model-based simulation is encouraging, and future work may explore observation models under various emission
distributions to directly model the effect of under-reporting. In models developed to forecast hospital occupancy during the COVID-19 pandemic, it is common to obtain parameter
estimates using knowledge from other regions. ",stat.ME,B,0.30958727,-0.20574205,-0.1276618
http://arxiv.org/pdf/2203.00229v2,Fitting a stochastic model of intensive care occupancy to noisy hospitalization time series during the COVID-19 pandemic,"In general, due to some level
of underreporting and noise in the data, it is safer to treat our results as slight underestimates of the average per-
patient ICU stay. Nonetheless, our validation study using model-based simulation is encouraging, and future work
may explore observation models under various emission distributions to directly model the effect of under-reporting. In models developed to forecast hospital occupancy during the COVID-19 pandemic, it is common to obtain parameter
estimates using knowledge from other regions. ",stat.ME,B,0.29798156,-0.20539033,-0.12407778
http://arxiv.org/pdf/2203.00820v1,Partial Likelihood Thompson Sampling,"This may be
a reasonable assumption for experiments run on the order of months; however, for longer
experiments, it may be necessary to extend the model to allow for waning eﬀectiveness. We
leave extensions to non-constant eﬃciency to future work. One major advantage of the proportional hazards model is that it enables a simple
approach to learning the eﬃciency parameters θk via partial likelihood [Cox, 1972, 1975,
Efron, 1977], as follows. ",stat.ME,B,0.14735672,-0.36158764,0.121237956
http://arxiv.org/pdf/2203.00820v2,Partial Likelihood Thompson Sampling,"However, for longer experiments, it may
be necessary to extend the model to allow for waning eﬃciency. We leave extensions to
non-constant eﬃciency to future work. One major advantage of the proportional hazards model is that it enables a simple
approach to learning the eﬃciency parameters θk via partial likelihood [Cox, 1972, 1975,
Efron, 1977], as follows. ",stat.ME,B,0.11694826,-0.36294407,0.10351658
http://arxiv.org/pdf/2203.00840v1,Flood hazard model calibration using multiresolution model output,"At 50 m resolution,
each model run contains observations at 14,214 locations, and at 10 m resolution, each
model run contains observations at 126,791 locations. To focus on tackling the issue of
calibration with multiple resolutions of model runs, we save the problem of treating
high dimensional spatial data for future work. For now, we simplify the model output
FLOOD HAZARD MODEL MULTIRESOLUTION CALIBRATION                                                                            14

by summarizing how it diﬀers from the observation in a scalar summary statistic:

Euclidean distance. ",stat.ME,C,-0.094576985,-0.19589913,-0.1914404
http://arxiv.org/pdf/2203.00840v2,Flood hazard model calibration using multiresolution model output,"At 50 m resolution,
each model run contains observations at 14,214 locations, and at 10 m resolution, each
model run contains observations at 126,791 locations. To focus on tackling the issue of
calibration with multiple resolutions of model runs, we save the problem of treating
high dimensional spatial data for future work. For now, we simplify the model output
FLOOD HAZARD MODEL MULTIRESOLUTION CALIBRATION                                                                            13

by summarizing how it diﬀers from the observation in a scalar summary statistic:

Euclidean distance. ",stat.ME,C,-0.09536173,-0.19253913,-0.19524434
http://arxiv.org/pdf/2203.00840v3,Flood hazard model calibration using multiresolution model output,"In future research, we plan on either switching our focus to a river with more
observations available or making use of citizen science in Selinsgrove to obtain real
observations. We also plan on varying the ratio of expensive to cheap computer model
model runs in future work to explore how the emulation and calibration results change. Perhaps there is a model-speciﬁc ‘best’ ratio for calibration. ",stat.ME,C,-0.061570346,-0.068823405,-0.10401385
http://arxiv.org/pdf/2203.01761v2,Doubly Robust Calibration of Prediction Sets under Covariate Shift,"Notably, the
proposed methods readily extend to accommodate such sensitivity analysis via a slight modiﬁcation of our
procedure to incorporate a sensitivity parameter, without compromising the product bias or double robust-
ness property of the approach. Fully developing prediction inference for this sensitivity analysis framework
however requires care in estimation of nuisance functions which, due to space limitation, we plan to consider
in future work. Overall, this paper reveals and leverages deep connections between modern literatures of
semiparametric theory, missing data and causal inference, and emerging methods for well-calibrated pre-
diction inference. ",stat.ME,B,0.13618791,-0.118898295,0.09014024
http://arxiv.org/pdf/2203.01761v3,Doubly Robust Calibration of Prediction Sets under Covariate Shift,"Notably, the
proposed methods readily extend to accommodate such sensitivity analysis via a slight modiﬁcation of our
procedure to incorporate a sensitivity parameter, without compromising the product bias or double robust-

                                                                     22
ness property of the approach. Fully developing prediction inference for this sensitivity analysis framework
however requires care in estimation of nuisance functions which, due to space limitation, we plan to consider
in future work. Overall, this paper reveals and leverages deep connections between modern literatures of
semiparametric theory, missing data and causal inference, and emerging methods for well-calibrated pre-
diction inference. ",stat.ME,B,0.14814505,-0.0961808,0.09073165
http://arxiv.org/pdf/2203.02090v1,Bayesian community detection for networks with covariates,"We also apply our model to two data examples in Section 4. We conclude
in Section 5 with possiblities for future work. 2. ",stat.ME,C,-0.03194242,-0.069210224,0.15190628
http://arxiv.org/pdf/2203.02234v1,Cluster-Robust Estimators for Bivariate Mixed-Effects Meta-Regression,"They propose the use of

                                                18
approximately inverse variance weights, based on these working models. An open question that requires further research is what the best testing

procedure is when the number of studies k is no greater than around ﬁve. Neither the adjusted Hotelling’s T 2 approach in combination with Zhang’s
estimator for the degrees of freedom, which was recommended by Tipton and
Pustejovsky (2015), nor the naive or adjusted F -tests used in our simulations
seem to be the ideal approach. ",stat.ME,B,0.14156255,0.20054707,0.19853172
http://arxiv.org/pdf/2203.02249v1,Dependence structure for the product of bi-dimensional finite-variance VAR(1) model components. An application to the cost of electricity load prediction errors,"Thus, it is stationary in the weak sense. Therefore, in the further analysis it will be denoted
as ACVFY (h). 4. ",stat.ME,C,-0.18245059,0.04438021,0.17042261
http://arxiv.org/pdf/2203.02268v1,Variance Reduction for Metropolis-Hastings Samplers,"Since we have never encountered
a case in which variance increases, we feel that there is strong evidence that our method is risk-free at least
for posterior densities up to 100 dimensions. There are many directions for future work. We limited ourselves to the simplest case of function
F (x) = x(j) but higher moments and indicator functions seem interesting avenues to be investigated next. ",stat.ME,C,-0.2122702,-0.1952821,0.24185714
http://arxiv.org/pdf/2203.02398v1,Curvature and Torsion estimation of 3D functional data: A geometric approach to build the mean shape under the Frenet Serret framework,"This example shows the interest of a method
for estimating the mean geometry as well as the mean shape. These additional estimates and
information could be used in a complex model of variance analysis (e.g., Backenroth et al., 2018)
and this would be an interesting direction to explore for future work. 24
References

Absil, P.-A., R. Mahony, and R. Sepulchre (2010). ",stat.ME,C,-0.1483691,-0.091895215,0.051324777
http://arxiv.org/pdf/2203.02560v1,Improving sandwich variance estimation for marginal Cox analysis of cluster randomized trials,"While
this more complex formulation of paired estimating equations can be of substantial interest,
we are currently not aware of any statistical packages that implement this approach, per-
haps due to the associated computationally challenges when the cluster sizes are relatively
large (which is common in CRTs). In future work with the paired estimating equations, an
additional useful direction is to develop bias-corrections for the correlation estimating equa-
tions, similar to the matrix-adjusted estimating equations proposed by Preisser et al. (2008). ",stat.ME,A,-0.040086433,0.0011459148,-0.058111858
http://arxiv.org/pdf/2203.02560v2,Improving sandwich variance estimation for marginal Cox analysis of cluster randomized trials,"While this
more complex formulation of paired estimating equations can be of substantial interest, we
are currently not aware of any statistical packages that implement this approach, perhaps
due to the associated computational challenges when the cluster sizes are relatively large
(which is not uncommon in CRTs). In future work with the paired estimating equations,
an additional useful direction is to develop bias-corrections for the correlation estimating
equations, similar to the matrix-adjusted estimating equations proposed by Preisser et al. (2008). ",stat.ME,A,-0.04889531,-0.0250562,-0.099651314
http://arxiv.org/pdf/2203.02709v1,Wasserstein Distance-based Spectral Clustering with Application to Transaction Data,"An alternative solution
involves integrating various information using multivariate ECDFs with multidimensional
Wasserstein distance. Second, we consider the generalization of WSC as another interesting
future work. Besides transaction data, the proposed method can also be applied in other
ﬁelds. ",stat.ME,C,-0.11882178,-0.109061465,-0.15699631
http://arxiv.org/pdf/2203.03020v1,Optimal regimes for algorithm-assisted human decision-making,"(2021) could have diﬀerent properties
than those from Cui and Tchetgen Tchetgen (2021b). We will study properties of diﬀer-
ent classes of estimators in future work. 12

   Finally, there exist results on optimal regime identiﬁcation in settings where conditional
outcome means are only partially identiﬁed (Pu and Zhang, 2021; Cui and Tchetgen,
2021; Cui, 2021). ",stat.ME,B,0.11856258,-0.15724295,0.31069055
http://arxiv.org/pdf/2203.03523v1,A Single Index Model for Longitudinal Outcomes to Optimize Individual Treatment Decision Rules,"There are several avenues for future research on the use of a Kullback-Leibler divergence to deﬁne treatment decision
rules. For example, future work will focus on developing efﬁcient and faster algorithms for implementing the LS-KLD
TDR with variable selection. Extensions will also investigate the use of more ﬂexible nonparametric link functions, i.e.,
consider a smooth function h of the biosignature h(αTx) in (1), as is done in the SIMML model [Park et al., 2020] and
incorporating functional predictors into the TDR [e.g., Ciarleglio et al., 2015, Park et al., 2021]. ",stat.ME,B,0.05866485,-0.12619253,-0.021112332
http://arxiv.org/pdf/2203.03532v1,E-detectors: a nonparametric framework for online changepoint detection,"The SR e-detector uses the sum (across time) of the minimum wealth (across P at each time),
though it could use the amount that this wealth exceeds n, which is the total dollar amount invested up to
time n. The CUSUM e-detector uses the max-min wealth; the maximum (across time) of the minimum
wealth (across P ). These are, of course, only two ways of constructing e-detectors, and we leave other
constructions to future work. Future directions. ",stat.ME,A,-0.16973509,0.20877519,-0.030086711
http://arxiv.org/pdf/2203.03960v1,Data fusion of distance sampling and capture-recapture data,"For another example, if the underlying
intensity function is a function of the distance from the transect, the underlying
point process is confounded with the detection process. Accounting for such
confounding of the underlying intensity and the detection/capture probability
is an area that needs further research. In most situations, we can avoid such
confounding during the design of the surveys. ",stat.ME,C,-0.0075148195,0.087559864,0.106705695
http://arxiv.org/pdf/2203.04454v1,Statistical Depth for Point Process via the Isometric Log-Ratio Transformation,"In Section 4, we will apply the new depth to a real world dataset to demonstrate its
effectiveness in characterization of typical patterns. Finally, we will summarize our study and provide future work in
Section 5. All mathematical details are shown in appendices. ",stat.ME,A,-0.16569373,0.13385107,-0.17910393
http://arxiv.org/pdf/2203.04582v1,Concave likelihood-based regression with finite-support response variables,"For
example, it may be informative to consider asymptotics where the length of the censoring
intervals is allowed to change with the sample size and the number of parameters. Additionally,
several special cases of the models considered herein are also of signiﬁcant interest in their
own right, and may hence merit further study. As noted in Section 3, more informative
high-dimensional convergence bounds can likely be obtained for special cases. ",stat.ME,C,-0.046434876,-0.20171925,0.28456646
http://arxiv.org/pdf/2203.04582v2,Concave likelihood-based regression with finite-support response variables,"For

                                                          25
example, it may be informative to consider asymptotics where the length of the censoring
intervals is allowed to change with the sample size and the number of parameters. Additionally,
several special cases of the models considered herein are also of signiﬁcant interest in their
own right, and may hence merit further study. As noted in Section 3, more informative
high-dimensional convergence bounds can likely be obtained for special cases. ",stat.ME,C,-0.02973872,-0.18471077,0.30184188
http://arxiv.org/pdf/2203.04602v1,Factor-augmented model for functional data,"It is easy to see that Snp(c0i = 0, A0H) = 0 for any r × r invertible H, because MA0H = MA0
and MA0A0 = 0. Here we deﬁne two matrix operations before further analysis on S˜np(ci, A). For an m × n
matrix U and a p × q matrix V , the vectorization of U is deﬁned as

                                    vec(U ) ≡ (u1,1, . ",stat.ME,A,-0.14966568,0.2696726,-0.035380714
http://arxiv.org/pdf/2203.04733v3,Bayesian tensor regression using the Tucker decomposition for sparse spatial modeling,"This slice image
contains 2202 = 48, 400 voxels. It is possible to analyze the whole brain using the current implementation of the
software package, but future work to improve computational speed will greatly reduce model runtimes. Phenotype
data were also included for each subject in the analysis, matched to patient ID using the ADNIMERGE package in R

                                                                     11
[the ADNI team, 2022]. ",stat.ME,A,0.03411153,0.25889337,-0.3546919
http://arxiv.org/pdf/2203.04920v1,Why Interpretable Causal Inference is Important for High-Stakes Decision Making for Critically Ill Patients and How To Do It,"Our approach has several limitations that could be improved in future work. When evaluating the EA burden, it would
be worthwhile in future work to consider the subtype of EA (GPD/LPD/LRDA), discharge frequency for periodic
discharge patterns, the morphological features (such as seizure with/without triphasic waves), and the spatial extent
of EAs. We currently do not have high quality human labels at the necessary resolution to pursue these tasks. ",stat.ME,C,0.051646344,0.09569506,-0.17727795
http://arxiv.org/pdf/2203.04920v2,Effects of Epileptiform Activity on Discharge Outcome in Critically Ill Patients,"Our approach has several limitations that could be improved in future work. When evaluating the EA burden, it would
be worthwhile in future work to consider the subtype of EA (GPD/LPD/LRDA), discharge frequency for periodic
discharge patterns, the morphological features (such as seizure with/without triphasic waves), and the spatial extent
of EAs. We currently do not have high quality human labels at the necessary resolution to pursue these tasks. ",stat.ME,C,0.051646344,0.09569506,-0.17727795
http://arxiv.org/pdf/2203.04926v2,Autoregressive models for time series of random sums of positive variables: application to tree growth as a function of climate and insect outbreaks,"We provided a valid statistical inference procedure and applied the
model to assessing the combined eﬀect of climate and SBW outbreak on white spruce tree-
ring growth in several sites in eastern Canada. We assumed a ﬁxed number of ecological
sites K. For future work, we plan to investigate the case of diverging K and the length n
of observed series. Because many other ecological studies rely on binary variable or count
data, it may be useful to extend the framework of this paper to these data types. ",stat.ME,B,0.09660343,-0.066348635,-0.055753022
http://arxiv.org/pdf/2203.05089v1,gcimpute: A Package for Missing Data Imputation,"To use mini-batching training, we set training_mode as
‘minibatch-offline’ also in the model call GaussianCopula(). The low rank Gaussian
copula is invoked using a diﬀerent model call LowRankGaussianCopula(rank=k) with desired
rank k. Mini-batch training for the low rank Gaussian copula is more challenging and remains
for future work, as the low rank update is nonlinear. Nevertheless, for large n and large p,
the parallel low rank Gaussian copula already converges quite rapidly. ",stat.ME,C,-0.29486787,-0.15960108,-0.1405027
http://arxiv.org/pdf/2203.05197v1,Spatially-Varying Bayesian Predictive Synthesis for Flexible and Interpretable Spatial Prediction,"Regarding scalable computation algorithms for spatial BPS, it may be possible to use

                                                       27
other types of scalable Gaussian processes, such as predictive process (Banerjee et al.,
2008), meshed Gaussian process (Peruzzi et al., 2020), and fused Gaussian process Ma
and Kang (2020). We leave the potential use of these techniques as future work. Apart
from MCMC-based algorithms, the integrated nested Laplace approximation (Rue et al.,
2009) may be an appealing strategy for fast computation. ",stat.ME,C,-0.43581134,-0.2840517,-0.20862398
http://arxiv.org/pdf/2203.05197v2,Spatially-Varying Bayesian Predictive Synthesis for Flexible and Interpretable Spatial Prediction,"Regarding scalable computation algorithms for spatial BPS, it may be possible to use

                                                       27
other types of scalable Gaussian processes, such as predictive process (Banerjee et al.,
2008), meshed Gaussian process (Peruzzi et al., 2020), and fused Gaussian process (Ma
and Kang, 2020). We leave the potential use of these techniques as future work. Apart
from MCMC-based algorithms, the integrated nested Laplace approximation (Rue et al.,
2009) may be an appealing strategy for fast computation. ",stat.ME,C,-0.43181562,-0.28121164,-0.21153992
http://arxiv.org/pdf/2203.05409v1,Nationally Representative Individualized Risk Estimation Combining Individual Data from Epidemiologic Studies and Representative Surveys with Summary Statistics from Disease Registries,"Although we have kept the model covariates simple to
facilitate potential clinical use, future all-cause mortality models could be made more powerful by
accounting for the severity of comorbidities and for geriatric ‘frailty’. (Schoenborn et al., 2021)

         In addition to developing more realistic propensity models and model diagnostics, other
topics need further research. The proposed two-step weighting procedure could be extended to
other epidemiologic study designs, such as case-cohort, nested case-control, and case-control
studies, which are examples of multi-phase sampling designs (Smoot and Haneuse 2015). ",stat.ME,B,0.3840176,-0.13266043,-0.09723796
http://arxiv.org/pdf/2203.05409v2,"Representative Individualized Absolute Risk Estimation by Using Data from Epidemiologic Studies, Surveys, and Registries: Estimating Risks for Minority Subgroups","Developing absolute risk estimation that is doubly robust to the post-
KW.S weights and the risk model is an area of future research. In addition to developing more realistic propensity models and model diagnostics, other
topics need further research. The proposed two-step weighting procedure could be extended to
other epidemiologic study designs, such as case-cohort, nested case-control, and case-control
studies, which are examples of multi-phase sampling designs (Smoot and Haneuse 2015). ",stat.ME,B,0.35239315,-0.11695513,0.02079005
http://arxiv.org/pdf/2203.05510v1,Controlling the flexibility of non-Gaussian processes through shrinkage priors,"The priors developed in
this paper make the estimation of the ﬂexibility parameters more robust, but we are also interested
in studying robustness of estimation (of the other model parameters) and prediction. This will be
investigated in future work. Also, as mentioned by (Berger et al., 1994): “An important aspect
of robustness is developing methods of detecting when a robustness problem exists and suggesting
where the diﬃculty might lie”. ",stat.ME,C,-0.041147824,-0.12334423,0.24648288
http://arxiv.org/pdf/2203.05510v2,Controlling the flexibility of non-Gaussian processes through shrinkage priors,"The analysis showed that the PC priors achieve the sought contraction towards the

                                          3
Gaussian model when there is not enough convincing evidence in the data of non-Gaussianity
and lead to more robust estimation. Finally, section 7 contains a summary and discussion of future work and possible exten-
sions. 2 A ﬂexible extension of Gaussian models

The GH distribution (Barndorﬀ-Nielsen, 1978) can be conveniently represented as a vari-
ance mixture of normal distributions, where the mixing distribution is a generalized inverse
Gaussian (GIG) random variable. ",stat.ME,C,-0.123268425,-0.169974,0.08611337
http://arxiv.org/pdf/2203.05749v1,Classification from Positive and Biased Negative Data with Skewed Labeled Posterior Probability,"In
this case, it was diﬃcult to provide learning with on high-dimensional data, unlike PUbN
classiﬁcation, because PUbN classiﬁcation treats P data and bN data as P data, and then
solves the PU classiﬁcation problem by applying a deep neural network with the sigmoid

                       11
function for the output layer, to estimate the probability that the data are observed. The
future work is to consider a method for the high-dimensional situation where it is diﬃcult
to estimate the probability density. Furthermore, we have to explore another method for
hyperparameter selection that does not require the assumption that the false negative
rate is known. ",stat.ME,C,-0.17253765,-0.091239214,-0.11554396
http://arxiv.org/pdf/2203.06056v1,Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past,"We have further argued that identifying the causal eﬀect may be of interest not only for causal
inference, but also for prediction of Y under the intervention do(Xt := x), where the minimal

                                                                18
expected squared error can be obtained by a mix of causal parameters and regression coeﬃcients,
see Proposition 14 and Section 5.2. For future work, it may be fruitful to develop principled techniques for deciding which estimator
yields the best ﬁnite sample performance (see, e.g., Henckel, 2021, Chapter 4) and to construct
conﬁdence statements, either based on Appendix B.2 or other techniques (e.g., Newey and West,
1987; Shah and Peters, 2020). Finally, as for the i.i.d. ",stat.ME,B,0.21358776,-0.09355642,0.24349567
http://arxiv.org/pdf/2203.06225v1,High-dimensional Generalized Additive Mixed Model with Longitudinal Data,"In addition, to improve efﬁciency for re-
                                                 gression coefﬁcients, the estimation of the working covariance matrix is involved in
                                                 the proposed iterative algorithm. We further study the asymptotic performance of the
                                                 resulting estimators and establish the oracle properties. We conduct extensive nu-
                                                 merical studies to assess the performance of our proposed estimation strategy and
                                                 numerically illustrate how efﬁcient it is in selecting signiﬁcant variables. ",stat.ME,C,-0.14774635,-0.14810416,0.14888932
http://arxiv.org/pdf/2203.06336v1,A New and Flexible Design Construction for Orthogonal Arrays for Modern Applications,"Compared with the existing approaches for constructing
balanced sliced orthogonal arrays and nested orthogonal arrays, the proposed method pro-
vides new such arrays of run sizes that are not prime powers, noting that [1] only constructs
the balanced sliced orthogonal arrays of runs sizes being prime powers, and [31] and [38]
only offer the nested orthogonal arrays of run sizes being prime powers. One direction for future work is to apply the proposed approach to obtain optimal orthog-
onal arrays in a similar fashion as in [45] which combines the construction with the algorith-
mic procedure. Another direction is to use this structure to obtain the catalogue of optimal
designs [26]. ",stat.ME,A,-0.24522433,0.38418865,-0.1008873
http://arxiv.org/pdf/2203.06496v1,Maxway CRT: Improving the Robustness of Model-X Inference,"Extension to Knockoﬀs. Another interesting direction for future work is in extending our
proposed method to other model-X procedures including Model-X knockoﬀs. When the X-modeling
is not perfect, Barber et al. ",stat.ME,C,-0.029117968,-0.123688295,0.08192696
http://arxiv.org/pdf/2203.06924v1,A universal test on spikes in a high-dimensional generalized spiked model and its applications,"This paper only focused on the one-sample spiked model
related to the covariance matrix. We will continue to study the two-sample
spiked model involved with the Fisher-matrix in future work. Acknowledgments

We thank LetPub (www.letpub.com) for linguistic assistance and pre-submission
expert review. ",stat.ME,B,0.08576378,-0.0764087,0.009683918
http://arxiv.org/pdf/2203.06948v1,"Continuous Time Graph Processes with Known ERGM Equilibria: Contextual Review, Extensions, and Synthesis","That said, deriving an
ERGM-generating graph process from ﬁrst principles can provide a strong motivation for applying
it in cases where the associated assumptions are met. Mechanistic derivations of ERGM-generating
continuous time graph processes would thus seem to be an important area for further research. 4.3 Considerations for Practical Use

Although our focus here is on model deﬁnition and general properties, we may glean a few con-
siderations for use of these models in practice. ",stat.ME,C,-0.19781245,-0.09725687,0.00932776
http://arxiv.org/pdf/2203.07108v1,Consistent and scalable Bayesian joint variable and graph selection for disease diagnosis leveraging functional brain network,"Although it does not harm the
primary goal of this paper, the selection of the support of the precision matrix and coeﬃcient vector, it will
obviously not be satisfactory when the estimation of the precision matrix is of interest. Thus, modifying
the CONCORD algorithm to ensure positive deﬁniteness of the precision matrix while maintaining fast
computation would be another possible direction of future work. 21
A Proofs

Notation. ",stat.ME,A,-0.3761415,0.14785881,-0.030433103
http://arxiv.org/pdf/2203.08269v1,Doubly-Robust Dynamic Treatment Regimen Estimation for Binary Outcomes,"Therefore, a possible extension would be to conduct sensitivity
analyses to study diﬀerent link functions as well as treatment-free functions in GLM. In future work, we note that some machine learning (ML) methods can be employed in our dWGLM analytical frame-
work. For example, tree-based methods (e.g., Bayesian additive regression trees, [Chipman et al., 2010]) are commonly

                                                                     19
                                                                                                          A preprint - March 17, 2022

used in estimating the treatment model, and some ensemble methods (e.g., Super Learner, [Van der Laan et al., 2007])
can be used for last stage estimation to provide a more accurate prediction of P(Y = 1 | hK, aK), and thus to produce
accurate pseudo outcome prediction. ",stat.ME,B,0.16835906,-0.21594477,-0.13147527
http://arxiv.org/pdf/2203.08701v1,One-step weighting to generalize and transport treatment effect estimates to a target population,"In such settings, it may be preferable to adjust for these two sets
of covariates separately. In future work we aim to extend to our approach to such settings. Our approach oﬀers other potential avenues for extension, including the settings of causal
mediation, informative censoring, and time-varying treatments, where 2MW approaches are
popular (see e.g., VanderWeele 2009; Viviano and Bradic 2021, respectively). ",stat.ME,B,0.3545132,-0.14187814,0.16967113
http://arxiv.org/pdf/2203.08701v2,One-step weighting to generalize and transport treatment effect estimates to a target population,"In such settings, it may be preferable to adjust for these
two sets of covariates separately. In future work we aim to extend to our approach to such
settings. While in this paper we focus on the settings of generalization and transportation, weighting
estimators with a multiplicative structure arise in numerous other areas of causal inference. ",stat.ME,B,0.17241587,-0.20672572,0.15153298
http://arxiv.org/pdf/2203.08701v3,One-Step weighting to generalize and transport treatment effect estimates to a target population,"2010). If the intervention can have eﬀects for white men, these results suggest that Black doctors can be
more eﬀective than white doctors regardless of the race of their patient, which is an interesting
hypothesis for further study. Figure 3: Estimates of the target average treatment eﬀect for various outcome variables and
target populations. ",stat.ME,B,0.3706079,0.24256116,0.18332449
http://arxiv.org/pdf/2203.08749v3,"On estimating the structure factor of a point process, with applications to hyperuniformity","Finally, as expected for the window sizes/intensity that we
consider, the case 0.9 < p < 1 remains diﬃcult: in preliminary experiments,
we did not reject hyperuniformity without hand-tuning the test’s parameters
to reach the desired conclusion. We leave this critical case to future work. Table 3: Multiscale hyperuniformity test obtained using SBI on the thinned
Ginibre process. ",stat.ME,A,-0.047625177,0.2841022,0.120080635
http://arxiv.org/pdf/2203.09330v2,Fighting Noise with Noise: Causal Inference with Many Candidate Instruments,"Suppose only one variable Zj0 survives the marginal screening, which implies that
the spurious correlation between Zj0 and DΛ1 is the maximal correlation between DΛ1 and candidate Zj for

                                                                                              a
all 1 ď j ď p. One can show that the effect of Zj0 on the exposure is of order plog pq{n1, while the effect
of Zj0 on the outcome converges to zero faster at rate 1{?n2. We leave this extension for future work. In addition, our current framework only considers invalid instruments that have a direct effect on the
outcome. ",stat.ME,B,0.16652882,0.069379814,0.23084596
http://arxiv.org/pdf/2203.09682v1,Optimizing Randomized and Deterministic Saturation Designs under Interference,"2∞)

    A proof is included in the supplementary materials. A more thorough extension of our
results to other random graph models is left for future work. 3 Deterministic Saturation Designs

In the previous section, we investigated randomized saturation designs, which assign random
treatment proportions to clusters of the experimental cohort. ",stat.ME,C,-0.023497328,0.120044254,0.14659166
http://arxiv.org/pdf/2203.09726v1,Efficient Estimation of the Additive Risks Model for Interval-Censored Data,"Relevant model-ﬁtting and implementation using our R package MMIntAdd are
presented in Section 6. Finally, Section 7 concludes, alluding to some future work. 2 Statistical Model

2.1 Notations and Setup

Let Ti denote the time-to-event for the ith subject. ",stat.ME,C,0.038410243,-0.15086667,-0.095363826
http://arxiv.org/pdf/2203.09785v1,Anytime-valid Confidence Intervals for Contingency Tables and Beyond,"How-
ever, the SPR does not satisfy the GRO property making it sub-optimal (see
also [Adams, 2020]); moreover, as should be clear from the development, our
method for constructing conﬁdence sequences can be implemented for any eﬀect
size notion with convex rejection sets Θ0(≤ δ) and Θ0(≥ δ), not just the log
odds ratio. A main goal for future work is to use Theorem 2 to provide such
sequences for sequential two-sample settings that go beyond the 2 × 2 table. References

Reuben Adams. ",stat.ME,C,-0.25536624,0.15073699,0.122591324
http://arxiv.org/pdf/2203.10002v1,A Comparison of Different Methods to Adjust Survival Curves for Confounders,"Estimates
are based on 2000 simulation repetitions. To further study when these eﬀects occur, ﬁgure 5 shows the percentage of OOB
estimates over the entire survival curve. OOB errors occur much more frequently at the
left and right end of the survival curve. ",stat.ME,B,0.17786843,0.098916546,0.0057262527
http://arxiv.org/pdf/2203.10002v2,A Comparison of Different Methods to Adjust Survival Curves for Confounders,"Estimates are based on
2000 simulation repetitions. To further study when these eﬀects occur, we plotted the percentage of OOB estimates
over the entire survival curve (see appendix). OOB errors occur much more frequently
at the left and right end of the survival curve. ",stat.ME,B,0.17496698,0.050528985,0.010058511
http://arxiv.org/pdf/2203.10115v1,Introducing causal inference in the energy-efficient building design process,"We believe this is one of the potential solutions to extend digitalization
and the beneﬁt from artiﬁcial intelligence into the empirical science domain. To further explore the domain integration
of causal modeling, requires further examination of the nature of compiled representations, intrinsic limitations, the
types of reasoning they support, and the effectiveness in getting the answers that users expect to get. 7 Acknowledgements

We gratefully acknowledge the German Research Foundation (DFG) support for funding the project under grant GE
1652/3-2 in the Researcher Unit FOR 2363. ",stat.ME,B,0.23891988,-0.086950645,-0.08064112
http://arxiv.org/pdf/2203.10115v2,Introducing causal inference in the energy-efficient building design process,"We believe this is one of the potential solutions to extend digitalization

                                                                     17
Introducing causal inference in the energy-efﬁcient building design process  A PREPRINT

and the beneﬁt from artiﬁcial intelligence into the empirical science domain. To further explore the domain integration
of causal modeling, requires further examination of the nature of compiled representations, intrinsic limitations, the
types of reasoning they support, and the effectiveness in getting the answers that users expect to get. 7 Acknowledgements

We gratefully acknowledge the German Research Foundation (DFG) support for funding the project under grant GE
1652/3-2 in the Researcher Unit FOR 2363. ",stat.ME,B,0.17688644,-0.08484937,-0.11161381
http://arxiv.org/pdf/2203.10115v3,Introducing causal inference in the energy-efficient building design process,"We believe this is one of the potential solutions to extend digitalization
and the beneﬁt of artiﬁcial intelligence into the empirical science domain. To further explore the domain integration of
causal modeling, requires further examination of the nature of compiled representations, intrinsic limitations, the types
of reasoning they support, and the effectiveness in getting the answers that users expect to get. 7 Acknowledgements

We gratefully acknowledge the German Research Foundation (DFG) support for funding the project under grant GE
1652/3-2 in the Researcher Unit FOR 2363. ",stat.ME,B,0.24239403,-0.08289017,-0.083759114
http://arxiv.org/pdf/2203.10130v1,EzGP: Easy-to-Interpret Gaussian Process Models for Computer Experiments with Both Quantitative and Qualitative Factors,"Section 4 presents several numerical examples and section 5 reports a
real application of the proposed models. Section 6 concludes this work and discusses some
future work. All proofs and technical details are relegated to the Appendix. ",stat.ME,C,-0.39411774,-0.0067484872,0.07207925
http://arxiv.org/pdf/2203.10268v1,Truncated estimation for varying-coefficient functional linear model,"Although the estimation strategy for it may be straightforward, the identiﬁability of the
coeﬃcient estimates need to be investigated. In addition, some asymptotic properties
such as consistency should be addressed as future works. As indicated in the end of the real data analysis, we found that it may fail to construct
a strict truncated model, that is, the coeﬃcient surface may be estimated to be zero only
at the closed domain. ",stat.ME,C,-0.046212435,-0.23599029,0.23475492
http://arxiv.org/pdf/2203.10360v1,Measuring the severity of multi-collinearity in high dimensions,"Though the main focus here was on the empirical properties of these measures without distributional assumptions, it is
possible to further characterize the statistical properties of SRj or SLi according to behaviours of the singular values
and vectors using random matrix theory such as in Bai [2008]. This will be the subject of future work. Following property 2.2, it is natural to deﬁne a scaled measure:

                                                    SRj         p
                                         sRj = (n − 1)2 =
                                                                      rj2j ∈ [1, p],              (2.3)

                                                                j =1

as it has a more natural interpretation of being the sum of squared pairwise Pearson’s correlation coefﬁcients. ",stat.ME,A,-0.12902993,0.11629849,0.1293225
http://arxiv.org/pdf/2203.10469v1,Improving Randomization Tests under Interference Based on Power Analysis,"Through simulations in a spatial interference setting, we conﬁrmed that the proposed method
shows higher power than the existing method. There are several possible directions for future works. First, in this paper, we derived the
power of the randomization test only for the contrast hypothesis with the diﬀerence in means
type test statistic. ",stat.ME,A,-0.08235043,0.1887646,0.19524576
http://arxiv.org/pdf/2203.10522v1,Elastic Full Procrustes Analysis of Plane Curves via Hermitian Covariance Smoothing,"6. DISCUSSION

   While we ﬁnd good performance of the proposed elastic full Procrustes mean estimator in
realistic irregular/sparse curve data, future work should focus on theoretical assessment of esti-
mation quality as well as inference. In particular, evaluation of the bias introduced by sub-optimal
alignment of curves based on single discrete measurements would be of interest, as well as char-
acterization of suitable sampling schemes where the bias is empirically negligible, which often
appears to be the case in practice. ",stat.ME,C,-0.1735645,-0.031140964,0.17029673
http://arxiv.org/pdf/2203.10522v2,Elastic Full Procrustes Analysis of Plane Curves via Hermitian Covariance Smoothing,"Yet, if suitable reference landmarks allowed, the information on
positioning, size, orientation and warping of the curve could also be separately investigated. 6 Discussion

While we ﬁnd good performance of the proposed elastic full Procrustes mean estimator in realistic irreg-
ular/sparse curve data, future work should focus on theoretical assessment of estimation quality as well
as inference. In particular, evaluation of the bias introduced by sub-optimal alignment of curves based on
single discrete measurements is a topic of its own that would be of interest, as well as characterization of
suitable sampling schemes where the bias is empirically negligible, which often appears to be the case in
practice. ",stat.ME,C,-0.15307945,-0.05027087,0.0777035
http://arxiv.org/pdf/2203.10561v1,Robust analyses for longitudinal clinical trials with missing and non-normal continuous outcomes,"To ensure that only one outcome is involved in a time
interval for each individual, only the outcome that is nearest to week 8k in the kth visit interval
is preserved for k = 1, · · · , 5. Since our proposed method is only valid for a monotone missingness
pattern, we delete the observations after the ﬁrst occurrence of missingness for each individual to
create a monotone missingness dataset and use it for further analysis. The fully-observed baseline
covariates consist of age, gender, and the baseline log CD4 counts. ",stat.ME,B,0.31801093,0.05456788,-0.19800064
http://arxiv.org/pdf/2203.10775v1,Modified Method of Moments for Generalized Laplace Distributions,"Then we use absolute moments to
improve eﬃciency for GAL. Finally, we suggest some venues for further research. 1.4. ",stat.ME,A,-0.0646344,0.16505104,0.04171854
http://arxiv.org/pdf/2203.10775v2,Modified Method of Moments for Generalized Laplace Distributions,"Then we use absolute moments to
improve eﬃciency for GAL. Finally, we suggest some venues for further research. 1.4. ",stat.ME,A,-0.0646344,0.16505104,0.04171854
http://arxiv.org/pdf/2203.10980v1,What is a randomization test?,"But conditioning can improve power [27] and obtain good frequentist
properties [40]. Theoretical guidance on choosing the conditioning event is an interesting
direction for future work. So which statistical test should be applied in practice—a randomization test, a quasi-
randomisation test, or a model-based test (such as the F -test in linear models)? ",stat.ME,B,0.17378531,0.05605284,0.113496594
http://arxiv.org/pdf/2203.11439v1,Bayesian outcome selection modelling,"A limitation of
the current model is that we only use an individual random intercept to capture the corre-
lations among the outcomes. This approach may not be ideal, and we may consider a more
sophisticated correlation structure in future works. Finally, the proposed framework is shown to be eﬀective in identifying sensitive outcomes
in various scenarios. ",stat.ME,B,0.23119786,-0.012879167,0.043098982
http://arxiv.org/pdf/2203.11576v1,Sparse Synthetic Controls,"Whereas
the standard synthetic control estimate becomes more biased when the number of predictors is
increased, the sparse synthetic control is robust to the predictor increase. A natural next step
for future work is to explore in which settings the sparse synthetic control can also improve the
standard errors of the treatment eﬀect estimates. References

 1. ",stat.ME,C,-0.031219613,-0.050128493,0.055556692
http://arxiv.org/pdf/2203.11798v1,Bayesian Nonparametric Adjustment of Confounding,"Therefore, we view subsets of variables prioritized
by the proposed methodology as optimal target sets of confounders that produce unbiased
estimates of casual eﬀects. There are several avenues for future work to reﬁne the methodology proposed here. First,
the methods proposed here use the default settings for the component BART model (hyper-)
parameters. ",stat.ME,B_centroid,0.19617921,-0.08162815,0.10395246
http://arxiv.org/pdf/2203.12005v1,Sequential Bayesian Registration for Functional Data,"The proposed method is therefore applicable to various real data studies where interest lies in
smooth evolutions of a variable. In future work, we will incorporate functional correlation over time in the model. This is a
reasonable assumption for applications such as climate monitoring, when functional variability
is dependent between observations. ",stat.ME,C,-0.021100203,-0.2652632,0.006575929
http://arxiv.org/pdf/2203.12464v1,Two-sample nonparametric test for proportional reversed hazards,"The second data related to Ducheme muscular dystrophy rejects the null
hypothesis in favour of the alternative. Finally, Section 5 contains some concluding remarks and a
discussion about possible avenues of future work. 2 Formulation of the test procedure

In this section, a non-parametric test will be developed for the testing problem given in (3) based
on the random samples X1, X2, . ",stat.ME,B,0.23717354,0.2776504,0.11246839
http://arxiv.org/pdf/2203.12474v1,Separating the Wheat from the Chaff: Bayesian Regularization in Dynamic Social Networks,"A further study could assess
the possible beneﬁts of such ﬁne-grained shrinkage methods. In addition, further research can explore the use of shrinkage priors to model tem-
poral changes of network parameters over time. The idea would be to place a shrinkage
prior for the diﬀerence of a parameter over time, similar as in graphical models for
variables (Shaﬁee Kamalabad and Grzegorczyk, 2020). ",stat.ME,C,-0.109640874,-0.21421385,-0.037152566
http://arxiv.org/pdf/2203.12495v1,On predictive inference for intractable models via approximate Bayesian computation,"Our key aim was to give a uniﬁed overview of some general ABC prediction methods and their basic
properties in an accessible manner. As future work, one could study more closely how to best use these
methods for speciﬁc models and inference tasks. One could also investigate if LFI techniques such as
regression adjustment (Beaumont et al., 2002; Blum, 2010), Bayesian synthetic likelihood (Price et al., 2018)
or conditional density estimation methods based on neural networks or Gaussian processes (Papamakarios
and Murray, 2016; Papamakarios et al., 2019; Grazian and Fan, 2020; Järvenpää et al., 2020) can be used
to improve the accuracy or computational eﬃciency of the ABC-P approach. ",stat.ME,C,-0.07497422,-0.24478889,-0.107080534
http://arxiv.org/pdf/2203.12495v2,On predictive inference for intractable models via approximate Bayesian computation,"On the other hand, ABC-P’ might facilitate
more convenient implementation than ABC-P in a sense that the estimation of θ and y˜ can be separated. More detailed investigation is however left as a potential topic for future work. B Additional mathematical details

B.1 Proof of Proposition 3.1

We obtain

           lim πh(P)(y˜ | sy) = lim           1sz∈At π(y˜, sz | θ)π(θ) dsz dθ      (B.7)
           t→∞ t              t→∞            1sz∈At π(y˜, sz | θ)π(θ) dsz dθ dy˜   (B.8)
                                                                                   (B.9)
                              = lim           1sz∈At π(y˜, sz, θ) dθ dsz          (B.10)
                                             1sz∈At π(y˜, sz, θ) dθ dy˜ dsz       (B.11)
                                  t→∞                                             (B.12)

                              = lim     sz∈At π(y˜, sz) dsz
                                         sz∈At π(sz) dsz
                                  t→∞

                              limt→∞         1t  |     s ∈A π(y˜, sz) dsz
                              =            |A             zt
                                   lim
                                                1             π(s ) ds
                                       t→∞ |At| sz ∈At        z       z

                              = π(y˜, sy)
                                   π(sy )

                              = π(y˜ | sy),

where on the second line we have used Tonelli’s theorem to change the order of integration and where the
ﬁfth equality holds almost everywhere and follows from Lebesgue diﬀerentiation theorem (see e.g. ",stat.ME,C,-0.24897072,0.003880009,0.23299542
http://arxiv.org/pdf/2203.12732v1,Tests of Linear Hypotheses using Indirect Information,"In the multigroup setting, properties such as the connectedness
or convexity of such a conﬁdence region found by inverting the FAB test warrant
further study. Another aspect of the multigroup FAB test that warrants further study are the
multiple testing properties of this test. The multigroup FAB test controls the type I
error rate for each group and thus controls the per-comparison error rate, but it does
not control the family-wise error rate [6]. ",stat.ME,A,0.07010859,0.3784386,0.08404495
http://arxiv.org/pdf/2203.12779v1,Estimating Viral Genetic Linkage Rates in the Presence of Missing Data,"We note that our methods would apply not only to power law networks but to networks
of all types, for which sampling of nodes is not complete. Due to the interest in analyzing the
BCPP, we chose our focus to be power law networks; future work is required for extension
to networks more generally. 22
7 Acknowledgements

The BCPP Impact Evaluation was supported by the President’s Emergency Plan for AIDS
Relief through the Centers for Disease Control and Prevention (CDC) (cooperative agree-
ments U01 GH000447 and U2G GH001911). ",stat.ME,B,0.09420379,0.07132072,-0.1005532
http://arxiv.org/pdf/2203.13067v1,How do dataset characteristics affect the performance of propensity score methods and regression for controlling confounding in observational studies? A simulation study,"Suboptimal coverage against a non-null marginal odds ratio has been
previously observed for several methods for analysing paired data following PS matching [9], and in
the present study we also found this to hold when using an unpaired regression method. A direct
comparison would be useful for future work. By design, we did not include covariates in the regression models incorporating the PS (as a covariate,
with IPTW, or following matching). ",stat.ME,B,0.23558661,0.20753601,0.050970778
http://arxiv.org/pdf/2203.13188v1,Derivation of an Inverse Spatial Autoregressive Model for Estimating Moran's Index,"The outer product equation can be derived from the
formula of Moran’s index based on a standardized variable and a normalized weight matrix. However, the inner product equation is not derivable from general principles or previous definition
and requires further study before it will lead us to the underlying rationale of the pair of spatial
autocorrelation equations. As a matter of fact, the inner product equation is obtained by considering
one of the necessary conditions for defining Moran’s index (Chen, 2013). ",stat.ME,A,-0.16322559,0.0074910615,0.008550169
http://arxiv.org/pdf/2203.13188v2,Derivation of an Inverse Spatial Autoregressive Model for Estimating Moran's Index,"The outer product equation can be derived from the
formula of Moran’s index based on a standardized variable and a globally normalized weight matrix. However, the inner product equation is not derivable from general principles or previous definition
and requires further study before it will lead us to the underlying rationale of the pair of spatial
autocorrelation equations. As a matter of fact, the inner product equation is obtained by considering
one of the necessary conditions for defining Moran’s index (Chen, 2013). ",stat.ME,A,-0.15495574,0.0016181488,0.015435757
http://arxiv.org/pdf/2203.13377v1,Statistic Selection and MCMC for Differentially Private Bayesian Estimation,"In Section 5 we present
the results of some numerical experiments. Finally, we give our concluding remarks and
possible future work in Section 6. 2 Diﬀerential Privacy

In this section, we take diﬀerential privacy as the primary deﬁnition of data privacy;
although we also mention other closely related deﬁnitions. ",stat.ME,A,-0.22064269,0.2600575,0.21424612
http://arxiv.org/pdf/2203.13377v2,Statistic Selection and MCMC for Differentially Private Bayesian Estimation,"In Section 5 we present
the results of some numerical experiments. Finally, we give our concluding remarks and
possible future work in Section 6. 2 Diﬀerential Privacy

In this section, we take diﬀerential privacy as the primary deﬁnition of data privacy;
although we also mention other closely related deﬁnitions. ",stat.ME,A,-0.22064269,0.2600575,0.21424612
http://arxiv.org/pdf/2203.13665v1,Resilience family of receiver operating characteristic curves,"This paper proposes ROC curve analysis in the direction of resilience family of distributions
for the ﬁrst time. A lot of work needs to be carried out as a further research for the proposed
model. Development of the Bayesian estimation methodology for the resilience parameter (assuming
θ ∈ (1, ∞)) could be considered. ",stat.ME,C,-0.00045065582,-0.14904407,0.0117157195
http://arxiv.org/pdf/2203.14063v1,Manifold Principle Component Analysis for Large-Dimensional Matrix Elliptical Factor Model,"In the theoretical analysis of the MPCAF , we assume that either R or C is given

                                                             21
to establish the convergence rate of C or R, which is not quite satisfying. As a future work, we will
establish the convergence rates of estimators from the iterative procedure, which is more challenging as
both statistical error and computational error should be taken into account. Acknowledgements

    He’s work is supported by National Science Foundation (NSF) of China (12171282,11801316),
National Statistical Scientiﬁc Research Key Project (2021LZ09), Young Scholars Program of Shan-
dong University, Project funded by China Postdoctoral Science Foundation (2021M701997) and the
Fundamental Research Funds of Shandong University. ",stat.ME,C,-0.15134895,-0.072499916,0.27350283
http://arxiv.org/pdf/2203.14223v2,Network Influence with Latent Homophily and Measurement Error,"Solv-
ing the optimization problem leads to solutions for δ, σ2 for a given ρ

           δ(ρ) = (XnT Xn)−1XnT Sn(ρ)E[Yn] = (XnT Xn)−1XnT Sn(ρ)Sn−1Xnδ0

           σ2(ρ) = 1 (ρ0 − ρ)2(GnXnδ0)T M1n(GnXnδ0
                      n

              σ02   T −1                    T        −1
(6)        +    tr  (Sn )  Sn(ρ) Sn(ρ)Sn                 ,
              n

where M1n = (In − Xn(XnT Xn)−1XnT ), and Gn = LnSn−1. The arguments in Lee (2004)
proves uniqueness of ρ0 as the global maximizer of Qn(ρ) in the compact parameter space

R. However we need to show the uniform convergence of the concentrated corrected log like-
lihood ln∗ (ρ) to Qn(ρ) over the compact parameter space R, which requires further analysis. Now we have

           n1 (ln∗ (ρ) − Qn(ρ)) = − 12 (log(σˆn2) − log(σ2(ρ))),

where σ2(ρ) is as deﬁned in Equation 6 and

(7) σˆn2 (ρ) = n1 YnT SnT (ρ)M2nSn(ρ)Yn,
with M2n = In − X˜n(X˜nT X˜n − Ω)−1X˜nT . ",stat.ME,C,-0.44579798,0.015144205,0.25155255
http://arxiv.org/pdf/2203.14914v1,Micro-Randomized Trial with Flexible Design and Sample Size Considerations,"This outcome measure can be categorized into a dummy variable (e.g., 6 or below versus above 6). An important
future work would be to develop a data analysis method, similar to the approach of Qian et al. 35 for binary outcomes, under the
proposed FlexiMRT design. ",stat.ME,B,0.32559234,0.25000218,-0.1742756
http://arxiv.org/pdf/2203.15184v2,Analysis of sloppiness in model simulations: unveiling parameter uncertainty when mathematical models are fitted to data,"Consequently, for analyzing model
sloppiness, eigenparameters obtained from the AS method are expected to have a different interpretation than
that of eigenparameters obtained from matrices P and G in relation to acknowledging the source of information
(i.e., prior and/or data). Thus, exploring how the AS method compares to the Bayesian methods discussed here
could be an interesting direction for future work. Hence, given the great ﬂexibility of the techniques discussed here to unveil sensitivities of the model-data
ﬁt to changes in parameter values, our comprehensive approach to analyzing model sloppiness does comprise a
suitable set of tools to aid understanding of many of nature’s systems, ranging from a single cell in the human
body (7,8) and the myriad of microorganisms found almost everywhere (3–5) to large ecosystem networks (2,17)
and beyond (9, 10), through the simultaneous usage of experimental data, mathematical models, and computer
simulation. ",stat.ME,C,0.024634823,-0.16053806,-0.14537098
http://arxiv.org/pdf/2203.15267v1,Selective inference for k-means clustering,"Empirically,
conditioning on too much information results in a loss of power (Fithian et al., 2014;
Jewell et al., 2022; Liu et al., 2018). In future work, we will investigate the possibility
of leveraging recent developments in selective inference (Chen et al., 2021a; Le Duy &
Takeuchi, 2021; Jewell et al., 2022) to compute the “ideal” p-value (8). We could also consider extending our proposal to other data generating models. ",stat.ME,B,0.090343244,0.022083797,0.06522192
http://arxiv.org/pdf/2203.15555v1,Progression models for repeated measures: Estimating novel treatment effects in progressive diseases,"One particularly relevant aspect to consider is the potential to include patient-level
differences in disease progression. This has been a major focus in Alzheimer’s disease, where
a range of exploratory disease progression models with latent variables describing patient-
level progression has been developed with a focus on predicting the disease stage and future
decline of an individual patient.26-31 Such covariate adjustment and explorations of
PMRMs for multivariate outcomes are left as future work. Acknowledgements

Data for this publication was obtained through TransCelerate Biopharma Inc.’s
Historical Trial Sharing project, hosted on TransCelerate’s DataCelerate platform. ",stat.ME,B,0.34904265,-0.09245665,-0.2642439
http://arxiv.org/pdf/2203.15641v1,Power and Sample Size Computation for Genetic Association Studies of Binary Traits: Accounting for Covariate Effects,"We demonstrated the accuracy and feasibility of the proposed approach in section 4,
and used the UKB data to show how the proposed method can be used in practice. However, there are still some limitations of the proposed method that require future works to address. For example
in GWAS studies, winner’s curse where the effect size estimates of signiﬁcant SNPs are biased upward is known to
be a common problem [6, 39, 5]. ",stat.ME,B,0.12736131,0.12684321,-0.05338211
http://arxiv.org/pdf/2203.15641v2,The hidden factor: accounting for covariate effects in power and sample size computation for a binary trait,"Finally, the
proposed method assumes a random sample of unrelated individuals. Power and sample size computation for related
individuals are worthy future work. The proposed method, and the default setting of the implemented software SPCompute, assumes all the parameters are
speciﬁed based on a prospective model as in the UKB application. ",stat.ME,A,0.029294554,0.23531014,-0.1023803
http://arxiv.org/pdf/2203.15676v1,Linear mixed models to handle missing at random data in trial-based economic evaluations,"In this letter, we aim to familiarise readers with the implementation of LMMs in trial-based CEA using
standard software and summarise the statistical and economic results from a case study. Finally, we
discuss the proposed approach and provide some suggestions for future work. 2 METHODS

2.1 Linear mixed effects models for repeated measurements
Linear mixed model extends the usual linear model framework by the addition of “random effect” terms,
which can take into account the dependence between observations. ",stat.ME,B,0.26569837,0.006035799,-0.031736486
http://arxiv.org/pdf/2203.15707v1,A review of heath economic evaluation practice in the Netherlands: are we moving forward?,"Discounting should always be applied when outcome data are analysed over a time horizon
exceeding one year using a yearly discount rate of 1.5% for eﬀects and 4% for costs. Uncertainty
surrounding the economic results from the analysis should always be assessed to: 1) quantify the
impact on cost-eﬀectiveness conclusions; 2) determine if and how much additional research may
reduce uncertainty. The methods and type of uncertainty analyses vary according to the type
of economic evaluation, with a clear distinction between empirical (e.g. ",stat.ME,B,0.2153273,0.08525136,0.16603795
http://arxiv.org/pdf/2203.16717v1,A comparison of strategies for selecting auxiliary variables for multiple imputation,"By doing
so, we may have overlooked a range of scenarios under which the analysis strategies perform
poorly. However, this study can be used to inform further research in this area. In conclusion, this study evaluated a range of strategies for selecting auxiliary variables
for MI models, with the aim of providing advice for researchers faced with this problem. ",stat.ME,B,0.2498196,-0.054829367,0.011680674
http://arxiv.org/pdf/2203.17208v1,Controlled Discovery and Localization of Signals via Bayesian Linear Programming,"By
carefully deﬁning “signals” of interest, could BLiP help extract intelligible results in these settings? We did not consider this question in this paper, but perhaps future work will address it. 7 URLs

For convenience, below are a collection of links which include all the code and data necessary to
replicate our analyses. ",stat.ME,C,-0.06408949,0.19184105,0.010461189
http://arxiv.org/pdf/2203.17208v2,Controlled Discovery and Localization of Signals via Bayesian Linear Programming,"By
carefully deﬁning “signals” of interest, could BLiP help extract intelligible results in these settings? We did not consider this question in this paper, but perhaps future work will address it. 23
7 URLs

For convenience, below are a collection of links which include all the code and data necessary to
replicate our analyses. ",stat.ME,C,-0.0688801,0.19696283,0.01903632
http://arxiv.org/pdf/2203.17208v3,Controlled Discovery and Localization of Signals via Bayesian Linear Programming,"By
carefully deﬁning “signals” of interest, could BLiP help extract intelligible results in these settings? We did not consider this question in this paper, but perhaps future work will address it. 23
7 URLs

For convenience, below are a collection of links which include all the code and data necessary to
replicate our analyses. ",stat.ME,C,-0.0688801,0.19696283,0.01903632
http://arxiv.org/pdf/2204.00126v1,On site occupancy models with heterogeneity,"), we have only given partial results when detection heterogeneity is considered to be
a mixture model or when the conditional likelihood approach is used in a regression frame-
work. Results for the maximum likelihood estimator in the regression setting still require
further research. Although we showed that conditional likelihood and maximum likelihood are not asymp-
                                                      21
totically equivalent in the regression case, most of our empirical results showed similarities
in terms of efﬁciency. ",stat.ME,B,0.16800304,-0.06406884,0.13475159
http://arxiv.org/pdf/2204.00126v2,On site occupancy models with heterogeneity,"), we have only given partial results when detection heterogeneity is considered to be
a mixture model or when the conditional likelihood approach is used in a regression frame-
work. Results for the maximum likelihood estimator in the regression setting still require
further research. Although we showed that conditional likelihood and maximum likelihood are not asymp-
                                                      21
totically equivalent in the regression case, most of our empirical results showed similarities
in terms of efﬁciency. ",stat.ME,B,0.16800304,-0.06406884,0.13475159
http://arxiv.org/pdf/2204.01127v1,Bayesian estimation of topological features of persistence diagrams,"Section 3 presents the
proposed Bayesian model for estimating the Betti numbers via outlier detection. A simulation study is also
performed in Section 4, and Section 5 contains some final remarks and future work. 2 Topological data analysis in a nutshell

TDA and Statistics, at first glance, tackle the same problem of clustering, as already mentioned. ",stat.ME,A,-0.23926115,0.044898637,-0.19196892
http://arxiv.org/pdf/2204.01301v1,A Modification of McFadden's $R^2$ for Binary and Ordinal Response Models,"In a few cases, how-
ever, androstenone had a value of zero, which may be due to androstenone content
below the detection threshold, or defective measurement. Therefore, those obser-
vations were excluded from further analysis. A linear version of the categorical
model having the same predictors, but with the average panel rating as response
was ﬁtted as well (similarly to Mörlein et al. ",stat.ME,B,0.38338935,0.24900432,0.095956735
http://arxiv.org/pdf/2204.01573v1,Low Tree-Rank Bayesian Vector Autoregression Model,"7 Discussion

A tree-rank prior distribution is introduced to induce both near-connectivity and high sparsity on
the network Granger causal network of a vector autoregression model, propose a fast algorithm
for calculating the posterior distribution of the model parameters and also establish posterior con-
sistency of their estimates. There are several interesting extensions to pursue in future work. The
focus of this paper was one connected but highly sparse Granger causal network; nevertheless,
there may be networks with relatively low tree-rank, but containing several small dense sub-
networks. ",stat.ME,C,-0.06826628,-0.17426232,-0.028807499
http://arxiv.org/pdf/2204.01831v1,An adaptive model checking test for functional linear model,"Although we don’t

know the exact distribution information of the error term under null hypothesis, numerical
experiments shows that the difference of sˆ∗1 and sˆ1 under the null hypothesis can be ignored
since ηj shares the same mean and variance with η. Theoretical analysis and discussion of

this data-driven selection procedure need further study. In practice, we also suggest setting a support order to deal with small variance models. ",stat.ME,B,0.09553048,-0.05253399,0.26733598
http://arxiv.org/pdf/2204.01831v2,An adaptive model checking test for functional linear model,"Although we don’t know the exact distribution information of the error term
under null hypothesis, numerical experiments shows that the diﬀerence of sˆ∗1 and sˆ1 under the null
hypothesis can be ignored since ηj shares the same mean and variance with η. Theoretical analysis
and discussion of this data-driven selection procedure need further study. In practice, we also suggest setting a support order to deal with small variance models. ",stat.ME,B,0.08532745,-0.06646004,0.2788116
http://arxiv.org/pdf/2204.01904v1,Prediction Intervals for Simulation Metamodeling,"On the other hand, a limitation of
our approach is the lack of specific guarantee for any particular design point, as our construction focuses on coverage
and width quality on average throughout the design space. When using metamodels for optimization purpose, this
issue could be especially relevant, and future work would study and test the performances and potential remedies of
this limitation. We close this introduction by reviewing several mainstream approaches for constructing prediction intervals. ",stat.ME,C,-0.043601096,-0.016805189,-0.088648364
http://arxiv.org/pdf/2204.02112v1,GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes,"Though
       our strategy of initialising GP-BART by a warm-up step that uses
       BART on the ﬁrst phase of MCMC iterations substantially reduces
       this cost, approximations for the GP — using for example the Nystro¨m
       method [27] or the methods of Quin˜onero-Candela et al. [24] — might
       prove to be advantageous in future work. • In the applications herein, we have focused on the use of GP-BART for
       spatial datasets, but there is nothing to prohibit the model being used
       in generic machine learning tasks. ",stat.ME,C,-0.4106735,-0.24485469,-0.27183867
http://arxiv.org/pdf/2204.02112v2,GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes,"Though
       our strategy of initialising GP-BART by a warm-up step that uses
       BART on the ﬁrst phase of MCMC iterations substantially reduces
       this cost, approximations for the GP — using for example the Nystro¨m
       method [27] or the methods of Quin˜onero-Candela et al. [24] — might
       prove to be advantageous in future work. • In the applications herein, we have focused on the use of GP-BART for
       spatial datasets, but there is nothing to prohibit the model being used
       in generic machine learning tasks. ",stat.ME,C,-0.4106735,-0.24485469,-0.27183867
http://arxiv.org/pdf/2204.02112v3,GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes,"This is most likely attributable to the underlying
       exponentiated-quadratic kernel functions used in our parameterisation
       of the GP components being inappropriate for these data. This reaf-
       ﬁrms that investigating alternative kernels could be of great interest for
       future work, particularly kernels capable of accommodating the non-
       continuous features we discarded in our analysis of these data. We hope to report on these developments as part of our future research plans. ",stat.ME,C,-0.18728626,-0.008415853,-0.14030562
http://arxiv.org/pdf/2204.02170v1,Semiparametric Approach to Estimation of Marginal and Quantile Effects,", m to estimate the marginal eﬀect ξ by

                                                     m 2
                                                          y pr(Y = y|xi; β, c)  . n     m
                                                      y=0
ξ ≡ β n−1  y2 pr(Y = y|xi; β, c) −

i=1 y=0

Because there is no generally accepted unique way of deﬁning quantiles for discrete data,
we do not further study the quantile eﬀect estimation in this case. 3 Theoretical Properties

We now establish the theoretical properties of our proposed estimators for both the marginal
eﬀect and the quantile eﬀect in (4). ",stat.ME,C,-0.04254193,-0.035263076,0.3785811
http://arxiv.org/pdf/2204.02271v1,Methods for Combining Probability and Nonprobability Samples Under Unknown Overlaps,"The re-
verse implication is that the classical setting for Lancaster and Imbens (1996) could be estimated
more efﬁciently by setting ψ = 1. Investigating whether this simpliﬁcation for ψ = 1 holds for
more complex applications such as k-indexed simultaneous outcomes with uniques values for ψk
(Johnson et al., 2021) is a subject for future work. The proof holds even when the reference sample is the entire target population U. ",stat.ME,C,-0.008797875,0.060956888,0.20995489
http://arxiv.org/pdf/2204.02477v1,Method of Winsorized Moments for Robust Fitting of Truncated and Censored Lognormal Distributions,"Their transformations, and number of loss observations within
each range of contract are also summarized in Table 6.1. Without considering the robustness, we ﬁrst compare the performance of three candidate mod-
els – stand-alone lognormal, composite LNPaI, and composite LNGPD (mentioned in Section 3.3),
and determine the benchmark for further study of adaptive robust estimators. In this stage, all
the parameters are estimated via maximum likelihood estimation and the corresponding statistics
and performance indicators (such as Negative log-likelihood and Akakie Information Criterion) are
illustrated in Table 6.2. ",stat.ME,C,-0.11813708,-0.070424385,0.22238757
http://arxiv.org/pdf/2204.03602v1,A General Class of Trimodal Distributions: Properties and Inference,"In Section 7, the real data sets are applied. Section 8 is for
conclusion and future works. In Appendices as a supplementary material, we provide proofs and codes
of Mathematica software. ",stat.ME,A,-0.25017986,0.13081567,-0.06265452
http://arxiv.org/pdf/2204.03887v2,Uniformly Valid Inference Based on the Lasso in Linear Mixed Models,"While the penalty term of the smoothly clipped absolute
deviations estimator (SCAD) [Fan and Li, 2001] does not exhibit this property, it is
particularly intricate to treat and leads to a non-convex objective function. Therefore,
while these methods behave similarly to the ordinary Lasso, an extension of our ﬁndings
for them requires substantial additional research, which is out of the scope of the current
work. It should be noted that among Lasso, adaptive Lasso and SCAD, P¨otscher and
Schneider [2010] show that in the case of orthogonal regressors, using the Lasso leads to
the shortest intervals in ﬁnite samples, strengthening our approach. ",stat.ME,C,-0.21110253,0.032178536,0.17377688
http://arxiv.org/pdf/2204.04119v1,Bespoke Instrumental Variables for Causal Inference,"With multiple
plausible bespoke IVs, the ATT may become over identiﬁed, and speciﬁcation tests (like
the Sargen-Hansen test) can then be employed to assess the validity of the identifying
assumptions described here. How to optimally combine or synthesise evidence from multiple
bespoke IVs is an important area for future work. References

Abadie, A., Diamond, A., and Hainmueller, J. ",stat.ME,B,0.30947033,0.20798236,0.15411764
http://arxiv.org/pdf/2204.04119v2,Semiparametric Bespoke Instrumental Variables,"With multiple
plausible bespoke IVs, the ATT may become over identiﬁed, and speciﬁcation tests (like
the Sargen-Hansen test) can then be employed to assess the validity of the identifying
assumptions described here. How to optimally combine or synthesise evidence from multiple
bespoke IVs is an important area for future work. 34
Table 2: Results from the analysis of the Life Span study under diﬀerent model choices. ",stat.ME,B,0.43122515,0.124558665,0.12890078
http://arxiv.org/pdf/2204.04119v3,Semiparametric Bespoke Instrumental Variables,"With multiple
plausible bespoke IVs, the ATT may become over identiﬁed, and speciﬁcation tests (like
the Sargen-Hansen test) can then be employed to assess the validity of the identifying
assumptions described here. How to optimally combine or synthesise evidence from multiple
bespoke IVs is an important area for future work. 34
Table 2: Results from the analysis of the Life Span study under diﬀerent model choices. ",stat.ME,B,0.43122515,0.124558665,0.12890078
http://arxiv.org/pdf/2204.04270v1,Conformalized Frequency Estimation from Sketched Data,"Even though the expected proportion of incorrect unique queries is sometimes below

                                                                12
α (Figures A14–A15), this is not always the case (Figure A16). It may be possible to modify the
procedure to achieve this additional guarantee, but we leave this intriguing problem for future work. Software availability

Code and data needed to reproduce these experiments are available online at https://github. ",stat.ME,A,-0.0792895,0.39581245,0.0361436
http://arxiv.org/pdf/2204.04270v2,Conformal Frequency Estimation with Sketched Data,"Even though the expected proportion of incorrect unique
queries is sometimes below α (Figures A14–A15), this is not always the case (Figure A16). It may
be possible to modify our procedure to achieve this additional guarantee, but we leave this problem
for future work. Future research may also study theoretically, in some settings, the length of our
conformal conﬁdence intervals, following for example an approach similar to those of [16, 47]. ",stat.ME,A,-0.15167648,0.3862797,0.11384192
http://arxiv.org/pdf/2204.04309v1,Long-term effect estimation when combining clinical trial and observational follow-up datasets,"Partly interval-censored data for Cox regression has been studied in Kim (2003),Cai
and Betensky (2003) and the estimation is more diﬃcult than right-censored data. For
simplicity, we do not deal with interval-censoring in the current paper and leave that to

                                                        58
future work. Instead we consider an alternative approach that transforms the interval-
censored data to right-censored data. ",stat.ME,B,0.26967755,-0.12601003,0.11412971
http://arxiv.org/pdf/2204.04973v1,Consistent Estimators for Nonlinear Vessel Models,"Obtaining consistent parameter
disturbance observers. Potential future work is to see how                          estimators for second-order modulus models. IEEE Control Systems
accurately the ﬁrst and second-order moments of the envi-                           Letters, 3(4):781–786, 10 2019.
ronmental disturbances can be estimated in the case where a
model of the undisturbed system is already known. ",stat.ME,C,-0.042063743,-0.12902106,0.18916732
http://arxiv.org/pdf/2204.05028v1,Robust and Efficient Parameter Estimation for Discretely Observed Stochastic Processes,"This work opens up a new direction of further research on the robust and efﬁcient parametric statistical inference for
more general stochastic processes. An immediate future work would be to extend the MDPDEs for general stochastic
process instead of restricting to speciﬁc dependence structure such as in Independent Increment Process or Markov
Process. One possible approach could be to extend the conditional density based deﬁnition from the Markov process
set-up to the general setup, through using the conditional density of X(ti) given X(ti−1), . ",stat.ME,C,-0.09240696,-0.32925928,0.15322372
http://arxiv.org/pdf/2204.05602v1,Strategic model reduction by analysing model sloppiness: a case study in coral calcification,"However, because in our case study the prior distribution was weakly informative on the poste-
rior, it is diﬃcult to state what the outcomes of informing model reductions via a LIS analysis
would show, if informative priors were instead used. Although we leave this exploration for
future work, we hypothesis that model reduction informed by LIS could yield reduced models
based purely on retaining mechanisms for which the data is highly informative relative to prior
beliefs for each mechanism. At the very least, the LIS method is a useful check to identify the
inﬂuence of the data on the model calibration process within a Bayesian framework. ",stat.ME,C,0.051577162,-0.24757239,-0.010166599
http://arxiv.org/pdf/2204.05602v2,Strategic model reduction by analysing model sloppiness: a case study in coral calcification,"process-based models). However, future work could examine how this

                                                             20
model reduction technique performs on various other types of models. For instance, Monsalve-
Bravo et al. ",stat.ME,C,-0.028210811,-0.07351281,-0.17844206
http://arxiv.org/pdf/2204.05827v1,Correction of overfitting bias in regression models,"In these applications we did not
yet include censoring, which is a distinctive feature of Survival data. The general theory is
conjectured to be still applicable to survival analysis models with censoring, but its equations
would be more involved, and hence this is left for future work. An alternative route would be
to use the so called pseudo observations from Andersen et al [1]. ",stat.ME,B,0.2219117,-0.15193716,0.092345774
http://arxiv.org/pdf/2204.06030v1,Variable importance measures for heterogeneous causal effects,"Here we
                                                  present new nonparametric treatment eﬀect variable importance measures (TE-VIMs). These may guide
                                                  clinicians as to which patient characteristics are important to consider when making treatment decisions,
                                                  and help researchers stratify patient populations for further study. TE-VIMs extend recent regression-
                                                  VIMs, viewed as nonparametric analogues to ANOVA statistics. ",stat.ME,B,0.37899733,0.11687694,-0.051844366
http://arxiv.org/pdf/2204.06632v1,Recurrent event analysis in the presence of real-time high frequency data via random subsampling,"We show limited loss of eﬃciency when the subsampling
is properly tuned to the event rates. Important extensions to an online sampling algo-
rithm, optimal weighting when the Poisson point process assumption does not hold, and
non-linear functional data methods are considered important future work. References

P.K. ",stat.ME,C,-0.1851016,-0.17814156,0.10627705
http://arxiv.org/pdf/2204.06911v1,Robust Bayesian inference in complex models with possibility theory,"Yet, they can be computed exactly with a
complexity of the order of t, which is easily achievable even for large values of t. The main limitation
of this model is that it introduces an additional tuning parameter c, which must be suitably chosen. Finding automatic ways to set c depending on prior information on the problem at hand will be the
topic of future work. The proposed solution is illustrated in a scenario where the true parameter is θ∗ = 100 and where
there are T = 100 observations. ",stat.ME,C,-0.27215475,-0.022551548,-0.024161179
http://arxiv.org/pdf/2204.07105v1,Nonresponse Bias Analysis in Longitudinal Educational Assessment Studies,"In either setting, the key to a strong
analysis is the availability of strong auxiliary variables that are not predictors in the regression
model of interest. As regards future work, data integration of multiple sources can improve NRBA by
providing better auxiliary information for nonresponse adjustment, and benchmark information
for external validation. We focused on a monotone dropout, which is the predominant pattern in

                                                                                                                   30
    the ECLS-K:2011 study; MI is one approach that can handle intermittent missingness patterns
    (e.g., Si, Palta, & Smith, 2020). ",stat.ME,B,0.23708846,-0.03569485,-0.15930569
http://arxiv.org/pdf/2204.07105v2,Nonresponse Bias Analysis in Longitudinal Educational Assessment Studies,"In either setting, the key to a strong
analysis is the availability of strong auxiliary variables that are not predictors in the regression
model of interest. As regards future work, data integration of multiple sources can improve NRBA by
providing better auxiliary information for nonresponse adjustment, and benchmark information
for external validation. We focused on a monotone dropout, which is the predominant pattern in
the ECLS-K:2011 study; MI is one approach that can handle intermittent missingness patterns

                                                                                                                   30
(e.g., Si, Palta, & Smith, 2020). ",stat.ME,B,0.22952962,-0.034703515,-0.15800795
http://arxiv.org/pdf/2204.07207v1,Hierarchical Embedded Bayesian Additive Regression Trees,"Optionally, we can use the prior k1/τ ∼ Half-Cauchy(φ),
or even Penalized Complexity Priors (Simpson, Rue, Riebler, Martins, & Sørbye 2017). We also set the prior µ ∼ N(0, k2τ −1/P), where k2 is ﬁxed

for now, but it could also get a prior/be sampled in future work. As for the overall residual precision τ , its prior is set as τ ∼ Ga(α, β), where α and

β are ﬁxed. ",stat.ME,C,-0.25876412,-0.013425982,0.14087656
http://arxiv.org/pdf/2204.09231v1,Optimal reconciliation with immutable forecasts,"It is worth to explore whether theoretical properties of
times series can be used to automate this process. Due to the diversity between diﬀerent
forecasting methods and the heterogeneity across diﬀerent datasets, the performance of the
forecast reconciliation framework may not be robust, therefore further research, particularly on

                                                             21
impact of the covariance matrix estimation is needed. Acknowledgments

    Yanfei Kang is supported by the National Natural Science Foundation of China (No. ",stat.ME,C,-0.0693733,-0.30639818,-0.14897203
http://arxiv.org/pdf/2204.09862v1,The $θ$-augmented model for Bayesian semiparametric inference on functional parameters,"Further research is needed to tackle this problem either from the algorithmic or theoretical front. Also relating to algorithms, further research on algorithmic eﬃciency of θ-augmented Bayesian inference
in large samples is helpful to determine the applicability of the θ-augmented model to large datasets. Finally, by requiring that the proposal model of a θ-augmented model be necessarily dominated, we are
limited in the class of nonparametric models that can be used to describe the observable random variable. ",stat.ME,C,-0.09937439,-0.2612025,0.0725341
http://arxiv.org/pdf/2204.09862v2,Targeting functional parameters with semiparametric Bayesian inference,"Further research is needed to tackle
this problem either from the algorithmic or theoretical front. Also relating to algorithms, further research
on algorithmic eﬃciency of θ-augmented Bayesian inference in large samples is helpful to determine the
applicability of the θ-augmented model to large datasets. Finally, choosing targets of inference that are functionals of the distribution for the observable provides
a simple way to avoid model misspeciﬁcation and counters the perception that the Bayesian paradigm is

                                                                     12
more limiting than the Frequentist simply because it always requires a likelihood. ",stat.ME,C,-0.08260545,-0.23541597,0.013088219
http://arxiv.org/pdf/2204.10147v1,Testing the equality of two coefficients of variation: a new Bayesian approach,"Then, Section 3 deals with the
comparison between two coeﬃcients of variation and provides, on a case-by-case basis,
the tools needed for that particular scenario, which are subsequently used in the related
examples taken from the literature. Finally, the last section contains conclusions and
guidelines to be followed for further research. As far as we know, some of the test analysed have not been investigated before in the
literature, see Section 3.3 concerning the Skew-Normal case and 3.4 the Negative Binomial
one. ",stat.ME,A,0.08104609,0.29024237,0.29652953
http://arxiv.org/pdf/2204.10291v1,Structural Nested Mean Models Under Parallel Trends Assumptions,"This strange combination of assumptions (i.e. that
treatments must have delayed eﬀects but unobserved confounders only short term
eﬀects) leads us not to present our current results for survival outcomes, but we
do wish to point out that extension of DiD to time-to-event settings via structural
nested models may still be a promising direction for future work. 6.5 Repeated Cross Sectional Data

In this paper, we have assumed throughout that panel data are available. ",stat.ME,B,0.48079747,-0.15705457,-0.038024746
http://arxiv.org/pdf/2204.10291v2,Structural Nested Mean Models Under Parallel Trends Assumptions,"This strange combination of assumptions (i.e. that
treatments must have delayed eﬀects but unobserved confounders only short term
eﬀects) leads us not to present our current results for survival outcomes, but we
do wish to point out that extension of DiD to time-to-event settings via structural
nested models may still be a promising direction for future work. 8.4 Repeated Cross Sectional Data

In this paper, we have assumed throughout that panel data are available. ",stat.ME,B,0.47675267,-0.16152468,-0.036395784
http://arxiv.org/pdf/2204.10291v3,Structural Nested Mean Models Under Parallel Trends Assumptions,"This strange combination of assumptions (i.e. that
treatments must have delayed eﬀects but unobserved confounders only short term
eﬀects) leads us not to present our current results for survival outcomes, but we
do wish to point out that extension of DiD to time-to-event settings via structural
nested models may still be a promising direction for future work. 8.4 Controlled Direct Eﬀects

We mentioned in passing that SNMM treatments may be multi-dimensional. ",stat.ME,B,0.35377377,-0.15413168,-0.06166029
http://arxiv.org/pdf/2204.10291v4,Structural Nested Mean Models Under Parallel Trends Assumptions,"This strange combination of assumptions (i.e. that
treatments must have delayed eﬀects but unobserved confounders only short term
eﬀects) leads us not to present our current results for survival outcomes, but we
do wish to point out that extension of DiD to time-to-event settings via structural
nested models may still be a promising direction for future work. 8.4 Controlled Direct Eﬀects

We mentioned in passing that SNMM treatments may be multi-dimensional. ",stat.ME,B,0.35377377,-0.15413168,-0.06166029
http://arxiv.org/pdf/2204.10426v1,Marginal Structural Illness-Death Models for Semi-Competing Risks Data,"[2022] Our multi-state structural models
instead consider the total eﬀect of the exposure on all three outcomes: non-terminal event, and
terminal event with and without non-terminal event. For future work, since the IPW estimator is biased if the propensity score model is misspeciﬁed,
an augmented IPW (AIPW) estimator with doubly robust properties can protect against such model
misspeciﬁcation. It would also allow us to apply machine learning or nonparametric methods to

                                                         11
the propensity score model. ",stat.ME,B,0.3094239,-0.11721639,-0.014225042
http://arxiv.org/pdf/2204.10426v2,Marginal Structural Illness-Death Models for Semi-Competing Risks Data,"In contrast we have considered coun-
terfactual systems that are characterized by their respective transition rates, and further
developed risk estimates that can be of use in practice. For future work, since the IPW estimator is biased if the propensity score model is mis-
speciﬁed, an augmented IPW (AIPW) estimator with doubly robust properties can protect
against such model misspeciﬁcation. It would also allow us to apply machine learning or
nonparametric methods to the propensity score model. ",stat.ME,B,0.30436057,-0.1497845,0.044063866
http://arxiv.org/pdf/2204.10508v1,Imputation with verifiable identification condition for nonignorable missing outcomes,"Rubin’s variance formula eases the complicated calculation of the asymptotic
variance of estimators. However, the congeniality condition requires further
discussion to guarantee the applicability of the Rubin’s variance formula,
which forms the scope of future work. Acknowledgement

The research of the second author was supported by MEXT Project for
Seismology toward Research Innovation with Data of Earthquake (STAR-E)
Grant Number JPJ010217 and JSPS KAKENHI Grant Number JP19186222. ",stat.ME,C,0.042602982,-0.09052292,0.33339214
http://arxiv.org/pdf/2204.10572v1,Notip: Non-parametric True Discovery Proportion estimation for brain imaging,"This method could                                                 dence bounds on false positives using reference families. Annals of Statis-
be extended to multivariate linear models in future work. [7]                                               tics, 48(3):1281–1303, 2020. ",stat.ME,B,0.11971138,0.010417711,0.1970307
http://arxiv.org/pdf/2204.10572v2,Notip: Non-parametric True Discovery Proportion control for brain imaging,"Notice that Notip is able to offer less                    Calibration
conservative guarantees on the TDP in all clusters than both                         The ﬁnal step of the procedure is to perform calibration
ARI and calibrated Simes. In Table 3 we retain 3 clusters
among the 9 found in Table 2 for further study, i.e. chang-                      using the randomized p-values that we previously computed. ",stat.ME,C,-0.21069857,0.206382,0.031825304
http://arxiv.org/pdf/2204.10736v1,Analysing Opportunity Cost of Care Work using Mixed Effects Random Forests under Aggregated Census Data,"Apart
from generalizations to quantiles, the approach of this paper is generalizable to model
(complex) spatial correlations. Additionally, a generalization towards binary or count
data is possible and left to further research. The semi-parametric composite formulation
of Model (1) allows for f to adapt any functional form regarding the estimation of the
conditional mean of yij given xij and technically transfers to other machine learning
methods, such as gradient-boosted trees or support vector machines. ",stat.ME,C,-0.06752645,-0.23152624,-0.09528556
http://arxiv.org/pdf/2204.10852v1,A Generalization of Ripley's K Function for the Detection of Spatial Clustering in Areal Data,"When the number
of observed areal units is large, the Monte Carlo simulations may be run in
parallel to reduce computation time. The development of faster methods for
approximating the null distribution is an excellent area for future work. Funding

SS and AM were supported in part by the Research Center for Child Well-
Being [NIGMS P20GM130420]. ",stat.ME,C,0.041151974,0.001447605,-0.11071822
http://arxiv.org/pdf/2204.10929v1,Bayesian Spatiotemporal Modeling for Inverse Problems,"These novel qualitative results imply that
the parameter learning (based on EnK methods) with the STGP model converges faster
than the other two traditional methods. In the future work, we will explore a quantitative
characterization on their convergence rates particularly in terms of covariance properties. The STGP model (16) considered in this paper has a classical separation structure
in their joint kernel. ",stat.ME,C,-0.23332717,-0.2074292,-0.08950803
http://arxiv.org/pdf/2204.10969v1,When Doubly Robust Methods Meet Machine Learning for Estimating Treatment Effects from Real-World Data: A Comparative Study,"Section 3 presents the extensive comparative simulations and Section 4 reports on
performance of these estimators on a real-world application. Section 5 concludes the paper
and discusses potential future works. 3
2 Methodology: Singly and Doubly Robust Estima-

     tors

2.1 Notations, Assumptions, and Estimand

All aforementioned methods are based on the potential outcomes framework (Neyman;
1923; Rubin; 1974). ",stat.ME,B,0.09809527,-0.13586819,0.27238482
http://arxiv.org/pdf/2204.11979v1,Trials with Irregular and Informative Assessment Times: A Sensitivity Analysis Approach,"Additionally, here we used bootstrap-t conﬁdence
intervals constructed using an inﬂuence function-based variance estimator. These conﬁ-
dence intervals undercovered at large values of the sensitivity parameter; future work could
investigate methods for improving coverage, for example using the double bootstrap [15]. 9 Funding

Shu Yang’s research is partially supported by NSF DMS 1811245, and by NIH 1R01AG066883
and 1R01ES031651. ",stat.ME,B,0.08617933,0.027230542,0.18744951
http://arxiv.org/pdf/2204.12135v1,Robust Two-Layer Partition Clustering of Sparse Multivariate Functional Data,"Overall, RTLP has a
signiﬁcant advantage in terms of clustering precision regardless of the outliers and the time
sparseness settings. In future works, the RTLP and current clustering methods can be applied to more gen-
eral sparse (multivariate) functional data, where the measurement can be observed for some
variables but could be missing for other variables for one index (more types of sparseness are
described in Qu & Genton 2022), which requires a more general distance measure. In addition,
the aforementioned clustering methods can be applied to multivariate nonfunctional data. ",stat.ME,A,-0.11192132,0.13091356,-0.3628453
http://arxiv.org/pdf/2204.12135v2,Robust Two-Layer Partition Clustering of Sparse Multivariate Functional Data,"Overall, RTLP has a signiﬁcant advantage
in terms of clustering precision regardless of the outliers and the time sparseness settings. 29
    In future works, the RTLP and current clustering methods can be applied to more general
sparse (multivariate) functional data, where the measurement can be observed for some variables
but could be missing for other variables for one index (more types of sparseness are described
in Qu & Genton 2022), which requires a more general distance measure. In addition, the afore-
mentioned clustering methods can be applied to multivariate nonfunctional data. ",stat.ME,A,-0.110745125,0.12581472,-0.36557013
http://arxiv.org/pdf/2204.12346v1,On automatic calibration of the SIRD epidemiological model for COVID-19 data in Poland,", n.

Hence, the main cost function for a single arbitrarily chosen compartment is deﬁned
as one of the previously introduced low-level functions with respect to the speciﬁed
compartment. For the ﬁrst part of further research we chose compartment D, since
it seemed to exhibit a signiﬁcant consistency with the real-world data reports. As a
result we ponder four cost-functions and deﬁned them using the following notation

   FDC = C(D) for C ∈ {MXSE, MSE, MAE, MAPE}. ",stat.ME,A,-0.19524963,0.15247932,-0.033208378
http://arxiv.org/pdf/2204.12447v1,E-values as unnormalized weights in multiple testing,"In summary, if handling arbitrary dependence is a concern in practice and ranks of exchangeable
statistics are being used as p-values, then switching to e-values may be a competitive alternative. Further examination of this special case, including a practical way to choose the free parameter r, is
left to future work. 5.3 E-values as masks in interactive multiple testing

    Since the original work by Lei and Fithian [15], the idea of “masking” p-values in order to enable
user interaction during a multiple testing procedure has received much attention [16, 6, 7]. ",stat.ME,B,0.15229577,0.3778576,0.07879713
http://arxiv.org/pdf/2204.12447v2,E-values as unnormalized weights in multiple testing,"In summary, if handling arbitrary dependence is a concern in practice and ranks of exchangeable
statistics are being used as p-values, then switching to e-values may be a competitive alternative. Further examination of this special case, including a practical way to choose the free parameter r, is
left to future work. 5.3 E-values as masks in interactive multiple testing

    Since the original work by Lei and Fithian [15], the idea of “masking” p-values in order to enable
user interaction during a multiple testing procedure has received much attention [16, 6, 7]. ",stat.ME,B,0.15229577,0.3778576,0.07879713
http://arxiv.org/pdf/2204.12635v1,Multivariate and regression models for directional data based on projected Pólya trees,"However it might not be easy
                                                          l=1

to determine an optimal maximum depth for each coordinate because we do not actually

observe data in Rk, we observe data in the hypersphere Sk, which is characterised by k − 1

directions and augment them with an extra latent resultant to produce data in the whole

space Rk, so we can not easily identify coordinates that would require ﬁner partitions. Proposing solutions to solve the computational burden, due to the curse of dimensionality,

                         19
is open and left for further study in a future work. Acknowledgements

The author acknowledges support from Asociaci´on Mexicana de Cultura, A.C.

References

Downs, T.D. ",stat.ME,A,-0.35012776,0.1458603,-0.27212954
http://arxiv.org/pdf/2204.12733v1,Modeling complex measurement error in microbiome experiments,"In addition, while we focus applications of our model on microbiome data, our model could be
applied to a broad variety of data structures obtained from high-throughput sequencing, such as
single-cell RNAseq. We leave these applications to future work. Software implementing the methodology described in this paper are implemented in a R package
available at https://github.com/statdivlab/tinyvamp. ",stat.ME,A,-0.07751431,0.06343756,-0.36583593
http://arxiv.org/pdf/2204.13193v1,On randomization inference after inexact Mahalanobis matching,"As discussed in Pashley et al [41, Section 5], the
usual justiﬁcation for design-based sensitivity analysis also not apply in the presence of inexact matching. The extent to which regression adjustment or alternative matching schemes can make up for this is an
important question for future work. Acknowledgement

We are grateful to Sky Cao, John Cherian, Peng Ding, Colin Fogarty, Isaac Gibbs, Samir Khan, Sam
Pimentel, Fredrik S¨avje and seminar participants at the 2021 Stanford Causal Science Center conference for
helpful comments and discussions. ",stat.ME,B,0.17945994,0.17007808,0.089342244
http://arxiv.org/pdf/2204.13248v1,Controlling the False Discovery Rate via knockoffs: is the +1 needed?,"Similarly, it is highly unusual to

have irrational values of c or α in practice, thus 1−c c α is almost always rational. Loosening these assumptions is an area for future work. Note that under the conditions of Theorem 2, Theorem 1 suggests that

using t > 1 − 1/b controls the FDR, while using t = 1 − u/b with u ≥ a is not

guaranteed to control the FDR. ",stat.ME,C,-0.13763702,0.30930644,0.14349614
http://arxiv.org/pdf/2204.13248v2,Controlling the False Discovery Rate via Competition: is the +1 needed?,"Similarly, it
is highly unusual to have irrational values of c or α in practice, thus 1−c c α is
almost always rational. Loosening these assumptions is an area for future work. Note that under the conditions of Theorem 2, Theorem 1 suggests that
using t > 1 − 1/b controls the FDR, while using t = 1 − u/b with u ≥ a is not
guaranteed to control the FDR. ",stat.ME,C,-0.13763702,0.30930644,0.14349614
http://arxiv.org/pdf/2204.13782v1,Pragmatic Clinical Trials in the Rubric of Structural Causal Models,"Thus, adherence to the trial is vital, and causal eﬀect estimation
becomes complex when the information is unavailable or hard to determine. Future Works Our future work will include instrumental variable analysis (Bareinboim
and Pearl, 2012), by using treatment X in Figure 4 as an instrumental variable for the pro-
posed causal graph. We will additionally explore time-series intervention with the deﬁnition
proposed, in place of point intervention, by altering the SCM and related transportability
equations. ",stat.ME,B,0.28060022,-0.15201601,0.06536132
http://arxiv.org/pdf/2204.13854v1,Hellinger-Bhattacharyya cross-validation for shape-preserving multivariate wavelet thresholding,"Along the way, we proposed a novel thresholding approach, based
on a jackknife estimation of the variance of each estimated wavelet coeﬃcient – this again ﬁts perfectly within the
considered framework of Hellinger-Bhattacharyya cross-validation. This thresholding scheme has proved superior to
other, more classical thresholding options in the simulations, and deﬁnitely deserves further research in a follow-up
paper. Appendix

Let An the search space for λ above in the ‘weighted delta sequence’ (2.9) for a sample of size n. We introduce the
following additional assumptions on An:

Assumption 1. ",stat.ME,C,-0.17253622,0.044271395,0.11006217
http://arxiv.org/pdf/2204.13975v1,Conditional average treatment effect estimation with treatment offset models,"The newly
introduced constraint on the implied marginal odds-ratio improved the PEHE even more. Further extensions of the oﬀset method for CR-CATE models remain for future work. Acknowledgments

We are very thankful to Nan van Geloven for providing feedback on an earlier version of this
manuscript. ",stat.ME,C,0.012549073,0.0048725344,0.23289356
http://arxiv.org/pdf/2204.14063v1,greed: An R Package for Model-Based Clustering by Greedy Maximization of the Integrated Classification Likelihood,"Finally, handling models for which there exists no explicit formula of the ICLex criterion
is a natural direction. However, it would required the adaptation of the two main algorithms
to handle the approximation steps and is therefore postpone to future works. References

Akaike H (1974). ",stat.ME,C,-0.20169204,-0.04036409,0.024744753
http://arxiv.org/pdf/2204.14112v1,Multiscale Partial Information Decomposition of Dynamic Processes with Short and Long-range correlations: Theory and Application to Cardiovascular Control,"‘Eﬃcient computation of multiscale entropy over                 URL: https://CRAN.R-project.org/package=emmeans
        short biomedical time series based on linear state-
        space models’, Complexity 2017. Lizier, J. T., Bertschinger, N., Jost, J. and Wibral,
                                                                        M. (2018), ‘Information decomposition of target
Faes, L., Porta, A. and Nollo, G. (2015), ‘Information                  eﬀects from multi-source interactions: Perspectives
        decomposition in bivariate systems: theory and                  on previous, current and future work’. application to cardiorespiratory dynamics’, Entropy
        17(1), 277–303. ",stat.ME,C,-0.094672166,-0.16823009,-0.22425091
http://arxiv.org/pdf/2204.14121v2,Inverse Probability Weighting: from Survey Sampling to Evidence Estimation,"Hesterberg, 1988], where the Horvitz–Thompson es-
timator is likened to the na¨ıve importance sampling, and much like survey
sampling, self-normalized weights or using control variates lead to better esti-
mators. We conclude with a brief discussion of applications in the context of
causal inference, a key use of IPW estimators, and a few possible directions for
future work. A possible future direction, borrowing from [Kong et al., 2003] is to use the
general semiparametric models and the associated estimators or computational
algorithm for k > 1 in the context of survey sampling that would allow one to
combine data from one or more surveys that use different but known inclusion
probabilities. ",stat.ME,B,0.16493899,-0.14717403,0.17821404
http://arxiv.org/pdf/2204.14165v1,Distributed Inference for Spatial Extremes Modeling in High Dimensions,"The proposed distributed inference approach can be directly
applied to any process that permits a bivariate density function and is thus broadly appli-
cable. However, future work is needed to verify the theoretical and statistical performance
of the approach for processes other than the MSP. Future work would also extend to a
spatiotemporal analysis to investigate climate change eﬀects on the distribution of extreme
streamﬂow. ",stat.ME,C,-0.10106352,-0.3807564,-0.059399232
http://arxiv.org/pdf/2205.00093v1,Bayesian Benefit Risk Analysis,"The introduced model assessment
framework does not examine cross-dependencies between binary and continuous data when it comes to goodness of
ﬁt and predictive performance as this is not a straightforward task. Finding metrics to do so is an interesting open
problem which is left for further research. In this paper, we proceeded requiring good performance on both marginal
parts of the data in the absence of a better alternative in line with Moustaki (1996). ",stat.ME,B,0.11829649,0.01235345,-0.1255554
http://arxiv.org/pdf/2205.00304v1,A General Framework For Constructing Locally Self-Normalized Multiple-Change-Point Tests,"Besides, our pro-
posal is driven by intuitive principles, so that as long as a one-change detecting statistic
is provided, our proposal can generalize it to a multiple-change detecting statistic. We
anticipate that our framework can be applied to non-time-series data, e.g., spatial data
and spatial–temporal data, in future work. A Proofs of theorems

Proof of Theorems 3.1 and 3.2. ",stat.ME,C,-0.036785793,-0.124588,0.017380428
http://arxiv.org/pdf/2205.00709v1,Computationally efficient and data-adaptive changepoint inference in high dimension,"A related issue is does the asymptotic normality still holds for the sum-L2-type statistic for
temporally dependent high-dimensional time series (e.g., under Assumptions A1–A2). We
leave them as future work. Supplementary material

The supplementary material collects all proofs of Theorems 1, 2 and 3, together with some
necessary lemmas. ",stat.ME,C,-0.059431627,-0.21772462,0.25834203
http://arxiv.org/pdf/2205.00901v1,Beyond Neyman-Pearson,"To the likelihood principle (Edwards,
1984) and to Dawid’s (1999) prequential principles? All of these comparisons are bound to
lead to interesting insights and provide lots of opportunity for future work! 6 Acknowledgements

I am much indebted to the pioneering work by Vovk (1993) (which foreshadows the use of
e-variables in a Neyman-Pearson setting) and the many subsequent works by Vovk and Shafer
on testing by betting, as culminating in (Shafer, 2021) and the text book (Shafer and Vovk,
2019). ",stat.ME,B,0.13721684,0.04054023,0.29260495
http://arxiv.org/pdf/2205.01016v1,Graphical Evidence,"(2022). Application of the technique developed in the current paper appears feasible in all these instances

                                                                    24
and should be considered future work. A further promising future direction is to shift focus from the prior to the likelihood. ",stat.ME,C,-0.058262285,-0.025884435,0.082322836
http://arxiv.org/pdf/2205.01016v2,Graphical Evidence,"(2022). Application of the technique developed in the current paper appears feasible in all these instances
and should be considered future work. A further promising future direction is to shift focus from the prior to the likelihood. ",stat.ME,C,-0.0605932,-0.07593954,0.11324192
http://arxiv.org/pdf/2205.01035v1,An information-theoretic approach to hypergraph psychometrics,"Please note that the
metrics introduced in (Stramaglia et al., 2021) can be used to calculate conditional
O-information metrics, which provide a close simile to the conditional correlation that is
often used in the network psychometric literature. Other interesting avenues of interesting
future work include leveraging recent algorithms to identify hypergraph centrality (Tudisco
& Higham, 2021) and modularity (Chodrow et al., 2021; Kamiński et al., 2020), and also
harmonic analysis and dimensionality reduction (Medina-Mardones et al., 2021). One limitation of the O-information (and any other coarse-grained metric over an
information decomposition (Williams & Beer, 2010)) is that a multiplet is labelled as
synergistic or redundant depending on its sign, and in this sense it reﬂects the net balance
between the two quantities and only acknowledges the dominant one. ",stat.ME,A,0.017689072,0.1767504,-0.18175441
http://arxiv.org/pdf/2205.01035v2,An information-theoretic approach to hypergraph psychometrics,"Please note that the
metrics introduced in (Stramaglia et al., 2021) can be used to calculate conditional
O-information metrics, which provide a close simile to the conditional correlation that is
often used in the network psychometric literature. Other interesting avenues of interesting
future work include leveraging recent algorithms to identify hypergraph centrality (Tudisco
& Higham, 2021) and modularity (Chodrow et al., 2021; Kamiński et al., 2020), and also
harmonic analysis and dimensionality reduction (Medina-Mardones et al., 2021). One limitation of the O-information (and any other coarse-grained metric over an
information decomposition (Williams & Beer, 2010)) is that a multiplet is labelled as
synergistic or redundant depending on its sign, and in this sense it reﬂects the net balance
between the two quantities and only acknowledges the dominant one. ",stat.ME,A,0.017689072,0.1767504,-0.18175441
http://arxiv.org/pdf/2205.01285v1,A Flexible Approach for Predictive Biomarker Discovery,"The study of other semiparametric estimators of these parameters, such as one-step
estimators or targeted maximum likelihood estimators, might also prove fruitful. Finally, future work might assess
whether using our method to ﬁlter the set of potentially predictive biomarkers prior to estimating treatment rules
improves their accuracy and interpretability. Software

The uniCATE method is implemented in the open-source uniCATE R software package at github.com/
insightsengineering/uniCATE. ",stat.ME,B,0.26289552,0.059695043,-0.18725756
http://arxiv.org/pdf/2205.01285v2,A Flexible Approach for Predictive Biomarker Discovery,"The study of other non and semiparametric estimators of these parameters, such
as one-step estimators or targeted maximum likelihood estimators, might also prove fruitful. Finally, future work
might assess whether treatment effect variable importance parameter inference procedures could be coupled with novel
multiple testing adjustment approaches, like that of Fithian and Lei [2020], to better account for the complex correlation
structures often found among biomarkers. Software

The uniCATE method is implemented in the open-source uniCATE R software package at github.com/
insightsengineering/uniCATE. ",stat.ME,B,0.33917543,0.14435765,-0.12243323
http://arxiv.org/pdf/2205.01804v1,Data fusion for predicting long-term program impacts,"In
contrast, many evaluations will be of treatments that cannot be randomized due to logistical
or ethical constraints. We leave the cases of nonrandomized interventions for future work. REFERENCES

Athey, S., R. Chetty, G. W. Imbens, and H. Kang (2019). ",stat.ME,B,0.35376534,0.12440409,0.10881092
http://arxiv.org/pdf/2205.02430v1,Hypothesis Testing in Sequentially Sampled Data: AdapRT to Maximize Power Beyond iid Sampling,"However, for presentational clarity, we present our method in the common stationary
scenario. Moreover, we add that our methodology and main theoretical results should naturally extend when
there are simple structural carryover eﬀects, but we leave this for future work. 7
Figure 1: Schematic diagram of the Sequential Adaptive Sampling Scheme in Deﬁnition 2.1. ",stat.ME,C,-0.31630033,-0.123710796,0.11167795
http://arxiv.org/pdf/2205.02430v2,Hypothesis Testing in Sequentially Sampled Data: AdapRT to Maximize Power Beyond iid Sampling,"Apart from the computational advantages the theorem provides, it is also
of theoretical interest by itself because our work leverages local asymptotic power analysis to characterize
the distributions under diﬀerent sampling strategies as opposed to characterizing the distributions under
diﬀerent test statistics. In addition, this theorem can also serve as a starting point and motivating example
for theoretically analyzing the power of the ART for future works. 3.3 Power Results

Given the asymptotic results presented in the previous section, we now attempt to understand how the ART
using an adaptive sampling procedure may be more powerful than the CRT using an iid sampling procedure. ",stat.ME,C,-0.21477178,0.061652146,0.34241745
http://arxiv.org/pdf/2205.02617v1,COMBSS: Best Subset Selection via Continuous Optimization,"For instance, we could consider tj(wj) = tanh(wj2). Finding an optimal
   such function could be a part of future work. In conclusion, to the best of our knowledge, COMBSS is the ﬁrst method that exploits uncon-
strained continuous optimization to solve best subset selection in linear regression. ",stat.ME,A,-0.1698601,0.07931808,-0.116336726
http://arxiv.org/pdf/2205.02617v2,COMBSS: Best Subset Selection via Continuous Optimization,"For instance, we could consider tj(wj) = tanh(wj2). Finding an optimal
   such function could be a part of future work. In conclusion, to the best of our knowledge, COMBSS is the ﬁrst method that exploits uncon-
strained continuous optimization to ﬁnd sets of models that are candidates for the best subset
of variables in linear regression. ",stat.ME,A,-0.16432352,0.011243414,-0.082471624
http://arxiv.org/pdf/2205.02948v1,High-Dimensional Survival Analysis: Methods and Applications,"In
     Section 5, we review existing deep learning procedures for competing risk analysis, illustrate
     a new deep learning approach for predicting semi-competing outcomes, and work through
     the BLCSC study. We conclude with remarks on future work and open areas. The online
     Supplementary Material tabulates the reviewed methods and their available software, and
     presents additional simulation results. ",stat.ME,B,0.22746155,-0.07693442,-0.19804773
http://arxiv.org/pdf/2205.03916v1,Sequential Linear Discriminant Analysis in High Dimensions Using Individual Discriminant Functions,"In addition, we believe that there
is open area to investigate further, e.g., we may consider modifying the SLDA where common
covariance assumption is violated. We leave it for future work. References

Aoshima, M., Shen, D., Shen, H., Yata, K., Zhou, Y.-H. & Marron, J. ",stat.ME,C,-0.021531455,-0.0069664866,0.22428215
http://arxiv.org/pdf/2205.03967v1,The saturated pairwise interaction Gibbs point process as a joint species distribution model,"In our
manuscript, simulating from the model has helped us carefully validate the model’s
performance and allowed us to do a sensitivity analysis, see Section 5. We also
believe that simulating from the model will be important in future work, since it
is necessary to do Monte-Carlo simulations as well as compute simulation envelopes
and run goodness of ﬁt tests. Our model can be applied in a wide range of settings, and may also be useful
outside of ecology. ",stat.ME,B,0.05635871,-0.027526975,-0.02007721
http://arxiv.org/pdf/2205.03967v2,The saturated pairwise interaction Gibbs point process as a joint species distribution model,"In
our manuscript, simulating from the model has helped us carefully validate the
model’s performance and allowed us to do a sensitivity analysis, see Section 5. We also believe that simulating from the model will be important in future work,
since it is necessary to do Monte-Carlo simulations as well as compute simulation
envelopes and run goodness of ﬁt tests. Our model can be applied in a wide range of settings, and may also be useful
outside of ecology. ",stat.ME,B,0.05635871,-0.027526975,-0.02007721
http://arxiv.org/pdf/2205.04216v1,Forecast combinations: an over 50-year review,"Moreover, access to feature engineering can lead to improved forecasting
performance, providing valuable information for forecast combinations in a cross-learning fashion
(Montero-Manso et al., 2020; Kang et al., 2021). In this regard, we believe that further research needs
to be done on feature engineering for time series data to unlock the potential of cross-learning. Encouraging researchers to contribute open-source software and datasets. ",stat.ME,B,0.024072995,-0.16231957,-0.3959663
http://arxiv.org/pdf/2205.04216v2,Forecast combinations: an over 50-year review,"Moreover, access to feature engineering can lead to improved forecasting
performance, providing valuable information for forecast combinations in a cross-learning fashion

                                                                 39
(Montero-Manso et al., 2020; Kang et al., 2021). In this regard, we believe that further research needs
to be done on feature engineering for time series data to unlock the potential of cross-learning. Encouraging researchers to contribute open-source software and datasets. ",stat.ME,B,0.017798202,-0.16669497,-0.3920955
http://arxiv.org/pdf/2205.04997v1,Random Forests for Change Point Detection,"The code for MultiRank is experimental
and broke for the dry beans dataset due to the multiple dummy encoded columns. We provide
further analysis of the computational eﬃciency of available implementations in Section 4.5. 17
                   CIM CIC Dirichlet iris glass breast abalone                     wine         dry
                                                                                             beans
                                                                  cancer
                                                                                         13611, 16
n, d            600, 5 600, 5 1000, 20 150, 4 214, 8 699, 9 4066, 9 6462, 12
                                                                                             <0.01
change in mean <0.01 <0.01 <0.01 <0.01 <0.01 <0.01 <0.01 <0.01                                   2.6
                                                                                                  24
changeforest       0.08 0.09             0.43 0.03 0.06 0.07                 0.86  0.89
                                                                                               5356
changekNN          0.04 0.04             0.15 <0.01 0.01 0.05                1.8   4.7            31

ECP                4.2 2.9                  18 0.37 0.72             4.3     386   741

KCP                0.08 0.08             0.18 0.02 0.04 0.10                 2.5   6.6

MultiRank          0.77 0.76                2.1 0.10 0.17            1.0     34    90

           Table 3: Average computation times in seconds on 8 Intel Xeon 2.3 GHz cores. ",stat.ME,A,-0.06340805,0.2949646,-0.35955858
http://arxiv.org/pdf/2205.05003v1,Mechanisms for Global Differential Privacy under Bayesian Data Synthesis,"We recommend these two alternatives for data disseminators who
depending on their priority, can choose the preferred strategy between these two. Interesting lines of future work include embedding other weighted synthesizers in
censoring to provide a non-asymptotic DP guarantee. Supplementary Materials

Supplementary Materials include Stan script for the censoring method and additional
privacy and utility comparison results from Section 4. ",stat.ME,A,-0.019848712,0.0632844,-0.03631494
http://arxiv.org/pdf/2205.05322v1,Shared Frailty Methods for Complex Survival Data: A Review of Recent Advances,"• Semicompeting risks via illness-death AFT models with other frailty distributions
        beside gamma. We also believe that there could be a place for additional investigation in the area of
random survival forests for clustered data, since existing works that uses frailty models
focus on extended Cox models with gamma frailty distribution. Moreover, R packages that
apply RSF for clustered survival data are currently missing. ",stat.ME,B,0.3170178,-0.1341378,-0.18795279
