url,title,further research,primary category,label,x,y,z
http://arxiv.org/pdf/2201.00235v1,Simulating and Modeling the Risk of Conversational Search,"Through detailed analyses and case studies, we verify
the improvements of our model over the baseline models are meaningful and provide new insights
and explanations of why our proposed model outperforms the baseline models. We consider multiple future work directions of our work. We only experiment with our model
together with response retrieval models in this work. ",cs.IR,A,0.031044602,0.12857287,-0.049361497
http://arxiv.org/pdf/2201.00365v1,Establishing Strong Baselines for TripClick Health Retrieval,"The nDCG & MRR cutoÔ¨Ä is at rank 10. Model  BERT                 Head (DCTR) Torso (RAW) Tail (RAW)
           Instance             nDCG MRR nDCG MRR nDCG MRR

Original Baselines

1 BM25     ‚Äì                    .140 .276  .206 .283  .267 .258
                                .198 .420  .243 .347  .271 .265
2 ConvKNRM ‚Äì                    .208 .434  .272 .381  .295 .280

3 TK       ‚Äì

Our Re-Ranking (BM25 Top-200)

4 TK       ‚Äì                    .232 .472 .300 .390 .345 .319

5 ColBERT  SciBERT              .270 .556  .326 .426  .374 .347
6          PubMedBERT-Abstract  .278 .557  .340 .431  .387 .361

7          DistilBERT           .272 .556  .333 .427  .381 .355
                                .287 .579  .349 .453  .396 .366
8          BERT-Base

9 BERTCAT  SciBERT              .294 .595  .360 .459  .408 .377
10         PubMedBERT-Full      .298 .582  .365 .462  .412 .381
           PubMedBERT-Abstract  .296 .587  .359 .456  .409 .380
11

12         Ensemble (Lines: 9,10,11) .303 .601 .370 .472 .420 .392

       ‚Äì We discard positional information (we expect position bias to be in the
          training data ‚Äì a potential for future work). 3. ",cs.IR,C,-0.19502039,-0.13321652,-0.15026525
http://arxiv.org/pdf/2201.00695v1,An Efficient Combinatorial Optimization Model Using Learning-to-Rank Distillation,"2016). The direction of our future work is to adapt our RL-based
                                                                 encoder-decoder model and distillation procedure for vari-
   Particularly, in the Ô¨Åeld of computer systems and resource    ous COPs with different consistency degrees between em-
management, there have been several works using deep RL          beddings and decoding results and to explore meta learning
to tackle system optimization under multiple, heterogeneous      for fast adaptation across different problem conditions. Acknowledgement                                  Chu, P. C.; and Beasley, J. E. 1998. ",cs.IR,C,-0.19970146,-0.047457818,-0.32032987
http://arxiv.org/pdf/2201.01180v1,Towards Fair Recommendation in Two-Sided Platforms,"Though our work considers the offline recommendation scenario where the
recommendations are computed for all the registered customers at once, it can also be extended for
online recommendation settings by limiting the set of customers to only the active customers at
any particular instant. However, developing a more robust realization of the proposed mechanism
for a completely online scenario remains future work. Going ahead, we also want to study attention
models that can handle position bias [4], where customers pay more attention to the top-ranked
products than the lower-ranked ones. ",cs.IR,B,0.42449778,-0.054377545,0.07081315
http://arxiv.org/pdf/2201.01745v1,Atomized Search Length: Beyond User Models,"Negative values represent a win for the best system (lower per-                 We also leave the study of how other user-based metrics such
document ASL). We generated and manually inspected the same                  as NDCG [10], ERR [4], and RBP [15] might be revisited within
graph for every track (always comparing the best to median system,           this framework as future work. Because these metrics express more
as ranked by ASL) and saw the same general shape: a large number             complicated functions of rank than precision, the adaptations above
                                                                             are not directly applicable, but the general concerns (particularly
                                                                             with the use of 1/ùëÉ instead of ùëÉ) apply. ",cs.IR,C,-0.08739247,-0.19784169,-0.04120376
http://arxiv.org/pdf/2201.01815v1,An Evaluation Study of Generative Adversarial Networks for Collaborative Filtering,"This work discusses the implications of certain diÔ¨Äerences between the CFGAN
                                       framework and the model that was used in the experimental evaluation, which
2  F. B. P¬¥erez Maurera et al. would adversely aÔ¨Äect its learning ability, providing a reference for future works. In particular, the generator is left prone to reach a degenerate solution and be-
have as a simple autoencoder, therefore, belonging to the same family of previous
recommendation models such as [28,32]. ",cs.IR,B,0.13762012,-0.116487905,-0.2368663
http://arxiv.org/pdf/2201.01815v2,An Evaluation Study of Generative Adversarial Networks for Collaborative Filtering,"This work discusses the implications of certain diÔ¨Äerences between the CFGAN
                                        framework and the model that was used in the experimental evaluation, which
2  F. B. P¬¥erez Maurera et al. would adversely aÔ¨Äect its learning ability, providing a reference for future works. In particular, the generator is left prone to reach a degenerate solution and
behave as a simple autoencoder, therefore, belonging to the same family of pre-
vious recommendation models such as [28,32]. ",cs.IR,B,0.17539603,-0.092415445,-0.21753404
http://arxiv.org/pdf/2201.02127v1,Sentiment Analysis and Sarcasm Detection of Indian General Election Tweets,"Section 4 is the experimental evaluation of the senti-
ment analysis and sarcasm detection model. Finally, Section 6 concludes the paper with
the scope of future work. 2 Related Works

Various researchers have been doing Sentiment analysis of Twitter data in various ap-
plication fields from past times which is not limited to only political tweets. ",cs.IR,A,-0.056696273,0.15689671,0.22569485
http://arxiv.org/pdf/2201.02339v1,"SaL-Lightning Dataset: Search and Eye Gaze Behavior, Resource Interactions and Knowledge Gain during Web Search","Afterward, we showcase already existing use cases (Section 3). Section 4 concludes with a summary and possible
future work. 2 DATASET DESCRIPTION
This section gives an in-depth explanation of the dataset acquisition process: (1) the initial user study in Section 2.1,
(2) the technical environment in Section 2.2 and (3) the detailed description of the diÔ¨Äerent data subsets in Section 2.3. ",cs.IR,A,-0.17251815,0.024488838,0.049511656
http://arxiv.org/pdf/2201.03144v2,Supervised Contrastive Learning for Recommendation,"In this work, supervised information is currently used to improve the contrastive learning loss only. In future work, we
hope to make fully use of supervised information. For example, using supervised information to mine hard samples or
improve BPR loss will be very interesting research directions. ",cs.IR,C,-0.10249292,-0.043793254,-0.084738
http://arxiv.org/pdf/2201.03158v1,Collaborative Reflection-Augmented Autoencoder Network for Recommender Systems,"Our proposed frameworks achieve significantly better performances as compared to
state-of-the-art techniques on both rating prediction and item recommendation applications across
multiple datasets. Since CRANet is a generic reflective collaborative filtering, our future work plans
to extend CRANet with other recommendation architecture, such as factorization machines. REFERENCES

 [1] Rianne van den Berg, Thomas N Kipf, and Max Welling. ",cs.IR,B,0.52437073,-0.043471865,-0.047122046
http://arxiv.org/pdf/2201.03356v1,Continual Learning of Long Topic Sequences in Neural Information Retrieval,"We also provided speciÔ¨Åc
stream of tasks, each of them addressing a likely scenario in case of IR contin-
ual learning. Our analysis suggests diÔ¨Äerent design implications for future work:
1) catastrophic forgetting in IR exists but is low compared to other domains
[17,40], 2) when designing lifelong learning strategy, it is important to care of
task similarity, the place of the task in the learning process and of the type of
the distribution that needs to be transfered (short vs. long texts). We are aware
that results are limited to the experimented models and settings and that much
remains to be accomplish for more generalizable results. ",cs.IR,A,-0.109898664,0.15509605,-0.14650886
http://arxiv.org/pdf/2201.03408v1,Watch Less and Uncover More: Could Navigation Tools Help Users Search and Explore Videos?,"several segments making it difficult to distinguish between them"". In
particular, for a few videos, a keyword was repeated systematically           In future work, we plan on conducting a more extensive analysis
across the video. As a participant pointed such keywords should be         of the interaction logs and user experiences. ",cs.IR,A,-0.016767208,0.17982438,0.25891125
http://arxiv.org/pdf/2201.03435v1,State of the Art of User Simulation approaches for conversational information retrieval,"language generation. In order to facilitate future works,
However, there is a strong variability in user behavior     the IR community should have a common platform for
[50]. Some are more persistent or curious in their          building and testing US for sequential IR systems. ",cs.IR,A,-0.12787293,0.21450594,0.2119132
http://arxiv.org/pdf/2201.03450v1,Leveraging Social Influence based on Users Activity Centers for Point-of-Interest Recommendation,"Our experimental results
on both datasets indicate that SUCP model signiÔ¨Åcantly outperforms the compared and
state-of-the-art methods. As for future work, one can be incorporating the other contex-
tual information into the proposed model such as user‚Äôs comments or reviews, categorical
information. Moreover, we may model the social inÔ¨Çuence by the other friendship and
similarity metrics like time of commonly visited check-ins. ",cs.IR,B,0.22693393,0.14584507,0.20412135
http://arxiv.org/pdf/2201.03622v2,Graph-Based Recommendation System Enhanced with Community Detection,"5. Conclusion and future works
   We examined the problems in tagged recommender systems and concluded that the performance of these

systems is affected by semantic and lexical ambiguities. Various solutions have been proposed in this field,
most of which suggested the use of external knowledge and thesaurus. ",cs.IR,B,0.25824046,0.23329607,0.12043456
http://arxiv.org/pdf/2201.04399v1,RGRecSys: A Toolkit for Robustness Evaluation of Recommender Systems,"Our library is open-source and can be accessed at https:         [9] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng
//www.github.com/salesforce/RGRecSys. Our future work aims to                  Wang. 2020. ",cs.IR,C,-0.17184624,-0.03496074,0.03572481
http://arxiv.org/pdf/2201.04458v1,Diagnosing BERT with Retrieval Heuristics,"Although only a small set of instances from each diagnostic
dataset contains a document with a relevant document (row II in Table 2) we
already see a trend: apart from TFC1 and M-TDC where 91% and 82% of the di-
agnostic instances have an agreement between axiomatic ordering and relevance
ordering, the remaining axioms are actually not in line with the relevance order-
ing for most of the instances. This is a Ô¨Årst indication that we have to consider
an alternative set of axioms, better Ô¨Åt for such a corpus, in future work. In Table 3 we report the fraction of instances both QL and BERT fulÔ¨Ål for
each diagnostic dataset. ",cs.IR,A,-0.28752926,0.20785952,-0.08191042
http://arxiv.org/pdf/2201.04672v1,How Can Graph Neural Networks Help Document Retrieval: A Case Study on CORD19 with Concept Map Generation,"Results show that instead of the complex structure-oriented GNNs
                                                 such as GINs and GATs, our proposed semantics-oriented graph func-
                                                 tions achieve better and more stable performance based on the BM25
                                                 retrieved candidates. Our insights in this case study can serve as a
                                                 guideline for future work to develop eÔ¨Äective GNNs with appropriate
                                                 semantics-oriented inductive biases for textual reasoning tasks like doc-
                                                 ument retrieval and classiÔ¨Åcation. All code for this case study is available
                                                 at https://github.com/HennyJie/GNN-DocRetrieval. ",cs.IR,A,-0.13312078,0.35212374,-0.20783588
http://arxiv.org/pdf/2201.05176v1,Neural Approaches to Conversational Information Retrieval,"While scheduling remains an everyday challenge for many
people, the technology in Calendar.help has grown well beyond its original hybrid-intelligence design
and has inÔ¨Çuenced the development of Microsoft‚Äôs Scheduler which is a product in early preview
release as of the date of this writing. 128
Chapter 9

Conclusions and Research Trends

We conclude the book with a brief discussion of research trends and areas for future work. While
we have colored a promising picture of CIR, the Ô¨Åeld is still at a research exploration stage in that a
commercial CIR system that goes beyond popular search engines (e.g., Google and Bing) to eÔ¨Äectively
meet users‚Äô information needs of wide diversity and complexity is yet to be developed. ",cs.IR,A,0.015978174,0.13911676,0.16478851
http://arxiv.org/pdf/2201.05327v1,The Lokahi Prototype: Toward the automatic Extraction of Entity Relationship Models from Text,"Also, it is a
purely syntactical approach fitted for extraction from text,
where all labels, even entity sets and relationship sets, are
named entities, that is, entities identified with their syntacti-
cal representation in form of their name. This reduces the
extraction is presented, and the insights, implications and
points for further research are discussed. The Lokahi Prototype for Concept Browsing

  Lokahi is a research prototype that prototypically ex-
plores the automatic generation of knowledge networks. ",cs.IR,A,-0.097820446,0.4002999,0.038584538
http://arxiv.org/pdf/2201.05333v1,Attention over Self-attention:Intention-aware Re-ranking with Dynamic Transformer Encoders for Recommendation,"5, we can see that a small number of transform                                       the additional gains brought by the devised IDM and DTE. In
matrices (t ‚â§ 4) is sufÔ¨Åcient to distinguish the main intentions of                                future work, we will investigate how to mine user intentions from
users. This indicates our DTE does not actually add much space                                     other auxiliary information such as social networks and knowledge
complexity and veriÔ¨Åes our assumption that user behavior is driven                                 graphs for further performance-enhanced re-ranking approaches. ",cs.IR,B,0.107695594,0.037280906,0.15830715
http://arxiv.org/pdf/2201.05333v2,Attention over Self-attention:Intention-aware Re-ranking with Dynamic Transformer Encoders for Recommendation,"In
In the IDM, we adopt a bilinear co-attention function (Eq. (3))                        future work, we will investigate how to mine user intentions from
to compute the matching scores, which enables RAISE to capture                         other auxiliary information such as social networks and knowledge
intention-aware information and to provide meaningful explana-                         graphs for further performance-enhanced re-ranking approaches. tions. ",cs.IR,B,0.15232222,0.14767438,0.014571536
http://arxiv.org/pdf/2201.05460v1,Impact of Stop Sets on Stopping Active Learning for Text Classification,"There is a small section of the paper that explores
how stopping performance is impacted if the stop set is made                        III. METHODS FOR STOPPING
smaller and it‚Äôs found that if the set becomes too small the
performance could begin to degrade, but it‚Äôs concluded that          In this section, we provide more details about the Stabilizing
the size required to be representative could vary depending       Predictions, Declining ConÔ¨Ådence, and Non-increasing Con-
on dataset and task so future work is needed to determine         Ô¨Ådence stopping methods, including details about their usage
how large the stop set should be. We experiment with this         of stop sets. ",cs.IR,C,-0.22069626,-0.28255022,0.054109372
http://arxiv.org/pdf/2201.05460v2,Impact of Stop Sets on Stopping Active Learning for Text Classification,"There is a small section of the paper that explores
how stopping performance is impacted if the stop set is made                        III. METHODS FOR STOPPING
smaller and it‚Äôs found that if the set becomes too small the
performance could begin to degrade, but it‚Äôs concluded that          In this section, we provide more details about the Stabilizing
the size required to be representative could vary depending       Predictions, Declining ConÔ¨Ådence, and Non-increasing Con-
on dataset and task so future work is needed to determine         Ô¨Ådence stopping methods, including details about their usage
how large the stop set should be. We experiment with this         of stop sets. ",cs.IR,C,-0.22069626,-0.28255022,0.054109372
http://arxiv.org/pdf/2201.05461v1,RecoMed: A Knowledge-Aware Recommender System for Hypertension Medications,"To evaluate the results of the implemented system, manual evaluation was performed by
experts in which they have verified and confirmed the method's outcomes. As future work, in addition to historical medicine datasets, clinical data can be utilized to enhance
further the proposed approach's accuracy. It is possible to recommend medicines by collecting a
database of patients' clinical symptoms resulting from clinical questionnaires designed by the
medical team, including personal information such as age, height, weight (BMI), daily activity,
patient history, underlying diseases, and consumable medicines. ",cs.IR,A,0.020879336,-0.01063125,0.16537108
http://arxiv.org/pdf/2201.05461v2,RecoMed: A Knowledge-Aware Recommender System for Hypertension Medications,"In the end, the output was reviewed, checked and confirmed by an expert
person. In future work, in addition to historical medicine datasets, clinical data can be utilized to enhance
further the proposed approach's accuracy. It is possible to recommend medicines by collecting a
database of patients' clinical symptoms resulting from clinical questionnaires designed by the
medical team, including personal information such as age, height, weight (BMI), daily activity,
patient history, underlying diseases, and consumable medicines. ",cs.IR,A,0.045422815,0.015453573,0.15853682
http://arxiv.org/pdf/2201.05646v1,ULTRA: A Data-driven Approach for Recommending Team Formation in Response to Proposal Calls,"A trusted team is one where all stake-
holders are convinced that the right members from those available have been selected on the needs of the call for unknown success in future. then present initial evaluation and conclude with a discus-                      respected while recommending team participants, the rec-
sion of future work. ommended participants may already know each other but
                                                                                 may not be free to work on the proposal. ",cs.IR,C,0.030111104,-0.11040144,0.3013364
http://arxiv.org/pdf/2201.05646v2,ULTRA: A Data-driven Approach for Recommending Team Formation in Response to Proposal Calls,"Sec-   presented preliminary empirical evidence that the approach is
ond, users want the system to assign star rating to team leaders  promising. This work lays the basis for future work on AI-
who have had good experiences and track record. Third, some       assisted teaming spanning multiple disciplines at University-
proposals expect junior faculty or member from disadvantaged      scale. ",cs.IR,C,0.051404517,-0.066949904,0.16971019
http://arxiv.org/pdf/2201.05861v1,Deep Unified Representation for Heterogeneous Recommendation,"2020. DDTCDR: Deep dual transfer cross domain
be an interesting and significant problem in our future work. recommendation. ",cs.IR,C,-0.16314173,-0.08798638,-0.1496567
http://arxiv.org/pdf/2201.06224v1,Unintended Bias in Language Model-drivenConversational Recommendation,"ReXPlug: Explainable Recom-
                                                                                                 mendation using Plug-and-Play Language Model. In Proceedings of the 44th
for future work. International ACM SIGIR Conference on Research and Development in Information
6 CONCLUSION AND FUTURE WORK                                                                     Retrieval. ",cs.IR,A,-0.079826236,0.38845217,0.05895578
http://arxiv.org/pdf/2201.06224v2,Unintended Bias in Language Model-driven Conversational Recommendation,"2021. Advances and challenges in conversational recommender systems: A
for future work. survey. ",cs.IR,B,0.28376156,0.13377236,0.16111323
http://arxiv.org/pdf/2201.07571v1,Batch versus Sequential Active Learning for Recommender Systems,"For active
learners that use an underlying prediction algorithm, FunkSVD
turned out to be a good choice, but the accuracy differences with
other predictors are small. In future work, active learners will be
tested in combination with other recommendation algorithms and
additional active learning algorithms will be explored. ACKNOWLEDGMENTS

This research received funding from the Flemish Government (AI
Research Program). ",cs.IR,B,0.2611898,-0.062483873,-0.049938276
http://arxiv.org/pdf/2201.07620v1,Validating Simulations of User Query Variants,"Likewise, the
experiments neglect click simulations. We leave it for future work to complement
and analyze simulations in this regard. 11
                 Table A.1: Average retrieval performance over q queries

                 All queries      First queries  Best queries

                 q nDCG P@10 AP q nDCG P@10 AP q nDCG P@10 AP

UQV1             150 .3787 .4507 .1581 50 .4293 .5040 .2003 50 .4969 .6320 .2429
UQV2              52 .4221 .5058 .2020 50 .4096 .4880 .1894 50 .4103 .4900 .1896
UQV3              68 .3922 .4353 .1780 50 .3979 .4560 .1813 50 .4117 .4800 .1878
UQV4
UQV5             123 .4126 .4894 .1888 50 .4469 .5220 .2099 50 .5146 .6300 .2644
UQV6             500 .3922 .4330 .1649 50 .4447 .4920 .2043 50 .5353 .7240 .2807
UQV7             136 .4030 .4713 .1843 50 .4488 .5080 .2197 50 .4980 .5980 .2515
UQV8
TTSS1             50 .4980 .5720 .2418 50 .4980 .5720 .2418 50 .4980 .5720 .2418
TTSS2            156 .3814 .4545 .1645 50 .4046 .4500 .1799 50 .4556 .5620 .2193
TTSS2
TTSS3            500 .0479 .0306 .0127 50 .1705 .1280 .0541 50 .3066 .2360 .0971
TTSS3            500 .1964 .1716 .0688 50 .3592 .3900 .1604 50 .4391 .5100 .2097
TTSS4            500 .3387 .3426 .1413 50 .3895 .4020 .1821 50 .4639 .5940 .2283
TTSS4            500 .3323 .3632 .1388 50 .1705 .1280 .0541 50 .4776 .6080 .2383
TTSS4            500 .3499 .3874 .1474 50 .3592 .3900 .1604 50 .4709 .6060 .2311
KISS1            500 .4493 .5168 .2088 50 .4409 .4920 .2072 50 .5945 .7620 .3282
KISS2            500 .4788 .5626 .2288 50 .4976 .5940 .2429 50 .6207 .8040 .3554
KISS2            500 .3780 .4224 .1644 50 .4393 .4860 .2065 50 .5812 .7680 .3222
KISS3
KISS3            500 .1334 .1044 .0314 50 .2836 .2040 .0813 50 .4087 .4400 .1492
KISS4            500 .3969 .3972 .1615 50 .5096 .5400 .2535 50 .5988 .7460 .3429
KISS4            500 .5114 .5666 .2507 50 .5474 .6220 .2870 50 .6336 .7980 .3762
KISS4            500 .5598 .6336 .3009 50 .2836 .2040 .0813 50 .6907 .8620 .4299
                 500 .5941 .6882 .3285 50 .5096 .5400 .2535 50 .6922 .8620 .4337
   0.5           500 .5216 .5976 .2604 50 .5146 .5960 .2630 50 .6461 .8200 .3902
   0.4           500 .5008 .5888 .2416 50 .5033 .5980 .2400 50 .6269 .8080 .3703
   0.3           500 .4859 .5584 .2293 50 .5191 .6020 .2644 50 .6401 .8360 .3781
   0.2
   0.1           UQV vs. TTS          0.5        UQV vs. KIS
   0.0
                     UQV              0.4                                         S1
                                                                                  S2
                                                                                  S2
                                                                                  S3
                                                                                  S3
                                                     UQV
      RMSE (nDCG)                     0.3
               1
                       2      S1      0.2
                               3S2
                                       4S2
                                               5S30.1
                                                      6S3
                                                              70.0
                                                                      8

                                                                               RMSE (nDCG)
                                                                                         1
                                                                                                2
                                                                                                        3
                                                                                                                4
                                                                                                                        5
                                                                                                                                6
                                                                                                                                        7
                                                                                                                                               8

Fig. ",cs.IR,C,-0.20000137,-0.105166465,0.022523904
http://arxiv.org/pdf/2201.07620v2,Validating Simulations of User Query Variants,"Likewise, the
experiments neglect click simulations. We leave it for future work to complement
and analyze simulations in this regard. 12               Breuer et al. ",cs.IR,C,-0.19578439,-0.11679039,0.17971477
http://arxiv.org/pdf/2201.07667v1,Expert Finding in Legal Community Question Answering,"BERT-based method outperformed probabilistic methods, and
the proposed methods outperformed all models. For future work, there is a need to study more in-depth the robustness of pro-
posed methods on diÔ¨Äerent legal categories. Moreover, by providing this dataset
we facilitate other tasks such as legal question answering, duplicate question
detection, and Ô¨Ånding lawyers who will reply to a question. ",cs.IR,A,-0.13139695,0.30105108,0.025127528
http://arxiv.org/pdf/2201.07667v2,Expert Finding in Legal Community Question Answering,"BERT-based method outperformed probabilistic methods, and
the proposed methods outperformed all models. For future work, there is a need to study more in-depth the robustness of pro-
posed methods on diÔ¨Äerent legal categories. Moreover, by providing this dataset
we facilitate other tasks such as legal question answering, duplicate question
detection, and Ô¨Ånding lawyers who will reply to a question. ",cs.IR,A,-0.13139695,0.30105108,0.025127528
http://arxiv.org/pdf/2201.07667v3,Expert Finding in Legal Community Question Answering,"BERT-based method outperformed probabilistic methods, and
the proposed methods outperformed all models. For future work, there is a need to study more in-depth the robustness of pro-
posed methods on diÔ¨Äerent legal categories. Moreover, by providing this dataset
we facilitate other tasks such as legal question answering, duplicate question
detection, and Ô¨Ånding lawyers who will reply to a question. ",cs.IR,A,-0.13139695,0.30105108,0.025127528
http://arxiv.org/pdf/2201.07745v1,Improving Biomedical Information Retrieval with Neural Retrievers,"(2021) use dual encoder as the neural      better than w2s1, it might because more answers for questions
retriever and generate large scale synthetic questions to train   in batch 4 are single sentences, and a detailed comparison
such a retriever. However the pure neural retriever is not out-   among the questions in different batches will reveal more
performing BM25, hence a hybrid method is proposed which          insights which will be our future work. achieves the best performance in BioASQ8 challenge. ",cs.IR,A,-0.20376141,0.23406804,-0.26922712
http://arxiv.org/pdf/2201.07754v2,Grep-BiasIR: A Dataset for Investigating Gender Representation-Bias in Information Retrieval Results,"14, 3 (1996), 330‚Äì347. https://doi.org/10.1145/230538.230561
stimulate further research on the investigation of data, algorith-
mic, and cognitive gender biases in IR systems, as well as novel                        [8] Peter Glick and Susan T Fiske. 1999. ",cs.IR,C,-0.14328992,-0.028757315,0.35599712
http://arxiv.org/pdf/2201.08024v1,UKD: Debiasing Conversion Rate Estimation via Uncertainty-regularized Knowledge Distillation,"1                                                                                         We also add a loss term D                            KL ùíëùëêùëúùëõùë£ ||ùíëùëê‚Ä≤ùëúùëõùë£ that acts

 We can distill more knowledge such as the learned representations of the represen-                                             ùë¢ùëõùëêùëôùëñùëêùëò
tation learner ùëáùëì ( ¬∑) [19, 28]. In this work we focus on verifying the effectiveness of
knowledge distillation paradigm for CVR estimation, and leave that in future work. as a regularization for uncertainty estimation. ",cs.IR,C,-0.10650039,-0.14341089,-0.30427706
http://arxiv.org/pdf/2201.08150v1,A Systematic Analysis on the Impact of Contextual Information on Point-of-Interest Recommendation,"This could be due to the existence of some
latent relation between exploration and temporal behavior of users that help the models in some cases to perform better. We leave the further investigation of this effect for future work. Between the contextual models, T, G, and their combination improve the performance more than the other contextual
information and combination in terms of all three evaluation metrics. ",cs.IR,A,0.05527581,0.12129223,0.0873225
http://arxiv.org/pdf/2201.08471v1,Transfer Learning Approaches for Building Cross-Language Dense Retrieval Models,"ColBERTv2 [27]
addresses this issue by clustering token embeddings. That approach could be ex-
tended to ColBERT-X for CLIR; we leave it for future work. An artifact of our

13 https://github.com/terrierteam/pyterrier_colbert
12  S. Nair et al. ",cs.IR,A,-0.095764555,0.1067541,-0.07632231
http://arxiv.org/pdf/2201.08580v1,Trustworthy Knowledge Graph Completion Based on Multi-sourced Noisy Data,"In
periment five times, and present the results on average. Based on                        future work, we plan to extend our method to choose data sources
Figure 3(b), we obtain two findings: (i) Compared TKGC with all                          for claim retrieval. We also want to apply our method to validate
claims, TKGC without claims increases 0.031 of RMSE, but signif-                         the facts from relation extraction. ",cs.IR,C,-0.21376589,-0.06725082,0.22485584
http://arxiv.org/pdf/2201.08614v1,Consumer Fairness in Recommender Systems: Contextualizing Definitions and Mitigations,"Consumer fairness metrics monitored equity through
Demographic Parity (DP), computed as the diÔ¨Äerence on utility for the corre-
sponding task between groups, and independence through Kolmogorov-Smirnov
(KS), computed on predicted relevance scores, covering two well-known perspec-
tives and steps of the pipeline. Mainly due to space constraints, we left analyses
on other fairness notions and implementations of the same fairness notions as a
future work. Experiments ran on a Ryzen7 machine with 32 GB RAM. ",cs.IR,C,-0.010764631,-0.25925002,0.22014207
http://arxiv.org/pdf/2201.08614v2,Consumer Fairness in Recommender Systems: Contextualizing Definitions and Mitigations,"Consumer fairness metrics monitored equity through
Demographic Parity (DP), computed as the diÔ¨Äerence on utility for the corre-
sponding task between groups, and independence through Kolmogorov-Smirnov
(KS), computed on predicted relevance scores, covering two well-known perspec-
tives and steps of the pipeline. Mainly due to space constraints, we left analyses
on other fairness notions and implementations of the same fairness notions as a
future work. Experiments ran on a Ryzen7 machine with 32 GB RAM. ",cs.IR,C,-0.010764631,-0.25925002,0.22014207
http://arxiv.org/pdf/2201.08742v1,Towards Building Economic Models of Conversational Search,"Finally, more sophisticated models of conversational search could also
be further developed to analyse diÔ¨Äerent possible mixed strategies. However, we
leave such the empirical investigations and further modelling for future work. Towards Building Economic Models of Conversational Search  7

Acknowledgements: This research was supported by the NWO (No. ",cs.IR,A,0.029971436,0.19736001,0.23691049
http://arxiv.org/pdf/2201.08808v1,Conversational Information Seeking,"We observe that the ongoing
trend in simulating users could be helpful here. Tools for dataset creation and evaluation may also beneÔ¨Åt from
further research eÔ¨Äort. For instance, many researchers build their own
wizard-of-oz frameworks with limited reuse capabilities. ",cs.IR,A,0.04189231,0.0063866973,0.20214896
http://arxiv.org/pdf/2201.10582v1,Out-of-Domain Semantics to the Rescue! Zero-Shot Hybrid Retrieval Models,"A recent work [36] found that deep retrieval models underperform lexical
models for rare entities in an entity-centric QA task. As a future work, we plan to
investigate the eÔ¨Äectivenss of our hybrid model in this task. Additionally, we plan
to parameterize the hybrid retrieval model using query structure, query length,
the degree of domain shift, and other signals that may reÔ¨Çect the performance
of each individual model. ",cs.IR,A,-0.02545368,0.41570687,-0.20158088
http://arxiv.org/pdf/2201.10751v1,Graph Neural Networks with Dynamic and Static Representations for Social Recommendation,"Modeling these users and
items requires a cold-start setting, which is beyond the scope of this work. The
cold-start problem will be left to our future work. Baselines. ",cs.IR,B,0.112593636,-0.065864995,0.2270413
http://arxiv.org/pdf/2201.10751v2,Graph Neural Networks with Dynamic and Static Representations for Social Recommendation,"Modeling these users and
items requires a cold-start setting, which is beyond the scope of this work. The
cold-start problem will be left to our future work. Baselines. ",cs.IR,B,0.112593636,-0.065864995,0.2270413
http://arxiv.org/pdf/2201.10980v1,Alleviating Cold-start Problem in CTR Prediction with A Variational Embedding Learning Framework,"In Proceedings of the 10th ACM conference
can achieve better performances. Our future work will include the                                 on recommender systems. 99‚Äì106. ",cs.IR,B,0.42078888,-0.012358835,0.022371206
http://arxiv.org/pdf/2201.11086v1,Can Old TREC Collections Reliably Evaluate Modern Neural Retrieval Models?,"So there is some support for the        quality. As both of these problems are areas of active research, we
claim that the neural methods are finding different documents than       leave them for future work. But for now, we can sleep more easily
traditional (automatic) methods. ",cs.IR,A,-0.1533905,0.11073762,0.01995034
http://arxiv.org/pdf/2201.11094v1,SCAI-QReCC Shared Task on Conversational Question Answering,"submitted run Ô¨Åles and no working software because                Hence, the Ô¨Ånal answer was generated using the
the deadline of the SCAI-QReCC 2021 shared task was               top-passage concatenated to the rewritten question
close to the deadline of the TREC 2021 CAsT track. (leaving the second stage of answer generation for
Overall, four teams submitted results to the shared task:         future work). ‚Ä¢ Rachael (Gonc¬∏alo Raposo and Coheur, 2022) im-            ‚Ä¢ Ultron use a two-stage pipeline rewriting the
      plemented a three-stage pipeline that rewrites the          question with the sequence-to-sequence model
      question with T5 (Raffel et al., 2020) and summa-           BART (Lewis et al., 2020a) and generating the
      rizes the top-10 passages retrieved with BM25 for           answers using RAG (Lewis et al., 2020b). ",cs.IR,C,-0.30783188,-0.0019513178,-0.15589917
http://arxiv.org/pdf/2201.11181v1,"Searching, Learning, and Subtopic Ordering: A Simulation-based Analysis","Recalling our original re-
search question which considered how diÔ¨Äerent subtopic switching strategies (œï)
aÔ¨Äected the behaviour or simulated agents, we show that strategies that mimic
a rational user (i.e., Greedy and Greedy-Skip) are more eÔ¨Äective at Ô¨Ånding
keywords, exploring subtopics and following subtopic structure when compared
to other strategies. With 1, 520 simulations, our study is the Ô¨Årst (to the best
of our knowledge) that focuses on simulated agents for Search as Learning, en-
abling future works in both SAL and IIR that may require large quantities of
user data, such as Reinforcement Learning models and studies on how changes
in the search system may impact the behaviour of learners. To further help re-
search eÔ¨Äorts, we also make public our implementation of the SACSM, built on
top of the already established SimIIR framework. ",cs.IR,A,-0.052858848,0.09859063,0.043716982
http://arxiv.org/pdf/2201.12662v1,"Fair ranking: a critical review, challenges, and future directions","The result of such diÔ¨Äerential informativeness may cause downstream disparate impact, such as
privileging longer-serving providers over newer and smaller ones. Together, these sources and areas of uncertainty should be an important aspect of future work
in fair ranking. Fair ranking desiderata. ",cs.IR,C,0.04623042,-0.14664546,0.28798348
http://arxiv.org/pdf/2201.12686v1,Robustness of Deep Recommendation Systems to Untargeted Interaction Perturbations,"Sequential user-based
                                                                                               recurrent neural network recommendations. In Proceedings of the eleventh ACM
   This work has some shortcomings and future work opportuni-                                  conference on recommender systems. 152‚Äì160. ",cs.IR,B,0.44255614,0.10771534,-0.17420581
http://arxiv.org/pdf/2201.12686v2,Rank List Sensitivity of Recommender Systems to Interaction Perturbations,"stability across all user groups. Addressing the differential impact
across user groups will be important to study in future work. Future work topics include: expanding CASPER to handle more
                                                                       complex perturbations, or to find more effective perturbations (e.g.,
7.4 Impact of the Number of Perturbations                              interaction reordering) for other training regimes; and improving
                                                                       scalability of CASPER to handle very large interaction graphs (e.g.,
Intuitively, more perturbations in training data will cause higher     by creating approximations of cascading scores using a randomly-
instability of a model. ",cs.IR,C,0.016674722,-0.23736049,0.09815775
http://arxiv.org/pdf/2201.12686v3,Rank List Sensitivity of Recommender Systems to Interaction Perturbations,"stability across all user groups. Addressing the differential impact
across user groups will be important to study in future work. Future work topics include: expanding CASPER to handle more
                                                                       complex perturbations, or to find more effective perturbations (e.g.,
7.4 Impact of the Number of Perturbations                              interaction reordering) for other training regimes; and improving
                                                                       scalability of CASPER to handle very large interaction graphs (e.g.,
Intuitively, more perturbations in training data will cause higher     by creating approximations of cascading scores using a randomly-
instability of a model. ",cs.IR,C,0.016674722,-0.23736049,0.09815775
http://arxiv.org/pdf/2201.12786v1,Similarity Search on Computational Notebooks,"Through our experiments using Kaggle note-
books, we showed that the graph-based similarity
achieves high accuracy and our methods are eÔ¨Écient. As the future work, we aim to improve our similar-
ity search to Ô¨Çexibly specify user requirements such
as diverse results and dissimilar contents. In addi-
tion, it is interesting to investigate the relationships
between tabular data and source codes. ",cs.IR,A,0.0004462474,0.2829104,0.07905787
http://arxiv.org/pdf/2201.13202v2,ODSearch: Fast and Resource Efficient On-device Natural Language Search for Fitness Trackers' Data,"Nevertheless, the emphasis of this work is on
the technical specifications of a novel on-device search component that is proposed. Our future work will consist of
analyzing its effect on the user interface. Studies have shown that conversational agents have advantages over conventional graphical user interfaces in appli-
cations like mental health [23, 79]. ",cs.IR,A,-0.05850931,0.22481802,0.24165939
http://arxiv.org/pdf/2201.13313v1,Efficiently Maintaining Next Basket Recommendations under Additions and Deletions of Baskets and Items,"[8] study data deletion mechanisms for variations of k-      deletions. For future work, we intend to investigate: 1) how to in-
means clustering. Schelter et al. ",cs.IR,C,-0.12691198,-0.075270034,0.1817599
http://arxiv.org/pdf/2201.13317v1,Hyper-Class Representation of Data,"run them. In the future work, we plan to study mainly two aspects as
4.3.3 Selected decision features                                      follows. Figs.16, 17 and 18 show the cross entropy, KL divergence and JS
divergence values of each feature on four data sets. ",cs.IR,C,-0.101748124,-0.1529315,0.035954025
http://arxiv.org/pdf/2201.13317v2,Hyper-Class Representation of Data,"In Figs. 10‚Äì12, we can see the MAE values of three algorithms                In the future work, we plan to study mainly two aspects as
CF_CE, CF_KL and CF_JS varying with parameters on four datasets. follows. ",cs.IR,C,-0.18926305,-0.3855734,-0.091942325
http://arxiv.org/pdf/2202.00216v1,Semantic Annotation and Querying Framework based on Semi-structured Ayurvedic Text,"We
also plan to explore more classical texts such as RƒÅmƒÅya·πáa and MahƒÅbhƒÅrata for annotating
other kinds of relationships. We also hope that the dataset created in the process will prove useful for further research
efforts in the area of NLP in Sanskrit. We make the ontology and the dataset available at
https://sanskrit.iitk.ac.in/ayurveda/dataset/. ",cs.IR,A,-0.16068953,0.2540268,0.09845733
http://arxiv.org/pdf/2202.00373v1,Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization,"We showed that the resulting model named MTFT-BERT re-ranker ob-
tains consistently better retrieval quality than the original BERT re-ranker using
the same training instances and structure. While our focus was on query-by-
document retrieval in professional search domains (legal and academic), as a
future work, it would be interesting to study the eÔ¨Äectiveness of MTFT-BERT
re-ranker in other retrieval tasks where we have shorter queries. Multi-task optimization for BERT-based QBD retrieval  7

References

 1. ",cs.IR,A,-0.037491176,0.31702298,-0.2790109
http://arxiv.org/pdf/2202.00373v2,Improving BERT-based Query-by-Document Retrieval with Multi-Task Optimization,"We showed that the resulting model named MTFT-BERT re-ranker ob-
tains consistently better retrieval quality than the original BERT re-ranker using
the same training instances and structure. While our focus was on query-by-
document retrieval in professional search domains (legal and academic), as a
future work, it would be interesting to study the eÔ¨Äectiveness of MTFT-BERT
re-ranker in other retrieval tasks where we have shorter queries. Multi-task optimization for BERT-based QBD retrieval  7

7 Acknowledgments

This work is funded by the DoSSIER project under European Union‚Äôs Horizon
2020 research and innovation program, Marie Sklodowska-Curie grant agreement
No. ",cs.IR,A,-0.04842411,0.3233143,-0.2696126
http://arxiv.org/pdf/2202.02576v1,Causal Disentanglement for Semantics-Aware Intent Learning in Recommendation,"the robustness and interpretability of our semantics-aware
user intent representation. In future work, we will explore               [14] C. Shi, Y. Li, J. Zhang, Y. Sun, and S. Y. Philip, ‚ÄúA survey of
the effect of different auxiliary information on the recom-                     heterogeneous information network analysis,‚Äù IEEE Transactions
mendation system using the intervention analysis in causal                      on Knowledge and Data Engineering, vol. ",cs.IR,A,-0.038896047,0.24550164,0.26455766
http://arxiv.org/pdf/2202.02830v2,Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors,"If usage is correlated within user sub-populations, generalization of thresholds across users is also viable, as we discuss in the case of sense
subjectivity below. 11We defer to future work the possibility of mixtures of senses. Personalized Soft Attribute Semantics in Recommender Systems Using CAVs                                                  11

                                           Linear     NonLin, Lin-Emb  Nonlin, NL-Emb
                                     Accur. ",cs.IR,B,0.35674334,0.06835248,0.12460325
http://arxiv.org/pdf/2202.03237v1,Introducing the Expohedron for Efficient Pareto-optimal Fairness-Utility Amortizations in Repeated Rankings,"an order of magnitude of several thousand rankings, Expo becomes
quicker than Ctrl for the total runtime. In future work we plan to extend our framework to group fair-
                                                                                                                ness and to different exposure models that are not PBMs, such as
                                                                                                             8  Dynamic Bayesian Network models [6]. ACKNOWLEDGMENTS

                                                                                                                This work has been partially supported by MIAI@Grenoble Alpes,
                                                                                                                (ANR-19-P3IA-0003). ",cs.IR,C,0.051089548,-0.24611261,0.12921213
http://arxiv.org/pdf/2202.03392v1,Large-scale Personalized Video Game Recommendation via Social-aware Contextualized Graph Neural Network,"Junliang et al. [52] discuss that                 We leave several research directions in game recommendations
explicit social links are not all reliable due to the existence of spam-        as to future work. Firstly, dwelling time measures user direct game
mers and bots. ",cs.IR,B,0.32106978,-0.027297962,0.3139986
http://arxiv.org/pdf/2202.03392v2,Large-scale Personalized Video Game Recommendation via Social-aware Contextualized Graph Neural Network,"Junliang et al. [52] discuss that                 We leave several research directions in game recommendations
explicit social links are not all reliable due to the existence of spam-        as to future work. Firstly, dwelling time measures user direct game
mers and bots. ",cs.IR,B,0.32106978,-0.027297962,0.3139986
http://arxiv.org/pdf/2202.04333v1,Who to Watch Next: Two-side Interactive Networks for Live Broadcast Recommendation,"In addition, we also develop a co-retrieval mechanism
third one is to measure the CVR performance from the user aspect,                               to reduce the high computation costs of the interactive network
which is called UCVR metric defined as UCTR = #conversions on users                             from the item aspect. For future work, it would be interesting to
                                                                                                combine TWINS with multi-tasking learning techniques to effec-
                                                                        #impressions on users   tively use user various behaviors (e.g., click, like, comment). where #conversions on users is the number of users that have per-                               Acknowledgments. ",cs.IR,B,0.15280846,0.10945715,-0.026492266
http://arxiv.org/pdf/2202.04972v1,IHGNN: Interactive Hypergraph Neural Network for Personalized Product Search,"Long et al. [23] used popularity combined with relevance      future work, we consider using attention mechanisms in both hy-
to improve product ranking. Guo et al. ",cs.IR,B,0.1445483,0.11278191,0.14542711
http://arxiv.org/pdf/2202.04975v1,FedAttack: Effective and Covert Poisoning Attack on Federated Recommendation via Hard Sampling,"existing defense and detection mechanisms for federated learning. Our work shows existing federated recommendation methods can
4.7 Gradient Visualization                                                                                                           be vulnerable, and the design of future federated recommender
                                                                                                                                     systems should be more secure and robust to these attacks, which
Finally, we use PCA to visualize the gradients on benign clients and                                                                 is one of our future work. Byzantine clients to see whether they are visually distinguishable, as
REFERENCES                                                                                [32] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. ",cs.IR,B,0.20537032,-0.06325875,0.056107998
http://arxiv.org/pdf/2202.05456v1,NEAT: A Label Noise-resistant Complementary Item Recommender System with Trustworthy Evaluation,"With a predeÔ¨Åned p-value for        the default train (INS-T) and test (INS-E) split provided by
the statistic signiÔ¨Åcance, we can create the high quality co-       Instacart dataset. To further study the model performance, we
purchase labels for evaluations. For clarity, we denote the         collect a proprietary dataset (WMT) with a larger scale from
item pairs which pass the Chi-squared test and O1 > E1              Walmart e-Commerce platform (www.walmart.com) following
as the positively-dependent item pairs and the item pairs           the same format of Instacart, where the sequence order of
which pass the Chi-squared test and O1 <= E1 as the                 transactions are kept and the order of purchases in the same
negatively-dependent item pairs in the rest of our paper. ",cs.IR,C,-0.069978476,-0.14469782,0.05864944
http://arxiv.org/pdf/2202.06081v1,Modeling User Behavior with Graph Convolution for Personalized Product Search,"Extensive ex-
                                                                                               periments on public datasets demonstrate the effectiveness of our
Figure 4: Ablation study of the time interval ùëÖ for successive                                 approach. In future work, we plan to investigate the possibility
graph construction. The results in HR@10 and NDCG@10                                           of applying our approach on dynamic behavior graphs for user
are reported. ",cs.IR,C,-0.1282227,-0.033610053,0.25388017
http://arxiv.org/pdf/2202.06129v1,RETE: Retrieval-Enhanced Temporal Event Forecasting on Unified Query Product Evolutionary Graph,"Algorithm 1: The optimization process for RETE. systematic study for optimal segmentation as our future work. Ta-
                                                                        ble 5 in Appendix A.4 summarizes the statistics of the experimental
   Input: Evolutionary knowledge graph {G1, ¬∑ ¬∑ ¬∑ , Gùëá } and            datasets. ",cs.IR,C,-0.22182389,-0.104172684,-0.055104923
http://arxiv.org/pdf/2202.06197v1,Web-Based File Clustering and Indexing for Mindoro State University,"For instance, when dealing with universities‚Äô websites, we may want to separate
professors‚Äô home pages from students‚Äô home pages, and pages for courses from pages
for research projects. This kind of clustering can benefit further analysis and utilization of
the dataset such as information retrieval and information extraction, by grouping similar
types of information sources together. The user will start at the top of the list and follow it down examining the
documents one at a time. ",cs.IR,A,0.010847079,0.22350284,0.16375092
http://arxiv.org/pdf/2202.06200v1,Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning,"Figure 2 shows that, after rescaled with
their means and standard deviations of log-transformed data, the recruitment time-
series collapse onto a standard log-normal distribution. I further study the diÔ¨Äerences between two consecutive values in (raw) recruit-
ment time-series, where the original time-series is detrended by subtracting the
mean trend. Based on the Kolmogorov-Smirnov test with data aggregated across
72 stocks, while the null hypothesis that the (rescaled) log-transformed data are
normally distributed cannot be rejected with a p-value of 9.54 √ó 10‚àí2, the null
hypothesis that the successive diÔ¨Äerences of the (rescaled) recruitment series are
normally distributed should be rejected with a p-value of 1.14 √ó 10‚àí12. ",cs.IR,C,-0.35880822,-0.19198601,0.17946684
http://arxiv.org/pdf/2202.06200v2,Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning,"strate the effectiveness of the proposed NCL . We speculate that a more uniform distribution of embeddings en-
dows a better capacity to model the diverse user preferences or                    As future work, we will extend our framework to other rec-
item characteristics. As shown in previous studies [30], there exists           ommendation tasks, such as sequential recommendation. ",cs.IR,B_centroid,0.41766798,0.15042004,-0.03005195
http://arxiv.org/pdf/2202.06306v1,An Analysis of Variations in the Effectiveness of Query Performance Prediction,"As part of our analysis, we have
found that certain factors, such as variations in the IR eÔ¨Äectiveness measures,
has a greater impact in terms of QPP outcomes than other factors, such as
variations in the choice of IR models. An important outcome arising from this
study is that further research on QPP should place greater emphasis on a clear
speciÔ¨Åcation of the experimental setup to enable better reproducibility. In future
we plan to expand our evaluations beyond the TREC Robust dataset. ",cs.IR,C,-0.20462489,-0.16868457,0.014891
http://arxiv.org/pdf/2202.06337v1,Learning to Rank from Relevance Judgments Distributions,"These experiments consolidated our hypothesis and showed en-
couraging results on the usage of probabilistic loss functions also on this dataset. As future work, we plan to further develop the proposed neural architecture to
take advantage of probability distributions on model weights ‚Äì i.e. employing
Bayesian neural layers [3] ‚Äì and to evaluate the performance of the proposed
loss functions to train a model based on implicit user feedback signals such as
clicks and dwell time. ",cs.IR,B,0.1526415,0.024069319,-0.14317876
http://arxiv.org/pdf/2202.06701v1,UA-FedRec: Untargeted Attack on Federated News Recommendation,"more than 1% malicious clients, let alone with defense. Second, our     As a future work, we plan to study effective defense methods on fed-
UA-FedRec outperforms model poisoning attacks (LIE and Fang)            erated news recommendation systems to defend against UA-FedRec. with both Norm-Bounding and Multi-Krum defenses. ",cs.IR,B,0.18592083,-0.112704426,0.06824992
http://arxiv.org/pdf/2202.07296v1,Roomsemble: Progressive web application for intuitive property search,"INTRODUCTION                             The rest of this work is organized as follows: we present
                                                                                                           related work in Section 2; image modeling techniques and
                                           One of the last domains to be disrupted by technology is        the overall application architecture in Section 3; Section 4
                                        real estate, with research mainly focusing on price predictions    describes the user study, metrics used and results obtained; we
                                        [5], [9], [10], and [12]. Although price is one of the most        discuss the results and conclude the paper with suggestions for
                                        important factors in making a decision, it is usually not the      future work in Section 5.
                                        only factor that motivates buyers. On the contrary, every
                                        transaction in the real estate market begins with a search for                              II. ",cs.IR,C,-0.08365898,-0.19596168,0.076375924
http://arxiv.org/pdf/2202.07371v1,Personalized Prompt Learning for Explainable Recommendation,"Extensive experiments demonstrate the effectiveness of our approaches in generating
high-quality explanations as measured by text quality and explainability metrics. As future works, we are immensely interested in whether the generated explanations possess bias
or stereotype against certain social groups and how to mitigate them, as reported in recent studies
[33, 45] that pre-trained models exhibit societal bias towards different groups of people. Besides
explanation generation for recommender systems, we also plan to adopt our approaches to other
applications of personalized natural language generation, such as personalized question answering
systems and personalized conversational agents. ",cs.IR,B,0.2130619,0.19191787,0.16928123
http://arxiv.org/pdf/2202.08959v1,Deep Interest Highlight Network for Click-Through RatePrediction in Trigger-Induced Recommendation,"Experiment setups as well as the corresponding
                                                                          results and analysis are presented in Section 4. We finally conclude
                                                                          the paper and discuss the future work in Section 5. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation  WWW ‚Äô22, April 25‚Äì29, 2022, Virtual Event, Lyon, France

2 RELATED WORK                                                           (UIN), which responds to generate a precise probability score to pre-
                                                                         dict user‚Äôs intent on the trigger item; 3) Fusion Embedding Module
In this section, we will review the related work from following          (FEM), which adaptively fuses trigger item and target item embed-
three respects briefly: Feature Interaction, User Behavior Modelling     dings based on the result of UIN; and (4) Hybrid Interest Extracting
and Trigger-Induced Recommendation. ",cs.IR,B,0.3666574,0.13573705,-0.03660499
http://arxiv.org/pdf/2202.08959v2,Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation,"Experiment setups as well as the corresponding
                                                                          results and analysis are presented in Section 4. We finally conclude
                                                                          the paper and discuss the future work in Section 5. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation  WWW ‚Äô22, April 25‚Äì29, 2022, Virtual Event, Lyon, France

2 RELATED WORK                                                           (UIN), which responds to generate a precise probability score to pre-
                                                                         dict user‚Äôs intent on the trigger item; 3) Fusion Embedding Module
In this section, we will review the related work from following          (FEM), which adaptively fuses trigger item and target item embed-
three respects briefly: Feature Interaction, User Behavior Modelling     dings based on the result of UIN; and (4) Hybrid Interest Extracting
and Trigger-Induced Recommendation. ",cs.IR,B,0.3666574,0.13573705,-0.03660499
http://arxiv.org/pdf/2202.08960v1,"Toward a traceable, explainable, and fairJD/Resume recommendation system","Moreover, to cover more domains, additional sources of knowledge (tags from
StackOverÔ¨Çow, quora, etc) may be added using the associations‚Äô rules (same as
related to)[87]. Although, expanding ontologies knowledge bases and labeling

                                                  45
diÔ¨Äerent multilingual categories will be a future work, due to the task complexity
challenges. Figure 13: The hierarchy structure of the ESCO ontology [6]
    The occupation pillar organises the occupation concepts in ESCO. ",cs.IR,A,-0.17352307,0.30089283,0.07716024
http://arxiv.org/pdf/2202.08963v1,Understanding and Shifting Preferences for Battery Electric Vehicles,"and hypothesize performance may improve with additional
                                                                      demographics. However, the improvement would trade off
                          (t) = 0.4 (1)                               with a requirement for more training episodes to learn the
                                  1 + (1 √ó 10‚àí5)t                     larger space, which we leave for future work. The learning rate is similarly annealed according to the fol-                    Discussion and Future Work
lowing schedule. ",cs.IR,C,-0.2585508,-0.15374534,0.024749741
http://arxiv.org/pdf/2202.09502v1,Graph Spring Network and Informative Anchor Selection for Session-based Recommendation,"345‚Äì354. items as another interesting future work. [11] A. Luo, P. Zhao, Y. Liu, F. Zhuang, D. Wang, J. Xu, J. Fang,
                                                                      and V. S. Sheng, ‚ÄúCollaborative self-attention network for session-
                                                                      based recommendation.‚Äù in IJCAI, 2020, pp. ",cs.IR,B,0.31299388,0.04138139,0.058207765
http://arxiv.org/pdf/2202.09508v1,Who Are the Best Adopters? User Selection Model for Free Trial Item Promotion,"7: Results under different tree depth. our future work. Next, we set depth from one to four to further explore                                                                                             ACKNOWLEDGMENTS
how different tree depth inÔ¨Çuences the efÔ¨Åciency and per-
formance of SMILE on the Movielens100K dataset. ",cs.IR,C,-0.29329234,-0.03223795,0.003053505
http://arxiv.org/pdf/2202.09508v2,Who Are the Best Adopters? User Selection Model for Free Trial Item Promotion,"7: Results under different tree depth. our future work. Next, we set depth from one to four to further explore                                                                                             ACKNOWLEDGMENTS
how different tree depth inÔ¨Çuences the efÔ¨Åciency and per-
formance of SMILE on the Movielens100K dataset. ",cs.IR,C,-0.29329234,-0.03223795,0.003053505
http://arxiv.org/pdf/2202.09730v1,Graph-based Extractive Explainer for Recommendations,"In addition, currently the scoring function‚Äôs weights in our ILP were
manually set. Learning-based methods can be introduced to optimize it for better performance in
our future work. Acknowledgments

This work is supported by the National Science Foundation under grant IIS-1553568, IIS-1718216
and IIS-2007492. ",cs.IR,C,-0.05498773,-0.2374919,-0.0939496
http://arxiv.org/pdf/2202.10221v1,Tracking environmental policy changes in the Brazilian Federal Official Gazette,"While a rule-based system working
jointly with domain experts already deliver immeasurable value when it comes
to policy monitoring, it is also paramount that the latest NLP technologies be
considered to increase the scalability and performance of these systems. Hence,
among the future work are the expansion of the annotated datasets, as well as
the improvement of the best models presented here so that they can keep the
quality and stability of the classiÔ¨Åcation for a greater number of classes. 10  F. Cac¬∏aÀúo et al. ",cs.IR,A,-0.0176134,0.13671489,0.015333128
http://arxiv.org/pdf/2202.10241v1,VRConvMF: Visual Recurrent Convolutional Matrix Factorization for Movie Recommendation,"Pooling 1 to 4 in Fig. 7 represent the
visual features of 4 pooling layers from shallow to deep                                                        In the future work, we will crawl corresponding trailers
in the VGG19 network respectively. These single-layers of                                                    information of movies directly and transfer them into textual
visual information are combined with RConvMF respectively. ",cs.IR,A,-0.1048155,0.10624941,-0.17185321
http://arxiv.org/pdf/2202.10326v1,A Deep Learning Approach for Repairing Missing Activity Labels in Event Logs for Process Mining,"Since both methods                    B. FURTHER ANALYSIS OF OUR PROPOSED METHOD
rely on trace clustering algorithms, only a small portion of                 To further analysis the performance of our proposed method,
activity labels can be deleted. In addition, only one activity               we evaluated our method with more event logs and miss-
was deleted in each trace. ",cs.IR,C,-0.15045622,-0.03571826,0.18163812
http://arxiv.org/pdf/2202.10326v2,A Deep Learning Approach for Repairing Missing Activity Labels in Event Logs for Process Mining,"The Ô¨Årst group of experiments compared the performance of our proposed
method with existing methods to repair missing activity labels in event logs. The second group
of experiments performed further analysis to prove the effectiveness of our method. We implemented our approach in Python 3.7.1 based on TensorÔ¨Çow 2.7.0. ",cs.IR,A,-0.20062351,0.07009212,0.0829743
http://arxiv.org/pdf/2202.10842v3,KuaiRec: A Fully-observed Dataset and Insights for Evaluating Recommender Systems,"It also contains a
‚Ä¢ With this unique dataset, we design experiments to illustrate how                  set of missing-complete-at-random (MCAR) data by asking 5,400
  data density and exposure bias affect the evaluation of recom-                     users to give ratings on 10 items that are randomly selected from
  mendations. We further study the effect of estimating the missing                  1,000 items. values, i.e., matrix completion, on the evaluation results. ",cs.IR,B,0.15227413,-0.03406284,0.23113477
http://arxiv.org/pdf/2202.10870v1,Socialformer: Social Network Inspired Long Document Modeling for Document Ranking,"In order to compare
between words. For further analysis, we remove one strategy at a          the impact of different sparsity on graph partition, we select a
time to observe the impact on the MS MARCO dataset. In addition,          document with 2,000 tokens, and set the sparsity of the graph at
we use random sampling that the probability of establishing each          0.99, 0.97, 0.95, 0.93 level respectively following Eq. ",cs.IR,A,-0.1830779,0.07947743,0.08591876
http://arxiv.org/pdf/2202.11527v1,A new LDA formulation with covariates,"A disadvantage of our method is the computational cost (especially in large datasets with many sample units and
categories) compared to models using variational Bayes methods. A possible future work would be to consider a
version of this model with a variational inference approach. Page 19 of 25
                                                    A new LDA formulation with covariates. ",cs.IR,C,-0.048162766,-0.047770612,0.08022543
http://arxiv.org/pdf/2202.12081v1,Community Trend Prediction on Heterogeneous Graph in E-commerce,"From the perspective of age,                                                        advance. For future work, it would be interesting to investigate how
attribute tags of the two communities differ significantly. There                                                       to dynamically divide the communities according to preferences. ",cs.IR,A,0.0034143776,0.01837838,0.39904082
http://arxiv.org/pdf/2202.12826v1,A Systematic Literature Review about Idea Mining: The Use of Machine-driven Analytics to Generate Ideas,"Thus, this study could summarize techniques and heuristics for idea gen-
eration for enthusiastic practitioners. It could also serve as a basis for future work in
academia. Ideas are sources of innovation, and hence the result of this study is a valua-
ble contribution to the industry, startups, accelerators, incubators, government agen-
cies, etc. ",cs.IR,C,-0.2941715,0.10909692,0.30825034
http://arxiv.org/pdf/2202.13090v1,Disentangling Long and Short-Term Interests for Recommendation,"During
which many sequential encoders and loss functions can be utilized. our experiments, we tried to add an independent loss between the
We leave the further study as future work. two interests as, and AUC drops by 0.01, which verifies our point. ",cs.IR,C,-0.16260508,-0.2519395,-0.28197613
http://arxiv.org/pdf/2202.13307v1,The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation,"Moreover, we observe that a primary challenge many
models face is the unfairness of popularity bias. As for future work, we plan to
extend our experiments on more datasets from diÔ¨Äerent domains (e.g., marking
in e-commerce [34], media-streaming, e-fashion [13]) and models such as session-
based [28], neural [8] and content-based systems [15]. Investigating the diÔ¨Äerent
type of bias, such as gender bias, can be a potential direction for future research. ",cs.IR,B,0.20223436,0.049677417,0.1769115
http://arxiv.org/pdf/2202.13307v2,The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation,"Moreover, we observe that a primary challenge many
models face is the unfairness of popularity bias. As for future work, we plan to
extend our experiments on more datasets from diÔ¨Äerent domains (e.g., marking
in e-commerce [34], media-streaming, e-fashion [13]) and models such as session-
based [28], neural [8] and content-based systems [15]. Investigating the diÔ¨Äerent
type of bias, such as gender bias, can be a potential direction for future research. ",cs.IR,B,0.20223436,0.049677417,0.1769115
http://arxiv.org/pdf/2202.13446v1,The Unfairness of Popularity Bias in Book Recommendation,"Additionally, our results suggest
that an underlying tradeoÔ¨Ä exists between personalization and fairness of popu-
larity bias in Diverse and Bestseller-focused groups, that is, algorithms with high
personalization abilities tend to experience fairness issues. Thus, further research
could be worthwhile into implementing a recommendation algorithm that can
Ô¨Ånd the optimal tradeoÔ¨Ä between personalization and the unfairness of popu-
larity biases to enhance the system‚Äôs overall eÔ¨Äectiveness. Finally, it would be
interesting to investigate popularity bias on other domains and algorithms such
as session-based [23], content-based [17], or reinforcement learning-based recom-
mendation [4] methods, as well as incorporating further evaluation metrics such
as novelty and coverage. ",cs.IR,B,0.38466915,-0.002286982,0.2179824
http://arxiv.org/pdf/2202.13506v1,Keyword Optimization in Sponsored Search Advertising: A Multi-Level Computational Framework,"Table 1 presents the resulting
performance of our MKOF and two baseline strategies. Strategy          Payoff

                            Case-1          Case-2

3 Note that determining the number of campaigns and the number of adgroups is beyond scope of this research, which might
be covered in the future work. 15
    MKOF                       11,938,036             61,585
BASE2-Ratio                    10,387,413             57,992
BASE1-Origin                   11,108,298             57,605

Table 1. ",cs.IR,C,-0.133976,-0.1397002,0.116861306
http://arxiv.org/pdf/2202.13556v1,Filter-enhanced MLP is All You Need for Sequential Recommendation,"We set                                                         requires to be further investigated. We leave it into future works. the number of the learnable filter blocks as 2, the batch size is set as                                               For hidden size, we can see that the best value is about 64. ",cs.IR,C,-0.21098,-0.18621436,-0.26105356
http://arxiv.org/pdf/2202.13616v1,WSLRec: Weakly Supervised Learning for Neural Sequential Recommendation Models,"We propose WSLRec for resolving the incompleteness and inaccu-
   Table 7 shows that Ensemble outperforms Original and Fine-          racy problems in sequential recommendation models, which relies
tune outperforms Ensemble, which verifies again that BR and            on pre-training to incorporate extra weak supervisions, the top-
ItemCF provide useful knowledge and implies that fine-tuning is        ùëò mining for mining reliable positive labels, and fine-tuning for
more effective in mining useful knowledge from BR and ItemCF           improving the model based on these labels. For future work, we‚Äôd
than merging the set of recommended items directly. Besides, WSLRec    like to investigate more auxiliary weak supervisions by leveraging
further achieves remarkable performance gains compared to Fine-        contextual information like item attributes. ",cs.IR,B,0.3179204,0.09143686,-0.19765688
http://arxiv.org/pdf/2202.13869v1,Query Expansion and Entity Weighting for Query Reformulation Retrieval in Voice Assistant Systems,"DeepImpact). 4) DeepImpact [16], which performs both document expansion
and semantic importance estimation using DocT5Query and a con-                                                                          For the future work, we would like to investigate more effective
trastive learning based term prediction. ways to learn entity extension/ weighting and how to leverage the

   To evaluate the effectiveness of QEEW, we applied it to 1) string-
match based Elasticsearch and 2) the neural embedding based Sim-
CSE. ",cs.IR,A,-0.008279001,0.2862621,-0.23452246
http://arxiv.org/pdf/2202.13871v1,Wastewater Pipe Rating Model Using Natural Language Processing,"2.2 Data Set and Annotation:

A total of 3100 pipe repair documents were extracted from the Dept. of Engineering &
Environmental Services' approved database by removing records with insufficient and missing
information for further analysis. There was no complete information related to defect location, so
we removed 130 documents and finally had 2970 pipe repair documents. ",cs.IR,C,-0.42281544,0.048939448,0.06739297
http://arxiv.org/pdf/2202.13871v2,Wastewater Pipe Rating Model Using Natural Language Processing,"Methods and Materials

3.1 Data Set and Data Preprocessing:

A total of 3100 pipe repair documents were extracted from the Dept. of Engineering &
Environmental Services' approved database by removing records with insufficient and missing
information for further analysis. There was no complete information about the defect location, so
130 documents were reoved, and finally had 2970 pipe repair documents. ",cs.IR,C,-0.4283687,0.004783664,0.06903635
http://arxiv.org/pdf/2202.13959v1,Semi-Structured Query Grounding for Document-Oriented Databases with Deep Retrieval and Its Application to Receipt and POI Matching,"Pretrained Language Models for Sequential Sen-
                                                                 tence ClassiÔ¨Åcation. In Proceedings of the 2019 Confer-
   As future work, testing the proposed grounding pipeline       ence on Empirical Methods in Natural Language Process-
on different applications or domains would help to get a         ing and the 9th International Joint Conference on Natural
                                                                 Language Processing (EMNLP-IJCNLP), 3693‚Äì3699. Hong
                                                                 Kong, China: Association for Computational Linguistics. ",cs.IR,A,-0.15886718,0.18334955,-0.20215441
http://arxiv.org/pdf/2203.00350v1,Results Merging in the Patent Domain,"For the document scores ranking, linear regression is
better than polynomial regression but the random forest is even better than both, so linear mapping to the scores is not
the best option. For future work, we plan to further investigate the models and try a different combination of parameters. Also, we plan
to create reusable models that can be trained and reused. ",cs.IR,B,0.09573747,-0.036384128,-0.062415022
http://arxiv.org/pdf/2203.00376v1,Popularity Bias in Collaborative Filtering-Based Multimedia Recommender Systems,"We believe that our Ô¨Åndings are a Ô¨Årst step
to inform the research on popularity bias mitigation techniques (see Section 2)
to choose the right mitigation strategy for a given setting. Additionally, as mentioned earlier, we plan to further study the diÔ¨Äerences
we found with respect to algorithmic performance for the diÔ¨Äerent user groups
and multimedia domains. Here, we also want to study popularity bias in top-n
settings using ranking-aware metrics such as nDCG (e.g., as used in [18]). ",cs.IR,B,0.20711583,-0.17399146,0.23110557
http://arxiv.org/pdf/2203.00897v1,An Effective Way for Cross-Market Recommendation with Hybrid Pre-Ranking and Ranking Models,"Firstly,   concise and flexible to solve this task in a more elegant way. We‚Äôll
Null importances distributions are created by fitting the models       leave it for future work. over several runs on a shuffled version of the target. ",cs.IR,C,-0.014302982,-0.19424084,-0.075969435
http://arxiv.org/pdf/2203.01155v1,Top-N Recommendation Algorithms: A Quest for the State-of-the-Art,"In terms of the outcomes of the experiments, our reproducibility study conÔ¨Årmed earlier Ô¨Åndings that the latest models
are not often the best performing ones, in particular for the modest-sized datasets that we considered in our evaluation. In our ongoing and future work, we plan to Ô¨Åne-tune our models also on larger datasets and to share these tuned models
publicly. Thereby, we hope to reduce the often huge computational eÔ¨Äort that other researchers would otherwise need to
Ô¨Åne-tune all baseline models whenever they propose a new model. ",cs.IR,C,-0.09639269,-0.17346647,-0.022554943
http://arxiv.org/pdf/2203.01155v2,Top-N Recommendation Algorithms: A Quest for the State-of-the-Art,"In terms of the outcomes of the experiments, our reproducibility study conÔ¨Årmed earlier Ô¨Åndings that the latest models
are not often the best performing ones, in particular for the modest-sized datasets that we considered in our evaluation. In our ongoing and future work, we plan to Ô¨Åne-tune our models also on larger datasets and to share these tuned models
publicly. Thereby, we hope to reduce the often huge computational eÔ¨Äort that other researchers would otherwise need to
Ô¨Åne-tune all baseline models whenever they propose a new model. ",cs.IR,C,-0.09639269,-0.17346647,-0.022554943
http://arxiv.org/pdf/2203.01731v1,Do Perceived Gender Biases in Retrieval Results Affect Relevance Judgements?,"The remainder of the paper is organized as follows: in Section 2, we discuss the re-
lated work. Section 3 explains the setting of our experiments, whose results are reported
and discussed in Section 4, followed by the conclusion and future work. 2 Related Work

Algorithmic bias is a socio-technological phenomenon. ",cs.IR,C,-0.11489833,-0.116779804,0.2864609
http://arxiv.org/pdf/2203.03367v1,Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval,"As introduced in Section 2, Chinese passage retrieval for           dataset. We also discuss some valuable research problems based on
general domain has been studied in a relatively long period, and            the Multi-CPR dataset for future work. Finally, we will open source
annotated dataset in general domain is also available. ",cs.IR,A,-0.10130933,0.29193443,-0.094145894
http://arxiv.org/pdf/2203.03367v2,Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval,"detailed explanation. There are usually two basic modules con-          We also discuss some valuable research problems based on the
tained in the query processor module: Query reformulation (QR)          Multi-CPR dataset for future work. Finally, we will open-source all
and Query suggestion (QS) [25, 47]. ",cs.IR,A,-0.1627921,0.14262965,0.004039362
http://arxiv.org/pdf/2203.03551v1,Semi-supervised Nonnegative Matrix Factorization for Document Classification,"5 keywords (i.e. those that have the highest weight in topic                 In future work, we plan to take a Bayesian approach to
column of Atrain) for each topic of the (D(¬∑ ¬∑), ¬∑ F )-SSNMF              SSNMF by assuming data-appropriate priors and performing
of Figure 1.                                                              maximum a posteriori estimation. Furthermore, we will form
                                                                          a general framework of MLE models for exponential family
B. Reuters Data Experiments                                               distributions of uncertainty, and study the class of models
                                                                          where multiplicative update methods are feasible. ",cs.IR,A,-0.11049791,0.010743424,0.059877858
http://arxiv.org/pdf/2203.03552v1,Automated Single-Label Patent Classification using Ensemble Classifiers,"Section 5 presents and discusses the experimental results. Finally, section 6 concludes the paper and
discuss the ongoing and future work. 2
2 PRIOR WORK
Several works were presented to solve the automated patent classification problem. ",cs.IR,C,-0.19273786,0.04568834,0.11285461
http://arxiv.org/pdf/2203.03853v1,Where Does the Performance Improvement Come From? -- A Reproducibility Concern about Image-Text Retrieval,"Therefore these modification methods are not reasonably        trials or at the very least avoid cherry-picking the best run [26]. We
hyperparameter-agnostic and stable with their modification of the       hope that future work in the field of information retrieval should
                                                                        pay more attention to the reproducibilities and capabilities of the
                                                                        model, rather than tuning parameters and stacking tricks for better
                                                                        performance. Conference acronym ‚ÄôXX, June 03‚Äì05, 2018, Woodstock, NY  Jun Rao1‚àó, Fei Wang2‚àó, Liang Ding3‚Ä†, Shuhan Qi1‚Ä†, Yibing Zhan3, Weifeng Liu2, Dacheng Tao3

REFERENCES                                                                                        In EMNLP (1). ",cs.IR,A,-0.09392273,0.057277855,-0.25859696
http://arxiv.org/pdf/2203.03853v2,Where Does the Performance Improvement Come From? -- A Reproducibility Concern about Image-Text Retrieval,"being thought to be some ‚Äútricks‚Äù, some of the details omitted by the
authors from the paper played a significant role. We wish that the           We hope that future work in the field of information retrieval
authors could have described them in detail to help the researchers       should pay more attention to the reproducibilities and capabilities
really understand where the enhancements came from. of the model, rather than trading cumbersome parameters-tuning
3. ",cs.IR,A_centroid,-0.049612068,0.18877561,-0.03669065
http://arxiv.org/pdf/2203.05406v1,Disentangled Multimodal Representation Learning for Recommendation,"underperforms DMRLv and DMRLt, which use our attention
   2) User Preferences (Ratings)                                           method. This further demonstrates the importance of mod-
   In order to further study the contributions of different                eling users‚Äô modality preferences. The further improvement
modalities to a user‚Äôs preference on the factors of the target             of DMRL over DMRLw/o u validate the effectiveness of

   10We selected two users (0 and 197) who purchased the same item (1294)
as an example. ",cs.IR,B,0.26503366,-0.120324425,0.21616162
http://arxiv.org/pdf/2203.05406v2,Disentangled Multimodal Representation Learning for Recommendation,"‚Ä¢ DMRLv: It is a variant of our method which only uses item
                                                                             IDs and visual features. 2) User Preferences (Ratings)
   In order to further study the contributions of different                ‚Ä¢ DMRLw/o a: This variant removes the designed multimodal
modalities to a user‚Äôs preference on the factors of the target               attention mechanism. It exploits the multimodal features of
item, we compute the ratings of the two different users given                different factors indiscriminately. ",cs.IR,B,0.18242538,0.015451492,0.08454697
http://arxiv.org/pdf/2203.05420v1,Evaluating Elements of Web-based Data Enrichment for Pseudo-Relevance Feedback Retrieval,"When we conducted our experiments, DuckDuckGo
had longer snippet texts that may lead to more expressive training data. We
leave it as future work to investigate the interactions and eÔ¨Äects between the
query and the snippet length (volume of the training data). How do the two diÔ¨Äerent query formulations aÔ¨Äect the Ô¨Ånal run results? ",cs.IR,A,-0.26933515,0.23425357,0.002396617
http://arxiv.org/pdf/2203.05824v1,Towards Analyzing the Bias of News Recommender Systems Using Sentiment and Stance Detection,"This means that if a user prefers only articles with a nega-             ommenders. However, future work should investigate also the be-
                                                                              havior of collaborative-Ô¨Åltering approaches in terms of sentiment
tive sentiment towards the topic of, for example, refugees living in          and stance bias. Moreover, the analysis could be extended to other
                                                                              datasets in order to examine if the same patterns can be observed
Germany, these recommenders will continue recommending news                   for a larger variety of topics. ",cs.IR,B,0.2612039,0.13092816,0.120863326
http://arxiv.org/pdf/2203.05954v1,An Adaptive Hybrid Active Learning Strategy with Free Ratings in Collaborative Filtering,"such free ratings are capable of improving the performance of the model without
requesting further interacting from user, improving, thus, his/her experience. We outline the following directions for future work:

 ‚Äì Further validation: As a proof of concept, we have restricted our experiments
     to the MovieLens dataset due to the presence of side information. Future
     work should consider datasets from other applications. ",cs.IR,B,0.19744474,-0.036705337,0.030476905
http://arxiv.org/pdf/2203.06407v1,Transition Relation Aware Self-Attention for Session-based Recommendation,"Table 4: Performance comparison between different session repre-
                                                                  sentation methods. 5.5 Deeper Model Analysis (RQ2)                                   55                                                        55

We conduct further analysis of TRASA to Ô¨Ånd out what ex-          50                                                        50
actly contributes to the performance improvement. 45P@20 16                                                 45     16
Impact of each component. ",cs.IR,C,-0.26850164,-0.22414342,-0.0789385
http://arxiv.org/pdf/2203.06467v1,G$^3$SR: Global Graph Guided Session-based Recommendation,"Last but not least,   PERFORMANCE COMPARISON WITH DIFFERENT MODEL STRUCTURES
as we discussed in Section IV, the proposed exponential
decaying strategy is simple but highly competitive with the       Method             Yoochoose 1/64           Diginetica
sophisticated attention mechanism. As a result, it‚Äôs promising                     P@20 MRR@20           P@20 MRR@20
to design better representation learning methods and/or readout   SR-GNN
functions for session-based recommendation in future works. G3SR             70.36         30.73   50.73     17.59
                                                                  GC-SAN           72.61         30.83   54.05     18.72
                             APPENDIX A                           G3SR+GC-SAN      68.49         29.54   42.75     13.86
           A CLOSER LOOK AT THE TOP-K RESULTS                     GCE-GNN          71.90         30.82   52.30     18.05
                                                                  G3SR+GCE-GNN     71.75         30.43   54.18     19.01
   To provide a better understanding of the proposed methods,                      72.83         30.78   54.29     18.94
we compare SR-GNN, G3SR-attn and G3SR on the three
datasets w.r.t. ",cs.IR,C,-0.03757135,-0.11638652,-0.31779796
http://arxiv.org/pdf/2203.06641v1,Exploring Customer Price Preference and Product Profit Role in Recommender Systems,"ACM, 2013,
proÔ¨Åt), which can be further used to target spe-
ciÔ¨Åc customer groups. This is a promising result,
which indicates further research that can result
in beneÔ¨Åts for customers and e-commerce. Going
further, the comparison of results with online
evaluation outcomes may implicate exciting Ô¨Ånd-
ings in a broader evaluation philosophy context. ",cs.IR,C,-0.010886885,-0.04494638,0.2979552
http://arxiv.org/pdf/2203.07167v1,Dataset and Case Studies for Visual Near-Duplicates Detection in the Context of Social Media,"While a more robust and elaborate analysis remains for
Procedure. We classiÔ¨Åed the Ô¨Årst retrieved result of the        future work, this case study demonstrates the potential use of
22, 797 Twitter and 4chan query images, by applying the re-     the process to automatically detect spread of visual content
trieval and classiÔ¨Åcation processes as outlined above. We use   across social media platforms. ",cs.IR,A,-0.113943025,0.23554927,0.13732919
http://arxiv.org/pdf/2203.07735v1,Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation,"representations like ours. Also, our DAR takes a lit-       among sparse and dense retrievers still depends on
tle more time to augment document representations           the dataset, and combining sparse and dense mod-
than the base DPR model, while signiÔ¨Åcantly im-             els to complement each other will be a valuable
proving retrieval performances as shown in Table 1.         research direction, which we leave as future work. Even compared to the term replacement based reg-
ularization model (DPR w/ AR), our DAR shows
noticeable efÔ¨Åciency, since an additional embed-
ding process of the document after the word re-
placement on it requires another forwarding step
besides the original forwarding step. ",cs.IR,A,-0.100916624,0.24447592,-0.32817397
http://arxiv.org/pdf/2203.07735v2,Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation,"representations like ours. Also, our DAR takes a lit-       among sparse and dense retrievers still depends on
tle more time to augment document representations           the dataset, and combining sparse and dense mod-
than the base DPR model, while signiÔ¨Åcantly im-             els to complement each other will be a valuable
proving retrieval performances as shown in Table 1.         research direction, which we leave as future work. Even compared to the term replacement based reg-
ularization model (DPR w/ AR), our DAR shows
noticeable efÔ¨Åciency, since an additional embed-
ding process of the document after the word re-
placement on it requires another forwarding step
besides the original forwarding step. ",cs.IR,A,-0.100916624,0.24447592,-0.32817397
http://arxiv.org/pdf/2203.08507v1,Personal Knowledge Graphs: Use Cases in e-learning Platforms,"Overall, we aim to                           Somewhat disagree
address this part by setting time constrains on PKG computation                        Neither agree or disagree
time falls to ensure some level of confidence on the computed data. We discuss further challenges in future work. Somewhat agree
                                                                                             Strongly agree
5 METHODOLOGY
                                                                                 100   100    100    100           100
The methodology for approaching the research questions combines          100
qualitative and quantitative analysis. ",cs.IR,C,-0.33558363,-0.33760926,0.22226122
http://arxiv.org/pdf/2203.10001v1,FORCE: A Framework of Rule-Based Conversational Recommender System,"We leave the sup-     at each turn and the Recall@k for recommendation task at
port of uploading annotated data for model training and ser-    the turns when the bot intent is ‚ÄòRecommend‚Äô. With the im-
vice conÔ¨Åguration on framework to future work. plementation and conÔ¨Åguration shown in our demo video,
                                                                we get the experiment results in Table 1. ",cs.IR,B,0.23177965,0.057252638,-0.07434881
http://arxiv.org/pdf/2203.10258v1,Doubly Robust Collaborative Targeted Learning for Recommendation on Data Missing Not at Random,"Throughout, we adopt 1/pÀÜu,i ‚àí 1 as a key
choice of targeting step for TMLE to satisfy equation (3), which is essentially a Ô¨Årst-order TMLE
[3]. In future work, we will explore higher-order TMLE and more effective covariate selection in the
targeting step. 9
Figure 2: Learning performance on MAR test set of AUC (left), NDCG@5 (middle), and NDCG@10
(right) with varying levels of propensity clipping threshold. ",cs.IR,C,-0.2091302,-0.31272608,-0.064708285
http://arxiv.org/pdf/2203.10258v2,Doubly Robust Collaborative Targeted Learning for Debiased Recommendations,"Throughout, we adopt 1/pÀÜu,i ‚àí 1 as a key choice of targeting step for
TMLE to satisfy equation (2), which is essentially a Ô¨Årst-order TMLE [3]. In future work, we will
explore higher-order TMLE and more effective feature selection in the targeting step. 9
Figure 2: Learning performance on MAR test set of AUC (left), NDCG@5 (middle), and NDCG@10
(right) with varying levels of propensity clipping threshold. ",cs.IR,C,-0.22254536,-0.26667136,-0.10423995
http://arxiv.org/pdf/2203.11011v1,Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks,"Our method can also be generalized to many other recom-
mendation scenarios. In our future work, we will deploy our concept recommendation algorithms
on a real-world MOOC platform XuetangX and provide a commercial concepts recommendation
service with personalized and dynamic characteristics. We will also explore how to use inverse
reinforcement learning to describe the system and further improve the performance of our method. ",cs.IR,B,0.36223608,0.13396095,-0.026753778
http://arxiv.org/pdf/2203.11011v2,Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks,"Our method can also be generalized to many other recom-
mendation scenarios. In our future work, we will deploy our concept recommendation algorithms
on a real-world MOOC platform XuetangX and provide a commercial concepts recommendation
service with personalized and dynamic characteristics. We will also explore how to use inverse
reinforcement learning to describe the system and further improve the performance of our method. ",cs.IR,B,0.36223608,0.13396095,-0.026753778
http://arxiv.org/pdf/2203.11015v1,Filter Drug-induced Liver Injury Literature with Natural Language Processing and Ensemble Learning,"abstract only, the TF-IDF model outperformed the ensemble                                                   TABLE I
model with higher accuracy of 0.927, a higher F1 score of          THE PERFORMANCE OF THE TF-IDF MODEL AND THE ENSEMBLE MODEL
0.930 and a higher precision of 0.886, while the ensemble
showed a higher recall of 0.988. Generally, on the two datasets       ON THE HOLD-OUT DATA (1) AND ADDITIONAL HOLD-OUT DATA (2)
of the hold-out data released by the challenge, both models
show high performance in classifying the literature with high      Model       Accuracy  F1 Score  Precision  Recall
accuracy and F1 score, which may enable researchers to ac-         TF-IDF-1    0.954     0.954     0.947      0.961
curately Ô¨Ålter the DILI-negative literature for further analysis. Ensemble-1  0.954     0.955     0.960      0.950
                                                                   TF-IDF-2    0.927     0.930     0.886      0.979
                                                                   Ensemble-2  0.900     0.908     0.840      0.988

                           IV. ",cs.IR,A,-0.15133569,0.0679799,-0.114010364
http://arxiv.org/pdf/2203.11027v1,Reasoning over Public and Private Data in Retrieval-Based Systems,"We do not observe a large difference between the two approaches for
CONCURRENTQA-results (also observed in [Xiong et al., 2021]), and thus use random negatives for all experiments. We hope to experiment with additional methods of selecting negatives for CONCURRENTQA in future work. The number of retrieved passages per retrieval, k, is an important hyperparameter as increasing k tends to increase
recall, but sacriÔ¨Åce precision. ",cs.IR,C,-0.1523065,-0.037051294,-0.097340144
http://arxiv.org/pdf/2203.11491v1,Making Recommender Systems Forget: Learning and Unlearning for Erasable Recommendation,"Instead of training models on each group in isolation and
   SpeciÔ¨Åcally, we take the following three steps to learn col-                  aggregating them, SeqTrain module trains the model on the
laborative embedding: (i) using R to build the correspond-                       whole dataset to preserve collaborative information. We
ing hypergraph; (ii) for each user, performing random walk                       achieve this by training the model sequentially on all groups,
to obtain its relations, which transforms the task to sequence                   and we further study the effect of training order. embedding; (iii) applying the sequence embedding technique,
e.g., Word2Vec [Church, 2017], to learn the collaborative em-                    Training Order
bedding. ",cs.IR,A,0.10723229,0.18284097,-0.13644567
http://arxiv.org/pdf/2203.13088v1,Introducing Neural Bag of Whole-Words with ColBERTer: Contextualized Late Interactions using Enhanced Reduction,"lines 6 & 8), only the reduced recall of the BOW2 indexing is carried
                                                                         over. This a great result for the robustness of our system, it shows
   A curious path for future work based on the results of Table 3        that it can be deployed in a variety of approaches, and practitioners
would be to use a conservative loss setting (such as line 6) that does   are not locked into a specific retrieval approach. For example if one
not force a lot of the word removal gates to become zero (so as to       has made large investments in an inverted index system, they could
not take away capacity from the loss surface for the ranking tasks),     build on these investments with Uni-ColBERTer. ",cs.IR,A,-0.11353995,0.079290494,-0.24717721
http://arxiv.org/pdf/2203.13769v1,An Audit of Misinformation Filter Bubbles on YouTube: Bubble Bursting and Recent Behavior Changes,"Real users also like or dislike
videos, subscribe to channels, leave comments or click on the search results or recommendations. A more human-like
bot simulation, with these interactions and possible inclusion of human biases bursting remains our future work. Nevertheless, our audit showed that YouTube (similar to other platforms), despite their best efforts so far, can
still promote misinformation seeking behavior to some extent. ",cs.IR,B,0.106518455,0.047357414,0.35831523
http://arxiv.org/pdf/2203.13995v1,Transfer of codebook latent factors for cross-domain recommendation with non-overlapping data,"Section 4 discusses the experimental results. Section 5 contains the conclusion and
future work. 2 Related Work

Though collaborative Ô¨Åltering based recommender systems have become the norm these days, they have trouble in
making accurate recommendations due to data sparsity problem, i.e., very little actual information available. ",cs.IR,B,0.26449913,-0.049131766,0.06910776
http://arxiv.org/pdf/2203.14037v1,Data Augmentation Strategies for Improving Sequential Recommender Systems,"‚Ä¢ We suggest the possibility of further performance improvements of other current state-of-the-art models, where
           data augmentation is applied in the preprocessing step while maintaining the overall model architecture. In this
           regard, we expect that future works can verify if data augmentation can serve as an universal preprocessing
           technique in the design of recommender systems. 2 Related Works

2.1 Sequential Recommendation

Traditional recommendation aims to model general and global preferences of users based on the assumption that user-
item relationships are not dynamic but static, which is intrinsically bound to ignore the order of user-item interactions
in the model. ",cs.IR,B,0.43803418,-0.035210125,-0.0244861
http://arxiv.org/pdf/2203.14232v1,Leveraging Search History for Improving Person-Job Fit,"Besides search history, there are other kinds of side information for person-
job Ô¨Åt. As future work, we will consider developing a more general approach to
leverage various kinds of side information in a uniÔ¨Åed way. Acknowledgements

This work was partially supported by the National Natural Science Foundation
of China under Grant No. ",cs.IR,A,-0.14651786,0.18530945,0.18024528
http://arxiv.org/pdf/2203.14541v1,Specialized Document Embeddings for Aspect-based Similarity of Research Papers,"2018. Explicit Retrofitting of Distributional Word
uation with user feedback is subject to future work. Vectors. ",cs.IR,A,-0.032367323,0.3057028,-0.021945821
http://arxiv.org/pdf/2203.15328v1,Compact Token Representations with Contextual Quantization for Efficient Document Re-ranking,"There is an about 1.2%     ColBERTv2. Our future work is to investigate the
improvement using MarginMSE. Figure 2 gives              above issue further and study the use of CQ in other
an explanation why MarginMSE is more effective. ",cs.IR,C,-0.18926525,-0.16341665,-0.046796247
http://arxiv.org/pdf/2203.15789v1,Revisiting Neighborhood-based Link Prediction for Collaborative Filtering,"With the sparse matrix                        tion to existing standard linkage scores. We further study how our
                                                                                          approach is robust to varying levels of interaction noise that could
ùëÄ stored in the Compressed Sparse Row (CSR) format, calculating                           be seen in real-world data. In total, we craft this section to answer
                                                                                          the following Research Questions (RQ):
      ùëá  ùëÄ   takes  ùëÇ (ùëô  ¬∑  ùëöùëñùëõ (ùë¢,  ùëñ))  time,  where    the  selection    between  ùë¢
                                                                                               ‚Ä¢ RQ1: How does our proposed method perform compared to
ùëÄùëÄ                                                                                                competitive SOTA works? ",cs.IR,C,-0.06476698,-0.1037799,-0.06029585
http://arxiv.org/pdf/2203.15876v1,Self-Supervised Learning for Recommender Systems: A Survey,"1‚Äì38, 2019.
when combined with the technique of knowledge distilla-
tion [148], [149], SSL may largely compensate for the ac-                   [7] X. Liu, F. Zhang, Z. Hou, L. Mian, Z. Wang, J. Zhang, and
curacy degradation of on-device recommendation models. J. Tang, ‚ÄúSelf-supervised learning: Generative or contrastive,‚Äù
Currently, on-device self-supervised recommendation has                             IEEE TKDE, 2021.
not been explored, and we believe it deserves further study. [8] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, ‚ÄúMomentum con-
9.5 Towards General-Purpose Pre-training                                            trast for unsupervised visual representation learning,‚Äù in CVPR,
                                                                                    2020, pp. ",cs.IR,B,0.22347195,0.007780239,-0.18656272
http://arxiv.org/pdf/2203.16161v1,Recommendation of Compatible Outfits Conditioned on Style,"More interest-
ingly, SATCORec chooses items which can make a pronounced style statement. Since in this paper we have focused on compatibility and employed a traditional
beam search for outÔ¨Åt generation, an immediate future work would be to explore
more sophisticated generation algorithms. References

 1. ",cs.IR,C,-0.12580101,-0.07669501,-0.09369311
http://arxiv.org/pdf/2203.16663v1,Robust Reputation Independence in Ranking Systems for Multiple Sensitive Attributes,"However, a more
Ô¨Åne-grained analysis would allow us to understand how robust is the system
when bribing diÔ¨Äerent demographic groups (e.g., assessing if minorities are also
more vulnerable). To focus on our core contribution, we leave this perspective
as future work. Despite these limitations, our multi-attribute mitigation method opens to
new avenues of research in the Ô¨Åeld of reputation-based ranking systems, with
a clear connection to other retrieval systems. ",cs.IR,B,0.16948698,0.024919154,0.24536549
http://arxiv.org/pdf/2204.00279v1,Proactively Control Privacy in Recommender Systems,"Second, more sophisticated

platform mechanisms are also worth exploring. Last but not least, deploying online experiments

and analyzing users‚Äô decisions in real-world can facilitate further research. REFERENCES

 [1] Monireh Abdoos. ",cs.IR,A,0.025322283,-0.021868218,0.53856075
http://arxiv.org/pdf/2204.00279v2,Studying the Impact of Data Disclosure Mechanism in Recommender Systems via Simulation,"Recent
mechanism design works also turn to the perspectives of deep neural network based mechanism
designs, which can be explored with our proposed framework. Last but not least, deploying online
experiments and analyzing users‚Äô decisions in real-world can facilitate further researches. ACM Transactions on Information Systems, Vol. ",cs.IR,B,0.05222731,0.027678737,0.06541097
http://arxiv.org/pdf/2204.00280v1,A Versatile Framework for Evaluating Ranked Lists in terms of Group Fairness and Relevance,"are available from https://waseda.box.com/GFR20220401targz . Table 5 shows the corresponding DistrSim scores as well as the                                Our future work includes further investigation of the properties
final revcnt-GF scores. Table 5(a) shows that for Topic 416, GFNMD                         of the similarity functions in the context of group-fair ranking
disagrees with GFJSD and GFRNOD precisely because DistrSimNMD                              evaluation, and implementing this framework in a shared task. ",cs.IR,C,-0.0046656597,-0.12226365,0.016524877
http://arxiv.org/pdf/2204.00281v1,i-Razor: A Neural Input Razor for Feature Selection and Dimension Search in Large-Scale Recommender Systems,"to derive the desired embedding configuration. To further study                 To study the impact of ùëêùëùùë°, we investigate how i-Razor performs
the role of these two components, we propose and compare the                    with the change of ùëêùëùùë°, while fixing other parameters (ùúè = 0.05, ùúÜ =
following four variants:                                                        0.0001). As shown in Figure 3, larger ùëêùëùùë° leads to larger value of
                                                                                Params, which is straightforward as more embedding blocks and
   (1) i-Razor+0: using the CPT-based pruning algorithm while                   fields would be reserved. ",cs.IR,C,-0.1654226,-0.06158465,-0.17397645
http://arxiv.org/pdf/2204.00308v1,Model-agnostic Counterfactual Synthesis Policy for Interactive Recommendation,"2018. DRN: A deep reinforcement learning framework
for future works, we are planning to make more exploration to                                   for news recommendation. In Proceedings of the 2018 World Wide Web Conference. ",cs.IR,B,0.26473176,0.120563954,-0.12838256
http://arxiv.org/pdf/2204.00716v1,CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos,"These
  con [46];                                                                results suggest that, on queries without typos, using Character-
                                                                           BERT as the core of the dense retrievers‚Äô encoders tends to have
‚Ä¢ CharacterBERT-DR+Aug: this relies on our proposed Character-             similar effectiveness as the use of BERT. It is expected, although
  BERT based dense retriever, and uses the augmentation-based typo-        not empirically proven here, that the adaptation of CharacterBERT
  aware training approach by Zhuang and Zuccon [46];                       to the same training regimes of ANCE and TCT-ColBERTv2 would
                                                                           lead to effectiveness similar to these more advance methods: We
‚Ä¢ StandardBERT-DR+ST: the BERT-based dense retriever is trained            leave confirming this hypothesis to future work. using our proposed Self-Teaching method: thus is it similar to the
  StandardBERT-DR+Aug where the augmentation-based typo-aware                 We then turn our attention to the results obtained on queries
  training approach is replaced by Self-Teaching                           without typos when training with methods that attempt to make
                                                                           DRs more robust on queries with typos ‚Äì namely runs f-i, which
‚Ä¢ CharacterBERT-DR+ST: this relies on our proposed CharacterBERT           are based on StandardBERT-DR or CharacterBERT-DR and the two
  based dense retriever and our Self-Teaching method. ",cs.IR,A,-0.16088071,0.34069312,-0.25785002
http://arxiv.org/pdf/2204.00716v2,CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos,"This is due to the fact that the number of token    do not find statistically significant differences, except for MAP
embeddings constructed by Character-CNNs is usually smaller than       for standardBERT-DR+Aug. We further study on this dataset what
the number of token embeddings constructed by the WordPiece            is the relative percentage of queries with typos that need to be
tokenizer. Thus, for the same query, the self-attention computation    present in a dataset to prefer the use of CharacterBERT-DR+ST over
in the BERT transformer layers is often less time consuming for        StandardBERT-DR. ",cs.IR,A,-0.1466319,0.32615232,-0.27982238
http://arxiv.org/pdf/2204.00752v1,Modeling Dynamic User Preference via Dictionary Learning for Sequential Recommendation,"And similarly the     data. The second future work is to introduce non-linearity
Recurrent Recommender Network (RRN) [62] proposed to            when combing the static user preferences and dynamic user
employ LSTM [22] to capture the dynamics of both users          preferences, which may further improve the performance
and items. Complementary to the RNN-based methods,              of the proposed method [18]. ",cs.IR,B,0.4022503,0.03108731,-0.10693099
http://arxiv.org/pdf/2204.00815v1,Unbiased Top-k Learning to Rank with Causal Likelihood Decomposition,"Once the examination ùê∏ is intervened artificially,
Assumption (3): The click probability on ùëë is equal to its rel-
   evance ùëÖ(x) if and only if ùëë always be examined:

      ùê∏ ‚â° 1 ‚áê‚áí Pr(ùê∂ = 1|x) = ùëÖ(x). 1

                                                                               Some studies also discuss the trust bias[2, 40], which will be our future work. Conference‚Äô17, July 2017, Washington, DC, USA                                                                                                                                   Haiyuan Zhao, et al. ",cs.IR,C,-0.14494826,-0.086472996,0.2682972
http://arxiv.org/pdf/2204.00849v1,Transformer-Empowered Content-Aware Collaborative Filtering,"textual modality, but can be applied to any other modalities that pro-
vide already good item/user representations for recommendation. [12] Danyang Liu, Jianxun Lian, Shiyin Wang, Ying Qiao, Jiun-Hung Chen,
We leave these promising extensions as future work. Guangzhong Sun, and Xing Xie. ",cs.IR,B,0.35649204,0.1490447,-0.008179918
http://arxiv.org/pdf/2204.00926v1,Learning to Augment for Casual User Recommendation,"dation for users who have very few observed interactions [46, 48]. For future work, we are interested in extending such a ‚Äúlearning to
Most of these works rely on side information or contextual data          augment‚Äù concept to other application scenarios (e.g., cross-domain,
                                                                         cold-start) for improving the robustness and adaptivity of different
                                                                         recommendation systems. Moreover, we are interested in extend-
                                                                         ing our augmentation policy from the bandit setup studied here to
                                                                         the reinforcement learning setup, where the agent chooses editing
                                                                         actions depending on its previous decisions. ",cs.IR,B,0.2797189,0.07848827,-0.0159101
http://arxiv.org/pdf/2204.00970v1,A Dynamic Meta-Learning Model for Time-Sensitive Cold-Start Recommendations,"Increasing
     No Interactions in the Current Period                      the size didn‚Äôt improve the results as shown in Figure 6 for
                                                                three datasets. So, we choose 32 for each attribute and the
We further study the model performance where a user             Ô¨Ånal embedding size is set as 160.
doesn‚Äôt have any interaction in the current period. In this
case, our time-speciÔ¨Åc module utilizes global user factors in-        Periodical Recommendation Results
stead of user-speciÔ¨Åc factors due to lack of interaction, and
hence no adaptation is made. ",cs.IR,B,0.19237785,-0.053842515,0.051013555
http://arxiv.org/pdf/2204.01089v1,Virtual Relational Knowledge Graphs for Recommendation,"applied. Our future work shall investigate how to combine the inference
                                                                          capability of a KG for recommendation. Table 2 presents the experiment results. ",cs.IR,B,0.23393886,-0.07318445,0.045036525
http://arxiv.org/pdf/2204.01089v2,VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation,"We also want to use our
VRKG4Rec model on MindSpore2 4, which is a new deep learning                                 of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30,
computing framework. These problems are left for future work. 2015, Austin, Texas, USA. ",cs.IR,C,-0.13512968,-0.07564096,-0.26674783
http://arxiv.org/pdf/2204.01089v3,VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation,"computing framework. These problems are left for future work. (2)It is labor-intensive and time-consuming when applying on KG
of large scale. ",cs.IR,C,-0.29475248,-0.19600517,0.07168711
http://arxiv.org/pdf/2204.01321v1,PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking Models,"SpanBERT: Improving pre-training by representing and pre-
documents or low-ranked documents. In the future work, we aim                                     dicting spans. TACL 8 (2020), 64‚Äì77. ",cs.IR,A,-0.07407753,0.21611354,-0.051261522
http://arxiv.org/pdf/2204.01321v2,PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking Models,"SpanBERT: Improving pre-training by representing and pre-
documents or low-ranked documents. In the future work, we aim                                     dicting spans. TACL 8 (2020), 64‚Äì77. ",cs.IR,A,-0.07407753,0.21611354,-0.051261522
http://arxiv.org/pdf/2204.01321v3,PRADA: Practical Black-Box Adversarial Attacks against Neural Ranking Models,"Qair: Practical query-efficient black-box attacks for image
documents or low-ranked documents. In the future work, we aim                                     retrieval. In CVPR. ",cs.IR,C,-0.15846318,-0.0043722615,-0.028183175
http://arxiv.org/pdf/2204.02002v1,Micro-Behavior Encoding for Session-based Recommendation,"This line of thoughts, though interesting, would                     M@10        22.64        24.41    25.21
make the model much more complicated than its current form. M@20        23.49        25.15    26.06
We have to leave the bulk of experiments for the future work. H@5         21.53        23.09    24.17
                                                                                H@10        32.01        32.99    34.75
B. Dyadic relational encoding with SGNN-HN                                      H@20        43.67        43.92    46.29
                                                                                M@5         11.61        13.28    13.98
   In Section V-E (Figure 5), we do witness the high utility of                 M@10        13.00        14.59    15.38
dyadic relational patterns for recommendation effectiveness. ",cs.IR,B,0.23603973,-0.06332283,0.022285253
http://arxiv.org/pdf/2204.02363v1,Towards Best Practices for Training Multilingual Dense Retrieval Models,"[4] also
                                                                                         made use of mBERT for retrieval in a many-to-many scenario. They
In summary, we provide practitioners with a ‚Äúhow to‚Äù guide for                           train a QA model that can answer a query in any language by re-
building multilingual search applications and researchers with a                         trieving evidence from a multilingual collection and generating an
solid foundation for future work in multilingual dense retrieval. answer in the query language. ",cs.IR,A,-0.095384,0.45393175,-0.074615374
http://arxiv.org/pdf/2204.02906v1,Knowledge Base Index Compression via Dimensionality and Precision Reduction,"Note the log scale on the x-axis  leave a more detailed exploration of these Ô¨Åndings
and the truncation of the y-axis. for future work. few samples (lower-bounded by 128 which is also          2 0.3   5.2            35.2  2 0.6   8.1             31.9
the number of dimensions used for this experiment). ",cs.IR,C,-0.3712609,-0.2758728,0.14953682
http://arxiv.org/pdf/2204.02906v2,Knowledge Base Index Compression via Dimensionality and Precision Reduction,"Note the log scale on the x-axis  leave a more detailed exploration of these Ô¨Åndings
and the truncation of the y-axis. for future work. few samples (lower-bounded by 128 which is also          2 0.3   5.2            35.2  2 0.6   8.1             31.9
the number of dimensions used for this experiment). ",cs.IR,C,-0.3712609,-0.2758728,0.14953682
http://arxiv.org/pdf/2204.03096v1,From Little Things Big Things Grow: A Collection with Seed Studies for Medical Systematic Review Literature Search,"However, we leave such                      detailed analysis of our collection. Here, we found that as a unique
investigation for future work. We perform our evaluation on the                   set of studies before query construction, only a small portion of
included studies that did not appear in the retrieved set of studies. ",cs.IR,A,-0.24418443,0.13022588,0.23138252
http://arxiv.org/pdf/2204.03096v2,From Little Things Big Things Grow: A Collection with Seed Studies for Medical Systematic Review Literature Search,"Our test collection will promote the development and real-
istic evaluation of methods that seed studies can be used to improve
systematic review literature search. This includes methods we al-
ready explored in this paper like screening prioritisation [20, 34] and
query formulation [30], and some we leave for future works such as
active learning [8] or MeSH term suggestion [33], etc. Such methods
can have considerable real-world impacts, as systematic reviews
are highly time consuming and costly. ",cs.IR,A,-0.08009928,0.17366119,0.17789756
http://arxiv.org/pdf/2204.03208v1,A Joint Learning Approach for Semi-supervised Neural Topic Modeling,"preprint arXiv:1907.05545. In future work, we hope to further experiment      Caitlin Doogan and Wray Buntine. 2021. ",cs.IR,C,-0.37171465,-0.15209305,0.09940876
http://arxiv.org/pdf/2204.03505v1,Integrating Rankings into Quantized Scores in Peer Review,"By providing Area Chairs the information aggregated across all

                                                                     13
the reviewers who reviewed their assigned papers, we need to ensure that it should not inadvertently reveal the review
information of paper(s) outside their scope. Another direction of future work is that of global versus subgroup accuracy. For example, some subgroups of papers might have a larger inter-reviewer disagreement, or fewer reviewer-provided
comparisons than other papers, because of their Ô¨Åelds. ",cs.IR,C,-0.04752817,0.0070198667,0.26286247
http://arxiv.org/pdf/2204.03706v1,Introducing a Framework and a Decision Protocol to Calibrate Recommender Systems,"In addition, we showed the possibilities of implementing the calibrated system
following the framework division in components to provide an easier way to be implemented and
tested. As a future work, we plan to investigate other calibration measures and compare the effect of
the post-processing in the collaborative filtering and content-based filtering. Another extension
is to explore different types of distribution, for instance, compare the normalized against the
non-normalized ones. ",cs.IR,B,0.24703367,-0.2505446,0.07743945
http://arxiv.org/pdf/2204.03827v1,IA-GCN: Interactive Graph Convolutional Network for Recommendation,"This implies         teractive graph convolution for recommendation and opens up a
        that reasonable layer weights could help distill information        new research line. In future work, we will follow the direction of
        from high-order neighbors more effectively. the attention mechanism and exploit various attention mechanisms
                                                                            e.g. ",cs.IR,B,0.29545468,0.14183652,-0.086884126
http://arxiv.org/pdf/2204.03972v1,FashionCLIP: Connecting Language and Images for Product Representations,"This poses an interesting ques-
   $900m valuation and acquires exponea. tion, left for future work, of how to Ô¨Åne-tune these
                                                         large pre-trained models without losing in general-
Manos Tsagkias, Tracy Holloway King, Surya               ization. The pipeline has been implemented with
   Kallumadi, Vanessa Murdock, and Maarten de Ri-        MetaÔ¨Çow (Berg et al., 2019), with training executed
   jke. ",cs.IR,C,-0.25585392,-0.27304354,-0.20471308
http://arxiv.org/pdf/2204.03972v2,FashionCLIP: Connecting Language and Images for Product Representations,"This poses an interesting ques-
   $900m valuation and acquires exponea. tion, left for future work, of how to Ô¨Åne-tune these
                                                         large pre-trained models without losing in general-
Manos Tsagkias, Tracy Holloway King, Surya               ization. The pipeline has been implemented with
   Kallumadi, Vanessa Murdock, and Maarten de Ri-        MetaÔ¨Çow (Berg et al., 2019), with training executed
   jke. ",cs.IR,C,-0.25585392,-0.27304354,-0.20471308
http://arxiv.org/pdf/2204.04303v1,CERES: Pretraining of Graph-Conditioned Transformer for Semi-Structured Session Data,"Their effectiveness and efÔ¨Åciency    sions can include product images and customer
in parallelism have made them popular and general-     reviews for more informative multimodal graphs. purpose language encoders for many text-rich appli-    We leave this extension for future work. cations. ",cs.IR,A,-0.08792412,0.16280171,-0.029156769
http://arxiv.org/pdf/2204.04397v1,Denoising Neural Network for News Recommendation with Positive and Negative Implicit Feedback,"formance of DRPN. The further study results also             IEEE Access, 7:145861‚Äì145879. show the effectiveness of the denoising module. ",cs.IR,C,-0.2316269,-0.31635323,-0.07435216
http://arxiv.org/pdf/2204.04724v1,ProFairRec: Provider Fairness-aware News Recommendation,"Experiments on
                                                                        a public dataset demonstrate that ProFairRec can effectively improve
4.5 Influence of Hyper-Parameters                                       the fairness of mainstream news recommendation methods with
                                                                        minor performance declines. In our future work, we plan to apply
In this section, we will explore how the adversarial learning in        ProFairRec to improve provider fairness in more recommendation
ProFairRec affects the recommendation performance and provider          scenarios (e.g. item recommendation). ",cs.IR,B,0.34632516,-0.1085037,-0.0007431172
http://arxiv.org/pdf/2204.05039v1,Answering Count Queries with Explanatory Evidence,"Experiments                                fail on semantically refined requests (e.g., ‚Äúfor the Beatles‚Äù), merely
                                        with a wide variety of queries show the benefits of our method. To                           returning either a number without explanatory evidence or multiple
                                        promote further research on this underexplored topic, we release                             candidate answers with high variance. an annotated dataset of 5k queries with 200k relevant text spans. ",cs.IR,A,-0.010484253,0.35792127,0.1220233
http://arxiv.org/pdf/2204.05039v2,Answering Count Queries with Explanatory Evidence,"SpanBERT: Improving pre-training by representing and pre-
through CNPs when there exist similar competing answers attrib-
uted to specific qualifiers. To foster further research, we release all          dicting spans. In TACL. ",cs.IR,A,-0.18929467,0.20828748,-0.14890319
http://arxiv.org/pdf/2204.05101v1,Concept Drift Adaptation for CTR Prediction in Online Advertising Systems,"‚Ä¢ IADM: which stack ‚Äúexperts‚Äù in the depth direction, and the output         Qualitative Results. To further study how the models handle
of experts are also aggregated by a gate network. Note that in IADM,      the concept drift in streaming data, we plot the AUC/10Min in Fig. ",cs.IR,C,-0.08236466,-0.15198064,0.0021909191
http://arxiv.org/pdf/2204.06518v1,A pipeline and comparative study of 12 machine learning models for text classification,"Future
directions include the evaluation of other machine learning algorithms that apply
supervised learning along with investing time into optimising the hyperparameters of
these algorithms. The issues discussed above, related to the possibility of bias with
public datasets, should also be addressed in future works. Acknowledgements

AO would like to thank the support from the Earlier.org Breast Cancer Award. ",cs.IR,C,-0.030365122,-0.1323164,0.02927364
http://arxiv.org/pdf/2204.06519v1,CARCA: Context and Attribute-Aware Next-Item Recommendation via Cross-Attention,"Deep residual
                                                                                                 learning for image recognition. In Proceedings of the IEEE conference on computer
   In future works, we plan to extend CARCA for next-basket rec-                                 vision and pattern recognition. 770‚Äì778. ",cs.IR,C,-0.08729974,-0.07984593,-0.33365458
http://arxiv.org/pdf/2204.06520v1,Negative Sampling for Recommendation,"Geo-ALM: POI Recommenda-
the ranking position of a negative instance can be further utilized to
improve negative sampling quality. With the help of posteriori esti-                        tion by Fusing Geographical Information and Adversarial Learning Mechanism..
mation of unbiasedness, future work can go further to investigate                           In IJCAI. 1807‚Äì1813. ",cs.IR,B,0.19013402,-0.035623502,-0.03951285
http://arxiv.org/pdf/2204.06520v2,Bayesian Negative Sampling for Recommendation,"More discussions can be found in Sec D.4.3. D.4.2 Sensitivity analysis

We further study the sensitivity of BNS to Œª, sample information xÀÜl, and prior information Pfn(l). - BNS-1: warm-start of Œª. ",cs.IR,C,-0.28570625,-0.25612348,0.03083901
http://arxiv.org/pdf/2204.06520v3,Bayesian Negative Sampling for Recommendation,"signal bias, leads to performance degradation. Therefore, the
                                                                     larger size of Mu is the better if the prior probability Pfn(¬∑)
   2) Sensitivity analysis: We further study the sensitivity of      is reliable, otherwise an Mu of moderate size should be
BNS to Œª, sample information xÀÜl, and prior information Pfn(l). chosen. ",cs.IR,C,-0.22417912,-0.3200208,-0.0010323562
http://arxiv.org/pdf/2204.06522v1,Graph Enhanced BERT for Query Understanding,"Section 4 discusses the performance of the          3 THE PROPOSED FRAMEWORK
proposed model with the experimental results. Conclusion of this
work with future work is given in Section 5. In this section, we present the details of the proposed framework. ",cs.IR,C,-0.19566303,-0.2647516,0.024582796
http://arxiv.org/pdf/2204.07023v1,Composite Code Sparse Autoencoders for first stage retrieval,"Also, we note a strange interaction between
HNSW and the quantization methods, where NDCG@10 is actually better
for the smaller budget scenario. Further study on these interactions is left as
future work, but could allow for a better understanding of this performant
index combination7. Table 3 RQ2 on MSMARCO. ",cs.IR,C,-0.26845062,-0.2348756,-0.1797842
http://arxiv.org/pdf/2204.07221v1,Causal Disentanglement with Network Information for Debiased Recommendations,"D2Rec considers a unified representation for the confounders. A meaningful direction for future work is extending

D2Rec to include more fine-grained confounders, such as user conformity and item popularity factors. Another

possible direction would be to explore how D2Rec would perform with distrust networks. ",cs.IR,B,0.12289559,-0.023175003,0.26280245
http://arxiv.org/pdf/2204.07233v1,How Different are Pre-trained Transformers for Text Ranking?,"By masking the query words in the document we demonstrate
the ability of CE to score queries and documents without any lexical overlap
with a moderate loss of performance, therefore demonstrating the true strength
of neural models over traditional methods, that would completely fail in this
scenario, in isolation. We leave it to further research to qualitatively investigate the query-document
pairs that BERT fails, but BM25 ranks correctly. Acknowledgments This research is funded in part by the Netherlands Organiza-
tion for ScientiÔ¨Åc Research (NWO CI # CISC.CC.016), and the Innovation Exchange
Amsterdam (POC grant). ",cs.IR,A,-0.14426628,0.43163162,-0.14776415
http://arxiv.org/pdf/2204.07304v1,On Variants of Root Normalised Order-aware Divergence and a Divergence based on Kendall's Tau,"[18] have used JSD, NMD, and RNOD as a component of their group-fair ranking
evaluation measures. Our future work includes examining the relationship between ordinal quan-
tiÔ¨Åcation task evaluation and the evaluation of other tasks such as group-fair ranking that involve
these divergence measures. REFERENCES

 [1] T. Chai and R.R. ",cs.IR,C,-0.004747051,-0.14263456,0.012848858
http://arxiv.org/pdf/2204.07433v1,Interacting with Non-Cooperative User: A New Paradigm for Proactive Dialogue Policy,"1951‚Äì1961. dialogue policy learning, and can serve as a preliminary baseline to
benefit further research. Naturally, there are thus a few loose ends                 [10] Veton K√´puska and Gamal Bohouta. ",cs.IR,C,-0.13964558,0.109254226,0.17768233
http://arxiv.org/pdf/2204.08085v1,CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems,"On the producer side,
                                                                                                                      fairness may be quantified in terms of two distinct types of benefit
compute       a  new  fair  ordered  list,                 ùêπ  (ùë¢)  from  the       original  unfair   base-           functions: exposure and relevance, both of which can be binary or
                                                                                                                      graded [19]. Given that suppliers‚Äô primary objective is their prod-
                                                         ùêø                                                            ucts‚Äô visibility, this study focuses its attention exclusively on the
                                                                                                                      (binary) exposure dimension, leaving the other producer fairness
                                                         ùêæ                                                            constraints for future work. To measure the exposure parity, we
                                                                                                                      divide items into two categories of short-head I1 and long-tail I2
line  recommended     items  ùêøùëÅ      (ùë¢  )               where       ùêπ  (ùë¢)     ‚äÇ  ùêøùëÅ (ùë¢)    ùë§ ‚Ñéùëíùëü ùëí  ùêæ  ‚â§            defined based on their popularity score where I1 ‚à© I2 = ‚àÖ. ",cs.IR,C,-0.007752888,-0.28835574,0.26146173
http://arxiv.org/pdf/2204.08176v1,HRCF: Enhancing Collaborative Filtering via Hyperbolic Geometric Regularization,"In                                                the collaborative filtering, and theoretically, they can be applied to
particular, it is proficient at matching such data to a hierarchical                                          other hyperbolic models. In future work, we will extend our idea to
structure or pow-law distribution. To improve the utilization of                                              more recommendation scenes or non-recommendation scenarios,
hyperbolic space and enhance the performance of a hyperbolic-                                                 like the hyperbolic temporal link prediction [46]. ",cs.IR,B,0.2857283,-0.09619592,-0.026269343
http://arxiv.org/pdf/2204.08176v2,HRCF: Enhancing Collaborative Filtering via Hyperbolic Geometric Regularization,"In                                                the collaborative filtering, and theoretically, they can be applied to
particular, it is proficient at matching such data to a hierarchical                                          other hyperbolic models. In future work, we will extend our idea to
structure or pow-law distribution. To improve the utilization of                                              more recommendation scenes or non-recommendation scenarios,
hyperbolic space and enhance the performance of a hyperbolic-                                                 like the hyperbolic temporal link prediction [46]. ",cs.IR,B,0.2857283,-0.09619592,-0.026269343
http://arxiv.org/pdf/2204.08235v1,Table Enrichment System for Machine Learning,"We show the use case                                  SIGMOD ‚Äô21: International Conference on Management of Data, Virtual Event, China,
of our system with a demo on a web UI. As future work, we plan                                     June 20-25, 2021, Guoliang Li, Zhanhuai Li, Stratos Idreos, and Divesh Srivastava
to extend our system with existing data clean techniques to create                                 (Eds.). ACM, 1531‚Äì1544. ",cs.IR,A,-0.13755895,0.06226814,0.21934259
http://arxiv.org/pdf/2204.08569v1,Learning Similarity Preserving Binary Codes for Recommender Systems,"It has an average 15.21% NDCG relative improvement       suffer from performance drop. We present a further analysis in
compared to the best MF-based models. On Amazon dataset, CCSR-        Section 5.6. ",cs.IR,C,-0.15991125,-0.309942,-0.16942173
http://arxiv.org/pdf/2204.09272v1,Is Non-IID Data a Threat in Federated Online Learning to Rank?,"In           Calling for FOLTR methods to address non-IID issues. Our
our empirical experiments, we have studied Type 4 data both on its      paper charts directions to direct future work on non-IID data in
own and combined with the document label distribution skew with         FOLTR concerning the creation of techniques that provide remedies
#ùëÖ = 1 (Type 1) and the document preferences skew (Type 2). to Type 1 and 2, while deeming solutions for Type 3 and 4 data less
                                                                        critical. ",cs.IR,C,-0.2145386,0.011890594,0.13647512
http://arxiv.org/pdf/2204.09272v2,Is Non-IID Data a Threat in Federated Online Learning to Rank?,"Calling for FOLTR methods to address non-IID issues. Our                                Despite federated learning receiving substantial attention, re-
paper charts directions to direct future work on non-IID data in                        search in FOLTR is still in its early stages, with only two methods
FOLTR concerning the creation of techniques that provide remedies                       available at the time of writing [21, 43]. Importantly, studies that
to Type 1 and 2, while deeming solutions for Type 3 and 4 data less                     have proposed FOLTR methods have ignored an important issue
critical. ",cs.IR,A,-0.19911522,0.10083637,0.0077633047
http://arxiv.org/pdf/2204.09422v1,Multi-Auxiliary Augmented Collaborative Variational Auto-encoder for Tag Recommendation,"Discov. Data Mining, pages
In future work, we would like to extend MA-CVAE to disentan-             448‚Äì456, 2011.
gled settings, where personality and matching are considered
as two aspects of tag recommendations. SpeciÔ¨Åcally, personal-      [13] Hao Wang, Binyi Chen, and Wu-Jun Li. ",cs.IR,B,0.18703082,-0.009060368,0.08713149
http://arxiv.org/pdf/2204.09969v1,Using consumer feedback from location-based services in PoI recommender systems for people with autism,"This opens
a research avenue towards the exploitation of information diÔ¨Äusion models
in recommender systems, similar to what has been done in (Xiong et al.,
2020b,a) for Matrix Factorization. Our future work also includes a cooperation with psychologists to develop
novel recommendation algorithms that are robust with respect to individual
biases in the evaluation of sensory features. In fact, as the perception of
places is subjective, the feature values extracted from consumer feedback, or
explicitly crowdsourced, might be biased. ",cs.IR,B,0.48012096,-0.039118987,0.093637094
http://arxiv.org/pdf/2204.10097v1,Content negotiation on the Web: State of the art,"Thus, the client may want a way to express this
importance for each constraint and get the representation that accounts for it. For future work, we will focus on creating an online resource (a website)
that collects and categorises CN features following the structure proposed in
this study: styles, dimensions, etc. This resource will also aim to collect CN
use cases, highlight existing solutions if available, or suggest plausible ways to
advance them. ",cs.IR,A,-0.013891257,0.17463554,0.12391211
http://arxiv.org/pdf/2204.10230v1,Cross-Lingual Query-Based Summarization of Crisis-Related Social Media: An Abstractive Approach Using Transformers,"Finally, users
can provide prototypes ‚Äì example messages or central passages typical in category-related texts, which can be obtained
by sampling diverse, informative messages from past events. We envision a specialized user interface may assist users
in formulating such queries, and we plan to explore that in future work. The scope of this paper is to demonstrate the
approach and provide an initial set of easily extended and reÔ¨Åned queries. ",cs.IR,A,-0.035167605,0.4425525,0.15718713
http://arxiv.org/pdf/2204.10254v1,From Who You Know to What You Read: Augmenting Scientific Recommendations with Implicit Social Networks,"And I‚Äôll almost always go look at it, to figure
                                                                         out how my work is being discussed and how my work influenced
                                                                         their work. And maybe think about future work.‚Äù (P14). B4. ",cs.IR,C,-0.08272159,0.036960095,0.3168123
http://arxiv.org/pdf/2204.10362v1,Human Preferences as Dueling Bandits,"section on the Combined Set. As future work, we hope to discover
and validate more a principled method for the finalization phase. Questions for the TREC 2021 Deep Learning Track were taken
                                                                        from questions held out from MS MARCO data releases [11], so that
5.4 Best item evaluation                                                MS MARCO sparse labels are available for these questions. ",cs.IR,C,-0.07327542,-0.019077083,-0.296821
http://arxiv.org/pdf/2204.10463v1,"Mostra: A Flexible Balancing Framework to Trade-off User, Artist and Platform Objectives for Music Sequencing","Modern day recommender systems have                                  recommends the most similar items across all categories, which, as
evolved from using matrix and tensor factorisation approaches [6,                            noted above, is a limitation in our use case. Extending [18] and [7]
20, 22], to leveraging the modelling capabilities of deep neural net-                        is an interesting direction for future work. works [41]. ",cs.IR,B,0.39169866,0.101961374,-0.21792062
http://arxiv.org/pdf/2204.10558v1,Sparse and Dense Approaches for the Full-rank Retrieval of Responses for Dialogues,"The re-
sults indicates that possibly confusing negative samples with exact
matches with the dialogue context were not detrimental. For the
fourth experiment (E4) we expected that when using only the
Sparse and Dense Approaches for the Full-rank Retrieval of Responses for Dialogues        Conference‚Äô17, July 2017, Washington, DC, USA

   As future work we believe important directions include: taking                               topic aware sampling. In Proceedings of the 44th International ACM SIGIR Confer-
advantage of language-model based term re-weighting for sparse                                  ence on Research and Development in Information Retrieval. ",cs.IR,A,-0.008867642,0.3900234,-0.06052044
http://arxiv.org/pdf/2204.10613v1,Zero-shot Query Contextualization for Conversational Search,"Initiative-Aware Self-Supervised Learning for Knowledge-
and salient terms. For future work we aim to explore zero-shot                                 Grounded Conversations. In Proceedings of the 44th International ACM SIGIR
re-ranking and extend this work to few-shot training. ",cs.IR,A,0.030687723,0.17598394,-0.13340442
http://arxiv.org/pdf/2204.10641v1,Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction,"that COSTA can produce discriminative representations for dense
                                                                         retrieval. In future work, we would like to apply COSTA to other IR
   As shown in Table 4, we can see that: (1) COSTA performs sig-         scenarios like open-domain question answering and conversational
nificantly better than SEED on these two datasets in terms of all        systems. metrics, indicating that COSTA is able to learn more discriminative
                                                                         ACKNOWLEDGMENTS

                                                                         This work was funded by the National Natural Science Founda-
                                                                         tion of China (NSFC) under Grants No. ",cs.IR,A,-0.033444304,0.28608546,-0.24541906
http://arxiv.org/pdf/2204.10796v1,DACSR: Dual-Aggregation End-to-End Calibrated Sequential Recommendation,"For the future work, we aim to investigate the evaluation
protocol of calibrated recommendation. In addition, how to fuse item attribute
information is also a direction of our future work. References

 [1] Huang, J., Zhao, W.X., Dou, H., Wen, J.-R., Chang, E.Y. ",cs.IR,B,0.45186055,-0.19847208,0.06154497
http://arxiv.org/pdf/2204.10796v10,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"Finally, we found that calibration is not always equivalent to
diversity, and conducted experiments of balancing calibration and diversity. For the future work, we Ô¨Årst want to explore the cleaner sequence
encoder with fewer parameters. SpeciÔ¨Åcally, we focus on the advanced train-
ing paradigm for calibrated sequential recommendation. ",cs.IR,B,0.20736237,-0.21638563,-0.25193182
http://arxiv.org/pdf/2204.10796v11,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"Finally, we investigated the connection
between calibration and diversity, and balanced them by normalizing the
historical preference distribution. For the future work, we Ô¨Årst want to explore the cleaner sequence
encoder with fewer parameters. SpeciÔ¨Åcally, we focus on the advanced training
paradigm rather than the traditional sequence-to-item paradigm to improve
the calibrated sequential recommendation. ",cs.IR,B,0.27152818,-0.10621363,-0.21012837
http://arxiv.org/pdf/2204.10796v12,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"Finally, we investigated the connection
between calibration and diversity, and balanced them by normalizing the
historical preference distribution. Springer Nature 2021 LATEX template

DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation 25

    For the future work, as mentioned in the discussion part, we Ô¨Årst want
to explore the cleaner sequence encoder with fewer parameters. SpeciÔ¨Åcally,
we may focus on the advanced training paradigm rather than the traditional
sequence-to-item paradigm to improve the calibrated sequential recommenda-
tion. ",cs.IR,B,0.29010916,-0.13619834,-0.24668345
http://arxiv.org/pdf/2204.10796v13,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"Finally, we inves-
tigated the connection between calibration and diversity, and balanced them
by normalizing the historical preference distribution. Springer Nature 2021 LATEX template

DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation 25

    For the future work, as mentioned in the discussion part, we Ô¨Årst want
to explore the cleaner sequence encoder with fewer parameters. SpeciÔ¨Åcally,
we may focus on the advanced training paradigm rather than the traditional
sequence-to-item paradigm to improve the calibrated sequential recommenda-
tion. ",cs.IR,B,0.2846497,-0.12507865,-0.27305582
http://arxiv.org/pdf/2204.10796v2,DACSR: Dual-Aggregation End-to-End Calibrated Sequential Recommendation,"In addition, the
time consumption of our model in prediction is much less than post-processing
models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions for this protocol. ",cs.IR,B,0.44292414,-0.35291964,-0.15863493
http://arxiv.org/pdf/2204.10796v3,DACSR: Dual-Aggregation End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions for this protocol. ",cs.IR,B,0.44292414,-0.35291964,-0.15863493
http://arxiv.org/pdf/2204.10796v4,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions and advanced model
                          Springer Nature 2021 LATEX template

22 DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation

structures to improve the performance of calibration and accuracy. ",cs.IR,B,0.35209885,-0.3229257,-0.28083086
http://arxiv.org/pdf/2204.10796v5,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions and advanced model
structures to improve the performance of calibration and accuracy. ",cs.IR,B,0.4263993,-0.37495607,-0.19549546
http://arxiv.org/pdf/2204.10796v6,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions and advanced model
structures to improve the performance of calibration and accuracy. ",cs.IR,B,0.4263993,-0.37495607,-0.19549546
http://arxiv.org/pdf/2204.10796v7,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions and advanced model
structures to improve the performance of calibration and accuracy. ",cs.IR,B,0.4263993,-0.37495607,-0.19549546
http://arxiv.org/pdf/2204.10796v8,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions and advanced model
structures to improve the performance of calibration and accuracy. ",cs.IR,B,0.4263993,-0.37495607,-0.19549546
http://arxiv.org/pdf/2204.10796v9,DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential Recommendation,"In
addition, the time consumption of our model in prediction is much less than
post-processing models. For the future work, we Ô¨Årst aim to investigate the evaluation protocol
of calibrated recommendation, which considers performances at each ranking
position. We are interested in designing loss functions and advanced model
structures to improve the performance of calibration and accuracy. ",cs.IR,B,0.4263993,-0.37495607,-0.19549546
http://arxiv.org/pdf/2204.10936v1,Counterfactual Learning To Rank for Utility-Maximizing Query Autocompletion,"model. Questions for future work include how we can go beyond
                                                                                           [22] R. Herbrich, T. Graepel, and K. Obermayer. 1999. ",cs.IR,C,-0.28960466,-0.116702616,0.002304106
http://arxiv.org/pdf/2204.11067v1,CORE: Simple and Effective Session-based Recommendation within Consistent Representation Space,"effectiveness of the proposed model CORE, we visualize the learned
session embeddings using t-SNE [22] algorithm in Figure 4. Detailed,             For future work, we will consider studying the expressive ability
sessions with the same next item are viewed as in the same class, and         of the proposed representation-consistent encoder both theoreti-
are marked the same color. We randomly sample 15 items as ground              cally and empirically. ",cs.IR,A,-0.07940133,0.091556445,-0.20353957
http://arxiv.org/pdf/2204.11154v1,Dual Skipping Guidance for Document Retrieval with Learned Sparse Representations,"A Few Brief Notes on DeepImpact, COIL,
here. Our future work is to assess the effectiveness of dual guidance                                                                   and a Conceptual Framework for Information Retrieval Techniques. ArXiv
in other retrieval algorithms which use threshold-based skipping. ",cs.IR,A,-0.03621919,0.29055884,-0.19261438
http://arxiv.org/pdf/2204.11241v1,"Post Processing Recommender Systems with Knowledge Graphs for Recency, Popularity, and Diversity of Explanations","The gain in EQ, when we         arise and call for a novel class of debiasing that takes into account both user-level
                                                                       explanation and recommendation utility. We left this line of research as a future work. Œîùê∂ (ùê∫1, ùê∫2, ùê∂) =  1  ‚àëÔ∏Å            1  ‚àëÔ∏Å                           (7)   be also used to control the fair exposure of the entities pertaining
                          ùê∂ (ùë¢) ‚àí          ùê∂ (ùë¢)                         to humans (in our case entities like producer, actor, category) in the
                  |ùê∫1 | ùë¢ ‚ààùê∫1      |ùê∫2 | ùë¢ ‚ààùê∫2                           explanations. ",cs.IR,B,0.12971333,0.06320208,0.22078767
http://arxiv.org/pdf/2204.11243v1,Regulating Group Exposure for Item Providers in Recommendation,"Another popular solution that

provider of has the attribute , we consider that F ( ) = . The         we leave for future work is the L1 distance, which however is less

set of items whose providers have attribute ‚àà is denoted by            intuitive and more likely to give high distance values. For these
reasons, as a support metric in our study, we use the Hellinger dis-    2( ,        |I         12‚àà   ( )‚àí                       22
tance, which is both symmetric and bounded in the range [0,1]. ",cs.IR,C,-0.1500945,-0.16341658,0.09722084
http://arxiv.org/pdf/2204.11314v1,Faster Learned Sparse Retrieval with Guided Traversal,"ColBERT: Efficient and effective passage search via
sparse ranking models. In future work, we plan to explore whether                           contextualized late interaction over BERT. In Proc. ",cs.IR,A,0.10486699,0.2756232,-0.18132064
http://arxiv.org/pdf/2204.11346v1,Less is More: Reweighting Important Spectral Graph Features for Recommendation,"We believe that the insights of our
not enough to capture the complex user-item interactions, recent                                                                   work are inspirational to future developments of GCN architecture
works resort to other advanced algorithms, such as neural networks                                                                 designs for recommender systems. In future work, we plan to ana-
[15], memory networks [9], word embeddings [22], etc and pro-                                                                      lyze the potential of GCNs from other perspectives and apply our
pose more fine-grained architectures. Some works [11, 36] explore                                                                  proposed models to other recommendation tasks. ",cs.IR,B,0.3924384,0.21963893,-0.1801419
http://arxiv.org/pdf/2204.11428v1,Personal Research Knowledge Graphs,"Appendix A.2 details the implementation of a PRKG. the identification of more fine-grained entities like performance
                                                                         scores, keyphrases, keystone citations, and future work, without
4 POPULATING A PRKG                                                      burdening the researcher with too many probing questions to be
                                                                         answered manually. The entities and the relations in the PRKG may be either curated
manually by the researcher or extracted automatically using NLP             Finally, symbolic and neural algorithms may be used to gen-
techniques from structured or unstructured sources through a soft-       erate more relations among the existing entities and derive new
ware agent. ",cs.IR,A,-0.163407,0.24494861,0.047011107
http://arxiv.org/pdf/2204.11447v1,Evaluating Extrapolation Performance of Dense Retrieval,"Note that recently there is another research
direction to improve the efficiency of DR via jointly optimizing                        ‚úì    0.615 0.582 -5%
encoders and index [51, 53]. We leave investigating these methods
to future work. ‚úì ‚úì 0.641 0.644 0%

6.2.2 Implementation. ",cs.IR,C,-0.21611822,-0.22414851,-0.24623609
http://arxiv.org/pdf/2204.11489v1,Groupwise Query Performance Prediction with BERT,"Evaluation on three stan-
dard TREC test collections indicates the groupwise model signiÔ¨Åcantly outper-
forms the BERT baselines nearly in all cases. In further research, we plan to
work on the eÔ¨Éciency, as well as adoption of our approach to more advanced
experimentation framework [21]. Groupwise Query Performance Prediction with BERT  7

References

 1. ",cs.IR,A,-0.14710227,0.13396853,-0.19425888
http://arxiv.org/pdf/2204.11588v1,Ad Creative Discontinuation Prediction with Multi-Modal Multi-Task Neural Survival Networks,"Section 6 describes case studies that simulate online
experiments using as-yet-unobserved (i.e., online) data. Section 7 describes the limitations and
future works of this study. Finally, Section 8 concludes this study. ",cs.IR,C,-0.11975868,-0.07564639,0.3433053
http://arxiv.org/pdf/2204.11673v1,Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking,"meta-graphs for a large scale of candidates. A further study could
                                                                       focus on how to use external knowledge in PLM based retriever. Table 6: Ranking performance comparison on different domains. ",cs.IR,A,0.008784175,0.087048255,0.05281388
http://arxiv.org/pdf/2204.11677v1,Conversational Question Answering on Heterogeneous Sources,"1966. Binary codes capable of correcting deletions,
of the most promising avenues for future work involves developing                                                     insertions, and reversals. In Soviet physics doklady. ",cs.IR,C,-0.29637715,-0.04787898,0.0696512
http://arxiv.org/pdf/2204.12200v1,Hypergraph Contrastive Collaborative Filtering,"The weight-decay regular-
                                                                                                                      ization term is applied over parameters Œò. 3.4 Hypergraph-enhanced Contrastive
      Learning                                                                                                        3.5 In-Depth Analysis of HCCF

This section describes how we enable our HCCF with the cross-view                                                     This section provides further analysis of our HCCF model with the
collaborative supervision under a hypergraph neural architecture,                                                     theoretical discussion and time complexity analysis. to augment the user representation with sparse supervision signals. ",cs.IR,C,-0.01941783,0.0009467555,-0.27965862
http://arxiv.org/pdf/2204.12200v2,Hypergraph Contrastive Collaborative Filtering,"The weight-decay regular-
                                                                                                            ization term is applied over parameters Œò. 3.4 Hypergraph-enhanced Contrastive
      Learning                                                                                              3.5 In-Depth Analysis of HCCF

This section describes how we enable our HCCF with the cross-view                                           This section provides further analysis of our HCCF model with the
collaborative supervision under a hypergraph neural architecture,                                           theoretical discussion and time complexity analysis. to augment the user representation with sparse supervision signals. ",cs.IR,C,-0.019417904,0.00094688823,-0.27965847
http://arxiv.org/pdf/2204.12326v1,Investigating Accuracy-Novelty Performance for Graph-based Collaborative Filtering,"Thus, the vector form of             Yelp2018
ùëü -ùê¥ùëë ùëóùëÅùëúùëüùëö plugin for LR-GCCF is:

E(ùëô) = 1 E(ùëô‚àí1) + ‚àëÔ∏Å                1         E(ùëô‚àí1) ,                  prone to suffer over-smoothing and popularity bias than shallow
                                                                        GNN. In the paper, we focus on studying the influence of NA layer
ùë¢ |Nùë¢ | ùë¢                           |Nùë¢ |ùëü |Nùëñ |1‚àíùëü ùëñ     (12)          and leave the exploration of the mechanism for LC as future work. ùëñ ‚ààNùë¢

E(ùëô) = 1 E(ùëô‚àí1) + ‚àëÔ∏Å                1         E(ùëô‚àí1) . ",cs.IR,C,-0.19461179,-0.25423312,-0.21792147
http://arxiv.org/pdf/2204.12326v2,Investigating Accuracy-Novelty Performance for Graph-based Collaborative Filtering,"Thus, the vector form of             Yelp2018
ùëü -ùê¥ùëë ùëóùëÅùëúùëüùëö plugin for LR-GCCF is:

E(ùëô) = 1 E(ùëô‚àí1) + ‚àëÔ∏Å                1         E(ùëô‚àí1) ,                  prone to suffer over-smoothing and popularity bias than shallow
                                                                        GNN. In the paper, we focus on studying the influence of NA layer
ùë¢ |Nùë¢ | ùë¢                           |Nùë¢ |ùëü |Nùëñ |1‚àíùëü ùëñ     (12)          and leave the exploration of the mechanism for LC as future work. ùëñ ‚ààNùë¢

E(ùëô) = 1 E(ùëô‚àí1) + ‚àëÔ∏Å                1         E(ùëô‚àí1) . ",cs.IR,C,-0.19461179,-0.25423312,-0.21792147
http://arxiv.org/pdf/2204.12682v1,A Practical Two-stage Ranking Framework for Cross-market Recommendation,"Here we use the
use the training set to train with sampling 99 negative items for each    training set to build the corresponding features and give predictions
positive interaction, public test set to validate model performance       on the public/private test set. Similarly, we keep the corresponding
and test candidate samples to predict without using any data from         score for further research. It is worth noting that the training set
source markets, due to no distinct performance improvement by             used here includes all the data from source markets and target
trying cross-market information. ",cs.IR,C,-0.024121366,-0.11867292,0.0372105
http://arxiv.org/pdf/2204.12793v1,Modern Baselines for SPARQL Semantic Parsing,"SPARQL should lay more emphasis on pre-training, since currently
                                                                        it is more focused on producing custom model architectures for the
7 ERROR ANALYSIS                                                        tasks. We randomly sampled 100 cases of erroneous outputs for PGN,                As future work, we would like to explore the ability of these
T5-Small and BART, as shown in Table 2. The most important dif-         models in disambiguation tasks, where the input consists of entity
ference in the errors produced by T5/BART versus PGN is what we         and relation candidates, instead of linked entities and relations. ",cs.IR,A,-0.20026591,0.18470222,-0.16481933
http://arxiv.org/pdf/2204.12793v2,Modern Baselines for SPARQL Semantic Parsing,"SPARQL should lay more emphasis on pre-training, since currently
                                                                        it is more focused on producing custom model architectures for the
7 ERROR ANALYSIS                                                        tasks. We randomly sampled 100 cases of erroneous outputs for PGN,                As future work, we would like to explore the ability of these
T5-Small and BART, as shown in Table 2. The most important dif-         models in disambiguation tasks, where the input consists of entity
ference in the errors produced by T5/BART versus PGN is what we         and relation candidates, instead of linked entities and relations. ",cs.IR,A,-0.20026591,0.18470222,-0.16481933
http://arxiv.org/pdf/2204.13003v1,MovieMat: Context-aware Movie Recommendation with Matrix Factorization by Matrix Fitting,"VI. DISCUSSION                                In future work, we would like to explore further the
                                                                     potentiality of the MatMat framework applied in the scenario of
    By incorporating contextual information into movie               contextual recommendation, to answer the previous questions. recommeder systems, we observe improvement in both                   Moreover, we would like to explore the optimization techniques
accuracy and fairness metrics. ",cs.IR,B,0.30419004,0.0072800685,0.04576447
http://arxiv.org/pdf/2204.13016v1,RankMat : Matrix Factorization with Calibrated Distributed Embedding and Fairness Enhancement,"Alongside with another algorithm proposed in this paper called GloVeMat, we prove the superiority
of these techniques over the primitive matrix factorization formulation. In future work, we would like to explore other
probabilistic modeling techniques for the matrix factorization framework and the application of other optimization
solvers such as Adam and Adagrad. REFERENCES

<bib id=""bib1""><number>[1]</number>G. ",cs.IR,B,0.15483943,-0.11070301,-0.15338819
http://arxiv.org/pdf/2204.13594v1,Poisoning Deep Learning based Recommender Model in Federated Learning Scenarios,"Experi-
                                                                    mental results demonstrate that our attacks set the state-of-
                                                                    the-art, and prove that there is necessary improvement should
                                                                    be made in FR. As part of future work, we will further explore
                                                                    the methods to detect the attacks in FR. Acknowledgement

                                                                    This research is supported by the National Key R&D Program
                                                                    of China (2021YFB2700500, 2021YFB2700502). ",cs.IR,C,-0.24061333,-0.13806775,0.20727552
http://arxiv.org/pdf/2204.13594v2,Poisoning Deep Learning Based Recommender Model in Federated Learning Scenarios,"Experi-
                                                                    mental results demonstrate that our attacks set the state-of-
                                                                    the-art, and prove that there is necessary improvement should
                                                                    be made in FR. As part of future work, we will further explore
                                                                    the methods to detect the attacks in FR. Acknowledgments

                                                                    This research is supported by the National Key R&D Program
                                                                    of China (2021YFB2700500, 2021YFB2700502). ",cs.IR,C,-0.24060877,-0.13630608,0.21243793
http://arxiv.org/pdf/2204.13596v1,Generative Retrieval for Long Sequences,"We leave the                retrieval both time and GPU memory efÔ¨Åciency
                                                                   advantage; GRLS with optimization is about 100
exploration of a better memorization strategy for                  times faster and uses 79.5% less GPU memory than
                                                                   ST5 (FP32) with the same number of parameters. multi-step retrieval as a future work. During inference time, GRLS can be time-
5.2 Do GRLS and BE behave differently? ",cs.IR,C,-0.21771961,-0.027033577,-0.26989436
http://arxiv.org/pdf/2204.13596v3,Generative Multi-hop Retrieval,"While the method is difÔ¨Åcult to apply to         end while
datasets with low unseen rates due to the Ô¨Åltering
process of removal when a set of target sequence           return Y
contains a set in the original retrieval dataset as
a subset, it is also not necessary as most retrieval    B Experimental Setup
sequences in the target corpus are covered by the
training set. We leave the method of generating         B.1 Fixed and Dynamic Multi-hop Retrieval
effective pseudo-multi hop data for datasets with
low unseen rate as future work. We formulate two settings of multi-hop retrieval:
                                                        Ô¨Åxed and dynamic multi-hop retrieval settings. ",cs.IR,A,-0.087152556,0.21771336,-0.18988891
http://arxiv.org/pdf/2204.13844v1,User-controllable Recommendation Against Filter Bubbles,"In SAC. potential directions to future work. In particular, 1) it is non-trivial                      ACM, 2002‚Äì2007. ",cs.IR,C,-0.28610814,-0.08647731,0.10462801
http://arxiv.org/pdf/2204.14069v1,Gating-adapted Wavelet Multiresolution Analysis for Exposure Sequence Modeling in CTR prediction,"Sequence Length: According to
ison results are shown in Table 3. With further analysis, we can                                Figure 4, for Gama and the BaseModels, i.e., AP-e and Trans-e,
find that Gama beats Transformer in exposure sequence modeling                                  longer exposure sequence results in higher AUC. This is reasonable
through de-nosing and multi-dimension decomposition. ",cs.IR,C,-0.35642615,-0.2719326,-0.12109519
http://arxiv.org/pdf/2205.00126v1,SciEv: Finding Scientific Evidence Papers for Scientific News,"The language model starts to exhibit
advantages over TFIDF when the search results are more inclusive with a higher K (K‚â• 20 in our case). The results
indicate that an ensembled re-ranking model may achieve an higher performance, which we will pursue in future work. The ultimate goal is to build a public application that is capable of automatically assessing the credibility of scientiÔ¨Åc
news, based on pertinent scientiÔ¨Åc papers. ",cs.IR,A,-0.0062321704,0.19647159,-0.0022510183
http://arxiv.org/pdf/2205.00584v1,Supporting Complex Information-Seeking Tasks with Implicit Constraints,"Estimating the query difficulty for information
                                                                                               retrieval. Synthesis Lectures on Information Concepts, Retrieval, and Services, 2
   In future work, we plan to design an online experiment that will                            (1):1‚Äì89, 2010.
involve business metrics, such as user satisfaction, the ratio of return-
ing users, and interactively collect ratings for the list of suggestions                 [17] Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St
made by our system. This will allow us to learn from language and                              John, Noah Constant, Mario Guajardo-C√©spedes, Steve Yuan, Chris Tar, et al. ",cs.IR,A,0.13453396,0.28648937,0.15405576
http://arxiv.org/pdf/2205.00806v1,Biographical: A Semi-Supervised Relation Extraction Dataset,"Finally, a linear classifier is stacked on top of
                                                                         the output representation. The architecture diagram is visualised
Upon further examination, we found that the first mention of the         in Figure 3.
place where someone died often was also the place where a person
lived. In future, cases like these may warrant a different approach         We fine-tune all the parameters from the transformer as well
to processing by our algorithm, but for now we leave it unchanged. ",cs.IR,C,-0.13531646,-0.069738925,-0.053917356
http://arxiv.org/pdf/2205.00820v1,Entity-aware Transformers for Entity Search,"BERT learns to retrieve specific entities for queries requesting a
list. For example for the query ‚ÄúGive me the capitals of all countries     For further research, the effect of the entity linking method
in Africa‚Äù, while monoBERT‚Äôs highest ranked entities are general        can be investigated; here we used REL, which is an entity linker
overview pages like ‚ÄòList of African dependencies‚Äô, all of EM-BERT‚Äôs    with high precision. It would be also interesting to evaluate the
highest-ranked entities are capitals of African countries like ‚ÄòDakar‚Äô  performance of other dense and sparse retrieval methods on entity-
and ‚ÄòPorto-Novo‚Äô. ",cs.IR,A,-0.08327106,0.36091447,-0.10087134
http://arxiv.org/pdf/2205.00926v1,ORCAS-I: Queries Annotated with Intent using Weak Supervision,"datasets. While our experiment does not indicate how the machine learn-               Label       ORCAS-I-gold    ORCAS-I-2M       ORCAS-I-18M
ing models could strictly outperform the base, weak labelling, we          distribution  Manual Snorkel       Snorkel           Snorkel
see some potential directions for future work. One solution would
be to use more than one annotated click log dataset, ideally using       Navigational    17.10% 15.50%         14.48%           14.51%
different annotation types (i.e. ",cs.IR,A,-0.12991986,0.07271954,-0.06334481
http://arxiv.org/pdf/2205.00926v2,ORCAS-I: Queries Annotated with Intent using Weak Supervision,"While our experiment does not indicate how the machine learn-        Table 10: Label distribution for all three annotated ORCAS-I
ing models could strictly outperform the base, weak labelling, we       datasets. see some potential directions for future work. One solution would
be to use more than one annotated click log dataset, ideally using            Label       ORCAS-I-gold    ORCAS-I-2M       ORCAS-I-18M
different annotation types (i.e. ",cs.IR,A,-0.12846306,0.12893413,-0.070954606
http://arxiv.org/pdf/2205.00937v1,Studying Retrievability of Publications and Datasets in an Integrated Retrieval System,"Utilizing
                                                                                        the difficulty of the query in order to compute the usefulness has
JCDL ‚Äô22, June 20‚Äì24, 2022, Cologne, Germany                                                                                                                     D. Roy et al. been left as part of future work; the difficulty of the query is kept      Acknowledgement. This work was funded by DFG under grant
as constant (‚Ñé(ùëû) in Equation 5 set to 1) in this study. ",cs.IR,C,-0.24675573,-0.041272074,0.0494356
http://arxiv.org/pdf/2205.01286v1,When Multi-Level Meets Multi-Interest: A Multi-Grained Neural Model for Sequential Recommendation,"When we remove the multi-level item representation learning
parameter settings to the performance of MGNM. supported by user-aware graph convolution (i.e., w/o UGCN), sub-
                                                                      stantial performance degradation is also experienced by MGNM,
4We leave it as a part of our future work. which illustrates the effectiveness of user-aware graph convolution
                                                                      and multi-level preference learning significantly. ",cs.IR,B,0.11814807,-0.027514867,-0.23473695
http://arxiv.org/pdf/2205.01289v1,On Ranking Consistency of Pre-ranking Stage,"distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time. For the   gression [16], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is  which is open for further research. to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels. ",cs.IR,C,0.036478586,-0.3566977,-0.22796193
http://arxiv.org/pdf/2205.01289v2,On Ranking Consistency of Pre-ranking Stage,"tency between the pre-ranking and ranking stage. Note that other
                                                                       distillation objective or post calibration methods, such as isotonic re-
   To mitigate the inconsistency caused by SSB, we propose to          gression [15], can also be explored to improve the proxy-calibration,
utilize samples in the pre-ranking set to train the pre-ranking        which is open for further research. models. ",cs.IR,C,-0.019161291,-0.3410276,-0.1642833
http://arxiv.org/pdf/2205.01289v3,On Ranking Consistency of Pre-ranking Stage,"distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time. For the    gression [17], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is   which is open for further research. to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels. ",cs.IR,C,0.041613188,-0.35709077,-0.22643909
http://arxiv.org/pdf/2205.01289v4,On Ranking Consistency of Pre-ranking Stage,"distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time. For the    gression [17], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is   which is open for further research. to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels. ",cs.IR,C,0.041613188,-0.35709077,-0.22643909
http://arxiv.org/pdf/2205.01289v5,On Ranking Consistency of Pre-ranking Stage,"distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time. For the    gression [17], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is   which is open for further research. to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels. ",cs.IR,C,0.041613188,-0.35709077,-0.22643909
http://arxiv.org/pdf/2205.01600v1,A Comparison of Approaches for Imbalanced Classification Problems in the Context of Retrieving Relevant Documents for an Analysis,"Then the proce-
dures are applied on the datasets and their retrieval performances are inspected (4). The
Ô¨Ånal discussion in Section 4.3.4 summarizes what has been learned and points toward
aspects that merit further study. Before continuing, note that the vocabulary used in this study often makes use of the
term retrieval. ",cs.IR,A,-0.17182401,0.18047887,-0.0589955
http://arxiv.org/pdf/2205.01763v1,Analyzing and Simulating User Utterance Reformulation in Conversational Recommender Systems,"Method   Rouge-1          Movie                     BLEU     Rouge-1                            Travel   BLEU     Rouge-1          Hybrid   BLEU
                  Rouge-2 Rouge-L                                                       Rouge-2 Rouge-L                    Rouge-2 Rouge-L
GPT2     0.112                                      0.058    0.056                                       0.049    0.118                     0.049
GPT2-T   0.113‚Ä°   0.031                     0.102   0.072‚Ä°   0.053‚Ä°                     0.017   0.061    0.072‚Ä°   0.125‚Ä°   0.005   0.092    0.055‚Ä°
GPT2-R   0.072    0.031‚Ä°                    0.106‚Ä°  0.037    0.056                      0.015‚Ä°  0.065‚Ä°   0.042    0.106    0.028‚Ä°  0.137‚Ä°   0.105
GPT2-TR  0.086‚Ä°                                     0.128‚Ä°   0.152‚Ä°                                      0.073‚Ä°   0.182‚Ä°                    0.156‚Ä°
                  0.021                     0.096                                       0.015   0.102                      0.017   0.124
BERT     0.228    0.032‚Ä°                    0.132‚Ä°  0.113    0.110                      0.031‚Ä°  0.127‚Ä°   0.092    0.260    0.032‚Ä°  0.173‚Ä°   0.112
BERT-T   0.220‚Ä°                                     0.121‚Ä°   0.121‚Ä°                                      0.141‚Ä°   0.265‚Ä°                    0.109‚Ä°
BERT-R   0.223    0.06                      0.221   0.132    0.132                      0.023   0.121    0.086    0.243    0.010   0.192    0.213
BERT-TR  0.324‚Ä°   0.069‚Ä°                    0.213‚Ä°  0.132‚Ä°   0.213‚Ä°                     0.032‚Ä°  0.132‚Ä°   0.153‚Ä°   0.321‚Ä°   0.054‚Ä°  0.262‚Ä°   0.327‚Ä°

BART     0.281    0.09                      0.193   2.229    0.281                      0.038   0.231    1.572    0.301    0.032   0.234    2.562
BART-T   0.504‚Ä°   0.092‚Ä°                    0.312‚Ä°  5.308‚Ä°   0.422‚Ä°                     0.065‚Ä°  0.231‚Ä°   5.286‚Ä°   0.519‚Ä°   0.072‚Ä°  0.342‚Ä°   8.214‚Ä°
BART-R   0.343                                      3.326    0.356                                       2.359    0.362                     3.382
BART-TR  0.521‚Ä°   0.108                     0.279   6.532‚Ä°   0.437‚Ä°                     0.094   0.281    6.473‚Ä°   0.585‚Ä°   0.120   0.302    9.481‚Ä°
                  0.123‚Ä°                    0.501‚Ä°                                      0.102‚Ä°  0.419‚Ä°                     0.175‚Ä°  0.516‚Ä°
T5       0.410                                      3.472    0.369                                       2.740    0.400                     4.739
T5-T     0.742‚Ä°   0.154                     0.328   19.031‚Ä°  0.741‚Ä°                     0.158   0.312    21.485‚Ä°  0.783‚Ä°   0.163   0.396    20.987‚Ä°
T5-R     0.401    0.124‚Ä°                    0.517‚Ä°  3.578    0.365                      0.100‚Ä°  0.433‚Ä°   3.253    0.420    0.285‚Ä°  0.532‚Ä°   6.242
T5-TR    0.766‚Ä°                                     20.739‚Ä°  0.755‚Ä°                                      23.242‚Ä°  0.792‚Ä°                    22.487‚Ä°
                  0.243                     0.410                                       0.262   0.367                      0.245   0.399
                  0.320‚Ä°                    0.739‚Ä°                                      0.297‚Ä°  0.738‚Ä°                     0.340‚Ä°  0.782‚Ä°

                  0.261                     0.399                                       0.240   0.340                      0.270   0.430
                  0.321‚Ä°                    0.740‚Ä°                                      0.294‚Ä°  0.753‚Ä°                     0.350‚Ä°  0.785‚Ä°

restart as the reformulation types in the experiments, as stop and                              6.1 Automatic Evaluation with NLP Metrics
change would change the intent of original utterances. We leave
the reformulation task with changed intent for future work. Each                                For automatic evaluation we use ROUGE [22] and BLEU [27] as our
original utterance ùë¢0 has more than one reformulated candidates                                 evaluation metrics. ",cs.IR,C,-0.13932271,-0.15163767,-0.0555888
http://arxiv.org/pdf/2205.01802v1,A Review on Pushing the Limits of Baseline Recommendation Systems with the integration of Opinion Mining & Information Retrieval Techniques,"11 EVALUATION APPROACHES FOR RECOMMENDATION SYSTEMS
As highlighted in past reviews, evaluating & benchmarking Recommendation Systems has been a major concern due to
the lack of available datasets and questions related to domain-specific approaches/ algorithms used for recommendations. For the convenience of future work, the following breakdown can be used to evaluate future Recommendations
Systems. Especially, those that integrate novel algorithmic, hybrid approaches for recommendations. ",cs.IR,B,0.50490177,-0.028437512,0.034730304
http://arxiv.org/pdf/2205.01886v1,P$^3$ Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning,"The mixture of the two tasks
                                                                        doesn‚Äôt bring significant improvements. Multi-task pre-finetuning
tialized from three officially released pre-trained T5 checkpoints:     for ranking needs further study. T5 (Vanilla), T5 (LM-Adapt) and T5 (Multi-task). ",cs.IR,C,-0.24152902,-0.12348671,-0.119181536
http://arxiv.org/pdf/2205.01886v2,P^3 Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning,"The mixture of the two tasks
                                                                        doesn‚Äôt bring significant improvements. Multi-task pre-finetuning
tialized from three officially released pre-trained T5 checkpoints:     for ranking needs further study. T5 (Vanilla), T5 (LM-Adapt) and T5 (Multi-task). ",cs.IR,C,-0.24152902,-0.12348671,-0.119181536
http://arxiv.org/pdf/2205.02303v1,Analysing the Robustness of Dual Encoders for Dense Retrieval Against Misspellings,"https://doi.org/10.18653/v1/2021.findings-acl.51
‚Äúcorrect spelling‚Äù of a typoed word during training. We leave these                          [11] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan
directions as future work. Majumder, and Li Deng. ",cs.IR,C,-0.27008644,0.085612796,-0.09742767
http://arxiv.org/pdf/2205.02870v1,Toward A Fine-Grained Analysis of Distribution Shifts in MSMARCO,"Finally, we note that the recent version of ColBERT-V2
                                                                       [22] reports results on BEIR (and Lotte) by regrouping different
         Rel Loss                                                      subtasks where ColBERT outperformed SPLADE. The impact of
                                                                       MSMARCO annotations or the BEIR aggregation measures could
   On length shifts, we notice that short queries are easier than      be questioned and is worth investigating in future work. longer ones, even for a model trained on long queries only. ",cs.IR,A,-0.15783358,0.056113772,-0.17726013
http://arxiv.org/pdf/2205.03067v1,Translating Place-Related Questions to GeoSPARQL Queries,"Enriching the current benchmark dataset to cover questions about activities and events is
also a necessary step for future work in translating place-related questions to queries. Using local context (e.g., user
location) to present relevant and personalized answers to geographic questions remains as a future work of this study. Acknowledgement

The support by the Australian Research Council grant DP210101156 is acknowledged. ",cs.IR,A,-0.0021012016,0.23427373,0.18148772
http://arxiv.org/pdf/2205.03273v1,Collective Relevance Labeling for Passage Retrieval,"Furthermore, obtaining qÀú from PRF requires addi-
tional online computation at evaluation time. In              As future work, we consider zero-shot transfer. contrast, we transfer such computations to training        While our collective self-KD effectively distills
time for relevance labeling, eliminating all over-         knowledge, one requirement we have is to boot-
heads at evaluation time. ",cs.IR,A,-0.112111375,0.11948827,-0.20243332
http://arxiv.org/pdf/2205.03273v2,Collective Relevance Labeling for Passage Retrieval,"Furthermore, obtaining qÀú from PRF requires addi-
tional online computation at evaluation time. In              As future work, we consider zero-shot transfer. contrast, we transfer such computations to training        While our collective self-KD effectively distills
time for relevance labeling, eliminating all over-         knowledge, one requirement we have is to boot-
heads at evaluation time. ",cs.IR,A,-0.112111375,0.11948827,-0.20243332
http://arxiv.org/pdf/2205.03876v1,It's the Same Old Story! Enriching Event-Centric Knowledge Graphs by Narrative Aspects,"Modeling and utiliz-                   plained in section 4.2, some subjective attributions are overlapping
ing narrative aspects for a variety of purposes have gained attention                   and lack a specific semantic. Therefore, future work will be done to
in recent years. Most works in this direction fall into one of two cat-                 mitigate both limitations. ",cs.IR,A,-0.09508868,0.17432779,0.2213713
http://arxiv.org/pdf/2205.04181v1,Price DOES Matter! Modeling Price and Interest Preferences in Session-based Recommendation,"results in different optimal values for ùúå. As to future work, we plan to extend CoHHN to incorporate more
   The iterative number of the dual-channel aggregating ùëü con-                                                           information such as item brand and seller‚Äôs reputation to further
trols the degree of information fusion among nodes. For a node in                                                        explore the preferences of users. ",cs.IR,B,0.09234841,-0.14402151,0.034668222
http://arxiv.org/pdf/2205.04212v1,Think outside the search box: A comparative study of visual and form-based query builders,"Although a number of the findings are statistically significant, it
would not be appropriate to generalise too far based on a single instance of each interface
type (RQ2). 5.1 Future work

The limitations identified earlier suggest a number of avenues for need for future work. First,
this study was carried out in a controlled experimental setting, and further studies would be
needed to validate our understanding of searching with visual interfaces within a naturalistic
setting. ",cs.IR,A,-0.19127345,0.15952647,0.16044447
http://arxiv.org/pdf/2205.04275v1,Long Document Re-ranking with Modular Re-ranker,"We
sophisticated query document interaction. In our experiments, we         focus on effectiveness impacts in this paper and leave the exploration
see on Robust04, the best PARADE systems, which pool passage             of efficiency to future work. latent vectors into global relevance scores, have similar performance
to MORES+4. ",cs.IR,A,0.022970907,0.30229437,-0.06927373
http://arxiv.org/pdf/2205.04275v2,Long Document Re-ranking with Modular Re-ranker,"tens of times. We focus on effectiveness impacts in this paper and
                                                                         leave the exploration of efficiency to future work. On the other hand, when moving over to Description queries
that are written in natural language, neural models start to show           In addition, MORES+ also outperforms the key block method
                                                                         BeST. ",cs.IR,A,-0.19810006,0.34035575,-0.13257533
http://arxiv.org/pdf/2205.05414v1,Recommending Research Papers to Chemists: A Specialized Interface for Chemical Entity Exploration,"researchers. In future work, the order or placement of chemical
entities within the publications might also be considered when    2020. doi: 10.1145/3366423.3380218. recommending chemistry publications. ",cs.IR,C,-0.11846179,-0.06825656,0.08679384
http://arxiv.org/pdf/2205.05888v1,How does Feedback Signal Quality Impact Effectiveness of Pseudo Relevance Feedback for Passage Retrieval?,"In-batch negatives
tations. However, in future work we plan to extend our analysis to                       for knowledge distillation with tightly-coupled teachers for dense retrieval. In
more complex signals, including larger samples. ",cs.IR,C,-0.19731623,0.0055247163,-0.23798484
http://arxiv.org/pdf/2205.05940v1,SimCPSR: Simple Contrastive Learning for Paper Submission Recommendation System,"Then, in Section 3, we describe our main methods, and Section
4 shows the details of chosen experiments, including the training conÔ¨Ågurations,
dataset, and achieved results. Finally, the paper ends with the conclusion and
our discussion on future work. Simple Contrastive Learning for Paper Submission Recommendation System  3

2 Related work

The idea of the paper recommendation system had developed by Wang, and his
coworker in computer science publications [19]. ",cs.IR,B,0.2705536,0.06270093,-0.011483072
http://arxiv.org/pdf/2205.05976v1,TaDeR: A New Task Dependency Recommendation for Project Management Platform,"It is fascinating if the TaDeR system can suggest top-related
tasks and classify users‚Äô corresponding types of links. We aim to apply other em-
bedding methods and extend our experiments to other challenging datasets in
future work. References

 1. ",cs.IR,A,0.114547774,0.13605744,0.029600263
http://arxiv.org/pdf/2205.05982v1,Vectorized and performance-portable Quicksort,"Partition already calls a comparison function. The larger change
required would be to replace Min/Max in Partition with comparisons and
conditional swaps, which we leave for future work. 6 Conclusions

We used the Highway cross-platform abstraction layer for implementing
vqsort (vectorized Quicksort) and utilizing the most eÔ¨Écient instructions
available on the current CPU. ",cs.IR,C,-0.14019859,-0.17187676,0.01644335
http://arxiv.org/pdf/2205.06205v1,kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval,"In conjunction with this
work, we open-source our curated Twitter Follow Graph dataset as a resource to the information retrieval community. Manuscript submitted to ACM
kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval  13

   There are many follow-up areas of investigation left to future work. For example, in our investigations we utilized a
global smoothing parameter; however a per-user smoothing parameter may be more appropriate. ",cs.IR,A,0.20602399,0.23502266,-0.056534864
http://arxiv.org/pdf/2205.06205v2,kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval,"In conjunction with this
work, we open-source our curated Twitter Follow Graph dataset as a resource to the information retrieval community. Manuscript submitted to ACM
kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval  13

   There are many follow-up areas of investigation left to future work. For example, in our investigations we utilized a
global smoothing parameter; however a per-user smoothing parameter may be more appropriate. ",cs.IR,A,0.20602399,0.23502266,-0.056534864
http://arxiv.org/pdf/2205.06296v1,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Recommendation,"We conclude that the DeepCoNN model shows superior performance over
standard collaborative Ô¨Åltering techniques. Our research into other architectures
and regularization methods conÔ¨Årm that further improvements to DeepCoNN
are available and further research into this model is certainly warranted. References

 1. ",cs.IR,B,0.08294479,-0.06425381,-0.3545689
http://arxiv.org/pdf/2205.06296v2,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Recommendation,"We Ô¨Ånd that the DeepCoNN model outperforms traditional collaborative Ô¨Ål-
tering strategies. Our investigation into diÔ¨Äerent architectures and regularisation
techniques conÔ¨Årms that more improvements to DeepCoNN are possible and that
further study of this model is necessary. Movie Recommendation using Deep Cooperative Neural Networks  13

References

 1. ",cs.IR,B,0.23289111,0.037638564,-0.33088857
http://arxiv.org/pdf/2205.06296v3,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Ranking Prediction,"We conclude that the DeepCoNN model outperforms traditional collabora-
tive Ô¨Åltering strategies. Our investigation into diÔ¨Äerent architectures and regular-
isation techniques conÔ¨Årms that more improvements to DeepCoNN are possible
and that further study of this model is necessary. Movie Ranking Prediction using Deep Cooperative Neural Networks  13

References

 1. ",cs.IR,B,0.12461601,0.03732889,-0.42435372
http://arxiv.org/pdf/2205.06296v4,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Ranking Prediction,"We conclude that the DeepCoNN model outperforms traditional collabora-
tive Ô¨Åltering strategies. Our investigation into diÔ¨Äerent architectures and regular-
isation techniques conÔ¨Årms that more improvements to DeepCoNN are possible
and that further study of this model is necessary. Movie Ranking Prediction using Deep Cooperative Neural Networks  13

References

 1. ",cs.IR,B,0.12461601,0.03732889,-0.42435372
http://arxiv.org/pdf/2205.06296v5,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Recommendation,"We conclude that the DeepCoNN model outperforms traditional collabora-
tive Ô¨Åltering strategies. Our investigation into diÔ¨Äerent architectures and regular-
isation techniques conÔ¨Årms that more improvements to DeepCoNN are possible
and that further study of this model is necessary. Movie Recommendation using Deep Cooperative Neural Networks  13

References

 1. ",cs.IR,B,0.19258505,0.05610181,-0.41813788
http://arxiv.org/pdf/2205.06532v1,Addressing Confounding Feature Issue for Causal Recommendation,"5.4 RQ3: Prediction Analyses

The performance study has shown the superiority of DCR-MoE regarding overall recommendation
accuracy. In this subsection, we further study whether our DCR-MoE truly eliminates the impact of
the confounding feature by conducting an analysis of the model predictions. Specifically, we first
divide items into different groups according to the values of ùê¥, 1such that items with the same value
of the confounding feature belong to a group. ",cs.IR,B,0.31841052,-0.13462964,-0.01947312
http://arxiv.org/pdf/2205.06532v2,Addressing Confounding Feature Issue for Causal Recommendation,"5.4 RQ3: Prediction Analyses

The performance study has shown the superiority of DCR-MoE regarding overall recommendation
accuracy. In this subsection, we further study whether our DCR-MoE truly eliminates the impact of
the confounding feature by conducting an analysis of the model predictions. Specifically, we first
divide items into different groups according to the values of ùê¥, such that items with the same value
of the confounding feature belong to a group. ",cs.IR,B,0.31914604,-0.14200142,-0.02460113
http://arxiv.org/pdf/2205.06985v1,Review-Based Tip Generation for Music Songs,"We de-
sides the textual relevance, the content-based ranking also      scribe the experiment setup in Section 5 and elaborate on the
involves the approval numbers of the reviews for the song,       benchmark results in Section 6. We conclude and mention
                                                                 future work in Section 7. 1Due to the privacy issue, the company name is anonymized. ",cs.IR,B,0.14542808,0.082835846,0.23137328
http://arxiv.org/pdf/2205.06985v2,Generating Tips from Song Reviews: A New Dataset and Framework,"benchmark results in Section 6. We conclude and mention
                                                                 future work in Section 7. Zang et al. ",cs.IR,C_centroid,-0.27297634,-0.20189345,-0.12623839
http://arxiv.org/pdf/2205.06997v1,PAS: A Position-Aware Similarity Measurement for Sequential Recommendation,"binations (k, Œª, h(¬∑)) on test sets, where k ‚àà {5, 10, 20, 40}
is the length of the input sequence. Œª ‚àà {0, 0.2, 0.4, ¬∑ ¬∑ ¬∑ , 1.0}                                           For future works, Ô¨Årstly we are interested in devising the
denotes the tradeoff parameter. Scaling function h(¬∑) is deÔ¨Åned                                            position-aware binary indicator in a new way that is not
in Equation (8). ",cs.IR,C,-0.23568666,-0.39846838,0.023139384
http://arxiv.org/pdf/2205.06997v2,PAS: A Position-Aware Similarity Measurement for Sequential Recommendation,"binations (k, Œª, h(¬∑)) on test sets, where k ‚àà {5, 10, 20, 40}
is the length of the input sequence. Œª ‚àà {0, 0.2, 0.4, ¬∑ ¬∑ ¬∑ , 1.0}                                           For future works, Ô¨Årstly we are interested in devising the
denotes range of the tradeoff parameter. Scaling function h(¬∑)                                             position-aware binary indicator in a new way that is not
is deÔ¨Åned in Equation (8). ",cs.IR,C,-0.23147714,-0.38793632,0.029343437
http://arxiv.org/pdf/2205.08289v1,Experiments on Generalizability of User-Oriented Fairness in Recommender Systems,"In general, finding a more stable and reason-               method. For example, the average number of long-tail items in the
able way of classifying users such as K-means (or other clustering                original top-10 recommendation list in BPR, MostPop, PF, WMF,
techniques) is a potential topic for future work. NeuMF, and VAECF across all datasets are 0, 0, 5083, 6211.87, 157,
SIGIR ‚Äô22, July 11‚Äì15, 2022, Madrid, Spain                                          H. A. Rahmani, M. Naghiaei, M. Dehghan, M. Aliannejadi

Table 3: The recommendation performance of all, advantaged, and disadvantaged users of UFR and corresponding baselines on
Last.fm datasets for G1 and G2. ",cs.IR,B,0.25850666,-0.09506701,0.13635318
http://arxiv.org/pdf/2205.09083v1,Health Information Retrieval -- State of the art report,"The second type of classiÔ¨Åcation is related to
the information that derives and is organized from observational and experimental research. This information provides health professionals the knowledge acquired in other situations
so it may be applied to individual patients or used to conduct further research. Similarly
to other types of scientiÔ¨Åc information, the knowledge-based information can be subdivided
in primary information (direct results of original research that appears in papers, journals
or other sources) and secondary information (reviews, condensations, summaries of primary
literature like books, monographs, review papers, clinical guidelines, health information on
web pages and other sources). ",cs.IR,A,-0.21310666,0.1520287,0.26976696
http://arxiv.org/pdf/2205.09240v1,Debiasing Neural Retrieval via In-batch Balancing Regularization,"We realize RaB is                    metrics. In future work, we will consider general-
focusing on the top-ranking result and |‚àÜA-PRF| is                    izing our method to multiple protected variables
focusing on the overall ranking result by deÔ¨Ånition. such as age, income, etc, and also addressing bias
We present the RaB result in the last column. ",cs.IR,C,-0.062303808,-0.1869219,0.17637675
http://arxiv.org/pdf/2205.09626v2,BARS: Towards Open Benchmarking for Recommender Systems,"We hope that
easy access to consistently split and pre-processed datasets with       Figure 1: A simplified workflow of modern industrial RS. reusable baseline results will help the research community avoid
reporting inconsistent or misleading results in their future work. prediction3 and returning a small number of top-ranking (i.e., in
                                                                       tens) items from the candidates. ",cs.IR,C,-0.09179195,-0.069012284,0.049951147
http://arxiv.org/pdf/2205.09626v3,BARS: Towards Open Benchmarking for Recommender Systems,"We hope that
easy access to consistently split and pre-processed datasets with       Figure 1: A simplified workflow of modern industrial RS. reusable baseline results will help the research community avoid
reporting inconsistent or misleading results in their future work. prediction3 and returning a small number of top-ranking (i.e., in
                                                                       tens) items from the candidates. ",cs.IR,C,-0.09179195,-0.069012284,0.049951147
http://arxiv.org/pdf/2205.09626v4,BARS: Towards Open Benchmarking for Recommender Systems,"Through these two phases, the
pre-processed datasets with reusable baseline results will help the    recommender system can strike a balance between accuracy and
research community avoid reporting inconsistent or misleading          efficiency. In the following, we introduce the related work of these
results in their future work. two recommendation phases. ",cs.IR,B,0.32638836,0.045128446,0.013146456
http://arxiv.org/pdf/2205.09626v5,BARS: Towards Open Benchmarking for Recommender Systems,"The matching
literature. We believe that easy access to consistently split and pre-   phase aims to perform retrieval of candidate items from a large
processed datasets with reusable baseline results could help the         item corpus (with millions of items) with high efficiency, while
research community avoid reporting inconsistent or misleading            the ranking phase targets at learning the fine-grained personal-
results in their future work. ized ranking of the retrieved items with click-through rate (CTR)
                                                                         prediction2 and returning a small number of top-ranking (i.e., in
   In summary, our work could serve as a useful resource for several     tens) items from the candidates. ",cs.IR,A,0.13865633,0.16310497,-0.087416425
http://arxiv.org/pdf/2205.09638v1,Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking,"Other datasets such
as TREC DL 2019 (Voorhees and Ellis, 2019) use                sf (q, d) =Œ≤ ¬∑ œÜ(Œ∑q(q), Œ∑d(d))+
metrics like nDCG, but such densely labelled data                          (1 ‚àí Œ≤) ¬∑ Œ∂(concat(q, d)),
are very scarce and therefore they are not suitable
for Ô¨Ånite-sample calibration, which we leave for      which is known as evidence fusion (Ma et al., 2022). future work. The weight Œ≤ ‚àà [0, 1] is searched on the calibration
                                                      set for the best MRR@10 score, such that the fusion
5.2 Retrievers and Rerankers                          model will consistently yield better ranking results
                                                      than both Œ∂ and œÜ. Tbl. ",cs.IR,C,-0.03442032,-0.23168227,-0.18668133
http://arxiv.org/pdf/2205.09670v1,A Unified Collaborative Representation Learning for Neural-Network based Recommender Systems,"when compared with state-of-the-art models on all evalu-
ation metrics, but also when trying to Ô¨Ånd a more stable                                  [14] M. Li, S. Zhang, F. Zhu, W. Qian, L. Zang, J. Han, and S. Hu,
latent space with the consideration of accuracy, efÔ¨Åciency,                                      ‚ÄúSymmetric metric learning with adaptive margin for recommendation,‚Äù
and overÔ¨Åtting. Our future work is to apply MML with                                             in The Thirty-Fourth AAAI Conference on ArtiÔ¨Åcial Intelligence, AAAI
some context and side information about users and items,                                         2020, The Thirty-Second Innovative Applications of ArtiÔ¨Åcial Intelligence
to construct a more reasonable similar-pair set for latent                                       Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances
relationships. in ArtiÔ¨Åcial Intelligence, EAAI 2020, New York, NY, USA, February
                                                                                                 7-12, 2020. ",cs.IR,B,0.21458861,0.113465555,0.029060753
http://arxiv.org/pdf/2205.09673v1,Detect Professional Malicious User with Metric Learning in Recommender Systems,"Dataset                       Amazon    Yelp     Taobao      Jingdong

    Because of the sequential process of MMD, the whole           #user                         30,759    45,980   10,121      8,031
time complexity should be:                                        #item                         16,515    11,537   9,892       3,025
                                                                  #review                       285,644   229,900  10,791      8,310
     OMMD = O(nlogn) + O(nd2) + O(p log p + k2). (27)             #rating                       285,644   229,900  49,053      25,152
                                                                  Sparsity                      0.051%    0.043%   0.049%      0.12%
Utilizing parallel processing or other computing frame-           PMU ratio                     0%        0%       9.31%       10.71%
works may accelerate our model, where we leave as an              PMU fake ratings/ratings      0%        0%       45.5%       56.7%
important future work. PMU fake reviews/reviews      0%        0%       66.6%       54.5%
                                                                  Avg words /s                  10.1      9.9      12.7        13.2
4 EXPERIMENTS                                                     Avg words /r                  104       130      65          70
                                                                  Avg sentences /r              9.7       11.9     4.9         5.1
In this section, we conduct extensive experiments to answer       Avg reviews /u                9.29      5.00     1.06        1.03
the following issues:
                                                                      a) Objective evaluation: we employ speciÔ¨Åcity and sensi-
    RQ1: Can our proposed method MMD outperform the               tivity as the objective metrics [29]:
state-of-the-art malicious user detection models? ",cs.IR,B,0.053016394,-0.12871246,-0.022756923
http://arxiv.org/pdf/2205.09707v1,PLAID: An Efficient Engine for Late Interaction Retrieval,"at a low level for this work) or suboptimal load balancing between
                                                                        threads due to the non-uniform passage lengths. We defer more
5.4 Scalability                                                         extensive profiling and potential solutions to future work. We evaluate PLAID‚Äôs scalability with respect to both the dataset        6 CONCLUSION
size as well as the parallelism degree (on CPU). ",cs.IR,C,-0.22539535,-0.1812329,0.025915083
http://arxiv.org/pdf/2205.09948v1,GDSRec: Graph-Based Decentralized Collaborative Filtering for Social Recommendation,"Effect of social network and user ratings on Ciao and Epinions datasets. ‚Ä¢ Impact of the Social Network: We now analyze the impact                                                                 applied directly to other models and lead to performance
  of the social network on the recommendation perfor-                                                                     improvements, and we leave it for future works. mance. ",cs.IR,B,0.3295676,-0.0411312,0.1607759
http://arxiv.org/pdf/2205.10759v1,"Sequential/Session-based Recommendations: Challenges, Approaches, Applications and Opportunities","This part will discuss some of the
      Figure 1: Session data vs. sequence data, from [12]                      most promising directions in the area and conclude this tutorial. to fill in these gaps so as to facilitate further research in this exciting
and vibrant area. 4 BACKGROUND AND PROBLEM
                                                                                 STATEMENT
2 RELATED WORK
                                                                             4.1 SRSs vs SBRSs
There are some surveys and tutorials focusing on the topic of SRSs
or SBRSs. ",cs.IR,C,-0.29572847,-0.058861382,0.1820034
http://arxiv.org/pdf/2205.11127v1,A Survey of Research on Fair Recommender Systems,"Future Directions. Our analysis of the current research landscape points to a number of further research gaps. Con-
sidering the type of contributions and the different notions of fairness, we Ô¨Ånd that today‚Äôs research efforts are not

                                                                     26
balanced. ",cs.IR,C,-0.132335,-0.13034262,0.56570506
http://arxiv.org/pdf/2205.11127v2,A Survey of Research on Fair Recommender Systems,"Future Directions. Our analysis of the current research landscape points to a number of further research gaps. Con-
sidering the type of contributions and the different notions of fairness, we Ô¨Ånd that today‚Äôs research efforts are not
balanced. ",cs.IR,C,-0.12503321,-0.12125039,0.58501744
http://arxiv.org/pdf/2205.11127v3,Fairness in Recommender Systems: Research Landscape and Future Directions,"While general-purpose solutions are certainly desirable, the danger of being
stuck in an abstraction trap with limited practical impact increases [78, 135]. Future Directions Our analysis of the current research landscape points to a
number of further research gaps. Considering the type of contributions and
the diÔ¨Äerent notions of fairness, we Ô¨Ånd that today‚Äôs research eÔ¨Äorts are not
balanced. ",cs.IR,C,-0.113864824,-0.06977977,0.48351473
http://arxiv.org/pdf/2205.11245v1,PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for Multi-stage Ranking,"This phenomenon largely
hints at the thirst for multi-stage ranking in generative models, which can be
expected to show powerful eÔ¨Äects with the pair-wise or list-wise training. We
believe that the interweaving sequence of diÔ¨Äerent methods will be a focus point
of future work. References

 1. ",cs.IR,C,-0.035057984,-0.073068194,-0.24700376
http://arxiv.org/pdf/2205.11245v2,PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for Multi-stage Ranking,"This phenomenon largely
hints at the thirst for multi-stage ranking in generative models, which can be
expected to show powerful eÔ¨Äects with the pair-wise or list-wise training. We
believe that the interweaving sequence of diÔ¨Äerent methods would be a focus
priority in the future work. References

 1. ",cs.IR,C,-0.040193044,-0.08301756,-0.24680051
http://arxiv.org/pdf/2205.11245v3,PASH at TREC 2021 Deep Learning Track: Generative Enhanced Model for Multi-stage Ranking,"This phenomenon largely
hints at the thirst for multi-stage ranking in generative models, which can be
expected to show powerful eÔ¨Äects with the pair-wise or list-wise training. We
believe that the interweaving sequence of diÔ¨Äerent methods would be a focus
priority in the future work. References

 1. ",cs.IR,C,-0.040193044,-0.08301756,-0.24680051
http://arxiv.org/pdf/2205.11248v1,Efficient Mixed Dimension Embeddings for Matrix Factorization,"Similar
methods are also applicable for implicit feedback setting, where unknown user-item pairs are assumed to have rating 0
and a low weight. We leave this for future work. 10
EfÔ¨Åcient Mixed Dimension Embeddings for Matrix Factorization  A PREPRINT

7 Conclusion

In this paper we propose two methods for matrix factorization with mixed dimension embeddings. ",cs.IR,B,0.3842142,-0.0008852228,-0.009332322
http://arxiv.org/pdf/2205.11498v1,Domain Adaptation for Memory-Efficient Dense Retrieval,"0.22                                             SCIFACT
                            0.36                                                       9 Limitations and Future Work
                                                     JPQ
          0.2   JPQ         0.34                     JPQ+GenQ                          Even though we Ô¨Ånd the GPL technique to provide
         0.18   JPQ+GenQ                             JPQ+GPL                           a boost with memory compressed models: BPR
                JPQ+GPL     0.32                     5M0xemory10E0fxficien1c5y0x 200x  and JPQ. Our work has a few limitations which we
            1x                                                                         brieÔ¨Çy mention them below and for future work:
                50x 100x 150x 200x 0.31x
                                                                                          Different compression algorithms: In our
                TREC-COVID  0.65                                                       work, we considered JPQ and BPR due to its popu-
                                                                                       larity and effectiveness shown in our preliminary
         0.7                                                                           results. In future, we can work on extending our
                                                                                       methods to more recent memory compression algo-
         0.65               0.6                                                        rithms such as RepCONC (Zhan et al., 2022). ",cs.IR,C,-0.27699426,-0.16930552,-0.20646617
http://arxiv.org/pdf/2205.11685v1,A Dataset for Sentence Retrieval for Open-Ended Dialogues,"1371‚Äì1374. In future work, we would like to devise BERT-based retrieval                     [15] Jianfeng Gao, Chenyan Xiong, Paul Bennett, and Nick Craswell. 2022. ",cs.IR,A,-0.13593662,0.369097,-0.14347962
http://arxiv.org/pdf/2205.11728v1,ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest,"Graph-based multilingual product retrieval in e-commerce search. eral promising areas for future work, such as replacing the bag                                arXiv:2105.02978
of words model used for text features with a pretrained Trans-                           [19] Yu A Malkov and Dmitry A Yashunin. 2018. ",cs.IR,A,-0.019139996,0.31991342,-0.07951406
http://arxiv.org/pdf/2205.11857v1,Comprehensive Privacy Analysis on Federated Recommender System against Attribute Inference Attacks,"solution by comparing with the baseline approaches. In the
                                                                  future work of privacy-preserving federated recommenders,
    Federated Learning. To tackle privacy issues existing in      it will be appealing to further investigate privacy protection
centralized scenarios, a common practice is to deploy the         against active attackers that can participate in the training
online system in a federated setting, which enables users         of federated recommender systems and craft adversarial
to collaboratively learn a global model while keeping all         parameter updates for follow-up attribute inference attacks. ",cs.IR,B,0.1968534,-0.06606899,0.0969841
http://arxiv.org/pdf/2205.12102v1,KQGC: Knowledge Graph Embedding with Smoothing Effects of Graph Convolutions for Recommendation,"In Proceedings of the 53rd
KGE is effective for improving performance on recommendation
tasks. Annual Meeting of the Association for Computational Linguistics and the 7th

   In future work, we will explore the following three things. (1)                                 International Joint Conference on Natural Language Processing (Volume 1: Long
Deeper analysis of our model; In this work, our model employs one                                  Papers). ",cs.IR,B,0.2311367,0.25865084,-0.12166442
http://arxiv.org/pdf/2205.12133v1,MealRec: A Meal Recommendation Dataset,"be applied to research including, but not limited to, cross-modal
                                                                        retrieval of recipe images, food recognition and multimodal meal
                                                                        recommendation techniques. This will become our future work. REFERENCES                                                                                                                        Ming Li, Lin Li, Qing Xie, Jingling Yuan, and Xiaohui Tao

 [1] Giuseppe Agapito, Mariadelina Simeoni, Barbara Calabrese, Pietro Hiram Guzzi,                    Information and Knowledge Management, Virtual Event, Queensland, Australia,
      Giorgio Fuiano, and Mario Cannataro. ",cs.IR,A,0.15276083,0.1533774,0.0915232
http://arxiv.org/pdf/2205.12408v1,Using user's local context to support local news,"In Section 4, we
present details of the experimental design and a discussion of our          We also wanted to explore using locality as an item-based con-
results. The paper ends with a conclusion and future works in            text since previous research mostly focused on user-based context. Section 5. ",cs.IR,A,0.056702867,0.075781204,0.27709776
http://arxiv.org/pdf/2205.12408v2,Using user's local context to support local news,"In Section 4, we
present details of the experimental design and a discussion of our          We also wanted to explore using locality as an item-based con-
results. The paper ends with a conclusion and future works in            text since previous research mostly focused on user-based context. Section 5. ",cs.IR,A,0.056702867,0.075781204,0.27709776
http://arxiv.org/pdf/2205.12682v1,TaCube: Pre-computing Data Cubes for Answering Numerical-Reasoning Questions over Tabular Data,"questions. For future work, we may try question-insensitive
cube generation if the length of the cube is not a
burden to the sequence length. Brute Force Generation It is straightforward to
use brute force method to traverse the whole search
space and generate all the candidate results for the
cubeext of a given table. ",cs.IR,A,-0.20317015,0.13675152,-0.029589191
http://arxiv.org/pdf/2205.12901v1,Fairness of Exposure in Light of Incomplete Exposure Estimation,"We use 20 re-sampling iterations. We see that for all             A potential direction for future work is to investigate whether
distributions, FELIX performs increasingly better as the number              FELIX can be extended for different user models. In this work we
of items increases. ",cs.IR,B,0.037276022,-0.033889025,-0.044862904
http://arxiv.org/pdf/2205.13121v1,Cali3F: Calibrated Fast Fair Federated Recommendation System,"21‚Äì30, 2021.
experimental results on three real-world datasets show that                       [16] Khalil Muhammad, Qinqin Wang, Diarmuid O‚ÄôReilly-Morgan, Elias Z.
our framework outperforms federated learning baselines. The                             Tragos, Barry Smyth, Neil Hurley, James Geraci, and Aonghus Lawlor,
theoretical analysis of our proposed framework‚Äôs ability will                           ‚ÄúFedfast: Going beyond average for faster training of federated recom-
be explored in future work. We will also work on how it may                             mender systems,‚Äù in The 26th ACM SIGKDD Conference on Knowledge
be used to improve the robustness. ",cs.IR,C,-0.10697216,-0.02797618,-0.015389079
http://arxiv.org/pdf/2205.13128v1,Cascading Residual Graph Convolutional Network for Multi-Behavior Recommendation,"We also evaluated the performance
of cold-start users and analyzed the model complexity, which confirms the high application value of our CRGCN in the
real world. For future work, we would like to explore how to combine and leverage micro-behavior (e.g., short-term multi-
behavior interactions at the session level) and macro-behavior (e.g., long-term multi-behavior interactions) to further
improve the performance of the personalized recommender systems. REFERENCES

 [1] Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. ",cs.IR,B,0.3000555,-0.0604436,0.09257607
http://arxiv.org/pdf/2205.13351v1,LeiBi@COLIEE 2022: Aggregating Tuned Lexical Models with a Cluster-driven BERT-based Model for Case Law Retrieval,"Table 3 shows that the weighting mechanism could improve BM25 optimiza-
tion by utilizing both lexical (obtained by BM25) and neural-based matching
(obtained by cluster-driven) scores. LeiBi@COLIEE 2022  13

7 Conclusion and future work

Our participation at COLIEE 2022 in Task 1 allowed exploring the eÔ¨Äect of term
extraction methods on lexical and neural models in case law retrieval. We identify
that the presence of long documents creates signiÔ¨Åcant issues both for neural re-
ranking strategies and statistical models. ",cs.IR,A,-0.095028505,0.2973746,-0.11544071
http://arxiv.org/pdf/2205.13619v1,Fairness in Recommendation: A Survey,"In recent years, works on fair recommendation have come to
                                        the fore and received increasing attention. The goal of this survey is to synthesize the current state
                                        of fairness in recommendation and to inspire more future work in this area. 1
                                                                                           Y. Li, H. Chen, S. Xu, Y. Ge, J. Tan and Y. Zhang

   We begin the survey with a brief introduction of fairness in machine learning to provide the
readers a general and basic background knowledge of fairness research. ",cs.IR,B,0.29826832,-0.119283445,0.24172626
http://arxiv.org/pdf/2205.13619v2,Fairness in Recommendation: A Survey,"In recent years, works on fair recommendation have come to
                                        the fore and received increasing attention. The goal of this survey is to synthesize the current state
                                        of fairness in recommendation and to inspire more future work in this area. 1
                                                                                  Y. Li, H. Chen, S. Xu, Y. Ge, J. Tan, S. Liu and Y. Zhang

   We begin the survey with a brief introduction of fairness in machine learning to provide the
readers a general and basic background knowledge of fairness research. ",cs.IR,B,0.30919582,-0.11477682,0.2458269
http://arxiv.org/pdf/2205.13619v3,Fairness in Recommendation: A Survey,"In recent years, works on fair recommendation have come to
                                        the fore and received increasing attention. The goal of this survey is to synthesize the current state
                                        of fairness in recommendation and to inspire more future work in this area. We begin the survey with a brief introduction of fairness in machine learning to provide the
                                        readers a general and basic background knowledge of fairness research. ",cs.IR,B,0.31415397,-0.11075555,0.21622245
http://arxiv.org/pdf/2205.13619v4,Fairness in Recommendation: A Survey,"In recent years, works on fair recommendation have come to
                                       the fore and received increasing attention. The goal of this survey is to synthesize the current state
                                       of fairness in recommendation and to inspire more future work in this area. We begin the survey with a brief introduction of fairness in machine learning to provide the
                                       readers a general and basic background knowledge of fairness research. ",cs.IR,B,0.31415397,-0.11075555,0.21622245
http://arxiv.org/pdf/2205.14781v1,COVID-19 Literature Mining and Retrieval using Text Mining Approaches,"TOPICS WITH TITLE             BoW          BoW     W2V          W2V     Bert  Tf-idf
                                                    +                    +              +
                  Query Title         46%                  78%                 73%
                Question Title        24%  Lemmatization   74%  Lemmatization  90%   W2V
                Narrative Title       12%          48%     78%          70%    87%    79%
           Query Question Title       36%          29%     77%          70%    89%    87%
           Query Narrative Title      16%          15%     74%          70%    86%    70%
         Question Narrative Title     19%          41%     77%          71%    88%    85%
     Query Question Narrative Title   23%          22%     74%          70%    88%    84%
                                                   20%                  67%           84%
                                                   28%                  72%           85%

     6. Conclusion and future work
         When comparing the accuracy of the bag of words model which is a frequency-

     based approach with the Word2vec model which understands the semantics of

                                                       25
     the words led us to the conclusion that the Word2vec model gave better predic-
400 tions than the bag of words model. This happened due to the fact that the bag

     of words uses a frequency-based approach which only considers the higher occur-
     ring frequencies of the words instead of understanding the meaning of the query
     provided, which is exactly done in the Word2vec hence giving better results. ",cs.IR,A,-0.24860746,0.32840902,-0.10981828
http://arxiv.org/pdf/2205.14859v1,Cache-Augmented Inbatch Importance Resampling for Training Recommender Retriever,"When Œª = 0.5, the cached items and inbatch items
contribute equally to convergence. For further study, we may link the resampled ratio with Œª, instead
of resampling half of the items from the cache and the batch. 17
0.150                              0.080                              0.075                              0.180                              0.066     RECALL@10
0.140                              0.060                              0.070                              0.170                              0.064     NDCG@10
0.130                              0.040                              0.065                              0.160                              0.062
0.120                                                                 0.060                                                                 0.060

0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0
                   Œª                                  Œª                                  Œª                                  Œª                                  Œª

       (a) Gowalla                        (b) Amazon                            (c) Ta-feng                     (d) Echonest                          (e) Tmall

                                                      Figure 6: Effect of Œª

0.160     512 1024 2048 4096 8192  0.095     512 1024 2048 4096 8192  0.090     512 1024 2048 4096 8192  0.160     512 1024 2048 4096 8192  0.067           SSL-Pop
                Batch Size                         Batch Size         0.088           Batch Size         0.150           Batch Size         0.066           BIR
0.155                              0.090                              0.086                                                                 0.065
                                                                      0.084                                   256                           0.064     512 1024 2048 4096 8192
0.150                              0.085                              0.082                                                                                 Batch Size
                                        256                                                                                                      256
0.145                                                                      256
     256

       (a) Gowalla                        (b) Amazon                         (c) Ta-feng                 (d) Echonest                                 (e) Tmall

                                             Figure 7: NDCG@10 vs. Batch Size

B.3 Varying batch sizes

In this chapter, we further explore BIR by taking a look at how NDCG@10 changes under different
batch sizes, i.e., |B|. ",cs.IR,C,-0.21947211,-0.24226668,-0.051494025
http://arxiv.org/pdf/2205.14970v1,Towards Personalized Bundle Creative Generation with Contrastive Non-Autoregressive Decoding,"Results verify that
it shows significant advantages in terms of creative quality and
generation speed. In future work, we shall explore how to avoid conflicting and
unfavorable items to be grouped together during generation. ACKNOWLEDGMENTS

We thank all the anonymous reviewers to their insightful comments. ",cs.IR,A,-0.0034608962,0.0621429,0.27923483
http://arxiv.org/pdf/2205.14970v2,Towards Personalized Bundle Creative Generation with Contrastive Non-Autoregressive Decoding,"Results verify that
it shows significant advantages in terms of creative quality and
generation speed. In future work, we shall explore how to avoid conflicting and
unfavorable items to be grouped together during generation. ACKNOWLEDGMENTS

We thank all the anonymous reviewers to their insightful comments. ",cs.IR,A,-0.0034608962,0.0621429,0.27923483
http://arxiv.org/pdf/2205.15918v1,Interactive Query Clarification and Refinement via User Simulation,"Our framework can be seen as a basis          to judge queries A or B regarding its information need. and a proof-of-concept for future work willing to integrate sequen-       ‚Ä¢ Third, guided by the motivation to propose a framework for
tial models (namely reinforcement learning models) for question           future work on sequential models, we consider here that each agent
clarification. It is worth noting that large language models relying      component is modeled at the embedding level. ",cs.IR,A,-0.045104757,0.2803151,-0.12498151
