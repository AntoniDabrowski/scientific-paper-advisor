Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
30,"The question why both models yield
diﬀerent behaviors is left open for further research.","They introduce a parameter ∆ which stands for that diﬀerence and had
found via simulations that a larger ∆ increase the diﬀerence between νx and νy.","ACKNOWLEDGMENTS

   This work was supported by the Israel Science Foundation, (Grant No.",2022-01-02 16:01:13+00:00,Percolation on spatial anisotropic networks,physics.soc-ph,"['physics.soc-ph', 'physics.app-ph']","[arxiv.Result.Author('Ouriel Gotesdyner'), arxiv.Result.Author('Bnaya Gross'), arxiv.Result.Author('Dana Vaknin Ben Porath'), arxiv.Result.Author('Shlomo Havlin')]","Many realistic systems such as infrastructures are characterized by spatial
structure and anisotropic alignment. Here we propose and study a model for
dealing with such characteristics by introducing a parameter that controls the
strength of the anisotropy in the spatial network. This parameter is added to
an existing isotropic model used to describe networks under spatial
constraints, thus generalizing the spatial model to take into account both
spatial and anisotropic features. We study the resilience of such networks by
using a percolation process and find that anisotropy has a negative impact on a
network's robustness. In addition, our results suggest that the anisotropy in
this model does not affect the critical exponent of the correlation length,
$\nu$, which remains the same as the known $\nu$ in 2D isotropic lattices.",0.031170368,-0.20443971,0.0317334,A
144,"We hope our work will motivate further study
many networks with an abundance of triangles, in con-         in this direction, and with a larger variety of generative
tradiction to what is commonly assumed to be possible         models within or beyond the SBM family.","For the other kinds of    ended, as there is no short supply of possible network de-
networks the agreement tends to be fairly good, even for      scriptors.",with this class of models.,2022-01-05 15:28:37+00:00,Systematic assessment of the quality of fit of the stochastic block model for empirical networks,physics.soc-ph,"['physics.soc-ph', 'physics.data-an', 'stat.AP', 'stat.ML']","[arxiv.Result.Author('Felipe Vaca-Ramírez'), arxiv.Result.Author('Tiago P. Peixoto')]","We perform a systematic analysis of the quality of fit of the stochastic
block model (SBM) for 275 empirical networks spanning a wide range of domains
and orders of size magnitude. We employ posterior predictive model checking as
a criterion to assess the quality of fit, which involves comparing networks
generated by the inferred model with the empirical network, according to a set
of network descriptors. We observe that the SBM is capable of providing an
accurate description for the majority of networks considered, but falls short
of saturating all modeling requirements. In particular, networks possessing a
large diameter and slow-mixing random walks tend to be badly described by the
SBM. However, contrary to what is often assumed, networks with a high abundance
of triangles can be well described by the SBM in many cases. We demonstrate
that simple network descriptors can be used to evaluate whether or not the SBM
can provide a sufficiently accurate representation, potentially pointing to
possible model extensions that can systematically improve the expressiveness of
this class of models.",0.40923983,-0.11570738,-0.07312795,A_centroid
335,and subjective safety implications of intersection approach design call for further research.,"Investigating both the OSM data quality and the objective
14                                                                                             VYBORNOVA et al.","Bridges
There are 3 gaps classiﬁed as bridge within the top 105 gaps: gap 1 on Knippelsbro (see Fig.",2022-01-10 15:35:14+00:00,Automated Detection of Missing Links in Developed Bicycle Networks,physics.soc-ph,"['physics.soc-ph', 'cs.CY']","[arxiv.Result.Author('Anastassia Vybornova'), arxiv.Result.Author('Tiago Cunha'), arxiv.Result.Author('Astrid Gühnemann'), arxiv.Result.Author('Michael Szell')]","Cycling is an effective solution for making urban transport more sustainable.
However, bicycle networks are typically developed in a slow, piecewise process
that leaves open a large number of gaps, even in well developed cycling cities
like Copenhagen. Here, we develop the IPCC procedure (Identify, Prioritize,
Cluster, Classify) for finding the most important missing links in developed
urban bicycle networks, by analyzing street networks from OpenStreetMap. We
apply the IPCC procedure to Copenhagen and report the 105 top priority gaps.
For evaluation, we compare these gaps with the city's most recent Cycle Path
Prioritization Plan and find considerable overlaps. Our results show how
network analysis with minimal data requirements can serve as a cost-efficient
support tool for bicycle network planning. The IPCC procedure takes into
account the whole city network for consolidating urban bicycle networks and can
therefore well complement localized, manual planning processes, providing a
data-driven framework for more effective, city-wide decision-making.",-0.053464483,0.18705441,-0.0035276413,C
336,"Investigating both the OSM data quality and the objective
and subjective safety implications of intersection approach design call for further research.","right-turns that have not been identiﬁed as gaps by the IPDC procedure
because they are tagged as “protected bicycle track” in OSM.",VYBORNOVA et al.,2022-01-10 15:35:14+00:00,Automated Detection of Missing Links in Bicycle Networks,physics.soc-ph,"['physics.soc-ph', 'cs.CY']","[arxiv.Result.Author('Anastassia Vybornova'), arxiv.Result.Author('Tiago Cunha'), arxiv.Result.Author('Astrid Gühnemann'), arxiv.Result.Author('Michael Szell')]","Cycling is an effective solution for making urban transport more sustainable.
However, bicycle networks are typically developed in a slow, piecewise process
that leaves open a large number of gaps, even in well developed cycling cities
like Copenhagen. Here, we develop the IPDC procedure (Identify, Prioritize,
Decluster, Classify) for finding the most important missing links in urban
bicycle networks, using data from OpenStreetMap. In this procedure we first
identify all possible gaps following a multiplex network approach, prioritize
them according to a flow-based metric, decluster emerging gap clusters, and
manually classify the types of gaps. We apply the IPDC procedure to Copenhagen
and report the 105 top priority gaps. For evaluation, we compare these gaps
with the city's most recent Cycle Path Prioritization Plan and find
considerable overlaps. Our results show how network analysis with minimal data
requirements can serve as a cost-efficient support tool for bicycle network
planning. By taking into account the whole city network for consolidating urban
bicycle infrastructure, our data-driven framework can complement localized,
manual planning processes for more effective, city-wide decision-making.",-0.080424994,0.2953222,0.03497959,C
508,"We hope our work will inspire applications
outperforms other approximation methods over a range                                                   as well as further research in this direction.","For                                              estimating an appropriate hyperstub degree distribution
                                                                                                       is another important problem, as an identiﬁability prob-
the SIS dynamics (3, 4) in Figure 3, our approximation                                                 lem arises from counting larger motifs that will include
                                                                                                       smaller motifs.","of (hyperstub) degree distributions and dynamics param-                                                   This work has been funded by the LOEWE initiative
                                                                                                       (Hesse, Germany) within the emergenCITY center.",2022-01-13 14:27:51+00:00,Motif-based mean-field approximation of interacting particles on clustered networks,physics.soc-ph,"['physics.soc-ph', 'cond-mat.dis-nn', 'cond-mat.stat-mech']","[arxiv.Result.Author('Kai Cui'), arxiv.Result.Author('Wasiur R. KhudaBukhsh'), arxiv.Result.Author('Heinz Koeppl')]","Interacting particles on graphs are routinely used to study magnetic
behaviour in physics, disease spread in epidemiology, and opinion dynamics in
social sciences. The literature on mean-field approximations of such systems
for large graphs is limited to cluster-free graphs for which standard
approximations based on degrees and pairs are often reasonably accurate. Here,
we propose a motif-based mean-field approximation that considers higher-order
subgraph structures in large clustered graphs. Numerically, our equations agree
with stochastic simulations where existing methods fail.",0.18773717,-0.33625352,0.119738035,A
623,"Because the analysis indicates where effects play
geographically, and with the knowledge of local issues and characteristics in mind,
hypotheses about actual causes can be drawn up for testing in further research.","Diverging policies
and a lack of governance coordination and integration across institutional boundaries can
of course play a major role.","3.2 Second analytical step: relating boundary effects to employment scaling
      residuals

Now that municipal boundary effects on spatial interaction (commuter flows) are localized,
we can measure to which degree these local effects are related to local employment.",2022-01-15 15:54:22+00:00,Urban Scaling and Effects of Municipal Boundaries,physics.soc-ph,"['physics.soc-ph', '91D10', 'J.4']","[arxiv.Result.Author('Pieter P. Tordoir'), arxiv.Result.Author('Anthony F. J. van Raan')]","Urban scaling, the superlinear increase of social and economic measures with
increasing population, is an ubiquitous and well-researched phenomenon. This
article is focused on socio-economic performance scaling, which could possibly
be driven by increasing returns of the spatial size and density of interaction
networks. If this is indeed the case, we should also find that spatial barriers
to interaction affect scaling and cause local performance deviations. Possible
barring effects of municipal boundaries are particularly interesting from the
perspective of urban area governance policy and regional cooperation. To our
best knowledge, this is the first study on this politically relevant and
strongly disputed subject. We test the hypothesis of possible barring effects
of municipal boundaries by correlating municipal boundaries with the structure
of commuter networks within a large densely urbanized region, the Randstad in
The Netherlands. The measured network impacts of these boundaries are
subsequently correlated with local employment deviations. In order to spatially
pinpoint correlations, we apply advanced spatially weighted modelling
technique. We find that municipal borders have significant effects on
inter-municipal commuting. Moreover we can indicate the specific effect of
individual municipal borders precisely on the map. The results show
particularly significant correlations along dividing lines between large urban
agglomerations and rural communities. The southern part of the Randstad is more
fragmented by such dividing lines than the northern part, which could partly
explain the diverging economic development between the two parts.",-0.166468,0.39430583,0.022571273,C
624,"With the technique of
spatially weighted regression fitting microdata, it is possible to test this hypothesis in
further research.","Such divides could of course also cut through municipalities, causing local
employment deviations that relate less with municipal boundaries.","On a more general level we see a striking coincidence between employment
underperformance and pronounced negative effects of municipal boundaries in the
Randstad South Wing, a coincidence that is lacking in the North Wing.",2022-01-15 15:54:22+00:00,Urban Scaling and Effects of Municipal Boundaries,physics.soc-ph,"['physics.soc-ph', '91D10', 'J.4']","[arxiv.Result.Author('Pieter P. Tordoir'), arxiv.Result.Author('Anthony F. J. van Raan')]","Urban scaling, the superlinear increase of social and economic measures with
increasing population, is an ubiquitous and well-researched phenomenon. This
article is focused on socio-economic performance scaling, which could possibly
be driven by increasing returns of the spatial size and density of interaction
networks. If this is indeed the case, we should also find that spatial barriers
to interaction affect scaling and cause local performance deviations. Possible
barring effects of municipal boundaries are particularly interesting from the
perspective of urban area governance policy and regional cooperation. To our
best knowledge, this is the first study on this politically relevant and
strongly disputed subject. We test the hypothesis of possible barring effects
of municipal boundaries by correlating municipal boundaries with the structure
of commuter networks within a large densely urbanized region, the Randstad in
The Netherlands. The measured network impacts of these boundaries are
subsequently correlated with local employment deviations. In order to spatially
pinpoint correlations, we apply advanced spatially weighted modelling
technique. We find that municipal borders have significant effects on
inter-municipal commuting. Moreover we can indicate the specific effect of
individual municipal borders precisely on the map. The results show
particularly significant correlations along dividing lines between large urban
agglomerations and rural communities. The southern part of the Randstad is more
fragmented by such dividing lines than the northern part, which could partly
explain the diverging economic development between the two parts.",-0.15912779,0.2800902,0.07210068,C
667,"The computer simulations have motivated to further study the impact of the model parameter
β instead of γ.","The points and the shaded area are the average and the standard

    deviation of the time of convergence for 100 trajectories of 50 initial conﬁgurations for a given γ.","The latter only indirectly determines group eﬀects on the opinion dynamics by

     10/24
  N. Papanikolaou, G. Vaccario, E. Hormann, R. Lambiotte, F. Schweitzer:
Consensus from group interactions: An adaptive voter model on hypergraphs

                                  (Submitted for publication)

specifying whether inﬂuence takes place.",2022-01-17 14:18:39+00:00,Consensus from group interactions: An adaptive voter model on hypergraphs,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech', 'cs.MA', 'nlin.AO']","[arxiv.Result.Author('Nikos Papanikolaou'), arxiv.Result.Author('Giacomo Vaccario'), arxiv.Result.Author('Erik Hormann'), arxiv.Result.Author('Renaud Lambiotte'), arxiv.Result.Author('Frank Schweitzer')]","We study the effect of group interactions on the emergence of consensus in a
spin system. Agents with discrete opinions $\{0,1\}$ form groups. They can
change their opinion based on their group's influence (voter dynamics), but
groups can also split and merge (adaptation). In a hypergraph, these groups are
represented by hyperedges of different sizes. The heterogeneity of group sizes
is controlled by a parameter $\beta$. To study the impact of $\beta$ on
reaching consensus, we provide extensive computer simulations and compare them
with an analytic approach for the dynamics of the average magnetization. We
find that group interactions amplify small initial opinion biases, accelerate
the formation of consensus and lead to a drift of the average magnetization.
The conservation of the initial magnetization, known for basic voter models, is
no longer obtained.",0.19338252,-0.10182712,0.28036147,A
701,These studies all suggest useful directions for further research.,"Furthermore, O’Brien and Gleeson
(2021) propose an alternative way to analyze snooker player rankings, based on complex
networks.","As a final note, in the year 1935, when Zipf first described his findings of an inverse
relationship between word frequency and rank, there was only one professional snooker
tournament held: the world championship.",2022-01-18 08:40:52+00:00,Snooker Statistics and Zipf's Law,physics.soc-ph,['physics.soc-ph'],[arxiv.Result.Author('Wim Hordijk')],"Zipf's law is well known in linguistics: the frequency of a word is inversely
proportional to its rank. This is a special case of a more general power law, a
common phenomenon in many kinds of real-world statistical data. Here, it is
shown that snooker statistics also follow such a mathematical pattern, but with
varying (estimated) parameter values. Two types of rankings (prize money earned
and centuries scored), and three time-frames (all-time, decade, and year) are
considered. The results indicate that the power law parameter values depend on
the type of ranking used as well as the time-frame considered. Furthermore, in
some cases the resulting parameter values vary significantly over time, for
which a plausible explanation is provided.",-0.052340392,-0.26511675,0.13149849,B
702,These studies all suggest useful directions for further research.,"Furthermore, O’Brien and Gleeson
(2021) propose an alternative way to analyze snooker player rankings, based on complex
networks.","As a final note, in the year 1935, when Zipf first described his findings of an inverse
relationship between word frequency and rank (Zipf 1935), there was only one
professional snooker tournament held: the world championship.",2022-01-18 08:40:52+00:00,Snooker Statistics and Zipf's Law,physics.soc-ph,['physics.soc-ph'],[arxiv.Result.Author('Wim Hordijk')],"Zipf's law is well known in linguistics: the frequency of a word is inversely
proportional to its rank. This is a special case of a more general power law, a
common phenomenon in many kinds of real-world statistical data. Here, it is
shown that snooker statistics also follow such a mathematical pattern, but with
varying (estimated) parameter values. Two types of rankings (prize money earned
and centuries scored), and three time-frames (all-time, decade, and year) are
considered. The results indicate that the power law parameter values depend on
the type of ranking used as well as the time-frame considered. Furthermore, in
some cases the resulting parameter values vary significantly over time, for
which a plausible explanation is provided.",-0.03762644,-0.2604879,0.13130495,B
739,"This topic merits
further study and perhaps more sophisticated framework for amenity accessibility
that takes into account local vs regional amenities as well (similar to [30]).","We could interpret this as suggesting, for example
in the case of car trip duration, is that what matters is not so much the presence
of further away amenities, but the absence of nearby amenities.","Overall, our ﬁndings generate important nuance in the debate on the development
of more walkable neighbourhoods via bringing residents closer to amenities (""15
minute cities” or ""walkable mixed use communities”).",2022-01-18 18:35:31+00:00,"Are neighbourhood amenities associated with more walking and less driving? Yes, but only for the wealthy",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Samuel Heroy'), arxiv.Result.Author('Isabella Loaiza'), arxiv.Result.Author('Alex Pentland'), arxiv.Result.Author(""Neave O'Clery"")]","Cities are home to a vast array of amenities, from local barbers to science
museums and shopping malls. But these are inequality distributed across urban
space. Using Google Places data combined with trip-based mobility data for
Bogot\'a, Colombia, we shed light on the impact of neighbourhood amenities on
urban mobility patterns. Deriving a new accessibility metric that explicitly
takes into account spatial range, we find that a higher density of local
amenities is associated a higher likelihood of walking as well as shorter bus
and car trips. Digging deeper, we use a sample stratification framework to show
that socioeconomic status (SES) modulates these effects. Amenities within about
a 1km radius are strongly associated with a higher propensity to walk and lower
driving time only for only the wealthiest group. In contrast, a higher density
of amenities is associated with shorter bus trips for low and middle SES
residents. As cities globally aim to boost public transport and green travel,
these findings enable us to better understand how commercial structure shapes
urban mobility in highly income-segregated settings.",-0.30349702,0.49607337,-0.007040387,C
945,"However, a further study by Lancichinetti
and Fortunato [7] pointed out that the resolution limit problem is actually induced simultaneously
by two opposite tendencies: the tendency of merging small clusters, and the tendency of breaking
large ones.","The former uses a tunable parameter to alter the resolution, and enables the
detection for communities of different levels in different resolution scales, while the latter refrains
from using a “null model” to avoid the resolution limit.","When communities in a network have very different sizes, it becomes impossible for an
optimization procedure, no matter modularity-based or Hamiltonian-based, to avoid both biases
simultaneously.",2022-01-24 09:32:39+00:00,Automatic detection of multilevel communities in complex networks with a scalable community fitness function,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Kun Gao'), arxiv.Result.Author('Xuezao Ren'), arxiv.Result.Author('Lei Zhou'), arxiv.Result.Author('Junfang Zhu')]","Community detection in complex networks has been held back by two obstacles:
the resolution limit problem, which restrains simultaneous detection for
communities of heterogeneous sizes, and the divergent outputs of heuristic
algorithm, which are unfavorable for differentiating more relevant and
significant results. In this paper, we propose a renewed method for community
detection with a multiresolution and rescalable community fitness function. The
scalability of the community fitness function on the one hand exempts our
method from the resolution limit problem in heterogeneous networks, and on the
other hand enables our method to detect multilevel community structures in deep
hierarchical networks. Furthermore, we suggest a strict definition of
""plateau,"" with which we evaluate the stability of the outputs, and remove
unstable and irrelevant ones automatically, without any artificial or arbitrary
selection. As a result, our method outperforms most previous methods; it
reproduces the expected community structures accurately for various classes of
synthetic networks, as well as the ground truths for real-world networks.",0.25863945,-0.05466076,0.014337435,A
946,"However, a further study by Lancichinetti
and Fortunato [7] pointed out that the resolution limit problem is actually induced simultaneously
by two opposite tendencies: the tendency of merging small clusters, and the tendency of breaking
large ones.","The former uses a tunable parameter to alter the resolution, and enables the
detection on communities of different levels in different resolution scales, while the latter refrains
from using a “null model” to avoid the resolution limit.","When communities in a same network have very different sizes, it becomes impossible
for an optimization method, no matter modularity-based or Hamiltonian-based, to avoid both biases
simultaneously.",2022-01-24 09:32:39+00:00,Automatic detection of multilevel communities: scalable and resolution-limit-free,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Kun Gao'), arxiv.Result.Author('Xuezao Ren'), arxiv.Result.Author('Lei Zhou'), arxiv.Result.Author('Junfang Zhu')]","Community detection in complex networks has been hindered by two defects: (1)
the resolution limit problem, which restrains simultaneous detection for
communities of heterogeneous sizes, and (2) divergent outputs of the
optimization algorithm, which set hurdles for the differentiation of more
relevant and significant results. In this paper, we suggest a renewed method
for community detection via a scalable community fitness function. Due to its
scalability, this method is on the one hand free of the resolution limit
problem, even in large heterogeneous networks, and on the other hand capable of
detecting multiple levels of communities in deep hierarchical networks.
Moreover, we propose a strict definition for the term ""plateau,"" which has been
always loosely used in previous literature, to help us remove random and
irrelevant outputs automatically--without any artificial selection. As a
result, our method has ""neat"" outputs that include only stable and informative
plateaus. On synthetic networks with prearranged community structures, our
method outperforms most previous methods by recreating the prearranged
communities accurately, while on real-world networks, it discovers reasonable
community structures that fit the ground truth we already know about the
network.",0.24879804,-0.06050621,0.0077021904,A
1058,"This could then be employed to make a quantitative
comparison with other socio-economic or environmental factors [44] to uncover their relationship
and help in building simulation models for further study.","Beyond urban practitioners to the wider community of urban planning research, the
methodology developed in this work can also allow the quantiﬁcation of the spatial organisation of
the built element in functional urban areas.","12
5 Conclusions

In this work, we investigate the network presentation of actual roads by assessing both the
structural and spatial properties of the network.",2022-01-26 14:03:12+00:00,Urban Landscape from the Structure of Road Network: A Complexity Perspective,physics.soc-ph,"['physics.soc-ph', 'cs.CY', 'J.1; K.4']","[arxiv.Result.Author('Hoai Nguyen Huynh'), arxiv.Result.Author('Muhamad Azfar Bin Ramli')]","Spatial road networks have been widely employed to model the structure and
connectivity of cities. In such representation, the question of spatial scale
of the entities in the network, i.e. what its nodes and edges actually embody
in reality, is of particular importance so that redundant information can be
identified and eliminated to provide an improved understanding of city
structure. To address this, we investigate in this work the relationship
between the spatial scale of the modelled network entities against the amount
of useful information contained within it. We employ an entropy measure from
complexity science and information theory to quantify the amount of information
residing in each presentation of the network subject to the spatial scale and
show that it peaks at some intermediate scale. The resulting network
presentation would allow us to have direct intuition over the hierarchical
structure of the urban organisation, which is otherwise not immediately
available from the traditional simple road network presentation. We demonstrate
our methodology on the Singapore road network and find the critical spatial
scale to be 85 m, at which the network obtained corresponds very well to the
planning boundaries used by the local urban planners, revealing the essential
urban connectivity structure of the city. Furthermore, the complexity measure
is also capable of informing the secondary transitions that correspond well to
higher-level hierarchical structures associated with larger-scale urban
planning boundaries in Singapore.",0.15447626,0.33035713,-0.13978918,C
1105,"By the time better methods are developed (which is left for
further research), we suggest that for small sample sizes, the estimated values should be used with caution.","This is
why we restrict ourselves only to the three above methods.",4.,2022-01-27 11:49:32+00:00,"Power Laws, the Price Model, and the Pareto type-2 Distribution",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Grzegorz Siudem'), arxiv.Result.Author('Przemysław Nowak'), arxiv.Result.Author('Marek Gagolewski')]","We consider a version of the D.J.Price's model for the growth of a
bibliographic network, where in each iteration a constant number of citations
is randomly allocated according to a weighted combination of accidental
(uniformly distributed) and preferential (rich-get-richer) rules. Instead of
relying on the typical master equation approach, we formulate and solve this
problem in terms of the rank-size distribution. We show that, asymptotically,
such a process leads to a Pareto-type 2 distribution with an appealingly
interpretable parametrisation. We prove that the solution to the Price model
expressed in terms of the rank-size distribution coincides with the expected
values of order statistics in an independent Paretian sample. We study the bias
and the mean squared error of three well-behaving estimators of the underlying
model parameters. An empirical analysis of a large repository of academic
papers yields a good fit not only in the tail of the distribution (as it is
usually the case in the power law-like framework), but also across the whole
domain. Interestingly, the estimated models indicate higher degree of
preferentially attached citations and smaller share of randomness than previous
studies.",-0.21569917,0.051907714,0.02944721,B
1106,"Still, we leave the empirical study of data from diﬀerent domains
(e.g., data from linguistics, economics, cellular biology, communication networks, ecology, transport, modelling of
extreme weather events) for further research.","Therefore, we expect that for all the power law-like
datasets (e.g., considered in [8, 31]) we enjoy a ﬁt of the same or better quality, because we can always truncate at
which yields a good power law-ﬁt and assume = 1.","Future work will also involve the construction of usable estimators of and for small, discretised samples.",2022-01-27 11:49:32+00:00,"Power Laws, the Price Model, and the Pareto type-2 Distribution",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Grzegorz Siudem'), arxiv.Result.Author('Przemysław Nowak'), arxiv.Result.Author('Marek Gagolewski')]","We consider a version of the D.J.Price's model for the growth of a
bibliographic network, where in each iteration a constant number of citations
is randomly allocated according to a weighted combination of accidental
(uniformly distributed) and preferential (rich-get-richer) rules. Instead of
relying on the typical master equation approach, we formulate and solve this
problem in terms of the rank-size distribution. We show that, asymptotically,
such a process leads to a Pareto-type 2 distribution with an appealingly
interpretable parametrisation. We prove that the solution to the Price model
expressed in terms of the rank-size distribution coincides with the expected
values of order statistics in an independent Paretian sample. We study the bias
and the mean squared error of three well-behaving estimators of the underlying
model parameters. An empirical analysis of a large repository of academic
papers yields a good fit not only in the tail of the distribution (as it is
usually the case in the power law-like framework), but also across the whole
domain. Interestingly, the estimated models indicate higher degree of
preferentially attached citations and smaller share of randomness than previous
studies.",-0.011959506,0.056458883,0.06493456,A
1107,"By the time better methods are developed (which is left for
further research), we suggest that for small sample sizes, the estimated values should be used with caution.","This is
why we restrict ourselves only to the three above methods.",4.,2022-01-27 11:49:32+00:00,"Power Laws, the Price Model, and the Pareto type-2 Distribution",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Grzegorz Siudem'), arxiv.Result.Author('Przemysław Nowak'), arxiv.Result.Author('Marek Gagolewski')]","We consider a version of D. Price's model for the growth of a bibliographic
network, where in each iteration a constant number of citations is randomly
allocated according to a weighted combination of accidental (uniformly
distributed) and preferential (rich-get-richer) rules. Instead of relying on
the typical master equation approach, we formulate and solve this problem in
terms of the rank-size distribution. We show that, asymptotically, such a
process leads to a Pareto-type 2 distribution with an appealingly interpretable
parametrisation. We prove that the solution to the Price model expressed in
terms of the rank-size distribution coincides with the expected values of order
statistics in an independent Paretian sample. We study the bias and the mean
squared error of three well-behaving estimators of the underlying model
parameters. An empirical analysis of a large repository of academic papers
yields a good fit not only in the tail of the distribution (as it is usually
the case in the power law-like framework), but also across the whole domain.
Interestingly, the estimated models indicate higher degree of preferentially
attached citations and smaller share of randomness than previous studies.",-0.21569917,0.051907714,0.02944721,B
1108,"Still, we leave the empirical study of data from diﬀerent domains
(e.g., data from linguistics, economics, cellular biology, communication networks, ecology, transport, modelling of
extreme weather events) for further research.","Therefore, we expect that for all the power law-like
datasets (e.g., considered in [8, 31]) we enjoy a ﬁt of the same or better quality, because we can always truncate at
which yields a good power law-ﬁt and assume = 1.","Future work will also involve the construction of usable estimators of and for small, discretised samples.",2022-01-27 11:49:32+00:00,"Power Laws, the Price Model, and the Pareto type-2 Distribution",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Grzegorz Siudem'), arxiv.Result.Author('Przemysław Nowak'), arxiv.Result.Author('Marek Gagolewski')]","We consider a version of D. Price's model for the growth of a bibliographic
network, where in each iteration a constant number of citations is randomly
allocated according to a weighted combination of accidental (uniformly
distributed) and preferential (rich-get-richer) rules. Instead of relying on
the typical master equation approach, we formulate and solve this problem in
terms of the rank-size distribution. We show that, asymptotically, such a
process leads to a Pareto-type 2 distribution with an appealingly interpretable
parametrisation. We prove that the solution to the Price model expressed in
terms of the rank-size distribution coincides with the expected values of order
statistics in an independent Paretian sample. We study the bias and the mean
squared error of three well-behaving estimators of the underlying model
parameters. An empirical analysis of a large repository of academic papers
yields a good fit not only in the tail of the distribution (as it is usually
the case in the power law-like framework), but also across the whole domain.
Interestingly, the estimated models indicate higher degree of preferentially
attached citations and smaller share of randomness than previous studies.",-0.011959506,0.056458883,0.06493456,A
1417,"6, which also concludes the paper
and provides an outlook to further research challenges.","The
limitations of the study are discussed in Sec.",2.,2022-02-02 10:39:26+00:00,Getting more with less? Why repowering onshore wind farms does not always lead to more wind power generation -- a German case study,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Jan Frederick Unnewehr'), arxiv.Result.Author('Eddy Jalbout'), arxiv.Result.Author('Christopher Jung'), arxiv.Result.Author('Dirk Schindler'), arxiv.Result.Author('Anke Weidlich')]","The best wind locations are nowadays often occupied by old, less efficient
and relatively small wind turbines. Many of them will soon reach the end of
their operating lifetime, or lose financial support. Therefore, repowering
comes to the fore. However, social acceptance and land use restrictions have
been under constant change since the initial expansions, which makes less area
available for new turbines, even on existing sites. For the example of Germany,
this study assesses the repowering potential for onshore wind energy in high
detail, on the basis of regionally differentiated land eligibility criteria.
The results show that under the given regional criteria, repowering will
decrease both operating capacity and annual energy yield by roughly 40\,\%
compared to the status quo. This is because around half of the wind turbines
are currently located in restricted areas, given newly enacted exclusion
criteria. Sensitivity analyses on the exclusion criteria show that the minimum
distance to discontinuous urban fabric is the most sensitive criterion in
determining the number of turbines that can be repowered. As regulations on
this can vary substantially across different regions, the location-specific
methodology chosen here can assess the repowering potential more realistically
than existing approaches.",-0.28621036,-0.0698497,-0.01807029,B_centroid
1418,"These
criteria, and potential other land use conﬂicts, are of interest for further research.","Besides, other
exclusion criteria can play a role in the approval of WT installations, such as
public acceptance of a wind power project by the local community and by the
land owners, priority areas for agriculture, or settlement development.","Independent from the current regulation, this work provides a methodolog-
ical approach for assessing the repowering potential for onshore wind power
generation at a high level of accuracy.",2022-02-02 10:39:26+00:00,Getting more with less? Why repowering onshore wind farms does not always lead to more wind power generation -- a German case study,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Jan Frederick Unnewehr'), arxiv.Result.Author('Eddy Jalbout'), arxiv.Result.Author('Christopher Jung'), arxiv.Result.Author('Dirk Schindler'), arxiv.Result.Author('Anke Weidlich')]","The best wind locations are nowadays often occupied by old, less efficient
and relatively small wind turbines. Many of them will soon reach the end of
their operating lifetime, or lose financial support. Therefore, repowering
comes to the fore. However, social acceptance and land use restrictions have
been under constant change since the initial expansions, which makes less area
available for new turbines, even on existing sites. For the example of Germany,
this study assesses the repowering potential for onshore wind energy in high
detail, on the basis of regionally differentiated land eligibility criteria.
The results show that under the given regional criteria, repowering will
decrease both operating capacity and annual energy yield by roughly 40\,\%
compared to the status quo. This is because around half of the wind turbines
are currently located in restricted areas, given newly enacted exclusion
criteria. Sensitivity analyses on the exclusion criteria show that the minimum
distance to discontinuous urban fabric is the most sensitive criterion in
determining the number of turbines that can be repowered. As regulations on
this can vary substantially across different regions, the location-specific
methodology chosen here can assess the repowering potential more realistically
than existing approaches.",-0.27801475,-0.044645958,-0.22771391,B
2198,"Given that
communities of color in Chicago are more likely to be underserved in relation to job accessibility, transit
supply, and on-demand mobility access, we believe this finding is likely a reflection of gaps in access to
resources in areas with lower shares of White residents rather than of a lower willingness to use ridesourcing
during disruptions, but further research is warranted to gain deeper understanding.","This finding adds to existing evidence that
                                                                                                                                         18

ridesourcing provides greater benefits to privileged user groups (Zhang & Zhang, 2018).","Additionally, a novel effect is found related to the proportion of transit commuters in the community
area and the disruption source.",2022-02-18 22:54:09+00:00,Does ridesourcing respond to unplanned rail disruptions? A natural experiment analysis of mobility resilience and disparity,physics.soc-ph,"['physics.soc-ph', 'stat.AP']","[arxiv.Result.Author('Elisa Borowski'), arxiv.Result.Author('Jason Soria'), arxiv.Result.Author('Joseph Schofer'), arxiv.Result.Author('Amanda Stathopoulos')]","Urban rail transit networks provide critical access to opportunities and
livelihood in many urban systems. Ensuring that these services are resilient
(that is, exhibiting efficient response to and recovery from disruptions) is a
key economic and social priority. Increasingly, the ability of urban rail
systems to cope with disruptions is a function of a complex patchwork of
mobility options, wherein alternative modes can complement and fill service
gaps. This study analyzes the role of ridesourcing in providing adaptive
mobility capacity that could be leveraged to fill no-notice gaps in rail
transit services, addressing the question of distributional impacts of
resilience. Using a natural experiment, we systematically identify 28 major
transit disruptions over the period of one year in Chicago and match them, both
temporally and spatially, with ridesourcing trip data. Using multilevel mixed
modeling, we quantify variation in the adaptive use of on-demand mobility
across the racially and economically diverse city of Chicago. Our findings show
that the gap-filling potential of adaptive ridesourcing during rail transit
disruptions is significantly influenced by station-, community-, and
district-level factors. Specifically, greater shifts to ridesourcing occur
during weekdays, nonholidays, and more severe disruptions, in community areas
that have higher percentages of White residents and transit commuters, and in
the more affluent North district of the city. These findings suggest that while
ridesourcing appears to provide adaptive capacity during rail disruptions, its
benefits do not appear to be equitable for lower-income communities of color
that already experience limited mobility options.",-0.15890107,0.4768548,0.006980866,C
2232,"We further study the classiﬁcation of RESS = max 1, 1c + 1−αα
as an evolutionarily-stable strategy and convergence stable strategy using the relevant conditions
on the local selection gradient in Appendix B.2.","As a result, the selection gradient is always decreasing and Rr = 1 is the resulting ESS level of so-
ciality when Equation (4.15) holds.","In Table 1, we compare the evolutionarily-stable and socially-optimal levels of sociality RESS and
Ropt for the diﬀerent possible values of the relative spreading abilities for the good and bad con-
tagion c and the weight α placed upon the good and bad contagion in the Cobb-Douglas utility.",2022-02-20 20:36:09+00:00,Social dilemmas of sociality due to beneficial and costly contagion,physics.soc-ph,"['physics.soc-ph', 'q-bio.PE', '91A22, 92D15, 92D30']","[arxiv.Result.Author('Daniel B. Cooney'), arxiv.Result.Author('Dylan H. Morris'), arxiv.Result.Author('Simon A. Levin'), arxiv.Result.Author('Daniel I. Rubenstein'), arxiv.Result.Author('Pawel Romanczuk')]","Levels of sociality in nature vary widely. Some species are solitary; others
live in family groups; some form complex multi-family societies. Increased
levels of social interaction can allow for the spread of useful innovations and
beneficial information, but can also facilitate the spread of harmful
contagions, such as infectious diseases. It is natural to assume that these
contagion processes shape the evolution of complex social systems, but an
explicit account of the dynamics of sociality under selection pressure imposed
by contagion remains elusive.
  We consider a model for the evolution of sociality strategies in the presence
of both a beneficial and costly contagion. We study the dynamics of this model
at three timescales: using a susceptible-infectious-susceptible (SIS) model to
describe contagion spread for given sociality strategies, a replicator equation
to study the changing fractions of two different levels of sociality, and an
adaptive dynamics approach to study the long-time evolution of the population
level of sociality.
  For a wide range of assumptions about the benefits and costs of infection, we
identify a social dilemma: the evolutionarily-stable sociality strategy (ESS)
is distinct from the collective optimum -- the level of sociality that would be
best for all individuals. In particular, the ESS level of social interaction is
greater (respectively less) than the social optimum when the good contagion
spreads more (respectively less) readily than the bad contagion.
  Our results shed light on how contagion shapes the evolution of social
interaction, but reveals that evolution may not necessarily lead populations to
social structures that are good for any or all.",0.061855115,-0.17562917,0.3255434,A
2233,"(3.19)
                                               c 1−α

We further study the classiﬁcation of R(EgS)S as an evolutionarily-stable strategy and convergence
stable strategy using the relevant conditions on the local selection gradient in Appendix B.","Therefore we ﬁnd that our evolutionarily-stable strategy has
the following piecewise characterization

                            (g)                 1α
                            RESS = max      1, +      .","In Table 1, we compare the evolutionarily-stable and socially-optimal levels of sociality R(EgS)S and
R(ogp)t for the diﬀerent possible values of the relative spreading abilities for the good and bad con-
tagion c and the weight α placed upon the good and bad contagion in the Cobb-Douglas utility.",2022-02-20 20:36:09+00:00,Social dilemmas of sociality due to beneficial and costly contagion,physics.soc-ph,"['physics.soc-ph', 'q-bio.PE', '91A22, 92D15, 92D30']","[arxiv.Result.Author('Daniel B. Cooney'), arxiv.Result.Author('Dylan H. Morris'), arxiv.Result.Author('Simon A. Levin'), arxiv.Result.Author('Daniel I. Rubenstein'), arxiv.Result.Author('Pawel Romanczuk')]","Levels of sociality in nature vary widely. Some species are solitary; others
live in family groups; some form complex multi-family societies. Increased
levels of social interaction can allow for the spread of useful innovations and
beneficial information, but can also facilitate the spread of harmful
contagions, such as infectious diseases. It is natural to assume that these
contagion processes shape the evolution of complex social systems, but an
explicit account of the dynamics of sociality under selection pressure imposed
by contagion remains elusive.
  We consider a model for the evolution of sociality strategies in the presence
of both a beneficial and costly contagion. We study the dynamics of this model
at three timescales: using a susceptible-infectious-susceptible (SIS) model to
describe contagion spread for given sociality strategies, a replicator equation
to study the changing fractions of two different levels of sociality, and an
adaptive dynamics approach to study the long-time evolution of the population
level of sociality.
  For a wide range of assumptions about the benefits and costs of infection, we
identify a social dilemma: the evolutionarily-stable sociality strategy (ESS)
is distinct from the collective optimum -- the level of sociality that would be
best for all individuals. In particular, the ESS level of social interaction is
greater (respectively less) than the social optimum when the good contagion
spreads more (respectively less) readily than the bad contagion.
  Our results shed light on how contagion shapes the evolution of social
interaction, but reveals that evolution may not necessarily lead populations to
social structures that are good for any or all.",0.052724943,-0.16356559,0.30234358,A
2561,"If a team can control an attack in the ﬁrst
as we know, the largest open collection of volleyball-logs                                                                                  5
ever released, an invaluable resource for the research
community that opens the door for further research in              team behavior through many indirect variables [22–25],
this area.","We can explain this
non-trivial behavior by analyzing the natural dynamics
of the game.","Finally, we want to point out that our ﬁndings          our results can be handy for designing new eﬃcient
provide new knowledge that should be actively taken                data-driven training systems aiming to enhance the
into account for sports scientists and coaches.",2022-02-18 00:10:04+00:00,Simple mechanism rules the dynamics of volleyball,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('A. Chacoma'), arxiv.Result.Author('O. V. Billoni')]","In this work, we study the emergence of complexity in the game of volleyball.
To do so, we first collected data from 20 high-level professional games. Then
we conducted a data-driven analysis from where we identified fundamental
insights that we used to define a parsimonious stochastic model. On these
bases, we show that it is possible to give a closed-form expression for the
probability that the players perform n hits in a rally using only two
stochastic variables. Our results fully agree with empirical observation,
representing a new advance in the comprehension of team-sports competition
complexity and dynamics.",-0.09105744,-0.18827735,0.59586966,A
2562,"Moreover,
the collected data that we make publicly available with this work is, as far as we know,
the largest open collection of volleyball-logs ever released, an invaluable resource for the
research community that opens the door for further research in this area.","In this regard, we consider that this work represents a new step
towards a broad understanding of volleyball games as complex adaptive systems.","Finally, we want
to point out that our ﬁndings provide new knowledge that should be actively taken into
account for sports scientists and coaches.",2022-02-18 00:10:04+00:00,Simple mechanism rules the dynamics of volleyball,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('A. Chacoma'), arxiv.Result.Author('O. V. Billoni')]","In volleyball games, we define a rally as the succession of events observed
since the ball is served until one of the two teams on the court scores the
point. In this process, athletes evolve in response to physical and information
constraints, spanning several spatiotemporal scales and interplaying
co-adaptively with the environment. Aiming to study the emergence of complexity
in this system, we carried out a study focused on three steps: data collection,
data analysis, and modeling. First, we collected data from 20 high-level
professional volleyball games. Then we conducted a data-driven analysis from
where we identified fundamental insights that we used to define a parsimonious
stochastic model for the dynamics of the game. On these bases, we show that it
is possible to give a closed-form expression for the probability that the
players perform n hits in a rally using only two stochastic variables. Our
results fully agree with the empirical observations and represent a new advance
in the comprehension of team-sports competition complexity and dynamics.",-0.14213552,-0.18651876,0.60438526,A
2563,"Moreover,
the collected data that we make publicly available with this work is, as far as we know,
the largest open collection of volleyball-logs ever released, an invaluable resource for the
research community that opens the door for further research in this area.","In this regard, we consider that this work represents a new step
towards a broad understanding of volleyball games as complex adaptive systems.","Finally, we want
to point out that our ﬁndings provide new knowledge that should be actively taken into
account for sports scientists and coaches.",2022-02-18 00:10:04+00:00,Simple mechanism rules the dynamics of volleyball,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('A. Chacoma'), arxiv.Result.Author('O. V. Billoni')]","In volleyball games, we define a rally as the succession of events observed
since the ball is served until one of the two teams on the court scores the
point. In this process, athletes evolve in response to physical and information
constraints, spanning several spatiotemporal scales and interplaying
co-adaptively with the environment. Aiming to study the emergence of complexity
in this system, we carried out a study focused on three steps: data collection,
data analysis, and modeling. First, we collected data from 20 high-level
professional volleyball games. Then we conducted a data-driven analysis from
where we identified fundamental insights that we used to define a parsimonious
stochastic model for the dynamics of the game. On these bases, we show that it
is possible to give a closed-form expression for the probability that the
players perform n hits in a rally using only two stochastic variables. Our
results fully agree with the empirical observations and represent a new advance
in the comprehension of team-sports competition complexity and dynamics.",-0.14213552,-0.18651876,0.60438526,A
2564,"Moreover,
the collected data that we make publicly available with this work is, as far as we know,
the largest open collection of volleyball-logs ever released, an invaluable resource for the
research community that opens the door for further research in this area.","In this regard, we consider that this work represents a new step
towards a broad understanding of volleyball games as complex adaptive systems.","Finally, we want
to point out that our ﬁndings provide new knowledge that should be actively taken into
account for sports scientists and coaches.",2022-02-18 00:10:04+00:00,Simple mechanism rules the dynamics of volleyball,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('A. Chacoma'), arxiv.Result.Author('O. V. Billoni')]","In volleyball games, we define a rally as the succession of events observed
since the ball is served until one of the two teams on the court scores the
point. In this process, athletes evolve in response to physical and information
constraints, spanning several spatiotemporal scales and interplaying
co-adaptively with the environment. Aiming to study the emergence of complexity
in this system, we carried out a study focused on three steps: data collection,
data analysis, and modeling. First, we collected data from 20 high-level
professional volleyball games. Then we conducted a data-driven analysis from
where we identified fundamental insights that we used to define a parsimonious
stochastic model for the dynamics of the game. On these bases, we show that it
is possible to give a closed-form expression for the probability that the
players perform n hits in a rally using only two stochastic variables. Our
results fully agree with the empirical observations and represent a new advance
in the comprehension of team-sports competition complexity and dynamics.",-0.14213552,-0.18651876,0.60438526,A
2651,"This quantity gives us a tool to identify local
activation and further study the localization phenomenon33.","Borrowing tools from statistical physics and the study
of phase transitions, we can use the derivative of local prevalence per layer as a proxy for the susceptibility (here used in the
statistical mechanics sense: the response of a system to changes in parameters).","Figure 3(a) presents the prevalence diagram on a tree with only
5 layers.",2022-03-01 21:07:29+00:00,Hierarchical team structure and multidimensional localization (or siloing) on networks,physics.soc-ph,"['physics.soc-ph', 'cs.MA', 'cs.SI', 'nlin.AO']","[arxiv.Result.Author('Laurent Hébert-Dufresne'), arxiv.Result.Author('Guillaume St-Onge'), arxiv.Result.Author('John Meluso'), arxiv.Result.Author('James Bagrow'), arxiv.Result.Author('Antoine Allard')]","Knowledge silos emerge when structural properties of organizational
interaction networks limit the diffusion of information. These structural
barriers are known to take many forms at different scales - hubs in otherwise
sparse organisations, large dense teams, or global core-periphery structure -
but we lack an understanding of how these different structures interact. Here
we bridge the gap between the mathematical literature on localization of
spreading dynamics and the more applied literature on knowledge silos in
organizational interaction networks. To do so, we introduce a new model that
considers a layered structure of teams to unveil a new form of hierarchical
localization (i.e., the localization of information at the top or center of an
organization) and study its interplay with known phenomena of mesoscopic
localization (i.e., the localization of information in large groups), $k$-core
localization (i.e., around denser $k$-cores) and hub localization (i.e., around
high degree stars). We also include a complex contagion mechanism by
considering a general infection kernel which can depend on hierarchical level
(influence), degree (popularity), infectious neighbors (social reinforcement)
or team size (importance). This general model allows us to study the
multifaceted phenomenon of information siloing in complex organizational
interaction networks and opens the door to new optimization problems to promote
or hinder the emergence of different localization regimes.",0.18441314,-0.057903215,0.009667359,A
2959,"(23) for q˙ = 0 allows estimating
lytical treatment, but its study is left for further research.","(17) as ∆r ∼ (ωi/ki − ωj/kj)2 also induces
the explosive phenomena and may simplify the ana-                   Solving the implicit Eq.",the phases of the oscillators in Eq.,2022-03-07 21:28:14+00:00,Self-organized explosive synchronization in complex networks: Emergence of synchronization bombs,physics.soc-ph,"['physics.soc-ph', 'nlin.AO']","[arxiv.Result.Author('Lluís Arola-Fernández'), arxiv.Result.Author('Sergio Faci-Lázaro'), arxiv.Result.Author('Per Sebastian Skardal'), arxiv.Result.Author('Emanuel-Cristian Boghiu'), arxiv.Result.Author('Jesús Gómez-Gardeñes'), arxiv.Result.Author('Alex Arenas')]","We introduce the concept of synchronization bombs as large networks of
coupled heterogeneous oscillators that operate in a bistable regime and
abruptly transit from incoherence to phase-locking (or vice-versa) by adding
(or removing) one or a few links. Here we build a self-organized and stochastic
version of these bombs, by optimizing global synchrony with decentralized
information in a competitive link-percolation process driven by a local rule.
We find explosive fingerprints on the emerging network structure, including
frequency-degree correlations, disassortative patterns and a delayed
percolation threshold. We show that these bomb-like transitions can be designed
both in systems of Kuramoto -- periodic -- and R\""ossler -- chaotic --
oscillators and in a model of cardiac pacemaker cells. We analytically
characterize the transitions in the Kuramoto case by combining a precise
collective coordinates approach and the Ott-Antonsen ansatz. Furthermore, we
study the robustness of the phenomena under changes in the main parameters and
the unexpected effect of optimal noise in our model. Our results propose a
minimal self-organized mechanism of network growth to understand and control
explosive synchronization in adaptive biological systems like the brain and
engineered ones like power-grids or electronic circuits. From a theoretical
standpoint, the emergence of synchronization explosions and bistability induced
by localized structural perturbations -- without any fine-tuning of global
parameters -- joins explosive synchronization and percolation under the same
mechanistic framework.",-0.0110909995,-0.35131156,-0.015924972,A
3200,of further research.,"order interactions on dynamical processes, we would still        [9] G. Bianconi, Higher-Order Networks (Cambridge Uni-
like to bring forward some of the noteworthy routes                  versity Press, 2021).","For instance, there are enough            [10] C. Giusti, R. Ghrist, and D. S. Bassett, Journal of Com-
scopes to contribute to the understanding of the tem-                putational Neuroscience 41, 1 (2016).",2022-03-13 08:59:33+00:00,Dynamics on higher-order networks: A review,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'nlin.AO', 'q-bio.PE']","[arxiv.Result.Author('Soumen Majhi'), arxiv.Result.Author('Matjaz Perc'), arxiv.Result.Author('Dibakar Ghosh')]","Network science has evolved into an indispensable platform for studying
complex systems. But recent research has identified limits of classical
networks, where links connect pairs of nodes, to comprehensively describe group
interactions. Higher-order networks, where a link can connect more than two
nodes, have therefore emerged as a new frontier in network science. Since group
interactions are common in social, biological, and technological systems,
higher-order networks have recently led to important new discoveries across
many fields of research. We here review these works, focusing in particular on
the novel aspects of the dynamics that emerges on higher-order networks. We
cover a variety of dynamical processes that have thus far been studied,
including different synchronization phenomena, contagion processes, the
evolution of cooperation, and consensus formation. We also outline open
challenges and promising directions for future research.",0.2119904,-0.15037817,0.078078106,A
3485,"We hope that this works provides awareness about information transmission biases and the simple
mathematical tools able to quantify them, so that further research can better understand how they emerge and ultimately
overcome them.","In conclusion, we have shown that contagion models beyond Simple Contagion can exhibit information transmission biases,
including echo chambers.","Methods

Measuring information transmission
As mentioned in the main text, the ﬁnal density of informed nodes within a group gt , when taking the seed node within a group
gs, coincides on average with the probability of information transmission from a source from gs to a target from gt .",2022-03-17 22:40:06+00:00,Echo chambers and information transmission biases in homophilic and heterophilic networks,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Fernando Diaz-Diaz'), arxiv.Result.Author('Maxi San Miguel'), arxiv.Result.Author('Sandro Meloni')]","We study how information transmission biases arise by the interplay between
the structural properties of the network and the dynamics of the information in
synthetic scale-free homophilic/heterophilic networks. We provide simple
mathematical tools to quantify these biases. Both Simple and Complex Contagion
models are insufficient to predict significant biases. In contrast, a Hybrid
Contagion model -- in which both Simple and Complex Contagion occur -- gives
rise to three different homophily-dependent biases: emissivity and receptivity
biases,and echo chambers. Simulations in an empirical network with high
homophily confirm the existence of these biases. Our results shed light into
the mechanisms that cause inequalities in the visibility of information
sources, reduced access to information, and lack of communication among
distinct groups.",0.23792207,-0.055867486,0.059092868,A
3513,"Tianjin-Hebei (BTH) and Yangtze River Delta (YRD) regions           Based on the weighted degree index, we further study the
have higher values in 2019.",We find that the value of weighted indegrees in the Beijing-     The influence of traffic to air pollution with pandemic.,"Compared with before the                influence of traffic to air pollution with pandemic in different
epidemic (2019), Beijing, Tianjin, Shijiazhuang, and                regions by constructing a multi-layer network between TL and
Changchun are all decreasing in North China, especially in          AQI.",2022-03-18 09:27:23+00:00,Network approach reveals the spatiotemporal influence of traffic to air pollution under the COVID-19,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Weiping Wang'), arxiv.Result.Author('Saini Yang'), arxiv.Result.Author('Kai Yin'), arxiv.Result.Author('Zhidan Zhao'), arxiv.Result.Author('Na Ying'), arxiv.Result.Author('Jingfang Fan')]","Air pollution causes widespread environmental and health problems and
severely hinders the life quality of urban residents. Traffic is a critical for
human life and its emissions are a major source of pollution, aggravating urban
air pollution. However, the complex interaction between the traffic emissions
and the air pollution in the cities has not yet been revealed. In particular,
the spread of the COVID-19 has caused various cities to implement different
traffic restriction policies according to the local epidemic situation, which
provides the possibility to explore the relationship between urban traffic and
air pollution. Here we explore the influence of traffic to air pollution by
reconstructing a multi-layer complex network base on traffic index and air
quality index. We uncover that air quality in Beijing-Tianjin-Hebei (BTH),
Chengdu-Chongqing Economic Circle (CCS) and Central China (CC) regions are
significantly influenced by the surrounding traffic conditions after the
outbreak. Under different fights against the epidemic stages, the influence of
traffic in other cities on the air pollution reached the maximum in stage 2
(also called Initial Progress in Containing the Virus). For BTH and CC regions,
the impact of traffic on air quality becomes larger in the first two stages and
then decreases, while for CC, the significant impact occurs in Phase 3 among
regions. For other regions, however, the changes are not evident. Our presented
network-based framework provides a new perspective in the field of
transportation and environment, and maybe helpful to guide the government to
formulate air pollution mitigation and traffic restriction policies.",0.07288181,0.29955655,-0.1250254,C
3514,"To further study the relationship between
                                                                      traffic and air pollution, we classify our datasets into 5 groups
                                                                      by using time intervals of these five stages.",normal as a whole.,"The Figure 4
                                                                      illustrates the the maps of weighted in- degrees for different
                                                                      stages.",2022-03-18 09:27:23+00:00,Network approach reveals the spatiotemporal influence of traffic to air pollution under the COVID-19,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Weiping Wang'), arxiv.Result.Author('Saini Yang'), arxiv.Result.Author('Kai Yin'), arxiv.Result.Author('Zhidan Zhao'), arxiv.Result.Author('Na Ying'), arxiv.Result.Author('Jingfang Fan')]","Air pollution causes widespread environmental and health problems and
severely hinders the life quality of urban residents. Traffic is a critical for
human life and its emissions are a major source of pollution, aggravating urban
air pollution. However, the complex interaction between the traffic emissions
and the air pollution in the cities has not yet been revealed. In particular,
the spread of the COVID-19 has caused various cities to implement different
traffic restriction policies according to the local epidemic situation, which
provides the possibility to explore the relationship between urban traffic and
air pollution. Here we explore the influence of traffic to air pollution by
reconstructing a multi-layer complex network base on traffic index and air
quality index. We uncover that air quality in Beijing-Tianjin-Hebei (BTH),
Chengdu-Chongqing Economic Circle (CCS) and Central China (CC) regions are
significantly influenced by the surrounding traffic conditions after the
outbreak. Under different fights against the epidemic stages, the influence of
traffic in other cities on the air pollution reached the maximum in stage 2
(also called Initial Progress in Containing the Virus). For BTH and CC regions,
the impact of traffic on air quality becomes larger in the first two stages and
then decreases, while for CC, the significant impact occurs in Phase 3 among
regions. For other regions, however, the changes are not evident. Our presented
network-based framework provides a new perspective in the field of
transportation and environment, and maybe helpful to guide the government to
formulate air pollution mitigation and traffic restriction policies.",0.031724475,0.3530038,0.037745938,C
3515,"Our results also
In this study, both single layer and multi-layers networks have          can call attention to further research on the impact of
been developed to explore the influence of traffic on air                transportation on air pollution.","Besides providing information for guiding government
                                                                         policies to improve air quality levels, the network parameters
V. CONCLUSIONS                                                           in this work are a profitable attempt in the field of
                                                                         transportation and atmospheric environment.","pollution during the pandemic based on complex network
approaches.",2022-03-18 09:27:23+00:00,Network approach reveals the spatiotemporal influence of traffic to air pollution under the COVID-19,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Weiping Wang'), arxiv.Result.Author('Saini Yang'), arxiv.Result.Author('Kai Yin'), arxiv.Result.Author('Zhidan Zhao'), arxiv.Result.Author('Na Ying'), arxiv.Result.Author('Jingfang Fan')]","Air pollution causes widespread environmental and health problems and
severely hinders the life quality of urban residents. Traffic is a critical for
human life and its emissions are a major source of pollution, aggravating urban
air pollution. However, the complex interaction between the traffic emissions
and the air pollution in the cities has not yet been revealed. In particular,
the spread of the COVID-19 has caused various cities to implement different
traffic restriction policies according to the local epidemic situation, which
provides the possibility to explore the relationship between urban traffic and
air pollution. Here we explore the influence of traffic to air pollution by
reconstructing a multi-layer complex network base on traffic index and air
quality index. We uncover that air quality in Beijing-Tianjin-Hebei (BTH),
Chengdu-Chongqing Economic Circle (CCS) and Central China (CC) regions are
significantly influenced by the surrounding traffic conditions after the
outbreak. Under different fights against the epidemic stages, the influence of
traffic in other cities on the air pollution reached the maximum in stage 2
(also called Initial Progress in Containing the Virus). For BTH and CC regions,
the impact of traffic on air quality becomes larger in the first two stages and
then decreases, while for CC, the significant impact occurs in Phase 3 among
regions. For other regions, however, the changes are not evident. Our presented
network-based framework provides a new perspective in the field of
transportation and environment, and maybe helpful to guide the government to
formulate air pollution mitigation and traffic restriction policies.",0.20267485,0.3916738,-0.22768712,C
3574,We will endeavour to investigate these possibilities in a further study.,"So diﬀerent Dobrynyas
                might have followed the same path as diﬀerent Volodymyrs and became a single
                character.","Appendix B: Bylyny giant component
                In Figure 3 we present the largest connected component of the bylyny network (in-
                cluding both friendly and hostile links) with vertices sized proportionate to node
                degree k. Prince Volodymyr (#52) and Illya Muromets’ (#46) have the highest
                degrees and corresponding nodes are largest.",2022-03-19 22:12:11+00:00,Network analysis of the Kyiv bylyny cycle -- east Slavic epic narratives,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Petro Sarkanych'), arxiv.Result.Author('Nazar Fedorak'), arxiv.Result.Author('Yurij Holovatch'), arxiv.Result.Author('Pádraig MacCarron'), arxiv.Result.Author('Joseph Yose'), arxiv.Result.Author('Ralph Kenna')]","Since the pioneering work of Joseph Campbell in the 1960's, universality
emerged as an important qualitative notion in the field of comparative
mythology. In recent times, the advent of network science permitted new
quantitative approaches to literary studies. Here we bring the Kyiv bylyny
cycle into the field -- East Slavic epic narratives originating in modern-day
Ukraine. By comparing them to other prominent European epics, we identify
universal and distinguishing properties of the social networks in bylyny. We
analyse community structures and rank most important characters. The method
allows to bolster hypotheses from humanities literature -- such as the solar
position of Prince Volodymyr -- and to generate new ones. We show how the Kyiv
cycle of bylyny fits very well with narrative networks from other nations --
especially heroic ones. We anticipate that, besides delivering new
narratological insights, this study will aid future scholars and interested
public to navigate their way through Ukraine's epic story and identify its
heroes.",0.296364,-0.28765604,-0.07582182,A
3575,We will endeavour to investigate these possibilities in a further study.,"So diﬀerent Dobrynyas
            might have followed the same path as diﬀerent Volodymyrs and became a single
            character.","Appendix B: Bylyny giant component

            In Figure 3 we present the largest connected component of the bylyny network (in-
            cluding both friendly and hostile links) with vertices sized proportionate to node
            degree k. Prince Volodymyr (#52) and Illya Muromets’ (#46) have the highest
            degrees and corresponding nodes are largest.",2022-03-19 22:12:11+00:00,Network analysis of the Kyiv bylyny cycle -- east Slavic epic narratives,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Petro Sarkanych'), arxiv.Result.Author('Nazar Fedorak'), arxiv.Result.Author('Yurij Holovatch'), arxiv.Result.Author('Pádraig MacCarron'), arxiv.Result.Author('Joseph Yose'), arxiv.Result.Author('Ralph Kenna')]","In recent times, the advent of network science permitted new quantitative
approaches to literary studies. Here we bring the Kyiv bylyny cycle into the
field - East Slavic epic narratives originating in modern-day Ukraine. By
comparing them to other prominent European epics, we identify universal and
distinguishing properties of the social networks in bylyny. We analyse
community structures and rank the most important characters. The method allows
to bolster hypotheses from humanities literature - such as the position of
Prince Volodymyr - and to generate new ones We show how the Kyiv cycle of
bylyny fits very well with narrative networks from other nations - especially
heroic ones. We anticipate that, besides delivering new narratological
insights, this study will aid future scholars and interested public to navigate
their way through Ukraine's epic story and identify its heroes.",0.296364,-0.28765604,-0.07582182,A
4242,"The equilibrium instability and indeterminacy should be
(c) q = 0.8                (d) q = 1                                           taken into account in understanding the dynamics of real-
                                                                               world social contagions, and I hope that the present work
                                                        0.08                   will stimulate further research in this direction.","While the average popularity of
0                                                       0                      each meme can be well approximated by the AME
                                                                               and MF methods, averaging is not appropriate when
 0 0.2 0.4ρ 0.6 0.8 1                                    0 0.2 0.4ρ 0.6 0.8 1  the spreading dynamics are described as a saddle path.","0.5
                                                                                  T. K. acknowledges ﬁnancial support from JSPS KAK-
Frequency0.4                                            0.06                   ENHI 19H01506 and 20H05633.",2022-04-02 08:14:31+00:00,Kinetics of competing social contagions: Symmetry breaking and equilibrium indeterminacy,physics.soc-ph,"['physics.soc-ph', 'cs.SI']",[arxiv.Result.Author('Teruyoshi Kobayashi')],"Complex contagion on social networks has been explained as a collective
outcome of threshold behaviors in which influence from local neighbors may
trigger a global cascade. However, it is largely unexplored what behavioral
rules best describe individuals' optimization and how spreading dynamics emerge
from them. Here, we develop a microfounded general threshold model that enables
us to analyze the collective dynamics of individual behavior in the propagation
of competing information/technologies (i.e., ""social memes""). The analysis
reveals that the popularities of competing memes in systems of finite size are
indeterminate since the propagation process follows a saddle path, leading to
symmetry breaking. It suggests that the virality of social memes may not be
attributed to their intrinsic attractiveness but rather to randomness in
network structure.",0.20044538,-0.106237225,0.14264396,A
4243,"A stable
late further research in this direction.","Let Gs be a function that represents the right-hand
     side of the MF equation (7) (i.e., ρ˙s = Gs(ρ)).","5
   T. K. acknowledges ﬁnancial support from JSPS KAK-
                                                               ENHI 19H01506 and 20H05633.",2022-04-02 08:14:31+00:00,Diffusion dynamics of competing information on networks,physics.soc-ph,"['physics.soc-ph', 'cs.SI']",[arxiv.Result.Author('Teruyoshi Kobayashi')],"Information diffusion on social networks has been described as a collective
outcome of threshold behaviors in the framework of threshold models. However,
since the existing models do not take into account individuals' optimization
problem, it remains an open question what dynamics emerge in the diffusion
process when individuals face multiple (and possibly incompatible) information.
Here, we develop a microfounded general threshold model that enables us to
analyze the collective dynamics of individual behavior in the propagation of
multiple information. The analysis reveals that the virality of competing
information is fundamentally indeterminate. When individuals maximize
coordination with neighbors, the diffusion process is described as a saddle
path, thereby leading to an unpredictable symmetry breaking. When individuals'
choices are irreversible, there is a continuum of stable equilibria where a
certain degree of social polarization takes place by chance.",0.0021408424,-0.14828932,0.017061371,A
4372,"In sum, for shared
microtransit services to succeed in mitigating externalities, further research is needed to understand
the tradeoffs travelers are willing to make to pool rides and optimal service implementation.","The Finnish pilot Kutsuplus found that substantial
subsidies were needed for the program to be financially viable (Rissanen, 2016).","2.3 Choice Experiment Analysis of Microtransit Features

         Stated choice research offers valuable insight on demand related to microtransit and
specific service features.",2022-04-05 04:00:35+00:00,Microtransit adoption in the wake of the COVID-19 pandemic: evidence from a choice experiment with transit and car commuters,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'econ.EM', 'stat.AP', 'J.4']","[arxiv.Result.Author('Jason Soria'), arxiv.Result.Author('Shelly Etzioni'), arxiv.Result.Author('Yoram Shiftan'), arxiv.Result.Author('Amanda Stathopoulos'), arxiv.Result.Author('Eran Ben-Elia')]","On-demand mobility platforms play an increasingly important role in urban
mobility systems. Impacts are still debated, as these platforms supply
personalized and optimized services, while also contributing to existing
sustainability challenges. Recently, microtransit services have emerged,
promising to combine advantages of pooled on-demand rides with more sustainable
fixed-route public transit services. Understanding traveler behavior becomes a
primary focus to analyze adoption likelihood and perceptions of different
microtransit attributes. The COVID-19 pandemic context adds an additional layer
of complexity to analyzing mobility innovation acceptance. This study
investigates the potential demand for microtransit options against the
background of the pandemic. We use a stated choice experiment to study the
decision-making of Israeli public transit and car commuters when offered to use
novel microtransit options (sedan vs. passenger van). We investigate the
tradeoffs related to traditional fare and travel time attributes, along with
microtransit features; namely walking time to pickup location, vehicle sharing,
waiting time, minimum advanced reservation time, and shelter at designated
boarding locations. Additionally, we analyze two latent constructs: attitudes
towards sharing, as well as experiences and risk-perceptions related to the
COVID-19 pandemic. We develop Integrated Choice and Latent Variable models to
compare the two commuter groups in terms of the likelihood to switch to
microtransit, attribute trade-offs, sharing preferences and pandemic impacts.
The results reveal high elasticities of several time and COVID effects for car
commuters compared to relative insensitivity of transit commuters to the risk
of COVID contraction. Moreover, for car commuters, those with strong sharing
identities were more likely to be comfortable in COVID risk situations, and to
accept microtransit.",-0.3157052,0.26847813,-0.06354557,B
4373,These issues warrant further research.,"Like above, there are likely to
be dynamic effects at play, connecting ridership to changing employment circumstances and
COVID-19 risk levels.","In addition to the sharing economy constructs, the IOS scale is used to measure sharing
propensity.",2022-04-05 04:00:35+00:00,Microtransit adoption in the wake of the COVID-19 pandemic: evidence from a choice experiment with transit and car commuters,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'econ.EM', 'stat.AP', 'J.4']","[arxiv.Result.Author('Jason Soria'), arxiv.Result.Author('Shelly Etzioni'), arxiv.Result.Author('Yoram Shiftan'), arxiv.Result.Author('Amanda Stathopoulos'), arxiv.Result.Author('Eran Ben-Elia')]","On-demand mobility platforms play an increasingly important role in urban
mobility systems. Impacts are still debated, as these platforms supply
personalized and optimized services, while also contributing to existing
sustainability challenges. Recently, microtransit services have emerged,
promising to combine advantages of pooled on-demand rides with more sustainable
fixed-route public transit services. Understanding traveler behavior becomes a
primary focus to analyze adoption likelihood and perceptions of different
microtransit attributes. The COVID-19 pandemic context adds an additional layer
of complexity to analyzing mobility innovation acceptance. This study
investigates the potential demand for microtransit options against the
background of the pandemic. We use a stated choice experiment to study the
decision-making of Israeli public transit and car commuters when offered to use
novel microtransit options (sedan vs. passenger van). We investigate the
tradeoffs related to traditional fare and travel time attributes, along with
microtransit features; namely walking time to pickup location, vehicle sharing,
waiting time, minimum advanced reservation time, and shelter at designated
boarding locations. Additionally, we analyze two latent constructs: attitudes
towards sharing, as well as experiences and risk-perceptions related to the
COVID-19 pandemic. We develop Integrated Choice and Latent Variable models to
compare the two commuter groups in terms of the likelihood to switch to
microtransit, attribute trade-offs, sharing preferences and pandemic impacts.
The results reveal high elasticities of several time and COVID effects for car
commuters compared to relative insensitivity of transit commuters to the risk
of COVID contraction. Moreover, for car commuters, those with strong sharing
identities were more likely to be comfortable in COVID risk situations, and to
accept microtransit.",-0.23030889,0.31414446,-0.02752364,C
4709,"This will require
further research.","This may have
implications in terms of how eﬀectively one can distinguish medium lifetimes in Italian ego-alter
pairs in comparison to the other cohorts on the basis of early phone call activity.",Results for bi( ) and s are presented in Sec.,2022-04-11 23:47:11+00:00,The Stability of Transient Relationships,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Valentin Vergara Hidd'), arxiv.Result.Author('Eduardo Lopez'), arxiv.Result.Author('Simone Centellegher'), arxiv.Result.Author('Sam Roberts'), arxiv.Result.Author('Bruno Lepri'), arxiv.Result.Author('Robin Dunbar')]","In contrast to stable relationships, far less is known about the temporal
evolution of transient relationships, although these constitute a substantial
fraction of people's communication networks. Previous literature suggests that
ratings of relationship emotional intensity decay gradually until the
relationship ends. Using mobile phone data from three countries (US, UK, and
Italy), we demonstrate that the volume of communication between ego and its
alters is stable for most of the duration of a transient relationship. Alters
with longer durations receive more calls, with the duration of the relationship
being predictable from call volume within the first few weeks of first contact.
Relationships typically start with an early elevated period of communication,
settling into the longer steady regime until eventually terminating abruptly.
This is observed across all three countries, which include samples of egos at
different life stages. These results are consistent with the suggestion that
individuals initially engage frequently with a new alter so as to evaluate
their potential as a tie, and then settle back into a contact frequency
commensurate with the alter's match to ego on the so-called Seven Pillars of
Friendship.",-0.12891535,-0.0793171,-0.0506223,B
5044,"This
is not a trivial observation, and requires further study.","Why this is not the case in the networks under study
here is not clear, However a similar eﬀect is observed in interdependent networks embedded in space [11, 12, 13].","3.3 Temporal and Spatial Propagation of the Cascade

In a localized attack on a random network not embedded in space [5], the nodes which are closest to the initial attack
have a smaller probability of being overloaded during the ﬁrst stages of the attack compared with nodes far from the
attacked region, while another work [3] has demonstrated that for the networks on a square lattice immediately after
the initial attack the overloaded nodes are concentrated near the perimeter of the attack, while at later stages they
spread around the area of the initial attack as concentric circles.",2022-04-19 17:17:23+00:00,Cascading traffic jamming in a two-dimensional Motter and Lai model,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Gabriel Cwilich'), arxiv.Result.Author('Sergey V. Buldyrev')]","We study the cascading traffic jamming on a two-dimensional random geometric
graph using the Motter and Lai model. The traffic jam is caused by a localized
attack incapacitating circular region or a line of a certain size, as well as a
dispersed attack on an equal number of randomly selected nodes. We investigate
if there is a critical size of the attack above which the network becomes
completely jammed due to cascading jamming, and how this critical size depends
on the average degree $\langle k\rangle$ of the graph, on the number of nodes
$N$ in the system, and the tolerance parameter $\alpha$ of the Motter and Lai
model.",0.43267643,-0.05977165,0.023322724,A
5545,"This method, dated back approximately 9,000 to 11,000 years, does not
require further research and testing for large-scale implementation/organic use, and it can
affect up to 10,000-300,000 genes in total.","Traditional breeding, established by Gregor Mendel in the 1860s, focuses on the
selection of desirable alleles and cross-breeding these selected crops together to produce
offspring that combines both beneficial traits or has a minimized disadvantage against its
environment.","Mutagenesis, invented in 1983 by Kary B.
Mullis, is a technique using chemicals and radiation that efficiently detects and escalates a
targeted genome/DNA sequence, amplifying the desired genes without cloning.",2022-04-30 02:25:14+00:00,"Avoiding the ""Great Filter"": An Assessment of Climate Change Solutions and Combinations for Effective Implementation",physics.soc-ph,"['physics.soc-ph', 'astro-ph.EP', 'physics.ao-ph']","[arxiv.Result.Author('Junze Zhang'), arxiv.Result.Author('Kerry Zhang'), arxiv.Result.Author('Mary Zhang'), arxiv.Result.Author('Jonathan H. Jiang'), arxiv.Result.Author('Philip E. Rosen'), arxiv.Result.Author('Kristen A. Fahy')]","Climate change is the long-term shift in global weather patterns, largely
caused by anthropogenic activity of greenhouse gas emissions. Global climate
temperatures have unmistakably risen and naturally-occurring climate
variability alone cannot account for this trend. Human activities are estimated
to have caused about 1.0 {\deg}C of global warming above the pre-industrial
baseline and if left unchecked, will continue to drastically damage the Earth
and its inhabitants. Globally, natural disasters and subsequent economic losses
have become increasingly impactful as a result of climate change. Both wildlife
ecosystems and human habitats have been negatively impacted, from rising sea
levels to alarming frequency of severe weather events around the world.
Attempts towards alleviating the effects of global warming have often been at
odds and remain divided among a multitude of strategies, reducing the overall
effectiveness of these efforts. It is evident that collaborative action is
required for avoiding the most severe consequences of climate change. This
paper evaluates the main strategies (industrial/energy, political, economic,
agricultural, atmospheric, geological, coastal, and social) towards both
mitigating and adapting to climate change. As well, it provides an optimal
combination of seven solutions which can be implemented simultaneously, working
in tandem to limit and otherwise accommodate the harmful effects of climate
change. Previous legislation and deployment techniques are also discussed as
guides for future endeavors.",-0.13533086,-0.30671102,-0.26609892,B
5546,"Needless to say, ocean fertilization on the phytoplankton population has a short-
term effect and requires further research to be conducted for longer-lasting results.","Nevertheless, ocean eutrophication (i.e., “excessive richness of nutrients in a body of water,
frequently due to runoff from the land, which causes a dense growth of plant life and death
of animal life from lack of oxygen” [84] presents as a disadvantage of ocean fertilization,
whereby the nutrient needs of the ocean may be exceeded, causing potential negative side
effects.","Calculations and data collection based on the “current technological readiness [and] the
time needed to reach full implementation” [85] reflect the technological feasibility of ocean
fertilization and is comparably low to other mitigation and adaptation technologies (e.g.,
reef restoration, renewable energy, vegetation, etc.)",2022-04-30 02:25:14+00:00,"Avoiding the ""Great Filter"": An Assessment of Climate Change Solutions and Combinations for Effective Implementation",physics.soc-ph,"['physics.soc-ph', 'astro-ph.EP', 'physics.ao-ph']","[arxiv.Result.Author('Junze Zhang'), arxiv.Result.Author('Kerry Zhang'), arxiv.Result.Author('Mary Zhang'), arxiv.Result.Author('Jonathan H. Jiang'), arxiv.Result.Author('Philip E. Rosen'), arxiv.Result.Author('Kristen A. Fahy')]","Climate change is the long-term shift in global weather patterns, largely
caused by anthropogenic activity of greenhouse gas emissions. Global climate
temperatures have unmistakably risen and naturally-occurring climate
variability alone cannot account for this trend. Human activities are estimated
to have caused about 1.0 {\deg}C of global warming above the pre-industrial
baseline and if left unchecked, will continue to drastically damage the Earth
and its inhabitants. Globally, natural disasters and subsequent economic losses
have become increasingly impactful as a result of climate change. Both wildlife
ecosystems and human habitats have been negatively impacted, from rising sea
levels to alarming frequency of severe weather events around the world.
Attempts towards alleviating the effects of global warming have often been at
odds and remain divided among a multitude of strategies, reducing the overall
effectiveness of these efforts. It is evident that collaborative action is
required for avoiding the most severe consequences of climate change. This
paper evaluates the main strategies (industrial/energy, political, economic,
agricultural, atmospheric, geological, coastal, and social) towards both
mitigating and adapting to climate change. As well, it provides an optimal
combination of seven solutions which can be implemented simultaneously, working
in tandem to limit and otherwise accommodate the harmful effects of climate
change. Previous legislation and deployment techniques are also discussed as
guides for future endeavors.",-0.4347402,-0.29046303,-0.26069635,B
5547,"This method, dating back approximately 9,000 to 11,000 years,
does not require further research and testing for large-scale implementation/organic use,
and can affect up to 10,000-300,000 genes in total.","13
    Traditional breeding, scientifically established by Gregor Mendel in the 1860s, focuses
on the selection of desirable alleles and cross breeding these selected crops together to
produce offspring that combines both beneficial traits while minimizing disadvantages
against its environment.","Mutagenesis, invented in 1983 by Kary
B. Mullis, is a technique using chemicals and radiation that efficiently detects and escalates
a targeted genome/DNA sequence, amplifying the desired genes without cloning.",2022-04-30 02:25:14+00:00,"Avoiding the ""Great Filter"": An Assessment of Climate Change Solutions and Combinations for Effective Implementation",physics.soc-ph,"['physics.soc-ph', 'astro-ph.EP', 'physics.ao-ph']","[arxiv.Result.Author('Junze Zhang'), arxiv.Result.Author('Kerry Zhang'), arxiv.Result.Author('Mary Zhang'), arxiv.Result.Author('Jonathan H. Jiang'), arxiv.Result.Author('Philip E. Rosen'), arxiv.Result.Author('Kristen A. Fahy')]","Climate change is the long-term shift in global weather patterns, largely
caused by anthropogenic activity of greenhouse gas emissions. Global climate
temperatures have unmistakably risen and naturally occurring climate
variability alone cannot account for this trend. Human activities are estimated
to have caused about 1.0 degree C of global warming above the pre-industrial
baseline and if left unchecked, will continue to drastically damage the Earth
and its inhabitants. Globally, natural disasters and subsequent economic losses
have become increasingly impactful because of climate change. Both wildlife
ecosystems and human habitats have been negatively impacted, from rising sea
levels to alarming frequency of severe weather events around the world.
Attempts towards alleviating the effects of global warming have often been at
odds and remain divided among a multitude of strategies, reducing the overall
effectiveness of these efforts. It is evident that collaborative action is
required for avoiding the most severe consequences of climate change. This
paper evaluates the main strategies (industrial/energy, political, economic,
agricultural, atmospheric, geological, coastal, and social) towards both
mitigating and adapting to climate change. As well, it provides an optimal
combination of seven solutions which can be implemented simultaneously, working
in tandem to limit and otherwise accommodate the harmful effects of climate
change. Previous legislation and deployment techniques are also discussed as
guides for future endeavors.",-0.14346045,-0.29526156,-0.2719971,B
5548,"Ocean fertilization on the phytoplankton population has a short-term
effect and requires further research to be conducted for confirmation of longer-lasting
results.","Nevertheless, ocean eutrophication (i.e., “excessive richness of nutrients in a body
of water, frequently due to runoff from the land, which causes a dense growth of plant life
and death of animal life from lack of oxygen” [72] presents as a disadvantage of ocean
fertilization, whereby the nutrient needs of the ocean may be exceeded, causing potential
negative side effects.","Calculations and data collection based on the “current technological readiness [and] the
time needed to reach full implementation” [73] reflect the technological feasibility of ocean
fertilization and is comparably low to other mitigation and adaptation technologies (e.g.,
reef restoration, renewable energy, vegetation, etc.)",2022-04-30 02:25:14+00:00,"Avoiding the ""Great Filter"": An Assessment of Climate Change Solutions and Combinations for Effective Implementation",physics.soc-ph,"['physics.soc-ph', 'astro-ph.EP', 'physics.ao-ph']","[arxiv.Result.Author('Junze Zhang'), arxiv.Result.Author('Kerry Zhang'), arxiv.Result.Author('Mary Zhang'), arxiv.Result.Author('Jonathan H. Jiang'), arxiv.Result.Author('Philip E. Rosen'), arxiv.Result.Author('Kristen A. Fahy')]","Climate change is the long-term shift in global weather patterns, largely
caused by anthropogenic activity of greenhouse gas emissions. Global climate
temperatures have unmistakably risen and naturally occurring climate
variability alone cannot account for this trend. Human activities are estimated
to have caused about 1.0 degree C of global warming above the pre-industrial
baseline and if left unchecked, will continue to drastically damage the Earth
and its inhabitants. Globally, natural disasters and subsequent economic losses
have become increasingly impactful because of climate change. Both wildlife
ecosystems and human habitats have been negatively impacted, from rising sea
levels to alarming frequency of severe weather events around the world.
Attempts towards alleviating the effects of global warming have often been at
odds and remain divided among a multitude of strategies, reducing the overall
effectiveness of these efforts. It is evident that collaborative action is
required for avoiding the most severe consequences of climate change. This
paper evaluates the main strategies (industrial/energy, political, economic,
agricultural, atmospheric, geological, coastal, and social) towards both
mitigating and adapting to climate change. As well, it provides an optimal
combination of seven solutions which can be implemented simultaneously, working
in tandem to limit and otherwise accommodate the harmful effects of climate
change. Previous legislation and deployment techniques are also discussed as
guides for future endeavors.",-0.4174856,-0.31509373,-0.2705146,B
5798,"Other key aspects of its network structure, namely
its connections with non-aﬃliated members such as professionals, politicians, or businessmen
operating in the legal sphere (Lavezzi, 2014), remains an interesting topic for further research.","Putting these results together, it appears that the Sicilian Maﬁa is organized following
rational principles, as its longevity suggests.","30
A Palermo’s Mandamenti

 Figure 8: Map of Mandamenti in the city of Palermo.",2022-05-04 20:07:02+00:00,Organizing Crime: an Empirical Analysis of the Sicilian Mafia,physics.soc-ph,"['physics.soc-ph', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Author('Michele Battisti'), arxiv.Result.Author('Andrea Mario Lavezzi'), arxiv.Result.Author('Roberto Musotto')]","In this article we study the organizational structure of a large group of
members of the Sicilian Mafia by means of social network analysis and an
econometric analysis of link formation. Our mains results are the following. i)
The Mafia network is a small-world network adjusted by its criminal nature, and
is strongly disassortative. ii) Mafia bosses are not always central in the
network. In particular, consistent with a prediction of Baccara and Bar-Isaac,
we identify a ""cell-dominated hierarchy"" in the network: a key member is not
central, but is connected to a relative with a central position. iii) The
probability of link formation between two agents is higher if the two agents
belong to the same Mandamento, if they share a high number of similar tasks,
while being a ""boss"" reduces the probability of link formation between them.
iv) The probability of link formation for an individual agent is higher if he
is in charge of keeping connections outside his Mandamento, of collecting
protection money and or having a directive role, while age has modest role.
These results are interpreted in the light of the efficiency/security trade-off
faced by the Mafia and of its known hierarchical structure.",0.10169554,0.061857678,0.015526962,A
6263,"Other neurofeminist authors seem to agree with this statement
as they call for further research on this matter (Joel & Fausto-Sterling, 2016; Bentley et al.,
2019b; Alon et al., 2020).","(2019), there is no “solid alternative measurement to
comparing women and men” yet.","For instance, Joel & Fausto-Sterling (2016) request more research on
the relationship between sex/gender and the brain and on the question of when to include the
sex/gender category as a variable and when not to.",2022-05-14 19:17:45+00:00,Neurofeminism: feminist critiques of research on sex/gender differences in the neurosciences,physics.soc-ph,"['physics.soc-ph', 'q-bio.OT']","[arxiv.Result.Author('Kassandra Friedrichs'), arxiv.Result.Author('Philipp Kellmeyer')]","Over the last three decades, the human brain, and its role in determining
behavior have been receiving a growing amount of attention in academia as well
as in society more generally. Neuroscientific explanations of human behavior or
other phenomena are often especially appealing to lay people. Therefore,
neuroscientific explanations that can affect individuals, groups, or social
relations in general should be formulated in a careful and responsible way. One
field in which especially feminist scholars request more caution is the
neuroscientific examination of sex or gender differences. Feminist scholars
have described various ways in which sexist bias might be present in
neuroscientific research on sex or gender differences. In this context, they
coined the term ""neurosexism"" to describe the entanglement between
neuroscientific work and sexist ideology, and ""neurofeminism"" as a response to
that. Here, we aim to give an overview over the contemporary neurofeminist
literature. In the first part, common levels of analysis in the neurofeminist
literature are presented and the research level is explored in more detail. In
the second part, some common developments in more recent neurofeminist
scholarship are discussed. For this, we review recent publications with the aim
to provide neuroscientists with a solid understanding of neurofeminist
criticism so that they may evaluate neuroscientific claims about on sex or
gender differences from this critical perspective.",-0.26863265,-0.06598994,-0.051760353,B
6264,"Outlook for further research
        From our perspective, it would be of great interest to further investigate how

neurofeminist critiques were received in the mainstream neurosciences in more detail.","Neurofeminist scholars have also reached out to their
colleagues from the neurosciences to move the debate about a more critical, gender-sensitive
neuroscientific research on SGDs into ‘mainstream’ neuroscience discourses (Rippon et al.,
2017; Gungor et al., 2019).","To this
regard, some of the following questions could be explored: Are the ‘mainstream’ neurosciences
aware of these critiques?",2022-05-14 19:17:45+00:00,Neurofeminism: feminist critiques of research on sex/gender differences in the neurosciences,physics.soc-ph,"['physics.soc-ph', 'q-bio.OT']","[arxiv.Result.Author('Kassandra Friedrichs'), arxiv.Result.Author('Philipp Kellmeyer')]","Over the last three decades, the human brain, and its role in determining
behavior have been receiving a growing amount of attention in academia as well
as in society more generally. Neuroscientific explanations of human behavior or
other phenomena are often especially appealing to lay people. Therefore,
neuroscientific explanations that can affect individuals, groups, or social
relations in general should be formulated in a careful and responsible way. One
field in which especially feminist scholars request more caution is the
neuroscientific examination of sex or gender differences. Feminist scholars
have described various ways in which sexist bias might be present in
neuroscientific research on sex or gender differences. In this context, they
coined the term ""neurosexism"" to describe the entanglement between
neuroscientific work and sexist ideology, and ""neurofeminism"" as a response to
that. Here, we aim to give an overview over the contemporary neurofeminist
literature. In the first part, common levels of analysis in the neurofeminist
literature are presented and the research level is explored in more detail. In
the second part, some common developments in more recent neurofeminist
scholarship are discussed. For this, we review recent publications with the aim
to provide neuroscientists with a solid understanding of neurofeminist
criticism so that they may evaluate neuroscientific claims about on sex or
gender differences from this critical perspective.",-0.21961501,-0.15055141,-0.03555799,B
6304,Possible further research includes the following aspects.,"Our ﬁndings would help alleviate urban congestion, make better urban planning, and improve
transportation efﬁciency in cities.","Currently, most state-of-the-art collective mobility models47–49
neglect the impacts of travel modes.",2022-05-17 06:39:14+00:00,Understanding urban congestion with biking traffic and routing detour ratio,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Xinze Qiu'), arxiv.Result.Author('Tianli Gao'), arxiv.Result.Author('Yu Yang'), arxiv.Result.Author('Ankang Luo'), arxiv.Result.Author('Fan Shang'), arxiv.Result.Author('Ruiqi Li')]","Bike-sharing systems have been regarded as a critical component of solutions
towards the transition to greener and more sustainable transportation, with the
benefits of reducing carbon emissions, improving public health, and mitigating
congestion by replacing short-distance motorized trips. Due to better
accessibility and usage flexibility, newly emergent dockless sharing bikes have
become quite popular and are reviving the fashion of cycling in cities. Urban
congestion is simultaneously influenced by heterogeneous saptio-temporal travel
demands, topology and spatial characteristics of road networks, and the
interplay between travel modes. In this paper, by considering aforementioned
factors, we discover a robust sublinear scaling relation between the level of
congestion for vehicles and the detour ratio weighted by biking traffic, which
is intriguing given the fact that congestion and detour ratio is linearly
independent. Such a scaling relation implies a strong interplay between vehicle
traffic and cycling activities and can be applied in predictions for congestion
or aggregated to more sophisticated traffic models. In addition,
biking-traffic-weighted detour ratio can be applied to detect inefficient
routes, which would help alleviate urban congestion, make better urban
planning, and improve transportation efficiency and equity in cities.",-0.045701478,0.53533524,-0.0017470825,C_centroid
6480,"Finally, the further research would extend the presented work by the analysis of
pedestrian surroundings, i.e.",(2022).,"the study of the area aﬀecting the pedestrian behaviour
assuming the density distribution is already known.",2022-05-20 12:39:27+00:00,Kernel Estimates as General Concept for the Measuring of Pedestrian Density,physics.soc-ph,"['physics.soc-ph', 'cs.MA', 'nlin.AO', 'stat.AP']","[arxiv.Result.Author('Jana Vacková'), arxiv.Result.Author('Marek Bukáček')]","The standard density definition produces scattered values. Hence approaches
improving features of the density estimates has been invented for many use
cases. Presented general framework evaluating density using various kernels
brings desired properties of density estimates and incorporates the most of
ordinarily used methods. Extensive parametric study is performed on
experimental data to illustrate effects of kernel selection (e.g. Gauss, cone)
and its parametrization (blur). Quantitative evaluation of introduced quality
criteria illustrates that kernel densities satisfy user requirements, e.g.
conic kernel with radius in $[0.7, 1.2]$ m. These parametric values are also
interpretable from proxemic theory indicating correctness of the whole concept.
Besides, the kernel approach is directly compared to Voronoi approximation and
customized distance to the nearest pedestrian - the comparison indicates a
relevant correspondence. Furthermore, the kernel approach is supposed to be
valid from mathematical perspective, since introduced Borsalino kernel has
promising mathematical properties enabling future analytical research.",-0.18672274,0.337984,0.03870589,C
6496,"Finally, our work establishes a clear connection between the study of multiplex networks
and the study of higher-order networks and oriented hypegraphs, and we hope that this
can lead to further research at the interface of these two hot topics.","In conclusion this work is a pioneering work that treats diﬀusion on multiplex
networks with higher-order interactions, and shows that the higher-order coupling
between the layers changes the diﬀusion properties of the entire multiplex network.","Possible directions
in which this work can be expanded include the investigation of hyper-diﬀusion on
multiplex networks with more than two layers and the application of this framework
to non-linear models, such as synchronisation of identical oscillators or generalised
Kuramoto models.",2022-05-20 16:41:07+00:00,Hyper-diffusion on multiplex networks,physics.soc-ph,"['physics.soc-ph', 'cond-mat.dis-nn', 'cs.SI']","[arxiv.Result.Author('Reza Ghorbanchian'), arxiv.Result.Author('Vito Latora'), arxiv.Result.Author('Ginestra Bianconi')]","Multiplex networks describe systems whose interactions can be of different
nature, and are fundamental to understand complexity of networks beyond the
framework of simple graphs. Recently it has been pointed out that restricting
the attention to pairwise interactions is also a limitation, as the vast
majority of complex systems include higher-order interactions and these
strongly affect their dynamics. Here, we propose hyper-diffusion on multiplex
network, a dynamical process in which the diffusion on each single layer is
coupled with the diffusion in other layers thanks to the presence of
higher-order interactions occurring when there exists link overlap in different
layers. We show that hyper-diffusion on a duplex (a network with two layers) is
driven by Hyper-Laplacians in which the relevance of higher-order interactions
can be tuned by a continuous parameter $\delta_{11}$. By combining tools of
spectral graph theory, applied topology and network science we provide a
general understanding of hyper-diffusion on duplex networks, including
theoretical bounds on the Fiedler and the largest eigenvalue of
Hyper-Laplacians and the asymptotic expansion of their spectrum for
$\delta_{11}\ll1$ and $\delta_{11}\gg1$. Although hyper-diffusion on multiplex
networks does not imply a direct ""transfer of mass"" among the layers (i.e. the
average state of replica nodes in each layer is a conserved quantity of the
dynamics), we find that the dynamics of the two layers is coupled as the
relaxation to the steady state becomes synchronous when higher-order
interactions are taken into account and the Fiedler eigenvalue of the
Hyper-Laplacian is not localized on a single layer of the duplex network.",0.36385375,-0.20771697,-0.065252125,A
6763,These challenges demand further research.,"S4
in SI for SF with γ = 2.5.","Finally, it is interesting to note that controlling a very small fraction of nodes can sustain a very large
network.",2022-05-26 14:10:12+00:00,Sustaining a network by controlling a fraction of nodes,physics.soc-ph,"['physics.soc-ph', 'math.DS']","[arxiv.Result.Author('Hillel Sanhedrai'), arxiv.Result.Author('Shlomo Havlin')]","Multi-stability is a widely observed phenomenon in real complex networked
systems, such as technological infrastructures, ecological systems, gene
regulation, transportation and more. When a system functions normally but there
exists also a potential state with abnormal low activity, although the system
is at equilibrium it might make a transition into the low activity undesired
state due to external disturbances and perturbations. Thus, such a system can
be regarded as unsustainable, due to the danger of falling into the potential
inactive state. Here we explore, analytically and by simulations, how
supporting the activity of a fraction $\rho$ of nodes can turn an unsustainable
system to be sustainable by eliminating the inactive potential stable state. We
thus unveil a new sustainability phase diagram in the presence of a fraction of
controlled nodes $\rho$. This phase diagram could provide guidelines to sustain
a network by external intervention and/or by strengthening the connectivity of
the network.",0.16943459,-0.17947851,-0.21873477,A
6949,"In the next sections, we further study the dynamics of the networks for individual airlines.","3a-b), the network structure had been still largely diﬀerent from the pre-
pandemic one.",4.2.,2022-05-31 05:08:36+00:00,Dynamics of the US domestic airline network during the COVID-19 pandemic,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Kashin Sugishita'), arxiv.Result.Author('Hiroki Mizutani'), arxiv.Result.Author('Shinya Hanaoka')]","The ongoing COVID-19 pandemic has had serious impacts on the airline
industry. Understanding the network dynamics of individual airlines is
essential for discussing aviation policies in emergent situations to achieve
both ensuring network connectivity and maintaining competition among airlines.
In this study, we quantitatively reveal the day-to-day dynamics of the US
domestic airline networks consisting of 17 airlines from January 2019 to
December 2021. Specifically, we applied a framework for analyzing temporal
networks, in which network structure changes over time. First, we found that,
even though the number of nodes and edges returned to the pre-pandemic levels
around July 2021, the structure of the entire US domestic airline network had
been still largely different from the pre-pandemic structure. We also found
that the network dynamics varied significantly from airline to airline.
Full-service carriers are less flexible in changing their network structure and
suffer higher revenue losses. On the contrary, most regional carriers
completely shifted to new structure, which may contribute to reduce their
revenue losses. Low-cost carriers are characterized by more pronounced
differences between airlines and drastically changed their network structure
immediately after the declaration of national emergency.",0.38878495,0.2227056,-0.0013276208,A
6950,"We speculate that
these network changes may be reﬂected by regulations related to COVID-19, which vary from state to state in the
US, but further research is warranted.","We found that the network structure has changed signiﬁcantly, especially
among RCs, but we have not been able to determine how the network has changed geographically.","Next, we can perform a weighted network analysis.",2022-05-31 05:08:36+00:00,Dynamics of the US domestic airline network during the COVID-19 pandemic,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Kashin Sugishita'), arxiv.Result.Author('Hiroki Mizutani'), arxiv.Result.Author('Shinya Hanaoka')]","The ongoing COVID-19 pandemic has had serious impacts on the airline
industry. Understanding the network dynamics of individual airlines is
essential for discussing aviation policies in emergent situations to achieve
both ensuring network connectivity and maintaining competition among airlines.
In this study, we quantitatively reveal the day-to-day dynamics of the US
domestic airline networks consisting of 17 airlines from January 2019 to
December 2021. Specifically, we applied a framework for analyzing temporal
networks, in which network structure changes over time. First, we found that,
even though the number of nodes and edges returned to the pre-pandemic levels
around July 2021, the structure of the entire US domestic airline network had
been still largely different from the pre-pandemic structure. We also found
that the network dynamics varied significantly from airline to airline.
Full-service carriers are less flexible in changing their network structure and
suffer higher revenue losses. On the contrary, most regional carriers
completely shifted to new structure, which may contribute to reduce their
revenue losses. Low-cost carriers are characterized by more pronounced
differences between airlines and drastically changed their network structure
immediately after the declaration of national emergency.",0.33438155,0.2113677,-0.15440127,A
6951,"We found that the network
dynamics of FSCs, LCCs, and RCs diﬀered signiﬁcantly during the COVID-19 pandemic, but this might be universal
property regardless of countries and types of emergency and further research is warranted.","Finally, we can analyze airlines in countries other than the US in the
COVID-19 pandemic, as well as the network analysis during other emergent situations.","Appendix A. Measurements of network structure for individual airlines

    In this section, we show the evolution of the measurements for the network structure of individual airlines
(Figs A.8-A.13).",2022-05-31 05:08:36+00:00,Dynamics of the US domestic airline network during the COVID-19 pandemic,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Kashin Sugishita'), arxiv.Result.Author('Hiroki Mizutani'), arxiv.Result.Author('Shinya Hanaoka')]","The ongoing COVID-19 pandemic has had serious impacts on the airline
industry. Understanding the network dynamics of individual airlines is
essential for discussing aviation policies in emergent situations to achieve
both ensuring network connectivity and maintaining competition among airlines.
In this study, we quantitatively reveal the day-to-day dynamics of the US
domestic airline networks consisting of 17 airlines from January 2019 to
December 2021. Specifically, we applied a framework for analyzing temporal
networks, in which network structure changes over time. First, we found that,
even though the number of nodes and edges returned to the pre-pandemic levels
around July 2021, the structure of the entire US domestic airline network had
been still largely different from the pre-pandemic structure. We also found
that the network dynamics varied significantly from airline to airline.
Full-service carriers are less flexible in changing their network structure and
suffer higher revenue losses. On the contrary, most regional carriers
completely shifted to new structure, which may contribute to reduce their
revenue losses. Low-cost carriers are characterized by more pronounced
differences between airlines and drastically changed their network structure
immediately after the declaration of national emergency.",0.38039213,0.27509058,-0.036764532,A
6952,"We found that the network
dynamics of FSCs, LCCs, and RCs diﬀered signiﬁcantly during the COVID-19 pandemic, but this might be a universal
occurrence regardless of country or type of emergency, which further research could help resolve.","Finally, an analysis of airlines in countries other than the
US during the COVID-19 pandemic should be conducted, as well as network analyses for other emergent situations
such as other disease outbreaks, ﬁnancial crises, terror-related events, and natural disasters.","Appendix A. Measurements of network structure for individual airlines

    In this section, we show the evolution of the measurements for the network structure of individual airlines
(Figs A.8-A.13).",2022-05-31 05:08:36+00:00,Dynamics of the US domestic airline network during the COVID-19 pandemic,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Kashin Sugishita'), arxiv.Result.Author('Hiroki Mizutani'), arxiv.Result.Author('Shinya Hanaoka')]","The ongoing COVID-19 pandemic has had serious impacts on the airline
industry. Ensuring that aviation policies in emergent situations both guarantee
network connectivity and maintain competition among airlines is crucial in
these circumstances. To this end, we aimed to understand the network dynamics
of individual airlines. In this study, we quantitatively reveal the day-to-day
dynamics of these US domestic airline networks, comprising 17 airlines, from
January 2019 to December 2021. Specifically, we applied a framework for
analyzing temporal networks, in which the network structure changes over time.
We found that, first, even though the number of nodes and edges returned to
pre-pandemic levels around July 2021, the structure of the entire US domestic
airline network remained altered. We also found that the network dynamics
varied significantly from airline to airline. Full-service carriers were less
flexible in changing their network structure and suffered higher revenue
losses. On the contrary, most regional carriers completely shifted to a new
structure, which may have contributed to reducing their revenue losses.
Low-cost carriers were characterized by more pronounced differences between
airlines and drastically changed their network structure immediately after the
declaration of a national emergency.",0.43106735,0.26292732,-0.031164326,A
7242,"15
                    Preprint - March 9, 2021 – V3

1.8

1.6

1.4

1.2

1

0.8

0.6

0.4

0.2

0

-0.2  total impact  total grants  journal impact  network quality          nr coauthors

      Granted Nearby Granted other Non funded Step 2 ToBtaelsitmopf athcteBrest

Figure 2: Scores on performance and reputation, four groups of applicants

              All variables normalized at panel level

Conclusions and further research

Our study suggests that having a nearby panel member does affect the grant decision process.","The granted-nearby group, however does score higher on the
reputation indicators, so if it is a form of ‘preferential attachment’ and not of interest
representation, it is reputation and not performance based.","Those with an organizational near-by panel member from the host institution have an overall
much higher success rate than average, and the difference is substantial: 50% higher.",2022-05-26 22:02:54+00:00,Do interests affect grant application success? The role of organizational proximity,physics.soc-ph,"['physics.soc-ph', 'cs.CY']","[arxiv.Result.Author('Charlie Mom'), arxiv.Result.Author('Peter van den Besselaar')]","Bias in grant allocation is a critical issue, as the expectation is that
grants are given to the best researchers, and not to applicants that are
socially, organizationally, or topic-wise near-by the decision-makers. In this
paper, we investigate the effect of organizational proximity, defined as an
applicant with the same affiliation as one of the panel members (a near-by
panelist), on the probability of getting a grant. This study is based on one of
the most prominent grant schemes in Europe, with overall excellent scientists
as panel members. Various aspects of this organizational proximity are
analyzed: Who gains from it? Does it have a gender dimension? Is it bias, or
can it be explained by performance differences? We do find that the probability
to get funded increases significantly for those that apply in a panel where
there is a panelist from the institution where the applicant has agreed to use
the grant. At the same time, the effect differs between disciplines and
countries, and men profit more of it than women do. Finally, depending on how
one defines what counts as the best researchers, the near-by panelist effect
can be interpreted as preferential attachment (quality links to quality) or as
bias and particularism.",-0.097862825,-0.05050023,-0.087561704,B
7243,"Understanding this observation would
also need further research.","Aside from the proximity effect at country level, we also showed that chances for non-EU
nationals who do not already reside in the EU are zero.","Almost all successful applicants from outside the EU are EU
citizens.",2022-05-26 22:02:54+00:00,Do interests affect grant application success? The role of organizational proximity,physics.soc-ph,"['physics.soc-ph', 'cs.CY']","[arxiv.Result.Author('Charlie Mom'), arxiv.Result.Author('Peter van den Besselaar')]","Bias in grant allocation is a critical issue, as the expectation is that
grants are given to the best researchers, and not to applicants that are
socially, organizationally, or topic-wise near-by the decision-makers. In this
paper, we investigate the effect of organizational proximity, defined as an
applicant with the same affiliation as one of the panel members (a near-by
panelist), on the probability of getting a grant. This study is based on one of
the most prominent grant schemes in Europe, with overall excellent scientists
as panel members. Various aspects of this organizational proximity are
analyzed: Who gains from it? Does it have a gender dimension? Is it bias, or
can it be explained by performance differences? We do find that the probability
to get funded increases significantly for those that apply in a panel where
there is a panelist from the institution where the applicant has agreed to use
the grant. At the same time, the effect differs between disciplines and
countries, and men profit more of it than women do. Finally, depending on how
one defines what counts as the best researchers, the near-by panelist effect
can be interpreted as preferential attachment (quality links to quality) or as
bias and particularism.",-0.2523489,0.006523356,-0.0094999075,B
7521,"Future directions We identify the following additional directions for further research.First, in our
procedure stops are set as optimal for travellers, while results often show that a minor shift may
signiﬁcantly reduce the vehicle route and avoid detours (as e.g.","Rides composed
of more than three travellers require special kinds of vehicles, resembling minibuses - presumably more
expensive to operate which may be taken into consideration in future research.",in Fielbaum et al (2021)).,2022-06-13 07:21:19+00:00,Hyper-pool: pooling private trips into high-occupancy transit-like attractive shared rides,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Rafal Kucharski'), arxiv.Result.Author('Oded Cats')]","We propose Hyper-pool, an analytical, offline, utility-driven ride-pooling
algorithm to aggregate individual trip requests into attractive shared rides of
high-occupancy. We depart from our ride-pooling ExMAS algorithm where single
rides are pooled into attractive door-to-door rides and propose two novel
demand-side algorithms for further aggregating individual demand towards more
compact pooling. First, we generate stop-to-stop rides, with a single pick up
and drop off points optimal for all the travellers. Second, we bundle such
rides again, resulting with hyper-pooled rides compact enough to resemble
public transport operations. We propose a bottom-up framework where the pooling
degree of identified rides is gradually increased, thereby ensuring
attractiveness at subsequent aggregation levels. Our Hyper-pool method outputs
the set of attractive pooled rides per service variant for a given travel
demand. The algorithms are publicly available and reproducible. It is
applicable for real-size demand datasets and opens new opportunities for
exploiting the limits of ride-pooling potential. In our Amsterdam case-study we
managed to pool over 220 travellers into 40 hyper-pooled rides of average
occupancy 5.8 pax/veh.",-0.19641884,0.46693274,-0.034423724,C
7912,"I, the tax data analyzed here offers the most comprehensive imprint
of scientific philanthropy over the past decade, representing a resource that we now make
available for further research.","Despite these and other limitations
explored in depth in SI Sec.",Our analysis reveals important differences between philanthropic and federal funding.,2022-06-09 16:43:54+00:00,Mapping Philanthropic Support of Science,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Louis M. Shekhtman'), arxiv.Result.Author('Alexander J. Gates'), arxiv.Result.Author('Albert-László Barabási')]","While philanthropic support plays an increasing role in supporting research,
there is limited quantitative knowledge about the patterns that characterize
the distribution of philanthropic support. Here, we map philanthropic funding
to universities and research institutions based on IRS tax forms from 685,397
non-profit organizations. We identify nearly one million grants supporting
institutions involved in science, finding that in volume and scope,
philanthropic funding is comparable to federal research funding. However,
whereas federal funding relies on a few large organizations to distribute
grants, the philanthropic ecosystem's support is fragmented among a large
number of funders with diverse focus that support research institutions at
varying levels. Furthermore, we find that distinct from government support,
philanthropic funders tend to focus locally, indicating that other criteria,
beyond research excellence, play a role in their funding decisions. We also
show evidence of persistence, i.e., once a grant-giving relationship begins, it
tends to continue in time. Finally, we discuss the policy implications of our
findings for philanthropic funders, individual researchers, the science of
science, and for quantitative studies of philanthropy in general.",-0.273139,-0.10935369,-0.21934387,B
8284,"The idea is
conceptually related to prize-based funding, in which success brings additional resources
for further research, as well as recognition.","This method
would allow new researchers to build up their expertise, laboratories, and working groups,
while limiting the perceived risk to funding agencies from “failing” projects.","Prize-based approaches are often considered
to be underutilized by economists and have been found to increase productivity [63].",2022-06-30 23:20:20+00:00,"Snowmass '21 Community Engagement Frontier 6: Public Policy and Government Engagement: Congressional Advocacy for HEP Funding (The ""DC Trip'')",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Mateus Carneiro'), arxiv.Result.Author('Richie Diurba'), arxiv.Result.Author('Rob Fine'), arxiv.Result.Author('Ketino Kaadze'), arxiv.Result.Author('Kevin Pedro'), arxiv.Result.Author('Alexx Perloff'), arxiv.Result.Author('Louise Suter'), arxiv.Result.Author('Shawn Westerdale')]","This document has been prepared as a Snowmass contributed paper by the Public
Policy \& Government Engagement topical group (CEF06) within the Community
Engagement Frontier. The charge of CEF06 is to review all aspects of how the
High Energy Physics (HEP) community engages with government at all levels and
how public policy impacts members of the community and the community at large,
and to assess and raise awareness within the community of direct
community-driven engagement of the U.S. federal government (\textit{i.e.}
advocacy). The focus of this paper is the advocacy undertaken by the HEP
community that pertains directly to the funding of the field by the U.S.
federal government.",-0.40556538,-0.02711498,-0.08005929,B
8285,"The idea is
conceptually related to prize-based funding, in which success brings additional resources
for further research, as well as recognition.","This method
would allow new researchers to build up their expertise, laboratories, and working groups,
while limiting the perceived risk to funding agencies from “failing” projects.","Prize-based approaches are often considered
to be underutilized by economists and have been found to increase productivity [63].",2022-06-30 23:20:20+00:00,"Snowmass '21 Community Engagement Frontier 6: Public Policy and Government Engagement: Congressional Advocacy for HEP Funding (The ""DC Trip'')",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Mateus Carneiro'), arxiv.Result.Author('Richie Diurba'), arxiv.Result.Author('Rob Fine'), arxiv.Result.Author('Mandeep Gill'), arxiv.Result.Author('Ketino Kaadze'), arxiv.Result.Author('Harvey Newman'), arxiv.Result.Author('Kevin Pedro'), arxiv.Result.Author('Alexx Perloff'), arxiv.Result.Author('Louise Suter'), arxiv.Result.Author('Shawn Westerdale')]","This document has been prepared as a Snowmass contributed paper by the Public
Policy \& Government Engagement topical group (CEF06) within the Community
Engagement Frontier. The charge of CEF06 is to review all aspects of how the
High Energy Physics (HEP) community engages with government at all levels and
how public policy impacts members of the community and the community at large,
and to assess and raise awareness within the community of direct
community-driven engagement of the U.S. federal government (\textit{i.e.}
advocacy). The focus of this paper is the advocacy undertaken by the HEP
community that pertains directly to the funding of the field by the U.S.
federal government.",-0.40556538,-0.02711498,-0.08005929,B
8544,"We hope that our work will
stimulate further research in these directions.","Finally, the idea that
a discrete multistate contagion model can provide an ap-            Fs =                                               1−θ          if              (A1)
proximation of continuous-state contagion could also be
utilized in other contexts, such as opinion dynamics and                                                               0 otherwise,
cascades of load [46–48].","η

                                                                                         m/k−θ represents the responsive-
                                                               where f (m/k) = 1−θ
                                                               ness to the neighbors’ states.",2022-07-07 09:51:59+00:00,Financial fire sales as continuous-state complex contagion,physics.soc-ph,"['physics.soc-ph', 'q-fin.RM']","[arxiv.Result.Author('Tomokatsu Onaga'), arxiv.Result.Author('Fabio Caccioli'), arxiv.Result.Author('Teruyoshi Kobayashi')]","Trading activities in financial systems create various channels through which
systemic risk can propagate. An important contagion channel is financial fire
sales, where a bank failure causes asset prices to fall due to asset
liquidation, which in turn drives further bank defaults, triggering the next
rounds of liquidation. This process can be considered as complex contagion, yet
it cannot be modeled using the conventional binary-state contagion models
because there is a continuum of states representing asset prices. Here, we
develop a threshold model of continuous-state cascades in which the states of
each node are represented by real values. We show that the solution of a
multi-state contagion model, for which the continuous states are discretized,
accurately replicates the simulated continuous state distribution as long as
the number of states is moderately large. This discretization approach allows
us to exploit the power of approximate master equations (AME) to trace the
trajectory of the fraction of defaulted banks and obtain the distribution of
asset prices that characterize the dynamics of fire sales on asset-bank
bipartite networks. We examine the accuracy of the proposed method using real
data on asset-holding relationships in exchange-traded funds (ETFs).",0.2806764,-0.09779695,0.20327091,A
8987,"Zhou

      form the starting point for further research.",Xie and W.-X.,"Firstly, it is crucial to uncover inﬂu-
      encing factors in the formation of bilateral trades and communities.",2022-07-18 01:41:18+00:00,Evolving community structure in the international pesticide trade networks,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Jian-An Li'), arxiv.Result.Author('Li Wang'), arxiv.Result.Author('Wen-Jie Xie'), arxiv.Result.Author('Wei-Xing Zhou')]","The statistical properties including community structure of the international
trade networks of all commodities as a whole have been studied extensively.
However, the international trade networks of individual commodities often
behave differently. Due to the importance of pesticides in agricultural
production and food security, we investigate the evolving community structure
in the international pesticide trade networks (iPTNs) of five categories from
2007 to 2018. We unveil the community structures in the undirected and directed
iPTNs exhibits regional patterns. However, the regional patterns are very
different for undirected and directed networks and for different categories of
pesticide. Moreover, the community structure is stabler in the directed iPTNs
than in the undirected iPTNs. We also extract the intrinsic community blocks
for the directed international trade networks of each pesticide category. It is
found that the largest intrinsic community block is the stablest that appears
in every pesticide category and contains important economies (Belgium, Germany,
Spain, France, United Kingdom, Italy, Netherlands, and Portugal) in Europe.
Other important and stable intrinsic community blocks are Canada and the United
States in North America, Argentina and Brazil in South America, and Australia
and New Zealand in Oceania. These findings imply the importance of geographic
distance and the complementarity of important adjacent economies in the
international trade of pesticides.",-0.11816215,-0.08493747,-0.0021707409,B
9027,"Gender assortativity in payment networks may also reﬂect, for instance, gendered economic
roles in ways that deserve further study.","Within Sarafu, such groups provide opportunities to
transact assortatively on gender.","Strong correlations in registration date also appear in several sub-networks, indicating
a cohort effect.",2022-07-18 21:01:17+00:00,Circulation of a digital community currency,physics.soc-ph,"['physics.soc-ph', 'econ.GN', 'q-fin.EC']","[arxiv.Result.Author('Carolina E S Mattsson'), arxiv.Result.Author('Teodoro Criscione'), arxiv.Result.Author('Frank W Takes')]","Circulation is the characteristic feature of successful currency systems,
from community currencies to cryptocurrencies to national currencies. In this
paper, we propose a network analysis methodology for studying circulation given
a system's digital transaction records. This is applied to Sarafu, a digital
community currency active in Kenya over a period that saw considerable economic
disruption due to the COVID-19 pandemic. Representing Sarafu as a network of
monetary flow among the 40,000 users reveals meaningful patterns at multiple
scales. Circulation was highly modular, geographically localized, and occurring
among users with diverse livelihoods. Network centrality highlights women's
participation, early adopters, and the especially prominent role of
community-based financial institutions. These findings have concrete
implications for humanitarian and development policy, helping articulate when
community currencies might best support interventions in marginalized areas.
Overall, networks of monetary flow allow for studying circulation within
digital currency systems at a striking level of detail.",-0.049849298,0.06252161,-0.062177286,B
9470,"Last, the paper proposes new avenues for further research.","It offers practical implications and a big-data based tool
                                                  to monitor ﬁrms’ discussions on SDGs on Twitter.","Introduction

                                                 Online social networks have changed communication, making it cheaper and faster than before and providing a new channel
                                                 for businesses to engage and directly interact with their stakeholders.",2022-07-29 13:18:39+00:00,Sustainable Development Goals as unifying narratives in large UK firms' Twitter discussions,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Alessia Patuelli'), arxiv.Result.Author('Fabio Saracco')]","Since 2015, the United Nations have called for a global effort to reach
Sustainable Development Goals (SDGs). Firms play a vital role in contributing
to SDGs. While many empirical approaches were used to map firms' contributions
to SDGs, online social networks are an underexplored but promising setting.
This paper maps large UK firms' discussions on Twitter, specifically focusing
on their SDG-related discussions, with complex network methods from statistical
physics. Results show that: 1) SDGs are the topics that tie conversations among
major UK firms together; 2) compared to the environmental and economic
dimensions, the social dimension is predominant; 3) the attention to different
SDGs varies depending on the community and sector firms belong to; 4) the use
of retweets on SDGs-related tweets highlights a high stakeholder engagement on
global challenges; 5) large UK companies and stakeholders generally behave
differently from Italian ones. This paper provides theoretical contributions,
combining institutional, stakeholder and legitimacy theories. It also
contributes to developing the literature on businesses and SDGs with an
interdisciplinary approach. It offers practical implications and a big-data
based tool to monitor firms' discussions on SDGs on Twitter. Last, the paper
proposes new avenues for further research.",0.07131398,0.009420726,-0.07542014,A
9767,"This enabled further research and development efforts
that supported the second quantum revolution.","Recent developments in technical fields such as nanotechnology, quantum
optics, and condensed matter physics resulted in capabilities that allow researchers to reliably
create, manipulate, and exploit quantum specific phenomena at a high precision and accuracy
levels that were previously not possible.",The extent of this technological revolution can be observed quantitatively.,2022-08-05 19:23:09+00:00,Democratization of Quantum Technologies,physics.soc-ph,"['physics.soc-ph', 'quant-ph']","[arxiv.Result.Author('Zeki C. Seskir'), arxiv.Result.Author('Steven Umbrello'), arxiv.Result.Author('Christopher Coenen'), arxiv.Result.Author('Pieter E. Vermaas')]","As quantum technologies (QT) have been becoming more and more realized, their
potential impact on and relation with society has been developing into a
pressing issue for exploration. In this paper, we investigate the topic of
democratization in the context of QT, particularly quantum computing. The paper
contains three main sections. First, we briefly introduce different theories of
democracy (participatory, representative, and deliberative), and how the
concept of democratization can be formulated with respect to these frameworks.
Second, we give an overview of how the concept of democratization is utilized
by the actors in the QT field. Democratization is mainly adopted by companies
working on quantum computing and used in a very narrow understanding of the
concept. We provide a discussion on where to locate this formulation of
democratization used by the QT community within the overall conceptual
landscape of democracy theories. Third, we explore various narratives and
counter-narratives concerning democratization in QT and we propose a five-step
approach to operationalizing the concept of democratization with respect to
different theories of democracy. Finally, we explore the concept of
democratization in QT beyond quantum computing. In conclusion, we argue that
although the ongoing efforts in the democratization of QT are necessary steps
towards the democratization of this set of emerging technologies, they should
not be accepted as sufficient to argue that QT is a democratized field. We
argue that more reflexivity and responsiveness regarding the narratives and
actions adopted by the actors in the QT field and making the underlying
assumptions of ongoing efforts on democratization of QT can result in a better
technology for the society.",-0.3318969,-0.3293675,-0.37934953,B
9768,"This enabled further research and development efforts
that supported the second quantum revolution.","Recent developments in technical fields such as nanotechnology, quantum
optics, and condensed matter physics resulted in capabilities that allow researchers to reliably
create, manipulate, and exploit quantum specific phenomena at a high precision and accuracy
levels that were previously not possible.",The extent of this technological revolution can be observed quantitatively.,2022-08-05 19:23:09+00:00,Democratization of Quantum Technologies,physics.soc-ph,"['physics.soc-ph', 'quant-ph']","[arxiv.Result.Author('Zeki C. Seskir'), arxiv.Result.Author('Steven Umbrello'), arxiv.Result.Author('Christopher Coenen'), arxiv.Result.Author('Pieter E. Vermaas')]","As quantum technologies (QT) have been becoming more and more realized, their
potential impact on and relation with society has been developing into a
pressing issue for exploration. In this paper, we investigate the topic of
democratization in the context of QT, particularly quantum computing. The paper
contains three main sections. First, we briefly introduce different theories of
democracy (participatory, representative, and deliberative), and how the
concept of democratization can be formulated with respect to these frameworks.
Second, we give an overview of how the concept of democratization is utilized
by the actors in the QT field. Democratization is mainly adopted by companies
working on quantum computing and used in a very narrow understanding of the
concept. We provide a discussion on where to locate this formulation of
democratization used by the QT community within the overall conceptual
landscape of democracy theories. Third, we explore various narratives and
counter-narratives concerning democratization in QT and we propose a five-step
approach to operationalizing the concept of democratization with respect to
different theories of democracy. Finally, we explore the concept of
democratization in QT beyond quantum computing. In conclusion, we argue that
although the ongoing efforts in the democratization of QT are necessary steps
towards the democratization of this set of emerging technologies, they should
not be accepted as sufficient to argue that QT is a democratized field. We
argue that more reflexivity and responsiveness regarding the narratives and
actions adopted by the actors in the QT field and making the underlying
assumptions of ongoing efforts on democratization of QT can result in a better
technology for the society.",-0.3318969,-0.3293675,-0.37934953,B
9769,"This enabled further research and development efforts that supported
the second quantum revolution.","Recent developments in technical fields such as nanotechnology, quantum optics,
and condensed matter physics resulted in capabilities that allow researchers to reliably create,
manipulate, and exploit quantum specific phenomena at a high precision and accuracy levels that
were previously not possible.",The extent of this technological revolution can be observed quantitatively.,2022-08-05 19:23:09+00:00,Democratization of Quantum Technologies,physics.soc-ph,"['physics.soc-ph', 'quant-ph']","[arxiv.Result.Author('Zeki C. Seskir'), arxiv.Result.Author('Steven Umbrello'), arxiv.Result.Author('Christopher Coenen'), arxiv.Result.Author('Pieter E. Vermaas')]","As quantum technologies (QT) advance, their potential impact on and relation
with society has been developing into an important issue for exploration. In
this paper, we investigate the topic of democratization in the context of QT,
particularly quantum computing. The paper contains three main sections. First,
we briefly introduce different theories of democracy (participatory,
representative, and deliberative) and how the concept of democratization can be
formulated with respect to whether democracy is taken as an intrinsic or
instrumental value. Second, we give an overview of how the concept of
democratization is used in the QT field. Democratization is mainly adopted by
companies working on quantum computing and used in a very narrow understanding
of the concept. Third, we explore various narratives and counter-narratives
concerning democratization in QT. Finally, we explore the general efforts of
democratization in QT such as different forms of access, formation of grassroot
communities and special interest groups, the emerging culture of manifesto
writing, and how these can be located within the different theories of
democracy. In conclusion, we argue that although the ongoing efforts in the
democratization of QT are necessary steps towards the democratization of this
set of emerging technologies, they should not be accepted as sufficient to
argue that QT is a democratized field. We argue that more reflexivity and
responsiveness regarding the narratives and actions adopted by the actors in
the QT field, and making the underlying assumptions of ongoing efforts on
democratization of QT explicit, can result in a better technology for society.",-0.33189708,-0.32936755,-0.37934953,B
9848,"Despite the specificity of traffic flows and markets, similar complexity-related
challenges are abundant in many cities around the world.59 To accomplish fully
functional, real-time, and bi-directional physical-virtual frameworks able to manage
mobility and other complexity challenges effectively,60 further research is required.61
Recent research focuses, for example, on connecting mobility with heterogeneous socio-
economic interactions and urban logistics.62 Reflecting the diversity of actions and
preferences in reality precisely is one of the goals of digital twins that increasingly aim
to mirror entire economic systems.63 Starting from operations for business
intelligence,64 they ultimately strive to optimize markets and financial ecosystems for
more sustainable development65 or other goals.","In these systems, a flexible and prompt adaptation to the respective local
conditions and needs is a promising approach to promote coordination and favourable
self-organization in the system, while the possibility of optimal control is often an
illusion.","Precision Health

Digital twins have been proposed also for use in medicine and health care.66 For
example, they have been applied to prepare for difficult surgeries.67 Eventually, digital
twins are expected to capture body structures, functions, and processes not only on a
macro-scale, i.e.",2022-07-20 11:16:28+00:00,"Digital Twins: Potentials, Ethical Issues, and Limitations",physics.soc-ph,"['physics.soc-ph', 'J.2; J.4; K.4.1']","[arxiv.Result.Author('Dirk Helbing'), arxiv.Result.Author('Javier Argota Sánchez-Vaquerizo')]","After Big Data and Artificial Intelligence (AI), the subject of Digital Twins
has emerged as another promising technology, advocated, built, and sold by
various IT companies. The approach aims to produce highly realistic models of
real systems. In the case of dynamically changing systems, such digital twins
would have a life, i.e. they would change their behaviour over time and, in
perspective, take decisions like their real counterparts \textemdash so the
vision. In contrast to animated avatars, however, which only imitate the
behaviour of real systems, like deep fakes, digital twins aim to be accurate
""digital copies"", i.e. ""duplicates"" of reality, which may interact with reality
and with their physical counterparts. This chapter explores, what are possible
applications and implications, limitations, and threats.",-0.20064437,0.20995863,0.044760503,C
9925,"We synthesize the key analysis approaches and based on which
identify and outline the following directions for further research: (i) predictions of passenger travel
patterns; (ii) decision support for service planning and policy evaluation; (iii) enhanced geographical
characterisation of users’ travel patterns; (iv) from demand analytics towards behavioural analytics.","Furthermore, a critical review of the literature reveals an important distinction between studies
focusing on the intra-personal variability of travel patterns versus those concerned with the inter-
personal variability of travel patterns.",Keywords: Public transport; Smart card data; Market segmentation; Clustering; Urban analytics.,2022-08-10 13:57:49+00:00,Identifying Human Mobility Patterns using Smart Card Data,physics.soc-ph,"['physics.soc-ph', 'cs.SI']",[arxiv.Result.Author('Oded Cats')],"Human mobility is subject to collective dynamics that are the outcome of
numerous individual choices. Smart card data which originated as a means of
facilitating automated fare collections has emerged as an invaluable source for
analyzing human mobility patterns. A variety of clustering and segmentation
techniques has been adopted and adapted for applications ranging from passenger
demand market segmentation to the analysis of urban activity locations. In this
paper we provide a systematic review of the state-of-the-art on clustering
public transport users based on their temporal or spatial-temporal
characteristics as well as studies that use the patter to characterize
individual stations, lines or urban areas. Furthermore, a critical review of
the literature reveals an important distinction between studies focusing on the
intra-personal variability of travel patterns versus those concerned with the
inter-personal variability of travel patterns. We synthesize the key analysis
approaches and based on which identify and outline the following directions for
further research: (i) predictions of passenger travel patterns; (ii) decision
support for service planning and policy evaluation; (iii) enhanced geographical
characterization of users' travel patterns; (iv) from demand analytics towards
behavioral analytics.",-0.11420112,0.58289194,0.036704373,C
9926,"Notwithstanding, there is much room
for further research in this domain as elaborated in Section 4.","In contrast, spatial
features are subject to local variations and are often labelled, their discretization is not trivial and the
findings cannot be easily made transferable to other contexts.","Table 2: Summary of studies clustering user spatial-temporal travel patterns

Study           Aim               Analysis             Clustering                 Contextual     Application
                                                                                  information    City/Region
                                                       technique

                                                                                                                 Modes  Tap- in (I) /
                                                                                                                        Tap out (O)
Ma et al.",2022-08-10 13:57:49+00:00,Identifying Human Mobility Patterns using Smart Card Data,physics.soc-ph,"['physics.soc-ph', 'cs.SI']",[arxiv.Result.Author('Oded Cats')],"Human mobility is subject to collective dynamics that are the outcome of
numerous individual choices. Smart card data which originated as a means of
facilitating automated fare collections has emerged as an invaluable source for
analyzing human mobility patterns. A variety of clustering and segmentation
techniques has been adopted and adapted for applications ranging from passenger
demand market segmentation to the analysis of urban activity locations. In this
paper we provide a systematic review of the state-of-the-art on clustering
public transport users based on their temporal or spatial-temporal
characteristics as well as studies that use the patter to characterize
individual stations, lines or urban areas. Furthermore, a critical review of
the literature reveals an important distinction between studies focusing on the
intra-personal variability of travel patterns versus those concerned with the
inter-personal variability of travel patterns. We synthesize the key analysis
approaches and based on which identify and outline the following directions for
further research: (i) predictions of passenger travel patterns; (ii) decision
support for service planning and policy evaluation; (iii) enhanced geographical
characterization of users' travel patterns; (iv) from demand analytics towards
behavioral analytics.",-0.068131104,0.43819392,-0.013523335,C
9927,"Based on our critical review of the state-of-the-art we identify in the following four knowledge gaps
and outline related directions for further research.",2021b)., Predictions of passenger travel patterns.,2022-08-10 13:57:49+00:00,Identifying Human Mobility Patterns using Smart Card Data,physics.soc-ph,"['physics.soc-ph', 'cs.SI']",[arxiv.Result.Author('Oded Cats')],"Human mobility is subject to collective dynamics that are the outcome of
numerous individual choices. Smart card data which originated as a means of
facilitating automated fare collections has emerged as an invaluable source for
analyzing human mobility patterns. A variety of clustering and segmentation
techniques has been adopted and adapted for applications ranging from passenger
demand market segmentation to the analysis of urban activity locations. In this
paper we provide a systematic review of the state-of-the-art on clustering
public transport users based on their temporal or spatial-temporal
characteristics as well as studies that use the patter to characterize
individual stations, lines or urban areas. Furthermore, a critical review of
the literature reveals an important distinction between studies focusing on the
intra-personal variability of travel patterns versus those concerned with the
inter-personal variability of travel patterns. We synthesize the key analysis
approaches and based on which identify and outline the following directions for
further research: (i) predictions of passenger travel patterns; (ii) decision
support for service planning and policy evaluation; (iii) enhanced geographical
characterization of users' travel patterns; (iv) from demand analytics towards
behavioral analytics.",-0.092811316,0.563397,0.03169529,C
10057,"It is unclear whether this eﬀect
also arises among diﬀerent sector coupling options and green hydrogen, if
renewable energy surpluses are scarce, so further research is required.","However, [17] also highlight that the electriﬁcation of ﬂexible transport and
heating, in conjuncture with long-term thermal energy storage, crowds out
the ﬂexibility provided by electricity storage.","More-
over, we do not analyze the spatial aspects of domestic hydrogen provision in

                                               23
this study.",2022-08-05 21:29:53+00:00,Power sector effects of alternative production and storage options for green hydrogen,physics.soc-ph,"['physics.soc-ph', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Dana Kirchem'), arxiv.Result.Author('Wolf-Peter Schill')]","The use of green hydrogen can support the decarbonization of sectors which
are difficult to electrify, such as industry or heavy transport. Yet, the wider
power sector effects of providing green hydrogen are not well understood so
far. We use an open-source electricity sector model to investigate potential
power sector interactions of three alternative supply chains for green hydrogen
in Germany in the year 2030. We distinguish between model settings in which
Germany is modeled as an electric island versus embedded in an interconnected
system with its neighboring countries, as well as settings with and without
technology-specific capacity bounds on renewable energies. Our analysis aims to
inform other energy system modelers as well as policy makers. The findings
suggest that large-scale hydrogen storage can provide valuable flexibility to
the power system in settings with high renewable energy shares. These benefits
are more pronounced in the absence of flexibility from geographical balancing.
We further find that the effects of green hydrogen production on the optimal
generation portfolio strongly depend on the model assumptions regarding
capacity expansion potentials. We also identify a potential distributional
effect of green hydrogen production at the expense of other electricity
consumers, of which policy makers should be aware.",-0.2854473,-0.04923349,-0.1845262,B
10190,"Developing
methods, such as maximum likelihood [45] or algorithmic classiﬁcation [46] techniques, to improve
                                                                                                                              18

the speciﬁcity of early warning signals is an important area of further research.",1).,"ACKNOWLEDGMENTS

    We thank Hiroshi Kori and Makito Oku for valuable discussion.",2022-08-18 17:10:20+00:00,Early Warnings for Multistage Transitions in Dynamics on Networks,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Neil G. MacLaren'), arxiv.Result.Author('Prosenjit Kundu'), arxiv.Result.Author('Naoki Masuda')]","Successfully anticipating sudden major changes in complex systems is a
practical concern. Such complex systems often form a heterogeneous network,
which may show multistage transitions in which some nodes experience a regime
shift earlier than others as an environment gradually changes. Here we
investigate early warning signals for networked systems undergoing a multistage
transition. We found that knowledge of both the ongoing multistage transition
and network structure enables us to calculate effective early warning signals
for multistage transitions. Furthermore, we found that small subsets of nodes
could anticipate transitions as well as or even better than using all the
nodes. Even if we fix the network and dynamical system, no single best subset
of nodes provides good early warning signals, and a good choice of sentinel
nodes depends on the tipping direction and the current stage of the dynamics
within a multistage transition, which we systematically characterize.",-0.015453722,-0.049768604,-0.026589442,A
10630,"That look for a more optimized method and a quantiﬁable uniﬁed standard to judge network
types is the direction we can further study.","The contribution of this paper has four aspects, the vectorized expression of network informa-
tion dissemination variables, inferring the relationship between reconstruction eﬀectiveness and
network type, using the diﬀerence of degree variance as an index to evaluate the diﬀerence of
network structure, and the optimization methods of making the network closer to small-world
network are presented.","The directions for further research are as follows:

(1) Try network reconstruction with HGNN and compare it with EM algorithm network recon-
     struction.",2022-09-01 01:57:04+00:00,Expectation-Maximizing Network Reconstruction and MostApplicable Network Types Based on Binary Time Series Data,physics.soc-ph,"['physics.soc-ph', 'math.ST', 'stat.TH']","[arxiv.Result.Author('Kaiwei Liu'), arxiv.Result.Author('Xing Lv'), arxiv.Result.Author('Jiang Zhang')]","Based on the binary time series data of social infection dynamics, we propose
a general framework to reconstruct 2-simplex complexes with two-body and
three-body interactions by combining the maximum likelihood estimation in
statistical inference and introducing the expectation maximization. In order to
improve the code running efficiency, the whole algorithm adopts vectorization
expression. Through the inference of maximum likelihood estimation, the
vectorization expression of the edge existence probability can be obtained, and
through the probability matrix, the adjacency matrix of the network can be
estimated. We apply a two-step scheme to improve the effectiveness of network
reconstruction while reducing the amount of computation significantly. The
framework has been tested on different types of complex networks. Among them,
four kinds of networks can obtain high reconstruction effectiveness. Besides,
we study the influence of noise data or random interference and prove the
robustness of the framework, then the effects of two kinds of hyper-parameters
on the experimental results are tested. Finally, we analyze which type of
network is more suitable for this framework, and propose methods to improve the
effectiveness of the experimental results.",0.5862623,0.0050129527,-0.3079049,A
10631,"The directions for further research are as follows:

(1) Try network reconstruction with HGNN and compare it with EM algorithm network recon-
     struction.","That look for a more optimized method and a quantiﬁable uniﬁed standard to judge network
types is the direction we can further study.","(2) Try to introduce the E-Bayesian estimation into the estimation of the network adjacency
     matrix, and the reconstruction under the EM algorithm can be regarded as a comparison.",2022-09-01 01:57:04+00:00,Expectation-Maximizing Network Reconstruction and MostApplicable Network Types Based on Binary Time Series Data,physics.soc-ph,"['physics.soc-ph', 'math.ST', 'stat.TH']","[arxiv.Result.Author('Kaiwei Liu'), arxiv.Result.Author('Xing Lv'), arxiv.Result.Author('Jiang Zhang')]","Based on the binary time series data of social infection dynamics, we propose
a general framework to reconstruct 2-simplex complexes with two-body and
three-body interactions by combining the maximum likelihood estimation in
statistical inference and introducing the expectation maximization. In order to
improve the code running efficiency, the whole algorithm adopts vectorization
expression. Through the inference of maximum likelihood estimation, the
vectorization expression of the edge existence probability can be obtained, and
through the probability matrix, the adjacency matrix of the network can be
estimated. We apply a two-step scheme to improve the effectiveness of network
reconstruction while reducing the amount of computation significantly. The
framework has been tested on different types of complex networks. Among them,
four kinds of networks can obtain high reconstruction effectiveness. Besides,
we study the influence of noise data or random interference and prove the
robustness of the framework, then the effects of two kinds of hyper-parameters
on the experimental results are tested. Finally, we analyze which type of
network is more suitable for this framework, and propose methods to improve the
effectiveness of the experimental results.",0.5659354,-0.034486122,-0.30406278,A
10632,"That look for a more optimized method and a quantiﬁable uniﬁed standard to judge network
types is the direction we can further study.","The contribution of this paper has four aspects, the vectorized expression of network informa-
tion dissemination variables, inferring the relationship between reconstruction eﬀectiveness and
network type, using the diﬀerence of degree variance as an index to evaluate the diﬀerence of
network structure, and the optimization methods of making the network closer to small-world
network are presented.","The directions for further research are as follows:

(1) Try network reconstruction with HGNN and compare it with EM algorithm network recon-
     struction.",2022-09-01 01:57:04+00:00,Expectation-Maximizing Network Reconstruction and MostApplicable Network Types Based on Binary Time Series Data,physics.soc-ph,"['physics.soc-ph', 'math.ST', 'stat.TH']","[arxiv.Result.Author('Kaiwei Liu'), arxiv.Result.Author('Xing Lv'), arxiv.Result.Author('Fei Gao'), arxiv.Result.Author('Jiang Zhang')]","Based on the binary time series data of social infection dynamics, we propose
a general framework to reconstruct 2-simplex complexes with two-body and
three-body interactions by combining the maximum likelihood estimation in
statistical inference and introducing the expectation maximization. In order to
improve the code running efficiency, the whole algorithm adopts vectorization
expression. Through the inference of maximum likelihood estimation, the
vectorization expression of the edge existence probability can be obtained, and
through the probability matrix, the adjacency matrix of the network can be
estimated. We apply a two-step scheme to improve the effectiveness of network
reconstruction while reducing the amount of computation significantly. The
framework has been tested on different types of complex networks. Among them,
four kinds of networks can obtain high reconstruction effectiveness. Besides,
we study the influence of noise data or random interference and prove the
robustness of the framework, then the effects of two kinds of hyper-parameters
on the experimental results are tested. Finally, we analyze which type of
network is more suitable for this framework, and propose methods to improve the
effectiveness of the experimental results.",0.5862623,0.0050129527,-0.3079049,A
10633,"The directions for further research are as follows:

(1) Try network reconstruction with HGNN and compare it with EM algorithm network recon-
     struction.","That look for a more optimized method and a quantiﬁable uniﬁed standard to judge network
types is the direction we can further study.","(2) Try to introduce the E-Bayesian estimation into the estimation of the network adjacency
     matrix, and the reconstruction under the EM algorithm can be regarded as a comparison.",2022-09-01 01:57:04+00:00,Expectation-Maximizing Network Reconstruction and MostApplicable Network Types Based on Binary Time Series Data,physics.soc-ph,"['physics.soc-ph', 'math.ST', 'stat.TH']","[arxiv.Result.Author('Kaiwei Liu'), arxiv.Result.Author('Xing Lv'), arxiv.Result.Author('Fei Gao'), arxiv.Result.Author('Jiang Zhang')]","Based on the binary time series data of social infection dynamics, we propose
a general framework to reconstruct 2-simplex complexes with two-body and
three-body interactions by combining the maximum likelihood estimation in
statistical inference and introducing the expectation maximization. In order to
improve the code running efficiency, the whole algorithm adopts vectorization
expression. Through the inference of maximum likelihood estimation, the
vectorization expression of the edge existence probability can be obtained, and
through the probability matrix, the adjacency matrix of the network can be
estimated. We apply a two-step scheme to improve the effectiveness of network
reconstruction while reducing the amount of computation significantly. The
framework has been tested on different types of complex networks. Among them,
four kinds of networks can obtain high reconstruction effectiveness. Besides,
we study the influence of noise data or random interference and prove the
robustness of the framework, then the effects of two kinds of hyper-parameters
on the experimental results are tested. Finally, we analyze which type of
network is more suitable for this framework, and propose methods to improve the
effectiveness of the experimental results.",0.5659354,-0.034486122,-0.30406278,A
10634,"That look for a more optimized method and a quantiﬁable uniﬁed standard to judge network
types is the direction we can further study.","The contribution of this paper has four aspects, the vectorized expression of network informa-
tion dissemination variables, inferring the relationship between reconstruction eﬀectiveness and
network type, using the diﬀerence of degree variance as an index to evaluate the diﬀerence of
network structure, and the optimization methods of making the network closer to small-world
network are presented.","The directions for further research are as follows:

(1) Try network reconstruction with HGNN and compare it with EM algorithm network recon-
     struction.",2022-09-01 01:57:04+00:00,Expectation-Maximizing Network Reconstruction and MostApplicable Network Types Based on Binary Time Series Data,physics.soc-ph,"['physics.soc-ph', 'math.ST', 'stat.TH']","[arxiv.Result.Author('Kaiwei Liu'), arxiv.Result.Author('Xing Lv'), arxiv.Result.Author('Fei Gao'), arxiv.Result.Author('Jiang Zhang')]","Based on the binary time series data of social infection dynamics, we propose
a general framework to reconstruct 2-simplex complexes with two-body and
three-body interactions by combining the maximum likelihood estimation in
statistical inference and introducing the expectation maximization. In order to
improve the code running efficiency, the whole algorithm adopts vectorization
expression. Through the inference of maximum likelihood estimation, the
vectorization expression of the edge existence probability can be obtained, and
through the probability matrix, the adjacency matrix of the network can be
estimated. We apply a two-step scheme to improve the effectiveness of network
reconstruction while reducing the amount of computation significantly. The
framework has been tested on different types of complex networks. Among them,
four kinds of networks can obtain high reconstruction effectiveness. Besides,
we study the influence of noise data or random interference and prove the
robustness of the framework, then the effects of two kinds of hyper-parameters
on the experimental results are tested. Finally, we analyze which type of
network is more suitable for this framework, and propose methods to improve the
effectiveness of the experimental results.",0.5862623,0.0050129527,-0.3079049,A
10635,"The directions for further research are as follows:

(1) Try network reconstruction with HGNN and compare it with EM algorithm network recon-
     struction.","That look for a more optimized method and a quantiﬁable uniﬁed standard to judge network
types is the direction we can further study.","(2) Try to introduce the E-Bayesian estimation into the estimation of the network adjacency
     matrix, and the reconstruction under the EM algorithm can be regarded as a comparison.",2022-09-01 01:57:04+00:00,Expectation-Maximizing Network Reconstruction and MostApplicable Network Types Based on Binary Time Series Data,physics.soc-ph,"['physics.soc-ph', 'math.ST', 'stat.TH']","[arxiv.Result.Author('Kaiwei Liu'), arxiv.Result.Author('Xing Lv'), arxiv.Result.Author('Fei Gao'), arxiv.Result.Author('Jiang Zhang')]","Based on the binary time series data of social infection dynamics, we propose
a general framework to reconstruct 2-simplex complexes with two-body and
three-body interactions by combining the maximum likelihood estimation in
statistical inference and introducing the expectation maximization. In order to
improve the code running efficiency, the whole algorithm adopts vectorization
expression. Through the inference of maximum likelihood estimation, the
vectorization expression of the edge existence probability can be obtained, and
through the probability matrix, the adjacency matrix of the network can be
estimated. We apply a two-step scheme to improve the effectiveness of network
reconstruction while reducing the amount of computation significantly. The
framework has been tested on different types of complex networks. Among them,
four kinds of networks can obtain high reconstruction effectiveness. Besides,
we study the influence of noise data or random interference and prove the
robustness of the framework, then the effects of two kinds of hyper-parameters
on the experimental results are tested. Finally, we analyze which type of
network is more suitable for this framework, and propose methods to improve the
effectiveness of the experimental results.",0.5659354,-0.034486122,-0.30406278,A
10774,"Section 6 discusses the results, limitations, and further research
and Section 7 concludes with the policy recommendations.","Section 4 introduces the Danish case study and Section 5 the numerical
analysis.","5
2.",2022-09-05 06:41:06+00:00,Power-to-X in Energy Hubs: Operations and Policies Supporting the Scale-Up of Renewable Fuel Production,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Ioannis Kountouris'), arxiv.Result.Author('Lissy Langer'), arxiv.Result.Author('Rasmus Bramstoft'), arxiv.Result.Author('Marie Münster'), arxiv.Result.Author('Dogan Keles')]","Power-to-X (P2X) needs to scale up rapidly to provide the fuels required in
the hard-to-decarbonize industrial and heavy transport sector. Only recently,
the European Commission proposed requirements for \textit{renewable} fuels. P2X
energy hubs enable efficient synergies between energy infrastructures,
production facilities, and storage options. In this study, we explore the
optimal operation of an energy hub by leveraging the flexibility of P2X
including hydrogen, methanol, and ammonia synthesizers, and analyze potential
revenue streams such as the day-ahead and ancillary service markets. We propose
EnerHub2X, a mixed-integer linear program that maximizes the hub's profit based
on current market prices, considering technical constraints of P2X such as unit
commitment and non-linear efficiencies. We model a representative Danish energy
hub and find that without price incentives, it mainly produces liquid hydrogen
and sells renewable electricity. Only by adding a price premium of about 50\%
(0.16 \euro{}/kg) to the conventional fuel prices, sufficient amounts of
renewable ammonia and methanol are produced. To utilize production efficiently,
on-site renewable capacity and P2X must be carefully aligned. We show that
renewable power purchase agreements can provide flexibility while complying
with the rules set by the European Commission.",-0.21401252,-0.03808583,0.01682459,B
10830,"Additionally, the danger from superiority of artificial intelligence over
humans, although still somewhat abstract, is worthy of further study as its potential for impeding
humankind’s progress towards becoming a more advanced civilization cannot be confidently
dismissed.","Since
the risks from asteroid impacts could be considered to reside mostly in the far future, it can be
concluded that nuclear war, climate change, and pandemics are presently the most prominent
threats to humanity.",1.,2022-09-02 05:38:26+00:00,Avoiding the Great Filter: A Simulation of Important Factors for Human Survival,physics.soc-ph,"['physics.soc-ph', 'physics.pop-ph']","[arxiv.Result.Author('Jonathan H. Jiang'), arxiv.Result.Author('Ruoxin Huang'), arxiv.Result.Author('Prithwis Das'), arxiv.Result.Author('Fuyang Feng'), arxiv.Result.Author('Philip E. Rosen'), arxiv.Result.Author('Chenyu Zuo'), arxiv.Result.Author('Rocky Gao'), arxiv.Result.Author('Kristen A. Fahy'), arxiv.Result.Author('Leopold Van Ijzendoorn')]","Humanity's path to avoiding extinction is a daunting and inevitable challenge
which proves difficult to solve, partially due to the lack of data and evidence
surrounding the concept. We aim to address this confusion by addressing the
most dangerous threats to humanity, in hopes of providing a direction to
approach this problem. Using a probabilistic model, we observed the effects of
nuclear war, climate change, asteroid impacts, artificial intelligence and
pandemics, which are the most harmful disasters in terms of their extent of
destruction on the length of human survival. We consider the starting point of
the predicted average number of survival years as the present calendar year.
Nuclear war, when sampling from an artificial normal distribution, results in
an average human survival time of 60 years into the future starting from the
present, before a civilization-ending disaster. While climate change results in
an average human survival time of 193 years, the simulation based on impact
from asteroids results in an average of 1754 years. Since the risks from
asteroid impacts could be considered to reside mostly in the far future, it can
be concluded that nuclear war, climate change, and pandemics are presently the
most prominent threats to humanity. Additionally, the danger from superiority
of artificial intelligence over humans, although still somewhat abstract, is
worthy of further study as its potential for impeding humankind's progress
towards becoming a more advanced civilization cannot be confidently dismissed.",-0.24238099,-0.06227058,-0.06496866,B
10943,Three main recommendations for further research can be formulated based on our work.,"This could support PT authorities in choosing between different
PT closure alternatives taking into account the accumulated, total impact on PT ridership and revenue losses.","First, we
recommend testing the performance of more complex, deep-learning models with time sequences on predicting
demand impacts of PT closures.",2022-08-05 18:26:43+00:00,Analysis and Prediction of Ridership Impacts during Planned Public Transport Disruptions,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Menno Yap'), arxiv.Result.Author('Oded Cats')]","Urban metro and tram networks are regularly subject to planned disruptions,
including closures, resulting from the need to maintain and renew
infrastructure. In this study, we first empirically analyse the passenger
demand response to planned public transport disruptions based on individual
passenger travel behaviour, based on which we infer generalised journey time
and cost elasticities for different passenger groups and time periods of the
day. Second, we develop a model which enables predicting public transport
demand for individual origin-destination pairs affected by a closure. The model
is trained based on the empirically observed travel behaviour. The proposed
method is applied to a case study closure in Amsterdam, the Netherlands, based
on which we empirically derive generalised journey time and generalised journey
cost elasticities. Our results suggest that passengers demand response is lower
for frequent users of the public transport network, as well as during weekdays,
especially during the peak periods. Arguably, this stems from a higher share of
captive passengers with a mandatory journey purpose in these segments, who will
continue making their journey nevertheless. During weekends, with typically
higher shares of leisure related journeys, a much more pronounced demand
response is found. The estimated neural network regression model is able to
predict passenger demand during public transport closures with a high level of
accuracy. This provides public transport agencies more precise insights into
the impact of closures on their revenue losses and on the potential need for
resources reallocation.",-0.2110684,0.24942145,-0.026610807,B
11019,"Accordingly, this paper and the proposed tool can serve as a backbone
for further research and business activities built on top of PyPSA-Earth, to meet various energy transition
planning needs that must be cheap and fast to develop for every nation and community on Earth.","Given the ﬂexibility of the approach,
additional improvements can be integrated, and scholars interested in contributing are invited to contact the
PyPSA-Earth team to join forces.","Further studies, may address the sector-coupled version of PyPSA-Earth, to account for sectors beyond
power (e.g.",2022-09-10 13:14:20+00:00,PyPSA-Earth. A New Global Open Energy System Optimization Model Demonstrated in Africa,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Maximilian Parzen'), arxiv.Result.Author('Hazem Abdel-Khalek'), arxiv.Result.Author('Ekaterina Fedorova'), arxiv.Result.Author('Matin Mahmood'), arxiv.Result.Author('Martha Maria Frysztacki'), arxiv.Result.Author('Johannes Hampp'), arxiv.Result.Author('Lukas Franken'), arxiv.Result.Author('Leon Schumm'), arxiv.Result.Author('Fabian Neumann'), arxiv.Result.Author('Davide Poli'), arxiv.Result.Author('Aristides Kiprakis'), arxiv.Result.Author('Davide Fioriti')]","Macro-energy system modelling is used by decision-makers to steer the global
energy transition toward an affordable, sustainable and reliable future.
Closed-source models are the current standard for most policy and industry
decisions. However, open models have proven to be competitive alternatives that
promote science, robust technical analysis, collaboration and transparent
policy decision-making. Yet, two issues slow the adoption: open models are
often designed with limited geographic scope, hindering synergies from
collaboration, or are based on low spatially resolved data, limiting their use.
Here we introduce PyPSA-Earth, the first open-source global energy system model
with data in high spatial and temporal resolution. It enables large-scale
collaboration by providing a tool that can model the world energy system or any
subset of it. This work is derived from the European PyPSA-Eur model using new
data and functions. It is suitable for operational as well as combined
generation, storage and transmission expansion studies. The model provides two
main features: (1) customizable data extraction and preparation scripts with
global coverage and (2) a PyPSA energy modelling framework integration. The
data includes electricity demand, generation and medium to high-voltage
networks from open sources, yet additional data can be further integrated. A
broad range of clustering and grid meshing strategies help adapt the model to
computational and practical needs. A data validation for the entire African
continent is performed and the optimization features are tested with a 2060
net-zero planning study for Nigeria. The demonstration shows that the presented
developments can build a highly detailed energy system model for energy
planning studies to support policy and technical decision-making. We welcome
joining forces to address the challenges of the energy transition together.",-0.34521952,-0.037657574,-0.24657351,B
11394,"This highlights a stark contrast between S1      To further study the angular distance between connected
and SD, D > 1, in a regime where the underlying hyper-       nodes, the marginal pdf of η has to be computed given
bolic geometry is the most binding to the topology of the    the pdf of κ, which is done in Appendix A, along with
graph.","(24)
maximum at the threshold η for all D > 1, which means
quite counterintuitively that in this limit, most connected                                                            0
nodes will be separated by their local maximal angular
distance η.",the computation for fA(1).,2022-09-19 17:24:30+00:00,Dimension matters when modeling network communities in hyperbolic spaces,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech']","[arxiv.Result.Author('Béatrice Désy'), arxiv.Result.Author('Patrick Desrosiers'), arxiv.Result.Author('Antoine Allard')]","Over the last decade, random hyperbolic graphs have proved successful in
providing geometric explanations to many key properties of real-world networks,
including strong clustering, high navigability, and heterogeneous degree
distributions. Although a few studies have shown that hyperbolic models can
generate community structures, another salient feature observed in real
networks, we argue that the current models are overlooking the choice of the
latent space dimensionality that is required to adequately represent data with
communities. We show that there is an important qualitative difference between
the lowest-dimensional model and its higher-dimensional counterparts with
respect to how similarity between nodes restricts connection probabilities.
Since more dimensions also increases the number of nearest neighbors for
angular clusters representing communities, considering only one more dimension
allows us to generate more realistic and diverse community structures.",0.26008368,-0.25686195,-0.040254794,A
11408,"Given
this ﬁnding, much of the further study focuses on plants like the mid-range
reference plant with a modiﬁed πV OM,th.","the plant value is predicted almost entirely by the cost of marginal generation,
our studies should be applicable to assess the value of a wide range of devices,
not only pulsed tokamaks, as part of similar future electricity systems.","The marginal value of fusion is determined by the resources that it com-
petes with or complements, and the composition of this set depends on the
πV OM,total of a given fusion plant.",2022-09-19 22:52:54+00:00,The value of fusion energy to a decarbonized United States electric grid,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('J. A. Schwartz'), arxiv.Result.Author('W. Ricks'), arxiv.Result.Author('E. Kolemen'), arxiv.Result.Author('J. D. Jenkins')]","Fusion could be a part of future decarbonized electricity systems, but it
will need to compete with other technologies. In particular, pulsed tokamaks
have a unique operational mode, and evaluating which characteristics make them
economically competitive can help select between design pathways. Using a
capacity expansion and operations model, we determined cost thresholds for
pulsed tokamaks to reach a range of penetration levels in a future decarbonized
US Eastern Interconnection. The required capital cost to reach a fusion
capacity of 100 GW varied from \$3000/kW to \$7200/kW, and the equilibrium
penetration increases rapidly with decreasing cost. The value per unit power
capacity depends on the variable operational cost and on cost of its
competition, particularly fission, much more than on the pulse cycle
parameters. These findings can therefore provide initial cost targets for
fusion more generally in the United States.",-0.32964107,-0.2896592,-0.31961143,B
11409,"Given
this ﬁnding, much of the further study focuses on plants like the mid-range
reference plant with a modiﬁed πV OM,th.","Since within a given scenario
the plant value is predicted almost entirely by the cost of marginal generation,
our studies should be applicable to assess the value of a wide range of devices,
not only pulsed tokamaks, as part of similar future electricity systems.","The marginal value of fusion is determined by the resources that it com-
petes with or complements, and the composition of this set depends on the
πV OM,total of a given fusion plant.",2022-09-19 22:52:54+00:00,The value of fusion energy to a decarbonized United States electric grid,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('J. A. Schwartz'), arxiv.Result.Author('W. Ricks'), arxiv.Result.Author('E. Kolemen'), arxiv.Result.Author('J. D. Jenkins')]","Fusion could be a part of future decarbonized electricity systems, but it
will need to compete with other technologies. In particular, pulsed tokamaks
have a unique operational mode, and evaluating which characteristics make them
economically competitive can help select between design pathways. Using a
capacity expansion and operations model, we determined cost thresholds for
pulsed tokamaks to reach a range of penetration levels in a future decarbonized
US Eastern Interconnection. The required capital cost to reach a fusion
capacity of 100 GW varied from \$3000/kW to \$7200/kW, and the equilibrium
penetration increases rapidly with decreasing cost. The value per unit power
capacity depends on the variable operational cost and on the cost of its
competition, particularly fission, much more than on the pulse cycle
parameters. These findings can therefore provide initial cost targets for
fusion more generally in the United States.",-0.3256345,-0.27708673,-0.30524382,B
12015,"If IT project performance does not follow a normal distribution, it could have important
implications for both IT project management research and practice, and further research is
warranted to understand the actual form of the distribution.","Therefore, they used the
log-transformed variable in their analysis.","To advance our understanding
in this area, a large sample study of IT project performance is needed.2 In this research, we
collected such a dataset and examined the cost performance of IT projects (i.e., cost
overruns).",2022-09-30 11:31:59+00:00,The Empirical Reality of IT Project Cost Overruns: Discovering A Power-Law Distribution,physics.soc-ph,"['physics.soc-ph', 'q-fin.RM']","[arxiv.Result.Author('Bent Flyvbjerg'), arxiv.Result.Author('Alexander Budzier'), arxiv.Result.Author('Jong Seok Lee'), arxiv.Result.Author('Mark Keil'), arxiv.Result.Author('Daniel Lunn'), arxiv.Result.Author('Dirk W. Bester')]","If managers assume a normal or near-normal distribution of Information
Technology (IT) project cost overruns, as is common, and cost overruns can be
shown to follow a power-law distribution, managers may be unwittingly exposing
their organizations to extreme risk by severely underestimating the probability
of large cost overruns. In this research, we collect and analyze a large sample
comprised of 5,392 IT projects to empirically examine the probability
distribution of IT project cost overruns. Further, we propose and examine a
mechanism that can explain such a distribution. Our results reveal that IT
projects are far riskier in terms of cost than normally assumed by decision
makers and scholars. Specifically, we found that IT project cost overruns
follow a power-law distribution in which there are a large number of projects
with relatively small overruns and a fat tail that includes a smaller number of
projects with extreme overruns. A possible generative mechanism for the
identified power-law distribution is found in interdependencies among
technological components in IT systems. We propose and demonstrate, through
computer simulation, that a problem in a single technological component can
lead to chain reactions in which other interdependent components are affected,
causing substantial overruns. What the power law tells us is that extreme IT
project cost overruns will occur and that the prevalence of these will be
grossly underestimated if managers assume that overruns follow a normal or
near-normal distribution. This underscores the importance of realistically
assessing and mitigating the cost risk of new IT projects up front.",-0.21291131,-0.0014254968,-0.17738876,B
12220,"Availability of Data and Code
All the datasets and scripts used for this study are freely available for further research and replication purposes.","We consider each census tract as an individual mobility
center and estimate a pair of parameters α and β for each census tract using Particle Swarm Optimization technique39–41.","The Safegraph mobility dataset is freely available for academic research purposes through request at:

https://www.safegraph.com/academics
The Google COVID-19 Community Mobility Reports data is available at:

https://www.google.com/covid19/mobility/
All scripts are available at the project github repository:

https://github.com/alppboz/safegraph-covid19-mobility

Abbreviations
CBG: Census Block Group
NPI: Non-pharmaceutical Intervention
NYC: New York City
POI: Point of Interest

                                                                                                                      11/13
References

 1.",2022-10-06 21:11:02+00:00,"One City, Two Tales: Using Mobility Networks to Understand Neighborhood Resilience and Fragility during the COVID-19 Pandemic",physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Hasan Alp Boz'), arxiv.Result.Author('Mohsen Bahrami'), arxiv.Result.Author('Selim Balcisoy'), arxiv.Result.Author('Burcin Bozkaya'), arxiv.Result.Author('Nina Mazar'), arxiv.Result.Author('Aaron Nichols'), arxiv.Result.Author('Alex Pentland')]","What predicts a neighborhood's resilience and adaptability to essential
public health policies and shelter-in-place regulations that prevent the
harmful spread of COVID-19? To answer this question, in this paper we present a
novel application of human mobility patterns and human behavior in a network
setting. We analyze mobility data in New York City over two years, from January
2019 to December 2020, and create weekly mobility networks between Census Block
Groups by aggregating Point of Interest level visit patterns. Our results
suggest that both the socioeconomic and geographic attributes of neighborhoods
significantly predict neighborhood adaptability to the shelter-in-place
policies active at that time. That is, our findings and simulation results
reveal that in addition to factors such as race, education, and income,
geographical attributes such as access to amenities in a neighborhood that
satisfy community needs were equally important factors for predicting
neighborhood adaptability and the spread of COVID-19. The results of our study
provide insights that can enhance urban planning strategies that contribute to
pandemic alleviation efforts, which in turn may help urban areas become more
resilient to exogenous shocks such as the COVID-19 pandemic.",0.045690946,0.223117,0.030298537,C
12507,"11/16
                                                  F. Schweitzer, C. Zingg, G. Casiraghi:
                                    Struggling with change: The fragile resilience of collectives

                                                         (Submitted for publication)

4.2 A need for further research

The need for overarching, quantitative and explanatory resilience measures for collectives has
been pointed out in the literature for long.","Moreover, the concepts of robustness
and adaptivity underlying our resilience approach also allow a better understanding of the reasons
for decreasing resilience.","Davidson (2010) emphasises that “the current [re-
silience theory] is not readily applicable to social systems.” She mentions reasons such as the
ability of social systems to postpone the eﬀects of disruptions, unequally distributed agency,
humans’ ability to anticipate risks, complex power relations, or a tendency for complex collective
actions in social systems.",2022-10-15 08:27:27+00:00,Struggling with change: The fragile resilience of collectives,physics.soc-ph,"['physics.soc-ph', 'cs.SI', 'nlin.AO']","[arxiv.Result.Author('Frank Schweitzer'), arxiv.Result.Author('Christian Zingg'), arxiv.Result.Author('Giona Casiraghi')]","Collectives form non-equilibrium social structures characterised by a
volatile dynamics. Individuals join or leave. Social relations change quickly.
Therefore, differently from engineered or ecological systems, a resilient
reference state cannot be defined. We propose a novel resilience measure
combining two dimensions: robustness and adaptivity. We demonstrate how they
can be quantified using data from a software developer collective. Our analysis
reveals a resilience life cycle, i.e., stages of increasing resilience are
followed by stages of decreasing resilience. We explain the reasons for these
observed dynamics and provide a formal model to reproduce them. The resilience
life cycle allows distinguishing between short-term resilience, given by a
sequence of resilient states, and long-term resilience, which requires
collectives to survive through different cycles.",-0.018311867,-0.038274914,0.1497069,A
12657,"Directions for further research                                                                 22

                                                 References                                                                                         23

                                                                                                1.","Shapley-Shubik index calculator                                                               21

                                                 5.","Introduction

                                                 Simplicial complexes are a natural tool for modeling structures in which there exist interactions
                                                 between objects; the objects can be represented by vertices and their interaction by a simplex.",2022-10-18 11:35:08+00:00,Quantification of power and the geometry of simplicial complexes,physics.soc-ph,"['physics.soc-ph', 'math.CO', '91F10, 91B12, 05E45']","[arxiv.Result.Author('Anastasia Brooks'), arxiv.Result.Author('Franjo Sarcevic'), arxiv.Result.Author('Ismar Volic')]","We use simplicial complexes to model voting systems where certain coalitions
are considered unlikely or impossible. We express the Banzhaf and
Shapley-Shubik power indices in terms of such voting systems. We show how
unweighted and weighted Banzhaf and Shapley-Shubik power indices can be
computed by formulas which count certain types of simplices. We also provide
several examples and supply the code for calculating these indices in Python.",0.12014352,-0.09936778,-0.014584351,A
12658,"Finally,
we oﬀer potential directions for further research.",Section 4 provides some details and samples from the code.,"One of the most promising routes is to improve
our formulas by taking into account that the probability of coalition formation may be non-binary,
which is of course closer to reality.",2022-10-18 11:35:08+00:00,Quantification of power and the geometry of simplicial complexes,physics.soc-ph,"['physics.soc-ph', 'math.CO', '91F10, 91B12, 05E45']","[arxiv.Result.Author('Anastasia Brooks'), arxiv.Result.Author('Franjo Sarcevic'), arxiv.Result.Author('Ismar Volic')]","We use simplicial complexes to model voting systems where certain coalitions
are considered unlikely or impossible. We express the Banzhaf and
Shapley-Shubik power indices in terms of such voting systems. We show how
unweighted and weighted Banzhaf and Shapley-Shubik power indices can be
computed by formulas which count certain types of simplices. We also provide
several examples and supply the code for calculating these indices in Python.",0.08948583,-0.18596263,0.21136025,A
12659,"Directions for further research

As discussed in [AMS18], the traditional method for assigning weights to a voter may not ac-
curately represent the power of a member in a voting system because it does not consider the
diplomatic inﬂuence of the member.","def maximumCoalitions(coalitionsList):
             maxCoalitions = [ ]
             for coalition in coalitionsList:
                  maxCoalitions.append(coalition)
             for coalition in coalitionsList:
                  for i in range(len(coalitionsList)):
                       if len(coalition) < len(coalitionsList[ i ]):
                            counter = 0
                            for voter in coalition:
                                 if voter in coalitionsList[i]:
                                 counter +=1
                            if counter >= len(coalition) and coalition in maxCoalitions:
                                 maxCoalitions.remove(coalition)
             return maxCoalitions

                               5.","The authors use an association matrix to quantify the “per-
suasive power” of a voter and use the entries of that matrix to improve the Banzhaf power index.",2022-10-18 11:35:08+00:00,Quantification of power and the geometry of simplicial complexes,physics.soc-ph,"['physics.soc-ph', 'math.CO', '91F10, 91B12, 05E45']","[arxiv.Result.Author('Anastasia Brooks'), arxiv.Result.Author('Franjo Sarcevic'), arxiv.Result.Author('Ismar Volic')]","We use simplicial complexes to model voting systems where certain coalitions
are considered unlikely or impossible. We express the Banzhaf and
Shapley-Shubik power indices in terms of such voting systems. We show how
unweighted and weighted Banzhaf and Shapley-Shubik power indices can be
computed by formulas which count certain types of simplices. We also provide
several examples and supply the code for calculating these indices in Python.",0.03790576,-0.098349065,0.21437979,A
13079,"Besides speciﬁc
                                                              results around social complexity build-up, our work introduces a powerful tool to be applied in
                                                              further study cases.",These shifts help us sharpen our observations.,"Keywords: social complexity, Dunbar number, social networks, social dynamics, linguistics

                                                 I.",2022-10-27 11:03:51+00:00,A spectrum of complexity uncovers Dunbar's number and other leaps in social structure,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Martín Saavedra'), arxiv.Result.Author('Jorge Mira'), arxiv.Result.Author('Alberto P Muñuzuri'), arxiv.Result.Author('Luís F Seoane')]","Social dynamics are shaped by each person's actions, as well as by collective
trends that emerge when individuals are brought together. These latter kind of
influences escape anyone's control. They are, instead, dominated by aggregate
societal properties such as size, polarization, cohesion, or hierarchy. Such
features add nuance and complexity to social structure, and might be present,
or not, for societies of different sizes. How do societies become more complex?
Are there specific scales at which they are reorganized into emergent entities?
In this paper we introduce the {\em social complexity spectrum}, a
methodological tool, inspired by theoretical considerations about dynamics on
complex networks, that addresses these questions empirically. We use as a probe
a sociolinguistic process that has unfolded over decades within the
north-western Spanish region of Galicia, across populations of varied sizes. We
estimate how societal complexity increases monotonously with population size;
and how specific scales stand out, at which complexity would build up faster.
These scales are noted as dips in our spectra, similarly to missing wavelengths
in light spectroscopy. Also, `red-' and `blue-shifts' take place as the general
population shifted from more rural to more urban settings. These shifts help us
sharpen our observations. Besides specific results around social complexity
build-up, our work introduces a powerful tool to be applied in further study
cases.",0.084078476,0.014070818,0.22379959,A
13154,"Figure 13

6.2 Future directions
We pose here several additional questions for further research.","As higher quality
tracking data becomes more available, one could (for example) better track the efﬁcacy and ubiquity of
the use of paths in the safe progression graphs, as well as get a more accurate computation of the graphs.","First, our framework does not consider
opponent response.",2022-10-29 02:56:40+00:00,Controlling ball progression in soccer,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Catherine Pfaff'), arxiv.Result.Author('Emily Hunter'), arxiv.Result.Author('Haozhi Hong'), arxiv.Result.Author('Daniel Forestell'), arxiv.Result.Author('Ari Fialkov'), arxiv.Result.Author('Zoey Drassinower'), arxiv.Result.Author('Timothy Chan')]","In this paper, we examine how soccer players can use their spatial
relationships to control parts of the field and safely move play up the field
via chains of ``safe configurations,'' i.e. configurations of players on a team
ensuring the possessor of the ball has a collection of open passing options all
connected by open passing lanes. An underlying philosophy behind our work is
that it is most difficult to disrupt an attacking team's progression forward
(with the ball) when this attacking team has multiple ``good'' options of how
to proceed at each moment in time. We provide some evidence of this. Our main
construction is a directed weighted graph where the nodes encode the
configurations of players, the directed edges encode transformations between
these configurations, and the weights encode the relative frequencies of the
transformations. We conclude with a few applications and proposed further
investigations. We believe that our work can serve as a launching platform for
significant further investigation into how teams can ``safely progress'' the
ball up the field, strategy development, and sophisticated decision making
metrics. For coaches and players, we aim to streamline the process of moving
safely up the field. In particular, we aim to construct a framework for
creating new successful patterns of movement and aim that our framework allows
for the development of new strategy. At the same time, our work could help
identify configurations on the field which often result in turnovers or that
allow for a lot of strategic flexibility (also impeding defensive containment
of the attacking team).
  *Because the contributions of the female authors to this paper were by no
means less than those of the male authors, we have chosen to reverse convention
and to list the authors in reverse alphabetical order to ensure that the female
authors were not listed only after the male authors.",0.18857649,-0.03386028,0.2519839,A
13155,"16/21
                                        Figure 13

6.2 Future directions
We pose here several additional questions for further research.","As higher quality
tracking data becomes more available, one could (for example) better track the efﬁcacy and ubiquity of
the use of paths in the safe progression graphs, as well as get a more accurate computation of the graphs.","First, our framework does not consider
opponent response.",2022-10-29 02:56:40+00:00,Controlling ball progression in soccer,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Catherine Pfaff'), arxiv.Result.Author('Emily Hunter'), arxiv.Result.Author('Haozhi Hong'), arxiv.Result.Author('Daniel Forestell'), arxiv.Result.Author('Ari Fialkov'), arxiv.Result.Author('Zoey Drassinower'), arxiv.Result.Author('Timothy Chan')]","In this paper, we examine how soccer players can use their spatial
relationships to control parts of the field and safely move play up the field
via chains of ``safe configurations,'' i.e. configurations of players on a team
ensuring the possessor of the ball has a collection of open passing options all
connected by open passing lanes. An underlying philosophy behind our work is
that it is most difficult to disrupt an attacking team's progression forward
(with the ball) when this attacking team has multiple ``good'' options of how
to proceed at each moment in time. We provide some evidence of this. Our main
construction is a directed weighted graph where the nodes encode the
configurations of players, the directed edges encode transformations between
these configurations, and the weights encode the relative frequencies of the
transformations. We conclude with a few applications and proposed further
investigations. We believe that our work can serve as a launching platform for
significant further investigation into how teams can ``safely progress'' the
ball up the field, strategy development, and sophisticated decision making
metrics. For coaches and players, we aim to streamline the process of moving
safely up the field. In particular, we aim to construct a framework for
creating new successful patterns of movement and aim that our framework allows
for the development of new strategy. At the same time, our work could help
identify configurations on the field which often result in turnovers or that
allow for a lot of strategic flexibility (also impeding defensive containment
of the attacking team).
  *Because the contributions of the female authors to this paper were by no
means less than those of the male authors, we have chosen to reverse convention
and to list the authors in reverse alphabetical order to ensure that the female
authors were not listed only after the male authors.",0.19056597,-0.034039237,0.25853172,A
13377,"Motivated by the results of this paper, further research should focus on
generalizing the performed analyses to other contexts: Is diversity key only
for fantasy football?","This echoes the
theoretical predictions of the Diversity Theorems [23].",What about other teams?,2022-11-04 12:43:14+00:00,Diversity is Key: Fantasy football dream teams under budget constraints,physics.soc-ph,"['physics.soc-ph', '91A68, 91A90, 91A80, 91A10, 91A06', 'J.4; J.2; G.4']","[arxiv.Result.Author('Josef Gullholm'), arxiv.Result.Author('Jil Klünder'), arxiv.Result.Author('Julie Rowlett'), arxiv.Result.Author('Jonathan Stålberg')]","Imagine you are managing a football team and have a fixed budget for
salaries. Which players should you draft for your team? We investigated this
question using the wealth of data available from fantasy premier league
football (soccer). Using the players' data from past seasons, for several
seasons and several different budget constraints, we identified the highest
scoring fantasy team for each season subject to each budget constraint. We then
investigated quantifiable characteristics of these teams. Interesting, across
nearly every variable that is significant to the game of football and the
budget, these top teams display diversity across these variables. Our results
indicate that diversity is a general feature of top performing teams.",-0.1858365,-0.13074672,0.36352718,B
13378,"We propose that further research should focus on strengthening
the results obtained here and analyzing them with regard to the applicability
in other contexts such as HR.","Therefore, transferring this idea to real teams would be
interesting.","18
References

 [1] Thuillier, J. P. (2004) Le sport dans la civilisation ´etrusque : entre
      Gr`ece et Rome.",2022-11-04 12:43:14+00:00,Diversity is Key: Fantasy football dream teams under budget constraints,physics.soc-ph,"['physics.soc-ph', '91A68, 91A90, 91A80, 91A10, 91A06', 'J.4; J.2; G.4']","[arxiv.Result.Author('Josef Gullholm'), arxiv.Result.Author('Jil Klünder'), arxiv.Result.Author('Julie Rowlett'), arxiv.Result.Author('Jonathan Stålberg')]","Imagine you are managing a football team and have a fixed budget for
salaries. Which players should you draft for your team? We investigated this
question using the wealth of data available from fantasy premier league
football (soccer). Using the players' data from past seasons, for several
seasons and several different budget constraints, we identified the highest
scoring fantasy team for each season subject to each budget constraint. We then
investigated quantifiable characteristics of these teams. Interesting, across
nearly every variable that is significant to the game of football and the
budget, these top teams display diversity across these variables. Our results
indicate that diversity is a general feature of top performing teams.",-0.20328745,-0.04314939,0.38068396,B
13494,"This eﬀect is clearly visible in Figure 7,      pointing out the deﬁciency of the original manuscript,
where the successive increase in θ leads to the systematic       possible directions of further research and References 35
impression that the opinions of minorities (or at least          and 39 and particularly Reference 87 as well as for en-
their spatial dispersion) successively decrease the mea-         couraging us to make the source code available online
sured number Φ∗ of the remaining opinions.","We thank anonymous Reviewers for
toral threshold.",This eﬀect            [75].,2022-11-08 11:54:05+00:00,Vanishing opinions in Latané model of opinion formation,physics.soc-ph,"['physics.soc-ph', 'cs.SI']","[arxiv.Result.Author('Maciej Dworak'), arxiv.Result.Author('Krzysztof Malarz')]","In this paper, the results of computer simulations based on
Nowak--Szamrej--Latan\'e model with multiple (from two to five) opinions
available in the system are presented. We introduce the noise discrimination
level (which says how small the clusters of agents could be considered as
negligible) as a quite useful quantity that allows qualitative characterization
of the system. We show that depending on the introduced noise discrimination
level, the range of actors' interactions (controlled indirectly by an exponent
in distance scaling function, the larger the exponent the more influential the
nearest neighbors are) and the information noise level (modeled as social
temperature, which increases results in increase of randomness in taking the
opinion by the agents), the ultimate number of the opinions (measured as the
number of clusters of actors sharing the same opinion in clusters greater than
the noise discrimination level) may be smaller than the number of opinions
available in the system. These are observed in small and large information
noise limits but result in either unanimity, or polarization, or randomization
of opinions.",-0.15462537,-0.043570563,0.017044194,B
13532,"For example, the threshold meth-         of urban systems require further research.","These eﬀorts include          ban hierarchies based on percolation theory [4] or com-
                                                the identiﬁcation of contiguous urban areas with a high       munity detection [30, 32], robust methods to delineate
                                                density of human activity, i.e., density-based methods        multi-scale urban clusters and reveal the diﬀerent levels
                                                [4, 31, 41, 42, 47].","ods deﬁne areas that exceed a certain density of pop-
                                                ulation, infrastructure (e.g., road networks), or socio-         With the development of information and communi-
                                                economic activity (e.g., nighttime light) as urban areas      cation technology, mobile phone data have shown great
                                                [6, 13, 33, 41].",2022-11-09 12:25:31+00:00,Constructing multi-level urban clusters based on population distributions and interactions,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Wenpu Cao'), arxiv.Result.Author('Lei Dong'), arxiv.Result.Author('Ying Cheng'), arxiv.Result.Author('Lun Wu'), arxiv.Result.Author('Qinghua Guo'), arxiv.Result.Author('Yu Liu')]","A city (or an urban cluster) is not an isolated spatial unit, but a
combination of areas with closely linked socio-economic activities. However, so
far, we lack a consistent and quantitative approach to define multi-level urban
clusters through these socio-economic connections. Here, using granular
population distribution and flow data from China, we propose a bottom-up
aggregation approach to quantify urban clusters at multiple spatial scales. We
reveal six 'phases' (i.e., levels) in the population density-flow diagram, each
of which corresponds to a spatial configuration of urban clusters from large to
small. Besides, our results show that Zipf's law appears only after the fifth
level, confirming the spatially dependent nature of urban laws. Our approach
does not need pre-defined administrative boundaries and can be applied
effectively on a global scale.",0.036831185,0.3617201,-0.03603346,C
13778,"4.1 Susceptible-decelerated-withdrawing model

The unstable characteristics in the transient response make the dynamic mechanism of responses
interesting for further study.","In section 4.2, we reveal the local dynamic mechanism of
transient responses through the parameters of propagation rates and recovery rates from this model.","We reformulate the velocity change of section i due to the heavy con-

                                                                               10
Response functions as a new concept to study local dynamics in trafﬁc networks

Figure 8: Left: time evolution of empirically occurring probability of heavy congestion during a workday,
where the blue color highlights the value of probability; right: the empirical occurring probabilities in the
morning, in the afternoon and in a whole workday versus the empirical duration of heavy congestion, as well
as the distribution of theoretical duration of heavy congestion worked out by equations (12) and (13).",2022-11-15 15:50:00+00:00,Response functions as a new concept to study local dynamics in traffic networks,physics.soc-ph,"['physics.soc-ph', 'physics.data-an']","[arxiv.Result.Author('Shanshan Wang'), arxiv.Result.Author('Michael Schreckenberg'), arxiv.Result.Author('Thomas Guhr')]","Vehicle velocities in neighbouring road sections are correlated with memory
effects. We explore the response of the velocities in the sequence of sections
to a congestion in a given section and its dynamic characteristics. To this
end, we transfer the concept of response functions from previous applications
in finance to traffic systems. The dynamical characteristics are of particular
interest. We identify two phases, a phase of transient response and a phase of
long-term response. The transient response is pronounced when considering the
backward propagation of heavy congestions but almost vanishes for forward
propagation. For each response phase, we find a linear relation between the
velocity response and the congestion correlator, implying that the correlation
of congestion is most likely the cause for the velocity response. We also
construct a susceptible-decelerated-withdrawing model mathematically inspired
by the susceptible-infectious-recovered (SIR) model in epidemiology to describe
the transient response. We find that the heavy congestion on a section
propagates forward and backward at a similar rate, but the forward sections are
more likely to recover from the effect of heavy congestion than the backward
sections.",0.28808284,0.11957513,0.10206731,A
14199,"Translating the possible routes and path lengths to measurable request distances and

detours is outside the scope of this study and is a direction for further research.","Therefore,

computing total trip lengths requires understanding the possible paths a trip may take among

the regions.","Nevertheless, we

should mention that even some regional trip lengths are the same for diﬀerent services/activities,

the total trip length from the time of a vehicle assigned to the ﬁrst passenger, until completing the

trip varies across time and sequence of activities.",2022-11-26 13:12:12+00:00,A dynamic multi-region MFD model for ride-sourcing systems with ridesplitting,physics.soc-ph,"['physics.soc-ph', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Caio Vitor Beojone'), arxiv.Result.Author('Nikolas Geroliminis')]","Dynamic network-level models directly addressing ride-sourcing services can
support the development of efficient strategies for both congestion alleviation
and promotion of more sustainable mobility. Recent developments presented
models focusing on ride-hailing (solo rides), but no work addressed
ridesplitting (shared rides) in dynamic contexts. Here, we sought to develop a
dynamic aggregated traffic network model capable of representing ride-sourcing
services and background traffic in a macroscopic multi-region urban network. We
combined the Macroscopic Fundamental Diagram (MFD) with detailed state-space
and transition descriptions of background traffic and ride-sourcing vehicles in
their activities to formulate mass conservation equations. Accumulation-based
MFD models might experience additional errors due to the variation profile of
trip lengths, e.g., when vehicles cruise for passengers. We integrate the
so-called M-model that utilizes the total remaining distance to capture
dynamics of regional and inter-regional flows and accumulations for different
vehicle (private or ride-sourcing) states. This aggregated model is capable to
reproduce the dynamics of complex systems without using resource-expensive
simulations. We also show that the model can accurately forecast the vehicles'
conditions in near-future predictions. Later, a comparison with benchmark
models showed lower errors in the proposed model in all states. Finally, we
evaluated the model's robustness to noises in its inputs, and forecast errors
remained below 15% even where inputs were 20% off the actual values for
ride-sourcing vehicles. The development of such a model prepares the path for
developing real-time feedback-based management policies such as priority-based
perimeter control or repositioning strategies for idle ride-sourcing vehicles
and developing regulations over ride-sourcing in congested areas.",-0.092283234,0.4520474,0.084684156,C
14312,"Estimating bird density using passive acoustic monitoring: A review of
   methods and suggestions for further research.",(2021).,"Ibis, 163(3), 765–783.",2022-11-29 10:41:41+00:00,Physics-based model to predict the acoustic detection distance of terrestrial autonomous recording units over the diel cycle and across seasons: insights from an Alpine and a Neotropical forest,physics.soc-ph,['physics.soc-ph'],"[arxiv.Result.Author('Sylvain Haupert'), arxiv.Result.Author('Frédéric Sèbe'), arxiv.Result.Author('Jérôme Sueur')]","1. Passive acoustic monitoring of biodiversity is growing fast, as it offers
an alternative to traditional aural point count surveys, with the possibility
to deploy long-term acoustic surveys in large and complex natural environments.
However, there is still a clear need to evaluate how the frequency-and
distancedependent attenuation of sound as well as the ambient sound level
impact the acoustic detection distance of the soniferous species in natural
environments over the diel cycles and across seasons. This is of great
importance to avoid pseudoreplication and to provide relevant biodiversity
indicators, including species richness, species abundance and species density.
2. To address the issue of detection distance, we tested a field-based protocol
in a Neotropical rainforest (French Guiana, France) and in an Alpine coniferous
forest (Jura, France). This standardized and repeatable method consists in a
recording session of the ambient sound directly followed by an experiment using
a calibrated white noise sound broadcast at different positions along a 100 m
linear transect. We then used acoustic laws to reveal the basic physics behind
sound propagation attenuation. 3. We demonstrate that habitat attenuation in
two different kinds of forests can be modelled by an exponential decay law with
a linear dependence on frequency and distance. We also report that habitat
attenuation, as first approximation, can be summarized by a single value, the
coefficient of attenuation of the habitat. 4. Finally, we show that the
detection distance can be predicted knowing the contribution of each
attenuation factor, the coefficient of attenuation of the habitat, the ambient
sound pressure level and the amplitude and frequency bandwidth characteristics
of the transmitted sound. We show that the detection 1 distance mostly depends
on the ambient sound and may vary by a factor of up to 5 over the diel cycle
and across seasons. These results reinforce the need to take into account the
variation of the detection distance when performing passive acoustic surveys
and producing reliable biodiversity indicators.",-0.16256486,0.0051990543,-0.062190812,B
14322,These questions are a good starting point for further research.,"How will properties of generic networks change when we randomly choose per-
       mutation σ1 and σ2 with LF 2(σ1σ2−1) precisely set from all possible values of
       LF 2?","Acknowledgements

While working on this paper, the second author was partially supported by the SGH
fund KAE/S21 and by the NCN fund UMO-2018/31/B/HS4/01005.",2022-10-22 14:11:58+00:00,Generic Networks of Votings,physics.soc-ph,"['physics.soc-ph', 'math.CO', 'math.PR']","[arxiv.Result.Author('Ewa Zawiślak-Sprysak'), arxiv.Result.Author('Paweł Zawiślak')]","In this paper, we analyse results of the $15^{\textrm{th}}$ International
Henryk Wieniawski Violin Competition by comparing the properties of its results
network to the properties of \emph{generic networks of votings}.",0.29014832,-0.12493345,-0.0764111,A
14514,"Whether it is more important to act on it or trigger a shock like the 2011
one, it is an issue that deserve further research.","Italy should increase the value of the imitation
coeﬃcient a (t).","ACKNOWLEDGMENT

   The paper constitutes the ﬁrst result of the interdisciplinary and inter-institutional re-
search group working within the research project funded by the Italian Ministry of Univer-
sity and Research under the title: “Teorie e strumenti per la transizione ecologica: proﬁli
ﬁlosoﬁci, matematici, etici e giuridici relativi alla sﬁda di sostenibilita` del carbon budget
/ Theories and tools for the ecological transition: philosophical, mathematical, ethical and
juridical proﬁles related to the sustainability challenge of the carbon budget” (Prog.",2022-11-24 19:51:02+00:00,Multiscale modeling of Green Energy Transition: Structural properties and an example,physics.soc-ph,"['physics.soc-ph', 'math.PR', '60K35, 91A16, 60J27']","[arxiv.Result.Author('Franco Flandoli'), arxiv.Result.Author('Fausto Corvino'), arxiv.Result.Author('Marta Leocata'), arxiv.Result.Author('Giulia Livieri'), arxiv.Result.Author('Silvia Morlacchi'), arxiv.Result.Author('Alberto Pirni')]","This work deals with Green Energy Transition, focusing on the problem of
understanding subjects' reactions to the urgency of a change and inputs coming
from governments. We use the example of solar photovoltaic as a concrete
example and compare our models to data. We develop two models following two
sets of assumptions: a Markovian model of interacting particle systems and a
MFG model. In both cases, we derive the scaling limit deterministic dynamics.
We compare the two dynamics to Italian solar photovoltaic data identifying
periods where the first model describes the behavior of domestic data well and
a period where the second model captures a particular feature of data
corresponding to companies. The comprehensive analysis, which is integrated by
a philosophical inquiry focusing on the conceptual vocabulary used and the
correlative implications, leads to the formulation of hypotheses about the
efficacy of different forms of governmental subsidies.",-0.33335137,-0.039789394,-0.0714914,B
14630,"Finally, in
Section 5, we summarize our ﬁndings and propose further research questions.","In
Section 3, we put under the microscope the aforementioned characteristics,
which have been associated with fractality, one by one, and in Section 4, we
also present our novel machine learning approach for the problem.",2.,2022-12-06 16:34:45+00:00,Towards a Better Understanding of the Characteristics of Fractal Networks,physics.soc-ph,"['physics.soc-ph', 'cs.DM', 'cs.SI', 'physics.data-an', '05C75, 05C82, 05C85, 05C90, 28A80, 68R10']","[arxiv.Result.Author('Enikő Zakar-Polyák'), arxiv.Result.Author('Marcell Nagy'), arxiv.Result.Author('Roland Molontay')]","The fractal nature of complex networks has received a great deal of research
interest in the last two decades. Similarly to geometric fractals, the
fractality of networks can also be defined with the so-called box-covering
method. A network is called fractal if the minimum number of boxes needed to
cover the entire network follows a power-law relation with the size of the
boxes. The fractality of networks has been associated with various network
properties throughout the years, for example, disassortativity, repulsion
between hubs, long-range-repulsive correlation, and small edge betweenness
centralities. However, these assertions are usually based on tailor-made
network models and on a small number of real networks, hence their ubiquity is
often disputed.
  Since fractal networks have been shown to have important properties, such as
robustness against intentional attacks, it is in dire need to uncover the
underlying mechanisms causing fractality. Hence, the main goal of this work is
to get a better understanding of the origins of fractality in complex networks.
To this end, we systematically review the previous results on the relationship
between various network characteristics and fractality. Moreover, we perform a
comprehensive analysis of these relations on five network models and a large
number of real-world networks originating from six domains. We clarify which
characteristics are universally present in fractal networks and which features
are just artifacts or coincidences.",0.16294138,-0.11787075,0.2744289,A
14631,"Finally, in
Section 5, we summarize our ﬁndings and propose further research questions.","In
Section 3, we put under the microscope the aforementioned characteristics,
which have been associated with fractality, one by one, and in Section 4, we
also present our novel machine learning approach for the problem.",2.,2022-12-06 16:34:45+00:00,Towards a Better Understanding of the Characteristics of Fractal Networks,physics.soc-ph,"['physics.soc-ph', 'cs.DM', 'cs.SI', 'physics.data-an', '05C75, 05C82, 05C85, 05C90, 28A80, 68R10']","[arxiv.Result.Author('Enikő Zakar-Polyák'), arxiv.Result.Author('Marcell Nagy'), arxiv.Result.Author('Roland Molontay')]","The fractal nature of complex networks has received a great deal of research
interest in the last two decades. Similarly to geometric fractals, the
fractality of networks can also be defined with the so-called box-covering
method. A network is called fractal if the minimum number of boxes needed to
cover the entire network follows a power-law relation with the size of the
boxes. The fractality of networks has been associated with various network
properties throughout the years, for example, disassortativity, repulsion
between hubs, long-range-repulsive correlation, and small edge betweenness
centralities. However, these assertions are usually based on tailor-made
network models and on a small number of real networks, hence their ubiquity is
often disputed.
  Since fractal networks have been shown to have important properties, such as
robustness against intentional attacks, it is in dire need to uncover the
underlying mechanisms causing fractality. Hence, the main goal of this work is
to get a better understanding of the origins of fractality in complex networks.
To this end, we systematically review the previous results on the relationship
between various network characteristics and fractality. Moreover, we perform a
comprehensive analysis of these relations on five network models and a large
number of real-world networks originating from six domains. We clarify which
characteristics are universally present in fractal networks and which features
are just artifacts or coincidences.",0.16294138,-0.11787075,0.2744289,A
14632,"Finally, in
Section 5, we summarize our ﬁndings and propose further research questions.","In
Section 3, we put under the microscope the aforementioned characteristics,
which have been associated with fractality, one by one, and in Section 4, we
also present our novel machine learning approach for the problem.",2.,2022-12-06 16:34:45+00:00,Towards a Better Understanding of the Characteristics of Fractal Networks,physics.soc-ph,"['physics.soc-ph', 'cs.DM', 'cs.SI', 'physics.data-an', '05C75, 05C82, 05C85, 05C90, 28A80, 68R10']","[arxiv.Result.Author('Enikő Zakar-Polyák'), arxiv.Result.Author('Marcell Nagy'), arxiv.Result.Author('Roland Molontay')]","The fractal nature of complex networks has received a great deal of research
interest in the last two decades. Similarly to geometric fractals, the
fractality of networks can also be defined with the so-called box-covering
method. A network is called fractal if the minimum number of boxes needed to
cover the entire network follows a power-law relation with the size of the
boxes. The fractality of networks has been associated with various network
properties throughout the years, for example, disassortativity, repulsion
between hubs, long-range-repulsive correlation, and small edge betweenness
centralities. However, these assertions are usually based on tailor-made
network models and on a small number of real networks, hence their ubiquity is
often disputed.
  Since fractal networks have been shown to have important properties, such as
robustness against intentional attacks, it is in dire need to uncover the
underlying mechanisms causing fractality. Hence, the main goal of this work is
to get a better understanding of the origins of fractality in complex networks.
To this end, we systematically review the previous results on the relationship
between various network characteristics and fractality. Moreover, we perform a
comprehensive analysis of these relations on five network models and a large
number of real-world networks originating from six domains. We clarify which
characteristics are universally present in fractal networks and which features
are just artifacts or coincidences.",0.16294138,-0.11787075,0.2744289,A
14774,"Our
                                                                     observations may hopefully stimulate further research to check the potential diﬀerences
                                                                     between PGG and R-PGG due to the alternative complexity of conditions.","This analysis also reveals
                                                                     the distinct roles of cooperator and defector strategies in the mentioned games.","Keywords: Public goods game, Cooperation, Heterogeneity, Evolutionary game theory
A reversed form of public goods game  2

1.",2022-12-09 18:06:48+00:00,A reversed form of public goods game: equivalence and difference,physics.soc-ph,"['physics.soc-ph', 'cond-mat.stat-mech', 'cs.GT', 'nlin.PS']","[arxiv.Result.Author('Chaoqian Wang'), arxiv.Result.Author('Attila Szolnoki')]","According to the public goods game (PGG) protocol, participants decide freely
whether they want to contribute to a common pool or not, but the resulting
benefit is distributed equally. A conceptually similar dilemma situation may
emerge when participants consider if they claim a common resource but the
related cost is covered equally by all group members. The latter establishes a
reversed form of the original public goods game (R-PGG). In this work, we show
that R-PGG is equivalent to PGG in several circumstances, starting from the
traditional analysis, via the evolutionary approach in unstructured
populations, to Monte Carlo simulations in structured populations. However,
there are also cases when the behavior of R-PGG could be surprisingly different
from the outcome of PGG. When the key parameters are heterogeneous, for
instance, the results of PGG and R-PGG could be diverse even if we apply the
same amplitudes of heterogeneity. We find that the heterogeneity in R-PGG
generally impedes cooperation, while the opposite is observed for PGG. These
diverse system reactions can be understood if we follow how payoff functions
change when introducing heterogeneity in the parameter space. This analysis
also reveals the distinct roles of cooperator and defector strategies in the
mentioned games. Our observations may hopefully stimulate further research to
check the potential differences between PGG and R-PGG due to the alternative
complexity of conditions.",-0.0872939,-0.06115946,0.2063509,B
15001,"is classiﬁed as of low certainty according to the Aerosol Society
[29] and requires further study.",This topic  to the momentum boundary layer.,"Therefore, the present work aims        The Rayleigh number, Ra, describes the ratio of buoyancy
to provide more insights on this phenomenon.",2022-12-14 17:38:49+00:00,Modelling of human exhaled sprays and aerosols to enable real-time estimation of spatially-resolved infection risk in indoor environments,physics.soc-ph,"['physics.soc-ph', 'physics.comp-ph', 'physics.flu-dyn']","[arxiv.Result.Author('Daniel Fredrich'), arxiv.Result.Author('Aliyah M. Akbar'), arxiv.Result.Author('Muhammad Faieq bin Mohd Fadzil'), arxiv.Result.Author('Afxentis Giorgallis'), arxiv.Result.Author('Alexander Kruse'), arxiv.Result.Author('Noah Liniger'), arxiv.Result.Author('Lazaros Papachristodoulou'), arxiv.Result.Author('Andrea Giusti')]","A numerical framework for the 'real-time' estimation of the infection risk
from airborne diseases (e.g., SARS-CoV-2) in indoor spaces such as hospitals,
restaurants, cinemas or teaching rooms is proposed. The developed model is
based on the use of computational fluid dynamics as a pre-processor to obtain
the time-averaged ventilation pattern inside a room, and a post-processing tool
for the computation of the dispersion of sprays and aerosols emitted by its
occupants in 'real time'. The model can predict the dispersion and
concentration of droplets carrying viable viral copies in the air, the
contamination of surfaces, and the related spatially-resolved infection risk.
It may therefore provide useful information for the management of indoor
environments in terms of, e.g., maximum occupancy, air changes per hour and
cleaning of surfaces. This work describes the fundamentals of the model and its
main characteristics. The model was developed using open-source software and is
conceived to be simple, user-friendly and highly automated to enable any
potential user to perform estimations of the local infection risk.",-0.089950934,-0.1575253,-0.06386294,B
