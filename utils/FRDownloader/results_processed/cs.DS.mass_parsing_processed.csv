Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
331,The concluding Section 5 provides open questions for further research.,"Section 4 is devoted to Longest Path above

                                                              4
Diameter.","2 Preliminaries

Parameterized Complexity.",2022-01-10 12:37:02+00:00,Detours in Directed Graphs,cs.DS,"['cs.DS', 'cs.DM']","[arxiv.Result.Author('Fedor V. Fomin'), arxiv.Result.Author('Petr A. Golovach'), arxiv.Result.Author('William Lochet'), arxiv.Result.Author('Danil Sagunov'), arxiv.Result.Author('Kirill Simonov'), arxiv.Result.Author('Saket Saurabh')]","We study two ""above guarantee"" versions of the classical Longest Path problem
on undirected and directed graphs and obtain the following results. In the
first variant of Longest Path that we study, called Longest Detour, the task is
to decide whether a graph has an (s,t)-path of length at least dist_G(s,t)+k
(where dist_G(s,t) denotes the length of a shortest path from s to t).
Bez\'akov\'a et al. proved that on undirected graphs the problem is
fixed-parameter tractable (FPT) by providing an algorithm of running time 2^{O
(k)} n. Further, they left the parameterized complexity of the problem on
directed graphs open. Our first main result establishes a connection between
Longest Detour on directed graphs and 3-Disjoint Paths on directed graphs.
Using these new insights, we design a 2^{O(k)} n^{O(1)} time algorithm for the
problem on directed planar graphs. Further, the new approach yields a
significantly faster FPT algorithm on undirected graphs.
  In the second variant of Longest Path, namely Longest Path Above Diameter,
the task is to decide whether the graph has a path of length at least diam(G)+k
(diam(G) denotes the length of a longest shortest path in a graph G). We obtain
dichotomy results about Longest Path Above Diameter on undirected and directed
graphs. For (un)directed graphs, Longest Path Above Diameter is NP-complete
even for k=1. However, if the input undirected graph is 2-connected, then the
problem is FPT. On the other hand, for 2-connected directed graphs, we show
that Longest Path Above Diameter is solvable in polynomial time for each
k\in{1,\dots, 4} and is NP-complete for every k\geq 5. The parameterized
complexity of Longest Path Above Diameter on general directed graphs remains an
interesting open problem.",-0.026190847,0.22156501,-0.12879723,A
458,"As a direction for further research, it would be interested to investigate if more problems
have polynomial Turing compressions parameterized by modular-width such as k-path(mw).","Meanwhile, we give the ﬁrst FPT algorithms for some problems parameterized by modular-
width.","In addition, Fomin et al.",2022-01-12 20:12:41+00:00,Polynomial Turing Compressions for Some Graph Problems Parameterized by Modular-Width,cs.DS,['cs.DS'],[arxiv.Result.Author('Weidong Luo')],"In this paper we investigate the parameterized complexity for NP-hard graph
problems parameterized by a structural parameter modular-width. We develop a
recipe that is able to simplify the process of obtaining polynomial Turing
compressions for a class of graph problems parameterized by modular-width.
Moreover, we prove that several problems, which include \textsc{chromatic
number, independent set}, \textsc{Hamiltonian cycle}, etc. have polynomial
Turing compressions parameterized by modular-width. In addition, under the
assumption that P $\neq$ NP, we provide tight kernels for a few problems such
as \textsc{Steiner tree} parameterized by modular-width. Meanwhile, we
demonstrate that some problems, which includes \textsc{dominating set},
\textsc{odd cycle transversal}, \textsc{connected vertex cover}, etc. are
fixed-parameter tractable parameterized by modular-width.",-0.2064721,0.23666969,0.1941866,A
459,"As a direction for further research, it would be interested to investigate if more problems
have polynomial Turing compressions parameterized by modular-width such as k-path(mw).","Additionally,
we ﬁnd conditional tight kernels for a few graph problems parameterized by modular-width, and
new parameterized algorithms for these problems are obtained.","In addition, Fomin et al.",2022-01-12 20:12:41+00:00,Polynomial Turing Compressions for Some Graph Problems Parameterized by Modular-Width,cs.DS,['cs.DS'],[arxiv.Result.Author('Weidong Luo')],"In this paper we investigate the parameterized complexity for NP-hard graph
problems parameterized by a structural parameter modular-width. We develop a
recipe that is able to simplify the process of obtaining polynomial Turing
compressions for a class of graph problems parameterized by modular-width. By
using the recipe, we demonstrate that several problems, which include Chromatic
Number, Independent Det, Hamiltonian Cycle, etc. have polynomial Turing
compressions parameterized by modular-width. In addition, under the assumption
that P $\neq$ NP, we provide tight kernels for a few problems such as Steiner
Tree parameterized by modular-width. As a byproduct of the result of the tight
kernels, new parameterized algorithms for these problems are obtained.",-0.2565832,0.22511783,0.091218695,A
1082,"Combining the propagations, we further study a variety of matrix operations of Generation Matrices.","For the upward propagation, aﬀected z j by vi satisﬁes j = i, or j is the ancestor of i in T ; for the
downward propagation, aﬀected z j by vi satisﬁes j = i, or j is a descendant of i in T .","They have
strong interpretability and provide crucial theoretical support for the research of hierarchical trees.",2022-01-27 03:32:55+00:00,Generation Matrix: An Embeddable Matrix Representation for Hierarchical Trees,cs.DS,"['cs.DS', 'cs.CR']","[arxiv.Result.Author('Jianping Cai'), arxiv.Result.Author('Ximeng Liu'), arxiv.Result.Author('Jiayin Li'), arxiv.Result.Author('Shuangyue Zhang')]","Starting from the local structures to study hierarchical trees is a common
research method. However, the cumbersome analysis and description make the
naive method challenging to adapt to the increasingly complex hierarchical tree
problems. To improve the efficiency of hierarchical tree research, we propose
an embeddable matrix representation for hierarchical trees, called Generation
Matrix. It can transform the abstract hierarchical tree into a concrete matrix
representation and then take the hierarchical tree as a whole to study, which
dramatically reduces the complexity of research. Mathematical analysis shows
that Generation Matrix can simulate various recursive algorithms without
accessing local structures and provides a variety of interpretable matrix
operations to support the research of hierarchical trees. Applying Generation
Matrix to differential privacy hierarchical tree release, we propose a
Generation Matrix-based optimally consistent release algorithm (GMC). It
provides an exceptionally concise process description so that we can describe
its core steps as a simple matrix expression rather than multiple complicated
recursive processes like existing algorithms. Our experiments show that GMC
takes only a few seconds to complete a release for large-scale datasets with
more than 10 million nodes. The calculation efficiency is increased by up to
100 times compared with the state-of-the-art schemes.",0.07189456,0.52151316,-0.06366185,A
1083,"Combining the propagations, we further study a variety of matrix operations of Generation Matrices.","For the upward propagation, aﬀected z j by vi satisﬁes j = i, or j is the ancestor of i in T ; for the
downward propagation, aﬀected z j by vi satisﬁes j = i, or j is a descendant of i in T .","They have
strong interpretability and provide crucial theoretical support for the research of hierarchical trees.",2022-01-27 03:32:55+00:00,Generation Matrix: An Embeddable Matrix Representation for Hierarchical Trees,cs.DS,"['cs.DS', 'cs.CR']","[arxiv.Result.Author('Jianping Cai'), arxiv.Result.Author('Ximeng Liu'), arxiv.Result.Author('Jiayin Li'), arxiv.Result.Author('Shuangyue Zhang')]","Starting from the local structures to study hierarchical trees is a common
research method. However, the cumbersome analysis and description make the
naive method challenging to adapt to the increasingly complex hierarchical tree
problems. To improve the efficiency of hierarchical tree research, we propose
an embeddable matrix representation for hierarchical trees, called Generation
Matrix. It can transform the abstract hierarchical tree into a concrete matrix
representation and then take the hierarchical tree as a whole to study, which
dramatically reduces the complexity of research. Mathematical analysis shows
that Generation Matrix can simulate various recursive algorithms without
accessing local structures and provides a variety of interpretable matrix
operations to support the research of hierarchical trees. Applying Generation
Matrix to differential privacy hierarchical tree release, we propose a
Generation Matrix-based optimally consistent release algorithm (GMC). It
provides an exceptionally concise process description so that we can describe
its core steps as a simple matrix expression rather than multiple complicated
recursive processes like existing algorithms. Our experiments show that GMC
takes only a few seconds to complete a release for large-scale datasets with
more than 10 million nodes. The calculation efficiency is increased by up to
100 times compared with the state-of-the-art schemes.",0.07189456,0.52151316,-0.06366185,A
1754,"As further research questions, it is interesting to consider W[2]-hardness of approximating
k-SETCOVER beyond constant ratio.","Our result could also be applied to rule out polynomial algorithm approximating

non-parameterized k-SETCOVER within ratio o                                 log n    , with k as small as O(log2 n · log log n).,
                                                                          log log n

assuming (randomized) W[1] = FPT.",Question 1.,2022-02-09 10:24:40+00:00,Constant Approximating Parameterized $k$-SetCover is W[2]-hard,cs.DS,"['cs.DS', 'cs.CC']","[arxiv.Result.Author('Bingkai Lin'), arxiv.Result.Author('Xuandi Ren'), arxiv.Result.Author('Yican Sun'), arxiv.Result.Author('Xiuhan Wang')]","In this paper, we prove that it is W[2]-hard to approximate $k$-SetCover
within any constant ratio. Our proof is built upon the recently developed
threshold graph composition technique. We propose a strong notion of threshold
graph and use a new composition method to prove this result. Our technique
could also be applied to rule out polynomial time $o\left(\frac{\log n}{\log
\log n}\right)$ ratio approximation algorithms for the non-parameterized
$k$-SetCover problem, assuming W[1]$\ne$FPT.
  We highlight that our proof does not depend on the well-known PCP theorem,
and only involves simple combinatorial objects. Furthermore, our reduction
results in a $k$-SetCover instance with $k$ as small as $O\left(\log^2 n\cdot
\log \log n\right)$.",-0.35224825,-0.14912333,0.029952254,B
1755,"As further research questions, it is interesting to consider W[2]-hardness of approximating
k-SETCOVER beyond constant ratio.","Our result could also be applied to rule out polynomial algorithm approximating
non-parameterized k-SETCOVER within ratio o lolgolgong n , with k as small as O lolgolgong n 3, assum-
ing W[1] = FPT.",Question 1.,2022-02-09 10:24:40+00:00,Constant Approximating Parameterized $k$-SetCover is W[2]-hard,cs.DS,"['cs.DS', 'cs.CC', 'F.2.2']","[arxiv.Result.Author('Bingkai Lin'), arxiv.Result.Author('Xuandi Ren'), arxiv.Result.Author('Yican Sun'), arxiv.Result.Author('Xiuhan Wang')]","In this paper, we prove that it is W[2]-hard to approximate k-SetCover within
any constant ratio. Our proof is built upon the recently developed threshold
graph composition technique. We propose a strong notion of threshold graphs and
use a new composition method to prove this result. Our technique could also be
applied to rule out polynomial time $o\left(\frac{\log n}{\log \log n}\right)$
ratio approximation algorithms for the non-parameterized k-SetCover problem
with $k$ as small as $O\left(\frac{\log n}{\log \log n}\right)^3$, assuming
W[1]$\neq$FPT. We highlight that our proof does not depend on the well-known
PCP theorem, and only involves simple combinatorial objects.",-0.3515091,-0.117833525,0.025812894,B
2147,"29
7 Conclusion and open problems

Let us conclude the paper with pointing out some direction for further research.","Since

W  M C is NP-hard and, assuming the ETH, cannot be solved in subexponential time in

complete graphs [3], which can be realized as intersection graphs of any geometric objects, we obtain an

analogous lower bound for WH (H).",Algorithms for unit disk graphs.,2022-02-17 20:58:16+00:00,Computing list homomorphisms in geometric intersection graphs,cs.DS,"['cs.DS', 'cs.CC']","[arxiv.Result.Author('Sándor Kisfaludi-Bak'), arxiv.Result.Author('Karolina Okrasa'), arxiv.Result.Author('Paweł Rzążewski')]","A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping
from $V(G)$ to $V(H)$. Let $H$ be a fixed graph with possible loops. In the
list homomorphism problem, denoted by \textsc{LHom}($H$), the instance is a
graph $G$, whose every vertex is equipped with a subset of $V(H)$, called list.
We ask whether there exists a homomorphism from $G$ to $H$, such that every
vertex from $G$ is mapped to a vertex from its list.
  We study the complexity of the \textsc{LHom}($H$) problem in intersection
graphs of various geometric objects. In particular, we are interested in
answering the question for what graphs $H$ and for what types of geometric
objects, the \textsc{LHom}($H$) problem can be solved in time subexponential in
the number of vertices of the instance.
  We fully resolve this question for string graphs, i.e., intersection graphs
of continuous curves in the plane. Quite surprisingly, it turns out that the
dichotomy exactly coincides with the analogous dichotomy for graphs excluding a
fixed path as an induced subgraph [Okrasa, Rz\k{a}\.zewski, STACS 2021].
  Then we turn our attention to subclasses of string graphs, defined as
intersections of fat objects. We observe that the (non)existence of
subexponential-time algorithms in such classes is closely related to the size
$\mathrm{mrc}(H)$ of a maximum reflexive clique in $H$, i.e., maximum number of
pairwise adjacent vertices, each of which has a loop. We study the maximum
value of $\mathrm{mrc}(H)$ that guarantees the existence of a
subexponential-time algorithm for \textsc{LHom}($H$) in intersection graphs of
(i) convex fat objects, (ii) fat similarly-sized objects, and (iii) disks. In
the first two cases we obtain optimal results, by giving matching algorithms
and lower bounds.
  Finally, we discuss possible extensions of our results to weighted
generalizations of \textsc{LHom}($H$).",-0.3003375,0.038314078,-0.20560928,A
3155,"In [13], it is also noted that determining

exactly the complexity of maintaining a d out-orientation for d ∈ [α, 2α] is a ’theoretically

interesting direction for further research’.","In the dynamic case, the out-orientation with the lowest bound on

the out-degree with O(poly(log n, α)) update time seem to be the algorithm of Brodal &

Fagerberg [13] that achieves 2(αmax + 1) out-degree.","We make some progress in this direction by showing

how to maintain a (1 + ε)α + 2 out-orientation with poly(log n, α, ε−1) update time.",2022-03-11 16:10:37+00:00,Fully-dynamic $α+ 2$ Arboricity Decomposition and Implicit Colouring,cs.DS,['cs.DS'],"[arxiv.Result.Author('Aleksander B. G. Christiansen'), arxiv.Result.Author('Eva Rotenberg')]","In the implicit dynamic colouring problem, the task is to maintain a
representation of a proper colouring as a dynamic graph is subject to
insertions and deletions of edges, while facilitating interspersed queries to
the colours of vertices. The goal is to use few colours, while still
efficiently handling edge-updates and responding to colour-queries. For an
n-vertex dynamic graph of arboricity $\alpha$, we present an algorithm that
maintains an implicit vertex colouring with $4\cdot2^\alpha$ colours, in
amortised poly-$(\log n)$ update time, and with $O({\alpha} log n)$ worst-case
query time. The previous best implicit dynamic colouring algorithm uses
$2^{40\alpha}$) colours, and has a more efficient update time of $O(\log^3 n)$
and the same query time of $O({\alpha} log n)$ [Henzinger et al'20].
  For graphs undergoing arboricity $\alpha$ preserving updates, we give a
fully-dynamic $\alpha+2$ arboricity decomposition in poly$(\log n,\alpha)$
time, which matches the number of forests in the best near-linear static
algorithm by Blumenstock and Fischer [2020] who obtain $\alpha+2$ forests in
near-linear time. Our construction goes via dynamic bounded out-degree
orientations, where we present a fully-dynamic explicit, deterministic,
worst-case algorithm for $\lfloor (1+\varepsilon)\alpha \rfloor + 2$ bounded
out-degree orientation with update time $O(\varepsilon^{-6}\alpha^2 \log^3 n)$.
The state-of-the-art explicit, deterministic, worst-case algorithm for bounded
out-degree orientations maintains a $\beta\cdot \alpha + \log_{\beta} n$
out-orientation in $O(\beta^2\alpha^2+\beta\alpha\log_{\beta} n)$ time
[Kopelowitz et al'13].",0.041691065,0.12585187,0.109099776,C
3520,"The paper is organized as follows: this introduction terminates with Section
1.1, which gives some basic terminology and notation; in Section 2 we give our
formulations for CVC and prove their correctness; the branch and bound algo-
rithm is described in Section 3; numerical experiments are given in Section 4;
ﬁnally, we conclude with some further research directions in Section 5.","This is interesting since, for the general Vertex
Cover problem, combinatorial algorithms usually outperform linear formulations.","1.1 Preliminaries

Throughout the paper we let G = (V, E) be a connected graph.",2022-03-18 11:18:57+00:00,Exact approaches for the Connected Vertex Cover problem,cs.DS,"['cs.DS', 'cs.DM', 'math.CO']",[arxiv.Result.Author('Manuel Aprile')],"Given a graph $G$, the Connected Vertex Cover problem (CVC) asks to find a
minimum cardinality vertex cover of $G$ that induces a connected subgraph. In
this paper we describe some approaches to solve the CVC problem exactly. First,
we give compact mixed-integer extended formulations for CVC: these are the
first formulations proposed for this problem, and can be easily adapted to
variations of the problem such as Tree Cover. Second, we describe a simple
branch and bound algorithm for the CVC problem. Finally, we implement our
algorithm and compare its performance against our best formulation: contrary to
what usually happens for the classical Vertex Cover problem, our formulation
outperforms the branch and bound algorithm.",-0.3076628,-0.08072591,-0.26544896,B_centroid
4469,"Besides experimental evaluations of the algorithms proposed in this work, it is also interesting to
further study theoretical running time improvements.","Thus, one
important topic for future work is to investigate how well the theoretical algorithms proposed in this
work perform in practice when combined with algorithm engineering tricks like data reduction rules,
upper and lower bounds for the solution size, and restarts.","Recall that our subexponential-time algorithms
for the inversions distance and the inversion-window distance are closely related to an algorithm for
FAST [1].",2022-04-06 15:38:09+00:00,Efficient Bayesian Network Structure Learning via Parameterized Local Search on Topological Orderings,cs.DS,"['cs.DS', 'cs.DM', 'cs.LG']","[arxiv.Result.Author('Niels Grüttemeier'), arxiv.Result.Author('Christian Komusiewicz'), arxiv.Result.Author('Nils Morawietz')]","In Bayesian Network Structure Learning (BNSL), one is given a variable set
and parent scores for each variable and aims to compute a DAG, called Bayesian
network, that maximizes the sum of parent scores, possibly under some
structural constraints. Even very restricted special cases of BNSL are
computationally hard, and, thus, in practice heuristics such as local search
are used. A natural approach for a local search algorithm is a hill climbing
strategy, where one replaces a given BNSL solution by a better solution within
some pre-defined neighborhood as long as this is possible. We study
ordering-based local search, where a solution is described via a topological
ordering of the variables. We show that given such a topological ordering, one
can compute an optimal DAG whose ordering is within inversion distance $r$ in
subexponential FPT time; the parameter $r$ allows to balance between solution
quality and running time of the local search algorithm. This running time bound
can be achieved for BNSL without structural constraints and for all structural
constraints that can be expressed via a sum of weights that are associated with
each parent set. We also introduce a related distance called `window inversions
distance' and show that the corresponding local search problem can also be
solved in subexponential FPT time for the parameter $r$. For two further
natural modification operations on the variable orderings, we show that
algorithms with an FPT time for $r$ are unlikely. We also outline the limits of
ordering-based local search by showing that it cannot be used for common
structural constraints on the moralized graph of the network.",0.08681449,0.11483919,0.21654871,C_centroid
4488,"It also opens up the door to further study of eﬃcient and deterministic
spectral sparsiﬁer.","From this perspective, our data structure formulation gives the right direction to
achieve the truly optimal running time for this problem, and various sparsiﬁcation problem using the
potential function of [BSS12].",Extensions to Sparsify PSD Matrices.,2022-04-07 04:49:06+00:00,Speeding Up Sparsification using Inner Product Search Data Structures,cs.DS,['cs.DS'],"[arxiv.Result.Author('Zhao Song'), arxiv.Result.Author('Zhaozhuo Xu'), arxiv.Result.Author('Lichen Zhang')]","We present a general framework that utilizes different efficient data
structures to improve various sparsification problems involving an iterative
process. We also provide insights and characterization for different iterative
process, and answer that when should we use which data structures in what type
of problem. We obtain improved running time for the following problems.
  * For constructing linear-sized spectral sparsifier (Batson, Spielman and
Srivastava, 2012), all the existing deterministic algorithms require
$\Omega(d^4)$ time. In this work, we provide the first deterministic algorithm
that breaks that barrier which runs in $O(d^{\omega+1})$ time, where $\omega$
is the exponent of matrix multiplication.
  * For one-sided Kadison-Singer-typed discrepancy problem, we give fast
algorithms for both small and large number of iterations.
  * For experimental design problem, we speed up a key swapping process.
  In the heart of our work is the design of a variety of different inner
product search data structures that have efficient initialization, query and
update time, compatible to dimensionality reduction and robust against adaptive
adversary.",-0.0032735327,0.02912739,0.09225437,C
5350,"We point further research directions to improve the current
                                                state-of-the-art.","We found a great variety of studies
                                                using data compression techniques and self-indexed compressed data
                                                structures.","1 Introduction

                                        Widespread adoption of complex network concepts in information technolo-
                                        gies has driven the creation of large volumes of data to be modelled as graphs.",2022-04-26 17:38:49+00:00,A Review of In-Memory Space-Efficient Data Structures for Temporal Graphs,cs.DS,['cs.DS'],"[arxiv.Result.Author('Luiz F. A. Brito'), arxiv.Result.Author('Bruno A. N. Travençolo'), arxiv.Result.Author('Marcelo K. Albertini')]","Temporal graphs model relationships among entities over time. Recent studies
applied temporal graphs to abstract complex systems such as continuous
communication among participants of social networks. Often, the amount of data
is larger than main memory, therefore, we need specialized structures that
balance space usage and query efficiency. In this paper, we review
space-efficient data structures that bring large temporal graphs from external
memory to primary memory and speed up specialized queries. We found a great
variety of studies using data compression techniques and self-indexed
compressed data structures. We point further research directions to improve the
current state-of-the-art.",0.15299901,0.17661697,-0.008682558,A
5674,"Closing this gap also for these objectives is a challenging
problem for further research.","The best known upper bound is 16 for k-median [9] and 32 for k-means [16] but no non-
trivial lower bounds are known.","Another natural question is which approximation factors can be achieved by algo-
rithms running in polynomial time.",2022-05-03 11:11:55+00:00,The Price of Hierarchical Clustering,cs.DS,['cs.DS'],"[arxiv.Result.Author('Anna Arutyunova'), arxiv.Result.Author('Heiko Röglin')]","Hierarchical Clustering is a popular tool for understanding the hereditary
properties of a data set. Such a clustering is actually a sequence of
clusterings that starts with the trivial clustering in which every data point
forms its own cluster and then successively merges two existing clusters until
all points are in the same cluster. A hierarchical clustering achieves an
approximation factor of $\alpha$ if the costs of each $k$-clustering in the
hierarchy are at most $\alpha$ times the costs of an optimal $k$-clustering. We
study as cost functions the maximum (discrete) radius of any cluster
($k$-center problem) and the maximum diameter of any cluster ($k$-diameter
problem). In general, the optimal clusterings do not form a hierarchy and hence
an approximation factor of $1$ cannot be achieved. We call the smallest
approximation factor that can be achieved for any instance the price of
hierarchy. For the $k$-diameter problem we improve the upper bound on the price
of hierarchy to $3+2\sqrt{2}\approx 5.83$. Moreover we significantly improve
the lower bounds for $k$-center and $k$-diameter, proving a price of hierarchy
of exactly $4$ and $3+2\sqrt{2}$, respectively.",-0.15559576,-0.23786348,-0.029125271,B
5719,"The toolbox of successful TA3 techniques can then become the starting point of further research;
moreover, it can be added to the bioinformatics curriculum in computer science.","It will be useful to also identify successful TA3 techniques from
areas of bioinformatics that are not based solely on sequencing data, such as whole-genome analysis and phylogeny
reconstruction.","The theoretical analysis of sequencing bioinformatics algorithms and beyond  9

   Viewing TA3 as its own research field would allow researchers to focus on retrospective prediction of algorithm
performance; i.e.",2022-05-03 21:17:53+00:00,The theoretical analysis of sequencing bioinformatics algorithms and beyond,cs.DS,['cs.DS'],[arxiv.Result.Author('Paul Medvedev')],"The theoretical analysis of performance has been an important tool in the
engineering of algorithms in many application domains. Its goals are to predict
the empirical performance of an algorithm and to be a yardstick that drives the
design of novel algorithms that perform well in practice. While these goals
have been achieved in many instances, they have not been achieved ubiquitously
across crucial application domains. I provide a case study in the area of
sequencing bioinformatics, an inter-disciplinary field that uses algorithms to
extract biological meaning from genome sequencing data. In particular, I give
three concrete examples: two showing how theoretical analysis has failed to
achieve its goals and one showing how it has been successful. I will then
catalog some of the challenges of applying theoretical analysis to sequencing
bioinformatics, argue why empirical analysis is not enough, and give a vision
for improving the relevance of theoretical analysis to sequencing
bioinformatics. By recognizing the problem, understanding its roots, and
providing potential solutions, this work can hopefully be a crucial first step
towards making theoretical analysis more relevant in sequencing bioinformatics
and potentially other fast-paced application domains.",0.3055269,0.23910794,0.21459489,C
5990,Section 8 summarizes the results and discusses possible directions for further research.,Section 7 describes experiments for an external implementation.,Our Contribution.,2022-05-10 08:42:03+00:00,PaCHash: Packed and Compressed Hash Tables,cs.DS,['cs.DS'],"[arxiv.Result.Author('Florian Kurpicz'), arxiv.Result.Author('Hans-Peter Lehmann'), arxiv.Result.Author('Peter Sanders')]","We introduce PaCHash, a hash table that stores its objects contiguously in an
array without intervening space, even if the objects have variable size. In
particular, each object can be compressed using standard compression
techniques. A small search data structure allows locating the objects in
constant expected time. PaCHash is most naturally described as a static
external hash table where it needs a constant number of bits of internal memory
per block of external memory. However, PaCHash can be dynamized and is also
useful for internal memory, having lower space consumption than all previous
approaches even when considering only objects of identical size. For example,
in some sense it beats a lower bound on the space consumption of k-perfect
hashing. An implementation for fast SSDs needs about 5 bits of internal memory
per block of external memory, requires only one disk access (of variable
length) per search operation and has internal search overhead small compared to
the disk access cost.",0.851084,-0.17019984,-0.10624193,C
5991,Section 8 summarizes the results and discusses possible directions for further research.,Section 7 describes experiments for an external implementation.,Our Contribution.,2022-05-10 08:42:03+00:00,PaCHash: Packed and Compressed Hash Tables,cs.DS,['cs.DS'],"[arxiv.Result.Author('Florian Kurpicz'), arxiv.Result.Author('Hans-Peter Lehmann'), arxiv.Result.Author('Peter Sanders')]","We introduce PaCHash, a hash table that stores its objects contiguously in an
array without intervening space, even if the objects have variable size. In
particular, each object can be compressed using standard compression
techniques. A small search data structure allows locating the objects in
constant expected time. PaCHash is most naturally described as a static
external hash table where it needs a constant number of bits of internal memory
per block of external memory. However, PaCHash can be dynamized and is also
useful for internal memory, having lower space consumption than all previous
approaches even when considering only objects of identical size. For example,
in some sense it beats a lower bound on the space consumption of k-perfect
hashing. An implementation for fast SSDs needs about 5 bits of internal memory
per block of external memory, requires only one disk access (of variable
length) per search operation and has internal search overhead small compared to
the disk access cost.",0.851084,-0.17019984,-0.10624193,C
5992,"Section 8 summarizes the results and discusses
   possible directions for further research.","Section 7 describes
   experiments for an external implementation.",Our Contribution.,2022-05-10 08:42:03+00:00,PaCHash: Packed and Compressed Hash Tables,cs.DS,['cs.DS'],"[arxiv.Result.Author('Florian Kurpicz'), arxiv.Result.Author('Hans-Peter Lehmann'), arxiv.Result.Author('Peter Sanders')]","We introduce PaCHash, a hash table that stores its objects contiguously in an
array without intervening space, even if the objects have variable size. In
particular, each object can be compressed using standard compression
techniques. A small search data structure allows locating the objects in
constant expected time. PaCHash is most naturally described as a static
external hash table where it needs a constant number of bits of internal memory
per block of external memory. Here, in some sense, PaCHash beats a lower bound
on the space consumption of k-perfect hashing. An implementation for fast SSDs
needs about 5 bits of internal memory per block of external memory, requires
only one disk access (of variable length) per search operation, and has small
internal search overhead compared to the disk access cost. Our experiments show
that it has lower space consumption than all previous approaches even when
considering objects of identical size.",0.851084,-0.17019984,-0.10624193,C
6058,"Another possible avenue of further research would be the generalizations of our
variants to the recently introduced extension of the BWT in the areas of graphs, languages
and automata [1, 17, 30].","We believe this larger class of transformation should
be further investigated: we have shown that some of them do have more eﬃcient inversion
and search algorithms and this suggests that there could be other subclasses of practical
interest.","References

  1 Jarno Alanko, Giovanna D’Agostino, Alberto Policriti, and Nicola Prezza.",2022-05-11 17:17:08+00:00,A New Class of String Transformations for Compressed Text Indexing,cs.DS,['cs.DS'],"[arxiv.Result.Author('Raffaele Giancarlo'), arxiv.Result.Author('Giovanni Manzini'), arxiv.Result.Author('Antonio Restivo'), arxiv.Result.Author('Giovanna Rosone'), arxiv.Result.Author('Marinella Sciortino')]","Introduced about thirty years ago in the field of Data Compression, the
Burrows-Wheeler Transform (BWT) is a string transformation that, besides being
a booster of the performance of memoryless compressors, plays a fundamental
role in the design of efficient self-indexing compressed data structures.
Finding other string transformations with the same remarkable properties of BWT
has been a challenge for many researchers for a long time. Among the known BWT
variants, the only one that has been recently shown to be a valid alternative
to BWT is the Alternating BWT (ABWT), another invertible string transformation
introduced about ten years ago in connection with a generalization of Lyndon
words. In this paper, we introduce a whole class of new string transformations,
called local orderings-based transformations, which have all the myriad virtues
of BWT. We show that this new family is a special case of a much larger class
of transformations, based on context adaptive alphabet orderings, that includes
BWT and ABWT. Although all transformations support pattern search, we show
that, in the general case, the transformations within our larger class may take
quadratic time for inversion and pattern search. As a further result, we show
that the local orderings-based transformations can be used for the construction
of the recently introduced r-index, which makes them suitable also for highly
repetitive collections. In this context, we consider the problem of finding,
for a given string, the BWT variant that minimizes the number of runs in the
transformed string, and we provide an algorithm solving this problem in linear
time.",0.09560998,0.27102023,0.00340628,C
6895,"Many of our bounds are close to optimal, but we have some avenues for
further research:

    • Reduce the gap between lower and upper bounds for shortest cycle in an unweighted undirected graph.","6 Conclusion and Further Research

We have presented several upper and lower bounds on the round complexity of RPaths, 2-SiSP, MWC and
ANSC in the CONGEST model.",• Reduce the gap between lower and upper bounds for RPaths in an unweighted directed graph.,2022-05-30 00:50:28+00:00,Near Optimal Bounds for Replacement Paths and Related Problems in the CONGEST Model,cs.DS,"['cs.DS', 'cs.DC']","[arxiv.Result.Author('Vignesh Manoharan'), arxiv.Result.Author('Vijaya Ramachandran')]","We present several results in the CONGEST model on round complexity for
Replacement Paths (RPaths), Minimum Weight Cycle (MWC), and All Nodes Shortest
Cycles (ANSC). We study these fundamental problems in both directed and
undirected graphs, both weighted and unweighted. Many of our results are
optimal to within a polylog factor: For an $n$-node graph $G$ we establish near
linear lower and upper bounds for computing RPaths if $G$ is directed and
weighted, and for computing MWC and ANSC if $G$ is weighted, directed or
undirected; near $\sqrt{n}$ lower and upper bounds for undirected weighted
RPaths; and $\Theta(D)$ bound for undirected unweighted RPaths. We also present
lower and upper bounds for approximation versions of these problems, notably a
$(2-(1/g))$-approximation algorithm for undirected unweighted MWC that runs in
$\tilde{O}(\sqrt{n}+D)$ rounds, improving on the previous best bound of
$\tilde{O}(\sqrt{ng}+D)$ rounds, where $g$ is the MWC length, and a
$(1+\epsilon)$-approximation algorithm for directed weighted RPaths and $(2+
\epsilon)$-approximation for weighted undirected MWC, for any constant
$\epsilon > 0$, that beat the round complexity lower bound for an exact
solution.",-0.20705819,0.10930237,-0.15986867,A_centroid
7335,As discussed in [11] this phenomenon merits further study.,"Also, the fact that Reduction
8 actually undoes an application of the chain reduction is interesting: it takes a step ‘back’,
in order to move forward.","Next, an empirical study in the spirit of [28] could investigate how much extra reductive
power the new 9k − 8 rules have in practice; the rules for the 11k − 9 kernel do have more
practical eﬀect than the 15k − 9 rules, does this trend continue?",2022-06-09 12:22:30+00:00,Deep kernelization for the Tree Bisection and Reconnnect (TBR) distance in phylogenetics,cs.DS,"['cs.DS', 'math.CO', 'q-bio.PE']","[arxiv.Result.Author('Steven Kelk'), arxiv.Result.Author('Simone Linz'), arxiv.Result.Author('Ruben Meuwese')]","We describe a kernel of size 9k-8 for the NP-hard problem of computing the
Tree Bisection and Reconnect (TBR) distance k between two unrooted binary
phylogenetic trees. We achieve this by extending the existing portfolio of
reduction rules with three novel new reduction rules. Two of the rules are
based on the idea of topologically transforming the trees in a
distance-preserving way in order to guarantee execution of earlier reduction
rules. The third rule extends the local neighbourhood approach introduced in
(Kelk and Linz, Annals of Combinatorics 24(3), 2020) to more global structures,
allowing new situations to be identified when deletion of a leaf definitely
reduces the TBR distance by one. The bound on the kernel size is tight up to an
additive term. Our results also apply to the equivalent problem of computing a
Maximum Agreement Forest (MAF) between two unrooted binary phylogenetic trees.
We anticipate that our results will be more widely applicable for computing
agreement-forest based dissimilarity measures.",0.27072388,0.2327029,-0.11176902,C
7494,"8 Open Problems

The results here suggest many open problems and avenues for further research.","So the total cost of requests in Items 5 and 6 above is at most twice the total cost of
all other requests.","Closing or tightening gaps left by our upper
and lower bounds would be of interest.",2022-06-11 17:52:10+00:00,Online Paging with Heterogeneous Cache Slots,cs.DS,['cs.DS'],"[arxiv.Result.Author('Marek Chrobak'), arxiv.Result.Author('Samuel Haney'), arxiv.Result.Author('Mehraneh Liaee'), arxiv.Result.Author('Debmalya Panigrahi'), arxiv.Result.Author('Rajmohan Rajaraman'), arxiv.Result.Author('Ravi Sundaram'), arxiv.Result.Author('Neal E. Young')]","It is natural to generalize the $k$-Server problem by allowing each request
to specify not only a point $p$, but also a subset $S$ of servers that may
serve it. To attack this generalization, we focus on uniform and star metrics.
For uniform metrics, the problem is equivalent to a generalization of Paging in
which each request specifies not only a page $p$, but also a subset $S$ of
cache slots, and is satisfied by having a copy of $p$ in some slot in $S$. We
call this problem Slot-Heterogeneous Paging.
  We parameterize the problem by specifying an arbitrary family ${\cal S}
\subseteq 2^{[k]}$, and restricting the sets $S$ to ${\cal S}$. If all request
sets are allowed (${\cal S}=2^{[k]}$), the optimal deterministic and randomized
competitive ratios are exponentially worse than for standard Paging (${\cal
S}=\{[k]\}$). As a function of $|{\cal S}|$ and the cache size $k$, the optimal
deterministic ratio is polynomial: at most $O(k^2|{\cal S}|)$ and at least
$\Omega(\sqrt{|{\cal S}|})$. For any laminar family ${\cal S}$ of height $h$,
the optimal ratios are $O(hk)$ (deterministic) and $O(h^2\log k)$ (randomized).
The special case that we call All-or-One Paging extends standard Paging by
allowing each request to specify a specific slot to put the requested page in.
For All-or-One Paging the optimal competitive ratios are $\Theta(k)$
(deterministic) and $\Theta(\log k)$ (randomized), while the offline problem is
NP-hard. We extend the deterministic upper bound to the weighted variant of
All-Or-One Paging (a generalization of standard Weighted Paging), showing that
it is also $\Theta(k)$.",0.18649438,-0.34515893,-0.03332757,B
7888,"Identifying a relationship of the two algorithms that establishes an identical loss is an intriguing
problem for further research.","Unfortunately, these arguments are heavily based on
steady-state analysis and are therefore hard to be made precise for non-Markovian processes.","Greedy algorithm We start by reasoning about the pool size similar to the proof sketch in
Section 4.1.",2022-06-21 12:13:14+00:00,High Satisfaction in Thin Dynamic Matching Markets,cs.DS,"['cs.DS', 'econ.TH']","[arxiv.Result.Author('Johannes Bäumler'), arxiv.Result.Author('Martin Bullinger'), arxiv.Result.Author('Stefan Kober'), arxiv.Result.Author('Donghao Zhu')]","Dynamic matching markets are an ubiquitous object of study with applications
in health, labor, or dating. There exists a rich literature on the formal
modeling of such markets. Typically, these models consist of an arrival
procedure, governing when and which agents enter the market, and a sojourn
period of agents during which they may leave the market matched with another
present agent, or after which they leave the market unmatched. One important
focus lies on the design of mechanisms for the matching process aiming at
maximizing the quality of the produced matchings or at minimizing waiting
costs.
  We study a dynamic matching procedure where homogeneous agents arrive at
random according to a Poisson process and form edges at random yielding a
sparse market. Agents leave according to a certain departure distribution and
may leave early by forming a pair with a compatible agent. The objective is to
maximize the number of matched agents. Our main result is to show that a mild
guarantee on the maximum sojourn time of agents suffices to get almost optimal
performance of instantaneous matching, despite operating in a thin market. This
has the additional advantages of avoiding the risk of market congestion and
guaranteeing short waiting times. We develop new techniques for proving our
results going beyond commonly adopted methods for Markov processes.",-0.049419064,-0.22476526,0.013774889,B
7889,"Still, a rigorous treatment of this model is beyond the
scope of this paper, and we leave it as an intriguing direction for further research.","It is possible to extend our results under certain assumptions on the relationship
between the diﬀerent density parameters.","Acknowledgements

This work was supported by the Deutsche Forschungsgemeinschaft (German Research Founda-
tion) under grants BR 2312/11-2, BR 2312/12-1, and 277991500/GRK2201.",2022-06-21 12:13:14+00:00,High Satisfaction in Thin Dynamic Matching Markets,cs.DS,"['cs.DS', 'econ.TH']","[arxiv.Result.Author('Johannes Bäumler'), arxiv.Result.Author('Martin Bullinger'), arxiv.Result.Author('Stefan Kober'), arxiv.Result.Author('Donghao Zhu')]","Dynamic matching markets are an ubiquitous object of study with applications
in health, labor, or dating. There exists a rich literature on the formal
modeling of such markets. Typically, these models consist of an arrival
procedure, governing when and which agents enter the market, and a sojourn
period of agents during which they may leave the market matched with another
present agent, or after which they leave the market unmatched. One important
focus lies on the design of mechanisms for the matching process aiming at
maximizing the quality of the produced matchings or at minimizing waiting
costs.
  We study a dynamic matching procedure where homogeneous agents arrive at
random according to a Poisson process and form edges at random yielding a
sparse market. Agents leave according to a certain departure distribution and
may leave early by forming a pair with a compatible agent. The objective is to
maximize the number of matched agents. Our main result is to show that a mild
guarantee on the maximum sojourn time of agents suffices to get almost optimal
performance of instantaneous matching, despite operating in a thin market. This
has the additional advantages of avoiding the risk of market congestion and
guaranteeing short waiting times. We develop new techniques for proving our
results going beyond commonly adopted methods for Markov processes.",0.18404987,-0.2401701,-0.27395543,B
8055,"This is material for further research and computational
testing in the future.","The ﬁrst step is to solve the Linear Program as in (5) to obtain the ﬁrst extreme point, then fol-
low the procedure outlined in Remark 1.","7 Lifting subset constraints to solve problem 128-vertex 1ZC

The problem instance is available at: https://oeis.org/A265032/a265032 1zc.128.txt.gz

7.1 Change (and abuse) of terminology

Traditionally, lifting means, in addition to the F [i] of the vertices of the original subset S, the
F [i] of some other vertices are added to the left side of the constraint.",2022-06-25 02:13:09+00:00,Maximum independent set (stable set) problem: A mathematical programming model with valid inequalities; Computational testing with binary search and alternate optimal basic solutions (extreme points),cs.DS,"['cs.DS', 'math.OC', '90C99, 68Q19, 68Q15, 68Q17, 03C13', 'F.2']",[arxiv.Result.Author('Prabhu Manyem')],"This paper deals with the maximum independent set (M.I.S.) problem, also
known as the stable set problem. The basic mathematical programming model that
captures this problem is an Integer Program (I.P.) with zero-one variables and
only the edge inequalities. We present an enhanced model by adding a polynomial
number of linear constraints, known as valid inequalities; this new model is
still polynomial in the number of vertices in the graph. We carried out
computational testing of the Linear Relaxation of the new Integer Program. We
tested about 7000 instances of randomly generated (and connected) graphs with
up to 64 vertices (as well as all 64, 128, and 256-vertex instances at the
""challenge"" website OEIS.org). In each of these instances, the Linear
Relaxation returned an optimal solution with (i) every variable having an
integer value, and (ii) the optimal solution value of the Linear Relaxation was
the same as that of the original (basic) Integer Program. Our computational
experience has been that a binary search on the objective function value is a
powerful tool which yields a (weakly) polynomial algorithm.",-0.15583399,-0.11491615,0.02370229,A
8056,The questions in Remarks (2) and (3) are topics for further research.,"A program is needed to remove
such duplicate constraints before solving the Linear programs.","8.1 Software Webpage URL

The software programs are available at the following URL:
https://sites.google.com/view/all-optimisation-slides/
We welcome readers to send us their comments and suggestions.",2022-06-25 02:13:09+00:00,Maximum independent set (stable set) problem: A mathematical programming model with valid inequalities; Computational testing with binary search and alternate optimal basic solutions (extreme points),cs.DS,"['cs.DS', 'math.OC', '90C99, 68Q19, 68Q15, 68Q17, 03C13', 'F.2']",[arxiv.Result.Author('Prabhu Manyem')],"This paper deals with the maximum independent set (M.I.S.) problem, also
known as the stable set problem. The basic mathematical programming model that
captures this problem is an Integer Program (I.P.) with zero-one variables and
only the edge inequalities. We present an enhanced model by adding a polynomial
number of linear constraints, known as valid inequalities; this new model is
still polynomial in the number of vertices in the graph. We carried out
computational testing of the Linear Relaxation of the new Integer Program. We
tested about 7000 instances of randomly generated (and connected) graphs with
up to 64 vertices (as well as all 64, 128, and 256-vertex instances at the
""challenge"" website OEIS.org). In each of these instances, the Linear
Relaxation returned an optimal solution with (i) every variable having an
integer value, and (ii) the optimal solution value of the Linear Relaxation was
the same as that of the original (basic) Integer Program. Our computational
experience has been that a binary search on the objective function value is a
powerful tool which yields a (weakly) polynomial algorithm.",0.083180405,-0.17430516,0.21297184,C
8368,"In this paper, we further study two natural generalizations of TSP—Subset TSP and
   Waypoint Routing Problem.",Our formulation is also known as Graphical TSP [19].,"In Subset TSP (subTSP) the objective is to find a closed
   walk required to traverse only a given subset W of vertices (referred to as waypoints) instead
   of the whole vertex set as is in TSP.",2022-07-03 19:49:43+00:00,On Polynomial Kernels for Traveling Salesperson Problem and its Generalizations,cs.DS,"['cs.DS', 'cs.DM', 'math.CO']","[arxiv.Result.Author('Václav Blažej'), arxiv.Result.Author('Pratibha Choudhary'), arxiv.Result.Author('Dušan Knop'), arxiv.Result.Author('Šimon Schierreich'), arxiv.Result.Author('Ondřej Suchý'), arxiv.Result.Author('Tomáš Valla')]","For many problems, the important instances from practice possess certain
structure that one should reflect in the design of specific algorithms. As data
reduction is an important and inextricable part of today's computation, we
employ one of the most successful models of such precomputation -- the
kernelization. Within this framework, we focus on Traveling Salesperson Problem
(TSP) and some of its generalizations.
  We provide a kernel for TSP with size polynomial in either the feedback edge
set number or the size of a modulator to constant-sized components. For its
generalizations, we also consider other structural parameters such as the
vertex cover number and the size of a modulator to constant-sized paths. We
complement our results from the negative side by showing that the existence of
a polynomial-sized kernel with respect to the fractioning number, the combined
parameter maximum degree and treewidth, and, in the case of Subset-TSP,
modulator to disjoint cycles (i.e., the treewidth two graphs) is unlikely.",-0.23578364,0.09528,-0.06079217,A
8369,"To
stimulate further research in this area we would like to promote some follow up research
directions.","◀

 9 Conclusions

The core focus of this work is kernelization of the Traveling Salesperson Problem.","Design of “local” rules might be impossible (as was mentioned in the case of
feedback edge set number) and therefore we occasionally have to consider generalizations of
this problem that give us more power when designing the reductions.",2022-07-03 19:49:43+00:00,On Polynomial Kernels for Traveling Salesperson Problem and its Generalizations,cs.DS,"['cs.DS', 'cs.DM', 'math.CO']","[arxiv.Result.Author('Václav Blažej'), arxiv.Result.Author('Pratibha Choudhary'), arxiv.Result.Author('Dušan Knop'), arxiv.Result.Author('Šimon Schierreich'), arxiv.Result.Author('Ondřej Suchý'), arxiv.Result.Author('Tomáš Valla')]","For many problems, the important instances from practice possess certain
structure that one should reflect in the design of specific algorithms. As data
reduction is an important and inextricable part of today's computation, we
employ one of the most successful models of such precomputation -- the
kernelization. Within this framework, we focus on Traveling Salesperson Problem
(TSP) and some of its generalizations.
  We provide a kernel for TSP with size polynomial in either the feedback edge
set number or the size of a modulator to constant-sized components. For its
generalizations, we also consider other structural parameters such as the
vertex cover number and the size of a modulator to constant-sized paths. We
complement our results from the negative side by showing that the existence of
a polynomial-sized kernel with respect to the fractioning number, the combined
parameter maximum degree and treewidth, and, in the case of Subset-TSP,
modulator to disjoint cycles (i.e., the treewidth two graphs) is unlikely.",-0.030436404,-0.108014,-0.16234529,B
8463,Our results open up new avenues for further research on MFD.,"Finally, we have corroborated the complexity gap between the
positive integer and the full integer case by disproving a conjecture from [13] (also motivating
the heuristic in [19]), which would have had sped up their FPT algorithm for MFDN.","For example, can the
width help ﬁnd larger classes of graphs for which some greedy path removal (or even some
sort of greedy path cover removal) algorithms have a guaranteed approximation factor?",2022-07-05 15:57:01+00:00,Width Helps and Hinders Splitting Flows,cs.DS,['cs.DS'],"[arxiv.Result.Author('Manuel Cáceres'), arxiv.Result.Author('Massimo Cairo'), arxiv.Result.Author('Andreas Grigorjew'), arxiv.Result.Author('Shahbaz Khan'), arxiv.Result.Author('Brendan Mumey'), arxiv.Result.Author('Romeo Rizzi'), arxiv.Result.Author('Alexandru I. Tomescu'), arxiv.Result.Author('Lucia Williams')]","Minimum flow decomposition (MFD) is the NP-hard problem of finding a smallest
decomposition of a network flow $X$ on directed graph $G$ into weighted
source-to-sink paths whose superposition equals $X$. We focus on a common
formulation of the problem where the path weights must be non-negative integers
and also on a new variant where these weights can be negative. We show that,
for acyclic graphs, considering the width of the graph (the minimum number of
$s$-$t$ paths needed to cover all of its edges) yields advances in our
understanding of its approximability. For the non-negative version, we show
that a popular heuristic is a $O( \log |X|)$ ($|X|$ being the total flow of
$X$) on graphs satisfying two properties related to the width (satisfied by
e.g., series-parallel graphs), and strengthen its worst-case approximation
ratio from $\Omega(\sqrt{m})$ to $\Omega(m / \log m)$ for sparse graphs, where
$m$ is the number of edges in the graph. For the negative version, we give a
$(\lceil \log \Vert X \Vert \rceil +1)$-approximation ($\Vert X \Vert$ being
the maximum absolute value of $X$ on any edge) using a power-of-two approach,
combined with parity fixing arguments and a decomposition of unitary flows
($\Vert X \Vert \leq 1$) into at most width paths. We also disprove a
conjecture about the linear independence of minimum (non-negative) flow
decompositions posed by Kloster et al. [ALENEX 2018], but show that its useful
implication (polynomial-time assignments of weights to a given set of paths to
decompose a flow) holds for the negative version.",-0.21885249,0.06469496,-0.05872142,A
8550,"Finally, in Section 6,
we also give further research directions opened by our work.","Sections 3, 4, and 5 present our results
for full doubling, RC doubling, and doubling, respectively.","1.2 Related work

Recent work has focused on studying the algorithmic principles of reconﬁgu-
ration, with the potential of developing artiﬁcial systems that will be able to

1 Note that there are two distinct notions of time used in this paper.",2022-07-07 13:02:58+00:00,On Geometric Shape Construction via Growth Operations,cs.DS,"['cs.DS', 'cs.CG', 'cs.RO']","[arxiv.Result.Author('Nada Almalki'), arxiv.Result.Author('Othon Michail')]","In this work, we investigate novel algorithmic growth processes. In
particular, we propose three growth operations, full doubling, RC doubling and
doubling, and explore the algorithmic and structural properties of their
resulting processes under a geometric setting. In terms of modeling, our system
runs on a 2-dimensional grid and operates in discrete time-steps. The process
begins with an initial shape $S_I=S_0$ and, in every time-step $t \geq 1$, by
applying (in parallel) one or more growth operations of a specific type to the
current shape-instance $S_{t-1}$, generates the next instance $S_t$, always
satisfying $|S_t| > |S_{t-1}|$. Our goal is to characterize the classes of
shapes that can be constructed in $O(\log n)$ or polylog $n$ time-steps and
determine whether a final shape $S_F$ can be constructed from an initial shape
$S_I$ using a finite sequence of growth operations of a given type, called a
constructor of $S_F$.
  For full doubling, in which, in every time-step, every node generates a new
node in a given direction, we completely characterize the structure of the
class of shapes that can be constructed from a given initial shape. For RC
doubling, in which complete columns or rows double, our main contribution is a
linear-time centralized algorithm that for any pair of shapes $S_I$, $S_F$
decides if $S_F$ can be constructed from $S_I$ and, if the answer is yes,
returns an $O(\log n)$-time-step constructor of $S_F$ from $S_I$. For the most
general doubling operation, where up to individual nodes can double, we show
that some shapes cannot be constructed in sub-linear time-steps and give two
universal constructors of any $S_F$ from a singleton $S_I$, which are efficient
(i.e., up to polylogarithmic time-steps) for large classes of shapes. Both
constructors can be computed by polynomial-time centralized algorithms for any
shape $S_F$.",0.049255908,0.019502606,0.15097219,C
8794,"We hope that this result motivates further research into tailored algorithms using the
property of realizability for larger, more relevant classes of USOs.","The Matoušek-type USOs form the ﬁrst known USO class admitting such a com-
plexity gap.","Note that an artiﬁcial class of USOs exhibiting such a complexity gap could easily be constructed
by combining a set R of easy-to-solve realizable USOs with a set N of diﬃcult-to-solve non-realizable
USOs.",2022-07-13 06:46:22+00:00,Realizability Makes a Difference: A Complexity Gap for Sink-Finding in USOs,cs.DS,"['cs.DS', 'cs.CC', 'math.CO', 'math.OC']","[arxiv.Result.Author('Simon Weber'), arxiv.Result.Author('Joel Widmer')]","Algorithms for finding the sink in Unique Sink Orientations (USOs) of the
hypercube can be used to solve many algebraic and geometric problems, most
importantly including the P-Matrix Linear Complementarity Problem and Linear
Programming. The realizable USOs are those that arise from the reductions of
these problems to the USO sink-finding problem. Finding the sink of realizable
USOs is thus highly practically relevant, yet it is unknown whether
realizability can be exploited algorithmically to find the sink more quickly.
However, all (non-trivial) known unconditional lower bounds for sink-finding
make use of USOs that are provably not realizable. This indicates that the
sink-finding problem might indeed be strictly easier on realizable USOs.
  In this paper we show that this is true for a subclass of all USOs. We
consider the class of Matou\v{s}ek-type USOs, which are a translation of
Matou\v{s}ek's LP-type problems into the language of USOs. We show a query
complexity gap between sink-finding in all, and sink-finding in only the
realizable $n$-dimensional Matou\v{s}ek-type USOs. We provide concrete
deterministic algorithms and lower bounds for both cases, and show that in the
realizable case $O(log^2 n)$ vertex evaluation queries suffice, while in
general exactly $n$ queries are needed. The Matou\v{s}ek-type USOs are the
first USO class found to admit such a gap.",-0.118420094,0.03216529,0.23349029,C
8917,"Our results show a richer variety of possibilities and motivate further study of CSPs with
                                                randomly ordered constraints.","Speciﬁcally it i√s known to be as hard
                                                to approximate with random ordering as with adversarial ordering, for o( n) space algorithms.",∗Microsoft Research.,2022-07-14 18:35:15+00:00,Streaming complexity of CSPs with randomly ordered constraints,cs.DS,"['cs.DS', 'cs.CC']","[arxiv.Result.Author('Raghuvansh R. Saxena'), arxiv.Result.Author('Noah Singer'), arxiv.Result.Author('Madhu Sudan'), arxiv.Result.Author('Santhoshini Velusamy')]","We initiate a study of the streaming complexity of constraint satisfaction
problems (CSPs) when the constraints arrive in a random order. We show that
there exists a CSP, namely $\textsf{Max-DICUT}$, for which random ordering
makes a provable difference. Whereas a $4/9 \approx 0.445$ approximation of
$\textsf{DICUT}$ requires $\Omega(\sqrt{n})$ space with adversarial ordering,
we show that with random ordering of constraints there exists a
$0.48$-approximation algorithm that only needs $O(\log n)$ space. We also give
new algorithms for $\textsf{Max-DICUT}$ in variants of the adversarial ordering
setting. Specifically, we give a two-pass $O(\log n)$ space
$0.48$-approximation algorithm for general graphs and a single-pass
$\tilde{O}(\sqrt{n})$ space $0.48$-approximation algorithm for bounded degree
graphs.
  On the negative side, we prove that CSPs where the satisfying assignments of
the constraints support a one-wise independent distribution require
$\Omega(\sqrt{n})$-space for any non-trivial approximation, even when the
constraints are randomly ordered. This was previously known only for
adversarially ordered constraints. Extending the results to randomly ordered
constraints requires switching the hard instances from a union of random
matchings to simple Erd\""os-Renyi random (hyper)graphs and extending tools that
can perform Fourier analysis on such instances.
  The only CSP to have been considered previously with random ordering is
$\textsf{Max-CUT}$ where the ordering is not known to change the
approximability. Specifically it is known to be as hard to approximate with
random ordering as with adversarial ordering, for $o(\sqrt{n})$ space
algorithms. Our results show a richer variety of possibilities and motivate
further study of CSPs with randomly ordered constraints.",-0.054763973,-0.18312909,0.1461306,B
9142,"Even so, we believe our work is still important since it introduces a new set of practically interesting
combinatorial problems for further study by the diﬀerential privacy community.","(2010), and is overall not technically
diﬃcult.","1.1 Related Work

The Set Cover problem and its various generalizations have been studied by combinatorial optimization

community for several decades (Wolsey, 1982; Alon et al., 2003).",2022-07-21 00:43:14+00:00,Differentially Private Partial Set Cover with Applications to Facility Location,cs.DS,"['cs.DS', 'cs.AI', 'cs.CR']","[arxiv.Result.Author('George Z. Li'), arxiv.Result.Author('Dung Nguyen'), arxiv.Result.Author('Anil Vullikanti')]","It was observed in \citet{gupta2009differentially} that the Set Cover problem
has strong impossibility results under differential privacy. In our work, we
observe that these hardness results dissolve when we turn to the Partial Set
Cover problem, where we only need to cover a $\rho$-fraction of the elements in
the universe, for some $\rho\in(0,1)$. We show that this relaxation enables us
to avoid the impossibility results: under loose conditions on the input set
system, we give differentially private algorithms which output an explicit set
cover with non-trivial approximation guarantees. In particular, this is the
first differentially private algorithm which outputs an explicit set cover.
  Using our algorithm for Partial Set Cover as a subroutine, we give a
differentially private (bicriteria) approximation algorithm for a facility
location problem which generalizes $k$-center/$k$-supplier with outliers. Like
with the Set Cover problem, no algorithm has been able to give non-trivial
guarantees for $k$-center/$k$-supplier-type facility location problems due to
the high sensitivity and impossibility results. Our algorithm shows that
relaxing the covering requirement to serving only a $\rho$-fraction of the
population, for $\rho\in(0,1)$, enables us to circumvent the inherent hardness.
Overall, our work is an important step in tackling and understanding
impossibility results in private combinatorial optimization.",-0.10311346,-0.3473552,-0.18810025,B
9719,These problems can be intriguing for further research.,"There are other open questions
to consider: what can we say when the jobs can have arbitrarily big processing time, or if there are
multiple types of resources.","16
Acknowledgements

This work has been supported by the National Research, Development and Innovation Oﬃce grants
no.",2022-08-04 16:22:16+00:00,An online joint replenishment problem combined with single machine scheduling,cs.DS,"['cs.DS', 'math.OC', '90B35']","[arxiv.Result.Author('Péter Györgyi'), arxiv.Result.Author('Tamás Kis'), arxiv.Result.Author('Tímea Tamási')]","This paper considers a combination of the joint replenishment problem with
single machine scheduling. There is a single resource, which is required by all
the jobs, and a job can be started at time point $t$ on the machine if and only
the machine does not process another job at $t$, and the resource is
replenished between its release date and $t$. Each replenishment has a cost,
which is independent of the amount replenished. The objective is to minimize
the total replenishment cost plus the maximum flow time of the jobs.
  We consider the online variant of the problem, where the jobs are released
over time, and once a job is inserted into the schedule, its starting time
cannot be changed. We propose a deterministic 2-competitive online algorithm
for the general input. Moreover, we show that for a certain class of inputs
(so-called $p$-bounded input), the competitive ratio of the algorithm tends to
$\sqrt{2}$ as the number of jobs tends to infinity. We also derive several
lower bounds for the best competitive ratio of any deterministic online
algorithm under various assumptions.",0.19836211,-0.18722479,0.003551945,B
9861,"Our reduction enables approxi-
mation schemes for Lp TSP on Euclidean as well as weighted tree metrics; this is yet another motivation to
further study the segmented-TSP problem.","We provided a high precision polynomial time reduction of Lp TSP to segmented-TSP with only a con-
stant number of deadlines for visiting the required number of destinations.","Next, we investigated the case where we do not know what norm is the best to optimize, but want to
be approximately optimal with respect to any.",2022-08-08 20:49:22+00:00,Multi Purpose Routing: New Perspectives and Approximation Algorithms,cs.DS,"['cs.DS', '68W25 (Primary) 68Q25, 90C27 (Secondary)', 'F.2.2']","[arxiv.Result.Author('Majid Farhadi'), arxiv.Result.Author('Jai Moondra'), arxiv.Result.Author('Prasad Tetali'), arxiv.Result.Author('Alejandro Toriello')]","The cost due to delay in services may be intrinsically different for various
applications of vehicle routing such as medical emergencies, logistical
operations, and ride-sharing. We study a fundamental generalization of the
Traveling Salesman Problem, namely $L_p$ TSP, where the objective is to
minimize an aggregated measure of the delay in services, quantified by the
Minkowski $p$-norm of the delay vector. We present efficient combinatorial and
Linear Programming algorithms for approximating $L_p$ TSP on general metrics.
We provide several approximation algorithms for the $L_p$ TSP problem,
including $4.27$ & $10.92$-approximation algorithms for single & multi vehicle
$L_2$ TSP, called the Traveling Firefighter Problem. Among other contributions,
we provide an $8$-approximation and a $1.78$ inapproximability for All-Norm TSP
problem, addressing scenarios where one does not know the ideal cost function,
or is seeking simultaneous approximation with respect to any cost function.",-0.1847763,0.030887295,0.18929255,A
11360,"This motivated further research on LP algorithms
                                        which are eﬃcient in both theory and practice.","The
                                        ﬁrst polynomial time algorithm for general LPs was the ellipsoid method [41], which is rather slow
                                        in practice compared to the simplex algorithm.","One of the most successful paradigms for solving
                                        LPs is the family of Interior Point Methods (IPMs), pioneered by Karmarkar in the mid 1980s [40].",2022-09-19 02:41:05+00:00,Faster Randomized Interior Point Methods for Tall/Wide Linear Programs,cs.DS,['cs.DS'],"[arxiv.Result.Author('Agniva Chowdhury'), arxiv.Result.Author('Gregory Dexter'), arxiv.Result.Author('Palma London'), arxiv.Result.Author('Haim Avron'), arxiv.Result.Author('Petros Drineas')]","Linear programming (LP) is an extremely useful tool which has been
successfully applied to solve various problems in a wide range of areas,
including operations research, engineering, economics, or even more abstract
mathematical areas such as combinatorics. It is also used in many machine
learning applications, such as $\ell_1$-regularized SVMs, basis pursuit,
nonnegative matrix factorization, etc. Interior Point Methods (IPMs) are one of
the most popular methods to solve LPs both in theory and in practice. Their
underlying complexity is dominated by the cost of solving a system of linear
equations at each iteration. In this paper, we consider both feasible and
infeasible IPMs for the special case where the number of variables is much
larger than the number of constraints. Using tools from Randomized Linear
Algebra, we present a preconditioning technique that, when combined with the
iterative solvers such as Conjugate Gradient or Chebyshev Iteration, provably
guarantees that IPM algorithms (suitably modified to account for the error
incurred by the approximate solver), converge to a feasible, approximately
optimal solution, without increasing their iteration complexity. Our empirical
evaluations verify our theoretical results on both real-world and synthetic
data.",0.04671079,-0.04063331,0.58993345,C
11361,"This motivated further research on LP algorithms
                                        which are eﬃcient in both theory and practice.","The
                                        ﬁrst polynomial time algorithm for general LPs was the ellipsoid method [41], which is rather slow
                                        in practice compared to the simplex algorithm.","One of the most successful paradigms for solving
                                        LPs is the family of Interior Point Methods (IPMs), pioneered by Karmarkar in the mid 1980s [40].",2022-09-19 02:41:05+00:00,Faster Randomized Interior Point Methods for Tall/Wide Linear Programs,cs.DS,['cs.DS'],"[arxiv.Result.Author('Agniva Chowdhury'), arxiv.Result.Author('Gregory Dexter'), arxiv.Result.Author('Palma London'), arxiv.Result.Author('Haim Avron'), arxiv.Result.Author('Petros Drineas')]","Linear programming (LP) is an extremely useful tool which has been
successfully applied to solve various problems in a wide range of areas,
including operations research, engineering, economics, or even more abstract
mathematical areas such as combinatorics. It is also used in many machine
learning applications, such as $\ell_1$-regularized SVMs, basis pursuit,
nonnegative matrix factorization, etc. Interior Point Methods (IPMs) are one of
the most popular methods to solve LPs both in theory and in practice. Their
underlying complexity is dominated by the cost of solving a system of linear
equations at each iteration. In this paper, we consider both feasible and
infeasible IPMs for the special case where the number of variables is much
larger than the number of constraints. Using tools from Randomized Linear
Algebra, we present a preconditioning technique that, when combined with the
iterative solvers such as Conjugate Gradient or Chebyshev Iteration, provably
guarantees that IPM algorithms (suitably modified to account for the error
incurred by the approximate solver), converge to a feasible, approximately
optimal solution, without increasing their iteration complexity. Our empirical
evaluations verify our theoretical results on both real-world and synthetic
data.",0.04671079,-0.04063331,0.58993345,C
11514,"We believe that understanding the full
power of the techniques developed in this paper is an intriguing direction for further research in the still
emerging area of learning-augmented algorithms.","Nevertheless, we expect that the techniques and
analysis that we introduce in this paper may be of independent interest for other related problems or settings,
such as the advice being adaptive, or in settings of multiple experts.","1.4 Organization

In Section 2, we present the PDLA algorithms for online covering LPs, prove Theorems 1.3 and 1.5, and
show the applications on fractional online set cover with fractional advice and group Steiner tree on trees.",2022-09-21 19:16:29+00:00,Learning-Augmented Algorithms for Online Linear and Semidefinite Programming,cs.DS,"['cs.DS', 'cs.LG', 'math.OC']","[arxiv.Result.Author('Elena Grigorescu'), arxiv.Result.Author('Young-San Lin'), arxiv.Result.Author('Sandeep Silwal'), arxiv.Result.Author('Maoyuan Song'), arxiv.Result.Author('Samson Zhou')]","Semidefinite programming (SDP) is a unifying framework that generalizes both
linear programming and quadratically-constrained quadratic programming, while
also yielding efficient solvers, both in theory and in practice. However, there
exist known impossibility results for approximating the optimal solution when
constraints for covering SDPs arrive in an online fashion. In this paper, we
study online covering linear and semidefinite programs in which the algorithm
is augmented with advice from a possibly erroneous predictor. We show that if
the predictor is accurate, we can efficiently bypass these impossibility
results and achieve a constant-factor approximation to the optimal solution,
i.e., consistency. On the other hand, if the predictor is inaccurate, under
some technical conditions, we achieve results that match both the classical
optimal upper bounds and the tight lower bounds up to constant factors, i.e.,
robustness.
  More broadly, we introduce a framework that extends both (1) the online set
cover problem augmented with machine-learning predictors, studied by Bamas,
Maggiori, and Svensson (NeurIPS 2020), and (2) the online covering SDP problem,
initiated by Elad, Kale, and Naor (ICALP 2016). Specifically, we obtain general
online learning-augmented algorithms for covering linear programs with
fractional advice and constraints, and initiate the study of learning-augmented
algorithms for covering SDP problems.
  Our techniques are based on the primal-dual framework of Buchbinder and Naor
(Mathematics of Operations Research, 34, 2009) and can be further adjusted to
handle constraints where the variables lie in a bounded region, i.e., box
constraints.",-0.10909927,-0.11704845,-0.0050125476,B
12042,"We conclude the
   article in Section 9 with some open questions for further research.","In Section 8 we bound the
   size of the obstructions for elimination distance, hence proving Theorem 5.","Laure Morelle, Ignasi Sau, Giannos Stamoulis, and Dimitrios M. Thilikos                           7

 2 Deﬁnitions and preliminary results

In this section, we give some deﬁnitions and preliminary results.",2022-10-05 11:49:59+00:00,Faster parameterized algorithms for modification problems to minor-closed classes,cs.DS,"['cs.DS', 'cs.CC', 'math.CO', '05C85, 68R10, 05C75, 05C83, 05C75, 05C69', 'F.2.2; G.2.2']","[arxiv.Result.Author('Laure Morelle'), arxiv.Result.Author('Ignasi Sau'), arxiv.Result.Author('Giannos Stamoulis'), arxiv.Result.Author('Dimitrios M. Thilikos')]","Let ${\cal G}$ be a minor-closed graph class and let $G$ be an $n$-vertex
graph. We say that $G$ is a $k$-apex of ${\cal G}$ if $G$ contains a set $S$ of
at most $k$ vertices such that $G\setminus S$ belongs to ${\cal G}$. Our first
result is an algorithm that decides whether $G$ is a $k$-apex of ${\cal G}$ in
time $2^{{\sf poly}(k)}\cdot n^2$, where ${\sf poly}$ is a polynomial function
depending on ${\cal G}$. This algorithm improves the previous one, given by
Sau, Stamoulis, and Thilikos [ICALP 2020], whose running time was $2^{{\sf
poly}(k)}\cdot n^3$. The elimination distance of $G$ to ${\cal G}$, denoted by
${\sf ed}_{\cal G}(G)$, is the minimum number of rounds required to reduce each
connected component of $G$ to a graph in ${\cal G}$ by removing one vertex from
each connected component in each round. Bulian and Dawar [Algorithmica 2017]
provided an FPT-algorithm, with parameter $k$, to decide whether ${\sf
ed}_{\cal G}(G)\leq k$. However, its dependence on $k$ is not explicit. We
extend the techniques used in the first algorithm to decide whether ${\sf
ed}_{\cal G}(G)\leq k$ in time $2^{2^{2^{{\sf poly}(k)}}}\cdot n^2$. This is
the first algorithm for this problem with an explicit parametric dependence in
$k$. In the special case where ${\cal G}$ excludes some apex-graph as a minor,
we give two alternative algorithms, running in time $2^{2^{{\cal O}(k^2\log
k)}}\cdot n^2$ and $2^{{\sf poly}(k)}\cdot n^3$ respectively, where $c$ and
${\sf poly}$ depend on ${\cal G}$. As a stepping stone for these algorithms, we
provide an algorithm that decides whether ${\sf ed}_{\cal G}(G)\leq k$ in time
$2^{{\cal O}({\sf tw}\cdot k+{\sf tw}\log{\sf tw})}\cdot n$, where ${\sf tw}$
is the treewidth of $G$. Finally, we provide explicit upper bounds on the size
of the graphs in the minor-obstruction set of the class of graphs ${\cal
E}_k({\cal G})=\{G\mid{\sf ed}_{\cal G}(G)\leq k\}$.",-0.1423479,0.03245323,-0.32377622,B
12142,"Still,
the existence of a practical (faster) exact algorithm for Delaunay Realization is left for
further research.",We have thus obtained the ﬁrst exact exponential-time algorithm for this problem.,"In this context, it is not even clear whether a signiﬁcantly faster algorithm,
say a polynomial-time algorithm, exists.",2022-10-08 06:03:30+00:00,A Finite Algorithm for the Realizabilty of a Delaunay Triangulation,cs.DS,"['cs.DS', 'cs.CG']","[arxiv.Result.Author('Akanksha Agrawal'), arxiv.Result.Author('Saket Saurabh'), arxiv.Result.Author('Meirav Zehavi')]","The \emph{Delaunay graph} of a point set $P \subseteq \mathbb{R}^2$ is the
plane graph with the vertex-set $P$ and the edge-set that contains $\{p,p'\}$
if there exists a disc whose intersection with $P$ is exactly $\{p,p'\}$.
Accordingly, a triangulated graph $G$ is \emph{Delaunay realizable} if there
exists a triangulation of the Delaunay graph of some $P \subseteq
\mathbb{R}^2$, called a \emph{Delaunay triangulation} of $P$, that is
isomorphic to $G$. The objective of \textsc{Delaunay Realization} is to compute
a point set $P \subseteq \mathbb{R}^2$ that realizes a given graph $G$ (if such
a $P$ exists). Known algorithms do not solve \textsc{Delaunay Realization} as
they are non-constructive. Obtaining a constructive algorithm for
\textsc{Delaunay Realization} was mentioned as an open problem by Hiroshima et
al.~\cite{hiroshima2000}. We design an $n^{\mathcal{O}(n)}$-time constructive
algorithm for \textsc{Delaunay Realization}. In fact, our algorithm outputs
sets of points with {\em integer} coordinates.",-0.072310895,0.15719123,0.2522911,C
12454,"2.4 Future Directions

Our work raises several directions for further research.",But we will work with the walk tree and use our Lemma 5.,We highlight two of them below.,2022-10-14 05:29:51+00:00,Time-Space Tradeoffs for Element Distinctness and Set Intersection via Pseudorandomness,cs.DS,"['cs.DS', 'cs.CC']","[arxiv.Result.Author('Xin Lyu'), arxiv.Result.Author('Weihao Zhu')]","In the Element Distinctness problem, one is given an array $a_1,\dots, a_n$
of integers from $[poly(n)]$ and is tasked to decide if $\{a_i\}$ are mutually
distinct. Beame, Clifford and Machmouchi (FOCS 2013) gave a low-space algorithm
for this problem running in space $S(n)$ and time $T(n)$ where $T(n) \le
\widetilde{O}(n^{3/2}/S(n)^{1/2})$, assuming a random oracle (i.e., random
access to polynomially many random bits). A recent breakthrough by Chen, Jin,
Williams and Wu (SODA 2022) showed how to remove the random oracle assumption
in the regime $S(n) = polylog(n)$ and $T(n) = \widetilde{O}(n^{3/2})$. They
designed the first truly $polylog(n)$-space, $\widetilde{O}(n^{3/2})$-time
algorithm by constructing a small family of hash functions $\mathcal{H}
\subseteq \{h | h:[poly(n)]\to [n]\}$ with a certain pseudorandom property.
  In this paper, we give a significantly simplified analysis of the
pseudorandom hash family by Chen et al. Our analysis clearly identifies the key
pseudorandom property required to fool the BCM algorithm, allowing us to
explore the full potential of this construction. As our main result, we show a
time-space tradeoff for Element Distinctness without random oracle. Namely, for
every $S(n),T(n)$ such that $T\approx \widetilde{O}(n^{3/2}/S(n)^{1/2})$, our
algorithm can solve the problem in space $S(n)$ and time $T(n)$. Our algorithm
also works for a related problem Set Intersection, for which this tradeoff is
tight due to a matching lower bound by Dinur (Eurocrypt 2020). As two
additional contributions, we show a more general pseudorandom property of the
hash family, and slightly improve the seed length to sample the pseudorandom
hash function.",0.27602062,0.27575713,-0.29936042,A
12806,"We further study lower and upper bounds on the competitive ratio in variants of this model,
                                        e.g., single-resource with diﬀerent demand sizes, or matching with deterministic integral allocations.","We establish the optimality of our
                                        results by obtaining separate lower-bounds for each of small and large buyback factor regimes, and showing
                                        how our primal-dual algorithm exactly matches this lower-bound by appropriately tuning a parameter as a
                                        function of f .","We
                                        show how algorithms in the our family of primal-dual algorithms can obtain the exact optimal competitive
                                        ratio in all of these variants — which in turn demonstrates the power of our algorithmic framework for online
                                        resource allocations with costly buyback.",2022-10-20 20:12:43+00:00,Online Resource Allocation with Buyback: Optimal Algorithms via Primal-Dual,cs.DS,"['cs.DS', 'cs.GT']","[arxiv.Result.Author('Farbod Ekbatani'), arxiv.Result.Author('Yiding Feng'), arxiv.Result.Author('Rad Niazadeh')]","Motivated by applications in cloud computing spot markets and selling banner
ads on popular websites, we study the online resource allocation problem with
""costly buyback"". To model this problem, we consider the classic edge-weighted
fractional online matching problem with a tweak, where the decision maker can
recall (i.e., buyback) any fraction of an offline resource that is
pre-allocated to an earlier online vertex; however, by doing so not only the
decision maker loses the previously allocated reward (which equates the
edge-weight), it also has to pay a non-negative constant factor $f$ of this
edge-weight as an extra penalty. Parameterizing the problem by the buyback
factor $f$, our main result is obtaining optimal competitive algorithms for all
possible values of $f$ through a novel primal-dual family of algorithms. We
establish the optimality of our results by obtaining separate lower-bounds for
each of small and large buyback factor regimes, and showing how our primal-dual
algorithm exactly matches this lower-bound by appropriately tuning a parameter
as a function of $f$. We further study lower and upper bounds on the
competitive ratio in variants of this model, e.g., single-resource with
different demand sizes, or matching with deterministic integral allocations. We
show how algorithms in the our family of primal-dual algorithms can obtain the
exact optimal competitive ratio in all of these variants -- which in turn
demonstrates the power of our algorithmic framework for online resource
allocations with costly buyback.",-0.07604278,-0.4269724,0.05224257,B
12820,"Feng, Niazadeh, Saberi: Two-stage Stochastic Matching and Pricing with Applications to Ride Hailing

                                                                                                                                                25

   We further study a special case of the above problem in Appendix EC.7, where it is just a single
stage — or equivalently, there is no demand vertex in the ﬁrst stage.","We then show how to obtain a feasible policy from this optimal solution
that only loses a factor 21 in the market eﬃciency.","We propose an optimal (1 − 1e )-
competitive algorithm against the ex-ante relaxation.",2022-10-21 00:34:05+00:00,Two-stage Stochastic Matching and Pricing with Applications to Ride Hailing,cs.DS,"['cs.DS', 'cs.GT']","[arxiv.Result.Author('Yiding Feng'), arxiv.Result.Author('Rad Niazadeh'), arxiv.Result.Author('Amin Saberi')]","Matching and pricing are two critical levers in two-sided marketplaces to
connect demand and supply. The platform can produce more efficient matching and
pricing decisions by batching the demand requests. We initiate the study of the
two-stage stochastic matching problem, with or without pricing, to enable the
platform to make improved decisions in a batch with an eye toward the imminent
future demand requests. This problem is motivated in part by applications in
online marketplaces such as ride hailing platforms.
  We design online competitive algorithms for vertex-weighted (or unweighted)
two-stage stochastic matching for maximizing supply efficiency, and two-stage
joint matching and pricing for maximizing market efficiency. In the former
problem, using a randomized primal-dual algorithm applied to a family of
``balancing'' convex programs, we obtain the optimal $3/4$ competitive ratio
against the optimum offline benchmark. Using a factor revealing program and
connections to submodular optimization, we improve this ratio against the
optimum online benchmark to $(1-1/e+1/e^2)\approx 0.767$ for the unweighted and
$0.761$ for the weighted case. In the latter problem, we design optimal
$1/2$-competitive joint pricing and matching algorithm by borrowing ideas from
the ex-ante prophet inequality literature. We also show an improved
$(1-1/e)$-competitive algorithm for the special case of demand efficiency
objective using the correlation gap of submodular functions. Finally, we
complement our theoretical study by using DiDi's ride-sharing dataset for
Chengdu city and numerically evaluating the performance of our proposed
algorithms in practical instances of this problem.",-0.031252168,-0.44346285,0.084493786,B
13201,"We expect a better analysis or a more involved algorithm to give a better running time
bound and leave this as an interesting open question for further research.","Since there are at most 2|V1|-many recursions for an instance (G, V1, V2) that are called,
DomColDP solves (G, ) in time O(3n · 2n) = O(6n).","For now, our
interest was to show that DomCol can be solved in a O(cn)-time for some constant c.

     Let (G, M, ) be an instance of of DomCol-CLQ where Q = G − M is a clique of size at
most k. Since |M | = k, |V (G)| ≤ 2k and therefore, by the proof of Theorem 2.2, (G, M, )
can be solved in O(36k)-time.",2022-10-31 13:40:44+00:00,Dominator Coloring Parameterized by Cluster Vertex Deletion Number,cs.DS,"['cs.DS', 'cs.CC', '05C85', 'G.2.2']","[arxiv.Result.Author('Aritra Banik'), arxiv.Result.Author('Prahlad Narasimhan Kasthurirangan'), arxiv.Result.Author('Venkatesh Raman')]","The Dominator Coloring (DC) problem borrows properties of two classical
problems in graph theory - Graph Coloring and Dominating Set. A dominator
coloring $\chi_d$ of a graph $G$ is a proper coloring of its vertices such that
each vertex dominates a color class - that is, for each $v \in V(G)$, there
exists a color $c$ such that $\emptyset \subset \chi^{-1}_d(c) \subseteq
N_G[v]$. Given a graph $G$ and a natural number $\ell$, DC asks if there is a
dominator coloring of $G$ which uses at most $\ell$-many colors. DC, which was
first described in 2006 and studied in several papers since then, still hosts
several important open questions. While it is known that DC is FPT when
parameterized by $(t,\ell)$ where $\ell$ is the number of colors used and $t$
the treewidth of $G$, the structural parameterized landscape of the problem
remains unexplored. We initiate the study of DC through the lens of structural
parameterization.
  Our first result in this paper is a randomized $O^*(c^k)$ algorithm for DC
where $c$ is a constant and $k$ is the size of a graph's Clique Modulator, a
set of vertices whose deletion results in a clique. This algorithm is obtained
by a non-trivial adaptation of the recent work by Gutin et al. for List
Coloring (LC) parameterized by the clique modulator that uses an
inclusion-exclusion based polynomial sieving technique, and in addition uses a
DP based exact algorithm we develop for DC. Later, we prove the main result of
the paper - DC is FPT when parameterized by the size of a graph's Cluster
Vertex Deletion (CVD) set; in contrast to the W[i]-hardness result for LC
parameterized by the CVD set size. En route, we design a simpler and faster
deterministic FPT algorithm when the problem is parameterized by the size of a
graph's Twin Cover. We believe that this algorithm's approach, which uses a
relationship between DC and LC that we establish, is of independent interest.",-0.21501482,-0.011951905,-0.11709841,B
13736,"Given the relative scarcity of algorithms for solving average-case dis-
crepancy problems, we hope that further study of the certiﬁcation problem will inspire the development
of novel algorithmic techniques and candidate optimal algorithms.","This body of work has amassed strong evidence of the optimality of
semideﬁnite programming (SDP)-based algorithms for a wide class of average-case problems exhibiting
statistical-to-computational gaps.","Finally, there is a long history of works in computer science and discrete mathematics designing eﬃcent
adligscorreitphamncsytoofcoammple×mnenGt anuosns-icaonnsmtrautcrtixiveispartoolfesasotf Ωco(m√bni2n−amto/rni)alwrietshulhtsi.ghTphreobkanbowilintypmroaokfetshautsethoef
the ﬁrst-moment method.",2022-11-14 16:39:06+00:00,Efficient algorithms for certifying lower bounds on the discrepancy of random matrices,cs.DS,"['cs.DS', 'cs.CC', 'cs.DM']",[arxiv.Result.Author('Prayaag Venkat')],"We initiate the study of the algorithmic problem of certifying lower bounds
on the discrepancy of random matrices: given an input matrix $A \in
\mathbb{R}^{m \times n}$, output a value that is a lower bound on
$\mathsf{disc}(A) = \min_{x \in \{\pm 1\}^n} ||Ax||_\infty$ for every $A$, but
is close to the typical value of $\mathsf{disc}(A)$ with high probability over
the choice of a random $A$. This problem is important because of its
connections to conjecturally-hard average-case problems such as
negatively-spiked PCA, the number-balancing problem and refuting random
constraint satisfaction problems. We give the first polynomial-time algorithms
with non-trivial guarantees for two main settings. First, when the entries of
$A$ are i.i.d. standard Gaussians, it is known that $\mathsf{disc} (A) = \Theta
(\sqrt{n}2^{-n/m})$ with high probability. Our algorithm certifies that
$\mathsf{disc}(A) \geq \exp(- O(n^2/m))$ with high probability. As an
application, this formally refutes a conjecture of Bandeira, Kunisky, and Wein
on the computational hardness of the detection problem in the negatively-spiked
Wishart model. Second, we consider the integer partitioning problem: given $n$
uniformly random $b$-bit integers $a_1, \ldots, a_n$, certify the non-existence
of a perfect partition, i.e. certify that $\mathsf{disc} (A) \geq 1$ for $A =
(a_1, \ldots, a_n)$. Under the scaling $b = \alpha n$, it is known that the
probability of the existence of a perfect partition undergoes a phase
transition from 1 to 0 at $\alpha = 1$; our algorithm certifies the
non-existence of perfect partitions for some $\alpha = O(n)$. We also give
efficient non-deterministic algorithms with significantly improved guarantees.
Our algorithms involve a reduction to the Shortest Vector Problem.",-0.07793258,-0.20069578,0.42648047,C
13861,"We encourage further research to investigate
which relaxations would work best (e.g.","Since the optimal solution to the 0-1 knapsack
problem is always an IMS, the bounds derived in Subsection 3.3 can also be added to the problem without changing
the optimum and this could be interesting to obtain strong relaxations.","linear relaxations, surrogate relaxations or Lagrangian-based relaxations) and
how these relaxations could be efﬁciently solved.",2022-11-16 12:48:35+00:00,Features for the 0-1 knapsack problem based on inclusionwise maximal solutions,cs.DS,"['cs.DS', 'cs.AI']","[arxiv.Result.Author('Jorik Jooken'), arxiv.Result.Author('Pieter Leyman'), arxiv.Result.Author('Patrick De Causmaecker')]","Decades of research on the 0-1 knapsack problem led to very efficient
algorithms that are able to quickly solve large problem instances to
optimality. This prompted researchers to also investigate whether relatively
small problem instances exist that are hard for existing solvers and
investigate which features characterize their hardness. Previously the authors
proposed a new class of hard 0-1 knapsack problem instances and demonstrated
that the properties of so-called inclusionwise maximal solutions (IMSs) can be
important hardness indicators for this class. In the current paper, we
formulate several new computationally challenging problems related to the IMSs
of arbitrary 0-1 knapsack problem instances. Based on generalizations of
previous work and new structural results about IMSs, we formulate polynomial
and pseudopolynomial time algorithms for solving these problems. From this we
derive a set of 14 computationally expensive features, which we calculate for
two large datasets on a supercomputer in approximately 540 CPU-hours. We show
that the proposed features contain important information related to the
empirical hardness of a problem instance that was missing in earlier features
from the literature by training machine learning models that can accurately
predict the empirical hardness of a wide variety of 0-1 knapsack problem
instances. Using the instance space analysis methodology, we also show that
hard 0-1 knapsack problem instances are clustered together around a relatively
dense region of the instance space and several features behave differently in
the easy and hard parts of the instance space.",-0.13559006,-0.38432366,0.098239765,B
14032,"We anticipate that further study of the
numerous open problems stated here will lead to signiﬁcant advances in these fun-
damental computational areas.","That they have been so much studied testiﬁes to their current
relevance as well as to their potential future impact on the development of com-
binatorics on words and string algorithms.","Compliance with Ethical Standards

Conﬂict of Interest: All authors declare that they have no conﬂict of interest.",2022-11-21 21:21:30+00:00,String Covering: A Survey,cs.DS,['cs.DS'],"[arxiv.Result.Author('Neerja Mhaskar'), arxiv.Result.Author('W. F. Smyth')]","The study of strings is an important combinatorial field that precedes the
digital computer. Strings can be very long, trillions of letters, so it is
important to find compact representations. Here we first survey various forms
of one potential compaction methodology, the cover of a given string x,
initially proposed in a simple form in 1990, but increasingly of interest as
more sophisticated variants have been discovered. We then consider covering by
a seed; that is, a cover of a superstring of x. We conclude with many proposals
for research directions that could make significant contributions to string
processing in future.",0.038308688,0.118315175,0.17462899,C
14045,"We further study the support size estimation problem when

we allow SAMP oracle access and conditioning on sets of size at most k (see Section 6).",The power of bounded-set conditioning.,"We show a lower
                                                                                        n  l  og l  og  n
bound   of  Ω(n/k)  (Theorem     6.2)         and      an  upper       bound  of  O  (          k          )  (Theorem     6.1)  for    constant  factor

approximation in this model.",2022-11-22 02:56:02+00:00,Support Size Estimation: The Power of Conditioning,cs.DS,['cs.DS'],"[arxiv.Result.Author('Diptarka Chakraborty'), arxiv.Result.Author('Gunjan Kumar'), arxiv.Result.Author('Kuldeep S. Meel')]","We consider the problem of estimating the support size of a distribution $D$.
Our investigations are pursued through the lens of distribution testing and
seek to understand the power of conditional sampling (denoted as COND), wherein
one is allowed to query the given distribution conditioned on an arbitrary
subset $S$. The primary contribution of this work is to introduce a new
approach to lower bounds for the COND model that relies on using powerful tools
from information theory and communication complexity.
  Our approach allows us to obtain surprisingly strong lower bounds for the
COND model and its extensions.
  1) We bridge the longstanding gap between the upper ($O(\log \log n +
\frac{1}{\epsilon^2})$) and the lower bound $\Omega(\sqrt{\log \log n})$ for
COND model by providing a nearly matching lower bound. Surprisingly, we show
that even if we get to know the actual probabilities along with COND samples,
still $\Omega(\log \log n + \frac{1}{\epsilon^2 \log (1/\epsilon)})$ queries
are necessary.
  2) We obtain the first non-trivial lower bound for COND equipped with an
additional oracle that reveals the conditional probabilities of the samples (to
the best of our knowledge, this subsumes all of the models previously studied):
in particular, we demonstrate that $\Omega(\log \log \log n +
\frac{1}{\epsilon^2 \log (1/\epsilon)})$ queries are necessary.",-0.18492535,-0.21666166,-0.15361153,B
14062,We conclude the paper with the following open problems for further research.,"We show that Star Coloring
is FPT when parameterized by (a) neighborhood diversity, (b) twin cover, and
(c) the combined parameter clique-width and the number of colors.",1.,2022-11-22 12:32:57+00:00,On Structural Parameterizations of Star Coloring,cs.DS,['cs.DS'],"[arxiv.Result.Author('Sriram Bhyravarapu'), arxiv.Result.Author('I. Vinod Reddy')]","A Star Coloring of a graph G is a proper vertex coloring such that every path
on four vertices uses at least three distinct colors. The minimum number of
colors required for such a star coloring of G is called star chromatic number,
denoted by \chi_s(G). Given a graph G and a positive integer k, the STAR
COLORING PROBLEM asks whether $G$ has a star coloring using at most k colors.
This problem is NP-complete even on restricted graph classes such as bipartite
graphs.
  In this paper, we initiate a study of STAR COLORING from the parameterized
complexity perspective. We show that STAR COLORING is fixed-parameter tractable
when parameterized by (a) neighborhood diversity, (b) twin-cover, and (c) the
combined parameters clique-width and the number of colors.",-0.017323287,-0.16892658,-0.39264825,B
15061,"There are some interesting directions and open questions for SREFLP further research:

    ➢ Is there a proof on the conjuncture of the 4/3 fully input polynomial-time approximation scheme
         for full SREFLP?","That was seen
absolutely for the full SREFLP.",➢ Can it apply also to the non-full SREFLP?,2022-12-16 21:03:11+00:00,On the Optimum Scenarios for Single Row Equidistant Facility Layout Problem,cs.DS,"['cs.DS', 'math.OC']","[arxiv.Result.Author('Shrouq Gamal'), arxiv.Result.Author('Ahmed A. Hawam'), arxiv.Result.Author('Ahmed M. El-Kassas')]","Single Row Equidistant Facility Layout Problem SREFLP is with an NP-Hard
nature to mimic material handling costs along with equally spaced straight-line
facilities layout. Based on literature, it is obvious that efforts of
researchers for solving SREFLP turn from exact methods into release the running
time tracing the principle of the approximate methods in time race, regardless
searching their time complexity release in conjunction with a provable quality
of solutions. This study focuses on Lower bounding LB techniques as an
independent potential solution tool for SREFLP. In particular, Best-known
SREFLP LBs are reported from literature and significantly LBs optimum scenarios
are highlighted. Initially, one gap of the SREFLP bidirectional LB is enhanced.
From the integration between the enhanced LB and the best-known Gilmore-Lawler
GL bounding, a new SREFLP optimum scenario is provided. Further improvements to
GLB lead to guarantee an exact Shipping/Receiving Facility assignment and
propose a conjecture of at most 4/3 approximation scheme for SREFLP.",0.16883293,0.3194161,0.07559625,C
15062,"There are some interesting directions and open questions for SREFLP further research:

    ➢ Is there a proof on the conjuncture of the 4/3 fully input polynomial-time approximation scheme
         for full SREFLP?","That was seen
absolutely for the full SREFLP.",➢ Can it apply also to the non-full SREFLP?,2022-12-16 21:03:11+00:00,On the Optimum Scenarios for Single Row Equidistant Facility Layout Problem,cs.DS,"['cs.DS', 'math.OC']","[arxiv.Result.Author('Shrouq Gamal'), arxiv.Result.Author('Ahmed A. Hawam'), arxiv.Result.Author('Ahmed M. El-Kassas')]","Single Row Equidistant Facility Layout Problem SREFLP is with an NP-Hard
nature to mimic material handling costs along with equally spaced straight-line
facilities layout. Based on literature, it is obvious that efforts of
researchers for solving SREFLP turn from exact methods into release the running
time tracing the principle of the approximate methods in time race, regardless
searching their time complexity release in conjunction with a provable quality
of solutions. This study focuses on Lower bounding LB techniques as an
independent potential solution tool for SREFLP. In particular, Best-known
SREFLP LBs are reported from literature and significantly LBs optimum scenarios
are highlighted. Initially, one gap of the SREFLP bidirectional LB is enhanced.
From the integration between the enhanced LB and the best-known Gilmore-Lawler
GL bounding, a new SREFLP optimum scenario is provided. Further improvements to
GLB lead to guarantee an exact Shipping/Receiving Facility assignment and
propose a conjecture of at most 4/3 approximation scheme for SREFLP.",0.16883293,0.3194161,0.07559625,C
15199,"They prove tight bounds for this prob-
lem on adversarial-order streams and further study it on random-order streams.","Hence, they consider a relaxed version of the problem
that asks for a (1 ± ǫ)-estimate of the number of conﬂicting edges.","Recently, Halldorsson,
Kuhn, Nolin, and Tonayan [HKNT22] gave a palette-sparsiﬁcation-based semi-streaming algorithm for
(degree + 1)-list-coloring for any arbitrary list of colors assigned to the nodes, improving upon the work
of [AA20] whose algorithm works only when the color-list of each vertex v is {1, .",2022-12-20 20:36:53+00:00,Coloring in Graph Streams via Deterministic and Adversarially Robust Algorithms,cs.DS,['cs.DS'],"[arxiv.Result.Author('Sepehr Assadi'), arxiv.Result.Author('Amit Chakrabarti'), arxiv.Result.Author('Prantar Ghosh'), arxiv.Result.Author('Manuel Stoeckl')]","In recent years, there has been a growing interest in solving various graph
coloring problems in the streaming model. The initial algorithms in this line
of work are all crucially randomized, raising natural questions about how
important a role randomization plays in streaming graph coloring. A couple of
very recent works have made progress on this question: they prove that
deterministic or even adversarially robust coloring algorithms (that work on
streams whose updates may depend on the algorithm's past outputs) are
considerably weaker than standard randomized ones. However, there is still a
significant gap between the upper and lower bounds for the number of colors
needed (as a function of the maximum degree $\Delta$) for robust coloring and
multipass deterministic coloring. We contribute to this line of work by proving
the following results.
  In the deterministic semi-streaming (i.e., $O(n \cdot \text{polylog } n)$
space) regime, we present an algorithm that achieves a combinatorially optimal
$(\Delta+1)$-coloring using $O(\log{\Delta} \log\log{\Delta})$ passes. This
improves upon the prior $O(\Delta)$-coloring algorithm of Assadi, Chen, and Sun
(STOC 2022) at the cost of only an $O(\log\log{\Delta})$ factor in the number
of passes.
  In the adversarially robust semi-streaming regime, we design an
$O(\Delta^{5/2})$-coloring algorithm that improves upon the previously best
$O(\Delta^{3})$-coloring algorithm of Chakrabarti, Ghosh, and Stoeckl (ITCS
2022). Further, we obtain a smooth colors/space tradeoff that improves upon
another algorithm of the said work: whereas their algorithm uses $O(\Delta^2)$
colors and $O(n\Delta^{1/2})$ space, ours, in particular, achieves
(i)~$O(\Delta^2)$ colors in $O(n\Delta^{1/3})$ space, and
(ii)~$O(\Delta^{7/4})$ colors in $O(n\Delta^{1/2})$ space.",-0.06594476,-0.11346394,-0.22445832,B
15306,"For further study, it should be interesting to extend the construction techniques and analyses
in this paper to more TTP related problems, for example, TTP-k with k ≥ 3, single round-robin
version of TTP-2 (STTP-2) [15], linear distance relaxation of TTP-k (LDTTP-k) [13], and so on.","The improvements in both theory and practical are
signiﬁcant.","Acknowledgments

The work is supported by the National Natural Science Foundation of China, under grant 61972070.",2022-12-23 10:30:20+00:00,Practical Algorithms with Guaranteed Approximation Ratio for TTP with Maximum Tour Length Two,cs.DS,['cs.DS'],"[arxiv.Result.Author('Jingyang Zhao'), arxiv.Result.Author('Mingyu Xiao')]","The Traveling Tournament Problem (TTP) is a hard but interesting sports
scheduling problem inspired by Major League Baseball, which is to design a
double round-robin schedule such that each pair of teams plays one game in each
other's home venue, minimizing the total distance traveled by all $n$ teams
($n$ is even). In this paper, we consider TTP-2, i.e., TTP under the constraint
that at most two consecutive home games or away games are allowed for each
team. We propose practical algorithms for TTP-2 with improved approximation
ratios. Due to the different structural properties of the problem, all known
algorithms for TTP-2 are different for $n/2$ being odd and even, and our
algorithms are also different for these two cases. For even $n/2$, our
approximation ratio is $1+3/n$, improving the previous result of $1+4/n$. For
odd $n/2$, our approximation ratio is $1+5/n$, improving the previous result of
$3/2+6/n$. In practice, our algorithms are easy to implement. Experiments on
well-known benchmark sets show that our algorithms beat previously known
solutions for all instances with an average improvement of $5.66\%$.",-0.06538416,0.01409781,0.14525105,A
15317,"We conclude
in Section 6 by providing possible directions of further research in this area.","In
Section 4.2 we also apply edge-subdivision to accelerate the Cut&Count approach for the
Feedback Vertex Set problem.Next in Section 5 we provide our lower-bound constructions
for Steiner Tree (Section 5.1), Connected Dominating Set (Section 5.2), Connected
Vertex Cover (Section 5.3), Odd Cycle Transversal (Section 5.4), Feedback Vertex
Set (Section 5.5), and Connected Odd Cycle Transversal (Section 5.6).","4  Tight Bounds for Connectivity Problems Parameterized by Cutwidth

    2 Preliminaries

   For n ∈ N0, let [n] = {1, 2, .",2022-12-23 15:04:24+00:00,Tight Bounds for Connectivity Problems Parameterized by Cutwidth,cs.DS,"['cs.DS', '05C85']","[arxiv.Result.Author('Narek Bojikian'), arxiv.Result.Author('Vera Chekan'), arxiv.Result.Author('Falko Hegerfeld'), arxiv.Result.Author('Stefan Kratsch')]","In this work we start the investigation of tight complexity bounds for
connectivity problems parameterized by cutwidth assuming the Strong
Exponential-Time Hypothesis (SETH). Van Geffen et al. posed this question for
odd cycle transversal and feedback vertex set. We answer it for these two and
four further problems, namely connected vertex cover, connected domintaing set,
steiner tree, and connected odd cycle transversal. For the latter two problems
it sufficed to prove lower bounds that match the running time inherited from
parameterization by treewidth; for the others we provide faster algorithms than
relative to treewidth and prove matching lower bounds. For upper bounds we
first extend the idea of Groenland et al.~[STACS~2022] to solve what we call
coloring-like problem. Such problems are defined by a symmetric matrix $M$ over
$\mathbb{F}_2$ indexed by a set of colors. The goal is to count the number
(modulo some prime $p$) of colorings of a graph such that $M$ has a $1$-entry
if indexed by the colors of the end-points of any edge. We show that this
problem can be solved faster if $M$ has small rank over $\mathbb{F}_p$. We
apply this result to get our upper bounds for connected vertex cover and
connected dominating set. The upper bounds for odd cycle transversal and
feedback vertex set use a subdivision trick to get below the bounds that matrix
rank would yield.",-0.20980677,0.017497748,-0.4216895,A
15384,"We provide a more detailed exploration of this connection in the
Conclusion section where we discuss possible directions of further research.","It is thus possible that such adaptation is possible for other treewidth
algorithms.",The rest of the paper is organized as follows.,2022-12-27 09:32:42+00:00,FPT algoritms providing constant ratio approximation of hypertree width parameters for hypergraphs of bounded rank,cs.DS,['cs.DS'],[arxiv.Result.Author('Igor Razgon')],"We propose an algorithm whose input are parameters $k$ and $r$ and a
hypergraph $H$ of rank at most $r$. The algorithm either returns a tree
decomposition of $H$ of generalized hypertree width at most $4k$ or 'NO'. In
the latter case, it is guaranteed that the hypertree width of $H$ is greater
than $k$. Most importantly, the runtime of the algorithm is \emph{FPT} in $k$
and $r$. The approach extends to fractional hypertree width with a slightly
worse approximation ($4k+1$ instead of $4k$). We hope that the results of this
paper will give rise to a new research direction whose aim is design of FPT
algorithms for computation and approximation of hypertree width parameters for
restricted classes of hypergraphs.",-0.13294604,0.23804876,-0.0030029158,A
15385,Section 5 discusses further research.,"The FPT approximations for ghw and fhw are described in
Sections 3 and 4 respectively.","3
2 Preliminaries

A hypergraph H is a pair (V, E) (also referred as V (H) and E(H)) where V (H)
is the set of vertices of H and E(H) is a family of subsets of V (H) that are
called hyperedges.",2022-12-27 09:32:42+00:00,FPT algoritms providing constant ratio approximation of hypertree width parameters for hypergraphs of bounded rank,cs.DS,['cs.DS'],[arxiv.Result.Author('Igor Razgon')],"We propose an algorithm whose input are parameters $k$ and $r$ and a
hypergraph $H$ of rank at most $r$. The algorithm either returns a tree
decomposition of $H$ of generalized hypertree width at most $4k$ or 'NO'. In
the latter case, it is guaranteed that the hypertree width of $H$ is greater
than $k$. Most importantly, the runtime of the algorithm is \emph{FPT} in $k$
and $r$. The approach extends to fractional hypertree width with a slightly
worse approximation ($4k+1$ instead of $4k$). We hope that the results of this
paper will give rise to a new research direction whose aim is design of FPT
algorithms for computation and approximation of hypertree width parameters for
restricted classes of hypergraphs.",-0.0013480261,0.22825634,-0.27195328,A
15386,"In this section, we iden-
tify two natural directions of further research.",", sq
in H.

5 Conclusion

In this paper we proposed the ﬁrst FPT algorithm for constant approximation
of ghw and fhw of hypergraphs of bounded rank.","The ﬁrst direction is to attempt
to reduce the approximation ratio and, ideally, to produce an exact algorithm.",2022-12-27 09:32:42+00:00,FPT algoritms providing constant ratio approximation of hypertree width parameters for hypergraphs of bounded rank,cs.DS,['cs.DS'],[arxiv.Result.Author('Igor Razgon')],"We propose an algorithm whose input are parameters $k$ and $r$ and a
hypergraph $H$ of rank at most $r$. The algorithm either returns a tree
decomposition of $H$ of generalized hypertree width at most $4k$ or 'NO'. In
the latter case, it is guaranteed that the hypertree width of $H$ is greater
than $k$. Most importantly, the runtime of the algorithm is \emph{FPT} in $k$
and $r$. The approach extends to fractional hypertree width with a slightly
worse approximation ($4k+1$ instead of $4k$). We hope that the results of this
paper will give rise to a new research direction whose aim is design of FPT
algorithms for computation and approximation of hypertree width parameters for
restricted classes of hypergraphs.",-0.24156554,0.15971601,-0.17044389,A
