Unnamed: 0,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract,x,y,z,cluster
16,"To better understand our model and the baseline models‚Äô behavior and why our model improves
both the Q0A and Q1A baselines, we further study the distribution of MRR scores of our model,
Q0A and Q1A baseline models on the test set when user tolerance is 0 and show the distribution in
Figure 3.","Therefore, it has a lower decision error rate than all the
baselines.","From the figure, we can see the reason for each model‚Äôs performance clearer.",2022-01-01 19:37:14+00:00,Simulating and Modeling the Risk of Conversational Search,cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Zhenduo Wang'), arxiv.Result.Author('Qingyao Ai')]","In conversational search, agents can interact with users by asking clarifying
questions to increase their chance to find better results. Many recent works
and shared tasks in both NLP and IR communities have focused on identifying the
need of asking clarifying questions and methodologies of generating them. These
works assume asking clarifying questions is a safe alternative to retrieving
results. As existing conversational search models are far from perfect, it's
possible and common that they could retrieve or generate bad clarifying
questions. Asking too many clarifying questions can also drain user's patience
when the user prefers searching efficiency over correctness. Hence, these
models can get backfired and harm user's search experience because of these
risks by asking clarifying questions.
  In this work, we propose a simulation framework to simulate the risk of
asking questions in conversational search and further revise a risk-aware
conversational search model to control the risk. We show the model's robustness
and effectiveness through extensive experiments on three conversations
datasets, including MSDialog, Ubuntu Dialog Corpus, and Opendialkg in which we
compare it with multiple baselines. We show that the risk-control module can
work with two different re-ranker models and outperform all the baselines in
most of our experiments.",-0.109171025,-0.26908997,-0.26162708,A
554,"This paper presents results of an explorative, prototypi-         Semantic Networks (Quillian, 1967), Conceptual Graphs
cal, qualitative and synthetic research, summarizes insights              (Sowa, 1976), Entity-relationship models (Chen, 1976),
from two research projects and, based on this, indicates an out-          Concept Maps (Novak & Gowin, 1984), Topic Maps (Rath
line for further research in the field of entity relationship extrac-     & Pepper, 1999) and the semantic web, all of which overlap
tion from text.","Instances are
mation.",in basic principles but differ in application orientation.,2022-01-14 08:06:58+00:00,The Lokahi Prototype: Toward the automatic Extraction of Entity Relationship Models from Text,cs.IR,['cs.IR'],[arxiv.Result.Author('Michael Kaufmann')],"Entity relationship extraction envisions the automatic generation of semantic
data models from collections of text, by automatic recognition of entities, by
association of entities to form relationships, and by classifying these
instances to assign them to entity sets (or classes) and relationship sets (or
associations). As a first step in this direction, the Lokahi prototype can
extract entities based on the TF*IDF measure, and generate semantic
relationships based on document-level co-occurrence statistics, for example
with likelihood ratios and pointwise mutual information. This paper presents
results of an explorative, prototypical, qualitative and synthetic research,
summarizes insights from two research projects and, based on this, indicates an
outline for further research in the field of entity relationship extraction
from text.",0.16764763,0.4343061,0.011187043,C
555,"This reduces the
extraction is presented, and the insights, implications and
points for further research are discussed.","Also, it is a
purely syntactical approach fitted for extraction from text,
where all labels, even entity sets and relationship sets, are
named entities, that is, entities identified with their syntacti-
cal representation in form of their name.","The Lokahi Prototype for Concept Browsing

  Lokahi is a research prototype that prototypically ex-
plores the automatic generation of knowledge networks.",2022-01-14 08:06:58+00:00,The Lokahi Prototype: Toward the automatic Extraction of Entity Relationship Models from Text,cs.IR,['cs.IR'],[arxiv.Result.Author('Michael Kaufmann')],"Entity relationship extraction envisions the automatic generation of semantic
data models from collections of text, by automatic recognition of entities, by
association of entities to form relationships, and by classifying these
instances to assign them to entity sets (or classes) and relationship sets (or
associations). As a first step in this direction, the Lokahi prototype can
extract entities based on the TF*IDF measure, and generate semantic
relationships based on document-level co-occurrence statistics, for example
with likelihood ratios and pointwise mutual information. This paper presents
results of an explorative, prototypical, qualitative and synthetic research,
summarizes insights from two research projects and, based on this, indicates an
outline for further research in the field of entity relationship extraction
from text.",0.08909845,0.5104757,0.20540944,C
798,"https://doi.org/10.1145/230538.230561
stimulate further research on the investigation of data, algorith-
mic, and cognitive gender biases in IR systems, as well as novel                        [8] Peter Glick and Susan T Fiske.","14, 3 (1996), 330‚Äì347.",1999.,2022-01-19 17:50:18+00:00,Grep-BiasIR: A Dataset for Investigating Gender Representation-Bias in Information Retrieval Results,cs.IR,['cs.IR'],"[arxiv.Result.Author('Klara Krieg'), arxiv.Result.Author('Emilia Parada-Cabaleiro'), arxiv.Result.Author('Gertraud Medicus'), arxiv.Result.Author('Oleg Lesota'), arxiv.Result.Author('Markus Schedl'), arxiv.Result.Author('Navid Rekabsaz')]","The provided contents by information retrieval (IR) systems can reflect the
existing societal biases and stereotypes. Such biases in retrieval results can
lead to further establishing and strengthening stereotypes in society and also
in the systems. To facilitate the studies of gender bias in the retrieval
results of IR systems, we introduce Gender Representation-Bias for Information
Retrieval (Grep-BiasIR), a novel thoroughly-audited dataset consisting of 118
bias-sensitive neutral search queries. The set of queries covers a wide range
of gender-related topics, for which a biased representation of genders in the
search result can be considered as socially problematic. Each query is
accompanied with one relevant and one non-relevant documents, where the
document is also provided in three variations of female, male, and neutral. The
dataset is available at https://github.com/KlaraKrieg/GrepBiasIR.",0.21978228,0.0053681573,-0.36359388,B
862,We compare their per-       worth further research.,"However, this is still a challenging problem and
relational fact scoring function (w/o Fùëüùëíùëô ).",formance on KG completion to the full TKGC.,2022-01-21 07:59:16+00:00,Trustworthy Knowledge Graph Completion Based on Multi-sourced Noisy Data,cs.IR,"['cs.IR', 'cs.AI', 'cs.DB']","[arxiv.Result.Author('Jiacheng Huang'), arxiv.Result.Author('Yao Zhao'), arxiv.Result.Author('Wei Hu'), arxiv.Result.Author('Zhen Ning'), arxiv.Result.Author('Qijin Chen'), arxiv.Result.Author('Xiaoxia Qiu'), arxiv.Result.Author('Chengfu Huo'), arxiv.Result.Author('Weijun Ren')]","Knowledge graphs (KGs) have become a valuable asset for many AI applications.
Although some KGs contain plenty of facts, they are widely acknowledged as
incomplete. To address this issue, many KG completion methods are proposed.
Among them, open KG completion methods leverage the Web to find missing facts.
However, noisy data collected from diverse sources may damage the completion
accuracy. In this paper, we propose a new trustworthy method that exploits
facts for a KG based on multi-sourced noisy data and existing facts in the KG.
Specifically, we introduce a graph neural network with a holistic scoring
function to judge the plausibility of facts with various value types. We design
value alignment networks to resolve the heterogeneity between values and map
them to entities even outside the KG. Furthermore, we present a truth inference
model that incorporates data source qualities into the fact scoring function,
and design a semi-supervised learning way to infer the truths from
heterogeneous values. We conduct extensive experiments to compare our method
with the state-of-the-arts. The results show that our method achieves superior
accuracy not only in completing missing facts but also in discovering new
facts.",-0.092540085,0.10384846,0.09001117,A
883,"However, further research should be done to understand
the impact of diÔ¨Äerent presentation techniques, chat-based search, and
distributed results presentation (e.g., results on both left and right
panel).","Furthermore, their design supported users interacting with
the search engine with the agent initiating dialogues to support the
search process.",Figure 3.4: A visual example of the Conversational Agent by Kaushik et al.,2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.25527644,0.23241308,-0.11724535,C
884,"Similarly, the ability for systems
to model uncertainty in user needs requires further study to eÔ¨Äec-
tively and eÔ¨Éciently clarify needs.","We believe that systems should more accurately
identify opportune moments to initiate the conversation, introduce new
topics, or support disambiguation.","We argue that supporting all these
interactions will enhance the user experience, enable improved informa-
tion seeking interactions, and thus positively impact this collaborative

                                                                 Draft Version 1.0
124  Conclusions and Open Research Directions

process.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.2393222,0.19789863,-0.004846031,C
885,"However, supporting users in long-term information needs, be
it multi-session tasks or the ability for a conversation to be continued
and repeated at a much later date, need further research.","In general, when investigating CIS it is often assumed that
the user is interacting with the system only at the time of information
need.","This implies
that the history and memory of conversations may be stored and used
in future user-system interactions.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.21502054,0.24991477,-0.19831179,C
886,"Thus, further research needs to be
done on how users want this memory to work, including privacy and
transparency of what is stored and how the system retrieves and
identiÔ¨Åes relevant past interactions responsibly.","This implies
that the history and memory of conversations may be stored and used
in future user-system interactions.","8.1.2 Result Presentation

Presenting results which the user can incorporate into their personal
‚Äúknowledge space,‚Äù and how the user interacts with them, can be seen as
part of a broader challenge of information transfer.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.19741493,0.1605973,-0.04430125,C
887,"Furthermore, with the increased interest in multi-
modal and cross-device CIS, further research on when, how, and
on which device users want to receive information is crucial.","This includes what and how the information needs
to be presented.","Questions
such as how CIS systems can/should use sensor data to optimize
result presentation is an open problems (e.g., if a user is close to a
screen, instead of using a smart speaker, should the information be
presented visually?).",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.17516467,0.16589089,-0.31321344,C
888,"As part of results presentation, further research
on interactions between multiple devices will be pivotal.","Questions
such as how CIS systems can/should use sensor data to optimize
result presentation is an open problems (e.g., if a user is close to a
screen, instead of using a smart speaker, should the information be
presented visually?).","Thus, research
on how to include more user context to predict how the user is going to
interact with the available devices is warranted.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.27177852,0.1308183,-0.28081375,C
889,"For example, further research is needed to investigate
a more robust deÔ¨Ånition of success in CIS across diÔ¨Äerent user
populations, contexts, and modalities.","Even though interactivity has always
been a major part of information seeking, interactivity becomes even
more critical with the paradigm shift from the basic query-response
approach to CIS.","Thus highlighting the diÔ¨Éculty
of deÔ¨Åning success since it is changeable depending on the context
or modality.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.35024086,0.24302182,-0.22692627,C
890,"As such, further research on personalized evaluation
of CIS is needed.","Furthermore, that success may be incredibly personal,
and metrics are only helpful when measuring what is desirable for a
particular user.","Another option of measuring interaction success includes keeping
track of how well a user has understood the system and vice versa.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.35238916,0.027166948,-0.22662327,C
891,"Tools for dataset creation and evaluation may also beneÔ¨Åt from
further research eÔ¨Äort.","We observe that the ongoing
trend in simulating users could be helpful here.","For instance, many researchers build their own
wizard-of-oz frameworks with limited reuse capabilities.",2022-01-21 18:09:23+00:00,Conversational Information Seeking,cs.IR,"['cs.IR', 'cs.CL', 'cs.HC']","[arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Jeff Dalton'), arxiv.Result.Author('Filip Radlinski')]","Conversational information seeking (CIS) is concerned with a sequence of
interactions between one or more users and an information system. Interactions
in CIS are primarily based on natural language dialogue, while they may include
other types of interactions, such as click, touch, and body gestures. This
monograph provides a thorough overview of CIS definitions, applications,
interactions, interfaces, design, implementation, and evaluation. This
monograph views CIS applications as including conversational search,
conversational question answering, and conversational recommendation. Our aim
is to provide an overview of past research related to CIS, introduce the
current state-of-the-art in CIS, highlight the challenges still being faced in
the community. and suggest future directions.",0.15264776,0.043522984,-0.0434861,B
1343,"Creation of knowledge bases through manual
annotation is, thus, of utmost importance both for the actual task of question-answering and
for further research in the field, including automated knowledge base construction since these
may act as ground-truth benchmark datasets for evaluation of future automated tools.","Another prevalent issue is the lack of datasets for training and evaluation of tasks such as
question-answering or creation of knowledge bases.","3We keep a timeout of 60 seconds, within which if the analysis is not found, we report the analysis as missing,
i.e., 0 solutions for that line.",2022-02-01 04:33:13+00:00,Semantic Annotation and Querying Framework based on Semi-structured Ayurvedic Text,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Author('Hrishikesh Terdalkar'), arxiv.Result.Author('Arnab Bhattacharya'), arxiv.Result.Author('Madhulika Dubey'), arxiv.Result.Author('Ramamurthy S'), arxiv.Result.Author('Bhavna Naneria Singh')]","Knowledge bases (KB) are an important resource in a number of natural
language processing (NLP) and information retrieval (IR) tasks, such as
semantic search, automated question-answering etc. They are also useful for
researchers trying to gain information from a text. Unfortunately, however, the
state-of-the-art in Sanskrit NLP does not yet allow automated construction of
knowledge bases due to unavailability or lack of sufficient accuracy of tools
and methods. Thus, in this work, we describe our efforts on manual annotation
of Sanskrit text for the purpose of knowledge graph (KG) creation. We choose
the chapter Dhanyavarga from Bhavaprakashanighantu of the Ayurvedic text
Bhavaprakasha for annotation. The constructed knowledge graph contains 410
entities and 764 relationships. Since Bhavaprakashanighantu is a technical
glossary text that describes various properties of different substances, we
develop an elaborate ontology to capture the semantics of the entity and
relationship types present in the text. To query the knowledge graph, we design
31 query templates that cover most of the common question patterns. For both
manual annotation and querying, we customize the Sangrahaka framework
previously developed by us. The entire system including the dataset is
available from https://sanskrit.iitk.ac.in/ayurveda/ . We hope that the
knowledge graph that we have created through manual annotation and subsequent
curation will help in development and testing of NLP tools in future as well as
studying of the Bhavaprakasanighantu text.",-0.008244826,0.43052495,0.034708846,C
1344,"We also hope that the dataset created in the process will prove useful for further research
efforts in the area of NLP in Sanskrit.","We
also plan to explore more classical texts such as RƒÅmƒÅya·πáa and MahƒÅbhƒÅrata for annotating
other kinds of relationships.","We make the ontology and the dataset available at
https://sanskrit.iitk.ac.in/ayurveda/dataset/.",2022-02-01 04:33:13+00:00,Semantic Annotation and Querying Framework based on Semi-structured Ayurvedic Text,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Author('Hrishikesh Terdalkar'), arxiv.Result.Author('Arnab Bhattacharya'), arxiv.Result.Author('Madhulika Dubey'), arxiv.Result.Author('Ramamurthy S'), arxiv.Result.Author('Bhavna Naneria Singh')]","Knowledge bases (KB) are an important resource in a number of natural
language processing (NLP) and information retrieval (IR) tasks, such as
semantic search, automated question-answering etc. They are also useful for
researchers trying to gain information from a text. Unfortunately, however, the
state-of-the-art in Sanskrit NLP does not yet allow automated construction of
knowledge bases due to unavailability or lack of sufficient accuracy of tools
and methods. Thus, in this work, we describe our efforts on manual annotation
of Sanskrit text for the purpose of knowledge graph (KG) creation. We choose
the chapter Dhanyavarga from Bhavaprakashanighantu of the Ayurvedic text
Bhavaprakasha for annotation. The constructed knowledge graph contains 410
entities and 764 relationships. Since Bhavaprakashanighantu is a technical
glossary text that describes various properties of different substances, we
develop an elaborate ontology to capture the semantics of the entity and
relationship types present in the text. To query the knowledge graph, we design
31 query templates that cover most of the common question patterns. For both
manual annotation and querying, we customize the Sangrahaka framework
previously developed by us. The entire system including the dataset is
available from https://sanskrit.iitk.ac.in/ayurveda/ . We hope that the
knowledge graph that we have created through manual annotation and subsequent
curation will help in development and testing of NLP tools in future as well as
studying of the Bhavaprakasanighantu text.",0.04855734,0.39602762,0.06316879,C
1837,"To further study the model performance, we
purchase labels for evaluations.","With a predeÔ¨Åned p-value for        the default train (INS-T) and test (INS-E) split provided by
the statistic signiÔ¨Åcance, we can create the high quality co-       Instacart dataset.","For clarity, we denote the         collect a proprietary dataset (WMT) with a larger scale from
item pairs which pass the Chi-squared test and O1 > E1              Walmart e-Commerce platform (www.walmart.com) following
as the positively-dependent item pairs and the item pairs           the same format of Instacart, where the sequence order of
which pass the Chi-squared test and O1 <= E1 as the                 transactions are kept and the order of purchases in the same
negatively-dependent item pairs in the rest of our paper.",2022-02-11 05:33:19+00:00,NEAT: A Label Noise-resistant Complementary Item Recommender System with Trustworthy Evaluation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Luyi Ma'), arxiv.Result.Author('Jianpeng Xu'), arxiv.Result.Author('Jason H. D. Cho'), arxiv.Result.Author('Evren Korpeoglu'), arxiv.Result.Author('Sushant Kumar'), arxiv.Result.Author('Kannan Achan')]","The complementary item recommender system (CIRS) recommends the complementary
items for a given query item. Existing CIRS models consider the item
co-purchase signal as a proxy of the complementary relationship due to the lack
of human-curated labels from the huge transaction records. These methods
represent items in a complementary embedding space and model the complementary
relationship as a point estimation of the similarity between items vectors.
However, co-purchased items are not necessarily complementary to each other.
For example, customers may frequently purchase bananas and bottled water within
the same transaction, but these two items are not complementary. Hence, using
co-purchase signals directly as labels will aggravate the model performance. On
the other hand, the model evaluation will not be trustworthy if the labels for
evaluation are not reflecting the true complementary relatedness. To address
the above challenges from noisy labeling of the copurchase data, we model the
co-purchases of two items as a Gaussian distribution, where the mean denotes
the co-purchases from the complementary relatedness, and covariance denotes the
co-purchases from the noise. To do so, we represent each item as a Gaussian
embedding and parameterize the Gaussian distribution of co-purchases by the
means and covariances from item Gaussian embedding. To reduce the impact of the
noisy labels during evaluation, we propose an independence test-based method to
generate a trustworthy label set with certain confidence. Our extensive
experiments on both the publicly available dataset and the large-scale
real-world dataset justify the effectiveness of our proposed model in
complementary item recommendations compared with the state-of-the-art models.",-0.10427348,-0.18518686,-0.101634875,A
1897,"I further study the diÔ¨Äerences between two consecutive values in (raw) recruit-
ment time-series, where the original time-series is detrended by subtracting the
mean trend.","Figure 2 shows that, after rescaled with
their means and standard deviations of log-transformed data, the recruitment time-
series collapse onto a standard log-normal distribution.","Based on the Kolmogorov-Smirnov test with data aggregated across
72 stocks, while the null hypothesis that the (rescaled) log-transformed data are
normally distributed cannot be rejected with a p-value of 9.54 √ó 10‚àí2, the null
hypothesis that the successive diÔ¨Äerences of the (rescaled) recruitment series are
normally distributed should be rejected with a p-value of 1.14 √ó 10‚àí12.",2022-02-13 04:18:18+00:00,Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Zihan Lin'), arxiv.Result.Author('Changxin Tian'), arxiv.Result.Author('Yupeng Hou'), arxiv.Result.Author('Wayne Xin Zhao')]","Recently, graph collaborative filtering methods have been proposed as an
effective recommendation approach, which can capture users' preference over
items by modeling the user-item interaction graphs. In order to reduce the
influence of data sparsity, contrastive learning is adopted in graph
collaborative filtering for enhancing the performance. However, these methods
typically construct the contrastive pairs by random sampling, which neglect the
neighboring relations among users (or items) and fail to fully exploit the
potential of contrastive learning for recommendation. To tackle the above
issue, we propose a novel contrastive learning approach, named
Neighborhood-enriched Contrastive Learning, named NCL, which explicitly
incorporates the potential neighbors into contrastive pairs. Specifically, we
introduce the neighbors of a user (or an item) from graph structure and
semantic space respectively. For the structural neighbors on the interaction
graph, we develop a novel structure-contrastive objective that regards users
(or items) and their structural neighbors as positive contrastive pairs. In
implementation, the representations of users (or items) and neighbors
correspond to the outputs of different GNN layers. Furthermore, to excavate the
potential neighbor relation in semantic space, we assume that users with
similar representations are within the semantic neighborhood, and incorporate
these semantic neighbors into the prototype-contrastive objective. The proposed
NCL can be optimized with EM algorithm and generalized to apply to graph
collaborative filtering methods. Extensive experiments on five public datasets
demonstrate the effectiveness of the proposed NCL, notably with 26% and 17%
performance gain over a competitive graph collaborative filtering base model on
the Yelp and Amazon-book datasets respectively. Our code is available at:
https://github.com/RUCAIBox/NCL.",-0.15454341,-0.05722857,-0.4147203,A
1906,"An important outcome arising from this
study is that further research on QPP should place greater emphasis on a clear
speciÔ¨Åcation of the experimental setup to enable better reproducibility.","As part of our analysis, we have
found that certain factors, such as variations in the IR eÔ¨Äectiveness measures,
has a greater impact in terms of QPP outcomes than other factors, such as
variations in the choice of IR models.","In future
we plan to expand our evaluations beyond the TREC Robust dataset.",2022-02-13 13:16:30+00:00,An Analysis of Variations in the Effectiveness of Query Performance Prediction,cs.IR,['cs.IR'],"[arxiv.Result.Author('Debasis Ganguly'), arxiv.Result.Author('Suchana Datta'), arxiv.Result.Author('Mandar Mitra'), arxiv.Result.Author('Derek Greene')]","A query performance predictor estimates the retrieval effectiveness of an IR
system for a given query. An important characteristic of QPP evaluation is
that, since the ground truth retrieval effectiveness for QPP evaluation can be
measured with different metrics, the ground truth itself is not absolute, which
is in contrast to other retrieval tasks, such as that of ad-hoc retrieval.
Motivated by this argument, the objective of this paper is to investigate how
such variances in the ground truth for QPP evaluation can affect the outcomes
of QPP experiments. We consider this not only in terms of the absolute values
of the evaluation metrics being reported (e.g. Pearson's $r$, Kendall's
$\tau$), but also with respect to the changes in the ranks of different QPP
systems when ordered by the QPP metric scores. Our experiments reveal that the
observed QPP outcomes can vary considerably, both in terms of the absolute
evaluation metric values and also in terms of the relative system ranks.
Through our analysis, we report the optimal combinations of QPP evaluation
metric and experimental settings that are likely to lead to smaller variations
in the observed results.",-0.21700838,-0.11422406,-0.28008214,A
2001,"Then, we further study the effect of our proposed two training strategies.","0.05   0.22    2.69    0.08    13.76       TripAdvisor  14.83**  15.32**  2.10    1.59    1.68
                                                                          ACMLM     0.05   0.02    6.07    0.00    15.20    0.02 4.86       14.57    15.58    2.42    2.32    2.19
                                                                       PEPLER-D     0.06   0.05    4.74    0.02    15.13    0.87** 18.07**  16.42    16.38    2.24    2.23    2.06
                                                                                    0.07   0.09    3.62    0.05    15.49    0.80 19.01      16.15    16.00    2.48    2.21    2.16
                                                                               NRT  0.07*  0.21**  2.71**  0.24**           0.96 18.74      15.67    16.24
                                                                           Att2Seq                                          1.00 18.30
                                                                             PETER                                          1.09 19.48
                                                                          PEPLER
Personalized Prompt Learning for Explainable Recommendation  111:17

5 RESULTS AND ANALYSIS

In this section, we first quantitatively compare the performance of different explanation methods
with automatic metrics.","At last, we qualitatively examine two explanation samples as generated by all the methods.",2022-02-15 12:53:52+00:00,Personalized Prompt Learning for Explainable Recommendation,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Author('Lei Li'), arxiv.Result.Author('Yongfeng Zhang'), arxiv.Result.Author('Li Chen')]","Providing user-understandable explanations to justify recommendations could
help users better understand the recommended items, increase the system's ease
of use, and gain users' trust. A typical approach to realize it is natural
language generation. However, previous works mostly adopt recurrent neural
networks to meet the ends, leaving the potentially more effective pre-trained
Transformer models under-explored. In fact, user and item IDs, as important
identifiers in recommender systems, are inherently in different semantic space
as words that pre-trained models were already trained on. Thus, how to
effectively fuse IDs into such models becomes a critical issue. Inspired by
recent advancement in prompt learning, we come up with two solutions: find
alternative words to represent IDs (called discrete prompt learning), and
directly input ID vectors to a pre-trained model (termed continuous prompt
learning). In the latter case, ID vectors are randomly initialized but the
model is trained in advance on large corpora, so they are actually in different
learning stages. To bridge the gap, we further propose two training strategies:
sequential tuning and recommendation as regularization. Extensive experiments
show that our continuous prompt learning approach equipped with the training
strategies consistently outperforms strong baselines on three datasets of
explainable recommendation.",-0.073814645,-0.10319124,-0.007660647,A
2305,"We further study the effect of estimating the missing                  1,000 items.","It also contains a
‚Ä¢ With this unique dataset, we design experiments to illustrate how                  set of missing-complete-at-random (MCAR) data by asking 5,400
  data density and exposure bias affect the evaluation of recom-                     users to give ratings on 10 items that are randomly selected from
  mendations.","values, i.e., matrix completion, on the evaluation results.",2022-02-22 12:08:14+00:00,KuaiRec: A Fully-observed Dataset and Insights for Evaluating Recommender Systems,cs.IR,"['cs.IR', 'cs.HC']","[arxiv.Result.Author('Chongming Gao'), arxiv.Result.Author('Shijun Li'), arxiv.Result.Author('Wenqiang Lei'), arxiv.Result.Author('Jiawei Chen'), arxiv.Result.Author('Biao Li'), arxiv.Result.Author('Peng Jiang'), arxiv.Result.Author('Xiangnan He'), arxiv.Result.Author('Jiaxin Mao'), arxiv.Result.Author('Tat-Seng Chua')]","The progress of recommender systems is hampered mainly by evaluation as it
requires real-time interactions between humans and systems, which is too
laborious and expensive. This issue is usually approached by utilizing the
interaction history to conduct offline evaluation. However, existing datasets
of user-item interactions are partially observed, leaving it unclear how and to
what extent the missing interactions will influence the evaluation. To answer
this question, we collect a fully-observed dataset from Kuaishou's online
environment, where almost all 1,411 users have been exposed to all 3,327 items.
To the best of our knowledge, this is the first real-world fully-observed data
with millions of user-item interactions.
  With this unique dataset, we conduct a preliminary analysis of how the two
factors - data density and exposure bias - affect the evaluation results of
multi-round conversational recommendation. Our main discoveries are that the
performance ranking of different methods varies with the two factors, and this
effect can only be alleviated in certain cases by estimating missing
interactions for user simulation. This demonstrates the necessity of the
fully-observed dataset. We release the dataset and the pipeline implementation
for evaluation at https://kuairec.com",0.14585127,-0.2735884,-0.06546748,B
2500,"our experiments, we tried to add an independent loss between the
We leave the further study as future work.","During
which many sequential encoders and loss functions can be utilized.","two interests as, and AUC drops by 0.01, which verifies our point.",2022-02-26 08:00:53+00:00,Disentangling Long and Short-Term Interests for Recommendation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Yu Zheng'), arxiv.Result.Author('Chen Gao'), arxiv.Result.Author('Jianxin Chang'), arxiv.Result.Author('Yanan Niu'), arxiv.Result.Author('Yang Song'), arxiv.Result.Author('Depeng Jin'), arxiv.Result.Author('Yong Li')]","Modeling user's long-term and short-term interests is crucial for accurate
recommendation. However, since there is no manually annotated label for user
interests, existing approaches always follow the paradigm of entangling these
two aspects, which may lead to inferior recommendation accuracy and
interpretability. In this paper, to address it, we propose a Contrastive
learning framework to disentangle Long and Short-term interests for
Recommendation (CLSR) with self-supervision. Specifically, we first propose two
separate encoders to independently capture user interests of different time
scales. We then extract long-term and short-term interests proxies from the
interaction sequences, which serve as pseudo labels for user interests. Then
pairwise contrastive tasks are designed to supervise the similarity between
interest representations and their corresponding interest proxies. Finally,
since the importance of long-term and short-term interests is dynamically
changing, we propose to adaptively aggregate them through an attention-based
network for prediction. We conduct experiments on two large-scale real-world
datasets for e-commerce and short-video recommendation. Empirical results show
that our CLSR consistently outperforms all state-of-the-art models with
significant improvements: GAUC is improved by over 0.01, and NDCG is improved
by over 4%. Further counterfactual evaluations demonstrate that stronger
disentanglement of long and short-term interests is successfully achieved by
CLSR. The code and data are available at
https://github.com/tsinghua-fib-lab/CLSR.",-0.40102988,-0.06517342,-0.08469042,A
2518,"[3] further researched user-centered evaluation of popularity
bias.",Abdollahpouri et al.,"They proposed a user-centered evaluation method that can eÔ¨Äectively tackle
popularity bias for diÔ¨Äerent user groups while accounting for users‚Äô tolerance
towards popularity bias using Jensen divergence.",2022-02-27 08:02:19+00:00,The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Hossein A. Rahmani'), arxiv.Result.Author('Yashar Deldjoo'), arxiv.Result.Author('Ali Tourani'), arxiv.Result.Author('Mohammadmehdi Naghiaei')]","Point-of-Interest (POI) recommender systems provide personalized
recommendations to users and help businesses attract potential customers.
Despite their success, recent studies suggest that highly data-driven
recommendations could be impacted by data biases, resulting in unfair outcomes
for different stakeholders, mainly consumers (users) and providers (items).
Most existing fairness-related research works in recommender systems treat user
fairness and item fairness issues individually, disregarding that RS work in a
two-sided marketplace. This paper studies the interplay between (i) the
unfairness of active users, (ii) the unfairness of popular items, and (iii) the
accuracy (personalization) of recommendation as three angles of our study
triangle. We group users into advantaged and disadvantaged levels to measure
user fairness based on their activity level. For item fairness, we divide items
into short-head, mid-tail, and long-tail groups and study the exposure of these
item groups into the top-k recommendation list of users. Experimental
validation of eight different recommendation models commonly used for POI
recommendation (e.g., contextual, CF) on two publicly available POI
recommendation datasets, Gowalla and Yelp, indicate that most well-performing
models suffer seriously from the unfairness of popularity bias (provider
unfairness). Furthermore, our study shows that most recommendation models
cannot satisfy both consumer and producer fairness, indicating a trade-off
between these variables possibly due to natural biases in data. We choose the
POI recommendation as our test scenario; however, the insights should be
trivially extendable on other domains.",0.41908234,-0.33609638,-0.075157225,B
2519,"[3] further researched user-centered evaluation of popularity
bias.",Abdollahpouri et al.,"They proposed a user-centered evaluation method that can eÔ¨Äectively tackle
popularity bias for diÔ¨Äerent user groups while accounting for users‚Äô tolerance
towards popularity bias using Jensen divergence.",2022-02-27 08:02:19+00:00,The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Hossein A. Rahmani'), arxiv.Result.Author('Yashar Deldjoo'), arxiv.Result.Author('Ali Tourani'), arxiv.Result.Author('Mohammadmehdi Naghiaei')]","Point-of-Interest (POI) recommender systems provide personalized
recommendations to users and help businesses attract potential customers.
Despite their success, recent studies suggest that highly data-driven
recommendations could be impacted by data biases, resulting in unfair outcomes
for different stakeholders, mainly consumers (users) and providers (items).
Most existing fairness-related research works in recommender systems treat user
fairness and item fairness issues individually, disregarding that RS work in a
two-sided marketplace. This paper studies the interplay between (i) the
unfairness of active users, (ii) the unfairness of popular items, and (iii) the
accuracy (personalization) of recommendation as three angles of our study
triangle. We group users into advantaged and disadvantaged levels to measure
user fairness based on their activity level. For item fairness, we divide items
into short-head, mid-tail, and long-tail groups and study the exposure of these
item groups into the top-k recommendation list of users. Experimental
validation of eight different recommendation models commonly used for POI
recommendation (e.g., contextual, CF) on two publicly available POI
recommendation datasets, Gowalla and Yelp, indicate that most well-performing
models suffer seriously from the unfairness of popularity bias (provider
unfairness). Furthermore, our study shows that most recommendation models
cannot satisfy both consumer and producer fairness, indicating a trade-off
between these variables possibly due to natural biases in data. We choose the
POI recommendation as our test scenario; however, the insights should be
trivially extendable on other domains.",0.41908234,-0.33609638,-0.075157225,B
2530,"Thus, further research
could be worthwhile into implementing a recommendation algorithm that can
Ô¨Ånd the optimal tradeoÔ¨Ä between personalization and the unfairness of popu-
larity biases to enhance the system‚Äôs overall eÔ¨Äectiveness.","Additionally, our results suggest
that an underlying tradeoÔ¨Ä exists between personalization and fairness of popu-
larity bias in Diverse and Bestseller-focused groups, that is, algorithms with high
personalization abilities tend to experience fairness issues.","Finally, it would be
interesting to investigate popularity bias on other domains and algorithms such
as session-based [23], content-based [17], or reinforcement learning-based recom-
mendation [4] methods, as well as incorporating further evaluation metrics such
as novelty and coverage.",2022-02-27 20:21:46+00:00,The Unfairness of Popularity Bias in Book Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Mohammadmehdi Naghiaei'), arxiv.Result.Author('Hossein A. Rahmani'), arxiv.Result.Author('Mahdi Dehghan')]","Recent studies have shown that recommendation systems commonly suffer from
popularity bias. Popularity bias refers to the problem that popular items
(i.e., frequently rated items) are recommended frequently while less popular
items are recommended rarely or not at all. Researchers adopted two approaches
to examining popularity bias: (i) from the users' perspective, by analyzing how
far a recommendation system deviates from user's expectations in receiving
popular items, and (ii) by analyzing the amount of exposure that long-tail
items receive, measured by overall catalog coverage and novelty. In this paper,
we examine the first point of view in the book domain, although the findings
may be applied to other domains as well. To this end, we analyze the well-known
Book-Crossing dataset and define three user groups based on their tendency
towards popular items (i.e., Niche, Diverse, Bestseller-focused). Further, we
evaluate the performance of nine state-of-the-art recommendation algorithms and
two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG,
Precision, Recall) and popularity bias perspectives. Our results indicate that
most state-of-the-art recommendation algorithms suffer from popularity bias in
the book domain, and fail to meet users' expectations with Niche and Diverse
tastes despite having a larger profile size. Conversely, Bestseller-focused
users are more likely to receive high-quality recommendations, both in terms of
fairness and personalization. Furthermore, our study shows a tradeoff between
personalization and unfairness of popularity bias in recommendation algorithms
for users belonging to the Diverse and Bestseller groups, that is, algorithms
with high capability of personalization suffer from the unfairness of
popularity bias.",0.32118523,-0.34408593,0.18015435,B
2622,"Additionally, as mentioned earlier, we plan to further study the diÔ¨Äerences
we found with respect to algorithmic performance for the diÔ¨Äerent user groups
and multimedia domains.","We believe that our Ô¨Åndings are a Ô¨Årst step
to inform the research on popularity bias mitigation techniques (see Section 2)
to choose the right mitigation strategy for a given setting.","Here, we also want to study popularity bias in top-n
settings using ranking-aware metrics such as nDCG (e.g., as used in [18]).",2022-03-01 11:43:53+00:00,Popularity Bias in Collaborative Filtering-Based Multimedia Recommender Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Dominik Kowald'), arxiv.Result.Author('Emanuel Lacic')]","Multimedia recommender systems suggest media items, e.g., songs, (digital)
books and movies, to users by utilizing concepts of traditional recommender
systems such as collaborative filtering. In this paper, we investigate a
potential issue of such collaborative-filtering based multimedia recommender
systems, namely popularity bias that leads to the underrepresentation of
unpopular items in the recommendation lists. Therefore, we study four
multimedia datasets, i.e., LastFm, MovieLens, BookCrossing and MyAnimeList,
that we each split into three user groups differing in their inclination to
popularity, i.e., LowPop, MedPop and HighPop. Using these user groups, we
evaluate four collaborative filtering-based algorithms with respect to
popularity bias on the item and the user level. Our findings are three-fold:
firstly, we show that users with little interest into popular items tend to
have large user profiles and thus, are important data sources for multimedia
recommender systems. Secondly, we find that popular items are recommended more
frequently than unpopular ones. Thirdly, we find that users with little
interest into popular items receive significantly worse recommendations than
users with medium or high interest into popularity.",0.16733003,-0.30776852,0.060552098,B
3082,"This further demonstrates the importance of mod-
   In order to further study the contributions of different                eling users‚Äô modality preferences.","underperforms DMRLv and DMRLt, which use our attention
   2) User Preferences (Ratings)                                           method.","The further improvement
modalities to a user‚Äôs preference on the factors of the target             of DMRL over DMRLw/o u validate the effectiveness of

   10We selected two users (0 and 197) who purchased the same item (1294)
as an example.",2022-03-10 15:03:13+00:00,Disentangled Multimodal Representation Learning for Recommendation,cs.IR,"['cs.IR', 'cs.MM', 'H.3.3; H.5.1']","[arxiv.Result.Author('Fan Liu'), arxiv.Result.Author('Zhiyong Cheng'), arxiv.Result.Author('Huilin Chen'), arxiv.Result.Author('Anan Liu'), arxiv.Result.Author('Liqiang Nie'), arxiv.Result.Author('Mohan Kankanhalli')]","Many multimodal recommender systems have been proposed to exploit the rich
side information associated with users or items (e.g., user reviews and item
images) for learning better user and item representations to enhance the
recommendation performance. Studies in psychology show that users have
individual differences in the utilization of different modalities for
organizing information. Therefore, for a certain factor of an item (such as
appearance or quality), the features of different modalities are of different
importance to a user. However, existing methods ignore the fact that different
modalities contribute differently to a user's preferences on various factors of
an item. In light of this, in this paper, we propose a novel Disentangled
Multimodal Representation Learning (DMRL) recommendation model, which can
capture users' attention to different modalities on each factor in user
preference modeling. In particular, we adopt a disentangled representation
technique to ensure the features of different factors in each modality are
independent to each other. A multimodal attention mechanism is then designed to
capture user's modality preference for each factor. Based on the estimated
weights obtained by the attention mechanism, we make recommendation by
combining the preference scores of a user's preferences to each factor of the
target item over different modalities. Extensive evaluations on five real-world
datasets demonstrate the superiority of our method compared with existing
methods.",0.25750136,-0.35872883,-0.06251712,B
3083,"2) User Preferences (Ratings)
   In order to further study the contributions of different                ‚Ä¢ DMRLw/o a: This variant removes the designed multimodal
modalities to a user‚Äôs preference on the factors of the target               attention mechanism.","‚Ä¢ DMRLv: It is a variant of our method which only uses item
                                                                             IDs and visual features.","It exploits the multimodal features of
item, we compute the ratings of the two different users given                different factors indiscriminately.",2022-03-10 15:03:13+00:00,Disentangled Multimodal Representation Learning for Recommendation,cs.IR,"['cs.IR', 'cs.MM', 'H.3.3; H.5.1']","[arxiv.Result.Author('Fan Liu'), arxiv.Result.Author('Huilin Chen'), arxiv.Result.Author('Zhiyong Cheng'), arxiv.Result.Author('Anan Liu'), arxiv.Result.Author('Liqiang Nie'), arxiv.Result.Author('Mohan Kankanhalli')]","Many multimodal recommender systems have been proposed to exploit the rich
side information associated with users or items (e.g., user reviews and item
images) for learning better user and item representations to improve the
recommendation performance. Studies from psychology show that users have
individual differences in the utilization of various modalities for organizing
information. Therefore, for a certain factor of an item (such as appearance or
quality), the features of different modalities are of varying importance to a
user. However, existing methods ignore the fact that different modalities
contribute differently towards a user's preference on various factors of an
item. In light of this, in this paper, we propose a novel Disentangled
Multimodal Representation Learning (DMRL) recommendation model, which can
capture users' attention to different modalities on each factor in user
preference modeling. In particular, we employ a disentangled representation
technique to ensure the features of different factors in each modality are
independent of each other. A multimodal attention mechanism is then designed to
capture users' modality preference for each factor. Based on the estimated
weights obtained by the attention mechanism, we make recommendations by
combining the preference scores of a user's preferences to each factor of the
target item over different modalities. Extensive evaluation on five real-world
datasets demonstrate the superiority of our method compared with existing
methods.",0.116078764,-0.2063514,0.014288906,B
3193,"In this paper, we
   Finally, we use the session representation hs(i) to predict            further study the use of graph pre-training techniques that
the next item v|(si()i)|+1.","Most recently, SR-GNN [12] adopts
          # of epochs                            5                        graph neural networks to model complex transitions between
                                                                          items and becomes the new state-of-the-art.",Using a fully-connected neural network        Ô¨Åts the session-based recommendation problem.,2022-03-12 15:44:03+00:00,G$^3$SR: Global Graph Guided Session-based Recommendation,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Zhi-Hong Deng'), arxiv.Result.Author('Chang-Dong Wang'), arxiv.Result.Author('Ling Huang'), arxiv.Result.Author('Jian-Huang Lai'), arxiv.Result.Author('Philip S. Yu')]","Session-based recommendation tries to make use of anonymous session data to
deliver high-quality recommendation under the condition that user-profiles and
the complete historical behavioral data of a target user are unavailable.
Previous works consider each session individually and try to capture user
interests within a session. Despite their encouraging results, these models can
only perceive intra-session items and cannot draw upon the massive historical
relational information. To solve this problem, we propose a novel method named
G$^3$SR (Global Graph Guided Session-based Recommendation). G$^3$SR decomposes
the session-based recommendation workflow into two steps. First, a global graph
is built upon all session data, from which the global item representations are
learned in an unsupervised manner. Then, these representations are refined on
session graphs under the graph networks, and a readout function is used to
generate session representations for each session. Extensive experiments on two
real-world benchmark datasets show remarkable and consistent improvements of
the G$^3$SR method over the state-of-the-art methods, especially for cold
items.",-0.08948511,-0.07531133,0.45764822,A
3194,"In this
fall into the trap of the over-smoothing problem [50], [51]       section, we conduct experiments to further study the effect of
where node features tend to converge to the same value.","Instead, deep graph networks may easily           argue that cold items can beneÔ¨Åt from this process.",The       the proposed method.,2022-03-12 15:44:03+00:00,G$^3$SR: Global Graph Guided Session-based Recommendation,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Zhi-Hong Deng'), arxiv.Result.Author('Chang-Dong Wang'), arxiv.Result.Author('Ling Huang'), arxiv.Result.Author('Jian-Huang Lai'), arxiv.Result.Author('Philip S. Yu')]","Session-based recommendation tries to make use of anonymous session data to
deliver high-quality recommendation under the condition that user-profiles and
the complete historical behavioral data of a target user are unavailable.
Previous works consider each session individually and try to capture user
interests within a session. Despite their encouraging results, these models can
only perceive intra-session items and cannot draw upon the massive historical
relational information. To solve this problem, we propose a novel method named
G$^3$SR (Global Graph Guided Session-based Recommendation). G$^3$SR decomposes
the session-based recommendation workflow into two steps. First, a global graph
is built upon all session data, from which the global item representations are
learned in an unsupervised manner. Then, these representations are refined on
session graphs under the graph networks, and a readout function is used to
generate session representations for each session. Extensive experiments on two
real-world benchmark datasets show remarkable and consistent improvements of
the G$^3$SR method over the state-of-the-art methods, especially for cold
items.",-0.22763002,-0.093223505,0.14611477,A
3202,"This is a promising result,
which indicates further research that can result
in beneÔ¨Åts for customers and e-commerce.","ACM, 2013,
proÔ¨Åt), which can be further used to target spe-
ciÔ¨Åc customer groups.","Going
further, the comparison of results with online
evaluation outcomes may implicate exciting Ô¨Ånd-
ings in a broader evaluation philosophy context.",2022-03-13 12:08:06+00:00,Exploring Customer Price Preference and Product Profit Role in Recommender Systems,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Michal Kompan'), arxiv.Result.Author('Peter Gaspar'), arxiv.Result.Author('Jakub Macina'), arxiv.Result.Author('Matus Cimerman'), arxiv.Result.Author('Maria Bielikova')]","Most of the research in the recommender systems domain is focused on the
optimization of the metrics based on historical data such as Mean Average
Precision (MAP) or Recall. However, there is a gap between the research and
industry since the leading Key Performance Indicators (KPIs) for businesses are
revenue and profit. In this paper, we explore the impact of manipulating the
profit awareness of a recommender system. An average e-commerce business does
not usually use a complicated recommender algorithm. We propose an adjustment
of a predicted ranking for score-based recommender systems and explore the
effect of the profit and customers' price preferences on two industry datasets
from the fashion domain. In the experiments, we show the ability to improve
both the precision and the generated recommendations' profit. Such an outcome
represents a win-win situation when e-commerce increases the profit and
customers get more valuable recommendations.",0.27914184,-0.1560555,-0.17620261,B
3382,"e-learning, collaborative search, collaborative learning, person-
                                        alised knowledge graphs                                                                         The proposed line of work aims to assist the efforts of the SW
                                                                                                                                     community in setting the standards of new applications with de-
                                        ACM Reference Format:                                                                        ploying further research in SW technologies, such as the PKGs, in no
                                        Eleni Ilkou, supervised by Prof. Dr. Wolfgang Nejdl.","PKGs in online learning environments can
                                        KEYWORDS                                                                                     benefit users by providing personalised features and connecting
                                                                                                                                     their actions on the web with KGs and Linked Data.",2022.,2022-03-16 10:04:40+00:00,Personal Knowledge Graphs: Use Cases in e-learning Platforms,cs.IR,"['cs.IR', 'cs.DB', 'cs.HC', 'H.3.3; H.5.2; H.1.2; K.3.1; K.3.2']",[arxiv.Result.Author('Eleni Ilkou')],"Personal Knowledge Graphs (PKGs) are introduced by the semantic web community
as small-sized user-centric knowledge graphs (KGs). PKGs fill the gap of
personalised representation of user data and interests on the top of big,
well-established encyclopedic KGs, such as DBpedia. Inspired by the widely
recent usage of PKGs in the medical domain to represent patient data, this PhD
proposal aims to adopt a similar technique in the educational domain in
e-learning platforms by deploying PKGs to represent users and learners. We
propose a novel PKG development that relies on ontology and interlinks to
Linked Open Data. Hence, adding the dimension of personalisation and
explainability in users' featured data while respecting privacy. This research
design is developed in two use cases: a collaborative search learning platform
and an e-learning platform. Our preliminary results show that e-learning
platforms can get benefited from our approach by providing personalised
recommendations and more user and group-specific data.",0.1679925,0.23240511,0.18675277,C
3627,"We hope the framework, resources, and analysis we present encourage further research towards building privacy-
preserving retrieval systems.5

2 Background & Related Work

Retrieval-Based Systems Open-domain applications in NLP, such as open-domain QA [Voorhees, 1999, Chen et al.,
2017], personal assistants [Dinan et al., 2019], and language modeling [Borgeaud et al., 2021] need to support inputs
across a broad range of topics.","‚Ä¢ We demonstrate and quantify the privacy-performance tradeoff faced by existing multi-hop systems in PAIR
           and investigate challenges in mitigating the tradeoff.","Implicit-memory approaches for open-domain tasks focus on memorizing knowledge
within model parameters, for example by taking a pretrained language model such as T5 or BART and Ô¨Åne-tuning it on
question-answer training pairs [Roberts et al., 2020].",2022-03-14 13:08:51+00:00,Reasoning over Public and Private Data in Retrieval-Based Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Simran Arora'), arxiv.Result.Author('Patrick Lewis'), arxiv.Result.Author('Angela Fan'), arxiv.Result.Author('Jacob Kahn'), arxiv.Result.Author('Christopher R√©')]","Users and organizations are generating ever-increasing amounts of private
data from a wide range of sources. Incorporating private data is important to
personalize open-domain applications such as question-answering, fact-checking,
and personal assistants. State-of-the-art systems for these tasks explicitly
retrieve relevant information to a user question from a background corpus
before producing an answer. While today's retrieval systems assume the corpus
is fully accessible, users are often unable or unwilling to expose their
private data to entities hosting public data. We first define the
PUBLIC-PRIVATE AUTOREGRESSIVE INFORMATION RETRIEVAL (PAIR) privacy framework
for the novel retrieval setting over multiple privacy scopes. We then argue
that an adequate benchmark is missing to study PAIR since existing textual
benchmarks require retrieving from a single data distribution. However, public
and private data intuitively reflect different distributions, motivating us to
create ConcurrentQA, the first textual QA benchmark to require concurrent
retrieval over multiple data-distributions. Finally, we show that existing
systems face large privacy vs. performance tradeoffs when applied to our
proposed retrieval setting and investigate how to mitigate these tradeoffs.",0.0927561,0.28764686,0.23891972,C
3628,"We hope CONCURRENTQA facilitates further study of concurrent multi-domain
retrieval.","In contrast to using
a single retriever for in and OOD data, a system that routes questions to different retrievers, depending on question
attributes, is another possibility.","8 Conclusion

This work asks how to personalize retrieval-based systems in a privacy-preserving way and identiÔ¨Åes that arbitrary
autoregressive retrieval over public and private data poses a privacy concern.",2022-03-14 13:08:51+00:00,Reasoning over Public and Private Data in Retrieval-Based Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Simran Arora'), arxiv.Result.Author('Patrick Lewis'), arxiv.Result.Author('Angela Fan'), arxiv.Result.Author('Jacob Kahn'), arxiv.Result.Author('Christopher R√©')]","Users and organizations are generating ever-increasing amounts of private
data from a wide range of sources. Incorporating private data is important to
personalize open-domain applications such as question-answering, fact-checking,
and personal assistants. State-of-the-art systems for these tasks explicitly
retrieve relevant information to a user question from a background corpus
before producing an answer. While today's retrieval systems assume the corpus
is fully accessible, users are often unable or unwilling to expose their
private data to entities hosting public data. We first define the
PUBLIC-PRIVATE AUTOREGRESSIVE INFORMATION RETRIEVAL (PAIR) privacy framework
for the novel retrieval setting over multiple privacy scopes. We then argue
that an adequate benchmark is missing to study PAIR since existing textual
benchmarks require retrieving from a single data distribution. However, public
and private data intuitively reflect different distributions, motivating us to
create ConcurrentQA, the first textual QA benchmark to require concurrent
retrieval over multiple data-distributions. Finally, we show that existing
systems face large privacy vs. performance tradeoffs when applied to our
proposed retrieval setting and investigate how to mitigate these tradeoffs.",0.19039334,0.21572453,0.17170489,C
3676,"We
ing hypergraph; (ii) for each user, performing random walk                       achieve this by training the model sequentially on all groups,
to obtain its relations, which transforms the task to sequence                   and we further study the effect of training order.","Instead of training models on each group in isolation and
   SpeciÔ¨Åcally, we take the following three steps to learn col-                  aggregating them, SeqTrain module trains the model on the
laborative embedding: (i) using R to build the correspond-                       whole dataset to preserve collaborative information.","embedding; (iii) applying the sequence embedding technique,
e.g., Word2Vec [Church, 2017], to learn the collaborative em-                    Training Order
bedding.",2022-03-22 06:56:06+00:00,Making Recommender Systems Forget: Learning and Unlearning for Erasable Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Yuyuan Li'), arxiv.Result.Author('Xiaolin Zheng'), arxiv.Result.Author('Chaochao Chen'), arxiv.Result.Author('Junlin Liu')]","Privacy laws and regulations enforce data-driven systems, e.g., recommender
systems, to erase the data that concern individuals. As machine learning models
potentially memorize the training data, data erasure should also unlearn the
data lineage in models, which raises increasing interest in the problem of
Machine Unlearning (MU). However, existing MU methods cannot be directly
applied into recommendation. The basic idea of most recommender systems is
collaborative filtering, but existing MU methods ignore the collaborative
information across users and items. In this paper, we propose a general
erasable recommendation framework, namely LASER, which consists of Group module
and SeqTrain module. Firstly, Group module partitions users into balanced
groups based on their similarity of collaborative embedding learned via
hypergraph. Then SeqTrain module trains the model sequentially on all groups
with curriculum learning. Both theoretical analysis and experiments on two
real-world datasets demonstrate that LASER can not only achieve efficient
unlearning, but also outperform the state-of-the-art unlearning framework in
terms of model utility.",-0.053989112,0.13702826,0.3181615,A
4045,"We further study how our
                                                                                          approach is robust to varying levels of interaction noise that could
ùëÄ stored in the Compressed Sparse Row (CSR) format, calculating                           be seen in real-world data.",With the sparse matrix                        tion to existing standard linkage scores.,"In total, we craft this section to answer
                                                                                          the following Research Questions (RQ):
      ùëá  ùëÄ   takes  ùëÇ (ùëô  ¬∑  ùëöùëñùëõ (ùë¢,  ùëñ))  time,  where    the  selection    between  ùë¢
                                                                                               ‚Ä¢ RQ1: How does our proposed method perform compared to
ùëÄùëÄ                                                                                                competitive SOTA works?",2022-03-29 17:48:05+00:00,Revisiting Neighborhood-based Link Prediction for Collaborative Filtering,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Hao-Ming Fu'), arxiv.Result.Author('Patrick Poirson'), arxiv.Result.Author('Kwot Sin Lee'), arxiv.Result.Author('Chen Wang')]","Collaborative filtering (CF) is one of the most successful and fundamental
techniques in recommendation systems. In recent years, Graph Neural Network
(GNN)-based CF models, such as NGCF [31], LightGCN [10] and GTN [9] have
achieved tremendous success and significantly advanced the state-of-the-art.
While there is a rich literature of such works using advanced models for
learning user and item representations separately, item recommendation is
essentially a link prediction problem between users and items. Furthermore,
while there have been early works employing link prediction for collaborative
filtering [5, 6], this trend has largely given way to works focused on
aggregating information from user and item nodes, rather than modeling links
directly. In this paper, we propose a new linkage (connectivity) score for
bipartite graphs, generalizing multiple standard link prediction methods. We
combine this new score with an iterative degree update process in the user-item
interaction bipartite graph to exploit local graph structures without any node
modeling. The result is a simple, non-deep learning model with only six
learnable parameters. Despite its simplicity, we demonstrate our approach
significantly outperforms existing state-of-the-art GNN-based CF approaches on
four widely used benchmarks. In particular, on Amazon-Book, we demonstrate an
over 60% improvement for both Recall and NDCG. We hope our work would invite
the community to revisit the link prediction aspect of collaborative filtering,
where significant performance gains could be achieved through aligning link
prediction with item recommendations.",-0.20682725,-0.058929935,0.004145071,A
4057,"J. Tang, ‚ÄúSelf-supervised learning: Generative or contrastive,‚Äù
Currently, on-device self-supervised recommendation has                             IEEE TKDE, 2021.
not been explored, and we believe it deserves further study.","1‚Äì38, 2019.
when combined with the technique of knowledge distilla-
tion [148], [149], SSL may largely compensate for the ac-                   [7] X. Liu, F. Zhang, Z. Hou, L. Mian, Z. Wang, J. Zhang, and
curacy degradation of on-device recommendation models.","[8] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, ‚ÄúMomentum con-
9.5 Towards General-Purpose Pre-training                                            trast for unsupervised visual representation learning,‚Äù in CVPR,
                                                                                    2020, pp.",2022-03-29 19:45:41+00:00,Self-Supervised Learning for Recommender Systems: A Survey,cs.IR,['cs.IR'],"[arxiv.Result.Author('Junliang Yu'), arxiv.Result.Author('Hongzhi Yin'), arxiv.Result.Author('Xin Xia'), arxiv.Result.Author('Tong Chen'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Zi Huang')]","Neural architecture-based recommender systems have achieved tremendous
success in recent years. However, when dealing with highly sparse data, they
still fall short of expectation. Self-supervised learning (SSL), as an emerging
technique to learn with unlabeled data, recently has drawn considerable
attention in many fields. There is also a growing body of research proceeding
towards applying SSL to recommendation for mitigating the data sparsity issue.
In this survey, a timely and systematical review of the research efforts on
self-supervised recommendation (SSR) is presented. Specifically, we propose an
exclusive definition of SSR, on top of which we build a comprehensive taxonomy
to divide existing SSR methods into four categories: contrastive, generative,
predictive, and hybrid. For each category, the narrative unfolds along its
concept and formulation, the involved methods, and its pros and cons.
Meanwhile, to facilitate the development and evaluation of SSR models, we
release an open-source library SELFRec, which incorporates multiple benchmark
datasets and evaluation metrics, and has implemented a number of
state-of-the-art SSR models for empirical comparison. Finally, we shed light on
the limitations in the current research and outline the future research
directions.",-0.10862848,-0.1081661,0.24782851,A
4200,"Last but not least, deploying online experiments

and analyzing users‚Äô decisions in real-world can facilitate further research.","Second, more sophisticated

platform mechanisms are also worth exploring.","REFERENCES

 [1] Monireh Abdoos.",2022-04-01 08:27:27+00:00,Proactively Control Privacy in Recommender Systems,cs.IR,['cs.IR'],"[arxiv.Result.Author('Ziqian Chen'), arxiv.Result.Author('Fei Sun'), arxiv.Result.Author('Yifan Tang'), arxiv.Result.Author('Haokun Chen'), arxiv.Result.Author('Jinyang Gao'), arxiv.Result.Author('Bolin Ding')]","Recently, privacy issues in web services that rely on users' personal data
have raised great attention. Unlike existing privacy-preserving technologies
such as federated learning and differential privacy, we explore another way to
mitigate users' privacy concerns, giving them control over their own data. For
this goal, we propose a privacy aware recommendation framework that gives users
delicate control over their personal data, including implicit behaviors, e.g.,
clicks and watches. In this new framework, users can proactively control which
data to disclose based on the trade-off between anticipated privacy risks and
potential utilities. Then we study users' privacy decision making under
different data disclosure mechanisms and recommendation models, and how their
data disclosure decisions affect the recommender system's performance.
  To avoid the high cost of real-world experiments, we apply simulations to
study the effects of our proposed framework. Specifically, we propose a
reinforcement learning algorithm to simulate users' decisions (with various
sensitivities) under three proposed platform mechanisms on two datasets with
three representative recommendation models. The simulation results show that
the platform mechanisms with finer split granularity and more unrestrained
disclosure strategy can bring better results for both end users and platforms
than the ""all or nothing"" binary mechanism adopted by most real-world
applications. It also shows that our proposed framework can effectively protect
users' privacy since they can obtain comparable or even better results with
much less disclosed data.",0.45173746,-0.04580936,-0.22316694,B
4201,"Last but not least, deploying online
experiments and analyzing users‚Äô decisions in real-world can facilitate further researches.","Recent
mechanism design works also turn to the perspectives of deep neural network based mechanism
designs, which can be explored with our proposed framework.","ACM Transactions on Information Systems, Vol.",2022-04-01 08:27:27+00:00,Studying the Impact of Data Disclosure Mechanism in Recommender Systems via Simulation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Ziqian Chen'), arxiv.Result.Author('Fei Sun'), arxiv.Result.Author('Yifan Tang'), arxiv.Result.Author('Haokun Chen'), arxiv.Result.Author('Jinyang Gao'), arxiv.Result.Author('Bolin Ding')]","Recently, privacy issues in web services that rely on users' personal data
have raised great attention. Unlike existing privacy-preserving technologies
such as federated learning and differential privacy, we explore another way to
mitigate users' privacy concerns, giving them control over their own data. For
this goal, we propose a privacy aware recommendation framework that gives users
delicate control over their personal data, including implicit behaviors, e.g.,
clicks and watches. In this new framework, users can proactively control which
data to disclose based on the trade-off between anticipated privacy risks and
potential utilities. Then we study users' privacy decision making under
different data disclosure mechanisms and recommendation models, and how their
data disclosure decisions affect the recommender system's performance.
  To avoid the high cost of real-world experiments, we apply simulations to
study the effects of our proposed framework. Specifically, we propose a
reinforcement learning algorithm to simulate users' decisions (with various
sensitivities) under three proposed platform mechanisms on two datasets with
three representative recommendation models. The simulation results show that
the platform mechanisms with finer split granularity and more unrestrained
disclosure strategy can bring better results for both end users and platforms
than the ""all or nothing"" binary mechanism adopted by most real-world
applications. It also shows that our proposed framework can effectively protect
users' privacy since they can obtain comparable or even better results with
much less disclosed data.",0.092175946,0.024855208,0.05733737,B
4202,"To further study                 To study the impact of ùëêùëùùë°, we investigate how i-Razor performs
the role of these two components, we propose and compare the                    with the change of ùëêùëùùë°, while fixing other parameters (ùúè = 0.05, ùúÜ =
following four variants:                                                        0.0001).",to derive the desired embedding configuration.,"As shown in Figure 3, larger ùëêùëùùë° leads to larger value of
                                                                                Params, which is straightforward as more embedding blocks and
   (1) i-Razor+0: using the CPT-based pruning algorithm while                   fields would be reserved.",2022-04-01 08:30:06+00:00,i-Razor: A Neural Input Razor for Feature Selection and Dimension Search in Large-Scale Recommender Systems,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Yao Yao'), arxiv.Result.Author('Bin Liu'), arxiv.Result.Author('Haoxun He'), arxiv.Result.Author('Dakui Sheng'), arxiv.Result.Author('Ke Wang'), arxiv.Result.Author('Li Xiao'), arxiv.Result.Author('Huanhuan Cao')]","Input features play a crucial role in the predictive performance of DNN-based
industrial recommender systems with thousands of categorical and continuous
fields from users, items, contexts, and their interactions. Noisy features and
inappropriate embedding dimension assignments can impair the performance of
recommender systems and introduce unnecessary complexity in model training and
online serving. Optimizing the input configuration of DNN models, including
feature selection and embedding dimension assignment, has become one of the
essential topics in feature engineering. Typically, feature selection and
embedding dimension search are optimized sequentially, i.e., feature selection
is performed first, followed by embedding dimension search to determine the
optimal dimension size for each selected feature. In contrast, this paper
studies the joint optimization of feature selection and embedding dimension
search. To this end, we propose a differentiable neural \textbf{i}nput
\textbf{razor}, namely \textbf{i-Razor}. Specifically, inspired by recent
advances in neural architecture search, we introduce an end-to-end
differentiable model to learn the relative importance between different
embedding regions of each feature. Furthermore, a flexible pruning algorithm is
proposed to simultaneously achieve feature filtering and dimension size
derivation. Extensive experiments on two large-scale public datasets in the
Click-Through-Rate (CTR) prediction task demonstrate the efficacy and
superiority of i-Razor in balancing model complexity and performance.",-0.2697122,0.03353981,-0.056480415,A
4232,"We further study on this dataset what
the number of token embeddings constructed by the WordPiece            is the relative percentage of queries with typos that need to be
tokenizer.","This is due to the fact that the number of token    do not find statistically significant differences, except for MAP
embeddings constructed by Character-CNNs is usually smaller than       for standardBERT-DR+Aug.","Thus, for the same query, the self-attention computation    present in a dataset to prefer the use of CharacterBERT-DR+ST over
in the BERT transformer layers is often less time consuming for        StandardBERT-DR.",2022-04-01 23:02:50+00:00,CharacterBERT and Self-Teaching for Improving the Robustness of Dense Retrievers on Queries with Typos,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Author('Shengyao Zhuang'), arxiv.Result.Author('Guido Zuccon')]","Current dense retrievers are not robust to out-of-domain and outlier queries,
i.e. their effectiveness on these queries is much poorer than what one would
expect. In this paper, we consider a specific instance of such queries: queries
that contain typos. We show that a small character level perturbation in
queries (as caused by typos) highly impacts the effectiveness of dense
retrievers. We then demonstrate that the root cause of this resides in the
input tokenization strategy employed by BERT. In BERT, tokenization is
performed using the BERT's WordPiece tokenizer and we show that a token with a
typo will significantly change the token distributions obtained after
tokenization. This distribution change translates to changes in the input
embeddings passed to the BERT-based query encoder of dense retrievers. We then
turn our attention to devising dense retriever methods that are robust to such
queries with typos, while still being as performant as previous methods on
queries without typos. For this, we use CharacterBERT as the backbone encoder
and an efficient yet effective training method, called Self-Teaching (ST), that
distills knowledge from queries without typos into the queries with typos.
Experimental results show that CharacterBERT in combination with ST achieves
significantly higher effectiveness on queries with typos compared to previous
methods. Along with these results and the open-sourced implementation of the
methods, we also provide a new passage retrieval dataset consisting of
real-world queries with typos and associated relevance assessments on the MS
MARCO corpus, thus supporting the research community in the investigation of
effective and robust dense retrievers. Code, experimental results and dataset
are made available at https://github.com/ielab/CharacterBERT-DR.",-0.20333534,0.26406193,0.21948022,C
4266,"So, we choose 32 for each attribute and the
We further study the model performance where a user             Ô¨Ånal embedding size is set as 160.
doesn‚Äôt have any interaction in the current period.","Increasing
     No Interactions in the Current Period                      the size didn‚Äôt improve the results as shown in Figure 6 for
                                                                three datasets.","In this
case, our time-speciÔ¨Åc module utilizes global user factors in-        Periodical Recommendation Results
stead of user-speciÔ¨Åc factors due to lack of interaction, and
hence no adaptation is made.",2022-04-03 02:04:12+00:00,A Dynamic Meta-Learning Model for Time-Sensitive Cold-Start Recommendations,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Krishna Prasad Neupane'), arxiv.Result.Author('Ervine Zheng'), arxiv.Result.Author('Yu Kong'), arxiv.Result.Author('Qi Yu')]","We present a novel dynamic recommendation model that focuses on users who
have interactions in the past but turn relatively inactive recently. Making
effective recommendations to these time-sensitive cold-start users is critical
to maintain the user base of a recommender system. Due to the sparse recent
interactions, it is challenging to capture these users' current preferences
precisely. Solely relying on their historical interactions may also lead to
outdated recommendations misaligned with their recent interests. The proposed
model leverages historical and current user-item interactions and dynamically
factorizes a user's (latent) preference into time-specific and time-evolving
representations that jointly affect user behaviors. These latent factors
further interact with an optimized item embedding to achieve accurate and
timely recommendations. Experiments over real-world data help demonstrate the
effectiveness of the proposed time-sensitive cold-start recommendation model.",0.05709925,-0.24269736,0.14887775,A
4594,"The further study results also             IEEE Access, 7:145861‚Äì145879.",formance of DRPN.,show the effectiveness of the denoising module.,2022-04-09 05:47:17+00:00,Denoising Neural Network for News Recommendation with Positive and Negative Implicit Feedback,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Author('Yunfan Hu'), arxiv.Result.Author('Zhaopeng Qiu'), arxiv.Result.Author('Xian Wu')]","News recommendation is different from movie or e-commercial recommendation as
people usually do not grade the news. Therefore, user feedback for news is
always implicit (click behavior, reading time, etc). Inevitably, there are
noises in implicit feedback. On one hand, the user may exit immediately after
clicking the news as he dislikes the news content, leaving the noise in his
positive implicit feedback; on the other hand, the user may be recommended
multiple interesting news at the same time and only click one of them,
producing the noise in his negative implicit feedback. Opposite implicit
feedback could construct more integrated user preferences and help each other
to minimize the noise influence. Previous works on news recommendation only
used positive implicit feedback and suffered from the noise impact. In this
paper, we propose a denoising neural network for news recommendation with
positive and negative implicit feedback, named DRPN. DRPN utilizes both
feedback for recommendation with a module to denoise both positive and negative
implicit feedback to further enhance the performance. Experiments on the
real-world large-scale dataset demonstrate the state-of-the-art performance of
DRPN.",-0.3694368,-0.008399991,-0.21406448,A
4665,"To                           returning either a number without explanatory evidence or multiple
                                        promote further research on this underexplored topic, we release                             candidate answers with high variance.","Experiments                                fail on semantically refined requests (e.g., ‚Äúfor the Beatles‚Äù), merely
                                        with a wide variety of queries show the benefits of our method.",an annotated dataset of 5k queries with 200k relevant text spans.,2022-04-11 12:20:13+00:00,Answering Count Queries with Explanatory Evidence,cs.IR,['cs.IR'],"[arxiv.Result.Author('Shrestha Ghosh'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum')]","A challenging case in web search and question answering are count queries,
such as \textit{""number of songs by John Lennon""}. Prior methods merely answer
these with a single, and sometimes puzzling number or return a ranked list of
text snippets with different numbers. This paper proposes a methodology for
answering count queries with inference, contextualization and explanatory
evidence. Unlike previous systems, our method infers final answers from
multiple observations, supports semantic qualifiers for the counts, and
provides evidence by enumerating representative instances. Experiments with a
wide variety of queries show the benefits of our method. To promote further
research on this underexplored topic, we release an annotated dataset of 5k
queries with 200k relevant text spans.",0.20679733,0.22391964,0.14440452,C
4666,"To                         from web contents thus poses several challenges:
                                        promote further research on this underexplored topic, we release
                                        an annotated dataset of 5k queries with 200k relevant text spans.","Answering count queries
                                        with a wide variety of queries show the benefits of our method.",1.,2022-04-11 12:20:13+00:00,Answering Count Queries with Explanatory Evidence,cs.IR,['cs.IR'],"[arxiv.Result.Author('Shrestha Ghosh'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum')]","A challenging case in web search and question answering are count queries,
such as \textit{""number of songs by John Lennon""}. Prior methods merely answer
these with a single, and sometimes puzzling number or return a ranked list of
text snippets with different numbers. This paper proposes a methodology for
answering count queries with inference, contextualization and explanatory
evidence. Unlike previous systems, our method infers final answers from
multiple observations, supports semantic qualifiers for the counts, and
provides evidence by enumerating representative instances. Experiments with a
wide variety of queries show the benefits of our method. To promote further
research on this underexplored topic, we release an annotated dataset of 5k
queries with 200k relevant text spans.",0.067300856,0.33140638,0.21883428,C
4667,"To foster further research, we release all          dicting spans.","SpanBERT: Improving pre-training by representing and pre-
through CNPs when there exist similar competing answers attrib-
uted to specific qualifiers.",In TACL.,2022-04-11 12:20:13+00:00,Answering Count Queries with Explanatory Evidence,cs.IR,['cs.IR'],"[arxiv.Result.Author('Shrestha Ghosh'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum')]","A challenging case in web search and question answering are count queries,
such as \textit{""number of songs by John Lennon""}. Prior methods merely answer
these with a single, and sometimes puzzling number or return a ranked list of
text snippets with different numbers. This paper proposes a methodology for
answering count queries with inference, contextualization and explanatory
evidence. Unlike previous systems, our method infers final answers from
multiple observations, supports semantic qualifiers for the counts, and
provides evidence by enumerating representative instances. Experiments with a
wide variety of queries show the benefits of our method. To promote further
research on this underexplored topic, we release an annotated dataset of 5k
queries with 200k relevant text spans.",-0.13638382,0.32113853,-0.01529631,C
4677,"To further study how the models handle
of experts are also aggregated by a gate network.","‚Ä¢ IADM: which stack ‚Äúexperts‚Äù in the depth direction, and the output         Qualitative Results.","Note that in IADM,      the concept drift in streaming data, we plot the AUC/10Min in Fig.",2022-04-01 07:43:43+00:00,Concept Drift Adaptation for CTR Prediction in Online Advertising Systems,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Congcong Liu'), arxiv.Result.Author('Yuejiang Li'), arxiv.Result.Author('Xiwei Zhao'), arxiv.Result.Author('Changping Peng'), arxiv.Result.Author('Zhangang Lin'), arxiv.Result.Author('Jingping Shao')]","Click-through rate (CTR) prediction is a crucial task in web search,
recommender systems, and online advertisement displaying. In practical
application, CTR models often serve with high-speed user-generated data
streams, whose underlying distribution rapidly changing over time. The concept
drift problem inevitably exists in those streaming data, which can lead to
performance degradation due to the timeliness issue. To ensure model freshness,
incremental learning has been widely adopted in real-world production systems.
However, it is hard for the incremental update to achieve the balance of the
CTR models between the adaptability to capture the fast-changing trends and
generalization ability to retain common knowledge. In this paper, we propose
adaptive mixture of experts (AdaMoE), a new framework to alleviate the concept
drift problem by adaptive filtering in the data stream of CTR prediction. The
extensive experiments on the offline industrial dataset and online A/B tests
show that our AdaMoE significantly outperforms all incremental learning
frameworks considered.",-0.102409974,0.027438099,-0.013707554,A
4815,"D.4.2 Sensitivity analysis

We further study the sensitivity of BNS to Œª, sample information xÀÜl, and prior information Pfn(l).",More discussions can be found in Sec D.4.3.,- BNS-1: warm-start of Œª.,2022-04-02 09:50:19+00:00,Bayesian Negative Sampling for Recommendation,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Bin Liu'), arxiv.Result.Author('Bang Wang')]","How to sample high quality negative instances from unlabeled data, i.e.,
negative sampling, is important for training implicit collaborative filtering
and contrastive learning models. Although previous studies have proposed some
approaches to sample informative instances, few has been done to discriminating
false negative from true negative for unbiased negative sampling. On the basis
of our order relation analysis of negatives' scores, we first derive the class
conditional density of true negatives and that of false negatives. We next
design a Bayesian classifier for negative classification, from which we define
a model-agnostic posterior probability estimate of an instance being true
negative as a quantitative negative signal measure. We also propose a Bayesian
optimal sampling rule to sample high-quality negatives. The proposed Bayesian
Negative Sampling (BNS) algorithm has a linear time complexity. Experimental
studies validate the superiority of BNS over the peers in terms of better
sampling quality and better recommendation performance.",-0.25707635,-0.035915155,-0.31937516,A
4816,"Therefore, the
                                                                     larger size of Mu is the better if the prior probability Pfn(¬∑)
   2) Sensitivity analysis: We further study the sensitivity of      is reliable, otherwise an Mu of moderate size should be
BNS to Œª, sample information xÀÜl, and prior information Pfn(l).","signal bias, leads to performance degradation.",chosen.,2022-04-02 09:50:19+00:00,Bayesian Negative Sampling for Recommendation,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Bin Liu'), arxiv.Result.Author('Bang Wang')]","How to sample high quality negative instances from unlabeled data, i.e.,
negative sampling, is important for training implicit collaborative filtering
and contrastive learning models. Although previous studies have proposed some
approaches to sample informative instances, few has been done to discriminating
false negative from true negative for unbiased negative sampling. On the basis
of our order relation analysis of negatives' scores, we first derive the class
conditional density of true negatives and that of false negatives. We next
design a Bayesian classifier for negative classification, from which we define
a model-agnostic posterior probability estimate of an instance being true
negative as a quantitative negative signal measure. We also propose a Bayesian
optimal sampling rule to sample high-quality negatives. The proposed Bayesian
Negative Sampling (BNS) algorithm has a linear time complexity. Experimental
studies validate the superiority of BNS over the peers in terms of better
sampling quality and better recommendation performance.",-0.29019248,-0.16473591,-0.3107561,A
4870,"We leave it to further research to qualitatively investigate the query-document
pairs that BERT fails, but BM25 ranks correctly.","By masking the query words in the document we demonstrate
the ability of CE to score queries and documents without any lexical overlap
with a moderate loss of performance, therefore demonstrating the true strength
of neural models over traditional methods, that would completely fail in this
scenario, in isolation.","Acknowledgments This research is funded in part by the Netherlands Organiza-
tion for ScientiÔ¨Åc Research (NWO CI # CISC.CC.016), and the Innovation Exchange
Amsterdam (POC grant).",2022-04-05 10:48:52+00:00,How Different are Pre-trained Transformers for Text Ranking?,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL']","[arxiv.Result.Author('David Rau'), arxiv.Result.Author('Jaap Kamps')]","In recent years, large pre-trained transformers have led to substantial gains
in performance over traditional retrieval models and feedback approaches.
However, these results are primarily based on the MS Marco/TREC Deep Learning
Track setup, with its very particular setup, and our understanding of why and
how these models work better is fragmented at best. We analyze effective
BERT-based cross-encoders versus traditional BM25 ranking for the passage
retrieval task where the largest gains have been observed, and investigate two
main questions. On the one hand, what is similar? To what extent does the
neural ranker already encompass the capacity of traditional rankers? Is the
gain in performance due to a better ranking of the same documents (prioritizing
precision)? On the other hand, what is different? Can it retrieve effectively
documents missed by traditional systems (prioritizing recall)? We discover
substantial differences in the notion of relevance identifying strengths and
weaknesses of BERT that may inspire research for future improvement. Our
results contribute to our understanding of (black-box) neural rankers relative
to (well-understood) traditional rankers, help understand the particular
experimental setting of MS-Marco-based test collections.",-0.065054595,0.31586927,0.19374825,C
4893,"dialogue policy learning, and can serve as a preliminary baseline to
benefit further research.",1951‚Äì1961.,"Naturally, there are thus a few loose ends                 [10] Veton K√´puska and Gamal Bohouta.",2022-04-07 14:11:31+00:00,Interacting with Non-Cooperative User: A New Paradigm for Proactive Dialogue Policy,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Wenqiang Lei'), arxiv.Result.Author('Yao Zhang'), arxiv.Result.Author('Feifan Song'), arxiv.Result.Author('Hongru Liang'), arxiv.Result.Author('Jiaxin Mao'), arxiv.Result.Author('Jiancheng Lv'), arxiv.Result.Author('Zhenglu Yang'), arxiv.Result.Author('Tat-Seng Chua')]","Proactive dialogue system is able to lead the conversation to a goal topic
and has advantaged potential in bargain, persuasion and negotiation. Current
corpus-based learning manner limits its practical application in real-world
scenarios. To this end, we contribute to advance the study of the proactive
dialogue policy to a more natural and challenging setting, i.e., interacting
dynamically with users. Further, we call attention to the non-cooperative user
behavior -- the user talks about off-path topics when he/she is not satisfied
with the previous topics introduced by the agent. We argue that the targets of
reaching the goal topic quickly and maintaining a high user satisfaction are
not always converge, because the topics close to the goal and the topics user
preferred may not be the same. Towards this issue, we propose a new solution
named I-Pro that can learn Proactive policy in the Interactive setting.
Specifically, we learn the trade-off via a learned goal weight, which consists
of four factors (dialogue turn, goal completion difficulty, user satisfaction
estimation, and cooperative degree). The experimental results demonstrate I-Pro
significantly outperforms baselines in terms of effectiveness and
interpretability.",0.15562238,0.20466734,-0.11185085,C
5191,"Undoubtedly, these fine-tuning methods can
                                                                        also be applied to our COSTA, and we leave this for further study.","This demonstrates the effectiveness of our proposed contrastive
                                                                        span prediction task.","Table 4: The performance of COSTA with different span                   Table 6: Performance comparison of COSTA with different
granularities.",2022-04-22 11:22:29+00:00,Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction,cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Xinyu Ma'), arxiv.Result.Author('Jiafeng Guo'), arxiv.Result.Author('Ruqing Zhang'), arxiv.Result.Author('Yixing Fan'), arxiv.Result.Author('Xueqi Cheng')]","Dense retrieval has shown promising results in many information retrieval
(IR) related tasks, whose foundation is high-quality text representation
learning for effective search. Some recent studies have shown that
autoencoder-based language models are able to boost the dense retrieval
performance using a weak decoder. However, we argue that 1) it is not
discriminative to decode all the input texts and, 2) even a weak decoder has
the bypass effect on the encoder. Therefore, in this work, we introduce a novel
contrastive span prediction task to pre-train the encoder alone, but still
retain the bottleneck ability of the autoencoder. % Therefore, in this work, we
propose to drop out the decoder and introduce a novel contrastive span
prediction task to pre-train the encoder alone. The key idea is to force the
encoder to generate the text representation close to its own random spans while
far away from others using a group-wise contrastive loss. In this way, we can
1) learn discriminative text representations efficiently with the group-wise
contrastive learning over spans and, 2) avoid the bypass effect of the decoder
thoroughly. Comprehensive experiments over publicly available retrieval
benchmark datasets show that our approach can outperform existing pre-training
methods for dense retrieval significantly.",-0.19117169,-0.0955036,-0.13874406,A
5267,"In further research, we plan to
work on the eÔ¨Éciency, as well as adoption of our approach to more advanced
experimentation framework [21].","Evaluation on three stan-
dard TREC test collections indicates the groupwise model signiÔ¨Åcantly outper-
forms the BERT baselines nearly in all cases.","Groupwise Query Performance Prediction with BERT  7

References

 1.",2022-04-25 08:10:28+00:00,Groupwise Query Performance Prediction with BERT,cs.IR,['cs.IR'],"[arxiv.Result.Author('Xiaoyang Chen'), arxiv.Result.Author('Ben He'), arxiv.Result.Author('Le Sun')]","While large-scale pre-trained language models like BERT have advanced the
state-of-the-art in IR, its application in query performance prediction (QPP)
is so far based on pointwise modeling of individual queries. Meanwhile, recent
studies suggest that the cross-attention modeling of a group of documents can
effectively boost performances for both learning-to-rank algorithms and
BERT-based re-ranking. To this end, a BERT-based groupwise QPP model is
proposed, in which the ranking contexts of a list of queries are jointly
modeled to predict the relative performance of individual queries. Extensive
experiments on three standard TREC collections showcase effectiveness of our
approach. Our code is available at https://github.com/VerdureChen/Group-QPP.",-0.17201549,0.09307422,0.04074426,A
5287,"A further study could
                                                                       focus on how to use external knowledge in PLM based retriever.",meta-graphs for a large scale of candidates.,Table 6: Ranking performance comparison on different domains.,2022-04-25 14:07:28+00:00,Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Qian Dong'), arxiv.Result.Author('Yiding Liu'), arxiv.Result.Author('Suqi Cheng'), arxiv.Result.Author('Shuaiqiang Wang'), arxiv.Result.Author('Zhicong Cheng'), arxiv.Result.Author('Shuzi Niu'), arxiv.Result.Author('Dawei Yin')]","Passage re-ranking is to obtain a permutation over the candidate passage set
from retrieval stage. Re-rankers have been boomed by Pre-trained Language
Models (PLMs) due to their overwhelming advantages in natural language
understanding. However, existing PLM based re-rankers may easily suffer from
vocabulary mismatch and lack of domain specific knowledge. To alleviate these
problems, explicit knowledge contained in knowledge graph is carefully
introduced in our work. Specifically, we employ the existing knowledge graph
which is incomplete and noisy, and first apply it in passage re-ranking task.
To leverage a reliable knowledge, we propose a novel knowledge graph
distillation method and obtain a knowledge meta graph as the bridge between
query and passage. To align both kinds of embedding in the latent space, we
employ PLM as text encoder and graph neural network over knowledge meta graph
as knowledge encoder. Besides, a novel knowledge injector is designed for the
dynamic interaction between text and knowledge encoder. Experimental results
demonstrate the effectiveness of our method especially in queries requiring
in-depth domain knowledge.",0.08895865,0.08723339,0.15558475,C
5378,"Similarly, we keep the corresponding
and test candidate samples to predict without using any data from         score for further research.","Here we use the
use the training set to train with sampling 99 negative items for each    training set to build the corresponding features and give predictions
positive interaction, public test set to validate model performance       on the public/private test set.","It is worth noting that the training set
source markets, due to no distinct performance improvement by             used here includes all the data from source markets and target
trying cross-market information.",2022-04-27 03:40:54+00:00,A Practical Two-stage Ranking Framework for Cross-market Recommendation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Zeyuan Chen'), arxiv.Result.Author('He Wang'), arxiv.Result.Author('Xiangyu Zhu'), arxiv.Result.Author('Haiyan Wu'), arxiv.Result.Author('Congcong Gu'), arxiv.Result.Author('Shumeng Liu'), arxiv.Result.Author('Jinchao Huang'), arxiv.Result.Author('Wei Zhang')]","Cross-market recommendation aims to recommend products to users in a
resource-scarce target market by leveraging user behaviors from similar
rich-resource markets, which is crucial for E-commerce companies but receives
less research attention. In this paper, we present our detailed solution
adopted in the cross-market recommendation contest, i.e., WSDM CUP 2022. To
better utilize collaborative signals and similarities between target and source
markets, we carefully consider multiple features as well as stacking learning
models consisting of deep graph recommendation models (Graph Neural Network,
DeepWalk, etc.) and traditional recommendation models (ItemCF, UserCF, Swing,
etc.). Furthermore, We adopt tree-based ensembling methods, e.g., LightGBM,
which show superior performance in prediction task to generate final results.
We conduct comprehensive experiments on the XMRec dataset, verifying the
effectiveness of our model. The proposed solution of our team WSDM_Coggle_ is
selected as the second place submission.",-0.045932442,-0.0048373956,-0.06832641,A
5631,"For example for the query ‚ÄúGive me the capitals of all countries     For further research, the effect of the entity linking method
in Africa‚Äù, while monoBERT‚Äôs highest ranked entities are general        can be investigated; here we used REL, which is an entity linker
overview pages like ‚ÄòList of African dependencies‚Äô, all of EM-BERT‚Äôs    with high precision.","BERT learns to retrieve specific entities for queries requesting a
list.","It would be also interesting to evaluate the
highest-ranked entities are capitals of African countries like ‚ÄòDakar‚Äô  performance of other dense and sparse retrieval methods on entity-
and ‚ÄòPorto-Novo‚Äô.",2022-05-02 11:53:59+00:00,Entity-aware Transformers for Entity Search,cs.IR,"['cs.IR', 'cs.CL', 'H.3.3']","[arxiv.Result.Author('Emma J. Gerritse'), arxiv.Result.Author('Faegheh Hasibi'), arxiv.Result.Author('Arjen P. de Vries')]","Pre-trained language models such as BERT have been a key ingredient to
achieve state-of-the-art results on a variety of tasks in natural language
processing and, more recently, also in information retrieval.Recent research
even claims that BERT is able to capture factual knowledge about entity
relations and properties, the information that is commonly obtained from
knowledge graphs. This paper investigates the following question: Do BERT-based
entity retrieval models benefit from additional entity information stored in
knowledge graphs? To address this research question, we map entity embeddings
into the same input space as a pre-trained BERT model and inject these entity
embeddings into the BERT model. This entity-enriched language model is then
employed on the entity retrieval task. We show that the entity-enriched BERT
model improves effectiveness on entity-oriented queries over a regular BERT
model, establishing a new state-of-the-art result for the entity retrieval
task, with substantial improvements for complex natural language queries and
queries requesting a list of entities with a certain property. Additionally, we
show that the entity information provided by our entity-enriched model
particularly helps queries related to less popular entities. Last, we observe
empirically that the entity-enriched BERT models enable fine-tuning on limited
training data, which otherwise would not be feasible due to the known
instabilities of BERT in few-sample fine-tuning, thereby contributing to
data-efficient training of BERT for entity search.",0.045721922,0.23937985,0.22770399,C
5659,"For the   gression [16], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is  which is open for further research.","distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time.","to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels.",2022-05-03 03:47:42+00:00,On Ranking Consistency of Pre-ranking Stage,cs.IR,"['cs.IR', 'H.0']","[arxiv.Result.Author('Siyu Gu'), arxiv.Result.Author('Xiang-Rong Sheng'), arxiv.Result.Author('Biye Jiang'), arxiv.Result.Author('Siyuan Lou'), arxiv.Result.Author('Shuguang Han'), arxiv.Result.Author('Hongbo Deng'), arxiv.Result.Author('Bo Zheng')]","Industrial ranking systems, such as advertising systems, rank items by
aggregating multiple objectives into one final objective to satisfy user demand
and commercial intent. Cascade architecture, composed of retrieval,
pre-ranking, and ranking stages, is usually adopted to reduce the computational
cost. Each stage may employ various models for different objectives and
calculate the final objective by aggregating these models' outputs. The
multi-stage ranking strategy causes a new problem - the ranked lists of the
ranking stage and previous stages may be inconsistent. For example, items that
should be ranked at the top of the ranking stage may be ranked at the bottom of
previous stages. In this paper, we focus on the ranking consistency between the
pre-ranking and ranking stages. Specifically, we formally define the problem of
ranking consistency and propose the Ranking Consistency Score (RCS) metric for
evaluation. We demonstrate that ranking consistency has a direct impact on
online performance. Compared with the traditional evaluation manner that mainly
focuses on the individual ranking quality of every objective, RCS considers the
ranking consistency of the fused final objective, which is more proper for
evaluation. Finally, to improve the ranking consistency, we propose several
methods from the perspective of sample selection and learning algorithms.
Experimental results on industrial datasets validate the efficacy of the
proposed metrics and methods. The proposed consistency methods have been
deployed on the display advertising system of Alibaba, obtaining a 6.7%
improvement on CTR (Click-Through Rate) and a 5.5% increase on RPM (Revenue Per
Mille).",-0.2942068,-0.14135316,0.0077856462,A
5660,"Note that other
                                                                       distillation objective or post calibration methods, such as isotonic re-
   To mitigate the inconsistency caused by SSB, we propose to          gression [15], can also be explored to improve the proxy-calibration,
utilize samples in the pre-ranking set to train the pre-ranking        which is open for further research.",tency between the pre-ranking and ranking stage.,models.,2022-05-03 03:47:42+00:00,On Ranking Consistency of Pre-ranking Stage,cs.IR,['cs.IR'],[arxiv.Result.Author('Siyu Gu')],"Industrial ranking systems, such as advertising systems, rank items by
aggregating multiple objectives into one final objective to satisfy user demand
and commercial intent. Cascade architecture, composed of retrieval,
pre-ranking, and ranking stages, is usually adopted to reduce the computational
cost. Each stage may employ various models for different objectives and
calculate the final objective by aggregating these models' outputs. The
multi-stage ranking strategy causes a new problem - the ranked lists of the
ranking stage and previous stages may be inconsistent. For example, items that
should be ranked at the top of the ranking stage may be ranked at the bottom of
previous stages. In this paper, we focus on the ranking consistency between the
pre-ranking and ranking stages. Specifically, we formally define the problem of
ranking consistency and propose the Ranking Consistency Score (RCS) metric for
evaluation. We demonstrate that ranking consistency has a direct impact on
online performance. Compared with the traditional evaluation manner that mainly
focuses on the individual ranking quality of every objective, RCS considers the
ranking consistency of the fused final objective, which is more proper for
evaluation. Finally, to improve the ranking consistency, we propose several
methods from the perspective of sample selection and learning algorithms.
Experimental results on industrial datasets validate the efficacy of the
proposed metrics and methods. increase on RPM (Revenue Per Mille).",-0.29171836,-0.14616193,-0.04634408,A
5661,"For the    gression [17], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is   which is open for further research.","distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time.","to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels.",2022-05-03 03:47:42+00:00,On Ranking Consistency of Pre-ranking Stage,cs.IR,['cs.IR'],[arxiv.Result.Author('Siyu Gu')],"Industrial ranking systems, such as advertising systems, rank items by
aggregating multiple objectives into one final objective to satisfy user demand
and commercial intent. Cascade architecture, composed of retrieval,
pre-ranking, and ranking stages, is usually adopted to reduce the computational
cost. Each stage may employ various models for different objectives and
calculate the final objective by aggregating these models' outputs. The
multi-stage ranking strategy causes a new problem - the ranked lists of the
ranking stage and previous stages may be inconsistent. For example, items that
should be ranked at the top of the ranking stage may be ranked at the bottom of
previous stages. In this paper, we focus on the \textbf{ranking consistency}
between the pre-ranking and ranking stages. Specifically, we formally define
the problem of ranking consistency and propose the Ranking Consistency Score
(RCS) metric for evaluation. We demonstrate that ranking consistency has a
direct impact on online performance. Compared with the traditional evaluation
manner that mainly focuses on the individual ranking quality of every
objective, RCS considers the ranking consistency of the fused final objective,
which is more proper for evaluation. Finally, to improve the ranking
consistency, we propose several methods from the perspective of sample
selection and learning algorithms. Experimental results on one of the biggest
industrial E-commerce platforms in China validate the efficacy of the proposed
metrics and methods.",-0.29058895,-0.14627303,0.0087835975,A
5662,"For the    gression [17], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is   which is open for further research.","distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time.","to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels.",2022-05-03 03:47:42+00:00,On Ranking Consistency of Pre-ranking Stage,cs.IR,['cs.IR'],[arxiv.Result.Author('Siyu Gu')],"Industrial ranking systems, such as advertising systems, rank items by
aggregating multiple objectives into one final objective to satisfy user demand
and commercial intent. Cascade architecture, composed of retrieval,
pre-ranking, and ranking stages, is usually adopted to reduce the computational
cost. Each stage may employ various models for different objectives and
calculate the final objective by aggregating these models' outputs. The
multi-stage ranking strategy causes a new problem - the ranked lists of the
ranking stage and previous stages may be inconsistent. For example, items that
should be ranked at the top of the ranking stage may be ranked at the bottom of
previous stages. In this paper, we focus on the \textbf{ranking consistency}
between the pre-ranking and ranking stages. Specifically, we formally define
the problem of ranking consistency and propose the Ranking Consistency Score
(RCS) metric for evaluation. We demonstrate that ranking consistency has a
direct impact on online performance. Compared with the traditional evaluation
manner that mainly focuses on the individual ranking quality of every
objective, RCS considers the ranking consistency of the fused final objective,
which is more proper for evaluation. Finally, to improve the ranking
consistency, we propose several methods from the perspective of sample
selection and learning algorithms. Experimental results on one of the biggest
industrial E-commerce platforms in China validate the efficacy of the proposed
metrics and methods.",-0.29058895,-0.14627303,0.0087835975,A
5663,"For the    gression [17], can also be explored to improve the proxy-calibration,
first difficulty, recall that the goal of the ranking consistency is   which is open for further research.","distillation objective or post calibration methods, such as isotonic re-
It is hard for the model to train all samples in real-time.","to align the pre-ranking stage with the ranking stage, so we can
use the prediction scores of ranking models as the proxy labels.",2022-05-03 03:47:42+00:00,On Ranking Consistency of Pre-ranking Stage,cs.IR,['cs.IR'],"[arxiv.Result.Author('Siyu Gu'), arxiv.Result.Author('Xiangrong Sheng')]","Industrial ranking systems, such as advertising systems, rank items by
aggregating multiple objectives into one final objective to satisfy user demand
and commercial intent. Cascade architecture, composed of retrieval,
pre-ranking, and ranking stages, is usually adopted to reduce the computational
cost. Each stage may employ various models for different objectives and
calculate the final objective by aggregating these models' outputs. The
multi-stage ranking strategy causes a new problem - the ranked lists of the
ranking stage and previous stages may be inconsistent. For example, items that
should be ranked at the top of the ranking stage may be ranked at the bottom of
previous stages. In this paper, we focus on the \textbf{ranking consistency}
between the pre-ranking and ranking stages. Specifically, we formally define
the problem of ranking consistency and propose the Ranking Consistency Score
(RCS) metric for evaluation. We demonstrate that ranking consistency has a
direct impact on online performance. Compared with the traditional evaluation
manner that mainly focuses on the individual ranking quality of every
objective, RCS considers the ranking consistency of the fused final objective,
which is more proper for evaluation. Finally, to improve the ranking
consistency, we propose several methods from the perspective of sample
selection and learning algorithms. Experimental results on one of the biggest
industrial E-commerce platforms in China validate the efficacy of the proposed
metrics and methods.",-0.29058895,-0.14627303,0.0087835975,A
5695,"The
Ô¨Ånal discussion in Section 4.3.4 summarizes what has been learned and points toward
aspects that merit further study.","Then the proce-
dures are applied on the datasets and their retrieval performances are inspected (4).","Before continuing, note that the vocabulary used in this study often makes use of the
term retrieval.",2022-05-03 16:22:42+00:00,A Comparison of Approaches for Imbalanced Classification Problems in the Context of Retrieving Relevant Documents for an Analysis,cs.IR,"['cs.IR', 'cs.CL', 'stat.AP', 'stat.ML', 'I.2.7; H.3.3']",[arxiv.Result.Author('Sandra Wankm√ºller')],"One of the first steps in many text-based social science studies is to
retrieve documents that are relevant for the analysis from large corpora of
otherwise irrelevant documents. The conventional approach in social science to
address this retrieval task is to apply a set of keywords and to consider those
documents to be relevant that contain at least one of the keywords. But the
application of incomplete keyword lists risks drawing biased inferences. More
complex and costly methods such as query expansion techniques, topic
model-based classification rules, and active as well as passive supervised
learning could have the potential to more accurately separate relevant from
irrelevant documents and thereby reduce the potential size of bias. Yet,
whether applying these more expensive approaches increases retrieval
performance compared to keyword lists at all, and if so, by how much, is
unclear as a comparison of these approaches is lacking. This study closes this
gap by comparing these methods across three retrieval tasks associated with a
data set of German tweets (Linder, 2017), the Social Bias Inference Corpus
(SBIC) (Sap et al., 2020), and the Reuters-21578 corpus (Lewis, 1997). Results
show that query expansion techniques and topic model-based classification rules
in most studied settings tend to decrease rather than increase retrieval
performance. Active supervised learning, however, if applied on a not too small
set of labeled training instances (e.g. 1,000 documents), reaches a
substantially higher retrieval performance than keyword lists.",-0.02900602,0.14837107,0.00792528,C
5730,"Multi-task pre-finetuning
tialized from three officially released pre-trained T5 checkpoints:     for ranking needs further study.","The mixture of the two tasks
                                                                        doesn‚Äôt bring significant improvements.","T5 (Vanilla), T5 (LM-Adapt) and T5 (Multi-task).",2022-05-04 04:23:29+00:00,P$^3$ Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning,cs.IR,"['cs.IR', 'cs.CL', 'H.3.3']","[arxiv.Result.Author('Xiaomeng Hu'), arxiv.Result.Author('Shi Yu'), arxiv.Result.Author('Chenyan Xiong'), arxiv.Result.Author('Zhenghao Liu'), arxiv.Result.Author('Zhiyuan Liu'), arxiv.Result.Author('Ge Yu')]","Compared to other language tasks, applying pre-trained language models (PLMs)
for search ranking often requires more nuances and training signals. In this
paper, we identify and study the two mismatches between pre-training and
ranking fine-tuning: the training schema gap regarding the differences in
training objectives and model architectures, and the task knowledge gap
considering the discrepancy between the knowledge needed in ranking and that
learned during pre-training. To mitigate these gaps, we propose Pre-trained,
Prompt-learned and Pre-finetuned Neural Ranker (P$^3$ Ranker). P$^3$ Ranker
leverages prompt-based learning to convert the ranking task into a pre-training
like schema and uses pre-finetuning to initialize the model on intermediate
supervised tasks. Experiments on MS MARCO and Robust04 show the superior
performances of P$^3$ Ranker in few-shot ranking. Analyses reveal that P$^3$
Ranker is able to better accustom to the ranking task through prompt-based
learning and retrieve necessary ranking-oriented knowledge gleaned in
pre-finetuning, resulting in data-efficient PLM adaptation. Our code is
available at \url{https://github.com/NEUIR/P3Ranker}.",-0.24646646,0.0899394,-0.07893526,A
5731,"Multi-task pre-finetuning
tialized from three officially released pre-trained T5 checkpoints:     for ranking needs further study.","The mixture of the two tasks
                                                                        doesn‚Äôt bring significant improvements.","T5 (Vanilla), T5 (LM-Adapt) and T5 (Multi-task).",2022-05-04 04:23:29+00:00,P^3 Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning,cs.IR,"['cs.IR', 'cs.CL', 'H.3.3']","[arxiv.Result.Author('Xiaomeng Hu'), arxiv.Result.Author('Shi Yu'), arxiv.Result.Author('Chenyan Xiong'), arxiv.Result.Author('Zhenghao Liu'), arxiv.Result.Author('Zhiyuan Liu'), arxiv.Result.Author('Ge Yu')]","Compared to other language tasks, applying pre-trained language models (PLMs)
for search ranking often requires more nuances and training signals. In this
paper, we identify and study the two mismatches between pre-training and
ranking fine-tuning: the training schema gap regarding the differences in
training objectives and model architectures, and the task knowledge gap
considering the discrepancy between the knowledge needed in ranking and that
learned during pre-training. To mitigate these gaps, we propose Pre-trained,
Prompt-learned and Pre-finetuned Neural Ranker (P^3 Ranker). P^3 Ranker
leverages prompt-based learning to convert the ranking task into a pre-training
like schema and uses pre-finetuning to initialize the model on intermediate
supervised tasks. Experiments on MS MARCO and Robust04 show the superior
performances of P^3 Ranker in few-shot ranking. Analyses reveal that P^3 Ranker
is able to better accustom to the ranking task through prompt-based learning
and retrieve necessary ranking-oriented knowledge gleaned in pre-finetuning,
resulting in data-efficient PLM adaptation. Our code is available at
https://github.com/NEUIR/P3Ranker.",-0.24646646,0.0899394,-0.07893526,A
5829,"Similarly with wh-words, we trained on ùë§‚Ñéùëé,             makes it interesting to further study model generalization.","This also shows that
therefore creates a zero-shot experiment on ùê∂ùëñ , as its distribution         the proposed clustering exhibits different levels of difficulty, which
was out-of-training.",‚Ñéùëúùë§ and ùë§‚Ñéùëú and tested each time on resp.,2022-05-05 18:13:06+00:00,Toward A Fine-Grained Analysis of Distribution Shifts in MSMARCO,cs.IR,['cs.IR'],"[arxiv.Result.Author('Simon Lupart'), arxiv.Result.Author('St√©phane Clinchant')]","Recent IR approaches based on Pretrained Language Models (PLM) have now
largely outperformed their predecessors on a variety of IR tasks. However, what
happens to learned word representations with distribution shifts remains
unclear. Recently, the BEIR benchmark was introduced to assess the performance
of neural rankers in zero-shot settings and revealed deficiencies for several
models. In complement to BEIR, we propose to control \textit{explicitly}
distribution shifts. We selected different query subsets leading to different
distribution shifts: short versus long queries, wh-words types of queries and 5
topic-based clusters. Then, we benchmarked state of the art neural rankers such
as dense Bi-Encoder, SPLADE and ColBERT under these different training and test
conditions. Our study demonstrates that it is possible to design distribution
shift experiments within the MSMARCO collection, and that the query subsets we
selected constitute an additional benchmark to better study factors of
generalization for various models.",-0.20765439,0.16444376,-0.016602445,A
6111,"Accompanying this
                                        work, we open source a large Twitter follow-graph dataset, to spur further research in graph-mining and representation learning for
                                        recommender systems.","We experimentally compare kNN-Embed to standard ANN candidate
                                        retrieval, and show significant improvements in overall recall and improved diversity across three datasets.","1 INTRODUCTION

                                        Recommendation systems for online services such as search engines or social networks present users with content and
                                        suggestions in the form of ranked lists of items [2, 7, 26].",2022-05-12 16:42:24+00:00,kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Ahmed El-Kishky'), arxiv.Result.Author('Thomas Markovich'), arxiv.Result.Author('Kenny Leung'), arxiv.Result.Author('Frank Portman'), arxiv.Result.Author('Aria Haghighi')]","Candidate generation is the first stage in recommendation systems, where a
light-weight system is used to retrieve potentially relevant items for an input
user. These candidate items are then ranked and pruned in later stages of
recommender systems using a more complex ranking model. Since candidate
generation is the top of the recommendation funnel, it is important to retrieve
a high-recall candidate set to feed into downstream ranking models. A common
approach for candidate generation is to leverage approximate nearest neighbor
(ANN) search from a single dense query embedding; however, this approach this
can yield a low-diversity result set with many near duplicates. As users often
have multiple interests, candidate retrieval should ideally return a diverse
set of candidates reflective of the user's multiple interests. To this end, we
introduce kNN-Embed, a general approach to improving diversity in dense
ANN-based retrieval. kNN-Embed represents each user as a smoothed mixture over
learned item clusters that represent distinct `interests' of the user. By
querying each of a user's mixture component in proportion to their mixture
weights, we retrieve a high-diversity set of candidates reflecting elements
from each of a user's interests. We experimentally compare kNN-Embed to
standard ANN candidate retrieval, and show significant improvements in overall
recall and improved diversity across three datasets. Accompanying this work, we
open source a large Twitter follow-graph dataset, to spur further research in
graph-mining and representation learning for recommender systems.",0.1528737,-0.037252504,0.5320593,A
6112,"Accompanying this
                                        work, we open source a large Twitter follow-graph dataset, to spur further research in graph-mining and representation learning for
                                        recommender systems.","We experimentally compare kNN-Embed to standard ANN candidate
                                        retrieval, and show significant improvements in overall recall and improved diversity across three datasets.","1 INTRODUCTION

                                        Recommendation systems for online services such as search engines or social networks present users with content and
                                        suggestions in the form of ranked lists of items [2, 7, 26].",2022-05-12 16:42:24+00:00,kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interest Candidate Retrieval,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Ahmed El-Kishky'), arxiv.Result.Author('Thomas Markovich'), arxiv.Result.Author('Kenny Leung'), arxiv.Result.Author('Frank Portman'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ying Xiao')]","Candidate generation is the first stage in recommendation systems, where a
light-weight system is used to retrieve potentially relevant items for an input
user. These candidate items are then ranked and pruned in later stages of
recommender systems using a more complex ranking model. Since candidate
generation is the top of the recommendation funnel, it is important to retrieve
a high-recall candidate set to feed into downstream ranking models. A common
approach for candidate generation is to leverage approximate nearest neighbor
(ANN) search from a single dense query embedding; however, this approach this
can yield a low-diversity result set with many near duplicates. As users often
have multiple interests, candidate retrieval should ideally return a diverse
set of candidates reflective of the user's multiple interests. To this end, we
introduce kNN-Embed, a general approach to improving diversity in dense
ANN-based retrieval. kNN-Embed represents each user as a smoothed mixture over
learned item clusters that represent distinct `interests' of the user. By
querying each of a user's mixture component in proportion to their mixture
weights, we retrieve a high-diversity set of candidates reflecting elements
from each of a user's interests. We experimentally compare kNN-Embed to
standard ANN candidate retrieval, and show significant improvements in overall
recall and improved diversity across three datasets. Accompanying this work, we
open source a large Twitter follow-graph dataset, to spur further research in
graph-mining and representation learning for recommender systems.",0.1528737,-0.037252504,0.5320593,A
6122,"Our research into other architectures
and regularization methods conÔ¨Årm that further improvements to DeepCoNN
are available and further research into this model is certainly warranted.","We conclude that the DeepCoNN model shows superior performance over
standard collaborative Ô¨Åltering techniques.","References

 1.",2022-05-12 18:18:45+00:00,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Aristeidis Karras'), arxiv.Result.Author('Christos Karras')]","User evaluations include a significant quantity of information across online
platforms. This information source has been neglected by the majority of
existing recommendation systems, despite its potential to ease the sparsity
issue and enhance the quality of suggestions. This work presents a deep model
for concurrently learning item attributes and user behaviour from review text.
Deep Cooperative Neural Networks (DeepCoNN) is the suggested model consisting
of two parallel neural networks connected in their final layers. One of the
networks focuses on learning user behaviour from reviews submitted by the user,
while the other network learns item attributes from user reviews. On top, a
shared layer is added to connect these two networks. Similar to factorization
machine approaches, the shared layer allows latent factors acquired for people
and things to interact with each other. On a number of datasets, DeepCoNN
surpasses all baseline recommendation systems, according to experimental
findings.",-0.39707506,0.007020388,0.34239084,A
6123,"Our investigation into diÔ¨Äerent architectures and regularisation
techniques conÔ¨Årms that more improvements to DeepCoNN are possible and that
further study of this model is necessary.","We Ô¨Ånd that the DeepCoNN model outperforms traditional collaborative Ô¨Ål-
tering strategies.","Movie Recommendation using Deep Cooperative Neural Networks  13

References

 1.",2022-05-12 18:18:45+00:00,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Aristeidis Karras'), arxiv.Result.Author('Christos Karras')]","User evaluations include a significant quantity of information across online
platforms. This information source has been neglected by the majority of
existing recommendation systems, despite its potential to ease the sparsity
issue and enhance the quality of suggestions. This work presents a deep model
for concurrently learning item attributes and user behaviour from review text.
Deep Cooperative Neural Networks (DeepCoNN) is the suggested model consisting
of two parallel neural networks connected in their final layers. One of the
networks focuses on learning user behaviour from reviews submitted by the user,
while the other network learns item attributes from user reviews. On top, a
shared layer is added to connect these two networks. Similar to factorization
machine approaches, the shared layer allows latent factors acquired for people
and things to interact with each other. On a number of datasets, DeepCoNN
surpasses all baseline recommendation systems, according to experimental
findings.",-0.24651137,-0.020525087,0.41667694,A
6124,"Our investigation into diÔ¨Äerent architectures and regular-
isation techniques conÔ¨Årms that more improvements to DeepCoNN are possible
and that further study of this model is necessary.","We conclude that the DeepCoNN model outperforms traditional collabora-
tive Ô¨Åltering strategies.","Movie Ranking Prediction using Deep Cooperative Neural Networks  13

References

 1.",2022-05-12 18:18:45+00:00,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Ranking Prediction,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Aristeidis Karras'), arxiv.Result.Author('Christos Karras')]","User evaluations include a significant quantity of information across online
platforms. This information source has been neglected by the majority of
existing recommendation systems, despite its potential to ease the sparsity
issue and enhance the quality of suggestions. This work presents a deep model
for concurrently learning item attributes and user behaviour from review text.
Deep Cooperative Neural Network (DeepCoNN) is the suggested model consisting of
two parallel neural networks connected in their final layers. One of the
networks focuses on learning user behaviour from reviews submitted by the user,
while the other network learns item attributes from user reviews. On top, a
shared layer is added to connect these two networks. Similar to factorization
machine approaches, the shared layer allows latent factors acquired for people
and things to interact with each other. On a number of datasets, DeepCoNN
surpasses all baseline recommendation systems, according to experimental
findings.",-0.3358664,0.0120370295,0.39448693,A
6125,"Our investigation into diÔ¨Äerent architectures and regular-
isation techniques conÔ¨Årms that more improvements to DeepCoNN are possible
and that further study of this model is necessary.","We conclude that the DeepCoNN model outperforms traditional collabora-
tive Ô¨Åltering strategies.","Movie Ranking Prediction using Deep Cooperative Neural Networks  13

References

 1.",2022-05-12 18:18:45+00:00,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Ranking Prediction,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Aristeidis Karras'), arxiv.Result.Author('Christos Karras')]","User evaluations include a significant quantity of information across online
platforms. This information source has been neglected by the majority of
existing recommendation systems, despite its potential to ease the sparsity
issue and enhance the quality of suggestions. This work presents a deep model
for concurrently learning item attributes and user behaviour from review text.
Deep Cooperative Neural Network (DeepCoNN) is the suggested model consisting of
two parallel neural networks connected in their final layers. One of the
networks focuses on learning user behaviour from reviews submitted by the user,
while the other network learns item attributes from user reviews. On top, a
shared layer is added to connect these two networks. Similar to factorization
machine approaches, the shared layer allows latent factors acquired for people
and things to interact with each other. On a number of datasets, DeepCoNN
surpasses all baseline recommendation systems, according to experimental
findings.",-0.3358664,0.0120370295,0.39448693,A
6126,"Our investigation into diÔ¨Äerent architectures and regular-
isation techniques conÔ¨Årms that more improvements to DeepCoNN are possible
and that further study of this model is necessary.","We conclude that the DeepCoNN model outperforms traditional collabora-
tive Ô¨Åltering strategies.","Movie Recommendation using Deep Cooperative Neural Networks  13

References

 1.",2022-05-12 18:18:45+00:00,Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Aristeidis Karras'), arxiv.Result.Author('Christos Karras')]","User evaluations include a significant quantity of information across online
platforms. This information source has been neglected by the majority of
existing recommendation systems, despite its potential to ease the sparsity
issue and enhance the quality of suggestions. This work presents a deep model
for concurrently learning item attributes and user behaviour from review text.
Deep Cooperative Neural Network (DeepCoNN) is the suggested model consisting of
two parallel neural networks connected in their final layers. One of the
networks focuses on learning user behaviour from reviews submitted by the user,
while the other network learns item attributes from user reviews. On top, a
shared layer is added to connect these two networks. Similar to factorization
machine approaches, the shared layer allows latent factors acquired for people
and things to interact with each other. On a number of datasets, DeepCoNN
surpasses all baseline recommendation systems, according to experimental
findings.",-0.33486477,0.011013472,0.40867102,A
6151,"In this subsection, we further study whether our DCR-MoE truly eliminates the impact of
the confounding feature by conducting an analysis of the model predictions.","5.4 RQ3: Prediction Analyses

The performance study has shown the superiority of DCR-MoE regarding overall recommendation
accuracy.","Specifically, we first
divide items into different groups according to the values of ùê¥, 1such that items with the same value
of the confounding feature belong to a group.",2022-05-13 09:35:06+00:00,Addressing Confounding Feature Issue for Causal Recommendation,cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Xiangnan He'), arxiv.Result.Author('Yang Zhang'), arxiv.Result.Author('Fuli Feng'), arxiv.Result.Author('Chonggang Song'), arxiv.Result.Author('Lingling Yi'), arxiv.Result.Author('Guohui Ling'), arxiv.Result.Author('Yongdong Zhang')]","In recommender system, some feature directly affects whether an interaction
would happen, making the happened interactions not necessarily indicate user
preference. For instance, short videos are objectively easier to be finished
even though the user does not like the video. We term such feature as
confounding feature, and video length is a confounding feature in video
recommendation. If we fit a model on such interaction data, just as done by
most data-driven recommender systems, the model will be biased to recommend
short videos more, and deviate from user actual requirement.
  This work formulates and addresses the problem from the causal perspective.
Assuming there are some factors affecting both the confounding feature and
other item features, e.g., the video creator, we find the confounding feature
opens a backdoor path behind user item matching and introduces spurious
correlation. To remove the effect of backdoor path, we propose a framework
named Deconfounding Causal Recommendation (DCR), which performs intervened
inference with do-calculus. Nevertheless, evaluating do calculus requires to
sum over the prediction on all possible values of confounding feature,
significantly increasing the time cost. To address the efficiency challenge, we
further propose a mixture-of experts (MoE) model architecture, modeling each
value of confounding feature with a separate expert module. Through this way,
we retain the model expressiveness with few additional costs. We demonstrate
DCR on the backbone model of neural factorization machine (NFM), showing that
DCR leads to more accurate prediction of user preference with small inference
time cost.",0.062113866,-0.3262683,0.14882353,A
6152,"In this subsection, we further study whether our DCR-MoE truly eliminates the impact of
the confounding feature by conducting an analysis of the model predictions.","5.4 RQ3: Prediction Analyses

The performance study has shown the superiority of DCR-MoE regarding overall recommendation
accuracy.","Specifically, we first
divide items into different groups according to the values of ùê¥, such that items with the same value
of the confounding feature belong to a group.",2022-05-13 09:35:06+00:00,Addressing Confounding Feature Issue for Causal Recommendation,cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Xiangnan He'), arxiv.Result.Author('Yang Zhang'), arxiv.Result.Author('Fuli Feng'), arxiv.Result.Author('Chonggang Song'), arxiv.Result.Author('Lingling Yi'), arxiv.Result.Author('Guohui Ling'), arxiv.Result.Author('Yongdong Zhang')]","In recommender system, some feature directly affects whether an interaction
would happen, making the happened interactions not necessarily indicate user
preference. For instance, short videos are objectively easier to be finished
even though the user does not like the video. We term such feature as
confounding feature, and video length is a confounding feature in video
recommendation. If we fit a model on such interaction data, just as done by
most data-driven recommender systems, the model will be biased to recommend
short videos more, and deviate from user actual requirement.
  This work formulates and addresses the problem from the causal perspective.
Assuming there are some factors affecting both the confounding feature and
other item features, e.g., the video creator, we find the confounding feature
opens a backdoor path behind user item matching and introduces spurious
correlation. To remove the effect of backdoor path, we propose a framework
named Deconfounding Causal Recommendation (DCR), which performs intervened
inference with do-calculus. Nevertheless, evaluating do calculus requires to
sum over the prediction on all possible values of confounding feature,
significantly increasing the time cost. To address the efficiency challenge, we
further propose a mixture-of experts (MoE) model architecture, modeling each
value of confounding feature with a separate expert module. Through this way,
we retain the model expressiveness with few additional costs. We demonstrate
DCR on the backbone model of neural factorization machine (NFM), showing that
DCR leads to more accurate prediction of user preference with small inference
time cost.",0.056523986,-0.32921422,0.15013558,A
6311,"We further study whether dividing users
For instance, Ferraro et al.",provement of fairness.,"[13] propose a re-ranking algorithm for       into groups based on a cutoff (e.g., top 5%) can create two cat-
user-oriented fairness, where they only evaluate the performance           egories of (dis)advantaged users in a meaningful way across
of their method on one type of bias and domain i.e., gender and            various domains.",2022-05-17 12:36:30+00:00,Experiments on Generalizability of User-Oriented Fairness in Recommender Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Hossein A. Rahmani'), arxiv.Result.Author('Mohammadmehdi Naghiaei'), arxiv.Result.Author('Mahdi Dehghan'), arxiv.Result.Author('Mohammad Aliannejadi')]","Recent work in recommender systems mainly focuses on fairness in
recommendations as an important aspect of measuring recommendations quality. A
fairness-aware recommender system aims to treat different user groups
similarly. Relevant work on user-oriented fairness highlights the
discriminative behavior of fairness-unaware recommendation algorithms towards a
certain user group, defined based on users' activity level. Typical solutions
include proposing a user-centered fairness re-ranking framework applied on top
of a base ranking model to mitigate its unfair behavior towards a certain user
group i.e., disadvantaged group. In this paper, we re-produce a user-oriented
fairness study and provide extensive experiments to analyze the dependency of
their proposed method on various fairness and recommendation aspects, including
the recommendation domain, nature of the base ranking model, and user grouping
method. Moreover, we evaluate the final recommendations provided by the
re-ranking framework from both user- (e.g., NDCG, user-fairness) and item-side
(e.g., novelty, item-fairness) metrics. We discover interesting trends and
trade-offs between the model's performance in terms of different evaluation
metrics. For instance, we see that the definition of the
advantaged/disadvantaged user groups plays a crucial role in the effectiveness
of the fairness algorithm and how it improves the performance of specific base
ranking models. Finally, we highlight some important open challenges and future
directions in this field. We release the data, evaluation pipeline, and the
trained models publicly on https://github.com/rahmanidashti/FairRecSys.",0.28044066,-0.2316795,-0.05868425,B
6380,"This information provides health professionals the knowledge acquired in other situations
so it may be applied to individual patients or used to conduct further research.","The second type of classiÔ¨Åcation is related to
the information that derives and is organized from observational and experimental research.","Similarly
to other types of scientiÔ¨Åc information, the knowledge-based information can be subdivided
in primary information (direct results of original research that appears in papers, journals
or other sources) and secondary information (reviews, condensations, summaries of primary
literature like books, monographs, review papers, clinical guidelines, health information on
web pages and other sources).",2022-05-18 17:19:16+00:00,Health Information Retrieval -- State of the art report,cs.IR,"['cs.IR', 'H.3.3']",[arxiv.Result.Author('Carla Teixeira Lopes')],"This report provides an overview of the field of Information Retrieval (IR)
in healthcare. It does not aim to introduce general concepts and theories of IR
but to present and describe specific aspects of Health Information Retrieval
(HIR). After a brief introduction to the more broader field of IR, the
significance of HIR at current times is discussed. Specific characteristics of
Health Information, its classification and the main existing representations
for health concepts are described together with the main products and services
in the area (e.g.: databases of health bibliographic content, health specific
search engines and others). Recent research work is discussed and the most
active researchers, projects and research groups are also presented. Main
organizations and journals are also identified.",0.20534408,0.33820206,-0.23128027,C
6537,"to fill in these gaps so as to facilitate further research in this exciting
and vibrant area.","This part will discuss some of the
      Figure 1: Session data vs. sequence data, from [12]                      most promising directions in the area and conclude this tutorial.","4 BACKGROUND AND PROBLEM
                                                                                 STATEMENT
2 RELATED WORK
                                                                             4.1 SRSs vs SBRSs
There are some surveys and tutorials focusing on the topic of SRSs
or SBRSs.",2022-05-22 06:17:36+00:00,"Sequential/Session-based Recommendations: Challenges, Approaches, Applications and Opportunities",cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Shoujin Wang'), arxiv.Result.Author('Qi Zhang'), arxiv.Result.Author('Liang Hu'), arxiv.Result.Author('Xiuzhen Zhang'), arxiv.Result.Author('Yan Wang'), arxiv.Result.Author('Charu Aggarwal')]","In recent years, sequential recommender systems (SRSs) and session-based
recommender systems (SBRSs) have emerged as a new paradigm of RSs to capture
users' short-term but dynamic preferences for enabling more timely and accurate
recommendations. Although SRSs and SBRSs have been extensively studied, there
are many inconsistencies in this area caused by the diverse descriptions,
settings, assumptions and application domains. There is no work to provide a
unified framework and problem statement to remove the commonly existing and
various inconsistencies in the area of SR/SBR. There is a lack of work to
provide a comprehensive and systematic demonstration of the data
characteristics, key challenges, most representative and state-of-the-art
approaches, typical real-world applications and important future research
directions in the area. This work aims to fill in these gaps so as to
facilitate further research in this exciting and vibrant area.",-0.076371044,0.102772005,-0.23698531,A
6564,Our analysis of the current research landscape points to a number of further research gaps.,Future Directions.,"Con-
sidering the type of contributions and the different notions of fairness, we Ô¨Ånd that today‚Äôs research efforts are not

                                                                     26
balanced.",2022-05-23 08:34:25+00:00,A Survey of Research on Fair Recommender Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Yashar Deldjoo'), arxiv.Result.Author('Dietmar Jannach'), arxiv.Result.Author('Alejandro Bellogin'), arxiv.Result.Author('Alessandro Difonzo'), arxiv.Result.Author('Dario Zanzonelli')]","Recommender systems can strongly influence which information we see online,
e.g, on social media, and thus impact our beliefs, decisions, and actions. At
the same time, these systems can create substantial business value for
different stakeholders. Given the growing potential impact of such AI-based
systems on individuals, organizations, and society, questions of fairness have
gained increased attention in recent years. However, research on fairness in
recommender systems is still a developing area. In this survey, we first review
the fundamental concepts and notions of fairness that were put forward in the
area in the recent past. Afterward, we provide a survey of how research in this
area is currently operationalized, for example, in terms of the general
research methodology, fairness metrics, and algorithmic approaches. Overall,
our analysis of recent works points to certain research gaps. In particular, we
find that in many research works in computer science very abstract problem
operationalizations are prevalent, which circumvent the fundamental and
important question of what represents a fair recommendation in the context of a
given application.",0.35008353,0.014765546,-0.37602746,B
6565,Our analysis of the current research landscape points to a number of further research gaps.,Future Directions.,"Con-
sidering the type of contributions and the different notions of fairness, we Ô¨Ånd that today‚Äôs research efforts are not
balanced.",2022-05-23 08:34:25+00:00,A Survey of Research on Fair Recommender Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Yashar Deldjoo'), arxiv.Result.Author('Dietmar Jannach'), arxiv.Result.Author('Alejandro Bellogin'), arxiv.Result.Author('Alessandro Difonzo'), arxiv.Result.Author('Dario Zanzonelli')]","Recommender systems can strongly influence which information we see online,
e.g, on social media, and thus impact our beliefs, decisions, and actions. At
the same time, these systems can create substantial business value for
different stakeholders. Given the growing potential impact of such AI-based
systems on individuals, organizations, and society, questions of fairness have
gained increased attention in recent years. However, research on fairness in
recommender systems is still a developing area. In this survey, we first review
the fundamental concepts and notions of fairness that were put forward in the
area in the recent past. Afterward, we provide a survey of how research in this
area is currently operationalized, for example, in terms of the general
research methodology, fairness metrics, and algorithmic approaches. Overall,
our analysis of recent works points to certain research gaps. In particular, we
find that in many research works in computer science very abstract problem
operationalizations are prevalent, which circumvent the fundamental and
important question of what represents a fair recommendation in the context of a
given application.",0.36602393,0.02171567,-0.3881111,B
6566,"Future Directions Our analysis of the current research landscape points to a
number of further research gaps.","While general-purpose solutions are certainly desirable, the danger of being
stuck in an abstraction trap with limited practical impact increases [78, 135].","Considering the type of contributions and
the diÔ¨Äerent notions of fairness, we Ô¨Ånd that today‚Äôs research eÔ¨Äorts are not
balanced.",2022-05-23 08:34:25+00:00,Fairness in Recommender Systems: Research Landscape and Future Directions,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Yashar Deldjoo'), arxiv.Result.Author('Dietmar Jannach'), arxiv.Result.Author('Alejandro Bellogin'), arxiv.Result.Author('Alessandro Difonzo'), arxiv.Result.Author('Dario Zanzonelli')]","Recommender systems can strongly influence which information we see online,
e.g., on social media, and thus impact our beliefs, decisions, and actions. At
the same time, these systems can create substantial business value for
different stakeholders. Given the growing potential impact of such AI-based
systems on individuals, organizations, and society, questions of fairness have
gained increased attention in recent years. However, research on fairness in
recommender systems is still a developing area. In this survey, we first review
the fundamental concepts and notions of fairness that were put forward in the
area in the recent past.
  Afterward, through a review of more than 150 scholarly publications, we
present an overview of how research in this field is currently operationalized,
e.g., in terms of general research methodology, fairness measures, and
algorithmic approaches. Overall, our analysis of recent works points to
specific research gaps. In particular, we find that in many research works in
computer science, very abstract problem operationalizations are prevalent, and
questions of the underlying normative claims and what represents a fair
recommendation in the context of a given application are often not discussed in
depth. These observations call for more interdisciplinary research to address
fairness in recommendation in a more comprehensive and impactful manner.",0.3176914,0.07742724,-0.32174152,B
6654,"The dataset and implementation of the            2 RELATED WORK
proposed model have been made available to the public 5, aiming
to facilitate further research on meal recommendation.","model and demonstrate MealRec as a good testbed for meal recom-
mendation related research.","2.1 Bundle Recommendation

   The contributions delivered by this work are summarized below:            Bundle Recommendation problem refers to predict a user‚Äôs prefer-
                                                                             ence on a bundle rather than an individual item [36].",2022-05-24 15:09:43+00:00,MealRec: A Meal Recommendation Dataset,cs.IR,['cs.IR'],"[arxiv.Result.Author('Ming Li'), arxiv.Result.Author('Lin Li'), arxiv.Result.Author('Qing Xie'), arxiv.Result.Author('Jingling Yuan'), arxiv.Result.Author('Xiaohui Tao')]","Bundle recommendation systems aim to recommend a bundle of items for a user
to consider as a whole. They have become a norm in modern life and have been
applied to many real-world settings, such as product bundle recommendation,
music playlist recommendation and travel package recommendation. However,
compared to studies of bundle recommendation approaches in areas such as online
shopping and digital music services, research on meal recommendations for
restaurants in the hospitality industry has made limited progress, due largely
to the lack of high-quality benchmark datasets. A publicly available dataset
specialising in meal recommendation research for the research community is in
urgent demand. In this paper, we introduce a meal recommendation dataset
(MealRec) that aims to facilitate future research. MealRec is constructed from
the user review records of Allrecipe.com, covering 1,500+ users, 7,200+ recipes
and 3,800+ meals. Each recipe is described with rich information, such as
ingredients, instructions, pictures, category and tags, etc; and each meal is
three-course, consisting of an appetizer, a main dish and a dessert.
Furthermore, we propose a category-constrained meal recommendation model that
is evaluated through comparative experiments with several state-of-the-art
bundle recommendation methods on MealRec. Experimental results confirm the
superiority of our model and demonstrate that MealRec is a promising testbed
for meal recommendation related research.
  The MealRec dataset and the source code of our proposed model are available
at https://github.com/WUT-IDEA/MealRec for access and reproducibility.",0.18551356,-0.26931882,0.17675292,B
6747,"4.3 Ablation Study (RQ2)
To further study the CRGCN model, we conduct extensive ablation studies to examine the effectiveness of different
components for the final performance.","Overall, we can have the following conclusions based on the performance comparisons among all the adopted
methods: 1) multi-behavior information is very useful for preference modeling and can help recommendation models
make much more accurate predictions; 2) the cascading effect of different behaviors is important for multi-behavior
recommendation methods to accurately model user preferences; 3) the way of modeling the cascading effects is also
important and can make a big difference on the recommendation performance.",We analyze the contributions of each component from the following aspects.,2022-05-26 03:25:45+00:00,Cascading Residual Graph Convolutional Network for Multi-Behavior Recommendation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Mingshi Yan'), arxiv.Result.Author('Zhiyong Cheng'), arxiv.Result.Author('Chen Gao'), arxiv.Result.Author('Jing Sun'), arxiv.Result.Author('Fan Liu'), arxiv.Result.Author('Fuming Sun'), arxiv.Result.Author('Haojie Li')]","Multi-behavior recommendation exploits multiple types of user-item
interactions to alleviate the data sparsity problem faced by the traditional
models that often utilize only one type of interaction for recommendation. In
real scenarios, users often take a sequence of actions to interact with an
item, in order to get more information about the item and thus accurately
evaluate whether an item fits personal preference. Those interaction behaviors
often obey a certain order, and different behaviors reveal different
information or aspects of user preferences towards the target item. Most
existing multi-behavior recommendation methods take the strategy to first
extract information from different behaviors separately and then fuse them for
final prediction. However, they have not exploited the connections between
different behaviors to learn user preferences. Besides, they often introduce
complex model structures and more parameters to model multiple behaviors,
largely increasing the space and time complexity. In this work, we propose a
lightweight multi-behavior recommendation model named Cascading Residual Graph
Convolutional Network (CRGCN for short), which can explicitly exploit the
connections between different behaviors into the embedding learning process
without introducing any additional parameters. In particular, we design a
cascading residual graph convolutional network structure, which enables our
model to learn user preferences by continuously refining user embeddings across
different types of behaviors. The multi-task learning method is adopted to
jointly optimize our model based on different behaviors. Extensive experimental
results on two real-world benchmark datasets show that CRGCN can substantially
outperform state-of-the-art methods. Further studies also analyze the effects
of leveraging multi-behaviors in different numbers and orders on the final
performance.",0.0998924,-0.39192003,0.08594732,A
6899,"For further study, we may link the resampled ratio with Œª, instead
of resampling half of the items from the cache and the batch.","When Œª = 0.5, the cached items and inbatch items
contribute equally to convergence.","17
0.150                              0.080                              0.075                              0.180                              0.066     RECALL@10
0.140                              0.060                              0.070                              0.170                              0.064     NDCG@10
0.130                              0.040                              0.065                              0.160                              0.062
0.120                                                                 0.060                                                                 0.060

0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0                0.0 0.2 0.5 0.8 1.0
                   Œª                                  Œª                                  Œª                                  Œª                                  Œª

       (a) Gowalla                        (b) Amazon                            (c) Ta-feng                     (d) Echonest                          (e) Tmall

                                                      Figure 6: Effect of Œª

0.160     512 1024 2048 4096 8192  0.095     512 1024 2048 4096 8192  0.090     512 1024 2048 4096 8192  0.160     512 1024 2048 4096 8192  0.067           SSL-Pop
                Batch Size                         Batch Size         0.088           Batch Size         0.150           Batch Size         0.066           BIR
0.155                              0.090                              0.086                                                                 0.065
                                                                      0.084                                   256                           0.064     512 1024 2048 4096 8192
0.150                              0.085                              0.082                                                                                 Batch Size
                                        256                                                                                                      256
0.145                                                                      256
     256

       (a) Gowalla                        (b) Amazon                         (c) Ta-feng                 (d) Echonest                                 (e) Tmall

                                             Figure 7: NDCG@10 vs. Batch Size

B.3 Varying batch sizes

In this chapter, we further explore BIR by taking a look at how NDCG@10 changes under different
batch sizes, i.e., |B|.",2022-05-30 05:29:39+00:00,Cache-Augmented Inbatch Importance Resampling for Training Recommender Retriever,cs.IR,['cs.IR'],"[arxiv.Result.Author('Jin Chen'), arxiv.Result.Author('Defu Lian'), arxiv.Result.Author('Yucheng Li'), arxiv.Result.Author('Baoyun Wang'), arxiv.Result.Author('Kai Zheng'), arxiv.Result.Author('Enhong Chen')]","Recommender retrievers aim to rapidly retrieve a fraction of items from the
entire item corpus when a user query requests, with the representative
two-tower model trained with the log softmax loss. For efficiently training
recommender retrievers on modern hardwares, inbatch sampling, where the items
in the mini-batch are shared as negatives to estimate the softmax function, has
attained growing interest. However, existing inbatch sampling based strategies
just correct the sampling bias of inbatch items with item frequency, being
unable to distinguish the user queries within the mini-batch and still
incurring significant bias from the softmax. In this paper, we propose a
Cache-Augmented Inbatch Importance Resampling (XIR) for training recommender
retrievers, which not only offers different negatives to user queries with
inbatch items, but also adaptively achieves a more accurate estimation of the
softmax distribution. Specifically, XIR resamples items for the given
mini-batch training pairs based on certain probabilities, where a cache with
more frequently sampled items is adopted to augment the candidate item set,
with the purpose of reusing the historical informative samples. XIR enables to
sample query-dependent negatives based on inbatch items and to capture dynamic
changes of model training, which leads to a better approximation of the softmax
and further contributes to better convergence. Finally, we conduct experiments
to validate the superior performance of the proposed XIR compared with
competitive approaches.",-0.28342363,-0.21763295,-0.13020778,A
6904,We will release our datasets to facilitate further research.,", ùë† | Os | and candidate template set
        effort to improve promotion effect in real world applications.","Ot = ùë°1, ùë°2, .",2022-05-30 10:15:16+00:00,Towards Personalized Bundle Creative Generation with Contrastive Non-Autoregressive Decoding,cs.IR,['cs.IR'],"[arxiv.Result.Author('Penghui Wei'), arxiv.Result.Author('Shaoguo Liu'), arxiv.Result.Author('Xuanhua Yang'), arxiv.Result.Author('Liang Wang'), arxiv.Result.Author('Bo Zheng')]","Current bundle generation studies focus on generating a combination of items
to improve user experience. In real-world applications, there is also a great
need to produce bundle creatives that consist of mixture types of objects
(e.g., items, slogans and templates) for achieving better promotion effect. We
study a new problem named bundle creative generation: for given users, the goal
is to generate personalized bundle creatives that the users will be interested
in. To take both quality and efficiency into account, we propose a contrastive
non-autoregressive model that captures user preferences with ingenious decoding
objective. Experiments on large-scale real-world datasets verify that our
proposed model shows significant advantages in terms of creative quality and
generation speed.",0.082556084,-0.11103009,-0.19045924,B
6905,We will release our datasets to facilitate further research.,", ùë† | Os | and candidate template set
        effort to improve promotion effect in real world applications.","Ot = ùë°1, ùë°2, .",2022-05-30 10:15:16+00:00,Towards Personalized Bundle Creative Generation with Contrastive Non-Autoregressive Decoding,cs.IR,['cs.IR'],"[arxiv.Result.Author('Penghui Wei'), arxiv.Result.Author('Shaoguo Liu'), arxiv.Result.Author('Xuanhua Yang'), arxiv.Result.Author('Liang Wang'), arxiv.Result.Author('Bo Zheng')]","Current bundle generation studies focus on generating a combination of items
to improve user experience. In real-world applications, there is also a great
need to produce bundle creatives that consist of mixture types of objects
(e.g., items, slogans and templates) for achieving better promotion effect. We
study a new problem named bundle creative generation: for given users, the goal
is to generate personalized bundle creatives that the users will be interested
in. To take both quality and efficiency into account, we propose a contrastive
non-autoregressive model that captures user preferences with ingenious decoding
objective. Experiments on large-scale real-world datasets verify that our
proposed model shows significant advantages in terms of creative quality and
generation speed.",0.082556084,-0.11103009,-0.19045924,B
7196,"Finally, we will further study                           Maximization for Learning Determinantal Point Processes,‚Äù in Proc.","A. Gillenwater, A. Kulesza, E. Fox, and B. Taskar, ‚ÄúExpectation-
feature representation method.",Adv.,2022-06-02 06:53:23+00:00,DCAN: Diversified News Recommendation with Coverage-Attentive Networks,cs.IR,['cs.IR'],"[arxiv.Result.Author('Hao Shi'), arxiv.Result.Author('Zi-Jiao Wang'), arxiv.Result.Author('Lan-Ru Zhai')]","Self-attention based models are widely used in news recommendation tasks.
However, previous Attention architecture does not constrain repeated
information in the user's historical behavior, which limits the power of hidden
representation and leads to some problems such as information redundancy and
filter bubbles. To solve this problem, we propose a personalized news
recommendation model called DCAN.It captures multi-grained user-news matching
signals through news encoders and user encoders. We keep updating a coverage
vector to track the history of news attention and augment the vector in 4 types
of ways. Then we fed the augmented Coverage vector into the Multi-headed
Self-attention model to help adjust the future attention and added the Coverage
regulation to the loss function(CRL), which enabled the recommendation system
to consider more about differentiated information. Extensive experiments on
Microsoft News Recommendation Dataset (MIND) show that our model significantly
improve the diversity of news recommendations with minimal sacrifice in
accuracy.",-0.15490046,0.020766672,-0.12786771,A
7333,"to manual annotation about the importance order of candidate
                                                                                 answers, enables further study on training and evaluating click
   In another analysis shown in Table 11, we ranked clarification                models for answer ranking in search clarification.","This information, in addition
candidate answers is high.","panes based on the Diversity, Understandability and Candidate An-
swer Order and compared the result with the ideal ranked lists                   7 CONCLUSIONS
based on the engagement level, quality labels and offline rating.",2022-06-09 11:10:22+00:00,MIMICS-Duo: Offline & Online Evaluation of Search Clarification,cs.IR,"['cs.IR', '68-06']","[arxiv.Result.Author('Leila Tavakoli'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Hamed Zamani'), arxiv.Result.Author('Falk Scholer'), arxiv.Result.Author('Mark Sanderson')]","Asking clarification questions is an active area of research; however,
resources for training and evaluating search clarification methods are not
sufficient. To address this issue, we describe MIMICS-Duo, a new freely
available dataset of 306 search queries with multiple clarifications (a total
of 1,034 query-clarification pairs). MIMICS-Duo contains fine-grained
annotations on clarification questions and their candidate answers and enhances
the existing MIMICS datasets by enabling multi-dimensional evaluation of search
clarification methods, including online and offline evaluation. We conduct
extensive analysis to demonstrate the relationship between offline and online
search clarification datasets and outline several research directions enabled
by MIMICS-Duo. We believe that this resource will help researchers better
understand clarification in search.",0.18243888,0.03110612,0.21013395,C
7860,"We further study whether our framework can
benefit from a single model; thus, we propose to jointly train lexical and semantic representations within a single
model.",This approach can be described as fusion of independent models.,Inspired by Gao et al.,2022-06-20 17:29:42+00:00,A Dense Representation Framework for Lexical and Semantic Matching,cs.IR,['cs.IR'],"[arxiv.Result.Author('Sheng-Chieh Lin'), arxiv.Result.Author('Jimmy Lin')]","Lexical and semantic matching capture different successful approaches to text
retrieval and the fusion of their results has proven to be more effective and
robust than either alone. Prior work performs hybrid retrieval by conducting
lexical and semantic text matching using different systems (e.g., Lucene and
Faiss, respectively) and then fusing their model outputs. In contrast, our work
integrates lexical representations with dense semantic representations by
densifying high-dimensional lexical representations into what we call
low-dimensional dense lexical representations (DLRs). Our experiments show that
DLRs can effectively approximate the original lexical representations,
preserving effectiveness while improving query latency. Furthermore, we can
combine dense lexical and semantic representations to generate dense hybrid
representations (DHRs) that are more flexible and yield faster retrieval
compared to existing hybrid techniques. Finally, we explore {\it jointly}
training lexical and semantic representations in a single model and empirically
show that the resulting DHRs are able to combine the advantages of each
individual component. Our best DHR model is competitive with state-of-the-art
single-vector and multi-vector dense retrievers in both in-domain and zero-shot
evaluation settings. Furthermore, our model is both faster and requires smaller
indexes, making our dense representation framework an attractive approach to
text retrieval. Our code is available at https://github.com/castorini/dhr.",-0.05507476,0.31854212,0.18938808,C
7861,"5.4 Performance of Two-Stage Retrieval

In this section, we further study our approach to end-to-end retrieval with DLRs/DHRs proposed in Section 3.4
to investigate our final research question:

RQ4 How effective is our proposed two-stage retrieval approach?",Recall comparison of approximate retrieval approaches at different cutoffs.,"To illustrate how well our proposed approximate GIP operation compares to the more expensive exact GIP
operation between DLRs (or DHRs), we use DeLADEDLR (768) and (DeLADE+[CLS])DHR (768) to conduct end-to-
end retrieval experiments on the MS MARCO dev queries.",2022-06-20 17:29:42+00:00,A Dense Representation Framework for Lexical and Semantic Matching,cs.IR,['cs.IR'],"[arxiv.Result.Author('Sheng-Chieh Lin'), arxiv.Result.Author('Jimmy Lin')]","Lexical and semantic matching capture different successful approaches to text
retrieval and the fusion of their results has proven to be more effective and
robust than either alone. Prior work performs hybrid retrieval by conducting
lexical and semantic text matching using different systems (e.g., Lucene and
Faiss, respectively) and then fusing their model outputs. In contrast, our work
integrates lexical representations with dense semantic representations by
densifying high-dimensional lexical representations into what we call
low-dimensional dense lexical representations (DLRs). Our experiments show that
DLRs can effectively approximate the original lexical representations,
preserving effectiveness while improving query latency. Furthermore, we can
combine dense lexical and semantic representations to generate dense hybrid
representations (DHRs) that are more flexible and yield faster retrieval
compared to existing hybrid techniques. Finally, we explore {\it jointly}
training lexical and semantic representations in a single model and empirically
show that the resulting DHRs are able to combine the advantages of each
individual component. Our best DHR model is competitive with state-of-the-art
single-vector and multi-vector dense retrievers in both in-domain and zero-shot
evaluation settings. Furthermore, our model is both faster and requires smaller
indexes, making our dense representation framework an attractive approach to
text retrieval. Our code is available at https://github.com/castorini/dhr.",-0.12955894,0.1505568,0.122440204,C
7968,"[22] further study the inÔ¨Çuence of some low-knowledge
B. Adversarial Attacks                                             attack approaches to promote an item (e.g., Random, Average,
                                                                   Bandwagon and Segment Attacks) and demote an item (e.g.,
   Investigating the security of machine learning based sys-       Love/Hate Attacks and Reverse Bandwagon Attacks) on CF
tems is a continuing concern within the machine learning
                                                                   4

methods.","[9], [21], Mobasher
                                                                   et al.","Assuming more knowledge and cost are available,                    real purchase.",2022-06-23 00:40:19+00:00,Shilling Black-box Recommender Systems by Learning to Generate Fake User Profiles,cs.IR,"['cs.IR', 'cs.CR', 'cs.LG']","[arxiv.Result.Author('Chen Lin'), arxiv.Result.Author('Si Chen'), arxiv.Result.Author('Meifang Zeng'), arxiv.Result.Author('Sheng Zhang'), arxiv.Result.Author('Min Gao'), arxiv.Result.Author('Hui Li')]","Due to the pivotal role of Recommender Systems (RS) in guiding customers
towards the purchase, there is a natural motivation for unscrupulous parties to
spoof RS for profits. In this paper, we study Shilling Attack where an
adversarial party injects a number of fake user profiles for improper purposes.
Conventional Shilling Attack approaches lack attack transferability (i.e.,
attacks are not effective on some victim RS models) and/or attack invisibility
(i.e., injected profiles can be easily detected). To overcome these issues, we
present Leg-UP, a novel attack model based on the Generative Adversarial
Network. Leg-UP learns user behavior patterns from real users in the sampled
``templates'' and constructs fake user profiles. To simulate real users, the
generator in Leg-UP directly outputs discrete ratings. To enhance attack
transferability, the parameters of the generator are optimized by maximizing
the attack performance on a surrogate RS model. To improve attack invisibility,
Leg-UP adopts a discriminator to guide the generator to generate undetectable
fake user profiles. Experiments on benchmarks have shown that Leg-UP exceeds
state-of-the-art Shilling Attack methods on a wide range of victim RS models.
The source code of our work is available at:
https://github.com/XMUDM/ShillingAttack.",-0.05025,-0.026564134,-0.057542894,B
7969,"To further study the attack invisibility
                                                                                                                          of Leg-UP, we visualize the real and fake user proÔ¨Åles using
                                                                                                                          the t-SNE projection [61] of the latent space.",Fake User Distribution.,Fig.,2022-06-23 00:40:19+00:00,Shilling Black-box Recommender Systems by Learning to Generate Fake User Profiles,cs.IR,"['cs.IR', 'cs.CR', 'cs.LG']","[arxiv.Result.Author('Chen Lin'), arxiv.Result.Author('Si Chen'), arxiv.Result.Author('Meifang Zeng'), arxiv.Result.Author('Sheng Zhang'), arxiv.Result.Author('Min Gao'), arxiv.Result.Author('Hui Li')]","Due to the pivotal role of Recommender Systems (RS) in guiding customers
towards the purchase, there is a natural motivation for unscrupulous parties to
spoof RS for profits. In this paper, we study Shilling Attack where an
adversarial party injects a number of fake user profiles for improper purposes.
Conventional Shilling Attack approaches lack attack transferability (i.e.,
attacks are not effective on some victim RS models) and/or attack invisibility
(i.e., injected profiles can be easily detected). To overcome these issues, we
present Leg-UP, a novel attack model based on the Generative Adversarial
Network. Leg-UP learns user behavior patterns from real users in the sampled
``templates'' and constructs fake user profiles. To simulate real users, the
generator in Leg-UP directly outputs discrete ratings. To enhance attack
transferability, the parameters of the generator are optimized by maximizing
the attack performance on a surrogate RS model. To improve attack invisibility,
Leg-UP adopts a discriminator to guide the generator to generate undetectable
fake user profiles. Experiments on benchmarks have shown that Leg-UP exceeds
state-of-the-art Shilling Attack methods on a wide range of victim RS models.
The source code of our work is available at:
https://github.com/XMUDM/ShillingAttack.",0.031130064,-0.05939452,-0.29951185,B
8119,A topic of further research would be to extend our model into the probabilistic landscape of RS.,"Our empirical results indicate high accuracy and
low errors on standard datasets and surpass the performance of state-of-the-art benchmark methods.","Future work will examine implicit feedback involving information about user behaviors associated

                                                           9
   ¬∑10‚àí3Mean convergence rate1 feature                                        1.5 RMSE
4                                                        Performance metrics2 features   MAE
              3 features
2             Overall mean                                                      1

                                                                              0.5

0                                                      0
                                                            1234567
   10     20  30                                                  Feature combination

   Number of iterations                         Figure 4: Performance TCA when D = 3.",2022-06-27 15:03:18+00:00,A Simple and Scalable Tensor Completion Algorithm via Latent Invariant Constraint for Recommendation System,cs.IR,"['cs.IR', 'cs.HC', 'cs.LG', 'math.OC']","[arxiv.Result.Author('Tung Nguyen'), arxiv.Result.Author('Sang T. Truong'), arxiv.Result.Author('Jeffrey Uhlmann')]","In this paper we provide a latent-variable formulation and solution to the
recommender system (RS) problem in terms of a fundamental property that any
reasonable solution should be expected to satisfy. Specifically, we examine a
novel tensor completion method to efficiently and accurately learn parameters
of a model for the unobservable personal preferences that underly user ratings.
By regularizing the tensor decomposition with a single latent invariant, we
achieve three properties for a reliable recommender system: (1) uniqueness of
the tensor completion result with minimal assumptions, (2) unit consistency
that is independent of arbitrary preferences of users, and (3) a consensus
ordering guarantee that provides consistent ranking between observed and
unobserved rating scores. Our algorithm leads to a simple and elegant
recommendation framework that has linear computational complexity and with no
hyperparameter tuning. We provide empirical results demonstrating that the
approach significantly outperforms current state-of-the-art methods.",-0.06837611,-0.20984331,0.03042762,A_centroid
8156,"[1] studied
across the e-commerce search landscape in general as a prompt for        stereotypes as representation harm in machine learning pipelines
discussion and further research.","We focus
on providing empirical support for the existence of the problem             In AI and machine learning more broadly, Abbasi et al.",and Ahn et al.,2022-06-28 04:08:06+00:00,Fire Dragon and Unicorn Princess; Gender Stereotypes and Children's Products in Search Engine Responses,cs.IR,"['cs.IR', 'cs.CY', 'cs.HC']","[arxiv.Result.Author('Amifa Raj'), arxiv.Result.Author('Michael D. Ekstrand')]","Search engines in e-commerce settings allow users to search, browse, and
select items from a wide range of products available online including
children's items. Children's products such as toys, books, and learning
materials often have stereotype-based gender associations. Both academic
research and public campaigns are working to promote stereotype-free childhood
development. However, to date, e-commerce search engines have not received as
much attention as physical stores, product design, or marketing as a potential
channel of gender stereotypes. To fill this gap, in this paper, we study the
manifestations of gender stereotypes in e-commerce sites when responding to
queries related to children's products by exploring query suggestions and
search results. We have three primary contributions. First, we provide an
aggregated list of children's products with associated gender stereotypes from
the existing body of research. Second, we provide preliminary methods for
identifying and quantifying gender stereotypes in system's responses. Third, to
show the importance of attending this problem, we identify the existence of
gender stereotypes in query suggestions and search results across multiple
e-commerce sites.",0.21078598,0.08679324,0.06330458,B
8504,"Considering the superior
performance of RTD pre-trained models on benchmarks like GLUE, we believe further research
efforts are needed to investigate the reason behind this phenomenon.",This is consistent with the results in Table 1.,"5.2 Effects of Replace Rate

Table 8: MS-MARCO passage ranking performance w.r.t different token replace rates.",2022-07-06 10:51:33+00:00,SimLM: Pre-training with Representation Bottleneck for Dense Passage Retrieval,cs.IR,['cs.IR'],"[arxiv.Result.Author('Liang Wang'), arxiv.Result.Author('Nan Yang'), arxiv.Result.Author('Xiaolong Huang'), arxiv.Result.Author('Binxing Jiao'), arxiv.Result.Author('Linjun Yang'), arxiv.Result.Author('Daxin Jiang'), arxiv.Result.Author('Rangan Majumder'), arxiv.Result.Author('Furu Wei')]","In this paper, we propose SimLM (Similarity matching with Language Model
pre-training), a simple yet effective pre-training method for dense passage
retrieval. It employs a simple bottleneck architecture that learns to compress
the passage information into a dense vector through self-supervised
pre-training. We use a replaced language modeling objective, which is inspired
by ELECTRA, to improve the sample efficiency and reduce the mismatch of the
input distribution between pre-training and fine-tuning. SimLM only requires
access to unlabeled corpus, and is more broadly applicable when there are no
labeled data or queries. We conduct experiments on several large-scale passage
retrieval datasets, and show substantial improvements over strong baselines
under various settings. Remarkably, SimLM even outperforms multi-vector
approaches such as ColBERTv2 which incurs significantly more storage cost.",-0.3307077,-0.09522678,-0.0068055578,A
8508,"Indeed, the preprocessing code
consistent, and the question of the loss function selection requires                   to generate masked training sequences requires 14GB of storage
further research.","However, as ùúÜRank did not improve                       Rec does not scale to its large number of items (indeed, Gowalla has
RSS results on Yelp, we can not say that the improvements are                          more items than users, see Table 1).","for MovieLens-20M, but 548GB for Gowalla.",2022-07-06 13:06:31+00:00,Effective and Efficient Training for Sequential Recommendation using Recency Sampling,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Aleksandr Petrov'), arxiv.Result.Author('Craig Macdonald')]","Many modern sequential recommender systems use deep neural networks, which
can effectively estimate the relevance of items but require a lot of time to
train. Slow training increases expenses, hinders product development timescales
and prevents the model from being regularly updated to adapt to changing user
preferences. Training such sequential models involves appropriately sampling
past user interactions to create a realistic training objective. The existing
training objectives have limitations. For instance, next item prediction never
uses the beginning of the sequence as a learning target, thereby potentially
discarding valuable data. On the other hand, the item masking used by BERT4Rec
is only weakly related to the goal of the sequential recommendation; therefore,
it requires much more time to obtain an effective model. Hence, we propose a
novel Recency-based Sampling of Sequences training objective that addresses
both limitations. We apply our method to various recent and state-of-the-art
model architectures - such as GRU4Rec, Caser, and SASRec. We show that the
models enhanced with our method can achieve performances exceeding or very
close to stateof-the-art BERT4Rec, but with much less training time.",-0.34261242,-0.10211734,0.009039067,A
8509,"Indeed, the preprocessing code
consistent, and the question of the loss function selection requires                   to generate masked training sequences requires 14GB of storage
further research.","However, as ùúÜRank did not improve                       Rec does not scale to its large number of items (indeed, Gowalla has
RSS results on Yelp, we can not say that the improvements are                          more items than users, see Table 1).","for MovieLens-20M, but 548GB for Gowalla.",2022-07-06 13:06:31+00:00,Effective and Efficient Training for Sequential Recommendation using Recency Sampling,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Aleksandr Petrov'), arxiv.Result.Author('Craig Macdonald')]","Many modern sequential recommender systems use deep neural networks, which
can effectively estimate the relevance of items but require a lot of time to
train. Slow training increases expenses, hinders product development timescales
and prevents the model from being regularly updated to adapt to changing user
preferences. Training such sequential models involves appropriately sampling
past user interactions to create a realistic training objective. The existing
training objectives have limitations. For instance, next item prediction never
uses the beginning of the sequence as a learning target, thereby potentially
discarding valuable data. On the other hand, the item masking used by BERT4Rec
is only weakly related to the goal of the sequential recommendation; therefore,
it requires much more time to obtain an effective model. Hence, we propose a
novel Recency-based Sampling of Sequences training objective that addresses
both limitations. We apply our method to various recent and state-of-the-art
model architectures - such as GRU4Rec, Caser, and SASRec. We show that the
models enhanced with our method can achieve performances exceeding or very
close to stateof-the-art BERT4Rec, but with much less training time.",-0.34261242,-0.10211734,0.009039067,A
8545,"Finally, we conduct further research on the application of SPR in Section 4.3.","Next, we conduct extensive comparative experiments on a variety of different loss functions and backbone networks
in Section 4.2.","4.1 Experimental Settings

4.1.1 Datasets

Three public recommendation datasets including Gowalla [24, 25], Yelp2018 [26, 17] and Amazon-Book [27] are
adopted for top-K recommendation to verify the effectiveness of the SPR.",2022-07-07 10:00:54+00:00,SPR:Supervised Personalized Ranking Based on Prior Knowledge for Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Chun Yang'), arxiv.Result.Author('Shicai Fan')]","The goal of a recommendation system is to model the relevance between each
user and each item through the user-item interaction history, so that maximize
the positive samples score and minimize negative samples. Currently, two
popular loss functions are widely used to optimize recommender systems: the
pointwise and the pairwise. Although these loss functions are widely used,
however, there are two problems. (1) These traditional loss functions do not
fit the goals of recommendation systems adequately and utilize prior knowledge
information sufficiently. (2) The slow convergence speed of these traditional
loss functions makes the practical application of various recommendation models
difficult.
  To address these issues, we propose a novel loss function named Supervised
Personalized Ranking (SPR) Based on Prior Knowledge. The proposed method
improves the BPR loss by exploiting the prior knowledge on the interaction
history of each user or item in the raw data. Unlike BPR, instead of
constructing <user, positive item, negative item> triples, the proposed SPR
constructs <user, similar user, positive item, negative item> quadruples.
Although SPR is very simple, it is very effective. Extensive experiments show
that our proposed SPR not only achieves better recommendation performance, but
also significantly accelerates the convergence speed, resulting in a
significant reduction in the required training time.",0.08414891,-0.30755436,0.27385062,A
8656,advertising [29] and percentage of successful purchases originated                         and further study is required in order to reach a conclusion [15].,"through rate [14, 22], some inspect users‚Äô attitude towards online

1The effective course of treatment for ADHD is out of the scope of this paper.","The
from ads [3].",2022-07-10 11:51:12+00:00,Not Just Skipping. Understanding the Effect of Sponsored Content on Users' Decision-Making in Online Health Search,cs.IR,"['cs.IR', 'cs.HC']","[arxiv.Result.Author('Anat Hashavit'), arxiv.Result.Author('Hongning Wang'), arxiv.Result.Author('Tamar Stern'), arxiv.Result.Author('Sarit Kraus')]","Advertisements (ads) are an innate part of search engine business models.
Advertisers are willing to pay search engines to promote their content to a
prominent position in the search result page (SERP). This raises concerns about
the search engine manipulation effect (SEME): the opinions of users can be
influenced by the way search results are presented. In this work, we
investigate the connection between SEME and sponsored content in the health
domain. We conduct a series of user studies in which participants need to
evaluate the effectiveness of different non-prescription natural remedies for
various medical conditions. We present participants SERPs with different
intentionally created biases towards certain viewpoints, with or without
sponsored content, and ask them to evaluate the effectiveness of the treatment
only based on the information presented to them. We investigate two types of
sponsored content: 1. Direct marketing ads that directly market the product
without expressing an opinion about its effectiveness, and 2. Indirect
marketing ads that explicitly advocate the product's effectiveness on the
condition in the query. Our results reveal a significant difference between the
influence on users from these two ad types. Though direct marketing ads are
mostly skipped by users, they can tilt users decision making towards more
positive viewpoints. Indirect marketing ads affect both the users' examination
behaviour and their perception of the treatment's effectiveness. We further
discover that the contrast between the indirect marketing ads and the viewpoint
presented in the organic search results plays an important role in users'
decision-making. When the contrast is high, users exhibit a strong preference
towards a negative viewpoint, and when the contrast is low or none, users
exhibit preference towards a more positive viewpoint.",0.2416516,-0.14189282,-0.3113485,B
8758,"To further study                                                                  item correlations by considering their behavior-aware interactions
the robustness of our model, we evaluate MBHT on item sequences                                                            in the specific sequence ùëÜùëñ of user ùë¢ùëñ .","We compute the item-
4.4.1 Performance w.r.t Sequence Length.","Figure 6 (e)-(f) show the scale-
with different length.",2022-07-12 15:07:21+00:00,Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Yuhao Yang'), arxiv.Result.Author('Chao Huang'), arxiv.Result.Author('Lianghao Xia'), arxiv.Result.Author('Yuxuan Liang'), arxiv.Result.Author('Yanwei Yu'), arxiv.Result.Author('Chenliang Li')]","Learning dynamic user preference has become an increasingly important
component for many online platforms (e.g., video-sharing sites, e-commerce
systems) to make sequential recommendations. Previous works have made many
efforts to model item-item transitions over user interaction sequences, based
on various architectures, e.g., recurrent neural networks and self-attention
mechanism. Recently emerged graph neural networks also serve as useful backbone
models to capture item dependencies in sequential recommendation scenarios.
Despite their effectiveness, existing methods have far focused on item sequence
representation with singular type of interactions, and thus are limited to
capture dynamic heterogeneous relational structures between users and items
(e.g., page view, add-to-favorite, purchase). To tackle this challenge, we
design a Multi-Behavior Hypergraph-enhanced Transformer framework (MBHT) to
capture both short-term and long-term cross-type behavior dependencies.
Specifically, a multi-scale Transformer is equipped with low-rank
self-attention to jointly encode behavior-aware sequential patterns from
fine-grained and coarse-grained levels. Additionally, we incorporate the global
multi-behavior dependency into the hypergraph neural architecture to capture
the hierarchical long-range item correlations in a customized manner.
Experimental results demonstrate the superiority of our MBHT over various
state-of-the-art recommendation solutions across different settings. Further
ablation studies validate the effectiveness of our model design and benefits of
the new MBHT framework. Our implementation code is released at:
https://github.com/yuh-yang/MBHT-KDD22.",-0.06809093,-0.2769326,-0.05140645,A
8759,"To further study                                                                  specific multi-behavior dependencies with the scales of ùëù1 and ùëù2 in
the robustness of our model, we evaluate MBHT on item sequences                                                            our multi-scale modeling of behavior-aware sequential patterns.","Figure 6 (e)-(f) show the scale-
4.4.1 Performance w.r.t Sequence Length.","In
with different length.",2022-07-12 15:07:21+00:00,Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Yuhao Yang'), arxiv.Result.Author('Chao Huang'), arxiv.Result.Author('Lianghao Xia'), arxiv.Result.Author('Yuxuan Liang'), arxiv.Result.Author('Yanwei Yu'), arxiv.Result.Author('Chenliang Li')]","Learning dynamic user preference has become an increasingly important
component for many online platforms (e.g., video-sharing sites, e-commerce
systems) to make sequential recommendations. Previous works have made many
efforts to model item-item transitions over user interaction sequences, based
on various architectures, e.g., recurrent neural networks and self-attention
mechanism. Recently emerged graph neural networks also serve as useful backbone
models to capture item dependencies in sequential recommendation scenarios.
Despite their effectiveness, existing methods have far focused on item sequence
representation with singular type of interactions, and thus are limited to
capture dynamic heterogeneous relational structures between users and items
(e.g., page view, add-to-favorite, purchase). To tackle this challenge, we
design a Multi-Behavior Hypergraph-enhanced Transformer framework (MBHT) to
capture both short-term and long-term cross-type behavior dependencies.
Specifically, a multi-scale Transformer is equipped with low-rank
self-attention to jointly encode behavior-aware sequential patterns from
fine-grained and coarse-grained levels. Additionally, we incorporate the global
multi-behavior dependency into the hypergraph neural architecture to capture
the hierarchical long-range item correlations in a customized manner.
Experimental results demonstrate the superiority of our MBHT over various
state-of-the-art recommendation solutions across different settings. Further
ablation studies validate the effectiveness of our model design and benefits of
the new MBHT framework. Our implementation code is released at:
https://github.com/yuh-yang/MBHT-KDD22.",-0.1967018,-0.17680842,-0.07351859,A
8790,"We further study the behaviors
                                                                    of BM3 by removing different parts of the multi-modal con-
G. Ablation Study (RQ3 & RQ4)                                       trastive loss.","BM3w/o mm       0.0410     0.0619      0.0227     0.0281
          BM3w/o inter    0.0437     0.0648      0.0247     0.0302     2) Multi-modal Contrastive Loss (RQ4): As the loss func-
          BM3w/o intra                                              tion plays a critical role in learning the model parameters of
          BM3                                                       BM3 without negative samples.","SpeciÔ¨Åcally, we consider the following variants
                                                                    of BM3 for experimental evaluation.",2022-07-13 05:25:39+00:00,Bootstrap Latent Representations for Multi-modal Recommendation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Xin Zhou'), arxiv.Result.Author('Hongyu Zhou'), arxiv.Result.Author('Yong Liu'), arxiv.Result.Author('Zhiwei Zeng'), arxiv.Result.Author('Chunyan Miao'), arxiv.Result.Author('Pengwei Wang'), arxiv.Result.Author('Yuan You'), arxiv.Result.Author('Feijun Jiang')]","This paper studies the multi-modal recommendation problem, where the item
multi-modality information (eg. images and textual descriptions) is exploited
to improve the recommendation accuracy. Besides the user-item interaction
graph, existing state-of-the-art methods usually use auxiliary graphs (eg.
user-user or item-item relation graph) to augment the learned representations
of users and/or items. These representations are often propagated and
aggregated on auxiliary graphs using graph convolutional networks, which can be
prohibitively expensive in computation and memory, especially for large graphs.
Moreover, existing multi-modal recommendation methods usually leverage randomly
sampled negative examples in Bayesian Personalized Ranking (BPR) loss to guide
the learning of user/item representations, which increases the computational
cost on large graphs and may also bring noisy supervision signals into the
training process. To tackle the above issues, we propose a novel
self-supervised multi-modal recommendation model, dubbed BM3, which requires
neither augmentations from auxiliary graphs nor negative samples. Specifically,
BM3 first bootstraps latent contrastive views from the representations of users
and items with a simple dropout augmentation. It then jointly optimizes three
multi-modal objectives to learn the representations of users and items by
reconstructing the user-item interaction graph and aligning modality features
under both inter- and intra-modality perspectives. BM3 alleviates both the need
for contrasting with negative examples and the complex graph augmentation from
an additional target network for contrastive view generation. We show BM3
outperforms prior recommendation models on three datasets with number of nodes
ranging from 20K to 200K, while achieving a 2-9X reduction in training time.
Our code is available at https://github.com/enoche/BM3.",-0.2633767,-0.12514794,-0.2504899,A
8852,"Although there are valuable progress and improvements in this Ô¨Åeld, there
is still a huge need for further research and contributions to help with identiÔ¨Åcation, prediction and treatment of
mental disorders such as depression.","For exam-
ple, as mentioned before, there are several versions of questionnaires developed during years aiming at progress in
depression screening and identiÔ¨Åcation.","As our Ô¨Årst contribution, we introduce a general-purpose Mental Disorder Knowledge Base (MDKB).",2022-07-07 10:04:43+00:00,Towards Knowledge-based Mining of Mental Disorder Patterns from Textual Data,cs.IR,"['cs.IR', 'cs.LG']",[arxiv.Result.Author('Maryam Shahabikargar')],"Mental health disorders may cause severe consequences on all the countries'
economies and health. For example, the impacts of the COVID-19 pandemic, such
as isolation and travel ban, can make us feel depressed. Identifying early
signs of mental health disorders is vital. For example, depression may increase
an individual's risk of suicide. The state-of-the-art research in identifying
mental disorder patterns from textual data, uses hand-labelled training sets,
especially when a domain expert's knowledge is required to analyse various
symptoms. This task could be time-consuming and expensive. To address this
challenge, in this paper, we study and analyse the various clinical and
non-clinical approaches to identifying mental health disorders. We leverage the
domain knowledge and expertise in cognitive science to build a domain-specific
Knowledge Base (KB) for the mental health disorder concepts and patterns. We
present a weaker form of supervision by facilitating the generating of training
data from a domain-specific Knowledge Base (KB). We adopt a typical scenario
for analysing social media to identify major depressive disorder symptoms from
the textual content generated by social users. We use this scenario to evaluate
how our knowledge-based approach significantly improves the quality of results.",0.017413318,0.18295479,-0.16507067,C
8925,"Therefore, meta-
search engines that combined the results of several search engines were meant to provide an additional value
(Chignell et al., 1999) and attracted further research (i.e., Meng et al., 2002).","The
generally small degrees of overlap indicated diverse underlying databases, each of limited size.","Consequently, Spink et al.",2022-07-15 07:58:49+00:00,A Comparison of Source Distribution and Result Overlap in Web Search Engines,cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Nurce Yagci'), arxiv.Result.Author('Sebastian S√ºnkler'), arxiv.Result.Author('Helena H√§u√üler'), arxiv.Result.Author('Dirk Lewandowski')]","When it comes to search engines, users generally prefer Google. Our study
aims to find the differences between the results found in Google compared to
other search engines. We compared the top 10 results from Google, Bing,
DuckDuckGo, and Metager, using 3,537 queries generated from Google Trends from
Germany and the US. Google displays more unique domains in the top results than
its competitors. Wikipedia and news websites are the most popular sources
overall. With some top sources dominating search results, the distribution of
domains is also consistent across all search engines. The overlap between
Google and Bing is always under 32%, while Metager has a higher overlap with
Bing than DuckDuckGo, going up to 78%. This study shows that the use of another
search engine, especially in addition to Google, provides a wider variety in
sources and might lead the user to find new perspectives.",0.24307172,0.20275664,0.017676607,C
8964,"than one actor (280), as measuring the representativeness of multiple     Based on the results in Table 4, there was no significant impact on the
actors in a single video is complicated and left for further research.","Subscribers 142   155                     125

(Thousands)

Note: MED ‚Äì Medical Information, UND ‚Äì Understandability                  To verify the impact of face visibility and gender on the views generated
                                                                          GLM and LASSO regressions are conducted using GLM and GLMNET
As presented in Figure 4, the study did not include videos with more      packages in R. The data is divided into train (70%) and test (30%) samples.","A  presence on presenter‚Äôs face in the videos, not supporting H1.",2022-07-13 01:54:59+00:00,On Curating Responsible and Representative Healthcare Video Recommendations for Patient Education and Health Literacy: An Augmented Intelligence Approach,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Krishna Pothugunta'), arxiv.Result.Author('Xiao Liu'), arxiv.Result.Author('Anjana Susarla'), arxiv.Result.Author('Rema Padman')]","Studies suggest that one in three US adults use the Internet to diagnose or
learn about a health concern. However, such access to health information online
could exacerbate the disparities in health information availability and use.
Health information seeking behavior (HISB) refers to the ways in which
individuals seek information about their health, risks, illnesses, and
health-protective behaviors. For patients engaging in searches for health
information on digital media platforms, health literacy divides can be
exacerbated both by their own lack of knowledge and by algorithmic
recommendations, with results that disproportionately impact disadvantaged
populations, minorities, and low health literacy users. This study reports on
an exploratory investigation of the above challenges by examining whether
responsible and representative recommendations can be generated using advanced
analytic methods applied to a large corpus of videos and their metadata on a
chronic condition (diabetes) from the YouTube social media platform. The paper
focusses on biases associated with demographic characters of actors using
videos on diabetes that were retrieved and curated for multiple criteria such
as encoded medical content and their understandability to address patient
education and population health literacy needs. This approach offers an immense
opportunity for innovation in human-in-the-loop, augmented-intelligence,
bias-aware and responsible algorithmic recommendations by combining the
perspectives of health professionals and patients into a scalable and
generalizable machine learning framework for patient empowerment and improved
health outcomes.",0.03935341,-0.0837489,-0.31832993,B
8965,"The results highlight interesting findings for further research, which
                                                                          underlines the importance of understandability (GLM = .731, LASSO =
                                                                          .506) on the videos viewed on YouTube.",Simple slope analysis to highlight interaction effects.,Figure 5.,2022-07-13 01:54:59+00:00,On Curating Responsible and Representative Healthcare Video Recommendations for Patient Education and Health Literacy: An Augmented Intelligence Approach,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Krishna Pothugunta'), arxiv.Result.Author('Xiao Liu'), arxiv.Result.Author('Anjana Susarla'), arxiv.Result.Author('Rema Padman')]","Studies suggest that one in three US adults use the Internet to diagnose or
learn about a health concern. However, such access to health information online
could exacerbate the disparities in health information availability and use.
Health information seeking behavior (HISB) refers to the ways in which
individuals seek information about their health, risks, illnesses, and
health-protective behaviors. For patients engaging in searches for health
information on digital media platforms, health literacy divides can be
exacerbated both by their own lack of knowledge and by algorithmic
recommendations, with results that disproportionately impact disadvantaged
populations, minorities, and low health literacy users. This study reports on
an exploratory investigation of the above challenges by examining whether
responsible and representative recommendations can be generated using advanced
analytic methods applied to a large corpus of videos and their metadata on a
chronic condition (diabetes) from the YouTube social media platform. The paper
focusses on biases associated with demographic characters of actors using
videos on diabetes that were retrieved and curated for multiple criteria such
as encoded medical content and their understandability to address patient
education and population health literacy needs. This approach offers an immense
opportunity for innovation in human-in-the-loop, augmented-intelligence,
bias-aware and responsible algorithmic recommendations by combining the
perspectives of health professionals and patients into a scalable and
generalizable machine learning framework for patient empowerment and improved
health outcomes.",0.03486931,-0.065041035,-0.28782737,B
9131,This paper contributes to this interdisciplinary conversation and guides further research in several ways.,"Building human values into recommender systems raises complex and
consequential challenges, including philosophical, regulatory, political, sociological, and technical issues.","We have identified some values that are relevant to recommender systems, and discussed the main issues
surrounding each.",2022-07-20 20:59:06+00:00,Building Human Values into Recommender Systems: An Interdisciplinary Synthesis,cs.IR,"['cs.IR', 'cs.SI', 'J.4; H.3.3; K.4.2']","[arxiv.Result.Author('Jonathan Stray'), arxiv.Result.Author('Alon Halevy'), arxiv.Result.Author('Parisa Assar'), arxiv.Result.Author('Dylan Hadfield-Menell'), arxiv.Result.Author('Craig Boutilier'), arxiv.Result.Author('Amar Ashar'), arxiv.Result.Author('Lex Beattie'), arxiv.Result.Author('Michael Ekstrand'), arxiv.Result.Author('Claire Leibowicz'), arxiv.Result.Author('Connie Moon Sehat'), arxiv.Result.Author('Sara Johansen'), arxiv.Result.Author('Lianne Kerlin'), arxiv.Result.Author('David Vickrey'), arxiv.Result.Author('Spandana Singh'), arxiv.Result.Author('Sanne Vrijenhoek'), arxiv.Result.Author('Amy Zhang'), arxiv.Result.Author('McKane Andrus'), arxiv.Result.Author('Natali Helberger'), arxiv.Result.Author('Polina Proutskova'), arxiv.Result.Author('Tanushree Mitra'), arxiv.Result.Author('Nina Vasan')]","Recommender systems are the algorithms which select, filter, and personalize
content across many of the worlds largest platforms and apps. As such, their
positive and negative effects on individuals and on societies have been
extensively theorized and studied. Our overarching question is how to ensure
that recommender systems enact the values of the individuals and societies that
they serve. Addressing this question in a principled fashion requires technical
knowledge of recommender design and operation, and also critically depends on
insights from diverse fields including social science, ethics, economics,
psychology, policy and law. This paper is a multidisciplinary effort to
synthesize theory and practice from different perspectives, with the goal of
providing a shared language, articulating current design approaches, and
identifying open problems. It is not a comprehensive survey of this large
space, but a set of highlights identified by our diverse author cohort. We
collect a set of values that seem most relevant to recommender systems
operating across different domains, then examine them from the perspectives of
current industry practice, measurement, product design, and policy approaches.
Important open problems include multi-stakeholder processes for defining values
and resolving trade-offs, better values-driven measurements, recommender
controls that people use, non-behavioral algorithmic feedback, optimization for
long-term outcomes, causal inference of recommender effects, academic-industry
research collaborations, and interdisciplinary policy-making.",0.46066338,-0.11668186,0.074770875,B
9187,"Thus, a proper number of imputation models can further enhance the performance of MR.

We further study how the different types of imputation models affect the MR method.","It is probably because the extra MF model brings unexpected noise into the learning
process.","As shown in
the right part of Table 3, it indicates consistent beneÔ¨Åts as the number of imputation models increases,
the MR methods with two MF and NCF imputations gain an absolute 3.4‚Ä∞ and 5.1‚Ä∞ increase in
AUC score respectively, compared to those with only one MF and NCF imputation model.",2022-07-09 13:15:56+00:00,Multiple Robust Learning for Recommendation,cs.IR,"['cs.IR', 'cs.LG', 'stat.ML']","[arxiv.Result.Author('Haoxuan Li'), arxiv.Result.Author('Quanyu Dai'), arxiv.Result.Author('Yuru Li'), arxiv.Result.Author('Yan Lyu'), arxiv.Result.Author('Zhenhua Dong'), arxiv.Result.Author('Peng Wu'), arxiv.Result.Author('Xiao-Hua Zhou')]","In recommender systems, a common problem is the presence of various biases in
the collected data, which deteriorates the generalization ability of the
recommendation models and leads to inaccurate predictions. Doubly robust (DR)
learning has been studied in many tasks in RS, with the advantage that unbiased
learning can be achieved when either a single imputation or a single propensity
model is accurate. In this paper, we propose a multiple robust (MR) estimator
that can take the advantage of multiple candidate imputation and propensity
models to achieve unbiasedness. Specifically, the MR estimator is unbiased when
any of the imputation or propensity models, or a linear combination of these
models is accurate. Theoretical analysis shows that the proposed MR is an
enhanced version of DR when only having a single imputation and propensity
model, and has a smaller bias. Inspired by the generalization error bound of
MR, we further propose a novel multiple robust learning approach with
stabilization. We conduct extensive experiments on real-world and
semi-synthetic datasets, which demonstrates the superiority of the proposed
approach over state-of-the-art methods.",-0.246907,-0.11712734,-0.13335317,A
9188,"The experiment on hyper-parameter Œª is a further study related to section 4.1, which follows the same
setting but varies the value of Œª to study its effect on the MR approach.","In addition, we use only one imputation model, i.e., MF, when analyzing the
effect of propensity models on the MR estimator.","In order to investigate the
practical effect of Œª, we perform the experiment for ten times with different random seeds.",2022-07-09 13:15:56+00:00,Multiple Robust Learning for Recommendation,cs.IR,"['cs.IR', 'cs.LG', 'stat.ML']","[arxiv.Result.Author('Haoxuan Li'), arxiv.Result.Author('Quanyu Dai'), arxiv.Result.Author('Yuru Li'), arxiv.Result.Author('Yan Lyu'), arxiv.Result.Author('Zhenhua Dong'), arxiv.Result.Author('Peng Wu'), arxiv.Result.Author('Xiao-Hua Zhou')]","In recommender systems, a common problem is the presence of various biases in
the collected data, which deteriorates the generalization ability of the
recommendation models and leads to inaccurate predictions. Doubly robust (DR)
learning has been studied in many tasks in RS, with the advantage that unbiased
learning can be achieved when either a single imputation or a single propensity
model is accurate. In this paper, we propose a multiple robust (MR) estimator
that can take the advantage of multiple candidate imputation and propensity
models to achieve unbiasedness. Specifically, the MR estimator is unbiased when
any of the imputation or propensity models, or a linear combination of these
models is accurate. Theoretical analysis shows that the proposed MR is an
enhanced version of DR when only having a single imputation and propensity
model, and has a smaller bias. Inspired by the generalization error bound of
MR, we further propose a novel multiple robust learning approach with
stabilization. We conduct extensive experiments on real-world and
semi-synthetic datasets, which demonstrates the superiority of the proposed
approach over state-of-the-art methods.",-0.08661406,-0.18122157,-0.35082704,A
9267,"It is worth further research towards automatic and       sponsored by DARPA, NSF Award #2118709, and research gifts from
intelligent GNN dataflow optimization.","Graphiler currently has limited cover-
age on possible dataflow optimizations; for example, it does not        This research was supported in part by CRISP, one of six centers
support the optimization of reusing SDDMM results that we ap-           in JUMP, a Semiconductor Research Corporation (SRC) program
plied to NGCF.",Intel and Facebook (now Meta).,2022-07-25 06:08:24+00:00,Benchmarking GNN-Based Recommender Systems on Intel Optane Persistent Memory,cs.IR,"['cs.IR', 'cs.DC', 'cs.LG']","[arxiv.Result.Author('Yuwei Hu'), arxiv.Result.Author('Jiajie Li'), arxiv.Result.Author('Zhongming Yu'), arxiv.Result.Author('Zhiru Zhang')]","Graph neural networks (GNNs), which have emerged as an effective method for
handling machine learning tasks on graphs, bring a new approach to building
recommender systems, where the task of recommendation can be formulated as the
link prediction problem on user-item bipartite graphs. Training GNN-based
recommender systems (GNNRecSys) on large graphs incurs a large memory
footprint, easily exceeding the DRAM capacity on a typical server. Existing
solutions resort to distributed subgraph training, which is inefficient due to
the high cost of dynamically constructing subgraphs and significant redundancy
across subgraphs.
  The emerging Intel Optane persistent memory allows a single machine to have
up to 6 TB of memory at an affordable cost, thus making single-machine
GNNRecSys training feasible, which eliminates the inefficiencies in distributed
training. One major concern of using Optane for GNNRecSys is Optane's
relatively low bandwidth compared with DRAMs. This limitation can be
particularly detrimental to achieving high performance for GNNRecSys workloads
since their dominant compute kernels are sparse and memory access intensive. To
understand whether Optane is a good fit for GNNRecSys training, we perform an
in-depth characterization of GNNRecSys workloads and a comprehensive
benchmarking study. Our benchmarking results show that when properly
configured, Optane-based single-machine GNNRecSys training outperforms
distributed training by a large margin, especially when handling deep GNN
models. We analyze where the speedup comes from, provide guidance on how to
configure Optane for GNNRecSys workloads, and discuss opportunities for further
optimizations.",-0.34396482,0.0714148,0.14805798,A
9268,"It is
devices from Kioxia and Everspin [6] may become suitable             worth further research towards automatic and intelligent
alternatives.","Graphiler currently has
                                                                     limited coverage on possible dataflow optimizations; for ex-
   Although Intel recently announced the discontinuation             ample, it does not support the optimization of reusing SD-
of future Optane products [5], upcoming persistent memory            DMM results that we applied to NGCF and LightGCN.","On these emerging devices, the key finding             GNN dataflow optimization.",2022-07-25 06:08:24+00:00,Analysis and Optimization of GNN-Based Recommender Systems on Persistent Memory,cs.IR,"['cs.IR', 'cs.DC', 'cs.LG']","[arxiv.Result.Author('Yuwei Hu'), arxiv.Result.Author('Jiajie Li'), arxiv.Result.Author('Zhongming Yu'), arxiv.Result.Author('Zhiru Zhang')]","Graph neural networks (GNNs), which have emerged as an effective method for
handling machine learning tasks on graphs, bring a new approach to building
recommender systems, where the task of recommendation can be formulated as the
link prediction problem on user-item bipartite graphs. Training GNN-based
recommender systems (GNNRecSys) on large graphs incurs a large memory
footprint, easily exceeding the DRAM capacity on a typical server. Existing
solutions resort to distributed subgraph training, which is inefficient due to
the high cost of dynamically constructing subgraphs and significant redundancy
across subgraphs.
  The emerging persistent memory technologies provide a significantly larger
memory capacity than DRAMs at an affordable cost, making single-machine
GNNRecSys training feasible, which eliminates the inefficiencies in distributed
training. One major concern of using persistent memory devices for GNNRecSys is
their relatively low bandwidth compared with DRAMs. This limitation can be
particularly detrimental to achieving high performance for GNNRecSys workloads
since their dominant compute kernels are sparse and memory access intensive. To
understand whether persistent memory is a good fit for GNNRecSys training, we
perform an in-depth characterization of GNNRecSys workloads and a comprehensive
analysis of their performance on a persistent memory device, namely, Intel
Optane. Based on the analysis, we provide guidance on how to configure Optane
for GNNRecSys workloads. Furthermore, we present techniques for large-batch
training to fully realize the advantages of single-machine GNNRecSys training.
Our experiment results show that with the tuned batch size and optimal system
configuration, Optane-based single-machine GNNRecSys training outperforms
distributed training by a large margin, especially when handling deep GNN
models.",-0.33049387,0.056159183,0.08380354,A
9285,"Even worse, there is no dataset available for the research
                                        community to serve as a benchmark and drive further research in                              Over the past decade, social networks have become an integral part
                                        this direction.","studied in depth by the research community, while the level of                               https://doi.org/10.1145/3503161.3548769
                                        impact of different personality traits on content recommendation
                                        accuracy has not been widely utilised and comprehensively evalu-                             1 INTRODUCTION
                                        ated so far.",The present study is one of the first attempts to                            of our lives.,2022-07-25 14:37:18+00:00,Personality-Driven Social Multimedia Content Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Qi Yang'), arxiv.Result.Author('Sergey Nikolenko'), arxiv.Result.Author('Alfred Huang'), arxiv.Result.Author('Aleksandr Farseev')]","Social media marketing plays a vital role in promoting brand and product
values to wide audiences. In order to boost their advertising revenues, global
media buying platforms such as Facebook Ads constantly reduce the reach of
branded organic posts, pushing brands to spend more on paid media ads. In order
to run organic and paid social media marketing efficiently, it is necessary to
understand the audience, tailoring the content to fit their interests and
online behaviours, which is impossible to do manually at a large scale. At the
same time, various personality type categorization schemes such as the
Myers-Briggs Personality Type indicator make it possible to reveal the
dependencies between personality traits and user content preferences on a wider
scale by categorizing audience behaviours in a unified and structured manner.
This problem is yet to be studied in depth by the research community, while the
level of impact of different personality traits on content recommendation
accuracy has not been widely utilised and comprehensively evaluated so far.
Specifically, in this work we investigate the impact of human personality
traits on the content recommendation model by applying a novel
personality-driven multi-view content recommender system called Personality
Content Marketing Recommender Engine, or PersiC. Our experimental results and
real-world case study demonstrate not just PersiC's ability to perform
efficient human personality-driven multi-view content recommendation, but also
allow for actionable digital ad strategy recommendations, which when deployed
are able to improve digital advertising efficiency by over 420% as compared to
the original human-guided approach.",0.34955955,-0.2244884,0.16392082,B
9286,"Finally, we are also publishing our multi-view large-scale content
                                                                          recommendation dataset for further research in this exciting direc-
   In this practical case study for Brand, we have gone beyond            tion.",reasonable and conform well to the assumptions behind this study.,"just making recommendations with PersiC into qualitative content
generation insights.",2022-07-25 14:37:18+00:00,Personality-Driven Social Multimedia Content Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Qi Yang'), arxiv.Result.Author('Sergey Nikolenko'), arxiv.Result.Author('Alfred Huang'), arxiv.Result.Author('Aleksandr Farseev')]","Social media marketing plays a vital role in promoting brand and product
values to wide audiences. In order to boost their advertising revenues, global
media buying platforms such as Facebook Ads constantly reduce the reach of
branded organic posts, pushing brands to spend more on paid media ads. In order
to run organic and paid social media marketing efficiently, it is necessary to
understand the audience, tailoring the content to fit their interests and
online behaviours, which is impossible to do manually at a large scale. At the
same time, various personality type categorization schemes such as the
Myers-Briggs Personality Type indicator make it possible to reveal the
dependencies between personality traits and user content preferences on a wider
scale by categorizing audience behaviours in a unified and structured manner.
This problem is yet to be studied in depth by the research community, while the
level of impact of different personality traits on content recommendation
accuracy has not been widely utilised and comprehensively evaluated so far.
Specifically, in this work we investigate the impact of human personality
traits on the content recommendation model by applying a novel
personality-driven multi-view content recommender system called Personality
Content Marketing Recommender Engine, or PersiC. Our experimental results and
real-world case study demonstrate not just PersiC's ability to perform
efficient human personality-driven multi-view content recommendation, but also
allow for actionable digital ad strategy recommendations, which when deployed
are able to improve digital advertising efficiency by over 420% as compared to
the original human-guided approach.",0.24968205,-0.11705512,0.24072957,B
9358,"The Slate Reranking          ‚Ä¢ We publish a large-scale dataset from decision log of JD
tries to present combinatorial recommendation from a global          Recommender System reranking module, so that other
perspective instead of point-wise value estimation and sort-         researchers can do further research.","2018, 2019; Zhuang, Ou, and Wang 2018), which
is commonly called ‚ÄùSlate Reranking‚Äù.",ing along with rule-based diversity control.,2022-07-27 05:47:12+00:00,JDRec: Practical Actor-Critic Framework for Online Combinatorial Recommender System,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Xin Zhao'), arxiv.Result.Author('Zhiwei Fang'), arxiv.Result.Author('Yuchen Guo'), arxiv.Result.Author('Jie He'), arxiv.Result.Author('Wenlong Chen'), arxiv.Result.Author('Changping Peng')]","A combinatorial recommender (CR) system feeds a list of items to a user at a
time in the result page, in which the user behavior is affected by both
contextual information and items. The CR is formulated as a combinatorial
optimization problem with the objective of maximizing the recommendation reward
of the whole list. Despite its importance, it is still a challenge to build a
practical CR system, due to the efficiency, dynamics, personalization
requirement in online environment. In particular, we tear the problem into two
sub-problems, list generation and list evaluation. Novel and practical model
architectures are designed for these sub-problems aiming at jointly optimizing
effectiveness and efficiency. In order to adapt to online case, a bootstrap
algorithm forming an actor-critic reinforcement framework is given to explore
better recommendation mode in long-term user interaction. Offline and online
experiment results demonstrate the efficacy of proposed JDRec framework. JDRec
has been applied in online JD recommendation, improving click through rate by
2.6% and synthetical value for the platform by 5.03%. We will publish the
large-scale dataset used in this study to contribute to the research community.",0.19909304,-0.22122876,0.35706592,B
9359,"We obtain that the CTR RL method makes remarkable
OfÔ¨Çine Evaluation                                               improvement on click through rate of recommendation list
                                                                when we take CTR-oriented reward function, which can be
In this section, we introduce the ofÔ¨Çine evaluation on the      a baseline for further research on reinforcement learning for
JDRec Dataset, including ofÔ¨Çine metrics of List Evaluator       Recommender System.","The evaluation results of List Generator are listed in Tab
                                                                3.","The experiment result shows that
and List Generator.",2022-07-27 05:47:12+00:00,JDRec: Practical Actor-Critic Framework for Online Combinatorial Recommender System,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Xin Zhao'), arxiv.Result.Author('Zhiwei Fang'), arxiv.Result.Author('Yuchen Guo'), arxiv.Result.Author('Jie He'), arxiv.Result.Author('Wenlong Chen'), arxiv.Result.Author('Changping Peng')]","A combinatorial recommender (CR) system feeds a list of items to a user at a
time in the result page, in which the user behavior is affected by both
contextual information and items. The CR is formulated as a combinatorial
optimization problem with the objective of maximizing the recommendation reward
of the whole list. Despite its importance, it is still a challenge to build a
practical CR system, due to the efficiency, dynamics, personalization
requirement in online environment. In particular, we tear the problem into two
sub-problems, list generation and list evaluation. Novel and practical model
architectures are designed for these sub-problems aiming at jointly optimizing
effectiveness and efficiency. In order to adapt to online case, a bootstrap
algorithm forming an actor-critic reinforcement framework is given to explore
better recommendation mode in long-term user interaction. Offline and online
experiment results demonstrate the efficacy of proposed JDRec framework. JDRec
has been applied in online JD recommendation, improving click through rate by
2.6% and synthetical value for the platform by 5.03%. We will publish the
large-scale dataset used in this study to contribute to the research community.",0.03158863,-0.22643468,0.25915194,A
9376,"However, the fact that the criteria weights were manually set may have underestimated
the model‚Äôs eÔ¨Äectiveness; therefore, further research will be conducted in this direction.","At the same time, it outperformed the
standard approach in terms of PREC@10 when combined with the employed query preprocessing
method.","6 Acknowledgements

This work was supported by the EU Horizon 2020 ITN/ETN on Domain SpeciÔ¨Åc Systems for
Information Extraction and Retrieval ‚Äì DoSSIER (H2020-EU.1.3.1., ID: 860721).",2022-07-27 13:39:30+00:00,UNIMIB at TREC 2021 Clinical Trials Track,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Author('Georgios Peikos'), arxiv.Result.Author('Oscar Espitia'), arxiv.Result.Author('Gabriella Pasi')]","This contribution summarizes the participation of the UNIMIB team to the TREC
2021 Clinical Trials Track. We have investigated the effect of different query
representations combined with several retrieval models on the retrieval
performance. First, we have implemented a neural re-ranking approach to study
the effectiveness of dense text representations. Additionally, we have
investigated the effectiveness of a novel decision-theoretic model for
relevance estimation. Finally, both of the above relevance models have been
compared with standard retrieval approaches. In particular, we combined a
keyword extraction method with a standard retrieval process based on the BM25
model and a decision-theoretic relevance model that exploits the
characteristics of this particular search task. The obtained results show that
the proposed keyword extraction method improves 84% of the queries over the
TREC's median NDCG@10 measure when combined with either traditional or
decision-theoretic relevance models. Moreover, regarding RPEC@10, the employed
decision-theoretic model improves 85% of the queries over the reported TREC's
median value.",-0.022859773,0.26529115,0.0780623,C
9433,We further study the                                                              multiple groups with different colors.,Data Sparsity.,"This may relate to users‚Äô
influence of data sparsity from both user and item side on model per-                                                     multiple interests.",2022-07-28 18:40:30+00:00,Self-Supervised Hypergraph Transformer for Recommender Systems,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Lianghao Xia'), arxiv.Result.Author('Chao Huang'), arxiv.Result.Author('Chuxu Zhang')]","Graph Neural Networks (GNNs) have been shown as promising solutions for
collaborative filtering (CF) with the modeling of user-item interaction graphs.
The key idea of existing GNN-based recommender systems is to recursively
perform the message passing along the user-item interaction edge for refining
the encoded embeddings. Despite their effectiveness, however, most of the
current recommendation models rely on sufficient and high-quality training
data, such that the learned representations can well capture accurate user
preference. User behavior data in many practical recommendation scenarios is
often noisy and exhibits skewed distribution, which may result in suboptimal
representation performance in GNN-based models. In this paper, we propose SHT,
a novel Self-Supervised Hypergraph Transformer framework (SHT) which augments
user representations by exploring the global collaborative relationships in an
explicit way. Specifically, we first empower the graph neural CF paradigm to
maintain global collaborative effects among users and items with a hypergraph
transformer network. With the distilled global context, a cross-view generative
self-supervised learning component is proposed for data augmentation over the
user-item interaction graph, so as to enhance the robustness of recommender
systems. Extensive experiments demonstrate that SHT can significantly improve
the performance over various state-of-the-art baselines. Further ablation
studies show the superior representation ability of our SHT recommendation
framework in alleviating the data sparsity and noise issues. The source code
and evaluation datasets are available at: https://github.com/akaxlh/SHT.",0.15436012,-0.24373549,-0.086751625,B
9540,"Lastly, we will further study how
                            14.112        13.0343                                                    800                         131.694       123.162  to model user preference with long and noisy history behav-
120                          Valid          Test                                                                                   Valid         Test   iors better and streaming it for online industrial scenarios.","Extensive experiment results show that our
                                                                                                                                                        method captures the changing trend of short-term prefer-
140  TGSRec          149.436        142.873                                                               TGSRec           920.204        818.05        ence, and signiÔ¨Åcantly outperforms various state-of-the-art
     LSTSR (our)                                                                                          LSTSR (our)                                   recommendation models.","100                                                                                                  600                                                                  Acknowledgments
Runtime (min)
                                                                                      Runtime (min)80                                                   No acknowledgement.",2022-08-01 03:44:55+00:00,Long Short-Term Preference Modeling for Continuous-Time Sequential Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Huixuan Chi'), arxiv.Result.Author('Hao Xu'), arxiv.Result.Author('Hao Fu'), arxiv.Result.Author('Mengya Liu'), arxiv.Result.Author('Mengdi Zhang'), arxiv.Result.Author('Yuji Yang'), arxiv.Result.Author('Qinfen Hao'), arxiv.Result.Author('Wei Wu')]","Modeling the evolution of user preference is essential in recommender
systems. Recently, dynamic graph-based methods have been studied and achieved
SOTA for recommendation, majority of which focus on user's stable long-term
preference. However, in real-world scenario, user's short-term preference
evolves over time dynamically. Although there exists sequential methods that
attempt to capture it, how to model the evolution of short-term preference with
dynamic graph-based methods has not been well-addressed yet. In particular: 1)
existing methods do not explicitly encode and capture the evolution of
short-term preference as sequential methods do; 2) simply using last few
interactions is not enough for modeling the changing trend. In this paper, we
propose Long Short-Term Preference Modeling for Continuous-Time Sequential
Recommendation (LSTSR) to capture the evolution of short-term preference under
dynamic graph. Specifically, we explicitly encode short-term preference and
optimize it via memory mechanism, which has three key operations: Message,
Aggregate and Update. Our memory mechanism can not only store one-hop
information, but also trigger with new interactions online. Extensive
experiments conducted on five public datasets show that LSTSR consistently
outperforms many state-of-the-art recommendation methods across various lines.",0.00850911,-0.27032557,0.07157211,A
9810,"In this work,           necessarily result in a fair evaluation of the system, and so
                                       we argue for increased attention on the presence of and methods for          further study is needed.","However, we argue that this metric may not
                                       effects of bias, much like traditional recommenders.",counteracting bias in these emerging systems.,2022-08-08 00:42:42+00:00,Towards Fair Conversational Recommender Systems,cs.IR,['cs.IR'],"[arxiv.Result.Author('Shuo Lin'), arxiv.Result.Author('Ziwei Zhu'), arxiv.Result.Author('Jianling Wang'), arxiv.Result.Author('James Caverlee')]","Conversational recommender systems have demonstrated great success. They can
accurately capture a user's current detailed preference - through a multi-round
interaction cycle - to effectively guide users to a more personalized
recommendation. Alas, conversational recommender systems can be plagued by the
adverse effects of bias, much like traditional recommenders. In this work, we
argue for increased attention on the presence of and methods for counteracting
bias in these emerging systems. As a starting point, we propose three
fundamental questions that should be deeply examined to enable fairness in
conversational recommender systems.",0.40613326,-0.34119204,0.113523014,B_centroid
9811,"In this work,           necessarily result in a fair evaluation of the system, and so
                                        we argue for increased attention on the presence of and methods for          further study is needed.","However, we argue that this metric may not
                                        effects of bias, much like traditional recommenders.",counteracting bias in these emerging systems.,2022-08-08 00:42:42+00:00,Towards Fair Conversational Recommender Systems,cs.IR,['cs.IR'],"[arxiv.Result.Author('Allen Lin'), arxiv.Result.Author('Ziwei Zhu'), arxiv.Result.Author('Jianling Wang'), arxiv.Result.Author('James Caverlee')]","Conversational recommender systems have demonstrated great success. They can
accurately capture a user's current detailed preference -- through a
multi-round interaction cycle -- to effectively guide users to a more
personalized recommendation. Alas, conversational recommender systems can be
plagued by the adverse effects of bias, much like traditional recommenders. In
this work, we argue for increased attention on the presence of and methods for
counteracting bias in these emerging systems. As a starting point, we propose
three fundamental questions that should be deeply examined to enable fairness
in conversational recommender systems.",0.40613326,-0.34119204,0.113523014,B
10230,"And we
vides more opportunities for further research on free-form           assume that all the claims are trivially deÔ¨Åned to support
argument mining and improves the feasibility and general-            a virtual main topic.","Although these properties sig-         ‚Ä¢ Co-Relevance: The i-th and j-th segments are deÔ¨Åned to
niÔ¨Åcantly increase the learning difÔ¨Åculty, this setting reduces      form a Co-Relevance relation if they belong to the sibling
the requirements on the corpus to the minimum, which pro-            components which support the same argument.","It can help recover the horizontal
ization of learned models in practice.",2022-08-20 06:03:35+00:00,AntCritic: Argument Mining for Free-Form and Visually-Rich Financial Comments,cs.IR,['cs.IR'],"[arxiv.Result.Author('Yang Zhao'), arxiv.Result.Author('Wenqiang Xu'), arxiv.Result.Author('Xuan Lin'), arxiv.Result.Author('Jingjing Huo'), arxiv.Result.Author('Hong Chen'), arxiv.Result.Author('Zhou Zhao')]","The task of argument mining aims to detect all possible argumentative
components and identify their relationships automatically. As a thriving field
in natural language processing, there has been a large amount of corpus for
academic study and application development in argument mining. However, the
research in this area is still constrained by the inherent limitations of
existing datasets. Specifically, all the publicly available datasets are
relatively small in scale, and few of them provide information from other
modalities to facilitate the learning process. Moreover, the statements and
expressions in these corpora are usually in a compact form, which means
non-adjacent clauses or text segments will always be regarded as multiple
individual components, thus restricting the generalization ability of models.
To this end, we collect and contribute a novel dataset AntCritic to serve as a
helpful complement to this area, which consists of about 10k free-form and
visually-rich financial comments and supports both argument component detection
and argument relation prediction tasks. Besides, in order to cope with the
challenges and difficulties brought by scenario expansion and problem setting
modification, we thoroughly explore the fine-grained relation prediction and
structure reconstruction scheme for free-form documents and discuss the
encoding mechanism for visual styles and layouts. And based on these analyses,
we design two simple but effective model architectures and conduct various
experiments on this dataset to provide benchmark performances as a reference
and verify the practicability of our proposed architecture.",-0.037450362,0.36054522,0.05089219,C
10243,We leave this for further study.,"On two document retrieval tasks, we find          SS prefix-tuning  MRR@10          MRR@100
that our methods cannot outperform the full fine-tuning baseline           SS LoRA
indicting training with BM25 negatives is not enough for bi-encoder        IAA-L LoRA        0.342           0.375
on document retrieval.","(3) Compare        IAA-L Adapter     0.351           0.383
the three insertion structures, we find that IAA-L which injects the                         0.366‚Ä†‚àó         0.391‚Ä†‚àó
aside module outside the layer performs best.",2022-08-21 08:56:02+00:00,Scattered or Connected? An Optimized Parameter-efficient Tuning Approach for Information Retrieval,cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Xinyu Ma'), arxiv.Result.Author('Jiafeng Guo'), arxiv.Result.Author('Ruqing Zhang'), arxiv.Result.Author('Yixing Fan'), arxiv.Result.Author('Xueqi Cheng')]","Pre-training and fine-tuning have achieved significant advances in the
information retrieval (IR). A typical approach is to fine-tune all the
parameters of large-scale pre-trained models (PTMs) on downstream tasks. As the
model size and the number of tasks increase greatly, such approach becomes less
feasible and prohibitively expensive. Recently, a variety of
parameter-efficient tuning methods have been proposed in natural language
processing (NLP) that only fine-tune a small number of parameters while still
attaining strong performance. Yet there has been little effort to explore
parameter-efficient tuning for IR.
  In this work, we first conduct a comprehensive study of existing
parameter-efficient tuning methods at both the retrieval and re-ranking stages.
Unlike the promising results in NLP, we find that these methods cannot achieve
comparable performance to full fine-tuning at both stages when updating less
than 1\% of the original model parameters. More importantly, we find that the
existing methods are just parameter-efficient, but not learning-efficient as
they suffer from unstable training and slow convergence. To analyze the
underlying reason, we conduct a theoretical analysis and show that the
separation of the inserted trainable modules makes the optimization difficult.
To alleviate this issue, we propose to inject additional modules alongside the
\acp{PTM} to make the original scattered modules connected. In this way, all
the trainable modules can form a pathway to smooth the loss surface and thus
help stabilize the training process. Experiments at both retrieval and
re-ranking stages show that our method outperforms existing parameter-efficient
methods significantly, and achieves comparable or even better performance over
full fine-tuning.",-0.30647808,0.09741774,0.17261913,A
10653,"spark further research in the field of contextualised and sequential
recommender systems.",3146‚Äì3154.,[12] Maciej Kula.,2022-09-01 09:53:57+00:00,MTS Kion Implicit Contextualised Sequential Dataset for Movie Recommendation,cs.IR,['cs.IR'],"[arxiv.Result.Author('Aleksandr Petrov'), arxiv.Result.Author('Ildar Safilo'), arxiv.Result.Author('Daria Tikhonovich'), arxiv.Result.Author('Dmitry Ignatov')]","We present a new movie and TV show recommendation dataset collected from the
real users of MTS Kion video-on-demand platform. In contrast to other popular
movie recommendation datasets, such as MovieLens or Netflix, our dataset is
based on the implicit interactions registered at the watching time, rather than
on explicit ratings. We also provide rich contextual and side information
including interactions characteristics (such as temporal information, watch
duration and watch percentage), user demographics and rich movies
meta-information. In addition, we describe the MTS Kion Challenge - an online
recommender systems challenge that was based on this dataset - and provide an
overview of the best performing solutions of the winners. We keep the
competition sandbox open, so the researchers are welcome to try their own
recommendation algorithms and measure the quality on the private part of the
dataset.",0.22060964,-0.1841718,0.2284384,B
10666,"Beauty   R@20    0.0448          0.1059           0.1095
Office   R@40    0.0709          0.1561           0.1541  0.1066         We further study how the sequence length affects the model‚Äôs
Toy      N@20    0.0180          0.0459           0.0496  0.1578
Tool     N@40    0.0233          0.0562           0.0587  0.0464      performance.","contributes to the overall performance of our method, as most items

Dataset  Metric  AVAE              DA              MA       VA        to be predicted are long-tail items.","Similar to the item frequency, we split user sequences
         R@20    0.1093          0.1745           0.1708
         R@40    0.1918          0.2658           0.2617  0.0568      into 5 groups according to their lengths, and we report the perfor-
         N@20    0.0419          0.0739           0.0741              mance of ContrastVAE and other models on Toy dataset in Fig.",2022-08-27 03:35:00+00:00,ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Yu Wang'), arxiv.Result.Author('Hengrui Zhang'), arxiv.Result.Author('Zhiwei Liu'), arxiv.Result.Author('Liangwei Yang'), arxiv.Result.Author('Philip S. Yu')]","Aiming at exploiting the rich information in user behaviour sequences,
sequential recommendation has been widely adopted in real-world recommender
systems. However, current methods suffer from the following issues: 1) sparsity
of user-item interactions, 2) uncertainty of sequential records, 3) long-tail
items. In this paper, we propose to incorporate contrastive learning into the
framework of Variational AutoEncoders to address these challenges
simultaneously. Firstly, we introduce ContrastELBO, a novel training objective
that extends the conventional single-view ELBO to two-view case and
theoretically builds a connection between VAE and contrastive learning from a
two-view perspective. Then we propose Contrastive Variational AutoEncoder
(ContrastVAE in short), a two-branched VAE model with contrastive
regularization as an embodiment of ContrastELBO for sequential recommendation.
We further introduce two simple yet effective augmentation strategies named
model augmentation and variational augmentation to create a second view of a
sequence and thus making contrastive learning possible. Experiments on four
benchmark datasets demonstrate the effectiveness of ContrastVAE and the
proposed augmentation methods. Codes are available at
https://github.com/YuWang-1024/ContrastVAE",-0.22766659,-0.18652107,-0.10538679,A
10667,We further study the impact of cor-                   augmentations outperforms other competitive baselines.,"Experiment
                                                                                 results and analysis show that our architecture combined with
5.4.3 Robustness analysis.","rupted input sequences for ContrastVAE to analyze its robustness
w.r.t.",2022-08-27 03:35:00+00:00,ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Yu Wang'), arxiv.Result.Author('Hengrui Zhang'), arxiv.Result.Author('Zhiwei Liu'), arxiv.Result.Author('Liangwei Yang'), arxiv.Result.Author('Philip S. Yu')]","Aiming at exploiting the rich information in user behaviour sequences,
sequential recommendation has been widely adopted in real-world recommender
systems. However, current methods suffer from the following issues: 1) sparsity
of user-item interactions, 2) uncertainty of sequential records, 3) long-tail
items. In this paper, we propose to incorporate contrastive learning into the
framework of Variational AutoEncoders to address these challenges
simultaneously. Firstly, we introduce ContrastELBO, a novel training objective
that extends the conventional single-view ELBO to two-view case and
theoretically builds a connection between VAE and contrastive learning from a
two-view perspective. Then we propose Contrastive Variational AutoEncoder
(ContrastVAE in short), a two-branched VAE model with contrastive
regularization as an embodiment of ContrastELBO for sequential recommendation.
We further introduce two simple yet effective augmentation strategies named
model augmentation and variational augmentation to create a second view of a
sequence and thus making contrastive learning possible. Experiments on four
benchmark datasets demonstrate the effectiveness of ContrastVAE and the
proposed augmentation methods. Codes are available at
https://github.com/YuWang-1024/ContrastVAE",-0.43263778,-0.13766994,-0.28455973,A
10668,"We further study how the sequence length affects the model‚Äôs
Dataset  Metric  AVAE              DA              MA       VA         performance.",variational augmentation.,"Similar to the item frequency, we split user sequences
Beauty   R@20    0.0448          0.1059           0.1095               into 5 groups according to their lengths, and we report the per-
Office   R@40    0.0709          0.1561           0.1541  0.1066       formance of ContrastVAE and other models on the Toy dataset in
Toy      N@20    0.0180          0.0459           0.0496  0.1578       Fig.",2022-08-27 03:35:00+00:00,ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Yu Wang'), arxiv.Result.Author('Hengrui Zhang'), arxiv.Result.Author('Zhiwei Liu'), arxiv.Result.Author('Liangwei Yang'), arxiv.Result.Author('Philip S. Yu')]","Aiming at exploiting the rich information in user behaviour sequences,
sequential recommendation has been widely adopted in real-world recommender
systems. However, current methods suffer from the following issues: 1) sparsity
of user-item interactions, 2) uncertainty of sequential records, 3) long-tail
items. In this paper, we propose to incorporate contrastive learning into the
framework of Variational AutoEncoders to address these challenges
simultaneously. Firstly, we introduce ContrastELBO, a novel training objective
that extends the conventional single-view ELBO to two-view case and
theoretically builds a connection between VAE and contrastive learning from a
two-view perspective. Then we propose Contrastive Variational AutoEncoder
(ContrastVAE in short), a two-branched VAE model with contrastive
regularization as an embodiment of ContrastELBO for sequential recommendation.
We further introduce two simple yet effective augmentation strategies named
model augmentation and variational augmentation to create a second view of a
sequence and thus making contrastive learning possible. Experiments on four
benchmark datasets demonstrate the effectiveness of ContrastVAE and the
proposed augmentation methods. Codes are available at
https://github.com/YuWang-1024/ContrastVAE",-0.26119196,-0.20646192,-0.13298512,A
10669,"We further study the impact of cor-
rupted input sequences for ContrastVAE to analyze its robustness
CIKM ‚Äô22, October 17‚Äì21, 2022, Atlanta, GA, USA.","Experiment
5.4.3 Robustness analysis.",Yu Wang et al.,2022-08-27 03:35:00+00:00,ContrastVAE: Contrastive Variational AutoEncoder for Sequential Recommendation,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Yu Wang'), arxiv.Result.Author('Hengrui Zhang'), arxiv.Result.Author('Zhiwei Liu'), arxiv.Result.Author('Liangwei Yang'), arxiv.Result.Author('Philip S. Yu')]","Aiming at exploiting the rich information in user behaviour sequences,
sequential recommendation has been widely adopted in real-world recommender
systems. However, current methods suffer from the following issues: 1) sparsity
of user-item interactions, 2) uncertainty of sequential records, 3) long-tail
items. In this paper, we propose to incorporate contrastive learning into the
framework of Variational AutoEncoders to address these challenges
simultaneously. Firstly, we introduce ContrastELBO, a novel training objective
that extends the conventional single-view ELBO to two-view case and
theoretically builds a connection between VAE and contrastive learning from a
two-view perspective. Then we propose Contrastive Variational AutoEncoder
(ContrastVAE in short), a two-branched VAE model with contrastive
regularization as an embodiment of ContrastELBO for sequential recommendation.
We further introduce two simple yet effective augmentation strategies named
model augmentation and variational augmentation to create a second view of a
sequence and thus making contrastive learning possible. Experiments on four
benchmark datasets demonstrate the effectiveness of ContrastVAE and the
proposed augmentation methods. Codes are available at
https://github.com/YuWang-1024/ContrastVAE",-0.4000299,-0.121431574,-0.39083293,A
10689,"By doing so, we hope to motivate and inspire further study of
                                                                                                                                  layer-wise pruning and architecture design of transformer models.","0.48% higher AUC, respectively.",Search efficiency comparison.,2022-08-30 03:05:56+00:00,SwiftPruner: Reinforced Evolutionary Pruning for Efficient Ad Relevance,cs.IR,"['cs.IR', 'cs.AI', 'cs.CL']","[arxiv.Result.Author('Li Lyna Zhang'), arxiv.Result.Author('Youkow Homma'), arxiv.Result.Author('Yujing Wang'), arxiv.Result.Author('Min Wu'), arxiv.Result.Author('Mao Yang'), arxiv.Result.Author('Ruofei Zhang'), arxiv.Result.Author('Ting Cao'), arxiv.Result.Author('Wei Shen')]","Ad relevance modeling plays a critical role in online advertising systems
including Microsoft Bing. To leverage powerful transformers like BERT in this
low-latency setting, many existing approaches perform ad-side computations
offline. While efficient, these approaches are unable to serve cold start ads,
resulting in poor relevance predictions for such ads. This work aims to design
a new, low-latency BERT via structured pruning to empower real-time online
inference for cold start ads relevance on a CPU platform. Our challenge is that
previous methods typically prune all layers of the transformer to a high,
uniform sparsity, thereby producing models which cannot achieve satisfactory
inference speed with an acceptable accuracy.
  In this paper, we propose SwiftPruner - an efficient framework that leverages
evolution-based search to automatically find the best-performing layer-wise
sparse BERT model under the desired latency constraint. Different from existing
evolution algorithms that conduct random mutations, we propose a reinforced
mutator with a latency-aware multi-objective reward to conduct better mutations
for efficiently searching the large space of layer-wise sparse models.
Extensive experiments demonstrate that our method consistently achieves higher
ROC AUC and lower latency than the uniform sparse baseline and state-of-the-art
search methods. Remarkably, under our latency requirement of 1900us on CPU,
SwiftPruner achieves a 0.86% higher AUC than the state-of-the-art uniform
sparse baseline for BERT-Mini on a large scale real-world dataset. Online A/B
testing shows that our model also achieves a significant 11.7% cut in the ratio
of defective cold start ads with satisfactory real-time serving latency.",-0.25696304,-0.0030313022,-0.008117407,A
10824,"They                 (ii) domain knowledge and its impact on learning outcomes when
                                       do so, for instance, by adopting diÔ¨Äerent search roles [4], each re-               searching [13], (iii) how to measure learning within SAL envi-
                                       sulting in varying degrees of satisfaction when conducting search                  ronments [14], (iv) datasets that sustain further research in this
                                       tasks individually in the home setting.","It covers diÔ¨Äerent aspects:
                                       dren can be in identifying ways to circumvent barriers and still use               (i) the connection of search behaviour and learning outcomes [12],
                                       search engines to address their leisure-related search tasks.","Looking at the dynamics of                 area [15], (v) new frameworks to better understanding and mea-
                                       information acquisition in the classroom, recent publications dis-                 suring of SAL processes [16], (vi) exploring the use of active read-
                                       close how the natural scaÔ¨Äolding provided by teachers and peers is                 ing tools to support search as learning [17], and (vii) knowledge
                                                                                                                          gain as a result of learning-related inquiry tasks [18], to name a
                                       ‚àóPresented at IWILDS 2022.                                                         few.",2022-09-06 09:54:15+00:00,Let's Learn from Children: Scaffolding to Enable Search as Learning in the Educational Environment,cs.IR,"['cs.IR', 'cs.CY']","[arxiv.Result.Author('Monica Landoni'), arxiv.Result.Author('Maria Soledad Pera'), arxiv.Result.Author('Emiliana Murgia'), arxiv.Result.Author('Theo Huibers')]","In this manuscript, we argue for the need to further look at search as
learning (SAL) with children as the primary stakeholders. Inspired by how
children learn and considering the classroom (regardless of the teaching
modality) as a natural educational ecosystem, we posit that scaffolding is the
tie that can simultaneously allow for learning to search while searching for
learning. The main contribution of this work is a list of open challenges
focused on the primary school classroom for the IR community to consider when
setting up to explore and make progress on SAL research with and for children
and beyond.",0.15675314,0.2636487,-0.08022848,C
10961,"7 THE DATA LIFE-CYCLE
                                                                                 Second, further research on the detection of objectionable (e.g.,
The data lifecycle is one of the most difficult challenges facing             obscene) shapes is sorely needed.","In particular, this type of attack may be appealing to competitors
                                                                              and other actors skilled at corporate espionage.","There is some existing work
Thangs.",2022-09-08 16:49:10+00:00,Data Management Challenges for Internet-scale 3D Search Engines,cs.IR,['cs.IR'],"[arxiv.Result.Author('James Williams'), arxiv.Result.Author('Shane Scott'), arxiv.Result.Author('Timur Hindanov'), arxiv.Result.Author('Christoph Roedig')]","This paper describes some of the major challenges encountered by Physna Inc.
in developing an internet-scale search engine for three-dimensional (3D)
models. The discussion focuses on the most significant data management issues
in this domain, including model acquisition, diversity of file formats, shape
retrieval, intellectual property, the legality of web crawling, and trustworthy
computing. The paper gives an overview of these topics, as well as some of the
general design choices that were made in the course of building the Thangs
search engine. While numerous works have been published on the topic of
algorithms for 3D similarity search, this paper is the first to discuss the
real-world challenges that arise in building a practical, internet-scale, 3D
search engine.",0.08692123,0.12008689,-0.33768606,B
10962,"Detecting remixed works by
geometry is a problem that requires further research and development by the 3D IR community.","However, there are hard cases
that are not caught by any of Physna‚Äôs existing search methods.",ACM SIGIR Forum  21  Vol.,2022-09-08 16:49:10+00:00,Data Management Challenges for Internet-scale 3D Search Engines,cs.IR,['cs.IR'],"[arxiv.Result.Author('James Williams'), arxiv.Result.Author('Shane Scott'), arxiv.Result.Author('Sean Wedig'), arxiv.Result.Author('Timur Hindanov'), arxiv.Result.Author('Christoph Roedig')]","This paper describes the most significant data-related challenges involved in
building internet-scale 3D search engines. The discussion centers on the most
pressing data management issues in this domain, including model acquisition,
support for multiple file formats, asset versioning, data integrity errors, the
data lifecycle, intellectual property, and the legality of web crawling. The
paper also discusses numerous issues that fall under the rubric of trustworthy
computing, including privacy, security, inappropriate content, and
copying/remixing of assets. The goal of the paper is to provide an overview of
these general issues, illustrated by empirical data drawn from the internet's
largest operational search engine. While numerous works have been published on
3D information retrieval, this paper is the first to discuss the real-world
challenges that arise in building practical search engines at scale.",-0.17308523,0.12192891,-0.09825051,A
10963,"Second, further research on the detection of objectionable (e.g., obscene) shapes is sorely
needed.","In particular, this type of attack may be appealing to
competitors and other actors skilled at corporate espionage.","There is some existing work that converts 3D objects to 2D images and then uses 2D
imaging techniques to classify the results.",2022-09-08 16:49:10+00:00,Data Management Challenges for Internet-scale 3D Search Engines,cs.IR,['cs.IR'],"[arxiv.Result.Author('James Williams'), arxiv.Result.Author('Shane Scott'), arxiv.Result.Author('Sean Wedig'), arxiv.Result.Author('Timur Hindanov'), arxiv.Result.Author('Christoph Roedig')]","This paper describes the most significant data-related challenges involved in
building internet-scale 3D search engines. The discussion centers on the most
pressing data management issues in this domain, including model acquisition,
support for multiple file formats, asset versioning, data integrity errors, the
data lifecycle, intellectual property, and the legality of web crawling. The
paper also discusses numerous issues that fall under the rubric of trustworthy
computing, including privacy, security, inappropriate content, and
copying/remixing of assets. The goal of the paper is to provide an overview of
these general issues, illustrated by empirical data drawn from the internet's
largest operational search engine. While numerous works have been published on
3D information retrieval, this paper is the first to discuss the real-world
challenges that arise in building practical search engines at scale.",0.05090046,0.081941225,-0.33667028,B
10964,"Fourth, there is a clear need for further research on remixing of 3D models.","For example,
local neighborhood estimates start to overlap in datasets of this size, causing serious problems for
PIP search.","In particular, the
Ô¨Åeld lacks detailed ethnographic research in which user attitudes towards remixing are elicited
and analyzed.",2022-09-08 16:49:10+00:00,Data Management Challenges for Internet-scale 3D Search Engines,cs.IR,['cs.IR'],"[arxiv.Result.Author('James Williams'), arxiv.Result.Author('Shane Scott'), arxiv.Result.Author('Sean Wedig'), arxiv.Result.Author('Timur Hindanov'), arxiv.Result.Author('Christoph Roedig')]","This paper describes the most significant data-related challenges involved in
building internet-scale 3D search engines. The discussion centers on the most
pressing data management issues in this domain, including model acquisition,
support for multiple file formats, asset versioning, data integrity errors, the
data lifecycle, intellectual property, and the legality of web crawling. The
paper also discusses numerous issues that fall under the rubric of trustworthy
computing, including privacy, security, inappropriate content, and
copying/remixing of assets. The goal of the paper is to provide an overview of
these general issues, illustrated by empirical data drawn from the internet's
largest operational search engine. While numerous works have been published on
3D information retrieval, this paper is the first to discuss the real-world
challenges that arise in building practical search engines at scale.",0.0938067,0.027157435,-0.21804751,B
11247,"To foster further research, we release all datasets9 and        V. Sanh, L. Debut, J. Chaumond, T. Wolf, DistilBERT, a distilled version
provide access to the system demonstrator10 to make queries            of bert: smaller, faster, cheaper and lighter, in: EMC2, 2019.
and see results through an interactive interface.",2020.,"D. Chen, A. Fisch, J. Weston, A. Bordes, Reading Wikipedia to answer
     9https://github.com/ghoshs/CoQEx                                  open-domain questions, in: ACL, 2017.",2022-09-15 12:35:32+00:00,Answering Count Questions with Structured Answers from Text,cs.IR,['cs.IR'],"[arxiv.Result.Author('Shrestha Ghosh'), arxiv.Result.Author('Simon Razniewski'), arxiv.Result.Author('Gerhard Weikum')]","In this work we address the challenging case of answering count queries in
web search, such as ``number of songs by John Lennon''. Prior methods merely
answer these with a single, and sometimes puzzling number or return a ranked
list of text snippets with different numbers. This paper proposes a methodology
for answering count queries with inference, contextualization and explanatory
evidence. Unlike previous systems, our method infers final answers from
multiple observations, supports semantic qualifiers for the counts, and
provides evidence by enumerating representative instances. Experiments with a
wide variety of queries, including existing benchmark show the benefits of our
method, and the influence of specific parameter settings. Our code, data and an
interactive system demonstration are publicly available at
https://github.com/ghoshs/CoQEx and https://nlcounqer.mpi-inf.mpg.de/.",-0.113818645,0.26236317,0.07729817,C
11480,"In this section, we will illustrate some
promising directions for further research on this topic.","However, there are also some other potential directions to be explored for the supplement to
the definition of trustworthy recommender systems (TRec).",Interactions among different dimensions.,2022-09-21 04:34:17+00:00,A Comprehensive Survey on Trustworthy Recommender Systems,cs.IR,"['cs.IR', 'cs.AI', 'cs.CR', 'cs.LG']","[arxiv.Result.Author('Wenqi Fan'), arxiv.Result.Author('Xiangyu Zhao'), arxiv.Result.Author('Xiao Chen'), arxiv.Result.Author('Jingran Su'), arxiv.Result.Author('Jingtong Gao'), arxiv.Result.Author('Lin Wang'), arxiv.Result.Author('Qidong Liu'), arxiv.Result.Author('Yiqi Wang'), arxiv.Result.Author('Han Xu'), arxiv.Result.Author('Lei Chen'), arxiv.Result.Author('Qing Li')]","As one of the most successful AI-powered applications, recommender systems
aim to help people make appropriate decisions in an effective and efficient
way, by providing personalized suggestions in many aspects of our lives,
especially for various human-oriented online services such as e-commerce
platforms and social media sites. In the past few decades, the rapid
developments of recommender systems have significantly benefited human by
creating economic value, saving time and effort, and promoting social good.
However, recent studies have found that data-driven recommender systems can
pose serious threats to users and society, such as spreading fake news to
manipulate public opinion in social media sites, amplifying unfairness toward
under-represented groups or individuals in job matching services, or inferring
privacy information from recommendation results. Therefore, systems'
trustworthiness has been attracting increasing attention from various aspects
for mitigating negative impacts caused by recommender systems, so as to enhance
the public's trust towards recommender systems techniques. In this survey, we
provide a comprehensive overview of Trustworthy Recommender systems (TRec) with
a specific focus on six of the most important aspects; namely, Safety &
Robustness, Nondiscrimination & Fairness, Explainability, Privacy,
Environmental Well-being, and Accountability & Auditability. For each aspect,
we summarize the recent related technologies and discuss potential research
directions to help achieve trustworthy recommender systems in the future.",0.3511808,-0.20927227,0.14738756,B
11538,"This specific distribution of frames can be related to the
differences in the framing process on search engines and legacy media, but also to differences in the
framing of COVID-19 and earlier pandemics, so further research is required to clarify them.","The other three types of frames are more underrepresented and appear
just in a few engine-language combinations.",Table 2.,2022-09-22 16:02:16+00:00,This is what a pandemic looks like: Visual framing of COVID-19 on search engines,cs.IR,['cs.IR'],"[arxiv.Result.Author('Mykola Makhortykh'), arxiv.Result.Author('Aleksandra Urman'), arxiv.Result.Author('Roberto Ulloa')]","In today's high-choice media environment, search engines play an integral
role in informing individuals and societies about the latest events. The
importance of search algorithms is even higher at the time of crisis, when
users search for information to understand the causes and the consequences of
the current situation and decide on their course of action. In our paper, we
conduct a comparative audit of how different search engines prioritize visual
information related to COVID-19 and what consequences it has for the
representation of the pandemic. Using a virtual agent-based audit approach, we
examine image search results for the term ""coronavirus"" in English, Russian and
Chinese on five major search engines: Google, Yandex, Bing, Yahoo, and
DuckDuckGo. Specifically, we focus on how image search results relate to
generic news frames (e.g., the attribution of responsibility, human interest,
and economics) used in relation to COVID-19 and how their visual composition
varies between the search engines.",0.10950667,0.1418752,-0.16606474,C
11592,"Thus we further study whether AUR                      LGCN as the backbone expectation estimator of AUR when
calibrates the recommendation list regarding the tail and                  all relevant items are needed to be recommended.","Meanwhile, LGCN-AUR achieves the best
many head items to users even though certain users usually                 result on both Yelp and Amazon, which suggests selecting
consume tail items.",head items.,2022-09-22 04:32:51+00:00,Rethinking Missing Data: Aleatoric Uncertainty-Aware Recommendation,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Chenxu Wang'), arxiv.Result.Author('Fuli Feng'), arxiv.Result.Author('Yang Zhang'), arxiv.Result.Author('Qifan Wang'), arxiv.Result.Author('Xunhan Hu'), arxiv.Result.Author('Xiangnan He')]","Historical interactions are the default choice for recommender model
training, which typically exhibit high sparsity, i.e., most user-item pairs are
unobserved missing data. A standard choice is treating the missing data as
negative training samples and estimating interaction likelihood between
user-item pairs along with the observed interactions. In this way, some
potential interactions are inevitably mislabeled during training, which will
hurt the model fidelity, hindering the model to recall the mislabeled items,
especially the long-tail ones. In this work, we investigate the mislabeling
issue from a new perspective of aleatoric uncertainty, which describes the
inherent randomness of missing data. The randomness pushes us to go beyond
merely the interaction likelihood and embrace aleatoric uncertainty modeling.
Towards this end, we propose a new Aleatoric Uncertainty-aware Recommendation
(AUR) framework that consists of a new uncertainty estimator along with a
normal recommender model. According to the theory of aleatoric uncertainty, we
derive a new recommendation objective to learn the estimator. As the chance of
mislabeling reflects the potential of a pair, AUR makes recommendations
according to the uncertainty, which is demonstrated to improve the
recommendation performance of less popular items without sacrificing the
overall performance. We instantiate AUR on three representative recommender
models: Matrix Factorization (MF), LightGCN, and VAE from mainstream model
architectures. Extensive results on two real-world datasets validate the
effectiveness of AUR w.r.t. better recommendation results, especially on
long-tail items.",0.08275038,-0.33488464,0.18883832,A
11711,settings to facilitate repeatability as well as further research 4.,"We have released the code and relevant parameter
issue in the model training [12, 32] and result collection [40] phases.","Despite their effectiveness, we argue that the existing solutions          In summary, the main contributions of this work are summarized
still suffer from the following three limitations: (1) Communica-          as follows:
tion and computation cost.",2022-09-27 03:40:27+00:00,Privacy-Preserving Synthetic Data Generation for Recommendation Systems,cs.IR,"['cs.IR', '68P20, 68P27', 'H.3.3']","[arxiv.Result.Author('Fan Liu'), arxiv.Result.Author('Zhiyong Cheng'), arxiv.Result.Author('Huilin Chen'), arxiv.Result.Author('Yinwei Wei'), arxiv.Result.Author('Liqiang Nie'), arxiv.Result.Author('Mohan Kankanhalli')]","Recommendation systems make predictions chiefly based on users' historical
interaction data (e.g., items previously clicked or purchased). There is a risk
of privacy leakage when collecting the users' behavior data for building the
recommendation model. However, existing privacy-preserving solutions are
designed for tackling the privacy issue only during the model training and
results collection phases. The problem of privacy leakage still exists when
directly sharing the private user interaction data with organizations or
releasing them to the public. To address this problem, in this paper, we
present a User Privacy Controllable Synthetic Data Generation model (short for
UPC-SDG), which generates synthetic interaction data for users based on their
privacy preferences. The generation model aims to provide certain privacy
guarantees while maximizing the utility of the generated synthetic data at both
data level and item level. Specifically, at the data level, we design a
selection module that selects those items that contribute less to a user's
preferences from the user's interaction data. At the item level, a synthetic
data generation module is proposed to generate a synthetic item corresponding
to the selected item based on the user's preferences. Furthermore, we also
present a privacy-utility trade-off strategy to balance the privacy and utility
of the synthetic data. Extensive experiments and ablation studies have been
conducted on three publicly accessible datasets to justify our method,
demonstrating its effectiveness in generating synthetic data under users'
privacy preferences.",-0.3187071,0.04855964,-0.03474219,A
12010,"Hybrid Retriever integrates the sparse and
                                                         dense retriever and ranks the documents by inter-
   We further study the generalization of our light      polating the relevance score from each retriever.","Our LITE          2 Related Work
model only needs the indexing memory same as a
single weak-learner.","hybrid retriever, another crucial feature for real-life  The most popular way to obtain the hybrid ranking
applications.",2022-10-04 04:22:46+00:00,A Study on the Efficiency and Generalization of Light Hybrid Retrievers,cs.IR,"['cs.IR', 'cs.CL']","[arxiv.Result.Author('Man Luo'), arxiv.Result.Author('Shashank Jain'), arxiv.Result.Author('Anchit Gupta'), arxiv.Result.Author('Arash Einolghozati'), arxiv.Result.Author('Barlas Oguz'), arxiv.Result.Author('Debojeet Chatterjee'), arxiv.Result.Author('Xilun Chen'), arxiv.Result.Author('Chitta Baral'), arxiv.Result.Author('Peyman Heidari')]","Existing hybrid retrievers which integrate sparse and dense retrievers, are
indexing-heavy, limiting their applicability in real-world on-devices settings.
We ask the question ""Is it possible to reduce the indexing memory of hybrid
retrievers without sacrificing performance?"" Driven by this question, we
leverage an indexing-efficient dense retriever (i.e. DrBoost) to obtain a light
hybrid retriever. Moreover, to further reduce the memory, we introduce a
lighter dense retriever (LITE) which is jointly trained on contrastive learning
and knowledge distillation from DrBoost. Compared to previous heavy hybrid
retrievers, our Hybrid-LITE retriever saves 13 memory while maintaining 98.0
performance.
  In addition, we study the generalization of light hybrid retrievers along two
dimensions, out-of-domain (OOD) generalization and robustness against
adversarial attacks. We evaluate models on two existing OOD benchmarks and
create six adversarial attack sets for robustness evaluation. Experiments show
that our light hybrid retrievers achieve better robustness performance than
both sparse and dense retrievers. Nevertheless there is a large room to improve
the robustness of retrievers, and our datasets can aid future research.",-0.034346186,0.08686877,0.30045497,C
12667,"In
                                       ùë¢ùë¢                         ùë¢                                                             ùë£                                                                                                        AUC LogLoss                                     AUC LogLoss

order to further study the influence of the user layer in FE-Block,                                                                                                                                                        (a) MovieLens                                   (b) Amazon

we perform experiments over MovieLens and Amazon datasets by                                                                                                                                                       Figure 8: Performance w.r.t.",", hùêø } and the last item layer hùêø.",the head subspace dimension .,2022-10-18 14:28:30+00:00,IntTower: the Next Generation of Two-Tower Model for Pre-Ranking System,cs.IR,['cs.IR'],"[arxiv.Result.Author('Xiangyang Li'), arxiv.Result.Author('Bo Chen'), arxiv.Result.Author('HuiFeng Guo'), arxiv.Result.Author('Jingjie Li'), arxiv.Result.Author('Chenxu Zhu'), arxiv.Result.Author('Xiang Long'), arxiv.Result.Author('Sujian Li'), arxiv.Result.Author('Yichao Wang'), arxiv.Result.Author('Wei Guo'), arxiv.Result.Author('Longxia Mao'), arxiv.Result.Author('Jinxing Liu'), arxiv.Result.Author('Zhenhua Dong'), arxiv.Result.Author('Ruiming Tang')]","Scoring a large number of candidates precisely in several milliseconds is
vital for industrial pre-ranking systems. Existing pre-ranking systems
primarily adopt the \textbf{two-tower} model since the ``user-item decoupling
architecture'' paradigm is able to balance the \textit{efficiency} and
\textit{effectiveness}. However, the cost of high efficiency is the neglect of
the potential information interaction between user and item towers, hindering
the prediction accuracy critically. In this paper, we show it is possible to
design a two-tower model that emphasizes both information interactions and
inference efficiency. The proposed model, IntTower (short for
\textit{Interaction enhanced Two-Tower}), consists of Light-SE, FE-Block and
CIR modules. Specifically, lightweight Light-SE module is used to identify the
importance of different features and obtain refined feature representations in
each tower. FE-Block module performs fine-grained and early feature
interactions to capture the interactive signals between user and item towers
explicitly and CIR module leverages a contrastive interaction regularization to
further enhance the interactions implicitly. Experimental results on three
public datasets show that IntTower outperforms the SOTA pre-ranking models
significantly and even achieves comparable performance in comparison with the
ranking models. Moreover, we further verify the effectiveness of IntTower on a
large-scale advertisement pre-ranking system. The code of IntTower is publicly
available\footnote{https://github.com/archersama/IntTower}",-0.16217902,-0.1470455,-0.015777059,A
12732,"In
(a) Effectiveness of BAL algorithm (b) Effectiveness of user behavior model design                                                 the existing ULTR and click model techniques, only position-related
                                                                                                                                   user behavior models are utilized for further study.","The most
                                                                                                   BAL PB-BAL FB-BAL Na√Øve         frequently utilized one is the [21] which proposes that the user
                                                                                                                                   shows more attention to the document with a higher position.","Figure 4: (a) Average positions after re-ranking of docu-
ments at the top-10 original position by different ULTR                                                                               Click Model.",2022-10-19 16:53:08+00:00,Whole Page Unbiased Learning to Rank,cs.IR,"['cs.IR', 'cs.AI']","[arxiv.Result.Author('Haitao Mao'), arxiv.Result.Author('Lixin Zou'), arxiv.Result.Author('Yujia Zheng'), arxiv.Result.Author('Jiliang Tang'), arxiv.Result.Author('Xiaokai Chu'), arxiv.Result.Author('Jiashu Zhao'), arxiv.Result.Author('Dawei Yin')]","The page presentation biases in the information retrieval system, especially
on the click behavior, is a well-known challenge that hinders improving ranking
models' performance with implicit user feedback. Unbiased Learning to
Rank~(ULTR) algorithms are then proposed to learn an unbiased ranking model
with biased click data. However, most existing algorithms are specifically
designed to mitigate position-related bias, e.g., trust bias, without
considering biases induced by other features in search result page
presentation(SERP). For example, the multimedia type may generate attractive
bias. Unfortunately, those biases widely exist in industrial systems and may
lead to an unsatisfactory search experience. Therefore, we introduce a new
problem, i.e., whole-page Unbiased Learning to Rank(WP-ULTR), aiming to handle
biases induced by whole-page SERP features simultaneously. It presents
tremendous challenges. For example, a suitable user behavior model (user
behavior hypothesis) can be hard to find; and complex biases cannot be handled
by existing algorithms. To address the above challenges, we propose a Bias
Agnostic whole-page unbiased Learning to rank algorithm, BAL, to automatically
discover and mitigate the biases from multiple SERP features with no specific
design. Experimental results on a real-world dataset verify the effectiveness
of the BAL.",0.12853499,-0.13224322,-0.0032172874,B
12804,"The study should be viewed as an
invitation for further research, methodological improvements, and applications that leverage
large pre-built knowledge bases to represent complex and multidisciplinary designs
automatically, efficiently, and accurately from unstructured natural language texts,
documents, and discourses.","It provides a novel and effective approach for design
representations as semantic networks, which has presented a contribution to the knowledge in
the intersection of engineering design and data science.","References

Ahmed, S., Kim, S., Wallace, K.M., 2007.",2022-10-20 19:03:52+00:00,Design Representation as Semantic Networks,cs.IR,['cs.IR'],"[arxiv.Result.Author('Serhad Sarica'), arxiv.Result.Author('Ji Han'), arxiv.Result.Author('Jianxi Luo')]","Design representation is a common task in the design process to facilitate
learning, analysis, redesign, communication, and other design activities.
Traditional representation techniques rely on human expertise and manual
construction and are difficult to repeat and scale. Here, we propose a
methodology that utilizes a pre-trained large-scale cross-domain design
knowledge base to automatically generate design representation as a semantic
network, i.e., a network of the entities and relations, based on design
descriptions in texts or natural languages. Our methodology requires no ad hoc
statistics. Based on a participatory study, we reveal the effectiveness and
differences of the semantic network representations that are automatically
generated with alternative knowledge bases. The findings illuminate future
research directions to enhance design representation as semantic networks.",0.08465357,0.38775033,0.03341333,C
12908,"The question of how to apply this item cross-session information
directly at a modeling level to enhance the recommendation effect is worthy of further research.","Several directions for future research are promising: First, the proposed algorithm
HICG-CL exploits item cross-session information by constructing a joint session graph during the training phase, which
means it still utilizes the information at a session level.","Second, when applied

Manuscript submitted to ACM
Heterogeneous Information Crossing on Graphs for Session-based Recommender Systems  23

in the practical applications, SBRS requires online calculating of user preferences based on recent behaviors, which is

time-consuming.",2022-10-24 04:02:33+00:00,Heterogeneous Information Crossing on Graphs for Session-based Recommender Systems,cs.IR,"['cs.IR', 'cs.LG']","[arxiv.Result.Author('Xiaolin Zheng'), arxiv.Result.Author('Rui Wu'), arxiv.Result.Author('Zhongxuan Han'), arxiv.Result.Author('Chaochao Chen'), arxiv.Result.Author('Linxun Chen'), arxiv.Result.Author('Bing Han')]","Recommender systems are fundamental information filtering techniques to
recommend content or items that meet users' personalities and potential needs.
As a crucial solution to address the difficulty of user identification and
unavailability of historical information, session-based recommender systems
provide recommendation services that only rely on users' behaviors in the
current session. However, most existing studies are not well-designed for
modeling heterogeneous user behaviors and capturing the relationships between
them in practical scenarios. To fill this gap, in this paper, we propose a
novel graph-based method, namely Heterogeneous Information Crossing on Graphs
(HICG). HICG utilizes multiple types of user behaviors in the sessions to
construct heterogeneous graphs, and captures users' current interests with
their long-term preferences by effectively crossing the heterogeneous
information on the graphs. In addition, we also propose an enhanced version,
named HICG-CL, which incorporates contrastive learning (CL) technique to
enhance item representation ability. By utilizing the item co-occurrence
relationships across different sessions, HICG-CL improves the recommendation
performance of HICG. We conduct extensive experiments on three real-world
recommendation datasets, and the results verify that (i) HICG achieves the
state-of-the-art performance by utilizing multiple types of behaviors on the
heterogeneous graph. (ii) HICG-CL further significantly improves the
recommendation performance of HICG by the proposed contrastive learning module.",0.114880145,-0.1945151,0.28312802,A
13376,"However, there are many unanswered questions, use
cases, and scenarios that need further research.","We have reviewed many interpretability methods and approaches
that cover various aspects and tasks in IR.","We feel that most interpretability approaches have
focussed on the functional aspect of the central IR tasks of ranking items.",2022-11-04 12:26:25+00:00,Explainable Information Retrieval: A Survey,cs.IR,['cs.IR'],"[arxiv.Result.Author('Avishek Anand'), arxiv.Result.Author('Lijun Lyu'), arxiv.Result.Author('Maximilian Idahl'), arxiv.Result.Author('Yumeng Wang'), arxiv.Result.Author('Jonas Wallat'), arxiv.Result.Author('Zijian Zhang')]","Explainable information retrieval is an emerging research area aiming to make
transparent and trustworthy information retrieval systems. Given the increasing
use of complex machine learning models in search systems, explainability is
essential in building and auditing responsible information retrieval models.
This survey fills a vital gap in the otherwise topically diverse literature of
explainable information retrieval. It categorizes and discusses recent
explainability methods developed for different application domains in
information retrieval, providing a common framework and unifying perspectives.
In addition, it reflects on the common concern of evaluating explanations and
highlights open challenges and opportunities.",0.22116977,0.10210307,-0.05194862,C
13395,"By regarding
users who have interacted with the long-tail items as ‚Äòtail                                                                                                                           As illustrated in Figure 3(a), our proposed CANet frame-
users‚Äô and the rest as ‚Äòhead users‚Äô, we can further study the                                                                                                                      work is made up of a light-weighted router and a backbone
recommendation results for users with diverse preferences.","Framework Description
head items and the rest are treated as tail items.",network.,2022-11-05 06:39:06+00:00,"One Person, One Model--Learning Compound Router for Sequential Recommendation",cs.IR,['cs.IR'],"[arxiv.Result.Author('Zhiding Liu'), arxiv.Result.Author('Mingyue Cheng'), arxiv.Result.Author('Zhi li'), arxiv.Result.Author('Qi Liu'), arxiv.Result.Author('Enhong Chen')]","Deep learning has brought significant breakthroughs in sequential
recommendation (SR) for capturing dynamic user interests. A series of recent
research revealed that models with more parameters usually achieve optimal
performance for SR tasks, inevitably resulting in great challenges for
deploying them in real systems. Following the simple assumption that light
networks might already suffice for certain users, in this work, we propose
CANet, a conceptually simple yet very scalable framework for assigning adaptive
network architecture in an input-dependent manner to reduce unnecessary
computation. The core idea of CANet is to route the input user behaviors with a
light-weighted router module. Specifically, we first construct the routing
space with various submodels parameterized in terms of multiple model
dimensions such as the number of layers, hidden size and embedding size. To
avoid extra storage overhead of the routing space, we employ a weight-slicing
schema to maintain all the submodels in exactly one network. Furthermore, we
leverage several solutions to solve the discrete optimization issues caused by
the router module. Thanks to them, CANet could adaptively adjust its network
architecture for each input in an end-to-end manner, in which the user
preference can be effectively captured. To evaluate our work, we conduct
extensive experiments on benchmark datasets. Experimental results show that
CANet reduces computation by 55 ~ 65% while preserving the accuracy of the
original model. Our codes are available at
https://github.com/icantnamemyself/CANet.",0.25499576,-0.19720772,0.18099262,B
13396,"To further study the efÔ¨Åciency of each
   2http://www.dtic.upf.edu/ocelma/MusicRecommendationDataset/lastfm-   model, we employ FLOPs as another metric.","Note that we evaluate each method on
      Layer Depth      2, 4, 6, 8                                       the whole item set instead of sampling negative items, which
                                                                        is questioned by [36].","Since CANet and
1K.html

   3https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-
from-multi-category-store
                                                                      TABLE III
                       PERFORMANCE COMPARASION IN TERMS OF NDCG@10, RECALL@10 AND FLOPS

Model         Dynamic                   Last.FM20                    Last.FM50                                                     RESS     FLOPs (M)
                       NDCG@10 Recall@10 FLOPs (M)  NDCG@10 Recall@10 FLOPs (M)                                NDCG@10 Recall@10
                                                                                                                                               57.704
FPMC                √ó  0.3655  0.4345  101.894                     0.3675  0.4472             101.786          0.1284  0.2385                  57.832
                       0.3887  0.4496  67.926                      0.4090  0.4697             123.342          0.1507  0.2760                  91.932
GRU4Rec             √ó  0.3863  0.4473  114.026                     0.4089  0.4703             208.590          0.1669  0.2979                  93.118
                       0.3948  0.4648  115.214                     0.4114  0.4804             211.560          0.1666  0.3000                  45.114
Nextitnet           √ó  0.3856  0.4571  56.582                      0.4010  0.4681             68.148           0.1628  0.2944
                                                                                                                                               84.926
SASRec-full         √ó                                                                                                                              /

SASRec-small        √ó                                                                                                                          37.348

SkipRec                0.3940  0.4657  104.534                     0.4118  0.4806             197.156          0.1643  0.2966                   59.89
AutoDim                0.3926  0.4610      /                       0.4084  0.4750                 /            0.1649  0.2974
CANet                  0.3898  0.4587                              0.4045  0.4706                              0.1637  0.2948
                                       53.226                                                 73.930

       Improve (%)     -1.26   -1.31   53.80                       -1.68   -2.04                65.05          -1.74   -1.73

SkipRec are dynamic frameworks, their FLOPs are the average        and AutoDim, we conduct ablation studies on the routing
of all inputs.",2022-11-05 06:39:06+00:00,"One Person, One Model--Learning Compound Router for Sequential Recommendation",cs.IR,['cs.IR'],"[arxiv.Result.Author('Zhiding Liu'), arxiv.Result.Author('Mingyue Cheng'), arxiv.Result.Author('Zhi li'), arxiv.Result.Author('Qi Liu'), arxiv.Result.Author('Enhong Chen')]","Deep learning has brought significant breakthroughs in sequential
recommendation (SR) for capturing dynamic user interests. A series of recent
research revealed that models with more parameters usually achieve optimal
performance for SR tasks, inevitably resulting in great challenges for
deploying them in real systems. Following the simple assumption that light
networks might already suffice for certain users, in this work, we propose
CANet, a conceptually simple yet very scalable framework for assigning adaptive
network architecture in an input-dependent manner to reduce unnecessary
computation. The core idea of CANet is to route the input user behaviors with a
light-weighted router module. Specifically, we first construct the routing
space with various submodels parameterized in terms of multiple model
dimensions such as the number of layers, hidden size and embedding size. To
avoid extra storage overhead of the routing space, we employ a weight-slicing
schema to maintain all the submodels in exactly one network. Furthermore, we
leverage several solutions to solve the discrete optimization issues caused by
the router module. Thanks to them, CANet could adaptively adjust its network
architecture for each input in an end-to-end manner, in which the user
preference can be effectively captured. To evaluate our work, we conduct
extensive experiments on benchmark datasets. Experimental results show that
CANet reduces computation by 55 ~ 65% while preserving the accuracy of the
original model. Our codes are available at
https://github.com/icantnamemyself/CANet.",-0.21294701,-0.2520339,0.035330493,A
13397,"By regarding
users who have interacted with the long-tail items as ‚Äòtail                                                                                                                           As illustrated in Figure 3(a), our proposed CANet frame-
users‚Äô and the rest as ‚Äòhead users‚Äô, we can further study the                                                                                                                      work is made up of a light-weighted router and a backbone
recommendation results for users with diverse preferences.","Framework Description
head items and the rest are treated as tail items.",network.,2022-11-05 06:39:06+00:00,"One Person, One Model--Learning Compound Router for Sequential Recommendation",cs.IR,['cs.IR'],"[arxiv.Result.Author('Zhiding Liu'), arxiv.Result.Author('Mingyue Cheng'), arxiv.Result.Author('Zhi Li'), arxiv.Result.Author('Qi Liu'), arxiv.Result.Author('Enhong Chen')]","Deep learning has brought significant breakthroughs in sequential
recommendation (SR) for capturing dynamic user interests. A series of recent
research revealed that models with more parameters usually achieve optimal
performance for SR tasks, inevitably resulting in great challenges for
deploying them in real systems. Following the simple assumption that light
networks might already suffice for certain users, in this work, we propose
CANet, a conceptually simple yet very scalable framework for assigning adaptive
network architecture in an input-dependent manner to reduce unnecessary
computation. The core idea of CANet is to route the input user behaviors with a
light-weighted router module. Specifically, we first construct the routing
space with various submodels parameterized in terms of multiple model
dimensions such as the number of layers, hidden size and embedding size. To
avoid extra storage overhead of the routing space, we employ a weight-slicing
schema to maintain all the submodels in exactly one network. Furthermore, we
leverage several solutions to solve the discrete optimization issues caused by
the router module. Thanks to them, CANet could adaptively adjust its network
architecture for each input in an end-to-end manner, in which the user
preference can be effectively captured. To evaluate our work, we conduct
extensive experiments on benchmark datasets. Experimental results show that
CANet reduces computation by 55 ~ 65% while preserving the accuracy of the
original model. Our codes are available at
https://github.com/icantnamemyself/CANet.",0.25499576,-0.19720772,0.18099262,B
13398,"To further study the efÔ¨Åciency of each
   2http://www.dtic.upf.edu/ocelma/MusicRecommendationDataset/lastfm-   model, we employ FLOPs as another metric.","Note that we evaluate each method on
      Layer Depth      2, 4, 6, 8                                       the whole item set instead of sampling negative items, which
                                                                        is questioned by [36].","Since CANet and
1K.html

   3https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-
from-multi-category-store
                                                                      TABLE III
                       PERFORMANCE COMPARASION IN TERMS OF NDCG@10, RECALL@10 AND FLOPS

Model         Dynamic                   Last.FM20                    Last.FM50                                                     RESS     FLOPs (M)
                       NDCG@10 Recall@10 FLOPs (M)  NDCG@10 Recall@10 FLOPs (M)                                NDCG@10 Recall@10
                                                                                                                                               57.704
FPMC                √ó  0.3655  0.4345  101.894                     0.3675  0.4472             101.786          0.1284  0.2385                  57.832
                       0.3887  0.4496  67.926                      0.4090  0.4697             123.342          0.1507  0.2760                  91.932
GRU4Rec             √ó  0.3863  0.4473  114.026                     0.4089  0.4703             208.590          0.1669  0.2979                  93.118
                       0.3948  0.4648  115.214                     0.4114  0.4804             211.560          0.1666  0.3000                  45.114
Nextitnet           √ó  0.3856  0.4571  56.582                      0.4010  0.4681             68.148           0.1628  0.2944
                                                                                                                                               84.926
SASRec-full         √ó                                                                                                                              /

SASRec-small        √ó                                                                                                                          37.348

SkipRec                0.3940  0.4657  104.534                     0.4118  0.4806             197.156          0.1643  0.2966                   59.89
AutoDim                0.3926  0.4610      /                       0.4084  0.4750                 /            0.1649  0.2974
CANet                  0.3898  0.4587                              0.4045  0.4706                              0.1637  0.2948
                                       53.226                                                 73.930

       Improve (%)     -1.26   -1.31   53.80                       -1.68   -2.04                65.05          -1.74   -1.73

SkipRec are dynamic frameworks, their FLOPs are the average        and AutoDim, we conduct ablation studies on the routing
of all inputs.",2022-11-05 06:39:06+00:00,"One Person, One Model--Learning Compound Router for Sequential Recommendation",cs.IR,['cs.IR'],"[arxiv.Result.Author('Zhiding Liu'), arxiv.Result.Author('Mingyue Cheng'), arxiv.Result.Author('Zhi Li'), arxiv.Result.Author('Qi Liu'), arxiv.Result.Author('Enhong Chen')]","Deep learning has brought significant breakthroughs in sequential
recommendation (SR) for capturing dynamic user interests. A series of recent
research revealed that models with more parameters usually achieve optimal
performance for SR tasks, inevitably resulting in great challenges for
deploying them in real systems. Following the simple assumption that light
networks might already suffice for certain users, in this work, we propose
CANet, a conceptually simple yet very scalable framework for assigning adaptive
network architecture in an input-dependent manner to reduce unnecessary
computation. The core idea of CANet is to route the input user behaviors with a
light-weighted router module. Specifically, we first construct the routing
space with various submodels parameterized in terms of multiple model
dimensions such as the number of layers, hidden size and embedding size. To
avoid extra storage overhead of the routing space, we employ a weight-slicing
schema to maintain all the submodels in exactly one network. Furthermore, we
leverage several solutions to solve the discrete optimization issues caused by
the router module. Thanks to them, CANet could adaptively adjust its network
architecture for each input in an end-to-end manner, in which the user
preference can be effectively captured. To evaluate our work, we conduct
extensive experiments on benchmark datasets. Experimental results show that
CANet reduces computation by 55 ~ 65% while preserving the accuracy of the
original model. Our codes are available at
https://github.com/icantnamemyself/CANet.",-0.21294701,-0.2520339,0.035330493,A
13712,"Finally, I would like to express my gratitude to my family sincerely because I could
not start my further study without their support.","I would also like to thank lecturers and staffs from School of Computer Science and
Statistics and class fellow for their helps in my postgradulate study.","Yuzhou Peng

University of Dublin, Trinity College
August 2018

                                       iii
Talent Recommendation on LinkedIn User Profiles

                    Yuzhou Peng , Master of Science in Computer Science
                           University of Dublin, Trinity College, 2018

                              Supervisor: Professor Seamus Lawless,

With the increasing amount of information on the Internet, recommender systems are
becoming increasingly crucial in supporting people to find and explore relevant
content.",2022-11-14 12:18:03+00:00,Talent Recommendation on LinkedIn User Profiles,cs.IR,['cs.IR'],[arxiv.Result.Author('Yuzhou Peng')],"With the increasing amount of information on the Internet, recommender
systems are becoming increasingly crucial in supporting people to find and
explore relevant content. This is also true in the online recruitment space,
with websites such as LinkedIn, Indeed.com, and Monster.com all using
recommender systems. In online recruitment, it can often be challenging for
companies to find suitable candidates with appropriate skills because of the
huge volume of user profiles available. Identifying users which satisfy a range
of different employer needs is also a difficult task. Thus, effective matching
of user-profiles and jobs is becoming crucial for companies. This research
project applies a wide range of recommendation techniques to the task of user
profile recommendation. Extensive experiments are conducted on a large-scale
real-world LinkedIn dataset to evaluate their performance, with the aim of
identifying the most suitable approach in this particular recommendation
scenario.",0.2946764,-0.067836024,0.2043905,B
14016,this compartment and provide insight for further research.,"More
synthesizing different papers in each compartment, common       importantly, each document set is from a different topic with
features will be extracted to both conclude the core idea of    multiple topic related documents inside.","3.2 Evaluation Metrics
3 Text Summarization Evaluation
                                                                The answer to what is a good metric for text summariza-
One of the most important portions in developing an effective   tion tasks is not trivial because the actual quality of the text
machine learning algorithm is to have validated evaluation      summaries is much more subjective than label matching in
that ensures the generalization of the developed algorithm      discriminative models such as text classification models, i.e.",2022-09-17 05:34:32+00:00,Survey of Query-based Text Summarization,cs.IR,"['cs.IR', 'cs.CL']",[arxiv.Result.Author('Hang Yu')],"Query-based text summarization is an important real world problem that
requires to condense the prolix text data into a summary under the guidance of
the query information provided by users. The topic has been studied for a long
time and there are many existing interesting research related to query-based
text summarization. Yet much of the work is not systematically surveyed. This
survey aims at summarizing some interesting work in query-based text
summarization methods as well as related generic text summarization methods.
Not all taxonomies in this paper exist the related work to the best of our
knowledge and some analysis will be presented.",0.057539754,0.1931336,0.088261455,C
14259,"Section 7 concludes the paper with further research direc-
tions.",Section 6 discusses related work.,All proofs are provided in the Appendix.,2022-11-23 22:20:12+00:00,Incentive-Aware Recommender Systems in Two-Sided Markets,cs.IR,"['cs.IR', 'cs.LG', 'stat.ML']","[arxiv.Result.Author('Xiaowu Dai'), arxiv.Result.Author('Yuan'), arxiv.Result.Author('Qi'), arxiv.Result.Author('Michael I. Jordan')]","Online platforms in the Internet Economy commonly incorporate recommender
systems that recommend arms (e.g., products) to agents (e.g., users). In such
platforms, a myopic agent has a natural incentive to exploit, by choosing the
best product given the current information rather than to explore various
alternatives to collect information that will be used for other agents. We
propose a novel recommender system that respects agents' incentives and enjoys
asymptotically optimal performances expressed by the regret in repeated games.
We model such an incentive-aware recommender system as a multi-agent bandit
problem in a two-sided market which is equipped with an incentive constraint
induced by agents' opportunity costs. If the opportunity costs are known to the
principal, we show that there exists an incentive-compatible recommendation
policy, which pools recommendations across a genuinely good arm and an unknown
arm via a randomized and adaptive approach. On the other hand, if the
opportunity costs are unknown to the principal, we propose a policy that
randomly pools recommendations across all arms and uses each arm's cumulative
loss as feedback for exploration. We show that both policies also satisfy an
ex-post fairness criterion, which protects agents from over-exploitation.",-0.30555913,0.14599377,-0.018613867,A
14261,"In so doing, the various
                                ML techniques used, challenges, limitations and scope of further research are
                                explained.","The present review identifies the objectives of the automation stud-
                                ies and the aspects of those steps that were automated.","Methods: Accessible published literature studies that primarily focus on auto-
                                mation of study selection, study quality assessment, data extraction and data syn-
                                thesis portions of SLR.",2022-11-20 04:42:14+00:00,Automating Systematic Literature Reviews with Natural Language Processing and Text Mining: a Systematic Literature Review,cs.IR,['cs.IR'],"[arxiv.Result.Author('Girish Sundaram'), arxiv.Result.Author('Daniel Berleant')]","Objectives: An SLR is presented focusing on text mining based automation of
SLR creation. The present review identifies the objectives of the automation
studies and the aspects of those steps that were automated. In so doing, the
various ML techniques used, challenges, limitations and scope of further
research are explained.
  Methods: Accessible published literature studies that primarily focus on
automation of study selection, study quality assessment, data extraction and
data synthesis portions of SLR. Twenty-nine studies were analyzed.
  Results: This review identifies the objectives of the automation studies,
steps within the study selection, study quality assessment, data extraction and
data synthesis portions that were automated, the various ML techniques used,
challenges, limitations and scope of further research.
  Discussion: We describe uses of NLP/TM techniques to support increased
automation of systematic literature reviews. This area has attracted increase
attention in the last decade due to significant gaps in the applicability of TM
to automate steps in the SLR process. There are significant gaps in the
application of TM and related automation techniques in the areas of data
extraction, monitoring, quality assessment and data synthesis. There is thus a
need for continued progress in this area, and this is expected to ultimately
significantly facilitate the construction of systematic literature reviews.",0.032060895,0.2177265,-0.19628185,C
14262,"Results: This review identifies the objectives of the automation studies, steps
                                within the study selection, study quality assessment, data extraction and data syn-
                                thesis portions that were automated, the various ML techniques used, challenges,
                                limitations and scope of further research.",Twenty-nine studies were analyzed.,"Discussion: We describe uses of NLP/TM techniques to support increased au-
                                tomation of systematic literature reviews.",2022-11-20 04:42:14+00:00,Automating Systematic Literature Reviews with Natural Language Processing and Text Mining: a Systematic Literature Review,cs.IR,['cs.IR'],"[arxiv.Result.Author('Girish Sundaram'), arxiv.Result.Author('Daniel Berleant')]","Objectives: An SLR is presented focusing on text mining based automation of
SLR creation. The present review identifies the objectives of the automation
studies and the aspects of those steps that were automated. In so doing, the
various ML techniques used, challenges, limitations and scope of further
research are explained.
  Methods: Accessible published literature studies that primarily focus on
automation of study selection, study quality assessment, data extraction and
data synthesis portions of SLR. Twenty-nine studies were analyzed.
  Results: This review identifies the objectives of the automation studies,
steps within the study selection, study quality assessment, data extraction and
data synthesis portions that were automated, the various ML techniques used,
challenges, limitations and scope of further research.
  Discussion: We describe uses of NLP/TM techniques to support increased
automation of systematic literature reviews. This area has attracted increase
attention in the last decade due to significant gaps in the applicability of TM
to automate steps in the SLR process. There are significant gaps in the
application of TM and related automation techniques in the areas of data
extraction, monitoring, quality assessment and data synthesis. There is thus a
need for continued progress in this area, and this is expected to ultimately
significantly facilitate the construction of systematic literature reviews.",0.0784467,0.29397768,-0.11233021,C
14263,"One objective of performing this SLR is to identify specific steps where there
has been considerable activity and where there is a scope for further research.","This paper performs an SLR on the current state of
the art.","We have
adapted Table 1 from Kitchenham and Charters [4] to name the steps within the SLR
process.",2022-11-20 04:42:14+00:00,Automating Systematic Literature Reviews with Natural Language Processing and Text Mining: a Systematic Literature Review,cs.IR,['cs.IR'],"[arxiv.Result.Author('Girish Sundaram'), arxiv.Result.Author('Daniel Berleant')]","Objectives: An SLR is presented focusing on text mining based automation of
SLR creation. The present review identifies the objectives of the automation
studies and the aspects of those steps that were automated. In so doing, the
various ML techniques used, challenges, limitations and scope of further
research are explained.
  Methods: Accessible published literature studies that primarily focus on
automation of study selection, study quality assessment, data extraction and
data synthesis portions of SLR. Twenty-nine studies were analyzed.
  Results: This review identifies the objectives of the automation studies,
steps within the study selection, study quality assessment, data extraction and
data synthesis portions that were automated, the various ML techniques used,
challenges, limitations and scope of further research.
  Discussion: We describe uses of NLP/TM techniques to support increased
automation of systematic literature reviews. This area has attracted increase
attention in the last decade due to significant gaps in the applicability of TM
to automate steps in the SLR process. There are significant gaps in the
application of TM and related automation techniques in the areas of data
extraction, monitoring, quality assessment and data synthesis. There is thus a
need for continued progress in this area, and this is expected to ultimately
significantly facilitate the construction of systematic literature reviews.",-0.123295724,0.23103294,-0.20027629,C
14264,"The
associated language bias problem helps define the scope of further research in the ap-
plication of OCR and NLP to query definition.",Computational reasoning tasks have not been used extensively in SLRs [30-32].,"The application of Automatic Query
Expansion (AQE) (synonym expansion, word sense disambiguation, auto-correction
etc.)",2022-11-20 04:42:14+00:00,Automating Systematic Literature Reviews with Natural Language Processing and Text Mining: a Systematic Literature Review,cs.IR,['cs.IR'],"[arxiv.Result.Author('Girish Sundaram'), arxiv.Result.Author('Daniel Berleant')]","Objectives: An SLR is presented focusing on text mining based automation of
SLR creation. The present review identifies the objectives of the automation
studies and the aspects of those steps that were automated. In so doing, the
various ML techniques used, challenges, limitations and scope of further
research are explained.
  Methods: Accessible published literature studies that primarily focus on
automation of study selection, study quality assessment, data extraction and
data synthesis portions of SLR. Twenty-nine studies were analyzed.
  Results: This review identifies the objectives of the automation studies,
steps within the study selection, study quality assessment, data extraction and
data synthesis portions that were automated, the various ML techniques used,
challenges, limitations and scope of further research.
  Discussion: We describe uses of NLP/TM techniques to support increased
automation of systematic literature reviews. This area has attracted increase
attention in the last decade due to significant gaps in the applicability of TM
to automate steps in the SLR process. There are significant gaps in the
application of TM and related automation techniques in the areas of data
extraction, monitoring, quality assessment and data synthesis. There is thus a
need for continued progress in this area, and this is expected to ultimately
significantly facilitate the construction of systematic literature reviews.",0.03511604,0.43808013,0.008229125,C
14909,"However, we plan to expand the data set in further research by adding articles
from other news outlets.","We select The Guardian as
data source for news articles due to its general trustworthiness and consistent
assignment of tags to articles, on which we base the creation of our data set.","78.3 % of the collected tweets contain a headline and a
link to the corresponding article on theguardian.com.",2022-12-13 12:51:14+00:00,Automatic ESG Assessment of Companies by Mining and Evaluating Media Coverage Data: NLP Approach and Tool,cs.IR,['cs.IR'],"[arxiv.Result.Author('Jannik Fischbach'), arxiv.Result.Author('Max Adam'), arxiv.Result.Author('Victor Dzhagatspanyan'), arxiv.Result.Author('Daniel Mendez'), arxiv.Result.Author('Julian Frattini'), arxiv.Result.Author('Oleksandr Kosenkov'), arxiv.Result.Author('Parisa Elahidoost')]","Context: Sustainable corporate behavior is increasingly valued by society and
impacts corporate reputation and customer trust. Hence, companies regularly
publish sustainability reports to shed light on their impact on environmental,
social, and governance (ESG) factors. Problem: Sustainability reports are
written by companies themselves and are therefore considered a
company-controlled source. Contrary, studies reveal that non-corporate channels
(e.g., media coverage) represent the main driver for ESG transparency. However,
analysing media coverage regarding ESG factors is challenging since (1) the
amount of published news articles grows daily, (2) media coverage data does not
necessarily deal with an ESG-relevant topic, meaning that it must be carefully
filtered, and (3) the majority of media coverage data is unstructured. Research
Goal: We aim to extract ESG-relevant information from textual media reactions
automatically to calculate an ESG score for a given company. Our goal is to
reduce the cost of ESG data collection and make ESG information available to
the general public. Contribution: Our contributions are three-fold: First, we
publish a corpus of 432,411 news headlines annotated as being environmental-,
governance-, social-related, or ESG-irrelevant. Second, we present our
tool-supported approach called ESG-Miner capable of analyzing and evaluating
headlines on corporate ESG-performance automatically. Third, we demonstrate the
feasibility of our approach in an experiment and apply the ESG-Miner on 3000
manually labeled headlines. Our approach processes 96.7 % of the headlines
correctly and shows a great performance in detecting environmental-related
headlines along with their correct sentiment. We encourage fellow researchers
and practitioners to use the ESG-Miner at https://www.esg-miner.com.",0.2680499,0.15616252,0.046443492,C
14910,"Although our evaluation
on 3000 unseen headlines showed that the ESG-Miner performs well in detecting
environmental-related headlines, we also observed several limitations (L) that
need to be addressed in further research:

  ‚Äì L1: The ESG-Miner is only suitable for analyzing the ESG performance
     of companies that are frequently featured in news articles.","We use
this corpus to train our NLP approach called ESG-Miner capable of detecting
companies in headlines, classifying them as ESG-relevant/irrelevant, assigning
relevant headlines into one of the three ESG domains, and calculating a Ô¨Ånal
ESG score by analyzing the sentiments of the headlines.","Thus, the ESG
     performance of companies with little or no coverage in headlines remains
     intransparent.",2022-12-13 12:51:14+00:00,Automatic ESG Assessment of Companies by Mining and Evaluating Media Coverage Data: NLP Approach and Tool,cs.IR,['cs.IR'],"[arxiv.Result.Author('Jannik Fischbach'), arxiv.Result.Author('Max Adam'), arxiv.Result.Author('Victor Dzhagatspanyan'), arxiv.Result.Author('Daniel Mendez'), arxiv.Result.Author('Julian Frattini'), arxiv.Result.Author('Oleksandr Kosenkov'), arxiv.Result.Author('Parisa Elahidoost')]","Context: Sustainable corporate behavior is increasingly valued by society and
impacts corporate reputation and customer trust. Hence, companies regularly
publish sustainability reports to shed light on their impact on environmental,
social, and governance (ESG) factors. Problem: Sustainability reports are
written by companies themselves and are therefore considered a
company-controlled source. Contrary, studies reveal that non-corporate channels
(e.g., media coverage) represent the main driver for ESG transparency. However,
analysing media coverage regarding ESG factors is challenging since (1) the
amount of published news articles grows daily, (2) media coverage data does not
necessarily deal with an ESG-relevant topic, meaning that it must be carefully
filtered, and (3) the majority of media coverage data is unstructured. Research
Goal: We aim to extract ESG-relevant information from textual media reactions
automatically to calculate an ESG score for a given company. Our goal is to
reduce the cost of ESG data collection and make ESG information available to
the general public. Contribution: Our contributions are three-fold: First, we
publish a corpus of 432,411 news headlines annotated as being environmental-,
governance-, social-related, or ESG-irrelevant. Second, we present our
tool-supported approach called ESG-Miner capable of analyzing and evaluating
headlines on corporate ESG-performance automatically. Third, we demonstrate the
feasibility of our approach in an experiment and apply the ESG-Miner on 3000
manually labeled headlines. Our approach processes 96.7 % of the headlines
correctly and shows a great performance in detecting environmental-related
headlines along with their correct sentiment. We encourage fellow researchers
and practitioners to use the ESG-Miner at https://www.esg-miner.com.",0.08670452,0.13825968,0.07391603,C
14913,"We further study the combination of this approach with knowledge distil-
lation, in which an interaction-based model is use as the teacher model, the
student model being the dense retrieval model.","Our study reveals that this approach
works well when the pseudo-labels are generated using a combination of BM25
and T53B, and that it helps improve the generalization results of the GPL model
which also makes use of generated queries and associated relevant documents on
the target collection.","Our experiments indicate that
the proposed pseudo-labeling with T53B and using MiniLM teacher outperform
other methods on average, obtaining new state-of-the-art results on several data
sets for DR model‚Äôs domain generalization.",2022-12-13 13:08:03+00:00,Domain Adaptation for Dense Retrieval through Self-Supervision by Pseudo-Relevance Labeling,cs.IR,['cs.IR'],"[arxiv.Result.Author('Minghan Li'), arxiv.Result.Author('Eric Gaussier')]","Although neural information retrieval has witnessed great improvements,
recent works showed that the generalization ability of dense retrieval models
on target domains with different distributions is limited, which contrasts with
the results obtained with interaction-based models. To address this issue,
researchers have resorted to adversarial learning and query generation
approaches; both approaches nevertheless resulted in limited improvements. In
this paper, we propose to use a self-supervision approach in which
pseudo-relevance labels are automatically generated on the target domain. To do
so, we first use the standard BM25 model on the target domain to obtain a first
ranking of documents, and then use the interaction-based model T53B to re-rank
top documents. We further combine this approach with knowledge distillation
relying on an interaction-based teacher model trained on the source domain. Our
experiments reveal that pseudo-relevance labeling using T53B and the MiniLM
teacher performs on average better than other approaches and helps improve the
state-of-the-art query generation approach GPL when it is fine-tuned on the
pseudo-relevance labeled data.",-0.0048884004,0.26739886,0.24878597,C
15087,"For example
                                        further research and experimentation, and we validate the results of                           for the Boolean query TB[tiab] OR tuberculosis[tiab] OR
                                        the methods contained in the library on standard datasets.","For the Python                                operators) and output one or more MeSH terms (sometimes dir-
                                        library, we describe how the library can be used for advancing                                 ectly in the context of the structured Boolean query).","Our web-                            MDR-TB[tiab] OR XDR-TB[tiab], ATM suggests the MeSH term
                                        based prototype system is available at http://ielab-mesh-suggest.",2022-12-18 05:32:19+00:00,MeSH Suggester: A Library and System for MeSH Term Suggestion for Systematic Review Boolean Query Construction,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Shuai Wang'), arxiv.Result.Author('Hang Li'), arxiv.Result.Author('Guido Zuccon')]","Boolean query construction is often critical for medical systematic review
literature search. To create an effective Boolean query, systematic review
researchers typically spend weeks coming up with effective query terms and
combinations. One challenge to creating an effective systematic review Boolean
query is the selection of effective MeSH Terms to include in the query. In our
previous work, we created neural MeSH term suggestion methods and compared them
to state-of-the-art MeSH term suggestion methods. We found neural MeSH term
suggestion methods to be highly effective.
  In this demonstration, we build upon our previous work by creating (1) a
Web-based MeSH term suggestion prototype system that allows users to obtain
suggestions from a number of underlying methods and (2) a Python library that
implements ours and others' MeSH term suggestion methods and that is aimed at
researchers who want to further investigate, create or deploy such type of
methods. We describe the architecture of the web-based system and how to use it
for the MeSH term suggestion task. For the Python library, we describe how the
library can be used for advancing further research and experimentation, and we
validate the results of the methods contained in the library on standard
datasets. Our web-based prototype system is available at
http://ielab-mesh-suggest.uqcloud.net, while our Python library is at
https://github.com/ielab/meshsuggestlib.",-0.1002462,0.31414613,0.11141175,C
15217,"While growers may          ferent query types (natural language vs keyword),
               recognise the value of this, they do not necessarily    as well as human generated answers; thus pro-
               want to delve into detailed scientiÔ¨Åc information,      viding a resource for further research on query
               or have the expertise to do so.","The collection contains dif-
               entiÔ¨Åc evidence and sources.","Instead, they           variations and automated answer generation.",2022-12-21 04:49:21+00:00,AgAsk: An Agent to Help Answer Farmer's Questions From Scientific Documents,cs.IR,['cs.IR'],"[arxiv.Result.Author('Bevan Koopman'), arxiv.Result.Author('Ahmed Mourad'), arxiv.Result.Author('Hang Li'), arxiv.Result.Author('Anton van der Vegt'), arxiv.Result.Author('Shengyao Zhuang'), arxiv.Result.Author('Simon Gibson'), arxiv.Result.Author('Yash Dang'), arxiv.Result.Author('David Lawrence'), arxiv.Result.Author('Guido Zuccon')]","Decisions in agriculture are increasingly data-driven; however, valuable
agricultural knowledge is often locked away in free-text reports, manuals and
journal articles. Specialised search systems are needed that can mine
agricultural information to provide relevant answers to users' questions. This
paper presents AgAsk -- an agent able to answer natural language agriculture
questions by mining scientific documents.
  We carefully survey and analyse farmers' information needs. On the basis of
these needs we release an information retrieval test collection comprising real
questions, a large collection of scientific documents split in passages, and
ground truth relevance assessments indicating which passages are relevant to
each question.
  We implement and evaluate a number of information retrieval models to answer
farmers questions, including two state-of-the-art neural ranking models. We
show that neural rankers are highly effective at matching passages to questions
in this context.
  Finally, we propose a deployment architecture for AgAsk that includes a
client based on the Telegram messaging platform and retrieval model deployed on
commodity hardware.
  The test collection we provide is intended to stimulate more research in
methods to match natural language to answers in scientific documents. While the
retrieval models were evaluated in the agriculture domain, they are
generalisable and of interest to others working on similar problems.
  The test collection is available at:
\url{https://github.com/ielab/agvaluate}.",0.27321714,0.47344202,-0.022442332,C_centroid
15275,"We
actually do hope that this discussion and, especially, further research by others

                                                  15
will deliver much better solutions in this respect.","We just say that we
should strive for this goal in the most sound and safe way possible; the proposed
intervalization procedure is just a simple example of such an attempt.","Both here and in our work commented by MoÔ¨Äat, we have indicated what

this ‚Äúsound and safe way‚Äù could be, i.e.",2022-12-22 14:28:10+00:00,"Response to Moffat's Comment on ""Towards Meaningful Statements in IR Evaluation: Mapping Evaluation Measures to Interval Scales""",cs.IR,"['cs.IR', 'H.3.3']","[arxiv.Result.Author('Marco Ferrante'), arxiv.Result.Author('Nicola Ferro'), arxiv.Result.Author('Norbert Fuhr')]","Moffat recently commented on our previous work. Our work focused on how
laying the foundations of our evaluation methodology into the theory of
measurement can improve our knowledge and understanding of the evaluation
measures we use in IR and how it can shed light on the different types of
scales adopted by our evaluation measures; we also provided evidence, through
extensive experimentation, on the impact of the different types of scales on
the statistical analyses, as well as on the impact of departing from their
assumptions. Moreover, we investigated, for the first time in IR, the concept
of meaningfulness, i.e. the invariance of the experimental statements and
inferences you draw, and proposed it as a way to ensure more valid and
generalizabile results. Moffat's comments build on: (i) misconceptions about
the representational theory of measurement, such as what an interval scale
actually is and what axioms it has to comply with; (ii) they totally miss the
central concept of meaningfulness. Therefore, we reply to Moffat's comments by
properly framing them in the representational theory of measurement and in the
concept of meaningfulness. All in all, we can only reiterate what we said
several times: the goal of this research line is to theoretically ground our
evaluation methodology - and IR is a field where it is extremely challenging to
perform any theoretical advances - in order to aim for more robust and
generalizable inferences - something we currently lack in the field. Possibly
there are other and better ways to achieve this objective and these proposals
could emerge from an open discussion in the field and from the work of others.
On the other hand, reducing everything to a contrast on what is (or pretend to
be) an interval scale or whether all or none evaluation measures are interval
scales may be more a barrier from than a help in progressing towards this goal.",-0.10115287,0.11886504,-0.397341,A
15304,"Thus, how to tradeoÔ¨Ä the algorithm scalability and
graph integrity could be one of the further research directions.","Though the subgraph strategy makes
GNN-based algorithms applicable no matter how large-scale the whole graph
is, the shortcoming is that the node representation should be recalculated for
each propagation layer.","More researches
can be studied on the sampling strategy in integrating more informative infor-
mation from neighborhood nodes and links while minimizing the harm to the
graph integrity.",2022-12-23 10:01:14+00:00,Recommending on Graphs: A Comprehensive Review from Data Perspective,cs.IR,['cs.IR'],"[arxiv.Result.Author('Lemei Zhang'), arxiv.Result.Author('Peng Liu'), arxiv.Result.Author('Jon Atle Gulla')]","Recent advances in graph-based learning approaches have demonstrated their
effectiveness in modelling users' preferences and items' characteristics for
Recommender Systems (RSS). Most of the data in RSS can be organized into graphs
where various objects (e.g., users, items, and attributes) are explicitly or
implicitly connected and influence each other via various relations. Such a
graph-based organization brings benefits to exploiting potential properties in
graph learning (e.g., random walk and network embedding) techniques to enrich
the representations of the user and item nodes, which is an essential factor
for successful recommendations. In this paper, we provide a comprehensive
survey of Graph Learning-based Recommender Systems (GLRSs). Specifically, we
start from a data-driven perspective to systematically categorize various
graphs in GLRSs and analyze their characteristics. Then, we discuss the
state-of-the-art frameworks with a focus on the graph learning module and how
they address practical recommendation challenges such as scalability, fairness,
diversity, explainability and so on. Finally, we share some potential research
directions in this rapidly growing area.",-0.12444712,0.16484307,0.17686397,A
15305,"This is thus another research question for
further study.","These two kinds of integration strategies can
both contribute to the improvement of recommendations, but there is no evi-
dence showing which one is better.",Generality of Graph Learning.,2022-12-23 10:01:14+00:00,Recommending on Graphs: A Comprehensive Review from Data Perspective,cs.IR,['cs.IR'],"[arxiv.Result.Author('Lemei Zhang'), arxiv.Result.Author('Peng Liu'), arxiv.Result.Author('Jon Atle Gulla')]","Recent advances in graph-based learning approaches have demonstrated their
effectiveness in modelling users' preferences and items' characteristics for
Recommender Systems (RSS). Most of the data in RSS can be organized into graphs
where various objects (e.g., users, items, and attributes) are explicitly or
implicitly connected and influence each other via various relations. Such a
graph-based organization brings benefits to exploiting potential properties in
graph learning (e.g., random walk and network embedding) techniques to enrich
the representations of the user and item nodes, which is an essential factor
for successful recommendations. In this paper, we provide a comprehensive
survey of Graph Learning-based Recommender Systems (GLRSs). Specifically, we
start from a data-driven perspective to systematically categorize various
graphs in GLRSs and analyze their characteristics. Then, we discuss the
state-of-the-art frameworks with a focus on the graph learning module and how
they address practical recommendation challenges such as scalability, fairness,
diversity, explainability and so on. Finally, we share some potential research
directions in this rapidly growing area.",-0.021132298,0.014702661,0.10891792,A
15326,"We further study
diction uncertainty and risk tendency by comparing with             the inÔ¨Çuence of constant uncertainty r0 by varying it in
                                                                    range [0, 1.8 √ó r¬Østd].","The method CURLB
                                                                    achieves relative comparable performance with ekRLB even
To answer Q2, we study the individual contributions of pre-         though a constant uncertainty is applied.","Here we set constant uncertainty r0
                                                                    as a constant coefÔ¨Åcient multiplying with the average un-
                                                                    certainty r¬Østd in the training dataset.",2022-12-06 18:50:09+00:00,Adaptive Risk-Aware Bidding with Budget Constraint in Display Advertising,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Zhimeng Jiang'), arxiv.Result.Author('Kaixiong Zhou'), arxiv.Result.Author('Mi Zhang'), arxiv.Result.Author('Rui Chen'), arxiv.Result.Author('Xia Hu'), arxiv.Result.Author('Soo-Hyun Choi')]","Real-time bidding (RTB) has become a major paradigm of display advertising.
Each ad impression generated from a user visit is auctioned in real time, where
demand-side platform (DSP) automatically provides bid price usually relying on
the ad impression value estimation and the optimal bid price determination.
However, the current bid strategy overlooks large randomness of the user
behaviors (e.g., click) and the cost uncertainty caused by the auction
competition. In this work, we explicitly factor in the uncertainty of estimated
ad impression values and model the risk preference of a DSP under a specific
state and market environment via a sequential decision process. Specifically,
we propose a novel adaptive risk-aware bidding algorithm with budget constraint
via reinforcement learning, which is the first to simultaneously consider
estimation uncertainty and the dynamic risk tendency of a DSP. We theoretically
unveil the intrinsic relation between the uncertainty and the risk tendency
based on value at risk (VaR). Consequently, we propose two instantiations to
model risk tendency, including an expert knowledge-based formulation embracing
three essential properties and an adaptive learning method based on
self-supervised reinforcement learning. We conduct extensive experiments on
public datasets and show that the proposed framework outperforms
state-of-the-art methods in practical settings.",-0.30958176,-0.042194165,-0.2136769,A
15327,"We further study its inÔ¨Çuences by consider-          Subsequently, we developed two instantiations to determine
ing Œ≤0 within range [‚àí0.5, 0].",performance.,"We only use the negative risk      risk tendency based on expert knowledge or self-supervised
tendencies since a positive one tends to overestimate an ad       learning.",2022-12-06 18:50:09+00:00,Adaptive Risk-Aware Bidding with Budget Constraint in Display Advertising,cs.IR,"['cs.IR', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Zhimeng Jiang'), arxiv.Result.Author('Kaixiong Zhou'), arxiv.Result.Author('Mi Zhang'), arxiv.Result.Author('Rui Chen'), arxiv.Result.Author('Xia Hu'), arxiv.Result.Author('Soo-Hyun Choi')]","Real-time bidding (RTB) has become a major paradigm of display advertising.
Each ad impression generated from a user visit is auctioned in real time, where
demand-side platform (DSP) automatically provides bid price usually relying on
the ad impression value estimation and the optimal bid price determination.
However, the current bid strategy overlooks large randomness of the user
behaviors (e.g., click) and the cost uncertainty caused by the auction
competition. In this work, we explicitly factor in the uncertainty of estimated
ad impression values and model the risk preference of a DSP under a specific
state and market environment via a sequential decision process. Specifically,
we propose a novel adaptive risk-aware bidding algorithm with budget constraint
via reinforcement learning, which is the first to simultaneously consider
estimation uncertainty and the dynamic risk tendency of a DSP. We theoretically
unveil the intrinsic relation between the uncertainty and the risk tendency
based on value at risk (VaR). Consequently, we propose two instantiations to
model risk tendency, including an expert knowledge-based formulation embracing
three essential properties and an adaptive learning method based on
self-supervised reinforcement learning. We conduct extensive experiments on
public datasets and show that the proposed framework outperforms
state-of-the-art methods in practical settings.",-0.14063293,-0.0855382,-0.13053983,A
15374,"Since including missing data, improves over
standard learning procedures, this observation opens avenues for further research that includes
modeling or sampling missing data.","In this setting as well, our models outperform other alternatives along with
better scalability and guaranteed convergence.","46  Overcoming Missing Events in Continuous-Time Sequences
                   Part II
Recommendation in Spatio-Temporal

                   Settings

                                                47
Chapter 4

Cross-Region Transfer for Spatial
Features

4.1 Introduction

In this chapter, we present our solution to overcome the drawbacks of data scarcity for top-k
recommendations in spatial mobility networks.",2022-12-25 09:34:15+00:00,Modeling Time-Series and Spatial Data for Recommendations and Other Applications,cs.IR,"['cs.IR', 'cs.LG']",[arxiv.Result.Author('Vinayak Gupta')],"With the research directions described in this thesis, we seek to address the
critical challenges in designing recommender systems that can understand the
dynamics of continuous-time event sequences. We follow a ground-up approach,
i.e., first, we address the problems that may arise due to the poor quality of
CTES data being fed into a recommender system. Later, we handle the task of
designing accurate recommender systems. To improve the quality of the CTES
data, we address a fundamental problem of overcoming missing events in temporal
sequences. Moreover, to provide accurate sequence modeling frameworks, we
design solutions for points-of-interest recommendation, i.e., models that can
handle spatial mobility data of users to various POI check-ins and recommend
candidate locations for the next check-in. Lastly, we highlight that the
capabilities of the proposed models can have applications beyond recommender
systems, and we extend their abilities to design solutions for large-scale CTES
retrieval and human activity prediction. A significant part of this thesis uses
the idea of modeling the underlying distribution of CTES via neural marked
temporal point processes (MTPP). Traditional MTPP models are stochastic
processes that utilize a fixed formulation to capture the generative mechanism
of a sequence of discrete events localized in continuous time. In contrast,
neural MTPP combine the underlying ideas from the point process literature with
modern deep learning architectures. The ability of deep-learning models as
accurate function approximators has led to a significant gain in the predictive
prowess of neural MTPP models. In this thesis, we utilize and present several
neural network-based enhancements for the current MTPP frameworks for the
aforementioned real-world applications.",0.0029655527,-0.13699502,0.24364763,A
