,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract
79,"Hence, while invasive BCIs merit              letting the user select from among different palettes of
further study, most patients and researchers may,              options, sometimes via a menu.","Some
entail expensive surgery, scarring, risk of infection, and     operating protocols allow a much larger vocabulary than
regular medical check-ups, and their long-term stability       most early BCIs, either by presenting many options or by
remains unclear.","understandably,choose noninvasive approaches.",2022-01-04 06:02:33+00:00,A Survey on Brain-Computer Interaction,cs.HC,"['cs.HC', 'cs.NE']","[arxiv.Result.Author('Bosubabu Sambana'), arxiv.Result.Author('Priyanka Mishra')]","Brain-Computer Interface(BCI) systems support communication through direct
measures of neural activity without muscle activity. Brain-Computer Interface
systems need to be validated in long-term studies of real-world use by people
with severe disabilities, and effective and viable models for their widespread
dissemination must be implemented. Finally, the day-to-day and moment-to-moment
reliability of BCI performance must be improved so that approaches the
reliability of natural muscle-based function. This review discusses the
structure and functions of BCI systems, clarifies terminology integration and
progress, and opportunities in the field are also identified and explicated
based on the current availability of invasive recording technologies used for
BCI systems."
80,"Hence, while invasive BCIs merit               BCIs, either by presenting many options or by letting the
further study, most patients and researchers may,               user select from among different palettes of options,
understandably,choose noninvasive approaches.","Some operating
regular medical check-ups, and their long-term stability        protocols allow a much larger vocabulary than most early
remains unclear.",sometimes via a menu.,2022-01-04 06:02:33+00:00,A Survey on Brain-Computer Interaction,cs.HC,"['cs.HC', 'cs.NE']","[arxiv.Result.Author('Bosubabu Sambana'), arxiv.Result.Author('Priyanka Mishra')]","Brain-Computer Interface(BCI) systems support communication through direct
measures of neural activity without muscle activity. Brain-Computer Interface
systems need to be validated in long-term studies of real-world use by people
with severe disabilities, and effective and viable models for their widespread
dissemination must be implemented. Finally, the day-to-day and moment-to-moment
reliability of BCI performance must be improved so that approaches the
reliability of natural muscle-based function. This review discusses the
structure and functions of BCI systems, clarifies terminology integration and
progress, and opportunities in the field are also identified and explicated
based on the current availability of invasive recording technologies used for
BCI systems."
81,"Hence, while invasive BCIs
merit further study, most patients and researchers may,
understandably,choose non-invasive approaches.","Furthermore,
they entail expensive surgery, scarring, risk of infection,
and regular medical check-ups, and their long-term
stability remains unclear.","BCI output devices

After the brain signal features are extracted and
translated, the third component of the BCI, the output
device,implements the messages or commands conveyed
by the translation algorithm.",2022-01-04 06:02:33+00:00,A Survey on Brain-Computer Interaction,cs.HC,"['cs.HC', 'cs.NE']","[arxiv.Result.Author('Bosubabu Sambana'), arxiv.Result.Author('Priyanka Mishra')]","Brain-Computer Interface(BCI) systems support communication through direct
measures of neural activity without muscle activity. Brain-Computer Interface
systems need to be validated in long-term studies of real-world use by people
with severe disabilities, and effective and viable models for their widespread
dissemination must be implemented. Finally, the day-to-day and moment-to-moment
reliability of BCI performance must be improved so that approaches the
reliability of natural muscle-based function. This review discusses the
structure and functions of BCI systems, clarifies terminology integration and
progress, and opportunities in the field are also identified and explicated
based on the current availability of invasive recording technologies used for
BCI systems."
148,"As such, several evaluations on the
Our results also lay groundwork to encourage further study of non-            inﬂuence shadow position and object shape on depth judgements have
photorealistic rendering techniques to improve spatial perception in          been conducted in both mobile AR [6, 59] and in OST AR [14, 22,
XR.",perception in augmented reality.,"25, 48, 54].",2022-01-06 02:00:41+00:00,Stay in Touch! Shape and Shadow Influence Surface Contact in XR Displays,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Haley Adams'), arxiv.Result.Author('Holly Gagnon'), arxiv.Result.Author('Sarah Creem-Regehr'), arxiv.Result.Author('Jeanine Stefanucci'), arxiv.Result.Author('Bobby Bodenheimer')]","The information provided to a person's visual system by extended reality (XR)
displays is not a veridical match to the information provided by the real
world. Due in part to graphical limitations in XR head-mounted displays (HMDs),
which vary by device, our perception of space may be altered. However, we do
not yet know which properties of virtual objects rendered by HMDs --
particularly augmented reality displays -- influence our ability to understand
space. In the current research, we evaluate how immersive graphics affect
spatial perception across three unique XR displays: virtual reality (VR), video
see-through augmented reality (VST AR), and optical see-through augmented
reality (OST AR). We manipulated the geometry of the presented objects as well
as the shading techniques for objects' cast shadows. Shape and shadow were
selected for evaluation as they play an important role in determining where an
object is in space by providing points of contact between an object and its
environment -- be it real or virtual. Our results suggest that a
non-photorealistic (NPR) shading technique, in this case for cast shadows, may
be used to improve depth perception by enhancing perceived surface contact in
XR. Further, the benefit of NPR graphics is more pronounced in AR than in VR
displays. One's perception of ground contact is influenced by an object's
shape, as well. However, the relationship between shape and surface contact
perception is more complicated."
250,"While further research is warranted, especially into these followers, our results suggest that human
behavior differs.","However,
followers did not seem to lose trust in systems’ suggestions when the supply chain was disrupted.",6.1.3 The Impact of the Manipulation.,2022-01-07 22:21:25+00:00,To Trust or to Stockpile: Modeling Human-Simulation Interaction in Supply Chain Shortages,cs.HC,['cs.HC'],"[arxiv.Result.Author('Omid Mohaddesi'), arxiv.Result.Author('Jacqueline Griffin'), arxiv.Result.Author('Ozlem Ergun'), arxiv.Result.Author('David Kaeli'), arxiv.Result.Author('Stacy Marsella'), arxiv.Result.Author('Casper Harteveld')]","Understanding decision-making in dynamic and complex settings is a challenge
yet essential for preventing, mitigating, and responding to adverse events
(e.g., disasters, financial crises). Simulation games have shown promise to
advance our understanding of decision-making in such settings. However, an open
question remains on how we extract useful information from these games. We
contribute an approach to model human-simulation interaction by leveraging
existing methods to characterize: (1) system states of dynamic simulation
environments (with Principal Component Analysis), (2) behavioral responses from
human interaction with simulation (with Hidden Markov Models), and (3)
behavioral responses across system states (with Sequence Analysis). We
demonstrate this approach with our game simulating drug shortages in a supply
chain context. Results from our experimental study with 135 participants show
different player types (hoarders, reactors, followers), how behavior changes in
different system states, and how sharing information impacts behavior. We
discuss how our findings challenge existing literature."
283,"Therefore, it remains a question for
based cartograms intend to perform tasks that are similar        further research whether legends and grid lines are effective
to those in our experiment.","rated the selectable legend with grid lines to be helpful        We acknowledge that our study was limited in scope to
rather than hindering, we believe that not all users of web-     contiguous cartograms.","Moreover, certain users may          for other cartogram types (e.g., rectangular [38] and mosaic
ﬁnd a selectable legend with grid lines obstructive because      cartograms [39]).",2022-01-09 12:39:07+00:00,Effectiveness of Area-to-Value Legends and Grid Lines in Contiguous Area Cartograms,cs.HC,"['cs.HC', 'cs.CG']","[arxiv.Result.Author('Kelvin L. T. Fung'), arxiv.Result.Author('Simon T. Perrault'), arxiv.Result.Author('Michael T. Gastner')]","A contiguous area cartogram is a geographic map in which the area of each
region is rescaled to be proportional to numerical data (e.g., population size)
while keeping neighboring regions connected. Few studies have investigated
whether readers can make accurate quantitative assessments using contiguous
area cartograms. Therefore, we conducted an experiment to determine the
accuracy, speed, and confidence with which readers infer numerical data values
for the mapped regions. We investigated whether including an area-to-value
legend (in the form of a square symbol next to the value represented by the
square's area) makes it easier for map readers to estimate magnitudes. We also
evaluated the effectiveness of two additional features: grid lines and an
interactive area-to-value legend that allows participants to select the value
represented by the square. Without any legends and only informed about the
total numerical value represented by the whole cartogram, the distribution of
estimates for individual regions was centered near the true value with
substantial spread. Selectable legends with grid lines significantly reduced
the spread but led to a tendency to underestimate the values. When comparing
differences between regions or between cartograms, legends and grid lines made
estimation slower but not more accurate. However, legends and grid lines made
it more likely that participants completed the tasks. We recommend considering
the cartogram's use case and purpose before deciding whether to include grid
lines or an interactive legend."
286,"Again, the older generation particularly those over 55 years are likely to
be less comfortable with adopting M-Banking Apps because of the generation gap, hence
further research focusing primarily on those aged 45+ years is necessary to understand attitudes
of this age group towards mobile banking applications.","The study did not get enough respondents aged 45+ which ultimately may affect observations
made, though initial observations indicate that the older generation has less trust in the security
of M-Banking Apps.","Finally, future research could arrive at a better understanding of the user-perceived security of
M-Banking Apps by integrating cultural dimensions.",2022-01-09 16:45:30+00:00,Measuring User Perceived Security of Mobile Banking Applications,cs.HC,"['cs.HC', 'cs.CR', 'cs.CY']","[arxiv.Result.Author('Richard Apaua'), arxiv.Result.Author('Harjinder Singh Lallie')]","Mobile banking applications have gained popularity and have significantly
revolutionised the banking industry. Despite the convenience offered by
M-Banking Apps, users are often distrustful of the security of the applications
due to an increasing trend of cyber security compromises, cyber-attacks, and
data breaches. Considering the upsurge in cyber security vulnerabilities of
M-Banking Apps and the paucity of research in this domain, this study was
conducted to empirically measure user-perceived security of M-Banking Apps. A
total of 315 responses from study participants were analysed using
covariance-based structural equation modelling (CB-SEM). The results indicated
that most constructs of the baseline Extended Unified Theory of Acceptance and
Use of Technology (UTAUT2) structure were validated. Perceived security,
institutional trust and technology trust were confirmed as factors that affect
user's intention to adopt and use M-Banking Apps. However, perceived risk was
not confirmed as a significant predictor. The current study further revealed
that in the context of M-Banking Apps, the effects of security and trust are
complex. The impact of perceived security and institutional trust on
behavioural intention was moderated by age, gender, experience, income, and
education, while perceived security on use behaviour was moderated by age,
gender, and experience. The effect of technology trust on behavioural intention
was moderated by age, education, and experience. Overall, the proposed
conceptual model achieved acceptable fit and explained 79% of the variance in
behavioural intention and 54.7% in use behaviour of M-Banking Apps, higher than
that obtained in the original UTAUT2. The guarantee of enhanced security,
advanced privacy mechanisms and trust should be considered paramount in future
strategies aimed at promoting M-Banking Apps adoption and use."
363,"The components of this mantra
committee of politicians, enabling further study of the user’s potential  (“overview”, “zoom”, “ﬁlter” and “details-on-demand”) can together
biases in decision making.","This dataset captures       demand” [Shn96]) express common sequences of user interactions
user interactions from a visualization system intended to select a        observed during visual exploration.","We represent our approach in Figure 2.         be represented as a set of non-terminal symbols NS (see Figure 2(4)):
                                                                          NS = {overview, zoom, filter, details_on_demand}
   Brehmer and Munzner classify individual interactions into 11           Other high-level taxonomies can also be represented using
categories, which we represent as a set of terminal symbols ΣBM:          non-terminal symbols in a similar fashion.",2022-01-11 01:59:06+00:00,A Programmatic Approach to Applying Visualization Taxonomies to Interaction Logs,cs.HC,['cs.HC'],"[arxiv.Result.Author('Sneha Gathani'), arxiv.Result.Author('Shayan Monadjemi'), arxiv.Result.Author('Alvitta Ottley'), arxiv.Result.Author('Leilani Battle')]","Researchers collect large amounts of user interaction data with the goal of
mapping user's workflows and behaviors to their higher-level motivations,
intuitions, and goals. Although the visual analytics community has proposed
numerous taxonomies to facilitate this mapping process, no formal methods exist
for systematically applying these existing theories to user interaction logs.
This paper seeks to bridge the gap between visualization task taxonomies and
interaction log data by making the taxonomies more actionable for interaction
log analysis. To achieve this, we leverage structural parallels between how
people express themselves through interactions and language by reformulating
existing theories as regular grammars. We represent interactions as terminals
within a regular grammar, similar to the role of individual words in a
language, and patterns of interactions or non-terminals as regular expressions
over these terminals to capture common language patterns. To demonstrate our
approach, we generate regular grammars for seven visualization taxonomies and
develop code to apply them to three interaction log datasets. In analyzing our
results, we find that existing taxonomies at the low-level (i.e., terminals)
show mixed results in expressing multiple interaction log datasets, and
taxonomies at the high-level (i.e., regular expressions) have limited
expressiveness, due to primarily two challenges: inconsistencies in interaction
log dataset granularity and structure, and under-expressiveness of certain
terminals. Based on our findings, we suggest new research directions for the
visualization community for augmenting existing taxonomies, developing new
ones, and building better interaction log recording processes to facilitate the
data-driven development of user behavior taxonomies."
364,"This dataset captures user interactions      High-level taxonomies such as Shneiderman’s information-
from a visualization system intended to select a committee of           seeking mantra (“overview ﬁrst, zoom and ﬁlter, then details-on-
politicians, enabling further study of the user’s potential biases in   demand” [Shn96]) express common sequences of user interactions
decision making.","We also demonstrate its application on an interaction log dataset
collected by Wall [Wal20].",We represent our approach in Figure 2.                 observed during visual exploration.,2022-01-11 01:59:06+00:00,A Grammar-Based Approach for Applying Visualization Taxonomies to Interaction Logs,cs.HC,['cs.HC'],"[arxiv.Result.Author('Sneha Gathani'), arxiv.Result.Author('Shayan Monadjemi'), arxiv.Result.Author('Alvitta Ottley'), arxiv.Result.Author('Leilani Battle')]","Researchers collect large amounts of user interaction data with the goal of
mapping user's workflows and behaviors to their higher-level motivations,
intuitions, and goals. Although the visual analytics community has proposed
numerous taxonomies to facilitate this mapping process, no formal methods exist
for systematically applying these existing theories to user interaction logs.
This paper seeks to bridge the gap between visualization task taxonomies and
interaction log data by making the taxonomies more actionable for interaction
log analysis. To achieve this, we leverage structural parallels between how
people express themselves through interactions and language by reformulating
existing theories as regular grammars. We represent interactions as terminals
within a regular grammar, similar to the role of individual words in a
language, and patterns of interactions or non-terminals as regular expressions
over these terminals to capture common language patterns. To demonstrate our
approach, we generate regular grammars for seven visualization taxonomies and
develop code to apply them to three interaction log datasets. In analyzing our
results, we find that existing taxonomies at the low-level (i.e., terminals)
show mixed results in expressing multiple interaction log datasets, and
taxonomies at the high-level (i.e., regular expressions) have limited
expressiveness, due to primarily two challenges: inconsistencies in interaction
log dataset granularity and structure, and under-expressiveness of certain
terminals. Based on our findings, we suggest new research directions for the
visualization community for augmenting existing taxonomies, developing new
ones, and building better interaction log recording processes to facilitate the
data-driven development of user behavior taxonomies."
419,"However, users may       imize the impact of these individual differences on the threshold
collide with the physical boundaries of the real space they are in       range, further research considering these differences is needed to
when they attempt to walk towards the perceived movable space            estimate personalized threshold ranges.","First, the perceived movable space should be made larger than the     Although we set the gender ratio between the two groups to be the
adjusted movable space to obtain a wider range of relative translation   same and adjusted the average height between conditions to min-
gain thresholds in constructing virtual scenes.","By considering the effects
with this approach.",2022-01-12 02:17:43+00:00,Effects of Virtual Room Size and Objects on Relative Translation Gain Thresholds in Redirected Walking,cs.HC,['cs.HC'],"[arxiv.Result.Author('Dooyoung Kim'), arxiv.Result.Author('Jinwook Kim'), arxiv.Result.Author('Jae-eun Shin'), arxiv.Result.Author('Boram Yoon'), arxiv.Result.Author('Jeongmi Lee'), arxiv.Result.Author('Woontack Woo')]","This paper investigates how the size of virtual space and objects within it
affect the threshold range of relative translation gains, a Redirected Walking
(RDW) technique that scales the user's movement in virtual space in different
ratios for the width and depth. While previous studies assert that a virtual
room's size affects relative translation gain thresholds on account of the
virtual horizon's location, additional research is needed to explore this
assumption through a structured approach to visual perception in Virtual
Reality (VR). We estimate the relative translation gain thresholds in six
spatial conditions configured by three room sizes and the presence of virtual
objects (3 X 2), which were set according to differing Angles of Declination
(AoDs) between eye-gaze and the forward-gaze. Results show that both size and
virtual objects significantly affect the threshold range, it being greater in
the large-sized condition and furnished condition. This indicates that the
effect of relative translation gains can be further increased by constructing a
perceived virtual movable space that is even larger than the adjusted virtual
movable space and placing objects in it. Our study can be applied to adjust
virtual spaces in synchronizing heterogeneous spaces without coordinate
distortion where real and virtual objects can be leveraged to create realistic
mutual spaces."
480,"For example, further research
is necessary to evaluate to what extent participants rely on machine-generated suggestions.",More research is still highly needed.,"It is
also interesting to check how these suggestions influence participants’ thinking process during
data analysis.",2022-01-13 10:20:06+00:00,Interactive Data Analysis with Next-step Natural Language Query Recommendation,cs.HC,"['cs.HC', 'cs.CL', 'cs.DB']","[arxiv.Result.Author('Xingbo Wang'), arxiv.Result.Author('Furui Cheng'), arxiv.Result.Author('Yong Wang'), arxiv.Result.Author('Ke Xu'), arxiv.Result.Author('Jiang Long'), arxiv.Result.Author('Hong Lu'), arxiv.Result.Author('Huamin Qu')]","Natural language interfaces (NLIs) provide users with a convenient way to
interactively analyze data through natural language queries. Nevertheless,
interactive data analysis is a demanding process, especially for novice data
analysts. When exploring large and complex datasets from different domains,
data analysts do not necessarily have sufficient knowledge about data and
application domains. It makes them unable to efficiently elicit a series of
queries and extensively derive desirable data insights. In this paper, we
develop an NLI with a step-wise query recommendation module to assist users in
choosing appropriate next-step exploration actions. The system adopts a
data-driven approach to generate step-wise semantically relevant and
context-aware query suggestions for application domains of users' interest
based on their query logs. Also, the system helps users organize query
histories and results into a dashboard to communicate the discovered data
insights. With a comparative user study, we show that our system can facilitate
a more effective and systematic data analysis process than a baseline without
the recommendation module."
481,"For example,
desired a function to adjust the resulting visualization (e.g.,   further research is necessary to evaluate to what extent
chart types, legends).",More research is still highly needed.,One participant suggested the au-          participants rely on machine-generated suggestions.,2022-01-13 10:20:06+00:00,Interactive Data Analysis with Next-step Natural Language Query Recommendation,cs.HC,"['cs.HC', 'cs.CL', 'cs.DB']","[arxiv.Result.Author('Xingbo Wang'), arxiv.Result.Author('Furui Cheng'), arxiv.Result.Author('Yong Wang'), arxiv.Result.Author('Ke Xu'), arxiv.Result.Author('Jiang Long'), arxiv.Result.Author('Hong Lu'), arxiv.Result.Author('Huamin Qu')]","Natural language interfaces (NLIs) provide users with a convenient way to
interactively analyze data through natural language queries. Nevertheless,
interactive data analysis is a demanding process, especially for novice data
analysts. When exploring large and complex SQL databases from different
domains, data analysts do not necessarily have sufficient knowledge about
different data tables and application domains. It makes them unable to
systematically elicit a series of topically-related and meaningful queries for
insight discovery in target domains. We develop a NLI with a step-wise query
recommendation module to assist users in choosing appropriate next-step
exploration actions. The system adopts a data-driven approach to suggest
semantically relevant and context-aware queries for application domains of
users' interest based on their query logs. Also, the system helps users
organize query histories and results into a dashboard to communicate the
discovered data insights. With a comparative user study, we show that our
system can facilitate a more effective and systematic data analysis process
than a baseline without the recommendation module."
499,"development potential, but there are also some shortcomings
worthy of further research.",SGMO have great                 instead of pursuing the latest games.,"In the following, we suggest                     Because of the different functional requirements of players
directions for research.",2022-01-12 16:13:26+00:00,Review of Serious Games for Medical Operation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhijie Guo'), arxiv.Result.Author('Raouf Hamzaoui'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Fadi Farha'), arxiv.Result.Author('Lingfeng Mao')]","Medical operations (MOs) are essential in healthcare,and they are also a big
concept that includes various operations during the perioperative
period.Traditional operation exposes its limitations during the perioperative
period,reflected in medical training,surgical preparation,and postoperative
rehabilitation.Serious Games for Medical Operation (SGMO) offer new ways and
complementary solutions to support MOs.As a review,this paper analyzes the
development of SGMO and considers various aspects of the SGMO,such as
interface,functions,and technologies.By combining MO and serious games
characteristics,the paper classifies SGMO and analyzes their features and
functions for different groups of users and at various stages of the
perioperative period (before,during,and after an MO).Interactive technologies
used in SGMO are presented from a visual,haptic,and auditory perspective.This
paper reviews the development of SGMO,summarizes its functions and
technologies.Besides,it presents representative products and suggests future
research directions."
500,"teamwork, game design, and remote MOs are important and
                                                                                  [19] E. M. Overtoom, T. Horeman, F.-W. Jansen, J. Dankelman, and H. W.
deserve further study.",468–471.,"Schreuder, “Haptic feedback, force feedback, and force-sensing in
                                                                                        simulation training for laparoscopy: A systematic overview,” Journal
                             REFERENCES                                                 of surgical education, vol.",2022-01-12 16:13:26+00:00,Review of Serious Games for Medical Operation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhijie Guo'), arxiv.Result.Author('Raouf Hamzaoui'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Fadi Farha'), arxiv.Result.Author('Lingfeng Mao')]","Medical operations (MOs) are essential in healthcare,and they are also a big
concept that includes various operations during the perioperative
period.Traditional operation exposes its limitations during the perioperative
period,reflected in medical training,surgical preparation,and postoperative
rehabilitation.Serious Games for Medical Operation (SGMO) offer new ways and
complementary solutions to support MOs.As a review,this paper analyzes the
development of SGMO and considers various aspects of the SGMO,such as
interface,functions,and technologies.By combining MO and serious games
characteristics,the paper classifies SGMO and analyzes their features and
functions for different groups of users and at various stages of the
perioperative period (before,during,and after an MO).Interactive technologies
used in SGMO are presented from a visual,haptic,and auditory perspective.This
paper reviews the development of SGMO,summarizes its functions and
technologies.Besides,it presents representative products and suggests future
research directions."
501,"Therefore, AI   worthy of further research and use.","player’s rehabilitation experience reasonably and efﬁciently to   Therefore, we believed that the multiplayer game mode is
help later players perform better rehabilitation.",and CI are directions worthy of further research by researchers.,2022-01-13 13:44:42+00:00,A Review on Serious Games for Exercise Rehabilitation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhenyu Wang'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Yudong Zhang'), arxiv.Result.Author('Lingfeng Mao')]","Disability is an important factor affecting todays society. At the same time,
more and more sub-healthy people are sick due to reduced body functions and
cognitive functions. Exercise rehabilitation is a kind of physical therapy,
which can recover the motor ability, cognitive ability, and mental state of
them through exercise. But the traditional exercise rehabilitation has some
drawbacks so that people who need exercise rehabilitation cannot stick to it.
Therefore, many researchers improved the drawbacks of traditional exercise
rehabilitation by serious games for exercise rehabilitation. Although there
were abundant achievements in the games, its relevant technologies and
representative games are not be summarized systematically. To fill this gap, we
introduced the significance of the convergence of exercise rehabilitation and
serious games. Then, our paper sorted out the development of the games based on
interaction mode between games and players. Besides, we analyzed the
characteristics of different user groups and the specific functions of the
games corresponding to them, and gave our classification based on this. Based
on the classification, we reviewed related studies of the games in the past
decade years and gave some suggestions on game design and development. Finally,
we proposed serval research directions worth studying about the games
technology development, functional design and social popularization."
502,and CI are directions worthy of further research by researchers.,"Therefore, AI   worthy of further research and use.","•To provide researchers with a deeper understanding and
   •To reduce the inconvenience of patients going to              help researchers develop better SGERs, further study serious
the treatment site and promote the sharing of exercise            games and exercise rehabilitation at the information and
rehabilitation experience, attention should be paid to the        physical levels.",2022-01-13 13:44:42+00:00,A Review on Serious Games for Exercise Rehabilitation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhenyu Wang'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Yudong Zhang'), arxiv.Result.Author('Lingfeng Mao')]","Disability is an important factor affecting todays society. At the same time,
more and more sub-healthy people are sick due to reduced body functions and
cognitive functions. Exercise rehabilitation is a kind of physical therapy,
which can recover the motor ability, cognitive ability, and mental state of
them through exercise. But the traditional exercise rehabilitation has some
drawbacks so that people who need exercise rehabilitation cannot stick to it.
Therefore, many researchers improved the drawbacks of traditional exercise
rehabilitation by serious games for exercise rehabilitation. Although there
were abundant achievements in the games, its relevant technologies and
representative games are not be summarized systematically. To fill this gap, we
introduced the significance of the convergence of exercise rehabilitation and
serious games. Then, our paper sorted out the development of the games based on
interaction mode between games and players. Besides, we analyzed the
characteristics of different user groups and the specific functions of the
games corresponding to them, and gave our classification based on this. Based
on the classification, we reviewed related studies of the games in the past
decade years and gave some suggestions on game design and development. Finally,
we proposed serval research directions worth studying about the games
technology development, functional design and social popularization."
503,"•To provide researchers with a deeper understanding and
   •To reduce the inconvenience of patients going to              help researchers develop better SGERs, further study serious
the treatment site and promote the sharing of exercise            games and exercise rehabilitation at the information and
rehabilitation experience, attention should be paid to the        physical levels.",and CI are directions worthy of further research by researchers.,development of telerehabilitation.,2022-01-13 13:44:42+00:00,A Review on Serious Games for Exercise Rehabilitation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhenyu Wang'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Yudong Zhang'), arxiv.Result.Author('Lingfeng Mao')]","Disability is an important factor affecting todays society. At the same time,
more and more sub-healthy people are sick due to reduced body functions and
cognitive functions. Exercise rehabilitation is a kind of physical therapy,
which can recover the motor ability, cognitive ability, and mental state of
them through exercise. But the traditional exercise rehabilitation has some
drawbacks so that people who need exercise rehabilitation cannot stick to it.
Therefore, many researchers improved the drawbacks of traditional exercise
rehabilitation by serious games for exercise rehabilitation. Although there
were abundant achievements in the games, its relevant technologies and
representative games are not be summarized systematically. To fill this gap, we
introduced the significance of the convergence of exercise rehabilitation and
serious games. Then, our paper sorted out the development of the games based on
interaction mode between games and players. Besides, we analyzed the
characteristics of different user groups and the specific functions of the
games corresponding to them, and gave our classification based on this. Based
on the classification, we reviewed related studies of the games in the past
decade years and gave some suggestions on game design and development. Finally,
we proposed serval research directions worth studying about the games
technology development, functional design and social popularization."
504,"Finally, we discussed current SGERs from technology                       [13] A. Kalron, M. Levy, L. Frid, and A. Ahiron, “Virtual reality training to
development, functional design and social popularization per-                          improve upper limb motor function in multiple sclerosis: A feasibility
spectives and proposed some further research directions.","3, 2017.
in the past decade years to help researchers better develop
SGERs.","To be                         study,” in 2019 International Conference on Virtual Rehabilitation
brief, our work aimed to help researchers better understand the                        (ICVR).",2022-01-13 13:44:42+00:00,A Review on Serious Games for Exercise Rehabilitation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhenyu Wang'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Yudong Zhang'), arxiv.Result.Author('Lingfeng Mao')]","Disability is an important factor affecting todays society. At the same time,
more and more sub-healthy people are sick due to reduced body functions and
cognitive functions. Exercise rehabilitation is a kind of physical therapy,
which can recover the motor ability, cognitive ability, and mental state of
them through exercise. But the traditional exercise rehabilitation has some
drawbacks so that people who need exercise rehabilitation cannot stick to it.
Therefore, many researchers improved the drawbacks of traditional exercise
rehabilitation by serious games for exercise rehabilitation. Although there
were abundant achievements in the games, its relevant technologies and
representative games are not be summarized systematically. To fill this gap, we
introduced the significance of the convergence of exercise rehabilitation and
serious games. Then, our paper sorted out the development of the games based on
interaction mode between games and players. Besides, we analyzed the
characteristics of different user groups and the specific functions of the
games corresponding to them, and gave our classification based on this. Based
on the classification, we reviewed related studies of the games in the past
decade years and gave some suggestions on game design and development. Finally,
we proposed serval research directions worth studying about the games
technology development, functional design and social popularization."
593,The results of the evaluation showed     further research and exploration.,"[39]
                                                                   6

every corner of the room.","For clarity, Fig.",2022-01-15 02:26:18+00:00,A Review on Serious Games for Phobia,cs.HC,['cs.HC'],"[arxiv.Result.Author('Sha Li'), arxiv.Result.Author('Peichen Yang'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Fadi Farha'), arxiv.Result.Author('Jianguo Ding'), arxiv.Result.Author('Per Backlund'), arxiv.Result.Author('Huansheng Ning')]","Phobia is a widespread mental illness, and severe phobias can seriously
impact patients daily lives. One-session Exposure Treatment (OST) has been used
to treat phobias in the early days,but it has many disadvantages. As a new way
to treat a phobia, virtual reality exposure therapy(VRET) based on serious
games is introduced. There have been much researches in the field of serious
games for phobia therapy (SGPT), so this paper presents a detailed review of
SGPT from three perspectives. First, SGPT in different stages has different
forms with the update and iteration of technology. Therefore, we reviewed the
development history of SGPT from the perspective of equipment. Secondly, there
is no unified classification framework for a large number of SGPT. So we
classified and combed SGPT according to different types of phobias. Finally,
most articles on SGPT have studied the therapeutic effects of serious games
from a medical perspective, and few have studied serious games from a technical
perspective. Therefore, we conducted in-depth research on SGPT from a technical
perspective in order to provide technical guidance for the development of SGPT.
Accordingly, the challenges facing the existing technology has been explored
and listed."
594,"Given these challenges, the          perspective of VR display devices and divided it into three
following directions deserve further research and development:      aspects: VR-Box, HMD, and CAVE.","In order to ﬁll this gap, this paper described
it is a single category that does not cover a large number          and summarized the development history of SGPT from the
of different types of phobias.","These studies can help
                                                                    relevant researchers to some extent.",2022-01-15 02:26:18+00:00,A Review on Serious Games for Phobia,cs.HC,['cs.HC'],"[arxiv.Result.Author('Sha Li'), arxiv.Result.Author('Peichen Yang'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Fadi Farha'), arxiv.Result.Author('Jianguo Ding'), arxiv.Result.Author('Per Backlund'), arxiv.Result.Author('Huansheng Ning')]","Phobia is a widespread mental illness, and severe phobias can seriously
impact patients daily lives. One-session Exposure Treatment (OST) has been used
to treat phobias in the early days,but it has many disadvantages. As a new way
to treat a phobia, virtual reality exposure therapy(VRET) based on serious
games is introduced. There have been much researches in the field of serious
games for phobia therapy (SGPT), so this paper presents a detailed review of
SGPT from three perspectives. First, SGPT in different stages has different
forms with the update and iteration of technology. Therefore, we reviewed the
development history of SGPT from the perspective of equipment. Secondly, there
is no unified classification framework for a large number of SGPT. So we
classified and combed SGPT according to different types of phobias. Finally,
most articles on SGPT have studied the therapeutic effects of serious games
from a medical perspective, and few have studied serious games from a technical
perspective. Therefore, we conducted in-depth research on SGPT from a technical
perspective in order to provide technical guidance for the development of SGPT.
Accordingly, the challenges facing the existing technology has been explored
and listed."
708,"This game allows players to play the
further research and exploration.","Thus, the speciﬁc        an emotional model into virtual teammates for a training game
implementation of the game ﬁdelity adaptive method requires      Ground Truth: Toxic City.","role of the incident commander, command virtual teammates
                                                                 to deal with the leakage of toxic chemicals,aim to training the
   2) SGDRs for Commanders: once an emergency occurs,            commander’s strategy.",2022-01-10 06:50:53+00:00,A Review on Serious Games for Disaster Relief,cs.HC,['cs.HC'],"[arxiv.Result.Author('Huansheng Ning'), arxiv.Result.Author('Zhangfeng Pi'), arxiv.Result.Author('Wenxi Wang'), arxiv.Result.Author('Fadi Farha'), arxiv.Result.Author('Shunkun Yang')]","Human beings have been affected by disasters from the beginning of life,
bringing them many sad memories. In the long struggle against disaster, people
have devised a variety of methods to train relevant participants in disaster
relief capabilities. However, many traditional training methods, such as
disaster exercises may not provide effective training to meet the need of
today. Serious games provide an innovative approach to train participants in
disaster relief, and a large number of Serious Games for Disaster Relief
(SGDRs) have been developed to train disaster planning and rescue capabilities.
At the same time, there is no systematics phase description for disaster
relief, which cannot effectively guide participants' work and training in
disaster relief. Therefore, this paper proposes a comprehensive and
professional disaster relief classification framework according to different
relief work in each stage of the disaster. Based on this framework, we review
the functions and technologies of serious games in each classification, which
can offer reliable guidance for researchers to better understand and use SGDRs.
In addition, we analyze the serious games in each category, point out the
limitations, and provide some valuable advice for developers on game design."
727,"While it is possible to simulate the weight and center of
gravity changes of such virtual objects, further research is                  [9] M. Kim et al., “A study on immersion and presence of a portable hand
needed to assess the performance, stability, and suitability                       haptic system for immersive virtual reality,” Sensors, vol.","1285–1294, 2017.","17, no.",2022-01-18 16:01:38+00:00,VibroWeight: Simulating Weight and Center of Gravity Changes of Objects in Virtual Reality for Enhanced Realism,cs.HC,['cs.HC'],"[arxiv.Result.Author('Xian Wang'), arxiv.Result.Author('Diego Monteiro'), arxiv.Result.Author('Lik-Hang Lee'), arxiv.Result.Author('Pan Hui'), arxiv.Result.Author('Hai-Ning Liang')]","Haptic feedback in virtual reality (VR) allows users to perceive the physical
properties of virtual objects (e.g., their weight and motion patterns).
However, the lack of haptic sensations deteriorates users' immersion and
overall experience. In this work, we designed and implemented a low-cost
hardware prototype with liquid metal, VibroWeight, which can work in
complementarity with commercial VR handheld controllers. VibroWeight is
characterized by bimodal feedback cues in VR, driven by adaptive absolute mass
(weights) and gravity shift. To our knowledge, liquid metal is used in a VR
haptic device for the first time. Our 29 participants show that VibroWeight
delivers significantly better VR experiences in realism and comfort."
1075,"Nonetheless, more experiments are needed to further study         [4] M. Ghafurian, C. Ellard, and K. Dautenhahn, “Social companion
interactions using a more natural dialogue manager (chat-               robots to reduce isolation: a perception change due to covid-19,”
bot).","72–8, 2017.
empathy can encourage users to have longer conversations.",The changes in users’ depression measurement scores               in IFIP Conference on Human-Computer Interaction.,2022-01-26 20:11:48+00:00,Artificial Emotional Intelligence in Socially Assistive Robots for Older Adults: A Pilot Study,cs.HC,"['cs.HC', 'cs.RO']","[arxiv.Result.Author('Hojjat Abdollahi'), arxiv.Result.Author('Mohammad H. Mahoor'), arxiv.Result.Author('Rohola Zandie'), arxiv.Result.Author('Jarid Siewierski'), arxiv.Result.Author('Sara H. Qualls')]","This paper presents our recent research on integrating artificial emotional
intelligence in a social robot (Ryan) and studies the robot's effectiveness in
engaging older adults. Ryan is a socially assistive robot designed to provide
companionship for older adults with depression and dementia through
conversation. We used two versions of Ryan for our study, empathic and
non-empathic. The empathic Ryan utilizes a multimodal emotion recognition
algorithm and a multimodal emotion expression system. Using different input
modalities for emotion, i.e. facial expression and speech sentiment, the
empathic Ryan detects users' emotional state and utilizes an affective dialogue
manager to generate a response. On the other hand, the non-empathic Ryan lacks
facial expression and uses scripted dialogues that do not factor in the users'
emotional state. We studied these two versions of Ryan with 10 older adults
living in a senior care facility. The statistically significant improvement in
the users' reported face-scale mood measurement indicates an overall positive
effect from the interaction with both the empathic and non-empathic versions of
Ryan. However, the number of spoken words measurement and the exit survey
analysis suggest that the users perceive the empathic Ryan as more engaging and
likable."
1155,"[24, 26, 27] and did serve as a foundation for further research in the area.","Some of the most signiﬁcant studies in the area came from 80’s
(e.g.",6  M. Lewicki et al.,2022-01-28 10:24:47+00:00,Dynamic pricing and discounts by means of interactive presentation systems in stationary point of sales,cs.HC,['cs.HC'],"[arxiv.Result.Author('Marcin Lewicki'), arxiv.Result.Author('Tomasz Kajdanowicz'), arxiv.Result.Author('Piotr Bródka'), arxiv.Result.Author('Janusz Sobecki')]","The main purpose of this article was to create a model and simulate the
profitability conditions of an interactive presentation system (IPS) with the
recommender system (RS) used in the kiosk. 90 million simulations have been run
in Python with SymPy to address the problem of discount recommendation offered
to the clients according to their usage of the IPS."
1301,"Some research has shown that viewers are sensitive to the social dynamics portrayed
by interacting musicians (e.g., dominance or insolence); however, further study is needed to
determine which types of (audio and visual) cues are meaningful to audiences.","We also propose that visual interaction may beneﬁt performance quality from the audience’s
perspective.","During public performance, the audience’s overt response can feed back to the performer, shap-
ing their performance as it unfolds.",2022-01-31 15:10:23+00:00,Beyond synchronization: Body gestures and gaze direction in duo performance,cs.HC,"['cs.HC', 'cs.SD', 'eess.AS']","[arxiv.Result.Author('Laura Bishop'), arxiv.Result.Author('Carlos Cancino-Chacón'), arxiv.Result.Author('Werner Goebl')]","In this chapter, we focus on two main categories of visual interaction: body
gestures and gaze direction. Our focus on body gestures is motivated by
research showing that gesture patterns often change during joint action tasks
to become more predictable (van der Wel et al., 2016). Moreover, coordination
sometimes emerges between musicians at the level of body sway (Chang et al.,
2017). Our focus on gaze direction was motivated by the fact that gaze can
serve simultaneously as a means of obtaining information about the world and as
a means of communicating one's own attention and intent."
1342,"While further research and additional clinical validation data are necessary, we feel that there are
numerous neuromuscular and/or neurodegenerative conditions that may benefit from improved
use of wearable sensor technology like Earable.","For
instance, this was notable in the Chewing activity, where residual EMG activity that overlapped
with typical EEG frequencies persisted in the EEG signal after signal separation, resulting in an
overestimate of EEG waveform contribution.","The main goal of a feature extraction pipeline
from specific waveforms as described in this work is to support the development of novel digital
endpoints for use in clinical trial settings.",2022-02-01 03:55:23+00:00,A pilot study of the Earable device to measure facial muscle and eye movement tasks among healthy volunteers,cs.HC,"['cs.HC', 'eess.SP', 'q-bio.QM', 'stat.AP']","[arxiv.Result.Author('Matthew F. Wipperman'), arxiv.Result.Author('Galen Pogoncheff'), arxiv.Result.Author('Katrina F. Mateo'), arxiv.Result.Author('Xuefang Wu'), arxiv.Result.Author('Yiziying Chen'), arxiv.Result.Author('Oren Levy'), arxiv.Result.Author('Andreja Avbersek'), arxiv.Result.Author('Robin R. Deterding'), arxiv.Result.Author('Sara C. Hamon'), arxiv.Result.Author('Tam Vu'), arxiv.Result.Author('Rinol Alaj'), arxiv.Result.Author('Olivier Harari')]","Many neuromuscular disorders impair function of cranial nerve enervated
muscles. Clinical assessment of cranial muscle function has several
limitations. Clinician rating of symptoms suffers from inter-rater variation,
qualitative or semi-quantitative scoring, and limited ability to capture
infrequent or fluctuating symptoms. Patient-reported outcomes are limited by
recall bias and poor precision. Current tools to measure orofacial and
oculomotor function are cumbersome, difficult to implement, and non-portable.
Here, we show how Earable, a wearable device, can discriminate certain cranial
muscle activities such as chewing, talking, and swallowing. We demonstrate
using data from a pilot study of 10 healthy participants how Earable can be
used to measure features from EMG, EEG, and EOG waveforms from subjects
performing mock Performance Outcome Assessments (mock-PerfOs), utilized widely
in clinical research. Our analysis pipeline provides a framework for how to
computationally process and statistically rank features from the Earable
device. Finally, we demonstrate that Earable data may be used to classify these
activities. Our results, conducted in a pilot study of healthy participants,
enable a more comprehensive strategy for the design, development, and analysis
of wearable sensor data for investigating clinical populations. Additionally,
the results from this study support further evaluation of Earable or similar
devices as tools to objectively measure cranial muscle activity in the context
of a clinical research setting. Future work will be conducted in clinical
disease populations, with a focus on detecting disease signatures, as well as
monitoring intra-subject treatment responses. Readily available quantitative
metrics from wearable sensor devices like Earable support strategies for the
development of novel digital endpoints, a hallmark goal of clinical research."
1410,"Though the use case here is different, with a truly interactive
ence sentiment, there remained contributions of variance from sources                            scenario, further research is merited.","Despite                              while watching 360 videos increases presence provided conﬂicting re-
this relationship, sentiment outperformed the embodiment predictor                               sults, with one paper ﬁnding supporting evidence [9] while the other did
in interaction models, suggesting that while embodiment could inﬂu-                              not [10].",other than embodiment.,2022-02-02 07:57:00+00:00,Augmenting Immersive Telepresence Experience with a Virtual Body,cs.HC,"['cs.HC', 'cs.MM', 'cs.RO']","[arxiv.Result.Author('Nikunj Arora'), arxiv.Result.Author('Markku Suomalainen'), arxiv.Result.Author('Matti Pouke'), arxiv.Result.Author('Evan G. Center'), arxiv.Result.Author('Katherine J. Mimnaugh'), arxiv.Result.Author('Alexis P. Chambers'), arxiv.Result.Author('Sakaria Pouke'), arxiv.Result.Author('Steven M. LaValle')]","We propose augmenting immersive telepresence by adding a virtual body,
representing the user's own arm motions, as realized through a head-mounted
display and a 360-degree camera. Previous research has shown the effectiveness
of having a virtual body in simulated environments; however, research on
whether seeing one's own virtual arms increases presence or preference for the
user in an immersive telepresence setup is limited. We conducted a study where
a host introduced a research lab while participants wore a head-mounted display
which allowed them to be telepresent at the host's physical location via a
360-degree camera, either with or without a virtual body. We first conducted a
pilot study of 20 participants, followed by a pre-registered 62 participant
confirmatory study. Whereas the pilot study showed greater presence and
preference when the virtual body was present, the confirmatory study failed to
replicate these results, with only behavioral measures suggesting an increase
in presence. After analyzing the qualitative data and modeling interactions, we
suspect that the quality and style of the virtual arms, and the contrast
between animation and video, led to individual differences in reactions to the
virtual body which subsequently moderated feelings of presence."
1500,"It is noted, that especially regarding the evidence-related assessment, the present paper is a living work

    2Four levels: (1) factors with proven impact on fatigue; (2) factors with link to effort or load that require further study (e.g., as
there is no empirical evidence for the speciﬁc link between effort/load and fatigue); (3) factors that are likely linked to at least effort
or load but without clear evidence and hence generally are for further study; (4) factors identiﬁed as irrelevant.","Here, a 4 × 3 categorization is employed
in [26] and the present paper, considering the level of evidence available for a given factor2 and the type of evidence
data provided3.","3Three levels: (1) Subjective, using scales and surveys as in, e.g., [31]; (2) objective, using metrics such as response times,
success rates, or regarding load as in, e.g., [87] for vocal load; (3) physiological, using indicators for effort, stress or fatigue, as e.g.,
in [2, 3, 4]

                                                                      3
Technological Factors Inﬂuencing Videoconferencing and Zoom Fatigue  A PREPRINT

that will be updated up to a certain point, shall evidence data become available.",2022-02-03 18:02:59+00:00,Technological Factors Influencing Videoconferencing and Zoom Fatigue,cs.HC,"['cs.HC', 'cs.CY', 'cs.MM', 'H.5.1; H.5.2']","[arxiv.Result.Author('Alexander Raake'), arxiv.Result.Author('Markus Fiedler'), arxiv.Result.Author('Katrin Schoenenberg'), arxiv.Result.Author('Katrien De Moor'), arxiv.Result.Author('Nicola Döring')]","The paper presents a conceptual, multidimensional approach to understand the
technological factors that are assumed to or even have been proven to
contribute to what has been coined as Zoom Fatigue (ZF) or more generally
Videoconferencing Fatigue (VCF). With the advent of the Covid-19 pandemic, the
usage of VC services has drastically increased, leading to more and more
reports about the ZF or VCF phenomenon. The paper is motivated by the fact that
some of the media outlets initially starting the debate on what Zoom fatigue is
and how it can be avoided, as well as some of the scientific papers addressing
the topic, contain assumptions that are rather hypothetical and insufficiently
underpinned by scientific evidence. Most of these works are acknowledge the
lacking evidence and partly suggest directions for future research. This paper
intends to deepen the survey of VC-technology-related literature and to provide
more existing evidence, where possible, while reviewing some of the already
provided support or evidence for certain causal hypotheses. The technological
factors dimension and its identified sub-dimensions presented in this paper are
embedded within a more holistic four-dimensional conceptual factors model
describing the causes for ZF or VCF. The paper describing this overall
conceptual model is written by the same group of authors and currently under
revision for an Open Access Journal publication. The present paper expands on
the technological factors dimension descriptions provided in the overall model
paper and provides more detailed analyzes and concepts associated with how VC
technology may affect users' perception, cognitive load, interaction and
communication, possibly leading to stress, exhaustion and fatigue. The paper
currently is a living document which will be expanded further with regard to
the evidence for or against the impact of certain technological factors."
1533,"available as an open-source project to facilitate further research on
                                       For all other uses, contact the owner/author(s).",Copyrights for third-party components of this work must be honored.,such tools.,2022-02-04 09:52:48+00:00,SummaryLens -- A Smartphone App for Exploring Interactive Use of Automated Text Summarization in Everyday Life,cs.HC,"['cs.HC', 'H.5.2']","[arxiv.Result.Author('Karim Benharrak'), arxiv.Result.Author('Florian Lehmann'), arxiv.Result.Author('Hai Dang'), arxiv.Result.Author('Daniel Buschek')]","We present SummaryLens, a concept and prototype for a mobile tool that
leverages automated text summarization to enable users to quickly scan and
summarize physical text documents. We further combine this with a
text-to-speech system to read out the summary on demand. With this concept, we
propose and explore a concrete application case of bringing ongoing progress in
AI and Natural Language Processing to a broad audience with interactive use
cases in everyday life. Based on our implemented features, we describe a set of
potential usage scenarios and benefits, including support for low-vision,
low-literate and dyslexic users. A first usability study shows that the
interactive use of automated text summarization in everyday life has noteworthy
potential. We make the prototype available as an open-source project to
facilitate further research on such tools."
1548,"Although studies
                                                                    of this nature exist in the literature, we suggest further study
                                                                    for the effects of our specific VCA approach on patients with
                                                                    fluid requirements or sleep disorders.","Finally, we recommend the implementation of a full-
                                                                    scale randomized study to discover and measure our
                                                                    system’s true effect on behavioral change.","6 Limitations

                                                                    Some limitations we found included the scaleability of the

                                                                    current system to accommodate a bigger trial, and the au-

                                                                    tomation of the data analysis and processing.",2022-02-04 15:24:23+00:00,Voice-Based Conversational Agents for self-reporting fluid consumption and sleep quality,cs.HC,['cs.HC'],"[arxiv.Result.Author('Abdalsalam Almzayyen'), arxiv.Result.Author('Angel Vela de la Garza Evia'), arxiv.Result.Author('Nick Coronato'), arxiv.Result.Author('Mehdi Boukhechba')]","Intelligent conversational agents and virtual assistants, such as chatbots
and voice assistants, have the potential of augmenting health service capacity
to screen symptoms and deliver healthcare interventions. In this paper, we
developed voice-based conversational agents (VCAs) in the Google Actions
Console to deliver periodic self-assessment health surveys. The focus of this
paper is to accommodate self-monitoring for patients with specific fluid
consumption requirements or sleep disorders. Our VCAs, named FluidMonitor and
Sleepy, have been tested to integrate naturally into a patient's daily
lifestyle for the purpose of providing useful interventions. We show the
functionality of our Google Actions and discuss the considerations for using
VCAs as an at-home self-reporting survey technique. User testing showed
satisfaction with the ease of use, likeability, and burden level of the VCAs."
1560,"Algorithmic methods that enable safe and automated tracking of PT exercises is an
unsolved issue that requires further research.","To alleviate this time-burden, wearable sensors
or camera-based technologies can be used to automatically track the type and number of exercises
completed.","During algorithm development, it is important to
consider our participants’ concerns about purchasing additional hardware.",2022-02-04 18:11:58+00:00,"""I'm Just Overwhelmed"": Investigating Physical Therapy Accessibility and Technology Interventions for People with Disabilities and/or Chronic Conditions",cs.HC,['cs.HC'],"[arxiv.Result.Author('Momona Yamagami'), arxiv.Result.Author('Kelly Mack'), arxiv.Result.Author('Jennifer Mankoff'), arxiv.Result.Author('Katherine M. Steele')]","Many individuals with disabilities and/or chronic conditions (da/cc)
experience symptoms that may require intermittent or ongoing medical care.
However, healthcare is an often-overlooked domain for accessibility work, where
access needs associated with temporary and long-term disability must be
addressed to increase the utility of physical and digital interactions with
healthcare workers and spaces. Our work focuses on a specific domain of
healthcare often used by individuals with da/ccs: Physical Therapy (PT).
Through a twelve-person interview study, we examined how people's access to PT
for their da/cc is hampered by social (e.g., physically visiting a PT clinic)
and physiological (e.g., chronic pain) barriers, and how technology could
improve PT access. In-person PT is often inaccessible to our participants due
to lack of transportation and insufficient insurance coverage. As such, many of
our participants relied on at-home PT to manage their da/cc symptoms and worked
towards PT goals. Participants felt that PT barriers, such as having
particularly bad symptoms or feeling short on time, could be addressed with
well-designed technology that flexibly adapts to the person's dynamically
changing needs while supporting their PT goals. We introduce core design
principles (flexibility, movement tracking, community building) and tensions
(insurance) to consider when developing technology to support PT access.
Rethinking da/cc access to PT from a lens that includes social and
physiological barriers presents opportunities to integrate accessibility and
flexibility into PT technology."
1561,"Algorithmic methods that enable safe
and automated tracking of PT exercises is an unsolved issue that requires further research.","16
“I’m Just Overwhelmed”  Conference acronym ’XX, June 03–05, 2018, Woodstock, NY

To alleviate this time-burden, wearable sensors or camera-based technologies can be used to auto-
matically track the type and number of exercises completed.","During
algorithm development, it is important to consider our participants’ concerns about purchasing
additional hardware.",2022-02-04 18:11:58+00:00,"""I'm Just Overwhelmed"": Investigating Physical Therapy Accessibility and Technology Interventions for People with Disabilities and/or Chronic Conditions",cs.HC,['cs.HC'],"[arxiv.Result.Author('Momona Yamagami'), arxiv.Result.Author('Kelly Mack'), arxiv.Result.Author('Jennifer Mankoff'), arxiv.Result.Author('Katherine M. Steele')]","Many individuals with disabilities and/or chronic conditions (da/cc)
experience symptoms that may require intermittent or on-going medical care.
However, healthcare is an often-overlooked domain for accessibility work, where
access needs associated with temporary and long-term disability must be
addressed to increase the utility of physical and digital interactions with
healthcare workers and spaces. Our work focuses on a specific domain of
healthcare often used by individuals with da/cc: physical therapy (PT). Through
a twelve-person interview study, we examined how people's access to PT for
their da/cc is hampered by social (e.g., physically visiting a PT clinic) and
physiological (e.g., chronic pain) barriers, and how technology could improve
PT access. In-person PT is often inaccessible to our participants due to lack
of transportation and insufficient insurance coverage. As such, many of our
participants relied on at-home PT to manage their da/cc symptoms and work
towards PT goals. Participants felt that PT barriers, such as having
particularly bad symptoms or feeling short on time, could be addressed with
well-designed technology that flexibly adapts to the person's dynamically
changing needs while supporting their PT goals. We introduce core design
principles (adaptability, movement tracking, community building) and tensions
(insurance) to consider when developing technology to support PT access.
Rethinking da/cc access to PT from a lens that includes social and
physiological barriers presents opportunities to integrate accessibility and
adaptability into PT technology."
1566,"Finally, further research should explore how the theory we extend holds in different organiza-
tional contexts, as well as longitudinally.","Continuing Olson
and Olson [75]’s decades-long line of work, organizations can experiment with in-person retreats
(already a staple at location-independent organizations [89]); as-needed co-working spaces; and
hybrid schedules, in which employees are expected to be on-site for face-to-face activities during
designated portions of the week.","How do the size, dispersion, geographic location, and
demographic diversity of an organization play a role in its ability to achieve effective remote

                               Proc.",2022-02-05 04:10:08+00:00,"A ""Distance Matters"" Paradox: Facilitating Intra-Team Collaboration Can Harm Inter-Team Collaboration",cs.HC,['cs.HC'],"[arxiv.Result.Author('Xinlan Emily Hu'), arxiv.Result.Author('Rebecca Hinds'), arxiv.Result.Author('Melissa A. Valentine'), arxiv.Result.Author('Michael S. Bernstein')]","By identifying the socio-technical conditions required for teams to work
effectively remotely, the Distance Matters framework has been influential in
CSCW since its introduction in 2000. Advances in collaboration technology and
practices have since brought teams increasingly closer to achieving these
conditions. This paper presents a ten-month ethnography in a remote
organization, where we observed that despite exhibiting excellent remote
collaboration, teams paradoxically struggled to collaborate across team
boundaries. We extend the Distance Matters framework to account for inter-team
collaboration, arguing that challenges analogous to those in the original
intra-team framework -- common ground, collaboration readiness, collaboration
technology readiness, and coupling of work -- persist but are actualized
differently at the inter-team scale. Finally, we identify a fundamental tension
between the intra- and inter-team layers: the collaboration technology and
practices that help individual teams thrive (e.g., adopting customized
collaboration software) can also prompt collaboration challenges in the
inter-team layer, and conversely the technology and practices that facilitate
inter-team collaboration (e.g., strong centralized IT organizations) can harm
practices at the intra-team layer. The addition of the inter-team layer to the
Distance Matters framework opens new opportunities for CSCW, where balancing
the tension between team and organizational collaboration needs will be a
critical technological, operational, and organizational challenge for remote
work in the coming decades."
1567,"Therefore, the expanded Distance Matters
framework represents a rich new area for further study.","In fact, efforts to optimize teams for remote
work can undermine the effectiveness for organizations as a whole — opening numerous future
questions for organizations transitioning to remote work.","ACKNOWLEDGMENTS

The authors sincerely thank our field site partners, without whose help, support, and close col-
laboration this research would not have been possible.",2022-02-05 04:10:08+00:00,"A ""Distance Matters"" Paradox: Facilitating Intra-Team Collaboration Can Harm Inter-Team Collaboration",cs.HC,['cs.HC'],"[arxiv.Result.Author('Xinlan Emily Hu'), arxiv.Result.Author('Rebecca Hinds'), arxiv.Result.Author('Melissa A. Valentine'), arxiv.Result.Author('Michael S. Bernstein')]","By identifying the socio-technical conditions required for teams to work
effectively remotely, the Distance Matters framework has been influential in
CSCW since its introduction in 2000. Advances in collaboration technology and
practices have since brought teams increasingly closer to achieving these
conditions. This paper presents a ten-month ethnography in a remote
organization, where we observed that despite exhibiting excellent remote
collaboration, teams paradoxically struggled to collaborate across team
boundaries. We extend the Distance Matters framework to account for inter-team
collaboration, arguing that challenges analogous to those in the original
intra-team framework -- common ground, collaboration readiness, collaboration
technology readiness, and coupling of work -- persist but are actualized
differently at the inter-team scale. Finally, we identify a fundamental tension
between the intra- and inter-team layers: the collaboration technology and
practices that help individual teams thrive (e.g., adopting customized
collaboration software) can also prompt collaboration challenges in the
inter-team layer, and conversely the technology and practices that facilitate
inter-team collaboration (e.g., strong centralized IT organizations) can harm
practices at the intra-team layer. The addition of the inter-team layer to the
Distance Matters framework opens new opportunities for CSCW, where balancing
the tension between team and organizational collaboration needs will be a
critical technological, operational, and organizational challenge for remote
work in the coming decades."
1613,"2.2 Publicly Available Datasets for Human Stress Detection

Only a few human stress assessment datasets have been curated by the research com-
munity and are publicly available for further research.","TSST has been used in a variety of
stress measurement studies for inducing stress (Kurniawan et al., 2013; Engert et al.,
2014; Vinkers et al., 2013; Nater et al., 2005).","In this section, we present
details of publicly available data for this task using physiological signals.",2022-02-07 09:48:46+00:00,Mental Stress Detection using Data from Wearable and Non-wearable Sensors: A Review,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Aamir Arsalan'), arxiv.Result.Author('Syed Muhammad Anwar'), arxiv.Result.Author('Muhammad Majid')]","This paper presents a comprehensive review of methods covering significant
subjective and objective human stress detection techniques available in the
literature. The methods for measuring human stress responses could include
subjective questionnaires (developed by psychologists) and objective markers
observed using data from wearable and non-wearable sensors. In particular,
wearable sensor-based methods commonly use data from electroencephalography,
electrocardiogram, galvanic skin response, electromyography, electrodermal
activity, heart rate, heart rate variability, and photoplethysmography both
individually and in multimodal fusion strategies. Whereas, methods based on
non-wearable sensors include strategies such as analyzing pupil dilation and
speech, smartphone data, eye movement, body posture, and thermal imaging.
Whenever a stressful situation is encountered by an individual, physiological,
physical, or behavioral changes are induced which help in coping with the
challenge at hand. A wide range of studies has attempted to establish a
relationship between these stressful situations and the response of human
beings by using different kinds of psychological, physiological, physical, and
behavioral measures. Inspired by the lack of availability of a definitive
verdict about the relationship of human stress with these different kinds of
markers, a detailed survey about human stress detection methods is conducted in
this paper. In particular, we explore how stress detection methods can benefit
from artificial intelligence utilizing relevant data from various sources. This
review will prove to be a reference document that would provide guidelines for
future research enabling effective detection of human stress conditions."
1722,"Multiple review papers for dif-
                                       ferent specialities follow a similar pattern of positivity, but  2 Background
                                       note that further research is needed.",AR in surgical applications.,"The lack of research
                                       demonstrating clinical beneﬁt has been widely noted.",2022-02-08 21:02:12+00:00,Utility of Optical See-Through Head Mounted Displays in Augmented Reality-Assisted Surgery: A systematic review,cs.HC,['cs.HC'],"[arxiv.Result.Author('Manuel Birlo'), arxiv.Result.Author('P. J. ""Eddie\'\' Edwards'), arxiv.Result.Author('Matthew Clarkson'), arxiv.Result.Author('Danail Stoyanov')]","This article presents a systematic review of optical see-through head mounted
display (OST-HMD) usage in augmented reality (AR) surgery applications from
2013 to 2020. Articles were categorised by: OST-HMD device, surgical
speciality, surgical application context, visualisation content, experimental
design and evaluation, accuracy and human factors of human-computer
interaction. 91 articles fulfilled all inclusion criteria. Some clear trends
emerge. The Microsoft HoloLens increasingly dominates the field, with
orthopaedic surgery being the most popular application (28.6\%). By far the
most common surgical context is surgical guidance (n=58) and segmented
preoperative models dominate visualisation (n = 40). Experiments mainly involve
phantoms (n = 43) or system setup (n = 21), with patient case studies ranking
third (n = 19), reflecting the comparative infancy of the field. Experiments
cover issues from registration to perception with very different accuracy
results. Human factors emerge as significant to OST-HMD utility. Some factors
are addressed by the systems proposed, such as attention shift away from the
surgical site and mental mapping of 2D images to 3D patient anatomy. Other
persistent human factors remain or are caused by OST-HMD solutions, including
ease of use, comfort and spatial perception issues. The significant upward
trend in published articles is clear, but such devices are not yet established
in the operating room and clinical studies showing benefit are lacking. A
focused effort addressing technical registration and perceptual factors in the
lab coupled with design that incorporates human factors considerations to solve
clear clinical problems should ensure that the significant current research
efforts will succeed."
1815,"6.2 Future Directions for LBG Research

First, further research must be conducted into how players leverage Pokémon GO and other LBGs to cope with stressors,
particularly those relating to the pandemic.","This work, however, opens
several avenues for future work.",Player relationships to space must also be investigated more closely.,2022-02-10 17:37:47+00:00,Pokémon GO to Pokémon STAY: How Covid-19 Affected Pokémon GO Players,cs.HC,['cs.HC'],"[arxiv.Result.Author('John Dunham'), arxiv.Result.Author('Konstantinos Papangelis'), arxiv.Result.Author('Samuli Laato'), arxiv.Result.Author('Nicolas LaLone'), arxiv.Result.Author('Jin Ha Lee'), arxiv.Result.Author('Michael Saker')]","Since its creation, the Location-Based Game (LBG), Pok\'emon GO, has been
embraced by a community of fans across the world. Due to its recency, the
impact of COVID-19 on the community of Pok\'emon GO players is underexplored.
We address how COVID-19 has impacted the players of Pok\'emon GO by building
upon existing work focusing on player gratifications and impacts in Pok\'emon
GO. Through semi-structured interviews, we provide a snapshot of the state of
LBG play during unprecedented times. These player testimonies demonstrate (1)
the importance of in-person socialization to LBG, (2) additional ways players
use the game as a coping mechanism, and (3) how intentionality mediates player
perceptions of people-place relationships. In demonstrating these behaviors, we
provide a glimpse of how a game that forces players to explore the world around
them changed when going outside with friends became a source of danger."
1900,"Such experiments will enable us to further study the long-term
impact of exploration metrics and bias mitigating suggestions on people’s review exploration, holistic understanding,
and data-driven decision-making.","In future, we plan to deploy Serendyze as a longitudinal study to track participants’ purchase
behavior across a month on multiple online products.",Future Work.,2022-02-13 05:58:43+00:00,Supporting Serendipitous Discovery and Balanced Analysis of Unstructured Text with Interaction-Driven Metrics and Bias-Mitigating Suggestions,cs.HC,['cs.HC'],"[arxiv.Result.Author('Mahmood Jasim'), arxiv.Result.Author('Christopher Collins'), arxiv.Result.Author('Ali Sarvghad'), arxiv.Result.Author('Narges Mahyar')]","In this study, we investigate how supporting serendipitous discovery and
analysis of short free-form texts, such as product reviews can encourage
readers to explore texts more comprehensively prior to decision-making. We
propose two interventions -- Exploration Metrics that help readers understand
and track their exploration patterns through visual indicators and a Bias
Mitigation Model that maximizes knowledge discovery by suggesting readers
sentiment and semantically diverse reviews. We designed, developed, and
evaluated a text analytics system called Serendyze, where we integrated these
interventions. We asked 100 crowd workers to use Serendyze to make purchase
decisions based on product reviews. Our evaluation suggests that exploration
metrics enable readers to efficiently cover more reviews in a balanced way, and
suggestions from the bias mitigation model influence readers to make confident
data-driven decisions. We discuss the role of user agency and trust in
text-level analysis systems and their applicability in domains beyond review
exploration."
1901,"Such experiments will enable us to further study the long-term impact
of exploration metrics and bias mitigating suggestions on people’s review exploration, holistic understanding, and
data-driven decision-making based on their purchase habits and experiences that may vary across different regions.","In the future, we plan to deploy Serendyze as a longitudinal
study to track participants’ purchase behaviors over a month across multiple sessions on multiple online products and
among participants from diverse demographics.",Future Work.,2022-02-13 05:58:43+00:00,Supporting Serendipitous Discovery and Balanced Analysis of Online Product Reviews with Interaction-Driven Metrics and Bias-Mitigating Suggestions,cs.HC,['cs.HC'],"[arxiv.Result.Author('Mahmood Jasim'), arxiv.Result.Author('Christopher Collins'), arxiv.Result.Author('Ali Sarvghad'), arxiv.Result.Author('Narges Mahyar')]","In this study, we investigate how supporting serendipitous discovery and
analysis of online product reviews can encourage readers to explore reviews
more comprehensively prior to making purchase decisions. We propose two
interventions -- Exploration Metrics that can help readers understand and track
their exploration patterns through visual indicators and a Bias Mitigation
Model that intends to maximize knowledge discovery by suggesting sentiment and
semantically diverse reviews. We designed, developed, and evaluated a text
analytics system called Serendyze, where we integrated these interventions. We
asked 100 crowd workers to use Serendyze to make purchase decisions based on
product reviews. Our evaluation suggests that exploration metrics enabled
readers to efficiently cover more reviews in a balanced way, and suggestions
from the bias mitigation model influenced readers to make confident data-driven
decisions. We discuss the role of user agency and trust in text-level analysis
systems and their applicability in domains beyond review exploration."
1963,We see a need for further research on both     technology for parents.,"However, technological    the many opportunities that lie in designing automated guidance
aids are yet scarce [1].","understanding the use of technology in immigrant families, as well
as designing supportive artifacts, and aim to explore both directions   2.3 Contextual second language learning tools
in our work.",2022-02-14 15:49:22+00:00,Captivate! Contextual Language Guidance for Parent-Child Interaction,cs.HC,['cs.HC'],"[arxiv.Result.Author('Taeahn Kwon'), arxiv.Result.Author('Minkyung Jeong'), arxiv.Result.Author('Eon-Suk Ko'), arxiv.Result.Author('Youngki Lee')]","To acquire language, children need rich language input. However, many parents
find it difficult to provide children with sufficient language input, which
risks delaying their language development. To aid these parents, we design
Captivate!, the first system that provides contextual language guidance to
parents during play. Our system tracks both visual and spoken language cues to
infer targets of joint attention, enabling the real-time suggestion of
situation-relevant phrases for the parent. We design our system through a
user-centered process with immigrant families--a highly vulnerable yet
understudied population--as well as professional speech language therapists.
Next, we evaluate Captivate! on parents with children aged 1-3 to observe
improvements in responsive language use. We share insights into developing
contextual guidance technology for linguistically diverse families."
1996,"Other applications that can beneﬁt
                                                                         from further study include social network analysis [96] or
    Verifying and inspecting improvements (What (com-                    computer networking [97] by visualizing graph networks,
parison) & Why Not).",intelligible fairness tool.,Most experts used the Timeline                      and fair scheduling [98] by visualizing time tables.,2022-02-15 12:14:45+00:00,"IF-City: Intelligible Fair City Planning to Measure, Explain and Mitigate Inequality",cs.HC,['cs.HC'],"[arxiv.Result.Author('Yan Lyu'), arxiv.Result.Author('Hangxin Lu'), arxiv.Result.Author('Min Kyung Lee'), arxiv.Result.Author('Gerhard Schmitt'), arxiv.Result.Author('Brian Y. Lim')]","With the increasing pervasiveness of Artificial Intelligence (AI), many
visual analytics tools have been proposed to examine fairness, but they mostly
focus on data scientist users. Instead, tackling fairness must be inclusive and
involve domain experts with specialized tools and workflows. Thus,
domain-specific visualizations are needed for algorithmic fairness.
Furthermore, while much work on AI fairness has focused on predictive
decisions, less has been done for fair allocation and planning, which require
human expertise and iterative design to integrate myriad constraints. We
propose the Intelligible Fair Allocation (IF-Alloc) Framework that leverages
explanations of causal attribution (Why), contrastive (Why Not) and
counterfactual reasoning (What If, How To) to aid domain experts to assess and
alleviate unfairness in allocation problems. We apply the framework to fair
urban planning for designing cities that provide equal access to amenities and
benefits for diverse resident types. Specifically, we propose an interactive
visual tool, Intelligible Fair City Planner (IF-City), to help urban planners
to perceive inequality across groups, identify and attribute sources of
inequality, and mitigate inequality with automatic allocation simulations and
constraint-satisfying recommendations. We demonstrate and evaluate the usage
and usefulness of IF-City on a real neighborhood in New York City, US, with
practicing urban planners from multiple countries, and discuss generalizing our
findings, application, and framework to other use cases and applications of
fair allocation."
2027,"We have also included a reproducibility
package in Appendix C to support further research in AI-supported code translation.","An Evaluation of AI-Supported Code Translation  IUI ’22, March 22–25, 2022, Helsinki, Finland

6.3 Future Opportunities

Our study suggests several opportunities for how generative code user experiences can be designed to help people work
more effectively, especially via increasing transparency and usability, which are both associated with establishing trust
with autonomous tools in the context of high-stakes software engineering [99].",6.3.1 Intelligent presentation of multiple alternatives.,2022-02-15 19:09:39+00:00,Better Together? An Evaluation of AI-Supported Code Translation,cs.HC,"['cs.HC', 'cs.SE']","[arxiv.Result.Author('Justin D. Weisz'), arxiv.Result.Author('Michael Muller'), arxiv.Result.Author('Steven I. Ross'), arxiv.Result.Author('Fernando Martinez'), arxiv.Result.Author('Stephanie Houde'), arxiv.Result.Author('Mayank Agarwal'), arxiv.Result.Author('Kartik Talamadupula'), arxiv.Result.Author('John T. Richards')]","Generative machine learning models have recently been applied to source code,
for use cases including translating code between programming languages,
creating documentation from code, and auto-completing methods. Yet,
state-of-the-art models often produce code that is erroneous or incomplete. In
a controlled study with 32 software engineers, we examined whether such
imperfect outputs are helpful in the context of Java-to-Python code
translation. When aided by the outputs of a code translation model,
participants produced code with fewer errors than when working alone. We also
examined how the quality and quantity of AI translations affected the work
process and quality of outcomes, and observed that providing multiple
translations had a larger impact on the translation process than varying the
quality of provided translations. Our results tell a complex, nuanced story
about the benefits of generative code models and the challenges software
engineers face when working with their outputs. Our work motivates the need for
intelligent user interfaces that help software engineers effectively work with
generative code models in order to understand and evaluate their outputs and
achieve superior outcomes to working alone."
2028,"[54] offers a starting point in enumerating the kinds of questions people have regarding
discriminative models, and our work motivates the need for further study into the kinds of questions people have

                                                                                           23
IUI ’22, March 22–25, 2022, Helsinki, Finland  Weisz et al.",Work by Liao et al.,regarding generative models.,2022-02-15 19:09:39+00:00,Better Together? An Evaluation of AI-Supported Code Translation,cs.HC,"['cs.HC', 'cs.SE']","[arxiv.Result.Author('Justin D. Weisz'), arxiv.Result.Author('Michael Muller'), arxiv.Result.Author('Steven I. Ross'), arxiv.Result.Author('Fernando Martinez'), arxiv.Result.Author('Stephanie Houde'), arxiv.Result.Author('Mayank Agarwal'), arxiv.Result.Author('Kartik Talamadupula'), arxiv.Result.Author('John T. Richards')]","Generative machine learning models have recently been applied to source code,
for use cases including translating code between programming languages,
creating documentation from code, and auto-completing methods. Yet,
state-of-the-art models often produce code that is erroneous or incomplete. In
a controlled study with 32 software engineers, we examined whether such
imperfect outputs are helpful in the context of Java-to-Python code
translation. When aided by the outputs of a code translation model,
participants produced code with fewer errors than when working alone. We also
examined how the quality and quantity of AI translations affected the work
process and quality of outcomes, and observed that providing multiple
translations had a larger impact on the translation process than varying the
quality of provided translations. Our results tell a complex, nuanced story
about the benefits of generative code models and the challenges software
engineers face when working with their outputs. Our work motivates the need for
intelligent user interfaces that help software engineers effectively work with
generative code models in order to understand and evaluate their outputs and
achieve superior outcomes to working alone."
2029,"We encourage further research into those use cases, especially focused on how intelligent user interfaces can help users
achieve successful outcomes when working in the presence of imperfect model output.","There are many other kinds of tasks for which generative code models can provide support,
such as natural language to code, code documentation, code autocomplete, test case generation, bug repair, and others.","30
Better Together?",2022-02-15 19:09:39+00:00,Better Together? An Evaluation of AI-Supported Code Translation,cs.HC,"['cs.HC', 'cs.SE']","[arxiv.Result.Author('Justin D. Weisz'), arxiv.Result.Author('Michael Muller'), arxiv.Result.Author('Steven I. Ross'), arxiv.Result.Author('Fernando Martinez'), arxiv.Result.Author('Stephanie Houde'), arxiv.Result.Author('Mayank Agarwal'), arxiv.Result.Author('Kartik Talamadupula'), arxiv.Result.Author('John T. Richards')]","Generative machine learning models have recently been applied to source code,
for use cases including translating code between programming languages,
creating documentation from code, and auto-completing methods. Yet,
state-of-the-art models often produce code that is erroneous or incomplete. In
a controlled study with 32 software engineers, we examined whether such
imperfect outputs are helpful in the context of Java-to-Python code
translation. When aided by the outputs of a code translation model,
participants produced code with fewer errors than when working alone. We also
examined how the quality and quantity of AI translations affected the work
process and quality of outcomes, and observed that providing multiple
translations had a larger impact on the translation process than varying the
quality of provided translations. Our results tell a complex, nuanced story
about the benefits of generative code models and the challenges software
engineers face when working with their outputs. Our work motivates the need for
intelligent user interfaces that help software engineers effectively work with
generative code models in order to understand and evaluate their outputs and
achieve superior outcomes to working alone."
2231,"Obviously, social robotics is a natural
domain for further research on interactive politeness.",The proposed framework offers multiple research directions.,"Early research in this field suggests that people are
sensitive to robots’ polite behavior (Inbar and Meyer, 2019; Kato et al., 2015).",2022-02-20 20:12:22+00:00,Towards a Sociolinguistics-Based Framework for the Study of Politeness in Human-Computer Interaction,cs.HC,"['cs.HC', 'H.5.2; H.5.3']","[arxiv.Result.Author('Ella Bar-Or'), arxiv.Result.Author('Tom Regev'), arxiv.Result.Author('Paz Shaviv'), arxiv.Result.Author('Noam Tractinsky')]","Politeness plays an important role in regulating communication and enhancing
social interactions.Research suggests that people treat interactive systems as
social agents and may expect those systems to exhibit polite behavior. We
augment early research in this area by proposing a framework that is grounded
in sociolinguistics and pragmatics. The framework focuses on two complementary
concepts - clarity and politeness. We suggest that these concepts are pertinent
to various domains of interactive technologies and provide examples for the
applicability of clarity and politeness rules to human-computer interaction
(HCI). We conducted a laboratory experiment, in which politeness and clarity
served as independent factors in the context of a cooperative computer game,
based on the Peekaboom game. The manipulation of clarity failed, yet politeness
was manipulated successfully based on the framework's rules of politeness. The
results provide empirical support for the basic propositions of the framework
and may facilitate more systematic research on politeness in various domains of
social computing and other areas related to HCI."
2248,"To ensure the quality of the database used in further research, researchers still
have to clean and correct data manually.","We would like to claim that we do not believe today’s AI technology can build a ""fully automated"" system
to replace researchers in data extraction.","We think that building a human-AI collaboration solution with the appropriate
level of automation would be a better way to solve the problem so that the human and AI can jointly iterate, improve
and complete the data extraction.",2022-02-21 12:18:08+00:00,DeepShovel: An Online Collaborative Platform for Data Extraction in Geoscience Literature with AI Assistance,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Shao Zhang'), arxiv.Result.Author('Yuting Jia'), arxiv.Result.Author('Hui Xu'), arxiv.Result.Author('Ying Wen'), arxiv.Result.Author('Dakuo Wang'), arxiv.Result.Author('Xinbing Wang')]","Geoscientists, as well as researchers in many fields, need to read a huge
amount of literature to locate, extract, and aggregate relevant results and
data to enable future research or to build a scientific database, but there is
no existing system to support this use case well. In this paper, based on the
findings of a formative study about how geoscientists collaboratively annotate
literature and extract and aggregate data, we proposed DeepShovel, a
publicly-available AI-assisted data extraction system to support their needs.
DeepShovel leverages the state-of-the-art neural network models to support
researcher(s) easily and accurately annotate papers (in the PDF format) and
extract data from tables, figures, maps, etc. in a human-AI collaboration
manner. A follow-up user evaluation with 14 researchers suggested DeepShovel
improved users' efficiency of data extraction for building scientific
databases, and encouraged teams to form a larger scale but more tightly-coupled
collaboration."
2249,"To ensure the quality of the database used in further research, researchers still
have to clean and correct data manually.","We would like to claim that we do not believe today’s AI technology can build a ""fully automated"" system
to replace researchers in data extraction.","We think that building a human-AI collaboration solution with the appropriate
level of automation would be a better way to solve the problem so that the human and AI can jointly iterate, improve
and complete the data extraction.",2022-02-21 12:18:08+00:00,DeepShovel: An Online Collaborative Platform for Data Extraction in Geoscience Literature with AI Assistance,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Shao Zhang'), arxiv.Result.Author('Yuting Jia'), arxiv.Result.Author('Hui Xu'), arxiv.Result.Author('Ying Wen'), arxiv.Result.Author('Dakuo Wang'), arxiv.Result.Author('Xinbing Wang')]","Geoscientists, as well as researchers in many fields, need to read a huge
amount of literature to locate, extract, and aggregate relevant results and
data to enable future research or to build a scientific database, but there is
no existing system to support this use case well. In this paper, based on the
findings of a formative study about how geoscientists collaboratively annotate
literature and extract and aggregate data, we proposed DeepShovel, a
publicly-available AI-assisted data extraction system to support their needs.
DeepShovel leverages the state-of-the-art neural network models to support
researcher(s) easily and accurately annotate papers (in the PDF format) and
extract data from tables, figures, maps, etc. in a human-AI collaboration
manner. A follow-up user evaluation with 14 researchers suggested DeepShovel
improved users' efficiency of data extraction for building scientific
databases, and encouraged teams to form a larger scale but more tightly-coupled
collaboration."
2282,The reset command and creation mode were also           features has a design implication that requires further research.,"Adding those
quite intuitive.","Such
found quite useful by participants, but one was not able either to       features are needed to fully support analytical processes [8], along
use nor remember those commands.",2022-02-21 21:58:41+00:00,ReViVD: Exploration and Filtering of Trajectories in an Immersive Environment using 3D Shapes,cs.HC,"['cs.HC', 'cs.CV']","[arxiv.Result.Author('François Homps'), arxiv.Result.Author('Yohan Beugin'), arxiv.Result.Author('Romain Vuillemot')]","We present ReViVD, a tool for exploring and filtering large trajectory-based
datasets using virtual reality. ReViVD's novelty lies in using simple 3D shapes
-- such as cuboids, spheres and cylinders -- as queries for users to select and
filter groups of trajectories. Building on this simple paradigm, more complex
queries can be created by combining previously made selection groups through a
system of user-created Boolean operations. We demonstrate the use of ReViVD in
different application domains, from GPS position tracking to simulated data
(e.g., turbulent particle flows and traffic simulation). Our results show the
ease of use and expressiveness of the 3D geometric shapes in a broad range of
exploratory tasks. ReViVD was found to be particularly useful for progressively
refining selections to isolate outlying behaviors. It also acts as a powerful
communication tool for conveying the structure of normally abstract datasets to
an audience."
2283,"Nevertheless, further research on how the
crowd can work collaboratively in other higher-level tasks such as feature selection, evaluation, and interpretations
of models, is still needed.","We have already
witnessed substantial progress in crowdsourcing-based labeling tasks.",8.,2022-02-21 22:45:59+00:00,Human-in-the-loop Machine Learning: A Macro-Micro Perspective,cs.HC,['cs.HC'],"[arxiv.Result.Author('Jiangtao Wang'), arxiv.Result.Author('Bin Guo'), arxiv.Result.Author('Liming Chen')]","Though technical advance of artificial intelligence and machine learning has
enabled many promising intelligent systems, many computing tasks are still not
able to be fully accomplished by machine intelligence. Motivated by the
complementary nature of human and machine intelligence, an emerging trend is to
involve humans in the loop of machine learning and decision-making. In this
paper, we provide a macro-micro review of human-in-the-loop machine learning.
We first describe major machine learning challenges which can be addressed by
human intervention in the loop. Then we examine closely the latest research and
findings of introducing humans into each step of the lifecycle of machine
learning. Finally, we analyze current research gaps and point out future
research directions."
2384,"Nips tutorial, 1: 2017.
in producing similar large-scale decision tasks and datasets
to further study such intricacies across varied domains.","Fairness in
environments and propose that the community jointly invest        machine learning.","Barocas, S.; and Selbst, A.",2022-02-21 17:58:07+00:00,Investigations of Performance and Bias in Human-AI Teamwork in Hiring,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Andi Peng'), arxiv.Result.Author('Besmira Nushi'), arxiv.Result.Author('Emre Kiciman'), arxiv.Result.Author('Kori Inkpen'), arxiv.Result.Author('Ece Kamar')]","In AI-assisted decision-making, effective hybrid (human-AI) teamwork is not
solely dependent on AI performance alone, but also on its impact on human
decision-making. While prior work studies the effects of model accuracy on
humans, we endeavour here to investigate the complex dynamics of how both a
model's predictive performance and bias may transfer to humans in a
recommendation-aided decision task. We consider the domain of ML-assisted
hiring, where humans -- operating in a constrained selection setting -- can
choose whether they wish to utilize a trained model's inferences to help select
candidates from written biographies. We conduct a large-scale user study
leveraging a re-created dataset of real bios from prior work, where humans
predict the ground truth occupation of given candidates with and without the
help of three different NLP classifiers (random, bag-of-words, and deep neural
network). Our results demonstrate that while high-performance models
significantly improve human performance in a hybrid setting, some models
mitigate hybrid bias while others accentuate it. We examine these findings
through the lens of decision conformity and observe that our model architecture
choices have an impact on human-AI conformity and bias, motivating the explicit
need to assess these complex dynamics prior to deployment."
2490,"Specific attention and further research will build on the current core elements of the wearable
    µBrain expanding out the research aspects linked to its robustness, fault tolerance, usability and
    performance.","Future research will investigate the potential to develop a more
    enhanced wearable µBrain design, investigating further elements of SNN and neuromorphic
    technologies along with brain inspired methodologies to develop a next iteration prototype.","Also, further research will be investigated around the application of the wearable
    µBrain concept across other health focused use cases (for example stroke rehabilitation and
    epilepsy) , assessing its extendibility and potential to impact such critical conditions is a beneficial
    manner.",2022-02-25 21:30:45+00:00,Wearable uBrain: Fabric Based-Spiking Neural Network,cs.HC,"['cs.HC', 'cs.ET']","[arxiv.Result.Author('Frances Cleary'), arxiv.Result.Author('Witawas Srisa-an'), arxiv.Result.Author('Beatriz Gil'), arxiv.Result.Author('Jaideep Kesavan'), arxiv.Result.Author('Tobias Engel'), arxiv.Result.Author('David C. Henshall'), arxiv.Result.Author('Sasitharan Balasubramaniam')]","On garment intelligence influenced by artificial neural networks and
neuromorphic computing is emerging as a research direction in the e-textile
sector. In particular, bio inspired Spiking Neural Networks mimicking the
workings of the brain show promise in recent ICT research applications. Taking
such technological advancements and new research directions driving forward the
next generation of e-textiles and smart materials, we present a wearable micro
Brain capable of event driven artificial spiking neural network computation in
a fabric based environment. We demonstrate a wearable Brain SNN prototype with
multi-layer computation, enabling scalability and flexibility in terms of
modifications for hidden layers to be augmented to the network. The wearable
micro Brain provides a low size, weight and power artificial on-garment
intelligent wearable solution with embedded functionality enabling offline
adaptive learning through the provision of interchangeable resistor synaptic
weightings. The prototype has been evaluated for fault tolerance, where we have
determine the robustness of the circuit when certain parts are damaged.
Validations were also conducted for movements to determine if the circuit can
still perform accurate computation."
2491,"Also, further research will be investigated around the application of the wearable
    µBrain concept across other health focused use cases (for example stroke rehabilitation and
    epilepsy) , assessing its extendibility and potential to impact such critical conditions is a beneficial
    manner.","Specific attention and further research will build on the current core elements of the wearable
    µBrain expanding out the research aspects linked to its robustness, fault tolerance, usability and
    performance.","6 Acknowledgments

D. Henshall is funded in part by FutureNeuro from Science Foundation Ireland (SFI) under Grant
Number 16/RC/3948 and co-funded under the European Regional Development Fund and by
FutureNeuro industry partners.",2022-02-25 21:30:45+00:00,Wearable uBrain: Fabric Based-Spiking Neural Network,cs.HC,"['cs.HC', 'cs.ET']","[arxiv.Result.Author('Frances Cleary'), arxiv.Result.Author('Witawas Srisa-an'), arxiv.Result.Author('Beatriz Gil'), arxiv.Result.Author('Jaideep Kesavan'), arxiv.Result.Author('Tobias Engel'), arxiv.Result.Author('David C. Henshall'), arxiv.Result.Author('Sasitharan Balasubramaniam')]","On garment intelligence influenced by artificial neural networks and
neuromorphic computing is emerging as a research direction in the e-textile
sector. In particular, bio inspired Spiking Neural Networks mimicking the
workings of the brain show promise in recent ICT research applications. Taking
such technological advancements and new research directions driving forward the
next generation of e-textiles and smart materials, we present a wearable micro
Brain capable of event driven artificial spiking neural network computation in
a fabric based environment. We demonstrate a wearable Brain SNN prototype with
multi-layer computation, enabling scalability and flexibility in terms of
modifications for hidden layers to be augmented to the network. The wearable
micro Brain provides a low size, weight and power artificial on-garment
intelligent wearable solution with embedded functionality enabling offline
adaptive learning through the provision of interchangeable resistor synaptic
weightings. The prototype has been evaluated for fault tolerance, where we have
determine the robustness of the circuit when certain parts are damaged.
Validations were also conducted for movements to determine if the circuit can
still perform accurate computation."
2511,"to further research into the malicious potential of perceptually           Broadly, whilst it would be understandable if there was still some
manipulating users in the context of XR.","Based on our current findings, we open the door

                                                                          8 https://en.wikipedia.org/wiki/Collingridge_dilemma
CHI ’22, April 29-May 5, 2022, New Orleans, LA, USA                                                                                                              Tseng, et al.","scepticism regarding the prescience of the risks posed by VPPMs, it
                                                                        is our view that we have only just begun to understand the extent
   Intent beyond Physical Harm.",2022-02-26 17:45:34+00:00,The Dark Side of Perceptual Manipulations in Virtual Reality,cs.HC,['cs.HC'],"[arxiv.Result.Author('Wen-Jie Tseng'), arxiv.Result.Author('Elise Bonnail'), arxiv.Result.Author('Mark McGill'), arxiv.Result.Author('Mohamed Khamis'), arxiv.Result.Author('Eric Lecolinet'), arxiv.Result.Author('Samuel Huron'), arxiv.Result.Author('Jan Gugenheimer')]","""Virtual-Physical Perceptual Manipulations"" (VPPMs) such as redirected
walking and haptics expand the user's capacity to interact with Virtual Reality
(VR) beyond what would ordinarily physically be possible. VPPMs leverage
knowledge of the limits of human perception to effect changes in the user's
physical movements, becoming able to (perceptibly and imperceptibly) nudge
their physical actions to enhance interactivity in VR. We explore the risks
posed by the malicious use of VPPMs. First, we define, conceptualize and
demonstrate the existence of VPPMs. Next, using speculative design workshops,
we explore and characterize the threats/risks posed, proposing mitigations and
preventative recommendations against the malicious use of VPPMs. Finally, we
implement two sample applications to demonstrate how existing VPPMs could be
trivially subverted to create the potential for physical harm. This paper aims
to raise awareness that the current way we apply and publish VPPMs can lead to
malicious exploits of our perceptual vulnerabilities."
2523,"Those EEG traits were linked to tiredness in
also conducted deconvolution analysis on the EEG-related          drivers, but we couldn't identify any further research that
fMRI time stream.",They           tDCS and tACS.,The authors segmented the deconvolution         properly verified the causal association.,2022-02-27 12:00:25+00:00,Drowsiness detection using combined neuroimaging: Overview and Challenges,cs.HC,['cs.HC'],"[arxiv.Result.Author('A S M Sharifuzzaman Sagar'), arxiv.Result.Author('Tajken Salehen'), arxiv.Result.Author('Md Abdur Rob')]","Brain-computer interfaces (BCIs) collect, analyze, and convert brain activity
into instructions and send it to the detection system. BCI is becoming popular
in under-brain activities in certain conditions such as attention-based tasks.
Researchers have recently used combined neuroimaging techniques such as
EEG+fNIRS and EEG+fMRI to solve many real-world problems. Drowsiness detection
or sleep inertia is one of the central research areas for the combined
neuroimaging techniques. This paper aims to investigate the recent application
of combined neuroimaging-based BCI on drowsiness detection or sleep inertia. To
this end, this is the only overview paper of the combined neuroimaging-based
drowsiness detection system."
2525,"In a further study, using a similar paradigm, Fusaro et al.","This study found that top-down factors modulate pleasure and pain
perceptions, with first-person perspective (1PP) and a self-oriented cognitive stance leading to more
intense touch experiences compared to adopting a third-person perspective and an others-oriented
mental mode.","(2021) found that mere
observation of visually presented touch on an embodied virtual body is sufficient to evoke increased
skin conductance responses (SCRs).",2022-02-27 16:09:23+00:00,Evoking realistic affective touch experiences in virtual reality,cs.HC,"['cs.HC', '68', 'J.4']","[arxiv.Result.Author('Sofia Seinfeld'), arxiv.Result.Author('Ivette Schmidt'), arxiv.Result.Author('Jörg Müller')]","This study aims to better understand the emotional and physiological
correlates of being caressed in VR depending on the type of multisensory
feedback provided and the animate or inanimate nature of the virtual
representation that touches an embodied virtual body. We evaluated how
pleasure, arousal, embodiment, and the illusion of being touched in VR were
influenced by the inclusion of only visual feedback compared to visuotactile
stimulation conditions, where participants, in addition to seeing an avatar or
feather caressing their virtual bodies, also perceived congruent mid-air
ultrasonic tactile stimulation or real interpersonal touch. We found that
visuotactile feedback, either based on ultrasound or real interpersonal touch,
boosts the illusion of being affectively touched and embodied in a virtual body
compared to conditions only based on visual feedback. However, real
interpersonal touch led to the strongest behavioral and emotional responses
compared to the other conditions. Moreover, arousal and the desire to withdraw
the caressed hand was highest when being touched by a female avatar compared to
a virtual feather. Female participants reported a stronger illusion of being
caressed in VR compared to males. Overall, this study advances knowledge of the
emotional and physiological impact of affective touch in VR."
2526,"This is an important aspect that deserves further research, since in the present study we
also took special care in animating the movement of the avatar and feather using full body motion
tracking recordings, and replicated the earlier results obtained by Fusaro et al.","Another interesting aspect is that Fusaro et al., (2019) stressed the importance of using natural human
kinematics to emulate the caresses, since in a previous study in which they used unnatural
preprogrammed avatar movements to simulate a caress, embodiment was not enhanced (Fusaro et
al., 2016).","(2019) with respect to
embodiment.",2022-02-27 16:09:23+00:00,Evoking realistic affective touch experiences in virtual reality,cs.HC,"['cs.HC', '68', 'J.4']","[arxiv.Result.Author('Sofia Seinfeld'), arxiv.Result.Author('Ivette Schmidt'), arxiv.Result.Author('Jörg Müller')]","This study aims to better understand the emotional and physiological
correlates of being caressed in VR depending on the type of multisensory
feedback provided and the animate or inanimate nature of the virtual
representation that touches an embodied virtual body. We evaluated how
pleasure, arousal, embodiment, and the illusion of being touched in VR were
influenced by the inclusion of only visual feedback compared to visuotactile
stimulation conditions, where participants, in addition to seeing an avatar or
feather caressing their virtual bodies, also perceived congruent mid-air
ultrasonic tactile stimulation or real interpersonal touch. We found that
visuotactile feedback, either based on ultrasound or real interpersonal touch,
boosts the illusion of being affectively touched and embodied in a virtual body
compared to conditions only based on visual feedback. However, real
interpersonal touch led to the strongest behavioral and emotional responses
compared to the other conditions. Moreover, arousal and the desire to withdraw
the caressed hand was highest when being touched by a female avatar compared to
a virtual feather. Female participants reported a stronger illusion of being
caressed in VR compared to males. Overall, this study advances knowledge of the
emotional and physiological impact of affective touch in VR."
2527,"The present study did not directly address some aspects that should be further researched by
future studies.","Based on the results of the present study, we propose
that the addition of visuotactile feedback in VR scenarios simulating social interactions has enormous
potential in areas such as psychological therapy (Kim et al., 2019), motor rehabilitation (Zakharov et
al., 2020), pain treatment (Donegan et al., 2020; Matamala-Gomez et al., 2019), and VR-based
videoconferences (Fermoselle et al., 2020), areas that should be researched in more detail in the near
future.","First, we only investigated the impact of being touched by a female avatar compared
to a virtual inanimate object (i.e., feather), however we did not include a condition where participants
were touched by a male avatar.",2022-02-27 16:09:23+00:00,Evoking realistic affective touch experiences in virtual reality,cs.HC,"['cs.HC', '68', 'J.4']","[arxiv.Result.Author('Sofia Seinfeld'), arxiv.Result.Author('Ivette Schmidt'), arxiv.Result.Author('Jörg Müller')]","This study aims to better understand the emotional and physiological
correlates of being caressed in VR depending on the type of multisensory
feedback provided and the animate or inanimate nature of the virtual
representation that touches an embodied virtual body. We evaluated how
pleasure, arousal, embodiment, and the illusion of being touched in VR were
influenced by the inclusion of only visual feedback compared to visuotactile
stimulation conditions, where participants, in addition to seeing an avatar or
feather caressing their virtual bodies, also perceived congruent mid-air
ultrasonic tactile stimulation or real interpersonal touch. We found that
visuotactile feedback, either based on ultrasound or real interpersonal touch,
boosts the illusion of being affectively touched and embodied in a virtual body
compared to conditions only based on visual feedback. However, real
interpersonal touch led to the strongest behavioral and emotional responses
compared to the other conditions. Moreover, arousal and the desire to withdraw
the caressed hand was highest when being touched by a female avatar compared to
a virtual feather. Female participants reported a stronger illusion of being
caressed in VR compared to males. Overall, this study advances knowledge of the
emotional and physiological impact of affective touch in VR."
2528,"Finally, as already noted, in the present study we
only stimulated the glabrous skin of the palmar side of the hand due to its higher tactile sensitivity,
however further research is needed to better understand whether bodily-related illusions (i.e., illusion
of being touched and embodiment) are differently impacted when participants are touched on
different body parts with glabrous and non-glabrous skin.","It would be interesting that future studies investigate if the
present results vary when using constant velocities, as well as if there are critical velocities ranges for
touch to be considered pleasant or unpleasant in VR.","Moreover, in this study we researched the
impact of being caressed in VR without the inclusion of a control condition based on the perception of
nociceptive stimuli or neutral non-affective touch.",2022-02-27 16:09:23+00:00,Evoking realistic affective touch experiences in virtual reality,cs.HC,"['cs.HC', '68', 'J.4']","[arxiv.Result.Author('Sofia Seinfeld'), arxiv.Result.Author('Ivette Schmidt'), arxiv.Result.Author('Jörg Müller')]","This study aims to better understand the emotional and physiological
correlates of being caressed in VR depending on the type of multisensory
feedback provided and the animate or inanimate nature of the virtual
representation that touches an embodied virtual body. We evaluated how
pleasure, arousal, embodiment, and the illusion of being touched in VR were
influenced by the inclusion of only visual feedback compared to visuotactile
stimulation conditions, where participants, in addition to seeing an avatar or
feather caressing their virtual bodies, also perceived congruent mid-air
ultrasonic tactile stimulation or real interpersonal touch. We found that
visuotactile feedback, either based on ultrasound or real interpersonal touch,
boosts the illusion of being affectively touched and embodied in a virtual body
compared to conditions only based on visual feedback. However, real
interpersonal touch led to the strongest behavioral and emotional responses
compared to the other conditions. Moreover, arousal and the desire to withdraw
the caressed hand was highest when being touched by a female avatar compared to
a virtual feather. Female participants reported a stronger illusion of being
caressed in VR compared to males. Overall, this study advances knowledge of the
emotional and physiological impact of affective touch in VR."
2535,"could be the main cause of the uncertainty,
which undermines the interpretability of these results and suggests the need for
further research.","Lack of environmental con-
trol (e.g., traﬃc, weather, etc.)","Additionally, only a limited number of human sensing devices
can be applied in naturalistic settings, as many of these devices are intrusive.",2022-02-27 22:36:10+00:00,Roadway Design Matters: Variation in Bicyclists' Psycho-Physiological Responses in Different Urban Roadway Designs,cs.HC,"['cs.HC', 'J.4']","[arxiv.Result.Author('Xiang Guo'), arxiv.Result.Author('Arash Tavakoli'), arxiv.Result.Author('Erin Robartes'), arxiv.Result.Author('Austin Angulo'), arxiv.Result.Author('T. Donna Chen'), arxiv.Result.Author('Arsalan Heydarian')]","As a healthier and more sustainable way of mobility, cycling has been
advocated by literature and policy. However, current trends in bicyclist crash
fatalities suggest deficiencies in current roadway design in protecting these
vulnerable road users. The lack of cycling data is a common challenge for
studying bicyclists' safety, behavior, and comfort levels under different
design contexts. To understand bicyclists' behavioral and physiological
responses in an efficient and safe way, this study uses a bicycle simulator
within an immersive virtual environment (IVE). Off-the-shelf sensors are
utilized to evaluate bicyclists' cycling performance (speed and lane position)
and physiological responses (eye tracking and heart rate (HR)). Participants
bike in a simulated virtual environment modeled to scale from a real-world
street with a shared bike lane (sharrow) to evaluate how introduction of a bike
lane and a protected bike lane with pylons may impact perceptions of safety, as
well as behavioral and psycho-physiological responses. Results from 50
participants show that the protected bike lane design received the highest
perceived safety rating and exhibited the lowest average cycling speed.
Furthermore, both the bike lane and the protected bike lane scenarios show a
less dispersed gaze distribution than the as-built sharrow scenario, reflecting
a higher gaze focus among bicyclists on the biking task in the bike lane and
protected bike lane scenarios, compared to when bicyclists share right of way
with vehicles. Additionally, heart rate change point results from the study
suggest that creating dedicated zones for bicyclists (bike lanes or protected
bike lanes) has the potential to reduce bicyclists' stress levels."
2536,"First, the duration of the experiment is
short, some ﬁndings in this experiment needs further study.","6 Limitations and Future Work

Limitations of this study are as follows.","Building a longer
road segment in the IVE with more street blocks can be a solution.",2022-02-27 22:36:10+00:00,Roadway Design Matters: Variation in Bicyclists' Psycho-Physiological Responses in Different Urban Roadway Designs,cs.HC,"['cs.HC', 'J.4']","[arxiv.Result.Author('Xiang Guo'), arxiv.Result.Author('Arash Tavakoli'), arxiv.Result.Author('Erin Robartes'), arxiv.Result.Author('Austin Angulo'), arxiv.Result.Author('T. Donna Chen'), arxiv.Result.Author('Arsalan Heydarian')]","As a healthier and more sustainable way of mobility, cycling has been
advocated by literature and policy. However, current trends in bicyclist crash
fatalities suggest deficiencies in current roadway design in protecting these
vulnerable road users. The lack of cycling data is a common challenge for
studying bicyclists' safety, behavior, and comfort levels under different
design contexts. To understand bicyclists' behavioral and physiological
responses in an efficient and safe way, this study uses a bicycle simulator
within an immersive virtual environment (IVE). Off-the-shelf sensors are
utilized to evaluate bicyclists' cycling performance (speed and lane position)
and physiological responses (eye tracking and heart rate (HR)). Participants
bike in a simulated virtual environment modeled to scale from a real-world
street with a shared bike lane (sharrow) to evaluate how introduction of a bike
lane and a protected bike lane with pylons may impact perceptions of safety, as
well as behavioral and psycho-physiological responses. Results from 50
participants show that the protected bike lane design received the highest
perceived safety rating and exhibited the lowest average cycling speed.
Furthermore, both the bike lane and the protected bike lane scenarios show a
less dispersed gaze distribution than the as-built sharrow scenario, reflecting
a higher gaze focus among bicyclists on the biking task in the bike lane and
protected bike lane scenarios, compared to when bicyclists share right of way
with vehicles. Additionally, heart rate change point results from the study
suggest that creating dedicated zones for bicyclists (bike lanes or protected
bike lanes) has the potential to reduce bicyclists' stress levels."
2666,"Also, the data from
the next timestep as:                                                          this participant is available online for further research [49].","We
Using a latent variable matrix at each timestep, together with                 ﬁrst focus on a long-term driving of one participant (#9) on
its covariance matrix (P), SSM predicts the latent variables at                a highway for the purpose of this paper.","A
                                                                               snapshot of the driving scenario is depicted on Fig.",2022-03-02 02:58:18+00:00,Driver State Modeling through Latent Variable State Space Framework in the Wild,cs.HC,['cs.HC'],"[arxiv.Result.Author('Arash Tavakoli'), arxiv.Result.Author('Steven Boker'), arxiv.Result.Author('Arsalan Heydarian')]","Analyzing the impact of the environment on drivers' stress level and workload
is of high importance for designing human-centered driver-vehicle interaction
systems and to ultimately help build a safer driving experience. However,
driver's state, including stress level and workload, are psychological
constructs that cannot be measured on their own and should be estimated through
sensor measurements such as psychophysiological measures. We propose using a
latent-variable state-space modeling framework for driver state analysis. By
using latent-variable state-space models, we model drivers' workload and stress
levels as latent variables estimated through multimodal human sensing data,
under the perturbations of the environment in a state-space format and in a
holistic manner. Through using a case study of multimodal driving data
collected from 11 participants, we first estimate the latent stress level and
workload of drivers from their heart rate, gaze measures, and intensity of
facial action units. We then show that external contextual elements such as the
number of vehicles as a proxy for traffic density and secondary task demands
may be associated with changes in driver's stress levels and workload. We also
show that different drivers may be impacted differently by the aforementioned
perturbations. We found out that drivers' latent states at previous timesteps
are highly associated with their current states. Additionally, we discuss the
utility of state-space models in analyzing the possible lag between the two
constructs of stress level and workload, which might be indicative of
information transmission between the different parts of the driver's
psychophysiology in the wild."
2682,"Unpacking the reasons for visitors constructing
accounts that tend to agree with the system is clearly a topic for further research.","Finally, we note that invoking “ambiguity of relationship” and “ambiguity
of context” are further tactics (in addition to the “ambiguity of information” noted earlier) for creating ambiguity as
proposed by Gaver et al [28]; perhaps our visitors were creating interpretations that could resolve their ambiguous
relationship to the system and its ambiguous presence within art gallery.",We draw attention to further opportunities for displaying emotion data in museums beyond take-away souvenirs.,2022-03-02 11:39:01+00:00,Sensitive Pictures: Emotional Interpretation in the Museum,cs.HC,['cs.HC'],"[arxiv.Result.Author('Steve Benford'), arxiv.Result.Author('Anders Sundnes Løvlie'), arxiv.Result.Author('Karin Ryding'), arxiv.Result.Author('Paulina Rajkowska'), arxiv.Result.Author('Edgar Bodiaj'), arxiv.Result.Author('Dimitrios Paris Darzentas'), arxiv.Result.Author('Harriet R Cameron'), arxiv.Result.Author('Jocelyn Spence'), arxiv.Result.Author('Joy Egede'), arxiv.Result.Author('Bogdan Spanjevic')]","Museums are interested in designing emotional visitor experiences to
complement traditional interpretations. HCI is interested in the relationship
between Affective Computing and Affective Interaction. We describe Sensitive
Pictures, an emotional visitor experience co-created with the Munch art museum.
Visitors choose emotions, locate associated paintings in the museum, experience
an emotional story while viewing them, and self-report their response. A
subsequent interview with a portrayal of the artist employs computer vision to
estimate emotional responses from facial expressions. Visitors are given a
souvenir postcard visualizing their emotional data. A study of 132 members of
the public (39 interviewed) illuminates key themes: designing emotional
provocations; capturing emotional responses; engaging visitors with their data;
a tendency for them to align their views with the system's interpretation; and
integrating these elements into emotional trajectories. We consider how
Affective Computing can hold up a mirror to our emotions during Affective
Interaction."
2722,"However, research on the long-term exposure to the
empathy stimulus is limited, and further research would help to elucidate how the duration of the experience affects
empathy.","Contrasting these XR technologies with literature, we see that most literature is experienced over a longer period of
time, which possibly serves to build a stronger feeling of empathy.","5 https://www.eff.org/deeplinks/2020/08/if- privacy- dies- vr- it- dies- real- life
                                                                                           18
From Digital Media to Empathic Reality  ACM CSUR, 2023, Online

4.2 Facilitating Empathy in XR and Metaverse

To elicit empathy in a person, the choice and design of the suitable stimulus play a large role.",2022-02-23 12:51:19+00:00,From Digital Media to Empathic Reality: A Systematic Review of Empathy Research in Extended Reality Environments,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Ville Paananen'), arxiv.Result.Author('Mohammad Sina Kiarostami'), arxiv.Result.Author('Lik-Hang Lee'), arxiv.Result.Author('Tristan Braud'), arxiv.Result.Author('Simo Hosio')]","Recent advances in extended reality (XR) technologies have enabled new and
increasingly realistic empathy tools and experiences. In XR, all interactions
take place in different spatial contexts, all with different features,
affordances, and constraints. We present a systematic literature survey of
recent work on empathy in XR. As a result, we contribute a research roadmap
with three future opportunities in XR-enabled empathy research across both
physical and virtual spaces."
2723,"Remarkably, the knowledge of
collaborative interactions (many-to-many) and user agency also requires further research (Sections 3 and 4), and we
call for diversified tools to promote the understanding of users’ empathy in XR, especially when designing interaction
for empathic reality requires doubled efforts compared to usual XR applications, for the investigation of both users and
the Other.","Researchers
have proposed various prototyping tools to address the issue, such as SpatialProto [89], but none of the existing works,
to the best of our knowledge, serves prototyping XR in empathic contexts specifically.","5.3 From Virtual Environments to the Metaverse

From the exhaustive list of studies considered in this paper (Appendix B), we see significant research efforts on pursuing
empathy development in people through XR technologies.",2022-02-23 12:51:19+00:00,From Digital Media to Empathic Reality: A Systematic Review of Empathy Research in Extended Reality Environments,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Ville Paananen'), arxiv.Result.Author('Mohammad Sina Kiarostami'), arxiv.Result.Author('Lik-Hang Lee'), arxiv.Result.Author('Tristan Braud'), arxiv.Result.Author('Simo Hosio')]","Recent advances in extended reality (XR) technologies have enabled new and
increasingly realistic empathy tools and experiences. In XR, all interactions
take place in different spatial contexts, all with different features,
affordances, and constraints. We present a systematic literature survey of
recent work on empathy in XR. As a result, we contribute a research roadmap
with three future opportunities in XR-enabled empathy research across both
physical and virtual spaces."
2796,"AR and VR enable instructors to conduct
                                       introduce avenues for further research and discuss collaboration         laboratory sessions remotely without travel and provide students
                                       challenges posed by this context.",We      approach to this challenge.,with immersive experiences that mimic realistic scenarios.,2022-03-04 08:37:53+00:00,Anatomy Studio II: A Cross-Reality Application for Teaching Anatomy,cs.HC,"['cs.HC', 'I.3; J.3']","[arxiv.Result.Author('Joaquim Jorge'), arxiv.Result.Author('Pedro Belchior'), arxiv.Result.Author('Abel Gomes'), arxiv.Result.Author('Maurício Sousa'), arxiv.Result.Author('João Pereira'), arxiv.Result.Author('Jean-François Uhl')]","Virtual Reality has become an important educational tool, due to the pandemic
and increasing globalization of education. This paper presents a framework for
teaching Virtual Anatomy at the university level. Virtual classes have become a
staple of today's curricula because of the isolation and quarantine
requirements and the increased international collaboration. Our work builds on
the Visible Human Projects for Virtual Dissection material and provides a
medium for groups of students to do collaborative anatomical dissections in
real-time using sketching and 3D visualizations and audio coupled with
interactive 2D tablets for precise drawing. We describe the system
architecture, compare requirements with those of previous development, and
discuss the preliminary results. Discussions with Anatomists show that this is
an effective tool. We introduce avenues for further research and discuss
collaboration challenges posed by this context."
2863,"This necessitates further research           back wall, which was achieved by gradually rotating the
into the understanding of rotation gains beyond perceptual         virtual scene towards the direction of the front screen.","Their method allowed
tive preferences to those large gains and how strong a user        users to virtually move around without facing the missing
might be manipulated.","Seven
limitations.",2022-03-05 14:09:33+00:00,On Rotation Gains Within and Beyond Perceptual Limitations for Seated VR,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Chen Wang'), arxiv.Result.Author('Song-Hai Zhang'), arxiv.Result.Author('Yizhuo Zhang'), arxiv.Result.Author('Stefanie Zollmann'), arxiv.Result.Author('Shi-Min Hu')]","Head tracking in head-mounted displays (HMDs) enables users to explore a
360-degree virtual scene with free head movements. However, for seated use of
HMDs such as users sitting on a chair or a couch, physically turning around
360-degree is not possible. Redirection techniques decouple tracked physical
motion and virtual motion, allowing users to explore virtual environments with
more flexibility. In seated situations with only head movements available, the
difference of stimulus might cause the detection thresholds of rotation gains
to differ from that of redirected walking. Therefore we present an experiment
with a two-alternative forced-choice (2AFC) design to compare the thresholds
for seated and standing situations. Results indicate that users are unable to
discriminate rotation gains between 0.89 and 1.28, a smaller range compared to
the standing condition. We further treated head amplification as an interaction
technique and found that a gain of 2.5, though not a hard threshold, was near
the largest gain that users consider applicable. Overall, our work aims to
better understand human perception of rotation gains in seated VR and the
results provide guidance for future design choices of its applications."
2864,"Our ﬁndings provide            ampliﬁed head rotations that introduce less sickness than
valuable insights and open up further research directions          scrolling [28].","We revealed that most participants thought gains            Another line of work is redirected head movements with
up to 2.5 were practical for usage.","Head rotations are ampliﬁed using an ampli-
for seated VR applications.",2022-03-05 14:09:33+00:00,On Rotation Gains Within and Beyond Perceptual Limitations for Seated VR,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Chen Wang'), arxiv.Result.Author('Song-Hai Zhang'), arxiv.Result.Author('Yizhuo Zhang'), arxiv.Result.Author('Stefanie Zollmann'), arxiv.Result.Author('Shi-Min Hu')]","Head tracking in head-mounted displays (HMDs) enables users to explore a
360-degree virtual scene with free head movements. However, for seated use of
HMDs such as users sitting on a chair or a couch, physically turning around
360-degree is not possible. Redirection techniques decouple tracked physical
motion and virtual motion, allowing users to explore virtual environments with
more flexibility. In seated situations with only head movements available, the
difference of stimulus might cause the detection thresholds of rotation gains
to differ from that of redirected walking. Therefore we present an experiment
with a two-alternative forced-choice (2AFC) design to compare the thresholds
for seated and standing situations. Results indicate that users are unable to
discriminate rotation gains between 0.89 and 1.28, a smaller range compared to
the standing condition. We further treated head amplification as an interaction
technique and found that a gain of 2.5, though not a hard threshold, was near
the largest gain that users consider applicable. Overall, our work aims to
better understand human perception of rotation gains in seated VR and the
results provide guidance for future design choices of its applications."
2972,"In addition, we would welcome further research into the concept and effects of
homogenising the device infrastructure both in terms of risk and quantifying benefits, which
we think is essential but is outside the scope of our study.","Primarily, we propose their validation within a similar context,
and from there, their extension to theory, as is often the case with qualitative studies, which
can in turn be validated and extended to different contexts (Davison & Martinsons, 2016, p.
247).","Although the concept of
homogenising devices is briefly examined in this paper, the validity of the concept must be
established through further research to determine if additional risks will be introduced by less
variance in IoT devices.",2022-03-08 09:04:48+00:00,Drivers and challenges of internet of things diffusion in smart stores: A field exploration,cs.HC,['cs.HC'],"[arxiv.Result.Author('Michael Roe'), arxiv.Result.Author('Konstantina Spanaki'), arxiv.Result.Author('Athina Ioannou'), arxiv.Result.Author('Efpraxia Zamani'), arxiv.Result.Author('Mihalis Giannakis')]","The digitally disruptive environment has evolved rapidly due to the
introduction of new advancements within the field of smart applications.
Applications of one of the most prominent technologies, Internet of Things
(IoT), often appear in the retail sector, where smart services have transformed
the customer experience holistically. Presented in this paper are the findings
from an exploratory field study in the retail service sector, which drew on the
views of experienced practitioners about the smart store experience and the
associated changes. The paper presents an overview of the drivers of smart
retail service diffusion and the relevant challenges, such as the business
expectations and the heterogeneity of devices. The arising themes indicate that
IoT security is a major challenge for businesses installing IoT devices in
their journey towards smart store transformation. The paper highlights the
importance of a secure data-sharing IoT environment that respects customer
privacy as the smart experience in-store offers data-driven insights and
services. Implications for research and practice are discussed in terms of the
customer experience relevant to the identified challenges."
2973,"Although the concept of
homogenising devices is briefly examined in this paper, the validity of the concept must be
established through further research to determine if additional risks will be introduced by less
variance in IoT devices.","In addition, we would welcome further research into the concept and effects of
homogenising the device infrastructure both in terms of risk and quantifying benefits, which
we think is essential but is outside the scope of our study.","Furthermore, in the present study, security experts from different retail
companies were interviewed regarding the drivers of and security challenges posed by IoT
implementation in the retail industry.",2022-03-08 09:04:48+00:00,Drivers and challenges of internet of things diffusion in smart stores: A field exploration,cs.HC,['cs.HC'],"[arxiv.Result.Author('Michael Roe'), arxiv.Result.Author('Konstantina Spanaki'), arxiv.Result.Author('Athina Ioannou'), arxiv.Result.Author('Efpraxia Zamani'), arxiv.Result.Author('Mihalis Giannakis')]","The digitally disruptive environment has evolved rapidly due to the
introduction of new advancements within the field of smart applications.
Applications of one of the most prominent technologies, Internet of Things
(IoT), often appear in the retail sector, where smart services have transformed
the customer experience holistically. Presented in this paper are the findings
from an exploratory field study in the retail service sector, which drew on the
views of experienced practitioners about the smart store experience and the
associated changes. The paper presents an overview of the drivers of smart
retail service diffusion and the relevant challenges, such as the business
expectations and the heterogeneity of devices. The arising themes indicate that
IoT security is a major challenge for businesses installing IoT devices in
their journey towards smart store transformation. The paper highlights the
importance of a secure data-sharing IoT environment that respects customer
privacy as the smart experience in-store offers data-driven insights and
services. Implications for research and practice are discussed in terms of the
customer experience relevant to the identified challenges."
2974,"Another interesting avenue for further research is exploring what makes a store environment
synonymous with the concept of IoT; how IoT may be implemented together with other
advance technologies, such as blockchain, both for payments and for security purposes and
how these combined technologies would influence customer and employee expectations in
relation to security design and privacy expectations.","Future research should aim to capture the opinions and
perspectives of marketing and customer insights professionals working in the retail industry
using IoT to better understand customer security concerns.","In a world where businesses are expected
to use information and communication technologies ahead of their competitors and be
trendsetters, it would be interesting to see whether and to what extent an equal amount of care
is expected or applied in making this offering secure by design.",2022-03-08 09:04:48+00:00,Drivers and challenges of internet of things diffusion in smart stores: A field exploration,cs.HC,['cs.HC'],"[arxiv.Result.Author('Michael Roe'), arxiv.Result.Author('Konstantina Spanaki'), arxiv.Result.Author('Athina Ioannou'), arxiv.Result.Author('Efpraxia Zamani'), arxiv.Result.Author('Mihalis Giannakis')]","The digitally disruptive environment has evolved rapidly due to the
introduction of new advancements within the field of smart applications.
Applications of one of the most prominent technologies, Internet of Things
(IoT), often appear in the retail sector, where smart services have transformed
the customer experience holistically. Presented in this paper are the findings
from an exploratory field study in the retail service sector, which drew on the
views of experienced practitioners about the smart store experience and the
associated changes. The paper presents an overview of the drivers of smart
retail service diffusion and the relevant challenges, such as the business
expectations and the heterogeneity of devices. The arising themes indicate that
IoT security is a major challenge for businesses installing IoT devices in
their journey towards smart store transformation. The paper highlights the
importance of a secure data-sharing IoT environment that respects customer
privacy as the smart experience in-store offers data-driven insights and
services. Implications for research and practice are discussed in terms of the
customer experience relevant to the identified challenges."
3055,"Therefore, further research on the role of presence (and its sub-dimensions) in VR body
image interventions seems required, as the latest reviews did not address this topic (Turbyne et al., 2021;
Riva et al., 2019; Horne et al., 2020).","Continuous
communication between therapist and patient during weight modiﬁcations might be a crucial element in
clinical settings.","Surprisingly, although participants rated their feeling of virtual body ownership descriptively higher
compared to non-personalized avatars (Waltemate et al., 2018; Wolf et al., 2020), their ratings were lower
than in prior work using personalized and photorealistic avatars (Waltemate et al., 2018).",2022-03-09 21:44:01+00:00,Resize Me! Exploring the User Experience of Embodied Realistic Modulatable Avatars for Body Image Intervention in Virtual Reality,cs.HC,['cs.HC'],"[arxiv.Result.Author('Nina Döllinger'), arxiv.Result.Author('Erik Wolf'), arxiv.Result.Author('David Mal'), arxiv.Result.Author('Stephan Wenninger'), arxiv.Result.Author('Mario Botsch'), arxiv.Result.Author('Marc Erich Latoschik'), arxiv.Result.Author('Carolin Wienrich')]","Obesity is a serious disease that can affect both physical and psychological
well-being. Due to weight stigmatization, many affected individuals suffer from
body image disturbances whereby they perceive their body in a distorted way,
evaluate it negatively, or neglect it. Beyond established interventions such as
mirror exposure, recent advancements aim to complement body image treatments by
the embodiment of visually altered virtual bodies in virtual reality (VR). We
present a high-fidelity prototype of an advanced VR system that allows users to
embody a rapidly generated personalized, photorealistic avatar and to
realistically modulate its body weight in real-time within a carefully designed
virtual environment. In a formative multi-method approach, a total of 12
participants rated the general user experience (UX) of our system during body
scan and VR experience using semi-structured qualitative interviews and
multiple quantitative UX measures. By using body weight modification tasks, we
further compared three different interaction methods for real-time body weight
modification and measured our system's impact on the body image relevant
measures body awareness and body weight perception. From the feedback received,
demonstrating an already solid UX of our overall system and providing
constructive input for further improvement, we derived a set of design
guidelines to guide future development and evaluation processes of systems
supporting body image interventions."
3573,"Moreover, we will identify research trends
           from the current literature, which aims to establish a solid base for stress measure-
           ment and quantiﬁcation and to guide further research.","We seek to identify the eﬀective methods to measure and quantify stress
           and stress-related concepts, which will provide technical support and theoretical
           foundation for stress-related applications.","We expect our results to have
           signiﬁcant implications in research and practice under stress such as ergonomics,
           human-computer interactions, design, learning and training, and so forth.",2022-03-19 21:27:12+00:00,"Mechanism, measurement, and quantification of stress in decision process: a model based systematic-review protocol",cs.HC,"['cs.HC', 'q-bio.QM']","[arxiv.Result.Author('Chang Su'), arxiv.Result.Author('Xiaoyuan Li'), arxiv.Result.Author('Lin Yang'), arxiv.Result.Author('Yong Zeng')]","Every human action begins with decision-making. Stress is a significant
source of biases that can influence human decision-making. In order to
understand the relationship between stress and decision-making, stress
quantification is fundamental. Different methods of measuring and quantifying
stress in decision-making have been described in the literature while an
up-to-date systematic review of the existing methods is lacking. Moreover,
mental stress, mental effort, cognitive workload, and workload are often used
interchangeably but should be distinguished to enable in-depth investigations
of decision-mechanisms. Our objectives are to clarify stress related concepts
and review the measurement, quantification, and application of stress during
decision making activities."
3581,"Especially for researchers, a       types are feasible to categorize visualizations with different back-
comprehensive survey can provide an overview of the community          end data structures based on observable features (such as with or
and inspire further research.","The newly proposed sub-
of under-explored design patterns.",without shared coordinates).,2022-03-20 07:22:48+00:00,Revisiting the Design Patterns of Composite Visualizations,cs.HC,['cs.HC'],"[arxiv.Result.Author('Dazhen Deng'), arxiv.Result.Author('Weiwei Cui'), arxiv.Result.Author('Xiyu Meng'), arxiv.Result.Author('Mengye Xu'), arxiv.Result.Author('Yu Liao'), arxiv.Result.Author('Haidong Zhang'), arxiv.Result.Author('Yingcai Wu')]","Composite visualization is a popular design strategy that represents complex
datasets by integrating multiple visualizations in a meaningful and aesthetic
layout, such as juxtaposition, overlay, and nesting. With this strategy,
numerous novel designs have been proposed in visualization publications to
accomplish various visual analytic tasks. These well-crafted composite
visualizations have formed a valuable collection for designers and researchers
to address real-world problems and inspire new research topics and designs.
However, there is a lack of understanding of design patterns of composite
visualization, thus failing to provide holistic design space and concrete
examples for practical use. In this paper, we opted to revisit the composite
visualizations in VIS publications and answered what and how visualizations of
different types are composed together. To achieve this, we first constructed a
corpus of composite visualizations from IEEE VIS publications and decomposed
them into a series of basic visualization types (e.g., bar chart, map, and
matrix). With this corpus, we studied the spatial (e.g., separated or
overlaying) and semantic relationships (e.g., with same types or shared axis)
between visualizations and proposed a taxonomy consisting of eight different
design patterns (e.g., repeated, stacked, accompanied, and nested).
Furthermore, we analyzed and discussed common practices of composite
visualizations, such as the distribution of different patterns and correlations
between visualization types. From the analysis and examples, we obtained
insights into different design patterns on the utilities, advantages, and
disadvantages. Finally, we developed an interactive system to help
visualization developers and researchers conveniently explore collected
examples and design patterns."
3582,"Sedig and
overview of the community and inspire further research.","Especially        primitives, such as grouping, nesting, and connecting, and
for researchers, a comprehensive survey can provide an             scaling patterns of primitives, such as repeating.","For        Parsons [16] proposed a language that characterizes visual
example, a widely used design pattern might request further        design patterns and the manners to fuse the patterns, such
research of empirical studies to validate its efﬁciency.",2022-03-20 07:22:48+00:00,Revisiting the Design Patterns of Composite Visualizations,cs.HC,['cs.HC'],"[arxiv.Result.Author('Dazhen Deng'), arxiv.Result.Author('Weiwei Cui'), arxiv.Result.Author('Xiyu Meng'), arxiv.Result.Author('Mengye Xu'), arxiv.Result.Author('Yu Liao'), arxiv.Result.Author('Haidong Zhang'), arxiv.Result.Author('Yingcai Wu')]","Composite visualization is a popular design strategy that represents complex
datasets by integrating multiple visualizations in a meaningful and aesthetic
layout, such as juxtaposition, overlay, and nesting. With this strategy,
numerous novel designs have been proposed in visualization publications to
accomplish various visual analytic tasks. These well-crafted composite
visualizations have formed a valuable collection for designers and researchers
to address real-world problems and inspire new research topics and designs.
However, there is a lack of understanding of design patterns of composite
visualization, thus failing to provide holistic design space and concrete
examples for practical use. In this paper, we opted to revisit the composite
visualizations in VIS publications and answered what and how visualizations of
different types are composed together. To achieve this, we first constructed a
corpus of composite visualizations from IEEE VIS publications and decomposed
them into a series of basic visualization types (e.g., bar chart, map, and
matrix). With this corpus, we studied the spatial (e.g., separated or
overlaying) and semantic relationships (e.g., with same types or shared axis)
between visualizations and proposed a taxonomy consisting of eight different
design patterns (e.g., repeated, stacked, accompanied, and nested).
Furthermore, we analyzed and discussed common practices of composite
visualizations, such as the distribution of different patterns and correlations
between visualization types. From the analysis and examples, we obtained
insights into different design patterns on the utilities, advantages, and
disadvantages. Finally, we developed an interactive system to help
visualization developers and researchers conveniently explore collected
examples and design patterns."
3732,We discuss this as further research.,"• P(B∩A): Probability of a win given that Agent B is on

                                                                           the team we are examining, but Agent A is not

                                                                           • n:  Number of team members whose relation-

                                                                           ship we are testing

                                                                           • Target Success Rate > 50%

1 We acknowledge that simply because two dyads are effective, there is no
reason to suspect that the four-man team assembled from their composition
would necessarily be effective.",4.2.,2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3733,"We offer the Har-              One final area of interest for further study is the addi-
mony Index as a functional building block for the building          tion of the specializations aspect of the various agents.","Future Opportunities
these structures in a way that will be useful and iterable in
order to improve the structures over time.","Each
and optimization of teams by working out the top level rela-        agent in the source game is equipped with skills and abilities
tionships of the team components.",2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3734,"Some have direct impact abilities, some reduce
   However, the Harmony Index is only a single piece of that        the aspects of opposing agents, some interact directly with
puzzle and a starting point from which further research can         smaller objectives, or may give nearby agents an increase in
be performed.","that give it specialized skills in various objectives to the
                                                                    game itself.",In order to move forward and improve the              their own abilities.,2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3735,"Damacharla et al., 2018: Damacharla, Praveen, Ahmad Y. Javaid,
   Therefore, we suggest further study is warranted on the          Jennie J. Gallimore, and Vijay K. Devabhaktuni.",gence Research 49 (2014): 207-240.,"""Common met-
integration of concepts such as the Prisoner’s Dilemma,             rics to benchmark human-machine teams (HMT): A review.""",2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3736,We discuss this as further research.,"• P(B∩A): Probability of a win given that Agent B is on

                                                                           the team we are examining, but Agent A is not

                                                                           • n:  Number of team members whose relation-

                                                                           ship we are testing

                                                                           • Target Success Rate > 50%

1 We acknowledge that simply because two dyads are effective, there is no
reason to suspect that the four-man team assembled from their composition
would necessarily be effective.",4.2.,2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3737,"We offer the Har-              One final area of interest for further study is the addi-
mony Index as a functional building block for the building          tion of the specializations aspect of the various agents.","Future Opportunities
these structures in a way that will be useful and iterable in
order to improve the structures over time.","Each
and optimization of teams by working out the top level rela-        agent in the source game is equipped with skills and abilities
tionships of the team components.",2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3738,"Some have direct impact abilities, some reduce
   However, the Harmony Index is only a single piece of that        the aspects of opposing agents, some interact directly with
puzzle and a starting point from which further research can         smaller objectives, or may give nearby agents an increase in
be performed.","that give it specialized skills in various objectives to the
                                                                    game itself.",In order to move forward and improve the              their own abilities.,2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
3739,"Damacharla et al., 2018: Damacharla, Praveen, Ahmad Y. Javaid,
   Therefore, we suggest further study is warranted on the          Jennie J. Gallimore, and Vijay K. Devabhaktuni.",gence Research 49 (2014): 207-240.,"""Common met-
integration of concepts such as the Prisoner’s Dilemma,             rics to benchmark human-machine teams (HMT): A review.""",2022-03-23 06:22:50+00:00,The Harmony Index: a Utilitarian Metric for Measuring Effectiveness in Mixed-Skill Teams,cs.HC,['cs.HC'],"[arxiv.Result.Author('Darryl Roman'), arxiv.Result.Author('Noah Ari'), arxiv.Result.Author('Johnathan Mell')]","As teamwork becomes ever-more important in a new age of remote work, it is
critical to develop metrics to quantitatively evaluate how effective teams are.
This is especially true with mixed-modality teams, such as those that include a
human and an agent or human and robot. We propose a novel utilitarian metric,
the Harmony Index, which quantifies the effectiveness of team members by
classifying them into four sub-types based on the result of their teaming on
overall effectiveness. This index is evaluated using a real-world dataset of
over 1 million interactions, and potential future uses of this index are
explored in the realm of team science."
4018,"Nonetheless, further research is needed            for abstract ideas and principles at ﬁrst, before progressively
to identify e ective designs of onboarding methods and to            abstracting them.","Concreteness fading is a
Yalçin [71] developed an in-situ help for the visualization          pedagogical method where concrete examples are provided
tool Keshif [72].","Recently, Bishop et al.",2022-03-29 10:33:08+00:00,Comparative Evaluations of Visualization Onboarding Methods,cs.HC,['cs.HC'],"[arxiv.Result.Author('Christina Stoiber'), arxiv.Result.Author('Conny Walchshofer'), arxiv.Result.Author('Margit Pohl'), arxiv.Result.Author('Benjamin Potzmann'), arxiv.Result.Author('Florian Grassinger'), arxiv.Result.Author('Holger Stitz'), arxiv.Result.Author('Marc Streit'), arxiv.Result.Author('Wolfgang Aigner')]","Comprehending and exploring large and complex data is becoming increasingly
important for users in a wide range of application domains. Still, non-experts
in visual data analysis often have problems with correctly reading and
interpreting information from visualizations that are new to them. To support
novices in learning how to use new digital technologies, the concept of
onboarding has been successfully applied in other fields and first approaches
also exist in the visualization domain. However, empirical evidence on the
effectiveness of such approaches is scarce. Therefore, we conducted 3 studies:
1) Firstly, we explored the effect of vis onboarding, using an interactive
step-by-step guide, on user performance for four increasingly complex
visualization techniques. We performed a between-subject experiment with 596
participants in total. The results showed that there are no significant
differences between the answer correctness of the questions with and without
onboarding. Furthermore, participants commented that for highly familiar
visualization types no onboarding is needed. 2) Second, we performed another
study with MTurk workers to assess if there is a difference in user
performances on different onboarding types: step-by-step, scrollytelling
tutorial, and video tutorial. The study revealed that the video tutorial was
ranked as the most positive on average, based on sentiment analysis, followed
by the scrollytelling tutorial and the interactive step-by-step guide. 3) For
our third study with students, we gathered data on users' experience in using
an in-situ scrollytelling for the VA tool. The results showed that they
preferred scrollytelling over the tutorial integrated into the landing page. In
summary, the in-situ scrollytelling approach works well for visualization
onboarding and a video tutorial can help to introduce interaction techniques."
4019,"We conducted a further study with MTurk workers to
investigate the e ect on user performance for four di erent         [4] Ant Design, 2022.",Accessed: 2022-01-31.,Ant Design.,2022-03-29 10:33:08+00:00,Comparative Evaluations of Visualization Onboarding Methods,cs.HC,['cs.HC'],"[arxiv.Result.Author('Christina Stoiber'), arxiv.Result.Author('Conny Walchshofer'), arxiv.Result.Author('Margit Pohl'), arxiv.Result.Author('Benjamin Potzmann'), arxiv.Result.Author('Florian Grassinger'), arxiv.Result.Author('Holger Stitz'), arxiv.Result.Author('Marc Streit'), arxiv.Result.Author('Wolfgang Aigner')]","Comprehending and exploring large and complex data is becoming increasingly
important for users in a wide range of application domains. Still, non-experts
in visual data analysis often have problems with correctly reading and
interpreting information from visualizations that are new to them. To support
novices in learning how to use new digital technologies, the concept of
onboarding has been successfully applied in other fields and first approaches
also exist in the visualization domain. However, empirical evidence on the
effectiveness of such approaches is scarce. Therefore, we conducted 3 studies:
1) Firstly, we explored the effect of vis onboarding, using an interactive
step-by-step guide, on user performance for four increasingly complex
visualization techniques. We performed a between-subject experiment with 596
participants in total. The results showed that there are no significant
differences between the answer correctness of the questions with and without
onboarding. Furthermore, participants commented that for highly familiar
visualization types no onboarding is needed. 2) Second, we performed another
study with MTurk workers to assess if there is a difference in user
performances on different onboarding types: step-by-step, scrollytelling
tutorial, and video tutorial. The study revealed that the video tutorial was
ranked as the most positive on average, based on sentiment analysis, followed
by the scrollytelling tutorial and the interactive step-by-step guide. 3) For
our third study with students, we gathered data on users' experience in using
an in-situ scrollytelling for the VA tool. The results showed that they
preferred scrollytelling over the tutorial integrated into the landing page. In
summary, the in-situ scrollytelling approach works well for visualization
onboarding and a video tutorial can help to introduce interaction techniques."
4020,"Nonetheless, further research is needed          of a scrollytelling onboarding by embedding it into a VA tool
 to identify effective designs of onboarding methods and to          (see study 3).","As a promising onboarding approach
  Yalçin [71] developed an in-situ help for the visualization        resulting from study 2, we further examined the applicability
  tool Keshif [72].",understand users’ behavior while using onboarding methods.,2022-03-29 10:33:08+00:00,Comparative Evaluations of Visualization Onboarding Methods,cs.HC,['cs.HC'],"[arxiv.Result.Author('Christina Stoiber'), arxiv.Result.Author('Conny Walchshofer'), arxiv.Result.Author('Margit Pohl'), arxiv.Result.Author('Benjamin Potzmann'), arxiv.Result.Author('Florian Grassinger'), arxiv.Result.Author('Holger Stitz'), arxiv.Result.Author('Marc Streit'), arxiv.Result.Author('Wolfgang Aigner')]","Comprehending and exploring large and complex data is becoming increasingly
important for users in a wide range of application domains. Still, non-experts
in visual data analysis often have problems with correctly reading and
interpreting information from visualizations that are new to them. To support
novices in learning how to use new digital technologies, the concept of
onboarding has been successfully applied in other fields and first approaches
also exist in the visualization domain. However, empirical evidence on the
effectiveness of such approaches is scarce. Therefore, we conducted 3 studies:
1) Firstly, we explored the effect of vis onboarding, using an interactive
step-by-step guide, on user performance for four increasingly complex
visualization techniques. We performed a between-subject experiment with 596
participants in total. The results showed that there are no significant
differences between the answer correctness of the questions with and without
onboarding. Furthermore, participants commented that for highly familiar
visualization types no onboarding is needed. 2) Second, we performed another
study with MTurk workers to assess if there is a difference in user
performances on different onboarding types: step-by-step, scrollytelling
tutorial, and video tutorial. The study revealed that the video tutorial was
ranked as the most positive on average, based on sentiment analysis, followed
by the scrollytelling tutorial and the interactive step-by-step guide. 3) For
our third study with students, we gathered data on users' experience in using
an in-situ scrollytelling for the VA tool. The results showed that they
preferred scrollytelling over the tutorial integrated into the landing page. In
summary, the in-situ scrollytelling approach works well for visualization
onboarding and a video tutorial can help to introduce interaction techniques."
4021,"We conducted a further study with MTurk workers to
    Participants who used MTurk worked fairly briefly and        investigate the effect on user performance for four different
got a visualization with reduced interaction possibilities.",engaging more with the onboarding concept.,"The  onboarding types (step-by-step, scrollytelling, video tutorial,
computer science students in study 3 worked for a longer         and in-situ scrollytelling in Netflower) in study 2 and 3.",2022-03-29 10:33:08+00:00,Comparative Evaluations of Visualization Onboarding Methods,cs.HC,['cs.HC'],"[arxiv.Result.Author('Christina Stoiber'), arxiv.Result.Author('Conny Walchshofer'), arxiv.Result.Author('Margit Pohl'), arxiv.Result.Author('Benjamin Potzmann'), arxiv.Result.Author('Florian Grassinger'), arxiv.Result.Author('Holger Stitz'), arxiv.Result.Author('Marc Streit'), arxiv.Result.Author('Wolfgang Aigner')]","Comprehending and exploring large and complex data is becoming increasingly
important for users in a wide range of application domains. Still, non-experts
in visual data analysis often have problems with correctly reading and
interpreting information from visualizations that are new to them. To support
novices in learning how to use new digital technologies, the concept of
onboarding has been successfully applied in other fields and first approaches
also exist in the visualization domain. However, empirical evidence on the
effectiveness of such approaches is scarce. Therefore, we conducted 3 studies:
1) Firstly, we explored the effect of vis onboarding, using an interactive
step-by-step guide, on user performance for four increasingly complex
visualization techniques. We performed a between-subject experiment with 596
participants in total. The results showed that there are no significant
differences between the answer correctness of the questions with and without
onboarding. Furthermore, participants commented that for highly familiar
visualization types no onboarding is needed. 2) Second, we performed another
study with MTurk workers to assess if there is a difference in user
performances on different onboarding types: step-by-step, scrollytelling
tutorial, and video tutorial. The study revealed that the video tutorial was
ranked as the most positive on average, based on sentiment analysis, followed
by the scrollytelling tutorial and the interactive step-by-step guide. 3) For
our third study with students, we gathered data on users' experience in using
an in-situ scrollytelling for the VA tool. The results showed that they
preferred scrollytelling over the tutorial integrated into the landing page. In
summary, the in-situ scrollytelling approach works well for visualization
onboarding and a video tutorial can help to introduce interaction techniques."
4038,"However, the digital transformations
of classrooms reflect an important and critical step when developing VR environments for
learning purposes and require further research.","While VR technology has a long history in the education domain [207, 208], the current
availability of consumer-grade head-mounted displays (HMDs) allows for the creation of im-
mersive experiences at a reasonable cost, making it possible to employ immersive personalized
VR experiences in classrooms in the near future [209].","A unique opportunity to understand the
gaze-based behavior, and consequently, attention distribution of learners in such VR settings
is provided through the analysis of the eye movement of learners [210].",2022-03-29 16:09:37+00:00,Towards Everyday Virtual Reality through Eye Tracking,cs.HC,"['cs.HC', 'cs.AI']",[arxiv.Result.Author('Efe Bozkir')],"With developments in computer graphics, hardware technology, perception
engineering, and human-computer interaction, virtual reality and virtual
environments are becoming more integrated into our daily lives. Head-mounted
displays, however, are still not used as frequently as other mobile devices
such as smart phones and watches. With increased usage of this technology and
the acclimation of humans to virtual application scenarios, it is possible that
in the near future an everyday virtual reality paradigm will be realized. When
considering the marriage of everyday virtual reality and head-mounted displays,
eye tracking is an emerging technology that helps to assess human behaviors in
a real time and non-intrusive way. Still, multiple aspects need to be
researched before these technologies become widely available in daily life.
Firstly, attention and cognition models in everyday scenarios should be
thoroughly understood. Secondly, as eyes are related to visual biometrics,
privacy preserving methodologies are necessary. Lastly, instead of studies or
applications utilizing limited human participants with relatively homogeneous
characteristics, protocols and use-cases for making such technology more
accessible should be essential. In this work, taking the aforementioned points
into account, a significant scientific push towards everyday virtual reality
has been completed with three main research contributions."
4039,"Having reasonably higher attention on
peer-learners on these conditions also indicates that VR can present an opportunity to create
digital environments to further study students’ self-concept.","The extreme conditions may represent either
more or less capable groups of peer-learners in the learning environment and participants may
have a higher self-concept when surrounded by a less capable group and the other way around,
which is related to the Big-fish-little-pond effect [259].","On the other hand, intermediate
hand-raising conditions may help students to focus more on learning related objects in the
classroom instead of peer-learners such as lecture content or instructor as experimentally
indicated.",2022-03-29 16:09:37+00:00,Towards Everyday Virtual Reality through Eye Tracking,cs.HC,"['cs.HC', 'cs.AI']",[arxiv.Result.Author('Efe Bozkir')],"With developments in computer graphics, hardware technology, perception
engineering, and human-computer interaction, virtual reality and virtual
environments are becoming more integrated into our daily lives. Head-mounted
displays, however, are still not used as frequently as other mobile devices
such as smart phones and watches. With increased usage of this technology and
the acclimation of humans to virtual application scenarios, it is possible that
in the near future an everyday virtual reality paradigm will be realized. When
considering the marriage of everyday virtual reality and head-mounted displays,
eye tracking is an emerging technology that helps to assess human behaviors in
a real time and non-intrusive way. Still, multiple aspects need to be
researched before these technologies become widely available in daily life.
Firstly, attention and cognition models in everyday scenarios should be
thoroughly understood. Secondly, as eyes are related to visual biometrics,
privacy preserving methodologies are necessary. Lastly, instead of studies or
applications utilizing limited human participants with relatively homogeneous
characteristics, protocols and use-cases for making such technology more
accessible should be essential. In this work, taking the aforementioned points
into account, a significant scientific push towards everyday virtual reality
has been completed with three main research contributions."
4233,"1083–1096, Nov. 2009.
reported improvements in performance, future XR studies
would benefit from further research to establish the specific      [6]  P. Milgram and F. Kishino, “A Taxonomy of Mixed Reality
aspects of interventions that are most effective in generating
transferable skills.","6, pp.","Furthermore, efforts to understand how             Visual Displays Using Stereoscopic Video,” IEICE Trans.",2022-04-01 23:41:54+00:00,Attention-Based Applications in Extended Reality to Support Autistic Users: A Systematic Review,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Katherine Wang'), arxiv.Result.Author('Simon Julier'), arxiv.Result.Author('Youngjun Cho')]","With the rising prevalence of autism diagnoses, it is essential for research
to understand how to leverage technology to support the diverse nature of
autistic traits. While traditional interventions focused on technology for
medical cure and rehabilitation, recent research aims to understand how
technology can accommodate each unique situation in an efficient and engaging
way. Extended reality (XR) technology has been shown to be effective in
improving attention in autistic users given that it is more engaging and
motivating than other traditional mediums. Here, we conducted a systematic
review of 59 research articles that explored the role of attention in XR
interventions for autistic users. We systematically analyzed demographics,
study design and findings, including autism screening and attention measurement
methods. Furthermore, given methodological inconsistencies in the literature,
we systematically synthesize methods and protocols including screening tools,
physiological and behavioral cues of autism and XR tasks. While there is
substantial evidence for the effectiveness of using XR in attention-based
interventions for autism to support autistic traits, we have identified three
principal research gaps that provide promising research directions to examine
how autistic populations interact with XR. First, our findings highlight the
disproportionate geographic locations of autism studies and underrepresentation
of autistic adults, evidence of gender disparity, and presence of individuals
diagnosed with co-occurring conditions across studies. Second, many studies
used an assortment of standardized and novel tasks and self-report assessments
with limited tested reliability. Lastly, the research lacks evidence of
performance maintenance and transferability."
4400,"Our study did therefore not deliver conclusive answers, but created questions for further research,
especially on the gender issue.","However, we found surprising differences in strategy by the
participants’ gender.","2 RELATED WORK

There is a growing body of research on how to detect emotion in speech.",2022-04-05 13:45:34+00:00,How Should Voice Assistants Deal With Users' Emotions?,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yong Ma'), arxiv.Result.Author('Heiko Drewes'), arxiv.Result.Author('Andreas Butz')]","There is a growing body of research in HCI on detecting the users' emotions.
Once it is possible to detect users' emotions reliably, the next question is
how an emotion-aware interface should react to the detected emotion. In a first
step, we tried to find out how humans deal with the negative emotions of an
avatar. The hope behind this approach was to identify human strategies, which
we can then mimic in an emotion-aware voice assistant. We present a user study
in which participants were confronted with an angry, sad, or frightened avatar.
Their task was to make the avatar happy by talking to it. We recorded the voice
signal and analyzed it. The results show that users predominantly reacted with
neutral emotion. However, we also found gender differences, which opens a range
of questions."
4543,"Realistic func-
                                                                        tionality generation could be a next step, through further study
   Convergence of few-shot/fine-tune trained text models (Fig-          into generative interfaces [17, 99], generalization of server-less
ure 6): We investigate the accuracy gains from fine-tuning pre-         app functionality (e.g.",perceived functionality change).,"learning from RICO dataset), program in-
trained text models as a function of user numbers and annotated         duction/synthesis from GUI [6], and context-aware screen state
sentence contributions.",2022-04-07 20:50:12+00:00,GreaseVision: Rewriting the Rules of the Interface,cs.HC,"['cs.HC', 'cs.LG']","[arxiv.Result.Author('Siddhartha Datta'), arxiv.Result.Author('Konrad Kollnig'), arxiv.Result.Author('Nigel Shadbolt')]","Digital harms can manifest across any interface. Key problems in addressing
these harms include the high individuality of harms and the fast-changing
nature of digital systems. As a result, we still lack a systematic approach to
study harms and produce interventions for end-users. We put forward
GreaseVision, a new framework that enables end-users to collaboratively develop
interventions against harms in software using a no-code approach and recent
advances in few-shot machine learning. The contribution of the framework and
tool allow individual end-users to study their usage history and create
personalized interventions. Our contribution also enables researchers to study
the distribution of harms and interventions at scale."
4569,"This is an
important result, because it encourages further research into the use of privacy risk communication
formats to transparently inform individuals about possible risks when sharing their data.",[65].,Our results also support the insights by Bullek et al.,2022-04-08 13:30:07+00:00,"""Am I Private and If So, how Many?"" -- Using Risk Communication Formats for Making Differential Privacy Understandable",cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Daniel Franzen'), arxiv.Result.Author('Saskia Nuñez von Voigt'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Florian Tschorsch'), arxiv.Result.Author('Claudia Müller-Birn')]","Mobility data is essential for cities and communities to identify areas for
necessary improvement. Data collected by mobility providers already contains
all the information necessary, but privacy of the individuals needs to be
preserved. Differential privacy (DP) defines a mathematical property which
guarantees that certain limits of privacy are preserved while sharing such
data, but its functionality and privacy protection are difficult to explain to
laypeople. In this paper, we adapt risk communication formats in conjunction
with a model for the privacy risks of DP. The result are privacy notifications
which explain the risk to an individual's privacy when using DP, rather than
DP's functionality. We evaluate these novel privacy communication formats in a
crowdsourced study. We find that they perform similarly to the best performing
DP communications used currently in terms of objective understanding, but did
not make our participants as confident in their understanding. We also
discovered an influence, similar to the Dunning-Kruger effect, of the
statistical numeracy on the effectiveness of some of our privacy communication
formats and the DP communication format used currently. These results generate
hypotheses in multiple directions, for example, toward the use of risk
visualization to improve the understandability of our formats or toward
adaptive user interfaces which tailor the risk communication to the
characteristics of the reader."
4570,"Since we could neither reject nor confirm the effect between the condition
and the privacy aptitude in our study, further research is needed to investigate this relationship.","Similar work has been done under the name
of nudges (e.g., [25]).","Concerning objective understanding, we found that participants with low privacy aptitude
performed less well with the condition FreqPure.",2022-04-08 13:30:07+00:00,"""Am I Private and If So, how Many?"" -- Using Risk Communication Formats for Making Differential Privacy Understandable",cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Daniel Franzen'), arxiv.Result.Author('Saskia Nuñez von Voigt'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Florian Tschorsch'), arxiv.Result.Author('Claudia Müller-Birn')]","Mobility data is essential for cities and communities to identify areas for
necessary improvement. Data collected by mobility providers already contains
all the information necessary, but privacy of the individuals needs to be
preserved. Differential privacy (DP) defines a mathematical property which
guarantees that certain limits of privacy are preserved while sharing such
data, but its functionality and privacy protection are difficult to explain to
laypeople. In this paper, we adapt risk communication formats in conjunction
with a model for the privacy risks of DP. The result are privacy notifications
which explain the risk to an individual's privacy when using DP, rather than
DP's functionality. We evaluate these novel privacy communication formats in a
crowdsourced study. We find that they perform similarly to the best performing
DP communications used currently in terms of objective understanding, but did
not make our participants as confident in their understanding. We also
discovered an influence, similar to the Dunning-Kruger effect, of the
statistical numeracy on the effectiveness of some of our privacy communication
formats and the DP communication format used currently. These results generate
hypotheses in multiple directions, for example, toward the use of risk
visualization to improve the understandability of our formats or toward
adaptive user interfaces which tailor the risk communication to the
characteristics of the reader."
4571,"This is an important
                                                                            result, because it encourages further research into the use of quanti-
                                                                            tative privacy risk notifications to transparently inform individuals
                                                                            about possible privacy risks when sharing their data.",[80].,Our results also support the insights by Bullek et al.,2022-04-08 13:30:07+00:00,"""Am I Private and If So, how Many?"" -- Using Risk Communication Formats for Making Differential Privacy Understandable",cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Daniel Franzen'), arxiv.Result.Author('Saskia Nuñez von Voigt'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Florian Tschorsch'), arxiv.Result.Author('Claudia Müller-Birn')]","Mobility data is essential for cities and communities to identify areas for
necessary improvement. Data collected by mobility providers already contains
all the information necessary, but privacy of the individuals needs to be
preserved. Differential privacy (DP) defines a mathematical property which
guarantees that certain limits of privacy are preserved while sharing such
data, but its functionality and privacy protection are difficult to explain to
laypeople. In this paper, we adapt risk communication formats in conjunction
with a model for the privacy risks of DP. The result are privacy notifications
which explain the risk to an individual's privacy when using DP, rather than
DP's functionality. We evaluate these novel privacy communication formats in a
crowdsourced study. We find that they perform similarly to the best performing
DP communications used currently in terms of objective understanding, but did
not make our participants as confident in their understanding. We also
discovered an influence, similar to the Dunning-Kruger effect, of the
statistical numeracy on the effectiveness of some of our privacy communication
formats and the DP communication format used currently. These results generate
hypotheses in multiple directions, for example, toward the use of risk
visualization to improve the understandability of our formats or toward
adaptive user interfaces which tailor the risk communication to the
characteristics of the reader."
4572,"Furthermore, one can see that a majority of the outliers                   reject nor confirm the effect between the condition and the privacy
achieved the highest numeracy score of 4, which indicates that the                aptitude in our study, further research might shed more light on
                                                                                  this relationship.","Since we could neither
sound.","22 https://statistikguru.de/spss/einfaktorielle-anova/voraussetzungen-5.html

                                                                              18
         Table 4: Risk Communication Formats in Medical Research  Format                   Description                           Examples                                Possible Variations                           Recommendations / Comments                        Am I Private and If So, How Many?",2022-04-08 13:30:07+00:00,"""Am I Private and If So, how Many?"" -- Using Risk Communication Formats for Making Differential Privacy Understandable",cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Daniel Franzen'), arxiv.Result.Author('Saskia Nuñez von Voigt'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Florian Tschorsch'), arxiv.Result.Author('Claudia Müller-Birn')]","Mobility data is essential for cities and communities to identify areas for
necessary improvement. Data collected by mobility providers already contains
all the information necessary, but privacy of the individuals needs to be
preserved. Differential privacy (DP) defines a mathematical property which
guarantees that certain limits of privacy are preserved while sharing such
data, but its functionality and privacy protection are difficult to explain to
laypeople. In this paper, we adapt risk communication formats in conjunction
with a model for the privacy risks of DP. The result are privacy notifications
which explain the risk to an individual's privacy when using DP, rather than
DP's functionality. We evaluate these novel privacy communication formats in a
crowdsourced study. We find that they perform similarly to the best performing
DP communications used currently in terms of objective understanding, but did
not make our participants as confident in their understanding. We also
discovered an influence, similar to the Dunning-Kruger effect, of the
statistical numeracy on the effectiveness of some of our privacy communication
formats and the DP communication format used currently. These results generate
hypotheses in multiple directions, for example, toward the use of risk
visualization to improve the understandability of our formats or toward
adaptive user interfaces which tailor the risk communication to the
characteristics of the reader."
4622,6] will require further research.,"Better understanding
this apparent contradiction between experts’ stated commitments to comprehensive review and the
realities of inevitable tradeoffs between recall and time [105, Fig.","Nevertheless, future researchers might resolve the contradiction with improved user interfaces.",2022-04-10 14:21:24+00:00,ClioQuery: Interactive Query-Oriented Text Analytics for Comprehensive Investigation of Historical News Archives,cs.HC,"['cs.HC', 'cs.DL']","[arxiv.Result.Author('Abram Handler'), arxiv.Result.Author('Narges Mahyar'), arxiv.Result.Author(""Brendan O'Connor"")]","Historians and archivists often find and analyze the occurrences of query
words in newspaper archives, to help answer fundamental questions about
society. But much work in text analytics focuses on helping people investigate
other textual units, such as events, clusters, ranked documents, entity
relationships, or thematic hierarchies. Informed by a study into the needs of
historians and archivists, we thus propose ClioQuery, a text analytics system
uniquely organized around the analysis of query words in context. ClioQuery
applies text simplification techniques from natural language processing to help
historians quickly and comprehensively gather and analyze all occurrences of a
query word across an archive. It also pairs these new NLP methods with more
traditional features like linked views and in-text highlighting to help
engender trust in summarization techniques. We evaluate ClioQuery with two
separate user studies, in which historians explain how ClioQuery's novel text
simplification features can help facilitate historical research. We also
evaluate with a separate quantitative comparison study, which shows that
ClioQuery helps crowdworkers find and remember historical information. Such
results suggest possible new directions for text analytics in other
query-oriented settings."
4645,"We provide the source code of the application, the collected data, and the analysis scripts to foster further research in
this area13.","Thus, we believe that much like other fields of
human-related research, such as Psychology, medicine, and sport sciences, HCI studies should consider placebo-control.","ACKNOWLEDGMENTS

This publication has been partially funded by the research initiative “Instant Teaming between Humans and Production
Systems” co-financed by tax funds of the Saxony State Ministry of Science and Art (SMWK3-7304/35/3-2021/4819) on
the basis of the budget passed by the deputies of the Saxony state parliament.",2022-04-11 08:19:33+00:00,The Placebo Effect of Artificial Intelligence in Human-Computer Interaction,cs.HC,['cs.HC'],"[arxiv.Result.Author('Thomas Kosch'), arxiv.Result.Author('Robin Welsch'), arxiv.Result.Author('Lewis Chuang'), arxiv.Result.Author('Albrecht Schmidt')]","In medicine, patients can obtain real benefits from a sham treatment. These
benefits are known as the placebo effect. We report two experiments (Experiment
I: N=369; Experiment II: N=100) demonstrating a placebo effect in adaptive
interfaces. Participants were asked to solve word puzzles while being supported
by no system or an adaptive AI interface. All participants experienced the same
word puzzle difficulty and had no support from an AI throughout the
experiments. Our results showed that the belief of receiving adaptive AI
support increases expectations regarding the participant's own task
performance, sustained after interaction. These expectations were positively
correlated to performance, as indicated by the number of solved word puzzles.
We integrate our findings into technological acceptance theories and discuss
implications for the future assessment of AI-based user interfaces and novel
technologies. We argue that system descriptions can elicit placebo effects
through user expectations biasing the results of user-centered studies."
4758,"architecture could be the primary enabling mechanism for            (v) Presenting a study of the major open issues for
decentralized pervasive healthcare applications, considering             application approaches in the IoT context, as well as the
the prevailing availability of distant wireless healthcare               future trends to provide the scope of further research for
platforms and the rising topic of electronic patientcare datasets        smart applications.",The IoT communication                    hospitals as well as smart home environments.,"[18], [19].",2022-04-12 16:27:05+00:00,"Internet of Things Device Capabilities, Architectures, Protocols, and Smart Applications in Healthcare Domain: A Review",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Md. Milon Islam'), arxiv.Result.Author('Sheikh Nooruddin'), arxiv.Result.Author('Fakhri Karray'), arxiv.Result.Author('Ghulam Muhammad')]","Nowadays, the Internet has spread to practically every country around the
world and is having unprecedented effects on people's lives. The Internet of
Things (IoT) is getting more popular and has a high level of interest in both
practitioners and academicians in the age of wireless communication due to its
diverse applications. The IoT is a technology that enables everyday things to
become savvier, everyday computation towards becoming intellectual, and
everyday communication to become a little more insightful. In this paper, the
most common and popular IoT device capabilities, architectures, and protocols
are demonstrated in brief to provide a clear overview of the IoT technology to
the researchers in this area. The common IoT device capabilities including
hardware (Raspberry Pi, Arduino, and ESP8266) and software (operating systems,
and built-in tools) platforms are described in detail. The widely used
architectures that have been recently evolved and used are the three-layer
architecture, SOA-based architecture, and middleware-based architecture. The
popular protocols for IoT are demonstrated which include CoAP, MQTT, XMPP,
AMQP, DDS, LoWPAN, BLE, and Zigbee that are frequently utilized to develop
smart IoT applications. Additionally, this research provides an in-depth
overview of the potential healthcare applications based on IoT technologies in
the context of addressing various healthcare concerns. Finally, this paper
summarizes state-of-the-art knowledge, highlights open issues and shortcomings,
and provides recommendations for further studies which would be quite
beneficial to anyone with a desire to work in this field and make breakthroughs
to get expertise in this area."
4789,"These are both
areas for further research.",We have also investigated approaches to query-time reasoning.,"In this paper we have discussed three approaches which either claim to offer improved RDF
reification or offer alternative modelling approaches:
1.",2022-04-13 10:05:34+00:00,Edge Labelled Graphs and Property Graphs; a comparison from the user perspective,cs.HC,['cs.HC'],"[arxiv.Result.Author('Paul Warren'), arxiv.Result.Author('Paul Mulholland')]","This study compares participant acceptance of the property graph and
edge-labelled graph paradigms, as represented by Cypher and the proposed
extensions to the W3C standards, RDF* and SPARQL*.
  In general, modelling preferences are consistent across the two paradigms.
When presented with location information, participants preferred to create
nodes to represent cities, rather than use metadata; although the preference
was less marked for Cypher. In Cypher, participants showed little difference in
preference between representing dates or population size as nodes. In RDF*,
this choice was not necessary since both could be represented as literals.
However, there was a significant preference for using the date as metadata to
describe a triple containing population size, rather than vice versa. There was
no significant difference overall in accuracy of interpretation of queries in
the two paradigms; although in one specific case, the use of a reverse arrow in
Cypher was interpreted significantly more accurately than the ^ symbol in
SPARQL. Based on our results and on the comments of participants, we make some
recommendations for modellers.
  Techniques for reifing RDF have attracted a great deal of research. Recently,
a hybrid approach, employing some of the features of property graphs, has
claimed to offer an improved technique for RDF reification. Query-time
reasoning is also a requirement which has prompted a number of proposed
extensions to SPARQL and which is only possible to a limited extent in the
property graph paradigm. Another recent development, the hypergraph paradigm
enables more powerful query-time reasoning. There is a need for more research
into the user acceptance of these various more powerful approaches to modelling
and querying. Such research should take account of complex modelling
situations."
4850,"CCS CONCEPTS                                                                 further research has observed that these measurements may not
                                                                                                                     be as inclusive and may be gender-biased.","In detail, we present the three tasks of
                                        learning, composing, and improvising in which a human-centered
                                        piano would be beneficial for the pianist.","To address this, physi-
                                        • Human-centered computing → Human computer interac-                         cal augmentations have been introduced instead to accommodate
                                        tion (HCI); Interaction devices; • Applied computing → Sound                 users with specific needs (e.g., adding a seat riser for shorter peo-
                                        and music computing; Interactive learning environments.",2022-04-14 13:16:46+00:00,The Vision of a Human-Centered Piano,cs.HC,['cs.HC'],"[arxiv.Result.Author('Jordan Aiko Deja'), arxiv.Result.Author('Sven Mayer'), arxiv.Result.Author('Klen Čopič Pucihar'), arxiv.Result.Author('Matjaž Kljun')]","For around 300 years, humans have been learning to play the modern piano
either with a teacher or on their own. In recent years teaching and learning
have been enhanced using augmented technologies that support novices. Other
technologies have also tried to improve different use cases with the piano,
such as composing and performing. Researchers and practitioners have showcased
several forms of augmentation, from hardware improvements, sound quality,
rendering projected visualizations to gesture-based and immersive technologies.
Today, the landscape of piano augmentations is very diverse, and it is unclear
how to describe the ideal piano and its features. In this work, we discuss how
the human-centered piano -- the piano that has been designed with humans in the
center of the design process and that effectively supports tasks performed on
it -- can support pianists. In detail, we present the three tasks of learning,
composing, and improvising in which a human-centered piano would be beneficial
for the pianist."
4920,"In the following paragraphs, we explain the interaction models
Designing Creative AI Partners with COFI: A Framework for Modeling Interaction in Human-AI Co-Creative System19s

and discuss the potential for further research in specific interaction components.","We identified three major
clusters of interaction models utilized by these systems.","These interaction models can be useful
when designing a co-creative system since they can help identify appropriate interaction components and determine if
interaction components should be modified for the corresponding type of co-creative AI agent.",2022-04-15 22:35:23+00:00,Designing Creative AI Partners with COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jeba Rezwana'), arxiv.Result.Author('Mary Lou Maher')]","Human-AI co-creativity involves both humans and AI collaborating on a shared
creative product as partners. In a creative collaboration, interaction
dynamics, such as turn-taking, contribution type, and communication, are the
driving forces of the co-creative process. Therefore the interaction model is a
critical and essential component for effective co-creative systems. There is
relatively little research about interaction design in the co-creativity field,
which is reflected in a lack of focus on interaction design in many existing
co-creative systems. The primary focus of co-creativity research has been on
the abilities of the AI. This paper focuses on the importance of interaction
design in co-creative systems with the development of the Co-Creative Framework
for Interaction design (COFI) that describes the broad scope of possibilities
for interaction design in co-creative systems. Researchers can use COFI for
modeling interaction in co-creative systems by exploring alternatives in this
design space of interaction. COFI can also be beneficial while investigating
and interpreting the interaction design of existing co-creative systems. We
coded a dataset of existing 92 co-creative systems using COFI and analyzed the
data to show how COFI provides a basis to categorize the interaction models of
existing co-creative systems. We identify opportunities to shift the focus of
interaction models in co-creativity to enable more communication between the
user and AI leading to human-AI partnerships."
4928,"Therefore, future studies should further study smart home IoT users’
preferences towards privacy versus convenience.","Therefore, our results could not be generalized
to older adult populations who may have a diﬀerent privacy versus convenience
calculus.","In our study, participants were
asked to imagine themselves in a hypothetical situation, where they explored our
IoT smart home device management website that was connected to a temper-
ature and pressure sensor that was located in the ﬁrst-author’s home.",2022-04-16 08:38:04+00:00,A User Study to Evaluate a Web-based Prototype for Smart Home Internet of Things Device Management,cs.HC,['cs.HC'],"[arxiv.Result.Author('Leena Alghamdi'), arxiv.Result.Author('Ashwaq Alsoubai'), arxiv.Result.Author('Mamtaj Akter'), arxiv.Result.Author('Faisal Alghamdi'), arxiv.Result.Author('Pamela Wisniewski')]","With the growing advances in the Internet of Things (IoT) technology, IoT
device management platforms are becoming increasingly important. We conducted a
web-based survey and usability study with 43 participants who use IoT devices
frequently to: 1) examine their smart home IoT usage patterns and privacy
preferences, and 2) evaluate a web-based prototype for smart home IoT device
management. We found that participants perceived privacy as more important than
the convenience afforded by the IoT devices. Based on their average scores of
privacy vs. convenience importance, participants with low privacy and low
convenience significantly reported less privacy control and convenience
preferences than participants with high privacy and high convenience. Overall,
all participants were satisfied with the proposed website prototype and their
actual usability evaluation demonstrated a good understanding of the website
features. This paper provides an empirical examination of the privacy versus
convenience trade-offs smart home users make when managing their IoT devices."
4968,"Besides analyzing the module-centric impact, we further study the system performance from the design layout
perspective in terms of score computation and score generation time.","Even though the gazing projection-based cognitive computation for excluding the first task causes to generate
the false positive instances, we obtain the median F2-score of 0.54.","We observe that although the predicted score
varies marginally across the participants (Figure 6a), the predicted score of 67% participants differs from the actual at
most by 12.5(%), whereas the exact match in terms of the score is found for 25% of the participants.",2022-04-18 07:13:54+00:00,"I Cannot See Students Focusing on My Presentation; Are They Following Me? Continuous Monitoring of Student Engagement through ""Stungage""",cs.HC,['cs.HC'],"[arxiv.Result.Author('Snigdha Das'), arxiv.Result.Author('Sandip Chakraborty'), arxiv.Result.Author('Bivas Mitra')]","Monitoring students' engagement and understanding their learning pace in a
virtual classroom becomes challenging in the absence of direct eye contact
between the students and the instructor. Continuous monitoring of eye gaze and
gaze gestures may produce inaccurate outcomes when the students are allowed to
do productive multitasking, such as taking notes or browsing relevant content.
This paper proposes Stungage - a software wrapper over existing online meeting
platforms to monitor students' engagement in real-time by utilizing the facial
video feeds from the students and the instructor coupled with a local on-device
analysis of the presentation content. The crux of Stungage is to identify a few
opportunistic moments when the students should visually focus on the
presentation content if they can follow the lecture. We investigate these
instances and analyze the students' visual, contextual, and cognitive presence
to assess their engagement during the virtual classroom while not directly
sharing the video captures of the participants and their screens over the web.
Our system achieves an overall F2-score of 0.88 for detecting student
engagement. Besides, we obtain 92 responses from the usability study with an
average SU score of 74.18."
5179,"We hope that there will be further research
to extend the knowledge on fairness in these situations.","In such
situations, end-users may judge fairness based on other attributes about who ’deserves’ the loan,
perhaps involving loan amount or sensitive attributes.","6 CONCLUSION

In this paper, we have presented an interactive human-in-the-loop prototype that supports end-
users in assessing the fairness of an AI system that makes loan decisions, and allows them to
feedback changes to the AI model.",2022-04-22 02:24:11+00:00,Towards Involving End-users in Interactive Human-in-the-loop AI Fairness,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Yuri Nakao'), arxiv.Result.Author('Simone Stumpf'), arxiv.Result.Author('Subeida Ahmed'), arxiv.Result.Author('Aisha Naseer'), arxiv.Result.Author('Lorenzo Strappelli')]","Ensuring fairness in artificial intelligence (AI) is important to counteract
bias and discrimination in far-reaching applications. Recent work has started
to investigate how humans judge fairness and how to support machine learning
(ML) experts in making their AI models fairer. Drawing inspiration from an
Explainable AI (XAI) approach called \emph{explanatory debugging} used in
interactive machine learning, our work explores designing interpretable and
interactive human-in-the-loop interfaces that allow ordinary end-users without
any technical or domain background to identify potential fairness issues and
possibly fix them in the context of loan decisions. Through workshops with
end-users, we co-designed and implemented a prototype system that allowed
end-users to see why predictions were made, and then to change weights on
features to ""debug"" fairness issues. We evaluated the use of this prototype
system through an online study. To investigate the implications of diverse
human values about fairness around the globe, we also explored how cultural
dimensions might play a role in using this prototype. Our results contribute to
the design of interfaces to allow end-users to be involved in judging and
addressing AI fairness through a human-in-the-loop approach."
5258,"Some parameters were kept in the model despite           show the negative effect of this variable on pedestrians stress
their low t-statistics values because of their importance        level for further research.","the utility function or latent variable is higher than δ1 and    In fact, our result may be rooted in our data, however, we
less than δ2, the pedestrians stress level is predicted to be    consider the impact of this variable in the utility function to
medium.",and the consistency of estimates.,2022-04-24 21:59:47+00:00,Ordered-logit pedestrian stress model for traffic flow with automated vehicles,cs.HC,"['cs.HC', 'stat.AP']","[arxiv.Result.Author('Kimia Kamal'), arxiv.Result.Author('Bilal Farooq'), arxiv.Result.Author('Mahwish Mudassar'), arxiv.Result.Author('Arash Kalatian')]","An ordered-logit model is developed to study the effects of Automated
Vehicles (AVs) in the traffic mix on the average stress level of a pedestrian
when crossing an urban street at mid-block. Information collected from a
galvanic skin resistance sensor and virtual reality experiments are transformed
into a dataset with interpretable average stress levels (low, medium, and high)
and geometric, traffic, and environmental conditions. Modelling results
indicate a decrease in average stress level with the increase in the percentage
of AVs in the traffic mix."
5396,"ences, such as data selection through legends, may impact the types of
Further, visualization tools can recommend insights with similar or             insights users can derive from the charts, which requires further study.","Other types of refer-
tailed insights, as this user is potentially looking for this type of insight.","different characteristics to the ones the user has discovered to focus or
expand exploration.",2022-04-27 13:01:47+00:00,Characterizing Visualization Insights through Entity-Based Interaction: An Exploratory Study,cs.HC,['cs.HC'],"[arxiv.Result.Author('Chen He'), arxiv.Result.Author('Tung Vuong'), arxiv.Result.Author('Giulio Jacucci')]","One of the primary purposes of visualization is to assist users in
discovering insights. While there has been much research in information
visualization aiming at complex data transformation and novel presentation
techniques, relatively little has been done to understand how users derive
insights through interactive visualization of data. This paper presents a
crowdsourced study with 158 participants investigating the relation between
entity-based interaction (an action + its target entity) and the resulting
insight. To this end, we generalized the interaction with an existing CO2
Explorer as entity-based interaction and enabled users to input notes and refer
to relevant entities to assist their narratives. We logged interactions of
users freely exploring the visualization and characterized their externalized
insights about the data. Using entity-based interactions and references to
infer insight characteristics (category, overview versus detail, and prior
knowledge), we found evidence that compared with interactions, entity
references improved insight characterization from slight/fair to fair/moderate
agreements. To interpret prediction outcomes, feature importance and
correlation analysis indicated that, e.g., detailed insights tended to have
more mouse-overs in the chart area and cite the vertical reference lines in the
line chart as evidence. We discuss study limitations and implications on
knowledge-assisted visualization, e.g., insight recommendations based on user
exploration."
5425,"We show that the proposed
We propose a framework to       the XAI literature that explanations should enable humans        framework enables us to articulate a dialogue between prior
make explicit the relation-     to assess the fairness of AI recommendations, and to ulti-       works and identify gaps that require further research.","Proposing a framework:       Among many other desiderata [26], it is often assumed in         AI, and distributive fairness.","In
ships between explanations,     mately make better and fairer decisions [2, 8, 10, 11, 14–16,    particular, we show that prior literature has focused on dif-
fairness perceptions, reliance  23, 35, 36].",2022-04-27 19:33:36+00:00,"On the Relationship Between Explanations, Fairness Perceptions, and Decisions",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jakob Schoeffer'), arxiv.Result.Author('Maria De-Arteaga'), arxiv.Result.Author('Niklas Kuehl')]","It is known that recommendations of AI-based systems can be incorrect or
unfair. Hence, it is often proposed that a human be the final decision-maker.
Prior work has argued that explanations are an essential pathway to help human
decision-makers enhance decision quality and mitigate bias, i.e., facilitate
human-AI complementarity. For these benefits to materialize, explanations
should enable humans to appropriately rely on AI recommendations and override
the algorithmic recommendation when necessary to increase distributive fairness
of decisions. The literature, however, does not provide conclusive empirical
evidence as to whether explanations enable such complementarity in practice. In
this work, we (a) provide a conceptual framework to articulate the
relationships between explanations, fairness perceptions, reliance, and
distributive fairness, (b) apply it to understand (seemingly) contradictory
research findings at the intersection of explanations and fairness, and (c)
derive cohesive implications for the formulation of research questions and the
design of experiments."
5426,"We show that the proposed
We propose a framework to       the XAI literature that explanations should enable humans        framework enables us to articulate a dialogue between prior
make explicit the relation-     to assess the fairness of AI recommendations, and to ulti-       works and identify gaps that require further research.","Proposing a framework:       Among many other desiderata [26], it is often assumed in         AI, and distributive fairness.","In
ships between explanations,     mately make better and fairer decisions [2, 8, 10, 11, 14–16,    particular, we show that prior literature has focused on dif-
fairness perceptions, reliance  23, 35, 36].",2022-04-27 19:33:36+00:00,"On the Relationship Between Explanations, Fairness Perceptions, and Decisions",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jakob Schoeffer'), arxiv.Result.Author('Maria De-Arteaga'), arxiv.Result.Author('Niklas Kuehl')]","It is known that recommendations of AI-based systems can be incorrect or
unfair. Hence, it is often proposed that a human be the final decision-maker.
Prior work has argued that explanations are an essential pathway to help human
decision-makers enhance decision quality and mitigate bias, i.e., facilitate
human-AI complementarity. For these benefits to materialize, explanations
should enable humans to appropriately rely on AI recommendations and override
the algorithmic recommendation when necessary to increase distributive fairness
of decisions. The literature, however, does not provide conclusive empirical
evidence as to whether explanations enable such complementarity in practice. In
this work, we (a) provide a conceptual framework to articulate the
relationships between explanations, fairness perceptions, reliance, and
distributive fairness, (b) apply it to understand (seemingly) contradictory
research findings at the intersection of explanations and fairness, and (c)
derive cohesive implications for the formulation of research questions and the
design of experiments."
5427,"We show that the proposed
We propose a framework to       the XAI literature that explanations should enable humans        framework enables us to articulate a dialogue between prior
make explicit the relation-     to assess the fairness of AI recommendations, and to ulti-       works and identify gaps that require further research.","Proposing a framework:       Among many other desiderata [27], it is often assumed in         AI, and distributive fairness.","In
ships between explanations,     mately make better and fairer decisions [2, 8, 10, 11, 14–16,    particular, we show that prior literature has focused on dif-
fairness perceptions, reliance  24, 37, 38].",2022-04-27 19:33:36+00:00,"On the Relationship Between Explanations, Fairness Perceptions, and Decisions",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jakob Schoeffer'), arxiv.Result.Author('Maria De-Arteaga'), arxiv.Result.Author('Niklas Kuehl')]","It is known that recommendations of AI-based systems can be incorrect or
unfair. Hence, it is often proposed that a human be the final decision-maker.
Prior work has argued that explanations are an essential pathway to help human
decision-makers enhance decision quality and mitigate bias, i.e., facilitate
human-AI complementarity. For these benefits to materialize, explanations
should enable humans to appropriately rely on AI recommendations and override
the algorithmic recommendation when necessary to increase distributive fairness
of decisions. The literature, however, does not provide conclusive empirical
evidence as to whether explanations enable such complementarity in practice. In
this work, we (a) provide a conceptual framework to articulate the
relationships between explanations, fairness perceptions, reliance, and
distributive fairness, (b) apply it to understand (seemingly) contradictory
research findings at the intersection of explanations and fairness, and (c)
derive cohesive implications for the formulation of research questions and the
design of experiments."
5431,"Efficiency is one of the most critical
factors for user experience and further research should be done to design two-way communication more efficient.","This reveals
the importance of the efficiency of the communication between users and AI.","Additionally, some participants suggested less frequent feedback collection as our communicating AI asked the user
for their preference every time it showed an inspiration.",2022-04-27 22:37:44+00:00,"Understanding User Perceptions, Collaborative Experience and User Engagement in Different Human-AI Interaction Designs for Co-Creative Systems",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jeba Rezwana'), arxiv.Result.Author('Mary Lou Maher')]","Human-AI co-creativity involves humans and AI collaborating on a shared
creative product as partners. In a creative collaboration, communication is an
essential component among collaborators. In many existing co-creative systems
users can communicate with the AI, usually using buttons or sliders. Typically,
the AI in co-creative systems cannot communicate back to humans, limiting their
potential to be perceived as partners rather than just a tool. This paper
presents a study with 38 participants to explore the impact of two interaction
designs, with and without AI-to-human communication, on user engagement,
collaborative experience and user perception of a co-creative AI. The study
involves user interaction with two prototypes of a co-creative system that
contributes sketches as design inspirations during a design task. The results
show improved collaborative experience and user engagement with the system
incorporating AI-to-human communication. Users perceive co-creative AI as more
reliable, personal, and intelligent when the AI communicates to users. The
findings can be used to design effective co-creative systems, and the insights
can be transferred to other fields involving human-AI interaction and
collaboration."
5432,"Our findings show that further research to identify ethical issues is needed as ethical issues may arise with
users relying on the AI too much and revealing unintended data to the AI.","Some participants wanted to talk back to the AI as it seemed more fun, personal and
reliable.","7 LIMITATIONS

Even though we chose simple and similar complexity design task objects, the exact design tasks chosen for each
prototype may have an impact on the results.",2022-04-27 22:37:44+00:00,"Understanding User Perceptions, Collaborative Experience and User Engagement in Different Human-AI Interaction Designs for Co-Creative Systems",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jeba Rezwana'), arxiv.Result.Author('Mary Lou Maher')]","Human-AI co-creativity involves humans and AI collaborating on a shared
creative product as partners. In a creative collaboration, communication is an
essential component among collaborators. In many existing co-creative systems
users can communicate with the AI, usually using buttons or sliders. Typically,
the AI in co-creative systems cannot communicate back to humans, limiting their
potential to be perceived as partners rather than just a tool. This paper
presents a study with 38 participants to explore the impact of two interaction
designs, with and without AI-to-human communication, on user engagement,
collaborative experience and user perception of a co-creative AI. The study
involves user interaction with two prototypes of a co-creative system that
contributes sketches as design inspirations during a design task. The results
show improved collaborative experience and user engagement with the system
incorporating AI-to-human communication. Users perceive co-creative AI as more
reliable, personal, and intelligent when the AI communicates to users. The
findings can be used to design effective co-creative systems, and the insights
can be transferred to other fields involving human-AI interaction and
collaboration."
5433,"Efficiency is one of the most critical
factors for user experience and further research should be done to design two-way communication more efficient.","This reveals
the importance of the efficiency of the communication between users and AI.","Additionally, some participants suggested less frequent feedback collection as our communicating AI asked the user
for their preference every time it showed an inspiration.",2022-04-27 22:37:44+00:00,"Understanding User Perceptions, Collaborative Experience and User Engagement in Different Human-AI Interaction Designs for Co-Creative Systems",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jeba Rezwana'), arxiv.Result.Author('Mary Lou Maher')]","Human-AI co-creativity involves humans and AI collaborating on a shared
creative product as partners. In a creative collaboration, communication is an
essential component among collaborators. In many existing co-creative systems
users can communicate with the AI, usually using buttons or sliders. Typically,
the AI in co-creative systems cannot communicate back to humans, limiting their
potential to be perceived as partners rather than just a tool. This paper
presents a study with 38 participants to explore the impact of two interaction
designs, with and without AI-to-human communication, on user engagement,
collaborative experience and user perception of a co-creative AI. The study
involves user interaction with two prototypes of a co-creative system that
contributes sketches as design inspirations during a design task. The results
show improved collaborative experience and user engagement with the system
incorporating AI-to-human communication. Users perceive co-creative AI as more
reliable, personal, and intelligent when the AI communicates to users. The
findings can be used to design effective co-creative systems, and the insights
can be transferred to other fields involving human-AI interaction and
collaboration."
5434,"Our findings show that further research to identify ethical issues is needed as ethical issues may arise with
users relying on the AI too much and revealing unintended data to the AI.","Some participants wanted to talk back to the AI as it seemed more fun, personal and
reliable.","7 LIMITATIONS

Even though we chose simple and similar complexity design task objects, the exact design tasks chosen for each
prototype may have an impact on the results.",2022-04-27 22:37:44+00:00,"Understanding User Perceptions, Collaborative Experience and User Engagement in Different Human-AI Interaction Designs for Co-Creative Systems",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jeba Rezwana'), arxiv.Result.Author('Mary Lou Maher')]","Human-AI co-creativity involves humans and AI collaborating on a shared
creative product as partners. In a creative collaboration, communication is an
essential component among collaborators. In many existing co-creative systems
users can communicate with the AI, usually using buttons or sliders. Typically,
the AI in co-creative systems cannot communicate back to humans, limiting their
potential to be perceived as partners rather than just a tool. This paper
presents a study with 38 participants to explore the impact of two interaction
designs, with and without AI-to-human communication, on user engagement,
collaborative experience and user perception of a co-creative AI. The study
involves user interaction with two prototypes of a co-creative system that
contributes sketches as design inspirations during a design task. The results
show improved collaborative experience and user engagement with the system
incorporating AI-to-human communication. Users perceive co-creative AI as more
reliable, personal, and intelligent when the AI communicates to users. The
findings can be used to design effective co-creative systems, and the insights
can be transferred to other fields involving human-AI interaction and
collaboration."
5541,"However, we
further research should be carried out to examine in more detail        found it hard to accommodate community biolabs within a di-
how community biolabs accommodate technically demanding work            chotomy that separates the resource-plentiful and the very resource-
without relying on the more rigid infrastructures established within    constrained.","However,      ence hardware for the “haves” and the “have nots”.","Community biolabs present a potentially unique set-
professional labs to support and direct work.",2022-04-29 20:57:25+00:00,"""Short on time and big on ideas"": Perspectives from Lab Members on DIYBio Work in Community Biolabs",cs.HC,['cs.HC'],"[arxiv.Result.Author('Orlando de Lange'), arxiv.Result.Author('Kellie Dunn'), arxiv.Result.Author('Nadya Peek')]","DIYbio challenges the status quo by positioning laboratory biology work
outside of traditional institutions. HCI has increasingly explored the DIYbio
movement, but we lack insight into sites of practice such as community biolabs.
Therefore, we gathered data on eleven community biolabs by interviewing sixteen
lab managers and members. These labs represent half of identified organizations
in scope worldwide. Participants detailed their practices and motivations,
outlining the constraints and opportunities of their community biolabs. We
found that lab members conducted technically challenging project work with
access to high-end equipment and professional expertise. We found that the
unique nature of biowork exacerbated challenges for cooperative work, partially
due to the particular time sensitivities of work with living organisms.
Building on our findings, we discuss how community biolab members are creating
new approaches to laboratory biology and how this has design implications for
systems that support non-traditional settings for scientific practice."
5583,"magnetism is a complex mechanism,           and improve their practice by the effects
Grand masters get great by further study-    and many physical phenomena such as         of their efforts in the world.",Chess duffers get good by playing.,ing famous games.,2022-04-30 22:24:39+00:00,"Towards Process-Oriented, Modular, and Versatile Question Generation that Meets Educational Needs",cs.HC,"['cs.HC', 'cs.CL']","[arxiv.Result.Author('Xu Wang'), arxiv.Result.Author('Simin Fan'), arxiv.Result.Author('Jessica Houghton'), arxiv.Result.Author('Lu Wang')]","NLP-powered automatic question generation (QG) techniques carry great
pedagogical potential of saving educators' time and benefiting student
learning. Yet, QG systems have not been widely adopted in classrooms to date.
In this work, we aim to pinpoint key impediments and investigate how to improve
the usability of automatic QG techniques for educational purposes by
understanding how instructors construct questions and identifying touch points
to enhance the underlying NLP models. We perform an in-depth need finding study
with 11 instructors across 7 different universities, and summarize their
thought processes and needs when creating questions. While instructors show
great interests in using NLP systems to support question design, none of them
has used such tools in practice. They resort to multiple sources of
information, ranging from domain knowledge to students' misconceptions, all of
which missing from today's QG systems. We argue that building effective
human-NLP collaborative QG systems that emphasize instructor control and
explainability is imperative for real-world adoption. We call for QG systems to
provide process-oriented support, use modular design, and handle diverse
sources of input."
5584,"them feel more comfortable learning and
                                            Grand masters get great by further study-    sharing.",Chess duffers get good by playing.,ing famous games.,2022-04-30 22:24:39+00:00,"Towards Process-Oriented, Modular, and Versatile Question Generation that Meets Educational Needs",cs.HC,"['cs.HC', 'cs.CL']","[arxiv.Result.Author('Xu Wang'), arxiv.Result.Author('Simin Fan'), arxiv.Result.Author('Jessica Houghton'), arxiv.Result.Author('Lu Wang')]","NLP-powered automatic question generation (QG) techniques carry great
pedagogical potential of saving educators' time and benefiting student
learning. Yet, QG systems have not been widely adopted in classrooms to date.
In this work, we aim to pinpoint key impediments and investigate how to improve
the usability of automatic QG techniques for educational purposes by
understanding how instructors construct questions and identifying touch points
to enhance the underlying NLP models. We perform an in-depth need finding study
with 11 instructors across 7 different universities, and summarize their
thought processes and needs when creating questions. While instructors show
great interests in using NLP systems to support question design, none of them
has used such tools in practice. They resort to multiple sources of
information, ranging from domain knowledge to students' misconceptions, all of
which missing from today's QG systems. We argue that building effective
human-NLP collaborative QG systems that emphasize instructor control and
explainability is imperative for real-world adoption. We call for QG systems to
provide process-oriented support, use modular design, and handle diverse
sources of input."
5604,"This lays the
foundation for further research with larger data sets that can focus         (1) We explore the impact on toxicity, insult, threat, identity
on particular identities and unpack their impact on ratings that                  attack, and profanity ratings of online conversations as per-
power machine learning models that in turn are used to moderate                   ceived by two groups of annotators (referred to as specialized
content on the internet.","empowering history), suggesting that the standards for evaluating
racist language annotations should reflect the interpretations of            This work has the following three primary contributions:
those who are impacted or are at the receiving end.","rater pools): African American and LGBTQ American raters

   To summarize, understanding how demographics of annotators                (2) We are open-sourcing a large corpora of Civil Comments
can impact annotations has been studied in seven different ways                   dataset and raters’ annotations of conversations in this cor-
so far in the literature:                                                         pora across toxicity, insult, threat, identity attack, and pro-
                                                                                  fanity.",2022-05-01 16:08:48+00:00,Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.LG']","[arxiv.Result.Author('Nitesh Goyal'), arxiv.Result.Author('Ian Kivlichan'), arxiv.Result.Author('Rachel Rosen'), arxiv.Result.Author('Lucy Vasserman')]","Machine learning models are commonly used to detect toxicity in online
conversations. These models are trained on datasets annotated by human raters.
We explore how raters' self-described identities impact how they annotate
toxicity in online comments. We first define the concept of specialized rater
pools: rater pools formed based on raters' self-described identities, rather
than at random. We formed three such rater pools for this study--specialized
rater pools of raters from the U.S. who identify as African American, LGBTQ,
and those who identify as neither. Each of these rater pools annotated the same
set of comments, which contains many references to these identity groups. We
found that rater identity is a statistically significant factor in how raters
will annotate toxicity for identity-related annotations. Using preliminary
content analysis, we examined the comments with the most disagreement between
rater pools and found nuanced differences in the toxicity annotations. Next, we
trained models on the annotations from each of the different rater pools, and
compared the scores of these models on comments from several test sets.
Finally, we discuss how using raters that self-identify with the subjects of
comments can create more inclusive machine learning models, and provide more
nuanced ratings than those by random raters."
5629,"However, these are non-trivial challenges that require
                                                                            formal design rules, which in turn require further study.",and composition.,An additional contribution is our dashboard corpus.,2022-05-02 09:09:42+00:00,Dashboard Design Patterns,cs.HC,['cs.HC'],"[arxiv.Result.Author('Benjamin Bach'), arxiv.Result.Author('Euan Freeman'), arxiv.Result.Author('Alfie Abdul-Rahman'), arxiv.Result.Author('Cagatay Turkay'), arxiv.Result.Author('Saiful Khan'), arxiv.Result.Author('Yulei Fan'), arxiv.Result.Author('Min Chen')]","This paper introduces design patterns for dashboards to inform their design
processes. Despite a growing number of public examples, case studies, and
general guidelines there is surprisingly little design guidance for dashboards.
Such guidance is necessary to inspire designs and discuss tradeoffs in
screenspace, interaction, and information shown. Based on a systematic review
of 144 dashboards, we report on eight groups of design patterns that provide
common solutions in dashboard design. We discuss combinations of these patterns
in dashboard genres such as narrative, analytical, or embedded dashboard. We
ran a 2 week dashboard design workshop with 23 participants of varying
expertise working on their own data and dashboards. We discuss the application
of patterns for the dashboard design processes, as well as general design
tradeoffs and common challenges. Our work complements previous surveys and aims
to support dashboard designers and researchers in co-creation, structured
design decisions, as well as future user evaluations about dashboard design
guidelines. Detailed pattern descriptions and workshop material can be found
online: https://dashboarddesignpatterns.github.io"
5630,"R. Reeve (U. Glasgow) and L. Matthews (U. Glasgow)
formal design rules, which in turn require further study.","However, these are non-trivial challenges that require       colleagues Profs.",for their advice on pandemic responses.,2022-05-02 09:09:42+00:00,Dashboard Design Patterns,cs.HC,['cs.HC'],"[arxiv.Result.Author('Benjamin Bach'), arxiv.Result.Author('Euan Freeman'), arxiv.Result.Author('Alfie Abdul-Rahman'), arxiv.Result.Author('Cagatay Turkay'), arxiv.Result.Author('Saiful Khan'), arxiv.Result.Author('Yulei Fan'), arxiv.Result.Author('Min Chen')]","This paper introduces design patterns for dashboards to inform dashboard
design processes. Despite a growing number of public examples, case studies,
and general guidelines there is surprisingly little design guidance for
dashboards. Such guidance is necessary to inspire designs and discuss tradeoffs
in, e.g., screenspace, interaction, or information shown. Based on a systematic
review of 144 dashboards, we report on eight groups of design patterns that
provide common solutions in dashboard design. We discuss combinations of these
patterns in dashboard genres such as narrative, analytical, or embedded
dashboard. We ran a 2-week dashboard design workshop with 23 participants of
varying expertise working on their own data and dashboards. We discuss the
application of patterns for the dashboard design processes, as well as general
design tradeoffs and common challenges. Our work complements previous surveys
and aims to support dashboard designers and researchers in co-creation,
structured design decisions, as well as future user evaluations about dashboard
design guidelines. Detailed pattern descriptions and workshop material can be
found online: https://dashboarddesignpatterns.github.io"
5652,"A potential reason is that,         this phenomenon merits further study.","In summary,
along the x-axis rather than the y-axis.","even when describing trends, users still need to refer to x-axis values
(e.g., “increase between 2000 and 2010”).",2022-05-03 01:13:58+00:00,How Do Captions Affect Visualization Reading?,cs.HC,"['cs.HC', 'H.5.2']","[arxiv.Result.Author('Shelly Cheng'), arxiv.Result.Author('Hazel Zhu'), arxiv.Result.Author('Eugene Wu')]","Captions help readers better understand visualizations. However, if the
visualization is intended to communicate specific features, should the caption
be statistical, and focus on specific values, or perceptual, and focus on
general patterns? Prior work has shown that when captions mention visually
salient features, users tend to recall those features. Still, we lack explicit
guidelines for how to compose the appropriate caption. Further, what if the
author wishes to emphasize a less salient feature?
  In this paper, we study how the visual salience of the feature described in a
caption, and the semantic level of the caption description, affect a reader's
takeaways from line charts. For each single- or multi-line chart, we generate 4
captions that 1) describe either the primary or secondary most salient feature
in a chart, and 2) describe the feature either at the statistical or perceptual
levels. We then show users random chart-caption pairs and record their
takeaways.
  We find that the primary salient feature is more memorable for single-line
charts when the caption is expressed at the statistical level; for secondary
salient features in single- and multi-line charts, the perceptual level is more
memorable. We also find that many users will tend to rely on erroneous data in
the caption and not double-check its veracity against the data in the chart."
5653,"A potential reason is that,         this phenomenon merits further study.","In summary,
along the x-axis rather than the y-axis.","even when describing trends, users still need to refer to x-axis values
(e.g., “increase between 2000 and 2010”).",2022-05-03 01:13:58+00:00,How Do Captions Affect Visualization Reading?,cs.HC,"['cs.HC', 'H.5.2']","[arxiv.Result.Author('Shelly Cheng'), arxiv.Result.Author('Hazel Zhu'), arxiv.Result.Author('Eugene Wu')]","Captions help readers better understand visualizations. However, if the
visualization is intended to communicate specific features, should the caption
be statistical, and focus on specific values, or perceptual, and focus on
general patterns? Prior work has shown that when captions mention visually
salient features, users tend to recall those features. Still, we lack explicit
guidelines for how to compose the appropriate caption. Further, what if the
author wishes to emphasize a less salient feature?
  In this paper, we study how the visual salience of the feature described in a
caption, and the semantic level of the caption description, affect a reader's
takeaways from line charts. For each single- or multi-line chart, we generate 4
captions that 1) describe either the primary or secondary most salient feature
in a chart, and 2) describe the feature either at the statistical or perceptual
levels. We then show users random chart-caption pairs and record their
takeaways.
  We find that the primary salient feature is more memorable for single-line
charts when the caption is expressed at the statistical level; for secondary
salient features in single- and multi-line charts, the perceptual level is more
memorable. We also find that many users will tend to rely on erroneous data in
the caption and not double-check its veracity against the data in the chart."
5715,"It is
can inform further research and design.","We hope to derive com-       material helps to flexibly study such relationships, and how new
monalities between different people’s experiences from this, that         technology interactions fit in with existing social contexts.","based on a simple but versatile visual format, freely available, and
                                                                          easily extensible.",2022-05-03 19:59:16+00:00,Social Practice Cards: Research material to study social contexts as interwoven practice constellations,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Alarith Uhde'), arxiv.Result.Author('Mena Mesenhöller'), arxiv.Result.Author('Marc Hassenzahl')]","Studying how social contexts shape technology interactions and how we
experience them is hard. One challenge is that social contexts are very dynamic
and shaped by the situated practices of everyone involved. As a result, the
same human-technology interaction can be experienced quite differently
depending on what other people around us do. As a first step to study
interpersonal and interpractice dynamics, we collected a broad range of visual
representations of practices, such as ""riding a bike"" or ""skipping the rope"".
This material can be used to further explore how different, co-located
practices relate to each other."
5723,"Despite these chal-
human and ethical aspect of digital phenotyping data collection    lenges, we hope that our work serves as a foundation for this
for mental health monitoring, especially focusing on potential     new research direction, and we call for further research on
privacy concerns.","[215] illustrated the         and IoT devices (e.g., iOS vs. Android).",data-driven DTx analytics.,2022-05-04 02:10:29+00:00,Toward Data-Driven Digital Therapeutics Analytics: Literature Review and Research Directions,cs.HC,['cs.HC'],"[arxiv.Result.Author('Uichin Lee'), arxiv.Result.Author('Gyuwon Jung'), arxiv.Result.Author('Eunyeol Ma'), arxiv.Result.Author('Jin San Kim'), arxiv.Result.Author('Heepyung Kim'), arxiv.Result.Author('Hyunsoo Lee'), arxiv.Result.Author('Jumabek Alikhanov'), arxiv.Result.Author('Youngtae Noh'), arxiv.Result.Author('Heeyoung Kim')]","With the advent of Digital Therapeutics (DTx), the development of software as
a medical device (SaMD) for mobile and wearable devices has gained significant
attention in recent years. Existing DTx evaluations, such as randomized
clinical trials, mostly focus on verifying the effectiveness of DTx products.
To acquire a deeper understanding of DTx engagement and behavioral adherence,
beyond efficacy, a large amount of contextual and interaction data from mobile
and wearable devices during field deployment would be required for analysis. In
this work, the overall flow of the data-driven DTx analytics is reviewed to
help researchers and practitioners to explore DTx datasets, to investigate
contextual patterns associated with DTx usage, and to establish the (causal)
relationship of DTx engagement and behavioral adherence. This review of the key
components of data-driven analytics provides novel research directions in the
analysis of mobile sensor and interaction datasets, which helps to iteratively
improve the receptivity of existing DTx."
5724,"However, it was found that users frequently have     lenges, we hope that our work serves as a foundation for this
incorrect mental models regarding the types of data collected     new research direction, and we call for further research on
from mobile and wearable devices, and how they are used to        data-driven DTx analytics.","Despite these chal-
sensor data.",build AI models [215].,2022-05-04 02:10:29+00:00,Toward Data-Driven Digital Therapeutics Analytics: Literature Review and Research Directions,cs.HC,['cs.HC'],"[arxiv.Result.Author('Uichin Lee'), arxiv.Result.Author('Gyuwon Jung'), arxiv.Result.Author('Eun-Yeol Ma'), arxiv.Result.Author('Jin San Kim'), arxiv.Result.Author('Heepyung Kim'), arxiv.Result.Author('Jumabek Alikhanov'), arxiv.Result.Author('Youngtae Noh'), arxiv.Result.Author('Heeyoung Kim')]","With the advent of Digital Therapeutics (DTx), the development of software as
a medical device (SaMD) for mobile and wearable devices has gained significant
attention in recent years. Existing DTx evaluations, such as randomized
clinical trials, mostly focus on verifying the effectiveness of DTx products.
To acquire a deeper understanding of DTx engagement and behavioral adherence,
beyond efficacy, a large amount of contextual and interaction data from mobile
and wearable devices during field deployment would be required for analysis. In
this work, the overall flow of the data-driven DTx analytics is reviewed to
help researchers and practitioners to explore DTx datasets, to investigate
contextual patterns associated with DTx usage, and to establish the (causal)
relationship of DTx engagement and behavioral adherence. This review of the key
components of data-driven analytics provides novel research directions in the
analysis of mobile sensor and interaction datasets, which helps to iteratively
improve the receptivity of existing DTx."
5725,"However, it was found that users frequently have     lenges, we hope that our work serves as a foundation for this
incorrect mental models regarding the types of data collected     new research direction, and we call for further research on
from mobile and wearable devices, and how they are used to        data-driven DTx analytics.","Despite these chal-
sensor data.",build AI models [215].,2022-05-04 02:10:29+00:00,Toward Data-Driven Digital Therapeutics Analytics: Literature Review and Research Directions,cs.HC,['cs.HC'],"[arxiv.Result.Author('Uichin Lee'), arxiv.Result.Author('Gyuwon Jung'), arxiv.Result.Author('Eun-Yeol Ma'), arxiv.Result.Author('Jin San Kim'), arxiv.Result.Author('Heepyung Kim'), arxiv.Result.Author('Jumabek Alikhanov'), arxiv.Result.Author('Youngtae Noh'), arxiv.Result.Author('Heeyoung Kim')]","With the advent of Digital Therapeutics (DTx), the development of software as
a medical device (SaMD) for mobile and wearable devices has gained significant
attention in recent years. Existing DTx evaluations, such as randomized
clinical trials, mostly focus on verifying the effectiveness of DTx products.
To acquire a deeper understanding of DTx engagement and behavioral adherence,
beyond efficacy, a large amount of contextual and interaction data from mobile
and wearable devices during field deployment would be required for analysis. In
this work, the overall flow of the data-driven DTx analytics is reviewed to
help researchers and practitioners to explore DTx datasets, to investigate
contextual patterns associated with DTx usage, and to establish the (causal)
relationship of DTx engagement and behavioral adherence. This review of the key
components of data-driven analytics provides novel research directions in the
analysis of mobile sensor and interaction datasets, which helps to iteratively
improve the receptivity of existing DTx."
5865,"Moreover, further research should be done to uncover potential differences in usability for CFEs generated for
different models.","The impact of
such a framing in XAI is yet to be shown.","While the way CFEs are presented in the Alien Zoo is always the same, the underlying models
may be fundamentally different.",2022-05-06 17:57:05+00:00,Let's Go to the Alien Zoo: Introducing an Experimental Framework to Study Usability of Counterfactual Explanations for Machine Learning,cs.HC,"['cs.HC', 'cs.LG']","[arxiv.Result.Author('Ulrike Kuhl'), arxiv.Result.Author('André Artelt'), arxiv.Result.Author('Barbara Hammer')]","To foster usefulness and accountability of machine learning (ML), it is
essential to explain a model's decisions in addition to evaluating its
performance. Accordingly, the field of explainable artificial intelligence
(XAI) has resurfaced as a topic of active research, offering approaches to
address the ""how"" and ""why"" of automated decision-making. Within this domain,
counterfactual explanations (CFEs) have gained considerable traction as a
psychologically grounded approach to generate post-hoc explanations. To do so,
CFEs highlight what changes to a model's input would have changed its
prediction in a particular way. However, despite the introduction of numerous
CFE approaches, their usability has yet to be thoroughly validated at the human
level. Thus, to advance the field of XAI, we introduce the Alien Zoo, an
engaging, web-based and game-inspired experimental framework. The Alien Zoo
provides the means to evaluate usability of CFEs for gaining new knowledge from
an automated system, targeting novice users in a domain-general context. As a
proof of concept, we demonstrate the practical efficacy and feasibility of this
approach in a user study. Our results suggest that users benefit from receiving
CFEs compared to no explanation, both in terms of objective performance in the
proposed iterative learning task, and subjective usability. With this work, we
aim to equip research groups and practitioners with the means to easily run
controlled and well-powered user studies to complement their otherwise often
more technology-oriented work. Thus, in the interest of reproducible research,
we provide the entire code, together with the underlying models and user data."
5972,"Although not deﬁnitive, we believe
   These tensions suggest further study regarding the deliberate or           that this indicates that this particular design is transferable across
automatic design choice and further study regarding how to signify            multiple computing domains working with hierarchical data.","versations about how this visual design for hierarchical data could
                                                                              work for their speciﬁc needs.",synchronization (or lack there of) between contexts.,2022-05-09 21:05:34+00:00,"Designing an Interactive, Notebook-Embedded, Tree Visualization to Support Exploratory Performance Analysis",cs.HC,['cs.HC'],"[arxiv.Result.Author('Connor Scully-Allison'), arxiv.Result.Author('Ian Lumsden'), arxiv.Result.Author('Katy Williams'), arxiv.Result.Author('Jesse Bartels'), arxiv.Result.Author('Michela Taufer'), arxiv.Result.Author('Stephanie Brink'), arxiv.Result.Author('Abhinav Bhatele'), arxiv.Result.Author('Olga Pearce'), arxiv.Result.Author('Katherine E. Isaacs')]","Interactive visualization via direct manipulation has inherent design
trade-offs in flexibility, discoverability, and ease-of-use. Scripting
languages can support a vast range of user queries and tasks, but may be more
cumbersome for free-form exploration. Embedding interactive visualization in a
scripting environment, such as a computational notebook, provides an
opportunity for leveraging the strengths of both direct manipulation and
scripting. We conduct a design study investigating this opportunity in the
context of calling context trees as used for performance analysis of parallel
software. Our collaborators make new performance analysis functionality
available to users via Jupyter notebook examples, making the project setting
conducive to such an investigation. Through a series of semi-structured
interviews and regular meetings with project stakeholders, we produce a formal
task analysis grounded in the expectation that tasks may be supported by
scripting, interactive visualization, or both paradigms. We then design an
interactive bivariate calling context tree visualization for embedding in
Jupyter notebooks with features to pass data and state between the scripting
and visualization contexts. We evaluated our embedded design with seven high
performance computing experts. The experts were able to complete tasks and
provided further feedback on the visualization and the notebook-embedded
interactive visualization paradigm. We reflect upon the project and discuss
factors in both the process and the design of the embedded visualization."
6009,"As game jams and hackathons are being used in many diﬀerent contexts
today, I argue that it is a worthwhile pursuit to further research for
example how game jams and hackathons promote the prioritising of
certain design decisions over others, and how they are distinguished from
non-accelerated design processes.","In that perspective, further developing and exploring
the real-time annotation tools can be a valuable endeavour.","Through the summarised contributions
of my PhD project, I have outline several research questions and directions
for future research on accelerated design processes.",2022-05-10 15:24:54+00:00,How Game Jams and Hackathons Accelerate Design Processes,cs.HC,['cs.HC'],[arxiv.Result.Author('Jeanette Falk')],"This dissertation presents three years of research on how design processes in
game jams and hackathons can be understood as accelerated. Hackathons and game
jams can both be described as formats where participants engage in designing
and developing prototypes during an intentionally short time frame, such as 48
hours, which is meant to facilitate creativity, and encourage fast decision
making and rapid prototyping. Game jams and hackathons are organised in many
different contexts and for many different purposes as well, such as: internally
in companies to spark new ideas; for fostering citizen innovation for
municipalities; in cultural and governmental agencies; integral parts of
education; entry points for developers wanting to enter especially the game
industry (Olesen, 2020; Kultima, 2015). During the recent decade, game jams and
hackathons have been introduced to academia as well, as formats for teaching
and learning, and as research platforms as well. Only few research
contributions engage with understanding how accelerated design processes in
game jams and hackathons unfold, or how the organisation of game jam and
hackathon formats influence these accelerated design processes.
  The main contributions of my PhD project are: 1) Descriptive process-level
knowledge, which contextualise and solidify how accelerated design processes
unfold under the circumstances of a game jam and a hackathon. 2) Overviews of
how game jams have been organised for supporting participants' creativity and
of how hackathons have been used as means and as research focus within
academia. 3) Exploring how game jam and hackathon formats may be organised in
order to support knowledge generation such as within academia, and in order to
support creativity."
6010,"As game jams and hackathons are being used in many diﬀerent contexts
today, I argue that it is a worthwhile pursuit to further research for
example how game jams and hackathons promote the prioritising of
certain design decisions over others, and how they are distinguished from
non-accelerated design processes.","In that perspective, further developing and exploring
the real-time annotation tools can be a valuable endeavour.","Through the summarised contributions
of my PhD project, I have outline several research questions and directions
for future research on accelerated design processes.",2022-05-10 15:24:54+00:00,How Game Jams and Hackathons Accelerate Design Processes,cs.HC,['cs.HC'],[arxiv.Result.Author('Jeanette Falk')],"This dissertation presents three years of research on how design processes in
game jams and hackathons can be understood as accelerated. Hackathons and game
jams can both be described as formats where participants engage in designing
and developing prototypes during an intentionally short time frame, such as 48
hours, which is meant to facilitate creativity, and encourage fast decision
making and rapid prototyping. Game jams and hackathons are organised in many
different contexts and for many different purposes as well, such as: internally
in companies to spark new ideas; for fostering citizen innovation for
municipalities; in cultural and governmental agencies; integral parts of
education; entry points for developers wanting to enter especially the game
industry (Olesen, 2020; Kultima, 2015). During the recent decade, game jams and
hackathons have been introduced to academia as well, as formats for teaching
and learning, and as research platforms as well. Only few research
contributions engage with understanding how accelerated design processes in
game jams and hackathons unfold, or how the organisation of game jam and
hackathon formats influence these accelerated design processes.
  The main contributions of my PhD project are: 1) Descriptive process-level
knowledge, which contextualise and solidify how accelerated design processes
unfold under the circumstances of a game jam and a hackathon. 2) Overviews of
how game jams have been organised for supporting participants' creativity and
of how hackathons have been used as means and as research focus within
academia. 3) Exploring how game jam and hackathon formats may be organised in
order to support knowledge generation such as within academia, and in order to
support creativity."
6072,"Lee [76] compares per-                    aspects exhaustively, but we hope that our work will be a stepping
ceptions of fairness and trustworthiness depending on whether the                       stone for further research.","We do by no means claim to examine these
[47, 49], also with mixed empirical findings.","decision maker is a person or an algorithm in the context of man-
agerial decisions.",2022-05-11 20:06:03+00:00,"""There Is Not Enough Information"": On the Effects of Explanations on Perceptions of Informational Fairness and Trustworthiness in Automated Decision-Making",cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Jakob Schoeffer'), arxiv.Result.Author('Niklas Kuehl'), arxiv.Result.Author('Yvette Machowski')]","Automated decision systems (ADS) are increasingly used for consequential
decision-making. These systems often rely on sophisticated yet opaque machine
learning models, which do not allow for understanding how a given decision was
arrived at. In this work, we conduct a human subject study to assess people's
perceptions of informational fairness (i.e., whether people think they are
given adequate information on and explanation of the process and its outcomes)
and trustworthiness of an underlying ADS when provided with varying types of
information about the system. More specifically, we instantiate an ADS in the
area of automated loan approval and generate different explanations that are
commonly used in the literature. We randomize the amount of information that
study participants get to see by providing certain groups of people with the
same explanations as others plus additional explanations. From our quantitative
analyses, we observe that different amounts of information as well as people's
(self-assessed) AI literacy significantly influence the perceived informational
fairness, which, in turn, positively relates to perceived trustworthiness of
the ADS. A comprehensive analysis of qualitative feedback sheds light on
people's desiderata for explanations, among which are (i) consistency (both
with people's expectations and across different explanations), (ii) disclosure
of monotonic relationships between features and outcome, and (iii)
actionability of recommendations."
6110,"https://arxiv.org/abs/2005.14165
infancy and thus demand further research and scientific insights.","Still, conversational approaches are in their                         CoRR abs/2005.14165 (2020).","In this work, we have shed some light on the limitations and chal-                       [5] Fred Davis.",2022-05-12 16:37:36+00:00,Conversational DevBots for Secure Programming: An Empirical Study on SKF Chatbot,cs.HC,"['cs.HC', 'cs.CR', 'cs.SE']","[arxiv.Result.Author('Catherine Tony'), arxiv.Result.Author('Mohana Balasubramanian'), arxiv.Result.Author('Nicolás E. Díaz Ferreyra'), arxiv.Result.Author('Riccardo Scandariato')]","Conversational agents or chatbots are widely investigated and used across
different fields including healthcare, education, and marketing. Still, the
development of chatbots for assisting secure coding practices is in its
infancy. In this paper, we present the results of an empirical study on SKF
chatbot, a software-development bot (DevBot) designed to answer queries about
software security. To the best of our knowledge, SKF chatbot is one of the very
few of its kind, thus a representative instance of conversational DevBots
aiding secure software development. In this study, we collect and analyse
empirical evidence on the effectiveness of SKF chatbot, while assessing the
needs and expectations of its users (i.e., software developers). Furthermore,
we explore the factors that may hinder the elaboration of more sophisticated
conversational security DevBots and identify features for improving the
efficiency of state-of-the-art solutions. All in all, our findings provide
valuable insights pointing towards the design of more context-aware and
personalized conversational DevBots for security engineering."
6179,"Moreover, our dataset fills an existing timely gap by facilitating the
creation of learning systems for better self-management of remote work meetings,
and further study of hypotheses regarding the impact of remote work on cognitive
load and affective states.","We
believe AVCAffe would be a challenging benchmark for the deep learning research
community given the inherent difficulty of classifying affect and cognitive load
in particular.","1 Introduction

Remote work, also referred to as ‘work from home’, has recently become the predominant employment
paradigm for many individuals in different sectors.",2022-05-13 20:55:25+00:00,AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work,cs.HC,"['cs.HC', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Pritam Sarkar'), arxiv.Result.Author('Aaron Posen'), arxiv.Result.Author('Ali Etemad')]","We introduce AVCAffe, the first Audio-Visual dataset consisting of Cognitive
load and Affect attributes. We record AVCAffe by simulating remote work
scenarios over a video-conferencing platform, where subjects collaborate to
complete a number of cognitively engaging tasks. AVCAffe is the largest
originally collected (not collected from the Internet) affective dataset in
English language. We recruit 106 participants from 18 different countries of
origin, spanning an age range of 18 to 57 years old, with a balanced
male-female ratio. AVCAffe comprises a total of 108 hours of video, equivalent
to more than 58,000 clips along with task-based self-reported ground truth
labels for arousal, valence, and cognitive load attributes such as mental
demand, temporal demand, effort, and a few others. We believe AVCAffe would be
a challenging benchmark for the deep learning research community given the
inherent difficulty of classifying affect and cognitive load in particular.
Moreover, our dataset fills an existing timely gap by facilitating the creation
of learning systems for better self-management of remote work meetings, and
further study of hypotheses regarding the impact of remote work on cognitive
load and affective states."
6180,"Affective computing (Picard 2000), which is an area
                                           tems for better self-management of remote work meetings,         that aims to investigate methods and algorithms for detection
                                           and further study of hypotheses regarding the impact of re-      (Sarkar et al.","Moreover, our dataset ﬁlls an ex-  by capturing arousal, valence, and other emotion-related fac-
                                           isting timely gap by facilitating the creation of learning sys-  tors.",2019; Kollias et al.,2022-05-13 20:55:25+00:00,AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work,cs.HC,"['cs.HC', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Pritam Sarkar'), arxiv.Result.Author('Aaron Posen'), arxiv.Result.Author('Ali Etemad')]","We introduce AVCAffe, the first Audio-Visual dataset consisting of Cognitive
load and Affect attributes. We record AVCAffe by simulating remote work
scenarios over a video-conferencing platform, where subjects collaborate to
complete a number of cognitively engaging tasks. AVCAffe is the largest
originally collected (not collected from the Internet) affective dataset in
English language. We recruit 106 participants from 18 different countries of
origin, spanning an age range of 18 to 57 years old, with a balanced
male-female ratio. AVCAffe comprises a total of 108 hours of video, equivalent
to more than 58,000 clips along with task-based self-reported ground truth
labels for arousal, valence, and cognitive load attributes such as mental
demand, temporal demand, effort, and a few others. We believe AVCAffe would be
a challenging benchmark for the deep learning research community given the
inherent difficulty of classifying affect and cognitive load in particular.
Moreover, our dataset fills an existing timely gap by facilitating the creation
of learning systems for better self-management of remote work meetings, and
further study of hypotheses regarding the impact of remote work on cognitive
load and affective states."
6300,"In this section, we discuss how our
findings and model suggest key directions for further research on the micro-work
ecosystem.","Unlike simple
annotation tasks reported in previous studies, we uncover a unique labeling design
model by workers with diverse backgrounds, established based on the connection with
the individual labeler, community, and machine.","6.1 Presence of the Loop
Our interviews and narrative analysis revealed that the individual labeler did not solely
perform their task.",2022-05-17 03:41:09+00:00,A Labeling Task Design for Supporting Algorithmic Needs: Facilitating Worker Diversity and Reducing AI Bias,cs.HC,['cs.HC'],"[arxiv.Result.Author('Jaeyoun You'), arxiv.Result.Author('Daemin Park'), arxiv.Result.Author('Joo-yeong Song'), arxiv.Result.Author('Bongwon Suh')]","Studies on supervised machine learning (ML) recommend involving workers from
various backgrounds in training dataset labeling to reduce algorithmic bias.
Moreover, sophisticated tasks for categorizing objects in images are necessary
to improve ML performance, further complicating micro-tasks. This study aims to
develop a task design incorporating the fair participation of people,
regardless of their specific backgrounds or task's difficulty. By collaborating
with 75 labelers from diverse backgrounds for 3 months, we analyzed workers'
log-data and relevant narratives to identify the task's hurdles and helpers.
The findings revealed that workers' decision-making tendencies varied depending
on their backgrounds. We found that the community that positively helps workers
and the machine's feedback perceived by workers could make people easily
engaged in works. Hence, ML's bias could be expectedly mitigated. Based on
these findings, we suggest an extended human-in-the-loop approach that connects
labelers, machines, and communities rather than isolating individual workers."
6428,"Research on the explanation of AI inferences frames
opportunities for further study of the influences of designs for workflow of human-AI collaboration, including

                 3
FAccT ’22, June 21–24, 2022, Seoul, Republic of Korea     R. Fogliato et al.","Thus we
expected that AI inferences presented at the same time as initial analysis would be more influential than when
the inferences are presented after an initial assessment.","altering the timing of AI-assistance and forcing users to spend more time on instances where AI inferences
present higher uncertainty [4, 10, 32, 67, 73].",2022-05-19 16:59:25+00:00,Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Riccardo Fogliato'), arxiv.Result.Author('Shreya Chappidi'), arxiv.Result.Author('Matthew Lungren'), arxiv.Result.Author('Michael Fitzke'), arxiv.Result.Author('Mark Parkinson'), arxiv.Result.Author('Diane Wilson'), arxiv.Result.Author('Paul Fisher'), arxiv.Result.Author('Eric Horvitz'), arxiv.Result.Author('Kori Inkpen'), arxiv.Result.Author('Besmira Nushi')]","Details of the designs and mechanisms in support of human-AI collaboration
must be considered in the real-world fielding of AI technologies. A critical
aspect of interaction design for AI-assisted human decision making are policies
about the display and sequencing of AI inferences within larger decision-making
workflows. We have a poor understanding of the influences of making AI
inferences available before versus after human review of a diagnostic task at
hand. We explore the effects of providing AI assistance at the start of a
diagnostic session in radiology versus after the radiologist has made a
provisional decision. We conducted a user study where 19 veterinary
radiologists identified radiographic findings present in patients' X-ray
images, with the aid of an AI tool. We employed two workflow configurations to
analyze (i) anchoring effects, (ii) human-AI team diagnostic performance and
agreement, (iii) time spent and confidence in decision making, and (iv)
perceived usefulness of the AI. We found that participants who are asked to
register provisional responses in advance of reviewing AI inferences are less
likely to agree with the AI regardless of whether the advice is accurate and,
in instances of disagreement with the AI, are less likely to seek the second
opinion of a colleague. These participants also reported the AI advice to be
less useful. Surprisingly, requiring provisional decisions on cases in advance
of the display of AI inferences did not lengthen the time participants spent on
the task. The study provides generalizable and actionable insights for the
deployment of clinical AI tools in human-in-the-loop systems and introduces a
methodology for studying alternative designs for human-AI collaboration. We
make our experimental platform available as open source to facilitate future
research on the influence of alternate designs on human-AI workflows."
6507,"There are several reasons why it is complex
to study the actual per hour return on work on OnlyFans: creators do many different kinds of work for their wage,
including networking, promotion off platform and content creation itself—however further research should strive to
investigate this in order to better support creators.","We note that we interviewed more than one creator who had genuinely reached
the level where content sales were steady enough to self-generate more than adequate income, but this had taken
enormous amounts of steady, creative, driven labor over many months.","Third, due to the very nature of the work itself, some of our participants found OnlyFans preferable to other work.",2022-05-20 19:59:51+00:00,"""Nudes? Shouldn't I charge for these?"" : Exploring What Motivates Content Creation on OnlyFans",cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Vaughn Hamilton'), arxiv.Result.Author('Ananta Soneji'), arxiv.Result.Author('Allison McDonald'), arxiv.Result.Author('Elissa Redmiles')]","Social media platforms are increasingly considering models to incentivize
creators to publish high quality content on their platforms. As a result,
social media content creation has transformed into a form of gig work for some
creators. In order to better design social media platforms to support this
labor, we need to understand professional creators' motivations. In this work,
we present a qualitative interview study of the motivations of $22$ U.S.
OnlyFans creators. OnlyFans is a subscription-based social media platform that
is unique in that it is primarily associated with sexual content (although it
is not marketed as such) and thus creators are positioned at the intersection
of professional content creation and sex work, exposing them to a unique set of
potential challenges. Beyond the typical motivations for pursuing other forms
of gig work (e.g., flexibility, autonomy) our findings highlight three key
factors explaining the rapid growth of OnlyFans despite the potential stigma of
sexual content creation: (1) societal visibility and mainstream acceptance of
OnlyFans, created through a combination of celebrity hype and the design of the
platform itself; (2) platform design: affordances for boundary setting with
clients, privacy from the public, and content archives, which together create a
labor environment participants viewed as better than other forms of gig work, a
natural avenue for sexual expression, and enabling monetization of existing
content, audiences, and skills; and (3) the pandemic, which led to both high
demand for immediate income while waiting for -- or after running out of --
unemployment benefits, and increased free time, which increased general demand
for pornographic content."
6634,"In the further study, we would like to conduct
                                                                the task setting which can not only matching to robot but
   The signiﬁcant difference between our work and previous      also to human.",virtual agent.,"research is not only the appearance of the virtual agent but
                                                                   Third, the limitation of the scoring of altruism is consid-
                                                                ered.",2022-05-24 05:27:15+00:00,Influence of perspective taking through robotic virtual agents on prosocial behavior,cs.HC,['cs.HC'],"[arxiv.Result.Author('Chenlin Hang'), arxiv.Result.Author('Tetsuo Ono'), arxiv.Result.Author('Seiji Yamada')]","Perspective taking, which allows people to imagine another's thinking and
goals, is known to be an effective method for promoting prosocial behaviors in
human-computer interactions. However, most of the previous studies have focused
on simulating human-human interactions in the real world by offering
participants experiences related to various moral tasks through the use of
human-like virtual agents. In this study, we investigated whether taking the
perspective of a different robot in a robot-altruistic task would influence the
social behaviors of participants in a dictator game. Our findings showed that
participants who watched the help-receiver view exhibited more altruistic
behaviors toward a robot than those who watched the help-provider view. We also
found that, after watching robots from two different viewpoints in the task,
participants did not change their behavior toward another participant."
6752,"To test this hypothesis, we select the player         further study in different visualization interests as Ph.D. students.","All of them are doing
player networks in area-b.","P1-P3

                                                                              8
   © 2022 IEEE.",2022-05-26 08:31:22+00:00,DGSVis: Visual Analysis of Hierarchical Snapshots in Dynamic Graph,cs.HC,"['cs.HC', 'cs.CV']",[arxiv.Result.Author('Baofeng Chang')],"Dynamic graph visualization attracts researchers' concentration as it
represents time-varying relationships between entities in multiple domains
(e.g., social media analysis, academic cooperation analysis, team sports
analysis). Integrating visual analytic methods is consequential in presenting,
comparing, and reviewing dynamic graphs. Even though dynamic graph
visualization is developed for many years, how to effectively visualize
large-scale and time-intensive dynamic graph data with subtle changes is still
challenging for researchers. To provide an effective analysis method for this
type of dynamic graph data, we propose a snapshot generation algorithm
involving Human-In-Loop to help users divide the dynamic graphs into
multi-granularity and hierarchical snapshots for further analysis. In addition,
we design a visual analysis prototype system (DGSVis) to assist users in
accessing the dynamic graph insights effectively. DGSVis integrates a graphical
operation interface to help users generate snapshots visually and
interactively. It is equipped with the overview and details for visualizing
hierarchical snapshots of the dynamic graph data. To illustrate the usability
and efficiency of our proposed methods for this type of dynamic graph data, we
introduce two case studies based on basketball player networks in a
competition. In addition, we conduct an evaluation and receive exciting
feedback from experienced visualization experts."
6753,"All of them are doing      the dynamic network has large-scale nodes and links, the matrix and
further study in different visualization interests as Ph.D. students.","She said “If
and one female (P2) to join our evaluation study.","P1-P3  scatter plot can no longer provide an effective overview for users.” She
are experienced in visual analysis and data mining.",2022-05-26 08:31:22+00:00,DGSVis: Visual Analysis of Hierarchical Snapshots in Dynamic Graph,cs.HC,"['cs.HC', 'cs.CV']","[arxiv.Result.Author('Baofeng Chang'), arxiv.Result.Author('Sujia Zhu'), arxiv.Result.Author('Qi Jiang'), arxiv.Result.Author('Wang Xia'), arxiv.Result.Author('Jingwei Tang'), arxiv.Result.Author('Lvhan Pan'), arxiv.Result.Author('Ronghua Liang'), arxiv.Result.Author('Guodao Sun')]","Dynamic graph visualization attracts researchers' concentration as it
represents time-varying relationships between entities in multiple domains
(e.g., social media analysis, academic cooperation analysis, team sports
analysis). Integrating visual analytic methods is consequential in presenting,
comparing, and reviewing dynamic graphs. Even though dynamic graph
visualization is developed for many years, how to effectively visualize
large-scale and time-intensive dynamic graph data with subtle changes is still
challenging for researchers. To provide an effective analysis method for this
type of dynamic graph data, we propose a snapshot generation algorithm
involving Human-In-Loop to help users divide the dynamic graphs into
multi-granularity and hierarchical snapshots for further analysis. In addition,
we design a visual analysis prototype system (DGSVis) to assist users in
accessing the dynamic graph insights effectively. DGSVis integrates a graphical
operation interface to help users generate snapshots visually and
interactively. It is equipped with the overview and details for visualizing
hierarchical snapshots of the dynamic graph data. To illustrate the usability
and efficiency of our proposed methods for this type of dynamic graph data, we
introduce two case studies based on basketball player networks in a
competition. In addition, we conduct an evaluation and receive exciting
feedback from experienced visualization experts."
6976,"The evolving landscape of platform labor warrants further study, as purveyors of this algorith-
mically mediated labor adapt employment and retaliation techniques to escape the scrutiny of
workers, journalists, and labor law.","There is also a feeling that they are starting from scratch, due to the clear gaps in U.S. labor law
when it comes to oﬀering protections for contracted workers, or allowing companies to misclassify
full-time workers as contracted or part-time workers.","We see possible connections between historical analysis of
mid-century union tactics, like data transparency, wage contestation, and strategic participation,
to the issues faced by contemporary platform-workers [33].",2022-05-31 18:18:47+00:00,Weaving Privacy and Power: On the Privacy Practices of Labor Organizers in the U.S. Technology Industry,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Sayash Kapoor'), arxiv.Result.Author('Matthew Sun'), arxiv.Result.Author('Mona Wang'), arxiv.Result.Author('Klaudia Jaźwińska'), arxiv.Result.Author('Elizabeth Anne Watkins')]","We investigate the privacy practices of labor organizers in the computing
technology industry and explore the changes in these practices as a response to
remote work. Our study is situated at the intersection of two pivotal shifts in
workplace dynamics: (a) the increase in online workplace communications due to
remote work, and (b) the resurgence of the labor movement and an increase in
collective action in workplaces -- especially in the tech industry, where this
phenomenon has been dubbed the tech worker movement. Through a series of
qualitative interviews with 29 tech workers involved in collective action, we
investigate how labor organizers assess and mitigate risks to privacy while
engaging in these actions. Among the most common risks that organizers
experienced are retaliation from their employer, lateral worker conflict,
emotional burnout, and the possibility of information about the collective
effort leaking to management. Depending on the nature and source of the risk,
organizers use a blend of digital security practices and community-based
mechanisms. We find that digital security practices are more relevant when the
threat comes from management, while community management and moderation are
central to protecting organizers from lateral worker conflict. Since labor
organizing is a collective rather than individual project, individual privacy
and collective privacy are intertwined, sometimes in conflict and often
mutually constitutive. Notions of privacy that solely center individuals are
often incompatible with the needs of organizers, who noted that safety in
numbers could only be achieved when workers presented a united front to
management. We conclude with design recommendations that can help create safer,
more secure and more private tools to better address the risks that organizers
face."
6977,"Though
developing a theoretical model for the relationship between individual and collective privacy is
outside the scope of this current work, we see it as a promising direction for further research
(Section 6.7), one that is aligned with prior research that frames privacy and security as collective
social and cultural practices [21].","Likewise, the existence of
the collective allows individuals to feel a sense of shared agency and provides a safe space for
venting, criticism, and getting to know their co-workers through informal conversation.","6.4 Limitations of modern privacy frameworks and comparison to other works

It may be inadequate to retroﬁt existing models of information security onto the myriad privacy
needs of labor organizers.",2022-05-31 18:18:47+00:00,Weaving Privacy and Power: On the Privacy Practices of Labor Organizers in the U.S. Technology Industry,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Sayash Kapoor'), arxiv.Result.Author('Matthew Sun'), arxiv.Result.Author('Mona Wang'), arxiv.Result.Author('Klaudia Jaźwińska'), arxiv.Result.Author('Elizabeth Anne Watkins')]","We investigate the privacy practices of labor organizers in the computing
technology industry and explore the changes in these practices as a response to
remote work. Our study is situated at the intersection of two pivotal shifts in
workplace dynamics: (a) the increase in online workplace communications due to
remote work, and (b) the resurgence of the labor movement and an increase in
collective action in workplaces -- especially in the tech industry, where this
phenomenon has been dubbed the tech worker movement. Through a series of
qualitative interviews with 29 tech workers involved in collective action, we
investigate how labor organizers assess and mitigate risks to privacy while
engaging in these actions. Among the most common risks that organizers
experienced are retaliation from their employer, lateral worker conflict,
emotional burnout, and the possibility of information about the collective
effort leaking to management. Depending on the nature and source of the risk,
organizers use a blend of digital security practices and community-based
mechanisms. We find that digital security practices are more relevant when the
threat comes from management, while community management and moderation are
central to protecting organizers from lateral worker conflict. Since labor
organizing is a collective rather than individual project, individual privacy
and collective privacy are intertwined, sometimes in conflict and often
mutually constitutive. Notions of privacy that solely center individuals are
often incompatible with the needs of organizers, who noted that safety in
numbers could only be achieved when workers presented a united front to
management. We conclude with design recommendations that can help create safer,
more secure and more private tools to better address the risks that organizers
face."
6978,"In an age where more aspects of our lives are becoming mediated by digital platforms, we
feel that recent changes in organizing practices deserve further study.","Some of these concern popula-
tions that our inclusion criteria did not cover, but that we believe may share similarities with our
results.","Other directions for future
work relate to particular phenomena related by our participants, such as organizing a platform-
based workplace, or increasing and more pervasive surveillance by employers.",2022-05-31 18:18:47+00:00,Weaving Privacy and Power: On the Privacy Practices of Labor Organizers in the U.S. Technology Industry,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Sayash Kapoor'), arxiv.Result.Author('Matthew Sun'), arxiv.Result.Author('Mona Wang'), arxiv.Result.Author('Klaudia Jaźwińska'), arxiv.Result.Author('Elizabeth Anne Watkins')]","We investigate the privacy practices of labor organizers in the computing
technology industry and explore the changes in these practices as a response to
remote work. Our study is situated at the intersection of two pivotal shifts in
workplace dynamics: (a) the increase in online workplace communications due to
remote work, and (b) the resurgence of the labor movement and an increase in
collective action in workplaces -- especially in the tech industry, where this
phenomenon has been dubbed the tech worker movement. Through a series of
qualitative interviews with 29 tech workers involved in collective action, we
investigate how labor organizers assess and mitigate risks to privacy while
engaging in these actions. Among the most common risks that organizers
experienced are retaliation from their employer, lateral worker conflict,
emotional burnout, and the possibility of information about the collective
effort leaking to management. Depending on the nature and source of the risk,
organizers use a blend of digital security practices and community-based
mechanisms. We find that digital security practices are more relevant when the
threat comes from management, while community management and moderation are
central to protecting organizers from lateral worker conflict. Since labor
organizing is a collective rather than individual project, individual privacy
and collective privacy are intertwined, sometimes in conflict and often
mutually constitutive. Notions of privacy that solely center individuals are
often incompatible with the needs of organizers, who noted that safety in
numbers could only be achieved when workers presented a united front to
management. We conclude with design recommendations that can help create safer,
more secure and more private tools to better address the risks that organizers
face."
6982,"[51] conducted an evalua-
tion on real-world web service, collected and released web      [2] M. D. Brindha, R. Jayaseelan, and S. Kadeswara, “Social media
service QoS data sets for further research.",Zheng et al.,"Another work              reigned by information or misinformation about covid-19: a phe-
[52] explored perceived quality from the user’s perspective           nomenological study,” SSRN Electronic Journal April, 2020.
for service selection and composition.",2022-05-30 02:14:23+00:00,An Empirical Study on How Well Do COVID-19 Information Dashboards Service Users' Information Needs,cs.HC,"['cs.HC', 'cs.SE']","[arxiv.Result.Author('Xinyan Li'), arxiv.Result.Author('Han Wang'), arxiv.Result.Author('Chunyang Chen'), arxiv.Result.Author('John Grundy')]","The ongoing COVID-19 pandemic highlights the importance of dashboards for
providing critical real-time information. In order to enable people to obtain
information in time and to understand complex statistical data, many developers
have designed and implemented public-oriented COVID-19 ""information dashboards""
during the pandemic. However, development often takes a long time and
developers are not clear about many people's information needs, resulting in
gaps between information needs and supplies. According to our empirical study
and observations with popular developed COVID-19 dashboards, this seriously
impedes information acquirement. Our study compares people's needs on Twitter
with existing information suppliers. We determine that despite the COVID-19
information that is currently on existing dashboards, people are also
interested in the relationship between COVID-19 and other viruses, the origin
of COVID-19, vaccine development, fake new about COVID-19, impact on women,
impact on school/university, and impact on business. Most of these have not yet
been well addressed. We also summarise the visualization and interaction
patterns commonly applied in dashboards, finding key patterns between data and
visualization as well as visualization and interaction. Our findings can help
developers to better optimize their dashboard to meet people's needs and make
improvements to future crisis management dashboard development."
7083,"Hence, further research is required towards designing kid-friendly
                                                                                                                                                                                                    primary task support for positive HBC.","We conjecture that such features, designed and fine-tuned
                                                                                                                                                                                                    on adult populations, might not be directly applicable to children.","Given the complexity of
                                                                                                                                                                                                    self-reporting, we could recommend a combination of indicative
                                                                                                                                                                                                    physical and interaction factors (Physical Self Aspect, Behavioral
                                                                                                                                                                                                    Self Aspect; see Section 3) for evaluating the effectiveness of fea-
                                                                                                                                                                                                    tures in interventions with children populations.",2022-06-03 07:25:41+00:00,12 Years of Self-tracking for Promoting Physical Activity from a User Diversity Perspective: Taking Stock and Thinking Ahead,cs.HC,['cs.HC'],"[arxiv.Result.Author('Sofia Yfantidou'), arxiv.Result.Author('Pavlos Sermpezis'), arxiv.Result.Author('Athena Vakali')]","Despite the indisputable personal and societal benefits of regular physical
activity, a large portion of the population does not follow the recommended
guidelines, harming their health and wellness. The World Health Organization
has called upon governments, practitioners, and researchers to accelerate
action to address the global prevalence of physical inactivity. To this end, an
emerging wave of research in ubiquitous computing has been exploring the
potential of interactive self-tracking technology in encouraging positive
health behavior change. Numerous findings indicate the benefits of
personalization and inclusive design regarding increasing the motivational
appeal and overall effectiveness of behavior change systems, with the ultimate
goal of empowering and facilitating people to achieve their goals. However,
most interventions still adopt a ""one-size-fits-all"" approach to their design,
assuming equal effectiveness for all system features in spite of individual and
collective user differences. To this end, we analyze a corpus of 12 years of
research in self-tracking technology for health behavior change, focusing on
physical activity, to identify those design elements that have proven most
effective in inciting desirable behavior across diverse population segments. We
then provide actionable recommendations for designing and evaluating behavior
change self-tracking technology based on age, gender, occupation, fitness, and
health condition. Finally, we engage in a critical commentary on the diversity
of the domain and discuss ethical concerns surrounding tailored interventions
and directions for moving forward."
7164,"These ﬁndings can provide guidance in selecting           driving simulator, we are able to further study the transition of
which object to highlight for the UI to improve the driver’s       the user’s SA on the object before and after the highlighting.","it can also decrease drivers’ SA of some objects at high trafﬁc    By controlling a speciﬁc object’s spatial characteristic in the
density.",SA while driving and monitoring SAE L2 or L3 AVs.,2022-06-06 03:23:34+00:00,Effects of Augmented-Reality-Based Assisting Interfaces on Drivers' Object-wise Situational Awareness in Highly Autonomous Vehicles,cs.HC,"['cs.HC', 'cs.AI', 'cs.RO']","[arxiv.Result.Author('Xiaofeng Gao'), arxiv.Result.Author('Xingwei Wu'), arxiv.Result.Author('Samson Ho'), arxiv.Result.Author('Teruhisa Misu'), arxiv.Result.Author('Kumar Akash')]","Although partially autonomous driving (AD) systems are already available in
production vehicles, drivers are still required to maintain a sufficient level
of situational awareness (SA) during driving. Previous studies have shown that
providing information about the AD's capability using user interfaces can
improve the driver's SA. However, displaying too much information increases the
driver's workload and can distract or overwhelm the driver. Therefore, to
design an efficient user interface (UI), it is necessary to understand its
effect under different circumstances. In this paper, we focus on a UI based on
augmented reality (AR), which can highlight potential hazards on the road. To
understand the effect of highlighting on drivers' SA for objects with different
types and locations under various traffic densities, we conducted an in-person
experiment with 20 participants on a driving simulator. Our study results show
that the effects of highlighting on drivers' SA varied by traffic densities,
object locations and object types. We believe our study can provide guidance in
selecting which object to highlight for the AR-based driver-assistance
interface to optimize SA for drivers driving and monitoring partially
autonomous vehicles."
7218,"A step-by-step analysis of students’ progress when solving pro-
gramming tasks and learning environments’ feedback may be an approach for
An Analysis of Feedback Types Used in Online Coding Exercises  11

further research in order to identify to what extent the oﬀered feedback matches
students’ informational needs.","However, designing fewer feedback options or buttons
with a one-to-one correspondence to feedback types seems unreasonable for learn-
ers in higher educational settings, as it may result in an increased cognitive
load [44,33,45].","Moreover, the investigated feedback types do not suﬃciently distinguish be-
tween general information that is provided and information that depends on
learners’ input.",2022-06-07 07:52:17+00:00,An Exploratory Analysis of Feedback Types Used in Online Coding Exercises,cs.HC,"['cs.HC', 'cs.CY']",[arxiv.Result.Author('Natalie Kiesler')],"Online coding environments can help support computing students gain
programming practice at their own pace. Especially informative feedback can be
beneficial during such self-guided, independent study phases. This research
aims at the identification of feedback types applied by CodingBat, Scratch and
Blockly. Tutoring feedback as coined by Susanne Narciss along with the
specification of subtypes by Keuning, Jeuring and Heeren constitute the
theoretical basis. Accordingly, the five categories of elaborated feedback
(knowledge about task requirements, knowledge about concepts, knowledge about
mistakes, knowledge about how to proceed, and knowledge about meta-cognition)
and their subtypes were utilized for the analysis of available feedback
options. The study revealed difficulties in identifying clear-cut boundaries
between feedback types, as the offered feedback usually integrates more than
one type or subtype. Moreover, currently defined feedback types do not
rigorously distinguish individualized and generic feedback. The lack of
granularity is also evident in the absence of subtypes relating to the
knowledge type of the task. The analysis thus has implications for the future
design and investigation of applied tutoring feedback. It encourages future
research on feedback types and their implementation in the context of
programming exercises to define feedback types that match the demands of novice
programmers."
7219,"To conclude,
an extension of the presented feedback typology to the context of programming
exercises is encouraged along with further research on their implementation and
eﬀects.","Therefore, the processes of designing and investigating informative tutoring
feedback both require a thorough consideration of feedback types and their im-
plementation (not to mention timing, and other design aspects [29]).","6 Limitations

This work is limited by its speciﬁc context (e.g., programming education) and the
selected coding exercises and tools.",2022-06-07 07:52:17+00:00,An Exploratory Analysis of Feedback Types Used in Online Coding Exercises,cs.HC,"['cs.HC', 'cs.CY']",[arxiv.Result.Author('Natalie Kiesler')],"Online coding environments can help support computing students gain
programming practice at their own pace. Especially informative feedback can be
beneficial during such self-guided, independent study phases. This research
aims at the identification of feedback types applied by CodingBat, Scratch and
Blockly. Tutoring feedback as coined by Susanne Narciss along with the
specification of subtypes by Keuning, Jeuring and Heeren constitute the
theoretical basis. Accordingly, the five categories of elaborated feedback
(knowledge about task requirements, knowledge about concepts, knowledge about
mistakes, knowledge about how to proceed, and knowledge about meta-cognition)
and their subtypes were utilized for the analysis of available feedback
options. The study revealed difficulties in identifying clear-cut boundaries
between feedback types, as the offered feedback usually integrates more than
one type or subtype. Moreover, currently defined feedback types do not
rigorously distinguish individualized and generic feedback. The lack of
granularity is also evident in the absence of subtypes relating to the
knowledge type of the task. The analysis thus has implications for the future
design and investigation of applied tutoring feedback. It encourages future
research on feedback types and their implementation in the context of
programming exercises to define feedback types that match the demands of novice
programmers."
7220,"A step-by-step analysis of students’ progress when solving pro-
gramming tasks and learning environments’ feedback may be an approach for
An Analysis of Feedback Types Used in Online Coding Exercises  11

further research in order to identify to what extent the oﬀered feedback matches
students’ informational needs.","However, designing fewer feedback options or buttons
with a one-to-one correspondence to feedback types seems unreasonable for learn-
ers in higher educational settings, as it may result in an increased cognitive
load [44,33,45].","Moreover, the investigated feedback types do not suﬃciently distinguish be-
tween general information that is provided and information that depends on
learners’ input.",2022-06-07 07:52:17+00:00,An Exploratory Analysis of Feedback Types Used in Online Coding Exercises,cs.HC,"['cs.HC', 'cs.CY']",[arxiv.Result.Author('Natalie Kiesler')],"Online coding environments can help support computing students gain
programming practice at their own pace. Especially informative feedback can be
beneficial during such self-guided, independent study phases. This research
aims at the identification of feedback types applied by CodingBat, Scratch and
Blockly. Tutoring feedback as coined by Susanne Narciss along with the
specification of subtypes by Keuning, Jeuring and Heeren constitute the
theoretical basis. Accordingly, the five categories of elaborated feedback
(knowledge about task requirements, knowledge about concepts, knowledge about
mistakes, knowledge about how to proceed, and knowledge about meta-cognition)
and their subtypes were utilized for the analysis of available feedback
options. The study revealed difficulties in identifying clear-cut boundaries
between feedback types, as the offered feedback usually integrates more than
one type or subtype. Moreover, currently defined feedback types do not
rigorously distinguish individualized and generic feedback. The lack of
granularity is also evident in the absence of subtypes relating to the
knowledge type of the task. The analysis thus has implications for the future
design and investigation of applied tutoring feedback. It encourages future
research on feedback types and their implementation in the context of
programming exercises to define feedback types that match the demands of novice
programmers."
7221,"To conclude,
an extension of the presented feedback typology to the context of programming
exercises is encouraged along with further research on their implementation and
eﬀects.","Therefore, the processes of designing and investigating informative tutoring
feedback both require a thorough consideration of feedback types and their im-
plementation (not to mention timing, and other design aspects [29]).","6 Limitations

This work is limited by its speciﬁc context (e.g., programming education) and the
selected coding exercises and tools.",2022-06-07 07:52:17+00:00,An Exploratory Analysis of Feedback Types Used in Online Coding Exercises,cs.HC,"['cs.HC', 'cs.CY']",[arxiv.Result.Author('Natalie Kiesler')],"Online coding environments can help support computing students gain
programming practice at their own pace. Especially informative feedback can be
beneficial during such self-guided, independent study phases. This research
aims at the identification of feedback types applied by CodingBat, Scratch and
Blockly. Tutoring feedback as coined by Susanne Narciss along with the
specification of subtypes by Keuning, Jeuring and Heeren constitute the
theoretical basis. Accordingly, the five categories of elaborated feedback
(knowledge about task requirements, knowledge about concepts, knowledge about
mistakes, knowledge about how to proceed, and knowledge about meta-cognition)
and their subtypes were utilized for the analysis of available feedback
options. The study revealed difficulties in identifying clear-cut boundaries
between feedback types, as the offered feedback usually integrates more than
one type or subtype. Moreover, currently defined feedback types do not
rigorously distinguish individualized and generic feedback. The lack of
granularity is also evident in the absence of subtypes relating to the
knowledge type of the task. The analysis thus has implications for the future
design and investigation of applied tutoring feedback. It encourages future
research on feedback types and their implementation in the context of
programming exercises to define feedback types that match the demands of novice
programmers."
7231,"we employed a widely available commercially available hardware and
Another effect observable in the results was a gradual accumulation of        software solution, we would also hope that further researchers could
some exhaustion across the week.","Since
overcame the initial expectations that people had previously about VR.",We observed this effect in some of           add to the data set by replicating the study.,2022-06-07 11:21:18+00:00,Quantifying the Effects of Working in VR for One Week,cs.HC,"['cs.HC', 'I.3.7']","[arxiv.Result.Author('Verena Biener Snehanjali Kalamkar'), arxiv.Result.Author('Negar Nouri'), arxiv.Result.Author('Eyal Ofek'), arxiv.Result.Author('Michel Pahud'), arxiv.Result.Author('John J. Dudley'), arxiv.Result.Author('Jinghui Hu'), arxiv.Result.Author('Per Ola Kristensson'), arxiv.Result.Author('Maheshya Weerasinghe'), arxiv.Result.Author('Klen Čopič Pucihar'), arxiv.Result.Author('Matjaž Kljun'), arxiv.Result.Author('Stephan Streuber'), arxiv.Result.Author('Jens Grubert')]","Virtual Reality (VR) provides new possibilities for modern knowledge work.
However, the potential advantages of virtual work environments can only be used
if it is feasible to work in them for an extended period of time. Until now,
there are limited studies of long-term effects when working in VR. This paper
addresses the need for understanding such long-term effects. Specifically, we
report on a comparative study (n=16), in which participants were working in VR
for an entire week -- for five days, eight hours each day -- as well as in a
baseline physical desktop environment. This study aims to quantify the effects
of exchanging a desktop-based work environment with a VR-based environment.
Hence, during this study, we do not present the participants with the best
possible VR system but rather a setup delivering a comparable experience to
working in the physical desktop environment. The study reveals that, as
expected, VR results in significantly worse ratings across most measures. Among
other results, we found concerning levels of simulator sickness, below average
usability ratings and two participants dropped out on the first day using VR,
due to migraine, nausea and anxiety. Nevertheless, there is some indication
that participants gradually overcame negative first impressions and initial
discomfort. Overall, this study helps lay the groundwork for subsequent
research, by clearly highlighting current shortcomings and identifying
opportunities for improving the experience of working in VR."
7232,"We hope this work will stimulate further research investigating
user ratings.","[59], there can be            and identifying opportunities for improving the experience of working
a disconnect between objective physiological effects and subjective           in VR.","In terms of eye strain, Wille et al.",2022-06-07 11:21:18+00:00,Quantifying the Effects of Working in VR for One Week,cs.HC,"['cs.HC', 'I.3.7']","[arxiv.Result.Author('Verena Biener Snehanjali Kalamkar'), arxiv.Result.Author('Negar Nouri'), arxiv.Result.Author('Eyal Ofek'), arxiv.Result.Author('Michel Pahud'), arxiv.Result.Author('John J. Dudley'), arxiv.Result.Author('Jinghui Hu'), arxiv.Result.Author('Per Ola Kristensson'), arxiv.Result.Author('Maheshya Weerasinghe'), arxiv.Result.Author('Klen Čopič Pucihar'), arxiv.Result.Author('Matjaž Kljun'), arxiv.Result.Author('Stephan Streuber'), arxiv.Result.Author('Jens Grubert')]","Virtual Reality (VR) provides new possibilities for modern knowledge work.
However, the potential advantages of virtual work environments can only be used
if it is feasible to work in them for an extended period of time. Until now,
there are limited studies of long-term effects when working in VR. This paper
addresses the need for understanding such long-term effects. Specifically, we
report on a comparative study (n=16), in which participants were working in VR
for an entire week -- for five days, eight hours each day -- as well as in a
baseline physical desktop environment. This study aims to quantify the effects
of exchanging a desktop-based work environment with a VR-based environment.
Hence, during this study, we do not present the participants with the best
possible VR system but rather a setup delivering a comparable experience to
working in the physical desktop environment. The study reveals that, as
expected, VR results in significantly worse ratings across most measures. Among
other results, we found concerning levels of simulator sickness, below average
usability ratings and two participants dropped out on the first day using VR,
due to migraine, nausea and anxiety. Nevertheless, there is some indication
that participants gradually overcame negative first impressions and initial
discomfort. Overall, this study helps lay the groundwork for subsequent
research, by clearly highlighting current shortcomings and identifying
opportunities for improving the experience of working in VR."
7233,"we employed a widely available commercially available hardware and
Another effect observable in the results was a gradual accumulation of        software solution, we would also hope that further researchers could
some exhaustion across the week.","Since
overcame the initial expectations that people had previously about VR.",We observed this effect in some of           add to the data set by replicating the study.,2022-06-07 11:21:18+00:00,Quantifying the Effects of Working in VR for One Week,cs.HC,"['cs.HC', 'I.3.7']","[arxiv.Result.Author('Verena Biener'), arxiv.Result.Author('Snehanjali Kalamkar'), arxiv.Result.Author('Negar Nouri'), arxiv.Result.Author('Eyal Ofek'), arxiv.Result.Author('Michel Pahud'), arxiv.Result.Author('John J. Dudley'), arxiv.Result.Author('Jinghui Hu'), arxiv.Result.Author('Per Ola Kristensson'), arxiv.Result.Author('Maheshya Weerasinghe'), arxiv.Result.Author('Klen Čopič Pucihar'), arxiv.Result.Author('Matjaž Kljun'), arxiv.Result.Author('Stephan Streuber'), arxiv.Result.Author('Jens Grubert')]","Virtual Reality (VR) provides new possibilities for modern knowledge work.
However, the potential advantages of virtual work environments can only be used
if it is feasible to work in them for an extended period of time. Until now,
there are limited studies of long-term effects when working in VR. This paper
addresses the need for understanding such long-term effects. Specifically, we
report on a comparative study (n=16), in which participants were working in VR
for an entire week -- for five days, eight hours each day -- as well as in a
baseline physical desktop environment. This study aims to quantify the effects
of exchanging a desktop-based work environment with a VR-based environment.
Hence, during this study, we do not present the participants with the best
possible VR system but rather a setup delivering a comparable experience to
working in the physical desktop environment. The study reveals that, as
expected, VR results in significantly worse ratings across most measures. Among
other results, we found concerning levels of simulator sickness, below average
usability ratings and two participants dropped out on the first day using VR,
due to migraine, nausea and anxiety. Nevertheless, there is some indication
that participants gradually overcame negative first impressions and initial
discomfort. Overall, this study helps lay the groundwork for subsequent
research, by clearly highlighting current shortcomings and identifying
opportunities for improving the experience of working in VR."
7234,"We hope this work will stimulate further research investigating
user ratings.","[59], there can be            and identifying opportunities for improving the experience of working
a disconnect between objective physiological effects and subjective           in VR.","In terms of eye strain, Wille et al.",2022-06-07 11:21:18+00:00,Quantifying the Effects of Working in VR for One Week,cs.HC,"['cs.HC', 'I.3.7']","[arxiv.Result.Author('Verena Biener'), arxiv.Result.Author('Snehanjali Kalamkar'), arxiv.Result.Author('Negar Nouri'), arxiv.Result.Author('Eyal Ofek'), arxiv.Result.Author('Michel Pahud'), arxiv.Result.Author('John J. Dudley'), arxiv.Result.Author('Jinghui Hu'), arxiv.Result.Author('Per Ola Kristensson'), arxiv.Result.Author('Maheshya Weerasinghe'), arxiv.Result.Author('Klen Čopič Pucihar'), arxiv.Result.Author('Matjaž Kljun'), arxiv.Result.Author('Stephan Streuber'), arxiv.Result.Author('Jens Grubert')]","Virtual Reality (VR) provides new possibilities for modern knowledge work.
However, the potential advantages of virtual work environments can only be used
if it is feasible to work in them for an extended period of time. Until now,
there are limited studies of long-term effects when working in VR. This paper
addresses the need for understanding such long-term effects. Specifically, we
report on a comparative study (n=16), in which participants were working in VR
for an entire week -- for five days, eight hours each day -- as well as in a
baseline physical desktop environment. This study aims to quantify the effects
of exchanging a desktop-based work environment with a VR-based environment.
Hence, during this study, we do not present the participants with the best
possible VR system but rather a setup delivering a comparable experience to
working in the physical desktop environment. The study reveals that, as
expected, VR results in significantly worse ratings across most measures. Among
other results, we found concerning levels of simulator sickness, below average
usability ratings and two participants dropped out on the first day using VR,
due to migraine, nausea and anxiety. Nevertheless, there is some indication
that participants gradually overcame negative first impressions and initial
discomfort. Overall, this study helps lay the groundwork for subsequent
research, by clearly highlighting current shortcomings and identifying
opportunities for improving the experience of working in VR."
7261,"Limitations of IoT devices and communication in
SO can be also a subject for further study.",Artificial intelligence coupled with IoT may address the SDGs goals.,"However, to our knowledge, this is the first research attempt in shading lights
of IoT based SO in achieving SDGs.",2022-06-07 20:14:19+00:00,Toward IoT enabled smart offices: Achieving Sustainable Development Goals,cs.HC,['cs.HC'],"[arxiv.Result.Author('Syeda Nishat Tasnim'), arxiv.Result.Author('Md Taimur Ahad')]","Despite research advocating the Internet of Things (IoT) as an effective
in-office monitoring system, little research has presented societal and climate
centric discussions. Whereas the United Nations (UN) and other development
agencies concerned with climate impact, are advocating transformative actions
towards smart cities, very little research in the IoT domain analyzes the
advantages of IoT in achieving sustainable development goals (SDGs) to fill
this gap. In this study, a smart office (SO) was developed in a Cisco packet
tracer. We then presented the SO through the lens of SDGs. We suggest that SOs
support targets mentioned in Goal 6, 7, 8, 9, 11 and 12 of the SDGs. This
research is crucial - both for developing and developed economies, as we move
toward industrialization, while ignoring the adverse impacts of
industrialization. This work is expected to provide a pathway with
technological innovation toward a more sustainable world for IT practitioners,
governments and development agencies."
7652,"We hope that our results will contribute to the
efﬁciency of crowd ﬁnancing and advance further research on mechanisms of social signaling, including outside of
crowdfunding.","With this, our ﬁndings not only provide
novel insights into an essential issue in online capital allocation, but also an open problem in understanding the link
between mechanisms of social inﬂuence and success on online platforms.","Acknowledgments

This work was supported by the U.S. National Science Foundation under Grant No.",2022-06-14 23:51:10+00:00,Hidden Influences of Crowd Behavior in Crowdfunding: An Experimental Study,cs.HC,"['cs.HC', 'J.4']","[arxiv.Result.Author('Henry K. Dambanemuya'), arxiv.Result.Author('Eunseo Choi'), arxiv.Result.Author('Darren Gergle'), arxiv.Result.Author('Emőke-Ágnes Horvát')]","Crowdfunding continues to transform financing opportunities for many across
the globe. While extensive research has explored factors related to fundraising
success, less is known about the social signaling mechanisms that lead
potential contributors to fund a project. Existing large-scale observational
studies point to non-straightforward characteristics of prior contributions
(aka ""crowd signals"") that forecast further contributions to a project, albeit
without theoretical support for their effectiveness in predicting fundraising
success. We translate empirical crowd signals based on variations in the
amounts and timings of contributions into mock contribution scenarios to
scrutinize the influence of essential signals on contributors' decisions to
fund. We conduct two experiments with 1,250 online participants. The first
experiment investigates whether high crowd signals, i.e., contributions of
varying amounts arriving at unequally spaced time intervals, are making people
more likely to contribute to a crowdfunding project. The second experiment
further examines the effect of basic competition on the role of the crowd
signals. Across both, we observe that high crowd signals attract 19.2% more
contributors than low signals. These findings are robust to different project
types, fundraising goals, participants' interest level in the projects, their
altruistic attitudes, and susceptibility to social influence. Participants'
unguided, post-hoc reflections about the reasons behind their choice to fund
revealed that most were unaware of their reliance on any crowd signals and
instead attributed their decision to nonexistent differences in project
descriptions. These results point to the power of crowd signals unbeknownst to
those affected by them and lay the groundwork for theory-building, specifically
in relation to the essential signaling that is happening on online platforms."
7839,"Section 4 summarizes and discusses
the gained results, before Section 5 concludes and provides some directions for
further research.","Then, Section 3 describes our methodologi-
cal approach including our sampling strategy.","2 Theoretical Framework and Related Work

Intrinsic motivation is critical for sustaining physical activity due to it being
perceived as enjoyable [27].",2022-06-20 07:55:48+00:00,Keep on Running! An Analysis of Running Tracking Application Features and their Potential Impact on Recreational Runner's Intrinsic Motivation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Dorothea Gute'), arxiv.Result.Author('Stephan Schlögl'), arxiv.Result.Author('Aleksander Groth')]","Physical activity is known to help improve and maintain one's health. In
particular, recreational running has become increasingly popular in recent
years. Yet, lack of motivation often interferes with people's routines and thus
may prohibit regular uptake. This is where running tracking applications are
frequently used to overcome one's weaker self and offer support. While
technology artifacts, such as sport watches or running applications, usually
count as extrinsic drivers, they can also impact one's intrinsic motivation
levels. The aim of this study was thus to investigate upon the motivational
impact of distinct features found within applications specifically used for
running. Focusing on the 22 most famous running applications, a
semi-structured, problem-centered interview study with $n=15$ recreational
runners showed that intrinsic motivation is stimulated from diverting runners,
aiding them in their goal setting, decreasing their efforts, improving and
sharing their run performance, allowing them to receive acknowledgements, as
well as providing them with guidance, information, and an overall variety in
their training routines."
7892,"Techniques for caching and indexing vir-
From the above discussions, we have the following observa-       tual environments (e.g., [67, 68]) need further study to scale
tions of the data-rich metaverse:                                to the large number of users.","CHALLENGES FROM DATA-CENTRIC                                  attention, including designing database engines for games
     PERSPECTIVES                                                workloads and methods to guarantee consistency across mul-
                                                                 tiple virtual views.","• There is a large amount of data/information generated      For the rest of this section, we shall focus on challenges that
       within the metaverse.",2022-06-14 14:21:33+00:00,"Sense The Physical, Walkthrough The Virtual, Manage The Metaverse: A Data-centric Perspective",cs.HC,"['cs.HC', 'cs.AI', 'cs.CV', 'cs.DB', 'cs.DC']","[arxiv.Result.Author('Beng Chin Ooi'), arxiv.Result.Author('Kian-Lee Tan'), arxiv.Result.Author('Anthony Tung'), arxiv.Result.Author('Gang Chen'), arxiv.Result.Author('Mike Zheng Shou'), arxiv.Result.Author('Xiaokui Xiao'), arxiv.Result.Author('Meihui Zhang')]","In the Metaverse, the physical space and the virtual space co-exist, and
interact simultaneously. While the physical space is virtually enhanced with
information, the virtual space is continuously refreshed with real-time,
real-world information. To allow users to process and manipulate information
seamlessly between the real and digital spaces, novel technologies must be
developed. These include smart interfaces, new augmented realities, efficient
storage and data management and dissemination techniques. In this paper, we
first discuss some promising co-space applications. These applications offer
experiences and opportunities that neither of the spaces can realize on its
own. We then argue that the database community has much to offer to this field.
Finally, we present several challenges that we, as a community, can contribute
towards managing the Metaverse."
7893,"Some of these are static (e.g., maps,   environments (e.g., [70], [71]) need further study to scale to
      quantity-on-hand), while others are dynamic (e.g., loca-      the large number of users.","Techniques for caching and indexing virtual
      within the metaverse.","tions, sensor data) and frequently changing.",2022-06-14 14:21:33+00:00,The Metaverse Data Deluge: What Can We Do About It?,cs.HC,"['cs.HC', 'cs.AI', 'cs.CV', 'cs.DB', 'cs.DC']","[arxiv.Result.Author('Beng Chin Ooi'), arxiv.Result.Author('Gang Chen'), arxiv.Result.Author('Mike Zheng Shou'), arxiv.Result.Author('Kian-Lee Tan'), arxiv.Result.Author('Anthony Tung'), arxiv.Result.Author('Xiaokui Xiao'), arxiv.Result.Author('James Wei Luen Yip'), arxiv.Result.Author('Meihui Zhang')]","In the Metaverse, the physical space and the virtual space co-exist, and
interact simultaneously. While the physical space is virtually enhanced with
information, the virtual space is continuously refreshed with real-time,
real-world information. To allow users to process and manipulate information
seamlessly between the real and digital spaces, novel technologies must be
developed. These include smart interfaces, new augmented realities, efficient
storage and data management and dissemination techniques. In this paper, we
first discuss some promising co-space applications. These applications offer
opportunities that neither of the spaces can realize on its own. We then
discuss challenges. Finally, we discuss and envision what are likely to be
required from the database and system perspectives."
8024,"We discuss key
                                        research problems in each category and suggest new opportunities to encourage further research in the related domain.","The taxonomy aims to
                                        provide an overview of current research and development in the automation involvement of narrative visualization tools.","Index Terms—Data Visualization; Automatic Visualization; Narrative Visualization; Design Space; Authoring Tools; Survey

                                                                                                        !",2022-06-24 07:25:28+00:00,How Does Automation Shape the Process of Narrative Visualization: A Survey on Tools,cs.HC,['cs.HC'],"[arxiv.Result.Author('Qing Chen'), arxiv.Result.Author('Shixiong Cao'), arxiv.Result.Author('Jiazhe Wang'), arxiv.Result.Author('Nan Cao')]","In recent years, narrative visualization has gained a lot of attention.
Researchers have proposed different design spaces for various narrative
visualization types and scenarios to facilitate the creation process. As users'
needs grow and automation technologies advance, more and more tools have been
designed and developed. In this paper, we surveyed 122 papers and tools to
study how automation can progressively engage in the visualization design and
narrative process. By investigating the narrative strengths and the drawing
efforts of various visualizations, we created a two-dimensional coordinate to
map different visualization types. Our resulting taxonomy is organized by the
seven types of narrative visualization on the +x-axis of the coordinate and the
four automation levels (i.e., design space, authoring tool, AI-supported tool,
and AI-generator tool) we identified from the collected work. The taxonomy aims
to provide an overview of current research and development in the automation
involvement of narrative visualization tools. We discuss key research problems
in each category and suggest new opportunities to encourage further research in
the related domain."
8213,"The sensor and EMA survey data are made public

409 timestamps were generated using the push button on the          to facilitate further research1.","In total,       settings.","We also share code2 that can

E4, and we labeled the sensor data around the generated             be used to process the sensor data and extract meaningful

timestamps as belonging to the stress class.",2022-06-14 20:39:02+00:00,ADARP: A Multi Modal Dataset for Stress and Alcohol Relapse Quantification in Real Life Setting,cs.HC,"['cs.HC', 'eess.SP']","[arxiv.Result.Author('Ramesh Kumar Sah'), arxiv.Result.Author('Michael McDonell'), arxiv.Result.Author('Patricia Pendry'), arxiv.Result.Author('Sara Parent'), arxiv.Result.Author('Hassan Ghasemzadeh'), arxiv.Result.Author('Michael J Cleveland')]","Stress detection and classification from wearable sensor data is an emerging
area of research with significant implications for individuals' physical and
mental health. In this work, we introduce a new dataset, ADARP, which contains
physiological data and self-report outcomes collected in real-world ambulatory
settings involving individuals diagnosed with alcohol use disorders. We
describe the user study, present details of the dataset, establish the
significant correlation between physiological data and self-reported outcomes,
demonstrate stress classification, and make our dataset public to facilitate
research."
8248,"First, literature reviews are a useful way to identify research trends and unearth
new directions for research communities, and have been used to this effect to further research on
the sharing economy [26], HCI for development [23], and sustainable HCI [27], among other areas.","Reviews in HCI and Social Computing

Literature reviews are not uncommon in HCI and social computing venues, and can provide insight
into both the knowledge built by a research community as well as the practices used to construct
this knowledge.","Second, literature reviews can also help develop clarity around methods and direct best practices
for a research community.",2022-06-30 06:03:55+00:00,"Privacy Research with Marginalized Groups: What We Know, What's Needed, and What's Next",cs.HC,"['cs.HC', 'J.4; K.4']","[arxiv.Result.Author('Shruti Sannon'), arxiv.Result.Author('Andrea Forte')]","People who are marginalized experience disproportionate harms when their
privacy is violated. Meeting their needs is vital for developing equitable and
privacy-protective technologies. In response, research at the intersection of
privacy and marginalization has acquired newfound urgency in the HCI and social
computing community. In this literature review, we set out to understand how
researchers have investigated this area of study. What topics have been
examined, and how? What are the key findings and recommendations? And,
crucially, where do we go from here? Based on a review of papers on privacy and
marginalization published between 2010-2020 across HCI, Communication, and
Privacy-focused venues, we make three main contributions: (1) we identify key
themes in existing work and introduce the Privacy Responses and Costs framework
to describe the tensions around protecting privacy in marginalized contexts,
(2) we identify understudied research topics (e.g., race) and other avenues for
future work, and (3) we characterize trends in research practices, including
the under-reporting of important methodological choices, and provide
suggestions for establishing shared best practices for this growing research
area."
8249,"We also uncovered topics that need further study, such as race, the structural aspects of marginal-
ization, and the role of policy, as well as the potential to use more diverse methods in our practices,
including quantitative and participatory methods.","28  Shruti Sannon and Andrea Forte

introduced the Privacy Responses and Costs framework to reflect the range of privacy responses
people enact and the costs and consequences of these responses to marginalized groups.","Finally, given our focus on marginalized groups,
we see a need to discuss and report research practices in greater detail, particularly around the
ethical considerations of our work, and we put forth some suggestions for establishing shared best
practices to do so.",2022-06-30 06:03:55+00:00,"Privacy Research with Marginalized Groups: What We Know, What's Needed, and What's Next",cs.HC,"['cs.HC', 'J.4; K.4']","[arxiv.Result.Author('Shruti Sannon'), arxiv.Result.Author('Andrea Forte')]","People who are marginalized experience disproportionate harms when their
privacy is violated. Meeting their needs is vital for developing equitable and
privacy-protective technologies. In response, research at the intersection of
privacy and marginalization has acquired newfound urgency in the HCI and social
computing community. In this literature review, we set out to understand how
researchers have investigated this area of study. What topics have been
examined, and how? What are the key findings and recommendations? And,
crucially, where do we go from here? Based on a review of papers on privacy and
marginalization published between 2010-2020 across HCI, Communication, and
Privacy-focused venues, we make three main contributions: (1) we identify key
themes in existing work and introduce the Privacy Responses and Costs framework
to describe the tensions around protecting privacy in marginalized contexts,
(2) we identify understudied research topics (e.g., race) and other avenues for
future work, and (3) we characterize trends in research practices, including
the under-reporting of important methodological choices, and provide
suggestions for establishing shared best practices for this growing research
area."
8273,"For this ResNet152 architecture with these sensor inputs it was determined that the most
useful directions for further research would be adapting the dataset labelling protocol,
increasing the number of dataset samples and subjects, and using frequency domain
processing.",tying shoelaces) and falls.,"By improving the quality of the data we could increase the model’s ability to
generalise, thus implying such research directions could produce less complex models
with similar/better AUC scores.",2022-06-28 12:49:25+00:00,Smart Application for Fall Detection Using Wearable ECG & Accelerometer Sensors,cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('Harry Wixley')],"Timely and reliable detection of falls is a large and rapidly growing field
of research due to the medical and financial demand of caring for a constantly
growing elderly population. Within the past 2 decades, the availability of
high-quality hardware (high-quality sensors and AI microchips) and software
(machine learning algorithms) technologies has served as a catalyst for this
research by giving developers the capabilities to develop such systems. This
study developed multiple application components in order to investigate the
development challenges and choices for fall detection systems, and provide
materials for future research. The smart application developed using this
methodology was validated by the results from fall detection modelling
experiments and model mobile deployment. The best performing model overall was
the ResNet152 on a standardised, and shuffled dataset with a 2s window size
which achieved 92.8% AUC, 7.28% sensitivity, and 98.33% specificity. Given
these results it is evident that accelerometer and ECG sensors are beneficial
for fall detection, and allow for the discrimination between falls and other
activities. This study leaves a significant amount of room for improvement due
to weaknesses identified in the resultant dataset. These improvements include
using a labelling protocol for the critical phase of a fall, increasing the
number of dataset samples, improving the test subject representation, and
experimenting with frequency domain preprocessing."
8412,"Still,
further research is necessary to determine whether the reported privacy behaviour outperforms the actual one across
the three user categories.","Our findings suggest traces of this paradox
among SO users, especially when contrasting the outcome of the survey analysis with that of the users’ profiles.","It would be of special interest to understand whether and up to which extent is the privacy
paradox manifested among SO users, and how does it relate to their overall engagement.",2022-07-04 15:52:24+00:00,Cybersecurity Discussions in Stack Overflow: A Developer-Centred Analysis of Engagement and Self-Disclosure Behaviour,cs.HC,"['cs.HC', 'cs.CR', 'cs.SE', 'cs.SI']","[arxiv.Result.Author('Nicolás E. Díaz Ferreyra'), arxiv.Result.Author('Melina Vidoni'), arxiv.Result.Author('Maritta Heisel'), arxiv.Result.Author('Riccardo Scandariato')]","Stack Overflow (SO) is a popular platform among developers seeking advice on
various software-related topics, including privacy and security. As for many
knowledge-sharing websites, the value of SO depends largely on users'
engagement, namely their willingness to answer, comment or post technical
questions. Still, many of these questions (including cybersecurity-related
ones) remain unanswered, putting the site's relevance and reputation into
question. Hence, it is important to understand users' participation in privacy
and security discussions to promote engagement and foster the exchange of such
expertise. Objective: Based on prior findings on online social networks, this
work elaborates on the interplay between users' engagement and their privacy
practices in SO. Particularly, it analyses developers' self-disclosure
behaviour regarding profile visibility and their involvement in discussions
related to privacy and security. Method: We followed a mixed-methods approach
by (i) analysing SO data from 1239 cybersecurity-tagged questions along with
7048 user profiles, and (ii) conducting an anonymous online survey (N=64).
Results: About 33% of the questions we retrieved had no answer, whereas more
than 50% had no accepted answer. We observed that ""proactive"" users tend to
disclose significantly less information in their profiles than ""reactive"" and
""unengaged"" ones. However, no correlations were found between these engagement
categories and privacy-related constructs such as Perceived Control or General
Privacy Concerns. Implications: These findings contribute to (i) a better
understanding of developers' engagement towards privacy and security topics,
and (ii) to shape strategies promoting the exchange of cybersecurity expertise
in SO."
8485,"We provide recommendations on privacy-supporting system
                                           design and suggest directions for further research.","We discuss the implications for user privacy
                                           and self-presentation.","KEYWORDS
                                           notiﬁcations; information disclosure; sharing attitudes; curiosity; cognitive style;
                                           aﬀective state

                                       1.",2022-07-05 20:39:02+00:00,Informing Users: Effects of Notification Properties and User Characteristics on Sharing Attitudes,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Yefim Shulman'), arxiv.Result.Author('Agnieszka Kitkowska'), arxiv.Result.Author('Joachim Meyer')]","Information sharing on social networks is ubiquitous, intuitive, and
occasionally accidental. However, people may be unaware of the potential
negative consequences of disclosures, such as reputational damages. Yet, people
use social networks to disclose information about themselves or others, advised
only by their own experiences and the context-invariant informed consent
mechanism. In two online experiments (N=515 and N=765), we investigated how to
aid informed sharing decisions and associate them with the potential outcomes
via notifications. Based on the measurements of sharing attitudes, our results
showed that the effectiveness of informing the users via notifications may
depend on the timing, content, and layout of the notifications, as well as on
the users' curiosity and rational cognitive style, motivating information
processing. Furthermore, positive emotions may result in disregard of important
information. We discuss the implications for user privacy and
self-presentation. We provide recommendations on privacy-supporting system
design and suggest directions for further research."
8486,"On the other
hand, when the notiﬁcation did not alert participants to consider their Privacy and
that of the others, the iconized notiﬁcation may have been more visually appealing
than the message composed as Simple text, resulting in a more relaxed preference to
conﬁrm posting with others (this mere suggestion requires further research, perhaps
measuring how information layout may aﬀect trust and privacy concerns).","When the notiﬁcation
contained Privacy-related information and the nature of the information was more
conventional (Traveling, rather than Gambling or Drinking), the iconized message
may have directed participants’ attention to the privacy-related implications of their
action more than the Neutral message containing generic information.","This ﬁnding
(T iming × Content × Suggested post variant) supports our conjecture from the ﬁrst
experiment that participants may be focusing their attention on the available layouts,
depending on the speciﬁc context of the interaction, i.e., the suggested post variant in
our case.",2022-07-05 20:39:02+00:00,Informing Users: Effects of Notification Properties and User Characteristics on Sharing Attitudes,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Yefim Shulman'), arxiv.Result.Author('Agnieszka Kitkowska'), arxiv.Result.Author('Joachim Meyer')]","Information sharing on social networks is ubiquitous, intuitive, and
occasionally accidental. However, people may be unaware of the potential
negative consequences of disclosures, such as reputational damages. Yet, people
use social networks to disclose information about themselves or others, advised
only by their own experiences and the context-invariant informed consent
mechanism. In two online experiments (N=515 and N=765), we investigated how to
aid informed sharing decisions and associate them with the potential outcomes
via notifications. Based on the measurements of sharing attitudes, our results
showed that the effectiveness of informing the users via notifications may
depend on the timing, content, and layout of the notifications, as well as on
the users' curiosity and rational cognitive style, motivating information
processing. Furthermore, positive emotions may result in disregard of important
information. We discuss the implications for user privacy and
self-presentation. We provide recommendations on privacy-supporting system
design and suggest directions for further research."
8487,"Lack of evidence for the role of the Ex-
periential cognitive style should not discourage further research.","This can be done by
ensuring that all the needed information is accessible in an intelligible format (for
instance, using comic-based designs (Tabassum et al., 2018) or dejargonized phrasing
and uncluttered layout (Waddell et al., 2016)).","Perhaps experiential
cognition might be more relevant for experience-based, automatic, learned processes
(like in the case of previously discussed car driving applications in Kehr et al.",2022-07-05 20:39:02+00:00,Informing Users: Effects of Notification Properties and User Characteristics on Sharing Attitudes,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Yefim Shulman'), arxiv.Result.Author('Agnieszka Kitkowska'), arxiv.Result.Author('Joachim Meyer')]","Information sharing on social networks is ubiquitous, intuitive, and
occasionally accidental. However, people may be unaware of the potential
negative consequences of disclosures, such as reputational damages. Yet, people
use social networks to disclose information about themselves or others, advised
only by their own experiences and the context-invariant informed consent
mechanism. In two online experiments (N=515 and N=765), we investigated how to
aid informed sharing decisions and associate them with the potential outcomes
via notifications. Based on the measurements of sharing attitudes, our results
showed that the effectiveness of informing the users via notifications may
depend on the timing, content, and layout of the notifications, as well as on
the users' curiosity and rational cognitive style, motivating information
processing. Furthermore, positive emotions may result in disregard of important
information. We discuss the implications for user privacy and
self-presentation. We provide recommendations on privacy-supporting system
design and suggest directions for further research."
8531,"ing a research agenda and posing open questions for further study
                                       on supporting people in learning to collaborate with generative AI                Even though collaboration plays an integral aspect in how users
                                       systems.",We conclude by propos-             among human—AI teams.,"interact with co-creative AI systems, it is often considered a sec-
                                                                                                                      ondary quality in the system’s design.",2022-07-06 22:11:13+00:00,Team Learning as a Lens for Designing Human-AI Co-Creative Systems,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Frederic Gmeiner'), arxiv.Result.Author('Kenneth Holstein'), arxiv.Result.Author('Nikolas Martelaro')]","Generative, ML-driven interactive systems have the potential to change how
people interact with computers in creative processes - turning tools into
co-creators. However, it is still unclear how we might achieve effective
human-AI collaboration in open-ended task domains. There are several known
challenges around communication in the interaction with ML-driven systems. An
overlooked aspect in the design of co-creative systems is how users can be
better supported in learning to collaborate with such systems. Here we reframe
human-AI collaboration as a learning problem: Inspired by research on team
learning, we hypothesize that similar learning strategies that apply to
human-human teams might also increase the collaboration effectiveness and
quality of humans working with co-creative generative systems. In this position
paper, we aim to promote team learning as a lens for designing more effective
co-creative human-AI collaboration and emphasize collaboration process quality
as a goal for co-creative systems. Furthermore, we outline a preliminary
schematic framework for embedding team learning support in co-creative AI
systems. We conclude by proposing a research agenda and posing open questions
for further study on supporting people in learning to collaborate with
generative AI systems."
8566,"However, this method of data collection is very common in the field of interruption
management, and as the data were used to develop the individual regression models, we believe that these initial
results are valuable for further research.","In addition, the questionnaire popped up on, the smartphone
as a notification, which may have caused the participants to interact with their smartphones more often than
they would normally have.","We are aware that a follow-up in-the-wild study is needed to validate
the models developed.",2022-07-07 16:22:45+00:00,Investigating the Effects of Mood & Usage Behaviour on Notification Response Time,cs.HC,['cs.HC'],"[arxiv.Result.Author('Judith S. Heinisch'), arxiv.Result.Author('Nan Gao'), arxiv.Result.Author('Christoph Anderson'), arxiv.Result.Author('Shohreh Deldari'), arxiv.Result.Author('Klaus David'), arxiv.Result.Author('Flora Salim')]","Notifications are one of the most prevailing mechanisms on smartphones and
personal computers to convey timely and important information. Despite these
benefits, smartphone notifications demand individuals' attention and can cause
stress and frustration when delivered at inopportune timings. This paper
investigates the effect of individuals' smartphone usage behavior and mood on
notification response time. We conduct an in-the-wild study with more than 18
participants for five weeks. Extensive experiment results show that the
proposed regression model is able to accurately predict the response time of
smartphone notifications using current user's mood and physiological signals.
We explored the effect of different features for each participant to choose the
most important user-oriented features in order to to achieve a meaningful and
personalised notification response prediction. On average, our regression model
achieved over all participants an MAE of 0.7764 ms and RMSE of 1.0527 ms. We
also investigate how physiological signals (collected from E4 wristbands) are
used as an indicator for mood and discuss the individual differences in
application usage and categories of smartphone applications on the response
time of notifications. Our research sheds light on the future intelligent
notification management system."
8588,"While considerable       their limited access to patient history and prior exams for
progress was achieved, further research on governance and           comparison.","We believe the proposed platform will enhance           image distribution systems offer limited functions compared
efficiency in workflow by eliminating the need for                  to those used by onsite radiologists but also teleradiologists
intermediaries and will benefit patients by eliminating the need    can only provide provisional reports in some cases due to
for storing medical images in hard copies.","Furthermore, current image transmission
HIPAA compliance is required to optimize the adoption of the        operates on the ""demand-push"" model, where the sending
new application.",2022-07-07 20:13:48+00:00,Blockchain-based Medical Image Sharing and Automated Critical-results Notification: A Novel Framework,cs.HC,"['cs.HC', 'cs.CR', 'cs.DC']","[arxiv.Result.Author('Jiyoun Randolph'), arxiv.Result.Author('Md Jobair Hossain Faruk'), arxiv.Result.Author('Hossain Shahriar'), arxiv.Result.Author('Maria Valero'), arxiv.Result.Author('Liang Zhao'), arxiv.Result.Author('Nazmus Sakib'), arxiv.Result.Author('Bilash Saha')]","In teleradiology, medical images are transmitted to offsite radiologists for
interpretation and the dictation report is sent back to the original site to
aid timely diagnosis and proper patient care. Although teleradiology offers
great benefits including time and cost efficiency, after-hour coverages, and
staffing shortage management, there are some technical and operational
limitations to overcome in reaching its full potential. We analyzed the current
teleradiology workflow to identify inefficiencies. Image unavailability and
delayed critical result communication stemmed from lack of system integration
between teleradiology practice and healthcare institutions are among the most
substantial factors causing prolonged turnaround time. In this paper, we
propose a blockchain-based medical image sharing and automated critical-results
notification platform to address the current limitation. We believe the
proposed platform will enhance efficiency in workflow by eliminating the need
for intermediaries and will benefit patients by eliminating the need for
storing medical images in hard copies. While considerable progress was
achieved, further research on governance and HIPAA compliance is required to
optimize the adoption of the new application. Towards an idea to a working
paradigm, we will implement the prototype during the next phase of our study."
8589,"regulatory compliance, further research on governance and
HIPAA compliance is required to optimize the adoption of            [3] J. H. Thrall, “Teleradiology.","3–9,
infrastructure facilitates the implementation and aids                        2010, doi: 10.1016/j.ejrad.2009.10.014.",Part II.,2022-07-07 20:13:48+00:00,Blockchain-based Medical Image Sharing and Automated Critical-results Notification: A Novel Framework,cs.HC,"['cs.HC', 'cs.CR', 'cs.DC']","[arxiv.Result.Author('Jiyoun Randolph'), arxiv.Result.Author('Md Jobair Hossain Faruk'), arxiv.Result.Author('Hossain Shahriar'), arxiv.Result.Author('Maria Valero'), arxiv.Result.Author('Liang Zhao'), arxiv.Result.Author('Nazmus Sakib'), arxiv.Result.Author('Bilash Saha')]","In teleradiology, medical images are transmitted to offsite radiologists for
interpretation and the dictation report is sent back to the original site to
aid timely diagnosis and proper patient care. Although teleradiology offers
great benefits including time and cost efficiency, after-hour coverages, and
staffing shortage management, there are some technical and operational
limitations to overcome in reaching its full potential. We analyzed the current
teleradiology workflow to identify inefficiencies. Image unavailability and
delayed critical result communication stemmed from lack of system integration
between teleradiology practice and healthcare institutions are among the most
substantial factors causing prolonged turnaround time. In this paper, we
propose a blockchain-based medical image sharing and automated critical-results
notification platform to address the current limitation. We believe the
proposed platform will enhance efficiency in workflow by eliminating the need
for intermediaries and will benefit patients by eliminating the need for
storing medical images in hard copies. While considerable progress was
achieved, further research on governance and HIPAA compliance is required to
optimize the adoption of the new application. Towards an idea to a working
paradigm, we will implement the prototype during the next phase of our study."
8594,"end, further research could explore new knowledge extraction
strategies and methodologies to quantify uncertainty.","To this
based model embedded into an interactive assistance system.","Finally,                     [18] J. Kukulies and R. H. Schmitt, “Uncertainty-based test planning using
                                                                                         dempster-shafer theory of evidence,” in 2017 2nd International Con-
knowledge internalization is a prospective line of research that                         ference on System Reliability and Safety, ICSRS 2017, vol.",2022-07-07 23:03:05+00:00,Production Assessment using a Knowledge Transfer Framework and Evidence Theory,cs.HC,['cs.HC'],"[arxiv.Result.Author('Fernando Arevalo N.'), arxiv.Result.Author('Christian Alison M. Piolo'), arxiv.Result.Author('Tahasanul Ibrahim'), arxiv.Result.Author('Andreas Schwung')]","Operational knowledge is one of the most valuable assets in a company, as it
provides a strategic advantage over competitors and ensures steady and optimal
operation in machines. An (interactive) assessment system on the shop floor can
optimize the process and reduce stopovers because it can provide constant
valuable information regarding the machine condition to the operators. However,
formalizing operational (tacit) knowledge to explicit knowledge is not an easy
task. This transformation considers modeling expert knowledge, quantification
of knowledge uncertainty, and validation of the acquired knowledge. This study
proposes a novel approach for production assessment using a knowledge transfer
framework and evidence theory to address the aforementioned challenges. The
main contribution of this paper is a methodology for the formalization of tacit
knowledge based on an extended failure mode and effect analysis for knowledge
extraction, as well as the use of evidence theory for the uncertainty
definition of knowledge. Moreover, this approach uses primitive recursive
functions for knowledge modeling and proposes a validation strategy of the
knowledge using machine data. These elements are integrated into an interactive
recommendation system hosted on a backend that uses HoloLens as a visual
interface. We demonstrate this approach using an industrial setup: a laboratory
bulk good system. The results yield interesting insights, including the
knowledge validation, uncertainty behavior of knowledge, and interactive
troubleshooting for the machine operator."
8595,"We are conﬁdent that our
tasks that are of a more exploratory or analytical nature, we believe      authoring tool is a basis for further research in guided dynamic
that in combination with guided dynamic narratives it can be an            narrative structures and their effectiveness for scientiﬁc commu-
effective way to present information.","While scrollytelling in general        to create immersive guided dynamic scrollytelling web experiences
might not be the best ﬁt for all visualization goals, in particular for    without having to write any code.",As demonstrated by our use           nication and educational purposes.,2022-07-07 23:32:06+00:00,ScrollyVis: Interactive visual authoring of guided dynamic narratives for scientific scrollytelling,cs.HC,['cs.HC'],"[arxiv.Result.Author('Eric Mörth'), arxiv.Result.Author('Stefan Bruckner'), arxiv.Result.Author('Noeska N. Smit')]","Visual stories are an effective and powerful tool to convey specific
information to a diverse public. Scrollytelling is a recent visual storytelling
technique extensively used on the web, where content appears or changes as
users scroll up or down a page. By employing the familiar gesture of scrolling
as its primary interaction mechanism, it provides users with a sense of
control, exploration and discoverability while still offering a simple and
intuitive interface. In this paper, we present a novel approach for authoring,
editing, and presenting data-driven scientific narratives using scrollytelling.
Our method flexibly integrates common sources such as images, text, and video,
but also supports more specialized visualization techniques such as interactive
maps as well as scalar field and mesh data visualizations. We show that
scrolling navigation can be used to traverse dynamic narratives and demonstrate
how it can be combined with interactive parameter exploration. The resulting
system consists of an extensible web-based authoring tool capable of exporting
stand-alone stories that can be hosted on any web server. We demonstrate the
power and utility of our approach with case studies from several of diverse
scientific fields and with a user study including 12 participants of diverse
professional backgrounds. Furthermore, an expert in creating interactive
articles assessed the usefulness of our approach and the quality of the created
stories."
8955,"We hope
                                        Uncrewed Aerial Systems (sUAS) have been applied in 114              that this information can be used to guide further research
                                        real world incidents as part of a technical rescue team from         and aid in the implementation of advanced capabilities with
                                        2016 to 2021.","within a technical rescue team in Boulder County, Colorado
                                        To aid in the alignment between researchers, technologists,          over the past ﬁve years and the methods by which they have
                                        and end users, we aim to provide perspective on how small            been employed on a range of emergency incidents.","We highlight the main applications, integration,       end users.",2022-07-15 21:29:08+00:00,A Review of the Operational Use of UAS in Public Safety Emergency Incidents,cs.HC,"['cs.HC', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Hunter Ray'), arxiv.Result.Author('Ryan Singer'), arxiv.Result.Author('Nisar Ahmed')]","The domain of public safety in the form of search \& rescue, wildland
firefighting, structure firefighting, and law enforcement operations have drawn
great interest in the field of aerospace engineering, human-robot teaming,
autonomous systems, and robotics. However, a divergence exists in the
assumptions made in research and how state-of-the-art technologies may
realistically transition into an operational capacity. To aid in the alignment
between researchers, technologists, and end users, we aim to provide
perspective on how small Uncrewed Aerial Systems (sUAS) have been applied in
114 real world incidents as part of a technical rescue team from 2016 to 2021.
We highlight the main applications, integration, tasks, and challenges of
employing UAS within five primary use cases including searches, evidence
collection, SWAT, wildland firefighting, and structure firefighting. Within
these use cases, key incidents are featured that provide perspective on the
evolving and dynamic nature of UAS tasking during an operation. Finally, we
highlight key technical directions for improving the utilization and efficiency
of employing aerial technology in all emergency types."
8956,"Incorporating computer vision into video stream analysis
of UAS derived video products presents another opportunity
for further research.","However, ensuring that operators reli-
ably trust the performance of these ﬂight modes is another
important aspect of their integration.","During a search with UAS, a single
person may be required to supervise a video feed to check for
evidence of the missing individual.",2022-07-15 21:29:08+00:00,A Review of the Operational Use of UAS in Public Safety Emergency Incidents,cs.HC,"['cs.HC', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Hunter Ray'), arxiv.Result.Author('Ryan Singer'), arxiv.Result.Author('Nisar Ahmed')]","The domain of public safety in the form of search \& rescue, wildland
firefighting, structure firefighting, and law enforcement operations have drawn
great interest in the field of aerospace engineering, human-robot teaming,
autonomous systems, and robotics. However, a divergence exists in the
assumptions made in research and how state-of-the-art technologies may
realistically transition into an operational capacity. To aid in the alignment
between researchers, technologists, and end users, we aim to provide
perspective on how small Uncrewed Aerial Systems (sUAS) have been applied in
114 real world incidents as part of a technical rescue team from 2016 to 2021.
We highlight the main applications, integration, tasks, and challenges of
employing UAS within five primary use cases including searches, evidence
collection, SWAT, wildland firefighting, and structure firefighting. Within
these use cases, key incidents are featured that provide perspective on the
evolving and dynamic nature of UAS tasking during an operation. Finally, we
highlight key technical directions for improving the utilization and efficiency
of employing aerial technology in all emergency types."
9396,"It is our hope that
these ﬁndings will inform further research and design toward the design of tools that can bring
out the best of both human and AI abilities.","Future research exploring each of these hy-
potheses is needed in order to understand how we can help human decision-makers better leverage
complementary perceptual abilities in the context of human-AI collaboration.","REFERENCES

 [1] Alex Albright.",2022-07-28 00:05:14+00:00,Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Kenneth Holstein'), arxiv.Result.Author('Maria De-Arteaga'), arxiv.Result.Author('Lakshmi Tumati'), arxiv.Result.Author('Yanghuidi Cheng')]","In many real world contexts, successful human-AI collaboration requires
humans to productively integrate complementary sources of information into
AI-informed decisions. However, in practice human decision-makers often lack
understanding of what information an AI model has access to in relation to
themselves. There are few available guidelines regarding how to effectively
communicate about unobservables: features that may influence the outcome, but
which are unavailable to the model. In this work, we conducted an online
experiment to understand whether and how explicitly communicating potentially
relevant unobservables influences how people integrate model outputs and
unobservables when making predictions. Our findings indicate that presenting
prompts about unobservables can change how humans integrate model outputs and
unobservables, but do not necessarily lead to improved performance.
Furthermore, the impacts of these prompts can vary depending on
decision-makers' prior domain expertise. We conclude by discussing implications
for future research and design of AI-based decision support tools."
9472,"Further, we align with research (e.g., [19]) that (value) scenarios unveil unforeseen
aspects of a specific context that might inform novel aspects of technology design and provoke reflection; but also that
further research is needed for the systematic use of VSD methods and toolkits [23].","Participant P5
explains: “[If physicians] would now also present such a value map for themselves [...], some misunderstandings I think
would also be cleared up.” Finally, we (facilitators) recognized the value of creating and maintaining a clearly defined
“common language” [3] for participants and us to create a deeper shared understanding such as the precise definition
and reasoning of each activity.","5 CONCLUSION AND FUTURE WORK

In our work, we leverage VSD with reflective design to create a value-centered participatory workshop divided into
three phases, namely, exploring, clustering, and translating with assisting tools (i.e., value questionnaire, value map, and
value scenario).",2022-07-29 13:56:15+00:00,Unfolding Values through Systematic Guidance: Conducting a Value-Centered Participatory Workshop for a Patient-Oriented Data Donation,cs.HC,['cs.HC'],"[arxiv.Result.Author('David Leimstädtner'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Claudia Müller-Birn')]","Routinely collected clinical patient data posits a valuable resource for
data-driven medical innovation. Such secondary data use for medical research
purposes is dependent on the patient's consent. To gain an understanding of the
patients' values and needs regarding medical data donations, we developed a
participatory workshop method, integrating approaches from value-sensitive and
reflective design to explore patients' values and translate them into
hypothetical, ideal design solutions. The data gathered in the workshop are
used to derive practicable design requirements for patient-oriented data
donation technologies. In this paper, we introduce the workshop process and
evaluate its application."
9546,"5.2 Using the model as a lens for analysis and further research

The proposed model, to our knowledge, is the first attempt to articulate writer-suggestion interaction
from a cognitive lens.","For example, a writer who thinks the suggestion system reflects the views of other
writers on the internet may be more willing to accept it.","It is derived from qualitative analysis of a specific type of writing task - movie
reviews, with a particular language model - GPT-2, fine-tuned on a specific data-set - IMDb movie
reviews, with a one-dimensional bias - positive and negative sentiment and using a particular
suggestion interaction modality - single inline next-phrase suggestions.",2022-08-01 06:49:07+00:00,Studying writer-suggestion interaction: A qualitative study to understand writer interaction with aligned/misaligned next-phrase suggestion,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Advait Bhat'), arxiv.Result.Author('Saaket Agashe'), arxiv.Result.Author('Niharika Mohile'), arxiv.Result.Author('Parth Oberoi'), arxiv.Result.Author('Ravi Jangir'), arxiv.Result.Author('Anirudha Joshi')]","We present an exploratory qualitative study to understand how writers
interact with next-phrase suggestions. While there has been some quantitative
research on the effects of suggestion systems on writing, there has been little
qualitative work to understand how writers interact with suggestion systems and
how it affects their writing process - specifically for a non-native but
English writer. We conducted a study where amateur writers were asked to write
two movie reviews each, one without suggestions and one with. We found writers
interact with next-phrase suggestions in various complex ways - writers are
able to abstract multiple parts of the suggestions and incorporate them within
their writing - even when they disagree with the suggestion as a whole. The
suggestion system also had various effects on the writing processes -
contributing to different aspects of the writing process in unique ways. We
propose a model of writer-suggestion interaction for writing with GPT-2 for a
movie review writing task, followed by ways in which the model can be used for
future research, along with outlining opportunities for research and design."
9547,"While not a definitive model
of writer-suggestion interaction, it can still act as a theoretical starting point for further research in
this area.","It is derived from qualitative analysis of a specific type of writing task - movie
reviews, with a particular language model - GPT-2, fine-tuned on a specific data-set - IMDb movie
reviews, with a one-dimensional bias - positive and negative sentiment and using a particular
suggestion interaction modality - single inline next-phrase suggestions.",Further research can happen in three directions.,2022-08-01 06:49:07+00:00,Studying writer-suggestion interaction: A qualitative study to understand writer interaction with aligned/misaligned next-phrase suggestion,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Advait Bhat'), arxiv.Result.Author('Saaket Agashe'), arxiv.Result.Author('Niharika Mohile'), arxiv.Result.Author('Parth Oberoi'), arxiv.Result.Author('Ravi Jangir'), arxiv.Result.Author('Anirudha Joshi')]","We present an exploratory qualitative study to understand how writers
interact with next-phrase suggestions. While there has been some quantitative
research on the effects of suggestion systems on writing, there has been little
qualitative work to understand how writers interact with suggestion systems and
how it affects their writing process - specifically for a non-native but
English writer. We conducted a study where amateur writers were asked to write
two movie reviews each, one without suggestions and one with. We found writers
interact with next-phrase suggestions in various complex ways - writers are
able to abstract multiple parts of the suggestions and incorporate them within
their writing - even when they disagree with the suggestion as a whole. The
suggestion system also had various effects on the writing processes -
contributing to different aspects of the writing process in unique ways. We
propose a model of writer-suggestion interaction for writing with GPT-2 for a
movie review writing task, followed by ways in which the model can be used for
future research, along with outlining opportunities for research and design."
9548,We call for further research using more multidimensional writer-suggestion alignments.,"The writer-suggestion misalignment in examples such
as political pieces would also be multidimensional, unlike single-dimensional positive and negative
sentiment.",6.0.4 Methodological Limitations.,2022-08-01 06:49:07+00:00,Studying writer-suggestion interaction: A qualitative study to understand writer interaction with aligned/misaligned next-phrase suggestion,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Advait Bhat'), arxiv.Result.Author('Saaket Agashe'), arxiv.Result.Author('Niharika Mohile'), arxiv.Result.Author('Parth Oberoi'), arxiv.Result.Author('Ravi Jangir'), arxiv.Result.Author('Anirudha Joshi')]","We present an exploratory qualitative study to understand how writers
interact with next-phrase suggestions. While there has been some quantitative
research on the effects of suggestion systems on writing, there has been little
qualitative work to understand how writers interact with suggestion systems and
how it affects their writing process - specifically for a non-native but
English writer. We conducted a study where amateur writers were asked to write
two movie reviews each, one without suggestions and one with. We found writers
interact with next-phrase suggestions in various complex ways - writers are
able to abstract multiple parts of the suggestions and incorporate them within
their writing - even when they disagree with the suggestion as a whole. The
suggestion system also had various effects on the writing processes -
contributing to different aspects of the writing process in unique ways. We
propose a model of writer-suggestion interaction for writing with GPT-2 for a
movie review writing task, followed by ways in which the model can be used for
future research, along with outlining opportunities for research and design."
9587,"further study how to simplify the aforementioned feature extractors
                                                                                to be used in real time for V-IMT systems or how to use depth
   Additionally, P4 pointed out that there was a lack of further                sensors to support V-IMT systems [57, 58].","Future research should
clicking on the camera icon in Figure 2a.",teaching/clarification support when object highlights fail.,2022-08-02 02:23:35+00:00,Gesture-aware Interactive Machine Teaching with In-situ Object Annotations,cs.HC,['cs.HC'],"[arxiv.Result.Author('Zhongyi Zhou'), arxiv.Result.Author('Koji Yatani')]","Interactive Machine Teaching (IMT) systems allow non-experts to easily create
Machine Learning (ML) models. However, existing vision-based IMT systems either
ignore annotations on the objects of interest or require users to annotate in a
post-hoc manner. Without the annotations on objects, the model may misinterpret
the objects using unrelated features. Post-hoc annotations cause additional
workload, which diminishes the usability of the overall model building process.
In this paper, we develop LookHere, which integrates in-situ object annotations
into vision-based IMT. LookHere exploits users' deictic gestures to segment the
objects of interest in real time. This segmentation information can be
additionally used for training. To achieve the reliable performance of this
object segmentation, we utilize our custom dataset called HuTics, including
2040 front-facing images of deictic gestures toward various objects by 170
people. The quantitative results of our user study showed that participants
were 16.3 times faster in creating a model with our system compared to a
standard IMT system with a post-hoc annotation process while demonstrating
comparable accuracies. Additionally, models created by our system showed a
significant accuracy improvement ($\Delta mIoU=0.466$) in segmenting the
objects of interest compared to those without annotations."
9609,"Researchers can
We conducted semi-structured interviews with E1 – E5 to check whether        attach more implicit factors to our work for further study.","7.3 Expert Interview                                                         online shopping [40], thus making it more important for e-commerce
                                                                             to weigh in when considering promotion strategies.",PromotionLens helped explore the impact of promotion strategies.,2022-08-01 04:13:24+00:00,PromotionLens: Inspecting Promotion Strategies of Online E-commerce via Visual Analytics,cs.HC,['cs.HC'],"[arxiv.Result.Author('Chenyang Zhang'), arxiv.Result.Author('Xiyuan Wang'), arxiv.Result.Author('Chuyi Zhao'), arxiv.Result.Author('Yijing Ren'), arxiv.Result.Author('Tianyu Zhang'), arxiv.Result.Author('Zhenhui Peng'), arxiv.Result.Author('Xiaomeng Fan'), arxiv.Result.Author('Quan Li')]","Promotions are commonly used by e-commerce merchants to boost sales. The
efficacy of different promotion strategies can help sellers adapt their
offering to customer demand in order to survive and thrive. Current approaches
to designing promotion strategies are either based on econometrics, which may
not scale to large amounts of sales data, or are spontaneous and provide little
explanation of sales volume. Moreover, accurately measuring the effects of
promotion designs and making bootstrappable adjustments accordingly remains a
challenge due to the incompleteness and complexity of the information
describing promotion strategies and their market environments. We present
PromotionLens, a visual analytics system for exploring, comparing, and modeling
the impact of various promotion strategies. Our approach combines
representative multivariant time-series forecasting models and well-designed
visualizations to demonstrate and explain the impact of sales and promotional
factors, and to support ""what-if"" analysis of promotions. Two case studies,
expert feedback, and a qualitative user study demonstrate the efficacy of
PromotionLens."
9770,"However, target user needs are not fully understood, and the functions that
                                       workers would ideally want a DA to support require further study.","Abstract

                                       Digital Assistants (DAs) can support workers in the workplace and beyond.","A richer
                                       understanding of worker needs could help inform the design of future DAs.",2022-08-06 04:48:24+00:00,Imagining Future Digital Assistants at Work: A Study of Task Management Needs,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yonchanok Khaokaew'), arxiv.Result.Author('Indigo Holcombe-James'), arxiv.Result.Author('Mohammad Saiedur Rahaman'), arxiv.Result.Author('Jonathan Liono'), arxiv.Result.Author('Johanne R. Trippas'), arxiv.Result.Author('Damiano Spina'), arxiv.Result.Author('Nicholas Belkin'), arxiv.Result.Author('Peter Bailey'), arxiv.Result.Author('Paul N. Bennett'), arxiv.Result.Author('Yongli Ren'), arxiv.Result.Author('Mark Sanderson'), arxiv.Result.Author('Falk Scholer'), arxiv.Result.Author('Ryen W. White'), arxiv.Result.Author('Flora D. Salim')]","Digital Assistants (DAs) can support workers in the workplace and beyond.
However, target user needs are not fully understood, and the functions that
workers would ideally want a DA to support require further study. A richer
understanding of worker needs could help inform the design of future DAs. We
investigate user needs of future workplace DAs using data from a user study of
40 workers over a four-week period. Our qualitative analysis confirms existing
research and generates new insight on the role of DAs in managing people's
time, tasks, and information. Placing these insights in relation to
quantitative analysis of self-reported task data, we highlight how different
occupation roles require DAs to take varied approaches to these domains and the
effect of task characteristics on the imagined features. Our findings have
implications for the design of future DAs in work settings, and we offer some
recommendations for reduction to practice."
9863,"Whether such scene management and content trans-
as ‘intuitive’, and as with any new approach, P6 stated: “it probably       formation functionality are activated by introducing a new set of
just takes some getting used to.”                                           non-distracting gestures or through off-screen presenter controls
                                                                            is a question worthy of further research and design.","Beyond individual discovery
A12 additionally praised swipe flourish when panning the timeline        of the interactions, P3 adds: “I think watching someone else do it first
                                                                         is probably very critical for training.” Despite a perceived learning
Augmented Chironomia for Presenting Data to Remote Audiences                                                   UIST ’22, October 29-November 2, 2022, Bend, OR, USA

curve, we were encouraged by P5 and P8 describing our interactions          engagement.","Audience participants also speculated on learnability, expressing
a similar blend of optimism and concern with respect to an expected         6 DISCUSSION
learning curve, particularly if we contrast A5 imagining a time
when “we all learn these skills — I presume that’s not a challenge”         We now reflect on the potential of our approach, proposing de-
with A16 suggesting that the presenter had extensively practiced            sign implications for presentation tools that reinforce and extend
the presentation beforehand.",2022-08-08 22:27:29+00:00,Augmented Chironomia for Presenting Data to Remote Audiences,cs.HC,['cs.HC'],"[arxiv.Result.Author('Brian D. Hall'), arxiv.Result.Author('Lyn Bartram'), arxiv.Result.Author('Matthew Brehmer')]","To facilitate engaging and nuanced conversations around data, we contribute a
touchless approach to interacting directly with visualization in remote
presentations. We combine dynamic charts overlaid on a presenter's webcam feed
with continuous bimanual hand tracking, demonstrating interactions that
highlight and manipulate chart elements appearing in the foreground. These
interactions are simultaneously functional and deictic, and some allow for the
addition of ""rhetorical flourish"", or expressive movement used when speaking
about quantities, categories, and time intervals. We evaluated our approach in
two studies with professionals who routinely deliver and attend presentations
about data. The first study considered the presenter perspective, where 12
participants delivered presentations to a remote audience using a presentation
environment incorporating our approach. The second study considered the
audience experience of 17 participants who attended presentations supported by
our environment. Finally, we reflect on observations from these studies and
discuss related implications for engaging remote audiences in conversations
about data."
9923,396-397)—is subject to further research.,"© 2022 Maximilian Speicher
Listen to Users, but Only 85% of the Time  UX Collective —— 11

How it might be possible to consistently identify potential Black Swan designs—i.e., how to op-
erationalize the theory laid out in this article and make those Black Swans gray (Taleb, 2007: pp.",I hope to motivate such research with this article.,2022-08-10 13:42:56+00:00,"Listen to Users, but Only 85% of the Time: How Black Swans Can Save Innovation in a Data-Driven World",cs.HC,"['cs.HC', 'H.5.2; K.6.1']",[arxiv.Result.Author('Maximilian Speicher')],"Data-driven design is a proven success factor that more and more digital
businesses embrace. At the same time, academics and practitioners alike warn
that when virtually everything must be tested and proven with numbers, that can
stifle creativity and innovation. This article argues that Taleb's Black Swan
theory can solve this dilemma. It shows that online experimentation, and
therefore digital design, are fat-tailed phenomena and, hence, prone to Black
Swans. It introduces the notion of Black Swan designs -- ""crazy"" designs that
make sense only in hindsight -- along with four specific criteria. To ensure
incremental improvements and their potential for innovation, businesses should
apply Taleb's barbell strategy: Invest 85-90% of resources into data-driven
approaches and 10-15% into potential Black Swans."
9924,"In Section 3.2, I have mentioned that further research is necessary on how it could be possible to
turn Black Swans gray.","This is one potential answer to how one
could “fill” the 10‒15% in the barbell strategy with potential Black Swan designs.","According to Taleb (2007: p. 397), Gray Swans are extreme events that
can be captured through models while Black Swans are really “unknown unknowns.” Aparicio,
Bacao, and Oliveira (2014) have investigated this relationship in the context of massive open
online courses (MOOCs) and propose that “[d]esigning business models for MOOCs can be a way
to domesticate Black Swans and turn MOOCs into Gray Swans” (Aparicio et al., 2014: p. 48).",2022-08-10 13:42:56+00:00,"Listen to Users, but Only 85% of the Time: How Black Swans Can Save Innovation in a Data-Driven World",cs.HC,"['cs.HC', 'H.5.2; K.6.1']",[arxiv.Result.Author('Maximilian Speicher')],"Data-driven design is a proven success factor that more and more digital
businesses embrace. At the same time, academics and practitioners alike warn
that when virtually everything must be tested and proven with numbers, that can
stifle creativity and innovation. This article argues that Taleb's Black Swan
theory can solve this dilemma. It shows that online experimentation, and
therefore digital design, are fat-tailed phenomena and, hence, prone to Black
Swans. It introduces the notion of Black Swan designs -- ""crazy"" designs that
make sense only in hindsight -- along with four specific criteria. To ensure
incremental improvements and their potential for innovation, businesses should
apply Taleb's barbell strategy: Invest 85-90% of resources into data-driven
approaches and 10-15% into potential Black Swans."
9937,"We also suggest that making more social
systems piggybackable can enable further research and experimentation, and deepen our knowledge

Proc.","8.2 Advocating for piggybacking and piggybackable platforms

In outlining a set of benefits that piggyback prototyping provides for answering a range of CSCW
systems questions, we argue that the community could benefit from broader use of the method
relative to designing single-purpose research systems.",ACM Hum.-Comput.,2022-08-10 17:24:23+00:00,Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Daniel A. Epstein'), arxiv.Result.Author('Fannie Liu'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Dennis Wang')]","The CSCW community has a history of designing, implementing, and evaluating
novel social interactions in technology, but the process requires significant
technical effort for uncertain value. We discuss the opportunities and
applications of ""piggyback prototyping"", building and evaluating new ideas for
social computing on top of existing ones, expanding on its potential to
contribute design recommendations. Drawing on about 50 papers which use the
method, we critically examine the intellectual and technical benefits it
provides, such as ecological validity and leveraging well-tested features, as
well as research-product and ethical tensions it imposes, such as limits to
customization and violation of participant privacy. We discuss considerations
for future researchers deciding whether to use piggyback prototyping and point
to new research agendas which can reduce the burden of implementing the method."
9938,"However, understanding the design
requirements for such a tool would require further research.","Toolkits could help both researchers and participants
by providing common customization options such as editable text, image layout, colors, emoji,
and fonts, and support exporting them to social platforms.","Additionally, tools could aggregate
authoring features from different commercial APIs to allow studies to recruit participants who
have different platform preferences.",2022-08-10 17:24:23+00:00,Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Daniel A. Epstein'), arxiv.Result.Author('Fannie Liu'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Dennis Wang')]","The CSCW community has a history of designing, implementing, and evaluating
novel social interactions in technology, but the process requires significant
technical effort for uncertain value. We discuss the opportunities and
applications of ""piggyback prototyping"", building and evaluating new ideas for
social computing on top of existing ones, expanding on its potential to
contribute design recommendations. Drawing on about 50 papers which use the
method, we critically examine the intellectual and technical benefits it
provides, such as ecological validity and leveraging well-tested features, as
well as research-product and ethical tensions it imposes, such as limits to
customization and violation of participant privacy. We discuss considerations
for future researchers deciding whether to use piggyback prototyping and point
to new research agendas which can reduce the burden of implementing the method."
9939,"We also suggest that making more social
systems piggybackable can enable further research and experimentation, and deepen our knowledge

Proc.","8.2 Advocating for piggybacking and piggybackable platforms

In outlining a set of benefits that piggyback prototyping provides for answering a range of CSCW
systems questions, we argue that the community could benefit from broader use of the method
relative to designing single-purpose research systems.",ACM Hum.-Comput.,2022-08-10 17:24:23+00:00,Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Daniel A. Epstein'), arxiv.Result.Author('Fannie Liu'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Dennis Wang')]","The CSCW community has a history of designing, implementing, and evaluating
novel social interactions in technology, but the process requires significant
technical effort for uncertain value. We discuss the opportunities and
applications of ""piggyback prototyping"", building and evaluating new ideas for
social computing on top of existing ones, expanding on its potential to
contribute design recommendations. Drawing on about 50 papers which use the
method, we critically examine the intellectual and technical benefits it
provides, such as ecological validity and leveraging well-tested features, as
well as research-product and ethical tensions it imposes, such as limits to
customization and violation of participant privacy. We discuss considerations
for future researchers deciding whether to use piggyback prototyping and point
to new research agendas which can reduce the burden of implementing the method."
9940,"However, understanding the design
requirements for such a tool would require further research.","Toolkits could help both researchers and participants
by providing common customization options such as editable text, image layout, colors, emoji,
and fonts, and support exporting them to social platforms.","Additionally, tools could aggregate
authoring features from different commercial APIs to allow studies to recruit participants who
have different platform preferences.",2022-08-10 17:24:23+00:00,Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Daniel A. Epstein'), arxiv.Result.Author('Fannie Liu'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Dennis Wang')]","The CSCW community has a history of designing, implementing, and evaluating
novel social interactions in technology, but the process requires significant
technical effort for uncertain value. We discuss the opportunities and
applications of ""piggyback prototyping"", building and evaluating new ideas for
social computing on top of existing ones, expanding on its potential to
contribute design recommendations. Drawing on about 50 papers which use the
method, we critically examine the intellectual and technical benefits it
provides, such as ecological validity and leveraging well-tested features, as
well as research-product and ethical tensions it imposes, such as limits to
customization and violation of participant privacy. We discuss considerations
for future researchers deciding whether to use piggyback prototyping and point
to new research agendas which can reduce the burden of implementing the method."
9941,"We also suggest that making more social
systems piggybackable can enable further research and experimentation, and deepen our knowledge

Proc.","8.2 Advocating for piggybacking and piggybackable platforms

In outlining a set of benefits that piggyback prototyping provides for answering a range of CSCW
systems questions, we argue that the community could benefit from broader use of the method
relative to designing single-purpose research systems.",ACM Hum.-Comput.,2022-08-10 17:24:23+00:00,Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Daniel A. Epstein'), arxiv.Result.Author('Fannie Liu'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Dennis Wang')]","The CSCW community has a history of designing, implementing, and evaluating
novel social interactions in technology, but the process requires significant
technical effort for uncertain value. We discuss the opportunities and
applications of ""piggyback prototyping"", building and evaluating new ideas for
social computing on top of existing ones, expanding on its potential to
contribute design recommendations. Drawing on about 50 papers which use the
method, we critically examine the intellectual and technical benefits it
provides, such as ecological validity and leveraging well-tested features, as
well as research-product and ethical tensions it imposes, such as limits to
customization and violation of participant privacy. We discuss considerations
for future researchers deciding whether to use piggyback prototyping and point
to new research agendas which can reduce the burden of implementing the method."
9942,"However, understanding the design
requirements for such a tool would require further research.","Toolkits could help both researchers and participants
by providing common customization options such as editable text, image layout, colors, emoji,
and fonts, and support exporting them to social platforms.","Additionally, tools could aggregate
authoring features from different commercial APIs to allow studies to recruit participants who
have different platform preferences.",2022-08-10 17:24:23+00:00,Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Daniel A. Epstein'), arxiv.Result.Author('Fannie Liu'), arxiv.Result.Author('Andrés Monroy-Hernández'), arxiv.Result.Author('Dennis Wang')]","The CSCW community has a history of designing, implementing, and evaluating
novel social interactions in technology, but the process requires significant
technical effort for uncertain value. We discuss the opportunities and
applications of ""piggyback prototyping"", building and evaluating new ideas for
social computing on top of existing ones, expanding on its potential to
contribute design recommendations. Drawing on about 50 papers which use the
method, we critically examine the intellectual and technical benefits it
provides, such as ecological validity and leveraging well-tested features, as
well as research-product and ethical tensions it imposes, such as limits to
customization and violation of participant privacy. We discuss considerations
for future researchers deciding whether to use piggyback prototyping and point
to new research agendas which can reduce the burden of implementing the method."
9981,"We hope the result can         [7] D. Daniels, “Why some games feel better than others - part
be an evaluation metric for further study.","even one of the three features will weaken the performance of
impact feel and make it undesirable.","3,” Mar.",2022-08-12 07:56:43+00:00,What Features Influence Impact Feel? A Study of Impact Feedback in Action Games,cs.HC,['cs.HC'],"[arxiv.Result.Author('Zhonghao Lin'), arxiv.Result.Author('Haihan Duan'), arxiv.Result.Author('Zikai Wen'), arxiv.Result.Author('Wei Cai')]","Making the hit effect satisfy players is a long-standing problem faced by
action game designers. However, no research systematically analyzed which game
design elements affect such game feel. There is not even a term to describe it.
So, we propose to use impact feel to describe the player's feeling when
receiving juicy impact feedback. After collecting player's comments on action
games from Steam's top seller list, we trained a natural language processing
(NLP) model to rank action games with their performance on impact feel. We
presented a 19-feature framework of impact feedback design and examined it in
the top eight and last eight games. We listed an inventory of the usage of
features and found that hit stop, sound coherence, and camera control may
strongly influence players' impact feel. A lack of dedicated design on one of
these three features may ruin players' impact feel. Our findings may become an
evaluation metric for future studies."
9982,"We hope the result can         [7] D. Daniels, “Why some games feel better than others - part
be an evaluation metric for further study.","even one of the three features will weaken the performance of
impact feel and make it undesirable.","3,” Mar.",2022-08-12 07:56:43+00:00,What Features Influence Impact Feel? A Study of Impact Feedback in Action Games,cs.HC,['cs.HC'],"[arxiv.Result.Author('Zhonghao Lin'), arxiv.Result.Author('Haihan Duan'), arxiv.Result.Author('Zikai Alex Wen'), arxiv.Result.Author('Wei Cai')]","Making the hit effect satisfy players is a long-standing problem faced by
action game designers. However, no research systematically analyzed which game
design elements affect such game feel. There is not even a term to describe it.
So, we propose to use impact feel to describe the player's feeling when
receiving juicy impact feedback. After collecting player's comments on action
games from Steam's top seller list, we trained a natural language processing
(NLP) model to rank action games with their performance on impact feel. We
presented a 19-feature framework of impact feedback design and examined it in
the top eight and last eight games. We listed an inventory of the usage of
features and found that hit stop, sound coherence, and camera control may
strongly influence players' impact feel. A lack of dedicated design on one of
these three features may ruin players' impact feel. Our findings may become an
evaluation metric for future studies."
9983,be an evaluation metric for further study.,We hope the result can              in- hit-effects.,"[7] D. Daniels, “Why some games feel better than others - part
   There are a few limitations that need to be considered in             3,” Mar.",2022-08-12 07:56:43+00:00,What Features Influence Impact Feel? A Study of Impact Feedback in Action Games,cs.HC,['cs.HC'],"[arxiv.Result.Author('Zhonghao Lin'), arxiv.Result.Author('Haihan Duan'), arxiv.Result.Author('Zikai Alex Wen'), arxiv.Result.Author('Wei Cai')]","Making the hit effect satisfy players is a long-standing problem faced by
action game designers. However, no research systematically analyzed which game
design elements affect such game feel. There is not even a term to describe it.
So, we propose to use impact feel to describe the player's feeling when
receiving juicy impact feedback. After collecting player's comments on action
games from Steam's top seller list, we trained a natural language processing
(NLP) model to rank action games with their performance on impact feel. We
presented a 19-feature framework of impact feedback design and examined it in
the top eight and last eight games. We listed an inventory of the usage of
features and found that hit stop, sound coherence, and camera control may
strongly influence players' impact feel. A lack of dedicated design on one of
these three features may ruin players' impact feel. Our findings may become an
evaluation metric for future studies."
9986,"Through a study of LLM-assisted
end-user programming in spreadsheets, we uncover issues in intent speciﬁcation, code correctness, com-
prehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area
(Section 9).","Nonetheless, there are is-
sues with their direct application in end-user programming scenarios.",2.,2022-08-12 10:48:46+00:00,What is it like to program with artificial intelligence?,cs.HC,"['cs.HC', 'cs.AI', 'cs.PL', 'D.2.3; D.2.6; I.2.5; I.2.7; H.5.2']","[arxiv.Result.Author('Advait Sarkar'), arxiv.Result.Author('Andrew D. Gordon'), arxiv.Result.Author('Carina Negreanu'), arxiv.Result.Author('Christian Poelitz'), arxiv.Result.Author('Sruti Srinivasa Ragavan'), arxiv.Result.Author('Ben Zorn')]","Large language models, such as OpenAI's codex and Deepmind's AlphaCode, can
generate code to solve a variety of problems expressed in natural language.
This technology has already been commercialised in at least one widely-used
programming editor extension: GitHub Copilot.
  In this paper, we explore how programming with large language models
(LLM-assisted programming) is similar to, and differs from, prior
conceptualisations of programmer assistance. We draw upon publicly available
experience reports of LLM-assisted programming, as well as prior usability and
design studies. We find that while LLM-assisted programming shares some
properties of compilation, pair programming, and programming via search and
reuse, there are fundamental differences both in the technical possibilities as
well as the practical experience. Thus, LLM-assisted programming ought to be
viewed as a new way of programming with its own distinct properties and
challenges.
  Finally, we draw upon observations from a user study in which non-expert end
user programmers use LLM-assisted tools for solving data tasks in spreadsheets.
We discuss the issues that might arise, and open research challenges, in
applying large language models to end-user programming, particularly with users
who have little or no programming expertise."
9987,"Through a study of LLM-assisted
end-user programming in spreadsheets, we uncover issues in intent speciﬁcation, code correctness, com-
prehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area
(Section 9).","Nonetheless, there are is-
sues with their direct application in end-user programming scenarios.",2.,2022-08-12 10:48:46+00:00,What is it like to program with artificial intelligence?,cs.HC,"['cs.HC', 'cs.AI', 'cs.PL', 'D.2.3; D.2.6; I.2.5; I.2.7; H.5.2']","[arxiv.Result.Author('Advait Sarkar'), arxiv.Result.Author('Andrew D. Gordon'), arxiv.Result.Author('Carina Negreanu'), arxiv.Result.Author('Christian Poelitz'), arxiv.Result.Author('Sruti Srinivasa Ragavan'), arxiv.Result.Author('Ben Zorn')]","Large language models, such as OpenAI's codex and Deepmind's AlphaCode, can
generate code to solve a variety of problems expressed in natural language.
This technology has already been commercialised in at least one widely-used
programming editor extension: GitHub Copilot.
  In this paper, we explore how programming with large language models
(LLM-assisted programming) is similar to, and differs from, prior
conceptualisations of programmer assistance. We draw upon publicly available
experience reports of LLM-assisted programming, as well as prior usability and
design studies. We find that while LLM-assisted programming shares some
properties of compilation, pair programming, and programming via search and
reuse, there are fundamental differences both in the technical possibilities as
well as the practical experience. Thus, LLM-assisted programming ought to be
viewed as a new way of programming with its own distinct properties and
challenges.
  Finally, we draw upon observations from a user study in which non-expert end
user programmers use LLM-assisted tools for solving data tasks in spreadsheets.
We discuss the issues that might arise, and open research challenges, in
applying large language models to end-user programming, particularly with users
who have little or no programming expertise."
10075,"However, further study is needed
While we have described possible extensions of our polymorphic           to fully characterize any effects on the distribution of papers and
lenses technique to other domains, we test it in one domain.","We believe that this is a
                                                                         net benefit for users and authors.",It          authors visited by the user.,2022-08-16 04:30:35+00:00,FeedLens: Polymorphic Lenses for Personalizing Exploratory Search over Knowledge Graphs,cs.HC,"['cs.HC', 'cs.IR']","[arxiv.Result.Author('Harmanpreet Kaur'), arxiv.Result.Author('Doug Downey'), arxiv.Result.Author('Amanpreet Singh'), arxiv.Result.Author('Evie Yu-Yen Cheng'), arxiv.Result.Author('Daniel S. Weld'), arxiv.Result.Author('Jonathan Bragg')]","The vast scale and open-ended nature of knowledge graphs (KGs) make
exploratory search over them cognitively demanding for users. We introduce a
new technique, polymorphic lenses, that improves exploratory search over a KG
by obtaining new leverage from the existing preference models that KG-based
systems maintain for recommending content. The approach is based on a simple
but powerful observation: in a KG, preference models can be re-targeted to
recommend not only entities of a single base entity type (e.g., papers in the
scientific literature KG, products in an e-commerce KG), but also all other
types (e.g., authors, conferences, institutions; sellers, buyers). We implement
our technique in a novel system, FeedLens, which is built over Semantic
Scholar, a production system for navigating the scientific literature KG.
FeedLens reuses the existing preference models on Semantic Scholar -- people's
curated research feeds -- as lenses for exploratory search. Semantic Scholar
users can curate multiple feeds/lenses for different topics of interest, e.g.,
one for human-centered AI and another for document embeddings. Although these
lenses are defined in terms of papers, FeedLens re-purposes them to also guide
search over authors, institutions, venues, etc. Our system design is based on
feedback from intended users via two pilot surveys (n=17 and n=13,
respectively). We compare FeedLens and Semantic Scholar via a third
(within-subjects) user study (n=15) and find that FeedLens increases user
engagement while reducing the cognitive effort required to complete a short
literature review task. Our qualitative results also highlight people's
preference for this more effective exploratory search experience enabled by
FeedLens."
10107,We kept the 49 drivers for further study.,"The reward function for expert E can
following events, and 49 drivers with more than 10 events.","be denoted as RE(s, a) =  M    ωm    ·  φm(s, a),  where  M
                                                                                                   m=1
   Figure 2 shows two car-following events: Driver 13101
was driving at relatively low speed (26.4 ± 0.08 m/s) while              is the number of features and ω is the weight.",2022-08-17 00:29:02+00:00,A Study on Learning and Simulating Personalized Car-Following Driving Style,cs.HC,['cs.HC'],"[arxiv.Result.Author('Shili Sheng'), arxiv.Result.Author('Erfan Pakdamanian'), arxiv.Result.Author('Kyungtae Han'), arxiv.Result.Author('Ziran Wang'), arxiv.Result.Author('Lu Feng')]","Automated vehicles are gradually entering people's daily life to provide a
comfortable driving experience for the users. The generic and user-agnostic
automated vehicles have limited ability to accommodate the different driving
styles of different users. This limitation not only impacts users' satisfaction
but also causes safety concerns. Learning from user demonstrations can provide
direct insights regarding users' driving preferences. However, it is difficult
to understand a driver's preference with limited data. In this study, we use a
model-free inverse reinforcement learning method to study drivers'
characteristics in the car-following scenario from a naturalistic driving
dataset, and show this method is capable of representing users' preferences
with reward functions. In order to predict the driving styles for drivers with
limited data, we apply Gaussian Mixture Models and compute the similarity of a
specific driver to the clusters of drivers. We design a personalized adaptive
cruise control (P-ACC) system through a partially observable Markov decision
process (POMDP) model. The reward function with the model to mimic drivers'
driving style is integrated, with a constraint on the relative distance to
ensure driving safety. Prediction of the driving styles achieves 85.7% accuracy
with the data of less than 10 car-following events. The model-based
experimental driving trajectories demonstrate that the P-ACC system can provide
a personalized driving experience."
10125,"Our
                                        SLR led to the discovery of a number of important areas where further research is needed; these include
                                        holistic methods that consider a more diverse and heterogeneous range of home devices, interactions between
                                        multiple home users, complicated data flow between multiple home devices and home users, some less-studied
                                        demographic factors, and advanced conceptual frameworks.","This identified gap motivated us to conduct
                                        a systematic literature review (SLR) covering 126 relevant research papers published from 2010 to 2021.","Based on these findings, we recommended key
                                        future research directions, e.g., research for a better understanding of security and privacy aspects in different
                                        multi-device and multi-user contexts, and a more comprehensive ontology on the security and privacy of the
                                        smart home covering varying types of home devices and behaviors of different types of home users.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10126,"Hence, our goal in this paper is to review the current research in this field and determine the
areas where further research is necessary.","Reviews that covered related user
perspectives studies, are either too dated [80, 191], or have a narrower scope, e.g., privacy only [96],
or focused on a particular segment of home users (older users’ privacy attitude) [142, 180].","With this in view, we need to explain two important
terms, which are used throughout this paper.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10127,"A Survey of User Perspectives on Security and Privacy in a Home Networking Environment  27

and hence it is important that further research should consider less-studied areas.",Publication date: August 2022.,"While some
demographic factors have been less or not studied, even for more-studied factor such as gender, we
have observed conflicting results, so more research is needed to consolidate our understanding.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10128,"5.6 Home users’ awareness, perceptions, attitudes, behaviors and practices

Although a lot of work has been done on these aspects, the research gaps we identified in the
previous subsections suggest that there are still several gaps to be filled by further research.","While some
demographic factors have been less or not studied, even for more-studied factor such as gender, we
have observed conflicting results, so more research is needed to consolidate our understanding.","Many
factors, including household types, types of home networks including those with multiple geo-
locations [201], different user structures [118, 200], different usage contexts and scenarios, and
different demographic factors, can affect home users’ awareness, perceptions, attitudes, behaviors
and practices.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10129,"Our
                                        SLR led to the discovery of a number of important areas where further research is needed; these include
                                        holistic methods that consider a more diverse and heterogeneous range of home devices, interactions between
                                        multiple home users, complicated data flow between multiple home devices and home users, some less-studied
                                        demographic factors, and advanced conceptual frameworks.","This identified gap motivated us to conduct
                                        a systematic literature review (SLR) covering 126 relevant research papers published from 2010 to 2021.","Based on these findings, we recommended key
                                        future research directions, e.g., research for a better understanding of security and privacy aspects in different
                                        multi-device and multi-user contexts, and a more comprehensive ontology on the security and privacy of the
                                        smart home covering varying types of home devices and behaviors of different types of home users.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10130,"Hence, our goal in this paper is to review the current research in this field and determine the
areas where further research is necessary.","Reviews that covered related user
perspectives studies, are either too dated [80, 191], or have a narrower scope, e.g., privacy only [96],
or focused on a particular segment of home users (older users’ privacy attitude) [142, 180].","With this in view, we need to explain two important
terms, which are used throughout this paper.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10131,"[44]
suggested that, “geographical perspectives” could be instrumental in deciding human behaviors
and hence it is important that further research should consider less-studied areas.",Chen et al.,"While some
demographic factors have been less or not studied, even for more-studied factor such as gender, we
have observed conflicting results, so more research is needed to consolidate our understanding.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10132,"5.6 Home users’ awareness, perceptions, attitudes, behaviors and practices

Although a lot of work has been done on these aspects, the research gaps we identified in the
previous subsections suggest that there are still several gaps to be filled by further research.","While some
demographic factors have been less or not studied, even for more-studied factor such as gender, we
have observed conflicting results, so more research is needed to consolidate our understanding.","Many
factors, including household types, types of home networks including those with multiple geo-
locations [201], different user structures [118, 200], different usage contexts and scenarios, and
different demographic factors, can affect home users’ awareness, perceptions, attitudes, behaviors
and practices.",2022-08-17 10:00:31+00:00,A Survey of User Perspectives on Security and Privacy in a Home Networking Environment,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Nandita Pattnaik'), arxiv.Result.Author('Shujun Li'), arxiv.Result.Author('Jason R. C. Nurse')]","The security and privacy of smart home systems, particularly from a home
user's perspective, have been a very active research area in recent years.
However, via a meta-review of 52 review papers covering related topics
(published between 2000 and 2021), this paper shows a lack of a more recent
literature review on user perspectives of smart home security and privacy since
the 2010s. This identified gap motivated us to conduct a systematic literature
review (SLR) covering 126 relevant research papers published from 2010 to 2021.
Our SLR led to the discovery of a number of important areas where further
research is needed; these include holistic methods that consider a more diverse
and heterogeneous range of home devices, interactions between multiple home
users, complicated data flow between multiple home devices and home users, some
less-studied demographic factors, and advanced conceptual frameworks. Based on
these findings, we recommended key future research directions, e.g., research
for a better understanding of security and privacy aspects in different
multi-device and multi-user contexts, and a more comprehensive ontology on the
security and privacy of the smart home covering varying types of home devices
and behaviors of different types of home users."
10209,"3A2, Zhang Jiuling served as a prefectural    for further research.",As in Fig.,"The system should provide a set of visual interpre-
  aide in 737 for the Jingzhou prefecture, Shannan circuit.",2022-08-19 09:27:42+00:00,CohortVA: A Visual Analytic System for Interactive Exploration of Cohorts based on Historical Data,cs.HC,['cs.HC'],"[arxiv.Result.Author('Wei Zhang'), arxiv.Result.Author('Jason K. Wong'), arxiv.Result.Author('Xumeng Wang'), arxiv.Result.Author('Youcheng Gong'), arxiv.Result.Author('Rongchen Zhu'), arxiv.Result.Author('Kai Liu'), arxiv.Result.Author('Zihan Yan'), arxiv.Result.Author('Siwei Tan'), arxiv.Result.Author('Huamin Qu'), arxiv.Result.Author('Siming Chen'), arxiv.Result.Author('Wei Chen')]","In history research, cohort analysis seeks to identify social structures and
figure mobilities by studying the group-based behavior of historical figures.
Prior works mainly employ automatic data mining approaches, lacking effective
visual explanation. In this paper, we present CohortVA, an interactive visual
analytic approach that enables historians to incorporate expertise and insight
into the iterative exploration process. The kernel of CohortVA is a novel
identification model that generates candidate cohorts and constructs cohort
features by means of pre-built knowledge graphs constructed from large-scale
history databases. We propose a set of coordinated views to illustrate
identified cohorts and features coupled with historical events and figure
profiles. Two case studies and interviews with historians demonstrate that
CohortVA can greatly enhance the capabilities of cohort identifications, figure
authentications, and hypothesis generation."
10210,"By
function, “which helps me to trace back and adjust my hypotheses for         properly deﬁning the features, it can process large text corpora and rela-
further research.” 3) Providing organized information across various         tional databases for many domains, such as medicine [13], ﬁnance [32],
perspectives enhances the result’s conﬁdence.",H3 highly appreciates the provenance tracking         alizable to domain-speciﬁc tasks targeting closely related groups.,Historians emphasize           and literature analysis [54].,2022-08-19 09:27:42+00:00,CohortVA: A Visual Analytic System for Interactive Exploration of Cohorts based on Historical Data,cs.HC,['cs.HC'],"[arxiv.Result.Author('Wei Zhang'), arxiv.Result.Author('Jason K. Wong'), arxiv.Result.Author('Xumeng Wang'), arxiv.Result.Author('Youcheng Gong'), arxiv.Result.Author('Rongchen Zhu'), arxiv.Result.Author('Kai Liu'), arxiv.Result.Author('Zihan Yan'), arxiv.Result.Author('Siwei Tan'), arxiv.Result.Author('Huamin Qu'), arxiv.Result.Author('Siming Chen'), arxiv.Result.Author('Wei Chen')]","In history research, cohort analysis seeks to identify social structures and
figure mobilities by studying the group-based behavior of historical figures.
Prior works mainly employ automatic data mining approaches, lacking effective
visual explanation. In this paper, we present CohortVA, an interactive visual
analytic approach that enables historians to incorporate expertise and insight
into the iterative exploration process. The kernel of CohortVA is a novel
identification model that generates candidate cohorts and constructs cohort
features by means of pre-built knowledge graphs constructed from large-scale
history databases. We propose a set of coordinated views to illustrate
identified cohorts and features coupled with historical events and figure
profiles. Two case studies and interviews with historians demonstrate that
CohortVA can greatly enhance the capabilities of cohort identifications, figure
authentications, and hypothesis generation."
10324,"One possible explanation is that the BaseLine condition
because it encourages further research into the use of quantitative           creates a feeling of confidence, while the quantitative notification
privacy risk notifications to transparently inform individuals about          cause a more cautious reaction.","This is an important result,       standing.","However, this confidence caused
possible privacy risks when sharing their data.",2022-08-23 09:05:30+00:00,"""Am I Private and If So, how Many?"" - Communicating Privacy Guarantees of Differential Privacy with Risk Communication Formats",cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Daniel Franzen'), arxiv.Result.Author('Saskia Nuñez von Voigt'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Florian Tschorsch'), arxiv.Result.Author('Claudia Müller-Birn')]","Decisions about sharing personal information are not trivial, since there are
many legitimate and important purposes for such data collection, but often the
collected data can reveal sensitive information about individuals.
Privacy-preserving technologies, such as differential privacy (DP), can be
employed to protect the privacy of individuals and, furthermore, provide
mathematically sound guarantees on the maximum privacy risk. However, they can
only support informed privacy decisions, if individuals understand the provided
privacy guarantees. This article proposes a novel approach for communicating
privacy guarantees to support individuals in their privacy decisions when
sharing data. For this, we adopt risk communication formats from the medical
domain in conjunction with a model for privacy guarantees of DP to create
quantitative privacy risk notifications. We conducted a crowd-sourced study
with 343 participants to evaluate how well our notifications conveyed the
privacy risk information and how confident participants were about their own
understanding of the privacy risk. Our findings suggest that these new
notifications can communicate the objective information similarly well to
currently used qualitative notifications, but left individuals less confident
in their understanding. We also discovered that several of our notifications
and the currently used qualitative notification disadvantage individuals with
low numeracy: these individuals appear overconfident compared to their actual
understanding of the associated privacy risks and are, therefore, less likely
to seek the needed additional information before an informed decision. The
promising results allow for multiple directions in future research, for
example, adding visual aids or tailoring privacy risk communication to
characteristics of the individuals."
10325,"Since we could neither
                                                                                                                                                                                                        participating            reject nor confirm the effect between the condition and the privacy
                                                                                                                                                                                                                                 aptitude in our study, further research might shed more light on
                                                                                                                                                                                                                                 this relationship.","Similar work has been
                                                                                                                                                                                                  𝑦𝑁 : people not revealed, not  done under the name of nudges (e.g., [27]).","C RISK COMMUNICATION FORMATS

                                                                                                                                                                                                                                 Table 4 summarizes all discovered medical risk communication
                                                                                                                                                                                                                                 formats.",2022-08-23 09:05:30+00:00,"""Am I Private and If So, how Many?"" - Communicating Privacy Guarantees of Differential Privacy with Risk Communication Formats",cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Daniel Franzen'), arxiv.Result.Author('Saskia Nuñez von Voigt'), arxiv.Result.Author('Peter Sörries'), arxiv.Result.Author('Florian Tschorsch'), arxiv.Result.Author('Claudia Müller-Birn')]","Decisions about sharing personal information are not trivial, since there are
many legitimate and important purposes for such data collection, but often the
collected data can reveal sensitive information about individuals.
Privacy-preserving technologies, such as differential privacy (DP), can be
employed to protect the privacy of individuals and, furthermore, provide
mathematically sound guarantees on the maximum privacy risk. However, they can
only support informed privacy decisions, if individuals understand the provided
privacy guarantees. This article proposes a novel approach for communicating
privacy guarantees to support individuals in their privacy decisions when
sharing data. For this, we adopt risk communication formats from the medical
domain in conjunction with a model for privacy guarantees of DP to create
quantitative privacy risk notifications. We conducted a crowd-sourced study
with 343 participants to evaluate how well our notifications conveyed the
privacy risk information and how confident participants were about their own
understanding of the privacy risk. Our findings suggest that these new
notifications can communicate the objective information similarly well to
currently used qualitative notifications, but left individuals less confident
in their understanding. We also discovered that several of our notifications
and the currently used qualitative notification disadvantage individuals with
low numeracy: these individuals appear overconfident compared to their actual
understanding of the associated privacy risks and are, therefore, less likely
to seek the needed additional information before an informed decision. The
promising results allow for multiple directions in future research, for
example, adding visual aids or tailoring privacy risk communication to
characteristics of the individuals."
10334,"How to conquer this problem may
require further research.","The
actual usefulness provided are vary between documents.","An incremental improvement on the system performance and accuracy can be achieved by
retraining the model with more questionnaire and through a feedback loop.",2022-08-13 18:41:35+00:00,Voice Chatbot for Hospitality,cs.HC,['cs.HC'],"[arxiv.Result.Author('Sagina Athikkal'), arxiv.Result.Author('John Jenq')]","Chatbot is a machine with the ability to answer automatically through a
conversational interface. A chatbot is considered as one of the most
exceptional and promising expressions of human computer interaction.
Voice-based chatbots or artificial intelligence devices transform
human-computer bidirectional interactions that allow users to navigate an
interactive voice response system with their voice generally using natural
language. In this paper, we focus on voice based chatbots for mediating
interactions between hotels and guests from both the hospitality technology
providers' and guests' perspectives. We developed a hotel web application with
the capability to receive a voice input. The application was developed with
Speech recognition and deep synthesis API for voice to text and text to voice
conversion, a closed domain question answering NLP solution was used for query
the answer."
10369,"VR-supported cooperative systems, with              [9] M. Cordeil, T. Dwyer, K. Klein, B. Laha, K. Marriott, and B. H. Thomas,
such focal points as remote control, multiple teleoperators,              “Immersive collaborative analysis of network connectivity: Cave-style
and cognitive workload are fruitful areas for further study.","coordination mechanisms to maintain the ﬂow of work in
VR environments.","or head-mounted display?” IEEE transactions on visualization and
Collaborative work could be greatly enhanced with further                 computer graphics, vol.",2022-08-24 04:18:08+00:00,Collaborative Remote Control of Unmanned Ground Vehicles in Virtual Reality,cs.HC,"['cs.HC', 'cs.RO']","[arxiv.Result.Author('Ziming Li'), arxiv.Result.Author('Yiming Luo'), arxiv.Result.Author('Jialin Wang'), arxiv.Result.Author('Yushan Pan'), arxiv.Result.Author('Lingyun Yu'), arxiv.Result.Author('Hai-Ning Liang')]","Virtual reality (VR) technology is commonly used in entertainment
applications; however, it has also been deployed in practical applications in
more serious aspects of our lives, such as safety. To support people working in
dangerous industries, VR can ensure operators manipulate standardized tasks and
work collaboratively to deal with potential risks. Surprisingly, little
research has focused on how people can collaboratively work in VR environments.
Few studies have paid attention to the cognitive load of operators in their
collaborative tasks. Once task demands become complex, many researchers focus
on optimizing the design of the interaction interfaces to reduce the cognitive
load on the operator. That approach could be of merit; however, it can actually
subject operators to a more significant cognitive load and potentially more
errors and a failure of collaboration. In this paper, we propose a new
collaborative VR system to support two teleoperators working in the VR
environment to remote control an uncrewed ground vehicle. We use a compared
experiment to evaluate the collaborative VR systems, focusing on the time spent
on tasks and the total number of operations. Our results show that the total
number of processes and the cognitive load during operations were significantly
lower in the two-person group than in the single-person group. Our study sheds
light on designing VR systems to support collaborative work with respect to the
flow of work of teleoperators instead of simply optimizing the design outcomes."
10378,"Based on the empirical analyses, we finally selected the variable electric cooking with the InceptionTime
predictor and the SHAP explainer for our further study.","We
computed this frequency using a random selection of 50 households and weeks (see Table 2).","The reasons were that these models showed a

2 Our instance of InceptionTime used the parameters: Max.",2022-08-24 10:03:54+00:00,Explainable AI for tailored electricity consumption feedback -- an experimental evaluation of visualizations,cs.HC,"['cs.HC', 'cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Jacqueline Wastensteiner'), arxiv.Result.Author('Tobias M. Weiss'), arxiv.Result.Author('Felix Haag'), arxiv.Result.Author('Konstantin Hopf')]","Machine learning (ML) methods can effectively analyse data, recognize
patterns in them, and make high-quality predictions. Good predictions usually
come along with ""black-box"" models that are unable to present the detected
patterns in a human-readable way. Technical developments recently led to
eXplainable Artificial Intelligence (XAI) techniques that aim to open such
black-boxes and enable humans to gain new insights from detected patterns. We
investigated the application of XAI in an area where specific insights can have
a significant effect on consumer behaviour, namely electricity use. Knowing
that specific feedback on individuals' electricity consumption triggers
resource conservation, we created five visualizations with ML and XAI methods
from electricity consumption time series for highly personalized feedback,
considering existing domain-specific design knowledge. Our experimental
evaluation with 152 participants showed that humans can assimilate the pattern
displayed by XAI visualizations, but such visualizations should follow known
visualization patterns to be well-understood by users."
10379,"Fifth, further research could focus on feedback elements that show what type of activity contributes how
much to the overall electricity consumption.",Our research design can be extended with alternative technical approaches.,"The new XAI explanations could be embedded in
interactive energy feedback displays that already depict the main energy consuming appliances in
specific time-of-use frames (Costanza et al., 2012).",2022-08-24 10:03:54+00:00,Explainable AI for tailored electricity consumption feedback -- an experimental evaluation of visualizations,cs.HC,"['cs.HC', 'cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Jacqueline Wastensteiner'), arxiv.Result.Author('Tobias M. Weiss'), arxiv.Result.Author('Felix Haag'), arxiv.Result.Author('Konstantin Hopf')]","Machine learning (ML) methods can effectively analyse data, recognize
patterns in them, and make high-quality predictions. Good predictions usually
come along with ""black-box"" models that are unable to present the detected
patterns in a human-readable way. Technical developments recently led to
eXplainable Artificial Intelligence (XAI) techniques that aim to open such
black-boxes and enable humans to gain new insights from detected patterns. We
investigated the application of XAI in an area where specific insights can have
a significant effect on consumer behaviour, namely electricity use. Knowing
that specific feedback on individuals' electricity consumption triggers
resource conservation, we created five visualizations with ML and XAI methods
from electricity consumption time series for highly personalized feedback,
considering existing domain-specific design knowledge. Our experimental
evaluation with 152 participants showed that humans can assimilate the pattern
displayed by XAI visualizations, but such visualizations should follow known
visualization patterns to be well-understood by users."
10380,"12
XAI for electricity consumption feedback

the recent calls for empirical research to get a better understanding on how to integrate AI in human
workplaces (Lyytinen et al., 2020; Rai et al., 2019), and the importance of AI technology to support
humans by augmenting reality rather than replacing humans by AI (Raisch and Krakowski, 2020), our
study demonstrated the power of XAI methods in human-AI interface design and highlights areas of
further research and development.","Given

Twenty-Ninth European Conference on Information Systems (ECIS 2021), Marrakesh, Morocco.","8 Appendix: Requirements and design features for XAI-based
    feedback on electricity consumption

We reviewed the related research fields to identify design requirements for XAI-based feedback on
electricity consumption.",2022-08-24 10:03:54+00:00,Explainable AI for tailored electricity consumption feedback -- an experimental evaluation of visualizations,cs.HC,"['cs.HC', 'cs.AI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Jacqueline Wastensteiner'), arxiv.Result.Author('Tobias M. Weiss'), arxiv.Result.Author('Felix Haag'), arxiv.Result.Author('Konstantin Hopf')]","Machine learning (ML) methods can effectively analyse data, recognize
patterns in them, and make high-quality predictions. Good predictions usually
come along with ""black-box"" models that are unable to present the detected
patterns in a human-readable way. Technical developments recently led to
eXplainable Artificial Intelligence (XAI) techniques that aim to open such
black-boxes and enable humans to gain new insights from detected patterns. We
investigated the application of XAI in an area where specific insights can have
a significant effect on consumer behaviour, namely electricity use. Knowing
that specific feedback on individuals' electricity consumption triggers
resource conservation, we created five visualizations with ML and XAI methods
from electricity consumption time series for highly personalized feedback,
considering existing domain-specific design knowledge. Our experimental
evaluation with 152 participants showed that humans can assimilate the pattern
displayed by XAI visualizations, but such visualizations should follow known
visualization patterns to be well-understood by users."
10501,"In future,
we plan to increase the maximum temperature change allowed            immersive experiences in applications, such as those of VR
by our device to further study human thermal perception to
improve the reliability of the proposed method for general            and metaverse.","They             a multisensory interactive system to provide users with more
may require a larger temperature change to feel cold.",applications involving thermal stimulation.,2022-08-28 14:55:46+00:00,Intensity-Adjustable Non-contact Cold Sensation Presentation Based on the Vortex Effect,cs.HC,['cs.HC'],"[arxiv.Result.Author('Jiayi Xu'), arxiv.Result.Author('Shunsuke Yoshimoto'), arxiv.Result.Author('Naoto Ienaga'), arxiv.Result.Author('Yoshihiro Kuroda')]","Cold sensations of varying intensities are perceived when human skin is
subject to diverse environments. The accurate presentation of temperature
changes is important to elicit immersive sensations in applications such as
virtual reality. We developed a method to elicit intensity-adjustable
non-contact cold sensations based on the vortex effect. We applied this effect
to generate cold air at approximately 0 {\deg}C and varied the skin temperature
over a wide range. The perception of different temperatures can be elicited by
adjusting the volume flow rate of the cold air. Additionally, we introduced a
cooling model to relate the changes in skin temperature to various parameters
such as the cold air volume flow rate and distance from the cold air outlet to
the skin. For validation, we conducted measurement experiments and found that
our model can estimate the change in skin temperature with a root mean-square
error of 0.16 {\deg}C. Furthermore, we evaluated the performance of a prototype
in psychophysical cold discrimination experiments based on the discrimination
threshold. Thus, cold sensations of varying intensities can be generated by
varying the parameters. These cold sensations can be combined with images,
sounds, and other stimuli to create an immersive and realistic artificial
environment."
10580,"These include touchscreen maps, shockwave-          further research in physical world navigation and exploration.","We also dis-
   Researchers have developed several types of SATs which repre-         cuss the potential for developing purpose-built hardware for spatial
sent very different approaches for facilitating a representation of the  awareness and how our findings within virtual worlds can inspire
game world for VIPs.","like systems, directional scanners, and audio-based menus.",2022-08-31 00:08:43+00:00,Uncovering Visually Impaired Gamers' Preferences for Spatial Awareness Tools Within Video Games,cs.HC,['cs.HC'],"[arxiv.Result.Author('Vishnu Nair'), arxiv.Result.Author('Shao-en Ma'), arxiv.Result.Author('Ricardo E. Gonzalez Penuela'), arxiv.Result.Author('Yicheng He'), arxiv.Result.Author('Karen Lin'), arxiv.Result.Author('Mason Hayes'), arxiv.Result.Author('Hannah Huddleston'), arxiv.Result.Author('Matthew Donnelly'), arxiv.Result.Author('Brian A. Smith')]","Sighted players gain spatial awareness within video games through sight and
spatial awareness tools (SATs) such as minimaps. Visually impaired players
(VIPs), however, must often rely heavily on SATs to gain spatial awareness,
especially in complex environments where using rich ambient sound design alone
may be insufficient. Researchers have developed many SATs for facilitating
spatial awareness within VIPs. Yet this abundance disguises a gap in our
understanding about how exactly these approaches assist VIPs in gaining spatial
awareness and what their relative merits and limitations are. To address this,
we investigate four leading approaches to facilitating spatial awareness for
VIPs within a 3D video game context. Our findings uncover new insights into
SATs for VIPs within video games, including that VIPs value position and
orientation information the most from an SAT; that none of the approaches we
investigated convey position and orientation effectively; and that VIPs highly
value the ability to customize SATs."
10611,"[34] concluded
their paper acknowledging that further research is needed to address the broader ethical and societal
concerns of robotic technologies.",Fiske et al.,"Also, Stahl and Coeckelbergh [81] discussed ethical aspects, and
they proposed a new framework to evaluate ethical principles and support researchers in this
process, namely Responsible Research and Innovation for healthcare robotics.",2022-08-31 14:01:14+00:00,Robots as Mental Well-being Coaches: Design and Ethical Recommendations,cs.HC,"['cs.HC', 'cs.RO']","[arxiv.Result.Author('Minja Axelsson'), arxiv.Result.Author('Micol Spitale'), arxiv.Result.Author('Hatice Gunes')]","The last decade has shown a growing interest in robots as well-being coaches.
However, cohesive and comprehensive guidelines for the design of robots as
coaches to promote mental well-being have not yet been proposed. This paper
details design and ethical recommendations based on a qualitative meta-analysis
drawing on a grounded theory approach, which was conducted with three distinct
user-centered design studies involving robotic well-being coaches, namely: (1)
a participatory design study conducted with 11 participants consisting of both
prospective users who had participated in a Brief Solution-Focused Practice
study with a human coach, as well as coaches of different disciplines, (2)
semi-structured individual interview data gathered from 20 participants
attending a Positive Psychology intervention study with the robotic well-being
coach Pepper, and (3) a participatory design study conducted with 3
participants of the Positive Psychology study as well as 2 relevant well-being
coaches. After conducting a thematic analysis and a qualitative meta-analysis,
we collated the data gathered into convergent and divergent themes, and we
distilled from those results a set of design guidelines and ethical
considerations. Our findings can inform researchers and roboticists on the key
aspects to take into account when designing robotic mental well-being coaches."
10746,"A further study could be conducted on a larger population of engineering
experts which would yield greater accuracy in understanding the eﬀectiveness of
the application.","Qualitative results suggest that engineering professionals
ﬁnd part collisions and superposition of virtual assembly parts within a physical
context as a useful and cost-eﬀective tool for conducting an assembly design re-
view.","6 Conclusion

The developed application is designed to enhance the eﬃciency of mechanical
design engineers when conducting DFMA.",2022-09-02 19:41:29+00:00,Mixed Reality for Mechanical Design and Assembly Planning,cs.HC,['cs.HC'],"[arxiv.Result.Author('Emran Poh'), arxiv.Result.Author('Kyrin Liong'), arxiv.Result.Author('Jeannie Lee')]","Design for Manufacturing and Assembly (DFMA) is a crucial design stage within
the heavy vehicle manufacturing process that involves optimising the order and
feasibility of the parts assembly process to reduce manufacturing complexity
and overall cost. Existing work has focused on conducting DFMA within virtual
environments to reduce manufacturing costs, but users are less able to relate
and compare physical characteristics of a virtual component with real physical
objects. Therefore, a Mixed Reality (MR) application is developed for engineers
to visualise and manipulate assembly parts virtually, conduct and plan out an
assembly within its intended physical environment. Two pilot evaluations were
conducted with both engineering professionals and non-engineers to assess
effectiveness of the software for assembly planning. Usability results suggest
that the application is overall usable (M=56.1, SD=7.89), and participants felt
a sense of involvement in the activity (M=13.1, SD=3.3). Engineering
professionals see the application as a useful and cost-effective tool for
optimising their mechanical assembly designs."
10781,"However, the analysis of situated visualization scenarios will                    turing, 61:101830:1–15, 2020.
require further research on how to combine and represent the tracked              [10] S. Chatterjee, K. Scheck, D. Ku¨ster, F. Putze, H. Moturu, J. Schering,
data from multiple participants best to derive meaningful insights.","Robotics and Computer-Integrated Manufac-
ware.","J. M. Go´mez, and T. Schultz.",2022-09-05 09:10:04+00:00,Evaluating Situated Visualization in AR with Eye Tracking,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Kuno Kurzhals'), arxiv.Result.Author('Michael Becher'), arxiv.Result.Author('Nelusa Pathmanathan'), arxiv.Result.Author('Guido Reina')]","Augmented reality (AR) technology provides means for embedding visualization
in a real-world context. Such techniques allow situated analyses of live data
in their spatial domain. However, as existing techniques have to be adapted for
this context and new approaches will be developed, the evaluation thereof poses
new challenges for researchers. Apart from established performance measures,
eye tracking has proven to be a valuable means to assess visualizations
qualitatively and quantitatively. We discuss the challenges and opportunities
of eye tracking for the evaluation of situated visualizations. We envision that
an extension of gaze-based evaluation methodology into this field will provide
new insights on how people perceive and interact with visualizations in
augmented reality."
10806,A further study with wheelchair users will be conducted                       reality.,"Effects of digital navigation aids on adults with intellectual
sports scientists to evaluate and modify the ARFit to make it more                       disabilities: Comparison of paper map, google maps, and augmented
inclusive.","Journal of Special Education Technology, 30(3):157–165, 2015.
to investigate the feasibility, acceptability, and effectiveness of using                doi: 10.1177/0162643415618927
ARFit for learning exercises.",2022-09-05 22:49:17+00:00,Comparative Study of AR Versus Image and Video for Exercise Learning,cs.HC,"['cs.HC', 'cs.MM', 'J.0; K.3']","[arxiv.Result.Author('Jamie Burns'), arxiv.Result.Author('Wenge Xu'), arxiv.Result.Author('Ian Williams'), arxiv.Result.Author('Irfan Khawaja')]","There is inadequate attention to using mobile Augmented Reality (AR) in
fitness, despite mobile AR being easy to use, requiring no extra cost, and can
be a powerful learning tool. In this work, we present a mobile AR application
that can help users learn exercises with a virtual personal trainer. We conduct
a user study with 10 participants to investigate the learning quality of the
ARFit (i.e., the proposed mobile AR application) in comparison to traditional
methods such as Image-based learning and Video-based learning. Our results
indicate that participants have a higher learning quality of exercise with
mobile AR than (1) Image-based learning among all exercises selected and (2)
video-based learning with exercise that requires greater spatial knowledge,
with the performance evaluated by a qualified personal trainer. In addition,
ARFit has an excellent rating in usability, is deemed to be highly acceptable,
and is the preferred exercise learning method by most participants (N=9)"
10808,"Future research should observe these
                                                                          interactions and further study how the interactions can be exploited
                                                                          and guided to enhance collaboration.","With more users engaged in the teaching process, new types of
                                                                          teaching interactions may emerge, bringing new research questions
                                                                          that requires investigation.","4
Exploiting and Guiding User Interaction in Interactive Machine Teaching                          UIST ’22 Adjunct, October 29-November 2, 2022, Bend, OR, USA

REFERENCES                                                                                       [19] Patrice Y. Simard, Saleema Amershi, David M. Chickering, Alicia Edelman Pelton,
                                                                                                       Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey,
 [1] Dimitrios Bounias, Ashish Singh, Spyridon Bakas, Sarthak Pati, Saima Rathore,                     Mo Wang, and John Wernsing.",2022-09-06 03:58:18+00:00,Exploiting and Guiding User Interaction in Interactive Machine Teaching,cs.HC,['cs.HC'],[arxiv.Result.Author('Zhongyi Zhou')],"Humans are talented with the ability to perform diverse interactions in the
teaching process. However, when humans want to teach AI, existing interactive
systems only allow humans to perform repetitive labeling, causing an
unsatisfactory teaching experience. My Ph.D. research studies Interactive
Machine Teaching (IMT), an emerging field of HCI research that aims to enhance
humans' teaching experience in the AI creation process. My research builds IMT
systems that exploit and guide user interaction and shows that such in-depth
integration of human interaction can benefit both AI models and user
experience."
10823,"Given that we
the perspectives of rules, or more specifically, “challenges.” Poor           referred to engagement in this paper, focusing on this point will be
usability leads to the potential of a challenge, which can lead to            particularly be important for further research.","[95] captured laughter to seek happiness,
and play literature (e.g., [51]), an experience can be designed from          and this also discussed by using the term enjoyment.","There are also cases
enjoyment, similar to that of games [84].",2022-09-06 09:02:28+00:00,Is it Fun?: Understanding Enjoyment in Non-Game HCI Research,cs.HC,['cs.HC'],"[arxiv.Result.Author('Michinari Kono'), arxiv.Result.Author('Koichi Araake')]","An experience of fun can be an important factor for validating the value of
games. Research on non-game HCI has been attempted to measure the enjoyment of
work. However, a majority of the studies do not discuss the importance and
value of the result. It is not clear as to how the term fun is understood in a
non-game context. To analyze this shortcoming, we reviewed extant studies, and
explored as to how researchers determine if the value of an activity is fun.
Consequently, we discussed and categorized the usage of the terms and analyzed
the methodologies that are used in extant studies that evaluate the effects of
fun and related terms. To gain a better understanding of fun in HCI, we
provided several directions that can be discussed for strengthening enjoyable
HCI research beyond applications involving games."
10831,"We encourage
further research to build new items for ALTAI on this topic, and suggest t h e u se o f
LifeComp competences for its development (Sala, et al., 2020): personal (self-
regulation, flexibility, well-being), social (empathy, communication, collab oratio n),
and learning to learn (growth mindset, critical thinking, managing learning).","This new - an d
needed- section would change our results of the risk assessment.","6 Conclusions

We have performed a literature review on conversational agents (CAs), id ent ify in g
opportunities, challenges and risks for their use with children.",2022-09-01 09:45:08+00:00,Guidelines to Develop Trustworthy Conversational Agents for Children,cs.HC,['cs.HC'],"[arxiv.Result.Author('Marina Escobar-Planas'), arxiv.Result.Author('Emilia Gómez'), arxiv.Result.Author('Carlos-D Martínez-Hinarejos')]","Conversational agents (CAs) embodied in speakers or chatbots are becoming
very popular in some countries, and despite their adult-centred design, they
have become part of children's lives, generating a need for children-centric
trustworthy systems. This paper presents a literature review to identify the
main opportunities, challenges and risks brought by CAs when used by children.
We then consider relevant ethical guidelines for AI and adapt them to this
particular system and population, using a Delphi methodology with a set of
experts from different disciplines. From this analysis, we propose specific
guidelines to help CAs developers improve their design towards trustworthiness
and children."
10914,"While Sporthesia
 and visualizing the deep semantic information are both challenging           is designed and implemented for tennis and table tennis, it can be
 tasks, which requires further study in NLP and visualizations.","“comments the same [kinds of] actions”, the visualizations should be
 different since he may have “different tendencies.” However, extracting      Generalizability—beyond racket-based sports.","From the      generalized to other racket- or team-based sports as it is built based
 perspective of visualization, visualizing such kind of highly abstract       on a formative study of both racket- and team-based sports.",2022-09-07 19:31:25+00:00,Sporthesia: Augmenting Sports Videos Using Natural Language,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Zhutian Chen'), arxiv.Result.Author('Qisen Yang'), arxiv.Result.Author('Xiao Xie'), arxiv.Result.Author('Johanna Beyer'), arxiv.Result.Author('Haijun Xia'), arxiv.Result.Author('Yingcai Wu'), arxiv.Result.Author('Hanspeter Pfister')]","Augmented sports videos, which combine visualizations and video effects to
present data in actual scenes, can communicate insights engagingly and thus
have been increasingly popular for sports enthusiasts around the world. Yet,
creating augmented sports videos remains a challenging task, requiring
considerable time and video editing skills. On the other hand, sports insights
are often communicated using natural language, such as in commentaries, oral
presentations, and articles, but usually lack visual cues. Thus, this work aims
to facilitate the creation of augmented sports videos by enabling analysts to
directly create visualizations embedded in videos using insights expressed in
natural language. To achieve this goal, we propose a three-step approach - 1)
detecting visualizable entities in the text, 2) mapping these entities into
visualizations, and 3) scheduling these visualizations to play with the video -
and analyzed 155 sports video clips and the accompanying commentaries for
accomplishing these steps. Informed by our analysis, we have designed and
implemented Sporthesia, a proof-of-concept system that takes racket-based
sports videos and textual commentaries as the input and outputs augmented
videos. We demonstrate Sporthesia's applicability in two exemplar scenarios,
i.e., authoring augmented sports videos using text and augmenting historical
sports videos based on auditory comments. A technical evaluation shows that
Sporthesia achieves high accuracy (F1-score of 0.9) in detecting visualizable
entities in the text. An expert evaluation with eight sports analysts suggests
high utility, effectiveness, and satisfaction with our language-driven
authoring method and provides insights for future improvement and
opportunities."
10952,"Introverted people should be considered as a relevant user group for Robotic Coaches and interactions
with such groups needs further research.","These results are supported by participants describing that the robot could be especially useful for
introverted users.","For this user group, the robot could provide the advantages of being accessible,
helping the participants speak out loud, and provide a lack of judgement and sense of presence.",2022-09-08 14:01:09+00:00,Participant Perceptions of a Robotic Coach Conducting Positive Psychology Exercises: A Systematic Analysis,cs.HC,"['cs.HC', 'cs.RO']","[arxiv.Result.Author('Minja Axelsson'), arxiv.Result.Author('Nikhil Churamani'), arxiv.Result.Author('Atahan Caldir'), arxiv.Result.Author('Hatice Gunes')]","This paper provides a detailed overview of a case study of applying Continual
Learning (CL) to a single-session Human-Robot Interaction (HRI) session (avg.
31 +- 10 minutes), where a robotic mental well-being coach conducted Positive
Psychology (PP) exercises with (n = 20) participants. We present the results of
a Thematic Analysis (TA) of data recorded from brief semi-structured interviews
that were conducted with participants after the interaction sessions, as well
as an analysis of statistical results demonstrating how participants'
personalities may affect how they perceive the robot and its interactions."
11063,"Given that gender may influence cybersickness [47, 49],
Section 5.7.1 and Section 5.7.2.                                             we plan to conduct a further study with more diverse and gender-
                                                                             balanced participants.",Their feature ranking with global explanation is discussed in         balanced.,"6 DISCUSSION
                                                                             8 CONCLUSION AND FUTURE WORKS
Our results show that the EBM model can classify the cybersickness
with an accuracy of 99.75% for the physiological and 94.10% for              In this paper, we used xML-based models namely, EBM, DT, LR,
the gameplay dataset with explainability.",2022-09-12 13:55:13+00:00,TruVR: Trustworthy Cybersickness Detection using Explainable Machine Learning,cs.HC,"['cs.HC', 'cs.LG']","[arxiv.Result.Author('Ripan Kumar Kundu'), arxiv.Result.Author('Rifatul Islam'), arxiv.Result.Author('Prasad Calyam'), arxiv.Result.Author('Khaza Anuarul Hoque')]","Cybersickness can be characterized by nausea, vertigo, headache, eye strain,
and other discomforts when using virtual reality (VR) systems. The previously
reported machine learning (ML) and deep learning (DL) algorithms for detecting
(classification) and predicting (regression) VR cybersickness use black-box
models; thus, they lack explainability. Moreover, VR sensors generate a massive
amount of data, resulting in complex and large models. Therefore, having
inherent explainability in cybersickness detection models can significantly
improve the model's trustworthiness and provide insight into why and how the
ML/DL model arrived at a specific decision. To address this issue, we present
three explainable machine learning (xML) models to detect and predict
cybersickness: 1) explainable boosting machine (EBM), 2) decision tree (DT),
and 3) logistic regression (LR). We evaluate xML-based models with publicly
available physiological and gameplay datasets for cybersickness. The results
show that the EBM can detect cybersickness with an accuracy of 99.75% and
94.10% for the physiological and gameplay datasets, respectively. On the other
hand, while predicting the cybersickness, EBM resulted in a Root Mean Square
Error (RMSE) of 0.071 for the physiological dataset and 0.27 for the gameplay
dataset. Furthermore, the EBM-based global explanation reveals exposure length,
rotation, and acceleration as key features causing cybersickness in the
gameplay dataset. In contrast, galvanic skin responses and heart rate are most
significant in the physiological dataset. Our results also suggest that
EBM-based local explanation can identify cybersickness-causing factors for
individual samples. We believe the proposed xML-based cybersickness detection
method can help future researchers understand, analyze, and design simpler
cybersickness detection and reduction models."
11159,"Since the absence of evidence is not evidence of absence, further research is needed to foster the user-developer
communication effectively.","However, when users do not report issues to developers, the perceived idea is that there are no

                                                                                           11
NordiCHI ’22, October 8–12, 2022, Aarhus, Denmark  Mohammed Alhamadi, Omar Alghamdi, Sarah Clinch, and Markel Vigo

problems.","Also, our results suggest that there are barriers that prevent effective communication between
developers and users.",2022-09-14 01:14:46+00:00,"Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design",cs.HC,['cs.HC'],"[arxiv.Result.Author('Mohammed Alhamadi'), arxiv.Result.Author('Omar Alghamdi'), arxiv.Result.Author('Sarah Clinch'), arxiv.Result.Author('Markel Vigo')]","Interactive information dashboards can help both specialists and the general
public understand complex datasets; but interacting with these dashboards often
presents users with challenges such as understanding and verifying the
presented information. To overcome these challenges, developers first need to
acquire a thorough understanding of user perspectives, including strategies
that users take when presented with problematic dashboards. We interviewed
seventeen dashboard developers to establish (i) their understanding of user
problems, (ii) the adaptations introduced as a result, and (iii) whether
user-tailored dashboards can cater for users' individual differences. We find
that users' literacy does not typically align with that required to use
dashboards, while dashboard developers struggle with keeping up with changing
requirements. We also find that developers are able to propose solutions to
most users' problems but not all. Encouragingly, our findings also highlight
that tailoring dashboards to individual user needs is not only desirable, but
also feasible. These findings inform future dashboard design recommendations
that can mitigate the identified challenges including recommendations for data
presentation and visual literacy."
11160,"This highlights the need for further research
to explore the feasibility of the adaptations.","Furthermore,
some participants could not give any suggestions to raised challenges such as data verification and interoperability
issues (as we asked for solutions to problems they had not reported).","The developers’ domains of expertise, although diverse, did not have a
noticeable effect on their development practices or suggested adaptations.",2022-09-14 01:14:46+00:00,"Data Quality, Mismatched Expectations, and Moving Requirements: The Challenges of User-Centred Dashboard Design",cs.HC,['cs.HC'],"[arxiv.Result.Author('Mohammed Alhamadi'), arxiv.Result.Author('Omar Alghamdi'), arxiv.Result.Author('Sarah Clinch'), arxiv.Result.Author('Markel Vigo')]","Interactive information dashboards can help both specialists and the general
public understand complex datasets; but interacting with these dashboards often
presents users with challenges such as understanding and verifying the
presented information. To overcome these challenges, developers first need to
acquire a thorough understanding of user perspectives, including strategies
that users take when presented with problematic dashboards. We interviewed
seventeen dashboard developers to establish (i) their understanding of user
problems, (ii) the adaptations introduced as a result, and (iii) whether
user-tailored dashboards can cater for users' individual differences. We find
that users' literacy does not typically align with that required to use
dashboards, while dashboard developers struggle with keeping up with changing
requirements. We also find that developers are able to propose solutions to
most users' problems but not all. Encouragingly, our findings also highlight
that tailoring dashboards to individual user needs is not only desirable, but
also feasible. These findings inform future dashboard design recommendations
that can mitigate the identified challenges including recommendations for data
presentation and visual literacy."
11200,"Our results provide     helpful in many scenarios where hands or handheld controllers are
                                        a solid platform for further research in this important area.","As described earlier, hands-free interaction is
                                        free interaction for text selection in VR HMDs.",not available or impractical to use.,2022-09-14 09:25:54+00:00,An Exploration of Hands-free Text Selection for Virtual Reality Head-Mounted Displays,cs.HC,"['cs.HC', 'H.5.1; I.3.7']","[arxiv.Result.Author('Xuanru Meng'), arxiv.Result.Author('Wenge Xu'), arxiv.Result.Author('Hai-Ning Liang')]","Hand-based interaction, such as using a handheld controller or making hand
gestures, has been widely adopted as the primary method for interacting with
both virtual reality (VR) and augmented reality (AR) head-mounted displays
(HMDs). In contrast, hands-free interaction avoids the need for users' hands
and although it can afford additional benefits, there has been limited research
in exploring and evaluating hands-free techniques for these HMDs. As VR HMDs
become ubiquitous, people will need to do text editing, which requires
selecting text segments. Similar to hands-free interaction, text selection is
underexplored. This research focuses on both, text selection via hands-free
interaction. Our exploration involves a user study with 24 participants to
investigate the performance, user experience, and workload of three hands-free
selection mechanisms (Dwell, Blink, Voice) to complement head-based pointing.
Results indicate that Blink outperforms Dwell and Voice in completion time.
Users' subjective feedback also shows that Blink is the preferred technique for
text selection. This work is the first to explore hands-free interaction for
text selection in VR HMDs. Our results provide a solid platform for further
research in this important area."
11201,"As such, our work can serve as the
                                                                                                                foundation for further research linking text selection and hands-free
                                            *e-mail: xuanru.meng18@student.xjtlu.edu.cn                         interaction.","a recent paper has explored text selection techniques in VR [48],
                                                                                                                their techniques are non-hands-free and are based on hand-based
                                           Text selection is an essential task when reading text content such   and controller-based interaction.","†e-mail: wenge.xu@bcu.ac.uk
                                            ‡e-mail: haining.liang@xjtlu.edu.cn (corresponding author)          2 EVALUATED SELECTION METHODS

                                                                                                                In this section, we described the selected hands-free methods evalu-
                                                                                                                ated in this work.",2022-09-14 09:25:54+00:00,An Exploration of Hands-free Text Selection for Virtual Reality Head-Mounted Displays,cs.HC,"['cs.HC', 'H.5.1; I.3.7']","[arxiv.Result.Author('Xuanru Meng'), arxiv.Result.Author('Wenge Xu'), arxiv.Result.Author('Hai-Ning Liang')]","Hand-based interaction, such as using a handheld controller or making hand
gestures, has been widely adopted as the primary method for interacting with
both virtual reality (VR) and augmented reality (AR) head-mounted displays
(HMDs). In contrast, hands-free interaction avoids the need for users' hands
and although it can afford additional benefits, there has been limited research
in exploring and evaluating hands-free techniques for these HMDs. As VR HMDs
become ubiquitous, people will need to do text editing, which requires
selecting text segments. Similar to hands-free interaction, text selection is
underexplored. This research focuses on both, text selection via hands-free
interaction. Our exploration involves a user study with 24 participants to
investigate the performance, user experience, and workload of three hands-free
selection mechanisms (Dwell, Blink, Voice) to complement head-based pointing.
Results indicate that Blink outperforms Dwell and Voice in completion time.
Users' subjective feedback also shows that Blink is the preferred technique for
text selection. This work is the first to explore hands-free interaction for
text selection in VR HMDs. Our results provide a solid platform for further
research in this important area."
11202,"Our results provide     helpful in many scenarios where hands or handheld controllers are
                                        a solid platform for further research in this important area.","As described earlier, hands-free interaction is
                                        free interaction for text selection in VR HMDs.",not available or impractical to use.,2022-09-14 09:25:54+00:00,An Exploration of Hands-free Text Selection for Virtual Reality Head-Mounted Displays,cs.HC,"['cs.HC', 'H.5.1; I.3.7']","[arxiv.Result.Author('Xuanru Meng'), arxiv.Result.Author('Wenge Xu'), arxiv.Result.Author('Hai-Ning Liang')]","Hand-based interaction, such as using a handheld controller or making hand
gestures, has been widely adopted as the primary method for interacting with
both virtual reality (VR) and augmented reality (AR) head-mounted displays
(HMDs). In contrast, hands-free interaction avoids the need for users' hands
and although it can afford additional benefits, there has been limited research
in exploring and evaluating hands-free techniques for these HMDs. As VR HMDs
become ubiquitous, people will need to do text editing, which requires
selecting text segments. Similar to hands-free interaction, text selection is
underexplored. This research focuses on both, text selection via hands-free
interaction. Our exploration involves a user study with 24 participants to
investigate the performance, user experience, and workload of three hands-free
selection mechanisms (Dwell, Blink, Voice) to complement head-based pointing.
Results indicate that Blink outperforms Dwell and Voice in completion time.
Users' subjective feedback also shows that Blink is the preferred technique for
text selection. This work is the first to explore hands-free interaction for
text selection in VR HMDs. Our results provide a solid platform for further
research in this important area."
11203,"As such, our work can serve as the
                                                                                                                foundation for further research linking text selection and hands-free
                                            *e-mail: xuanru.meng18@student.xjtlu.edu.cn                         interaction.","a recent paper has explored text selection techniques in VR [48],
                                                                                                                their techniques are non-hands-free and are based on hand-based
                                           Text selection is an essential task when reading text content such   and controller-based interaction.","†e-mail: wenge.xu@bcu.ac.uk
                                            ‡e-mail: haining.liang@xjtlu.edu.cn (corresponding author)          2 EVALUATED SELECTION METHODS

                                                                                                                In this section, we described the selected hands-free methods evalu-
                                                                                                                ated in this work.",2022-09-14 09:25:54+00:00,An Exploration of Hands-free Text Selection for Virtual Reality Head-Mounted Displays,cs.HC,"['cs.HC', 'H.5.1; I.3.7']","[arxiv.Result.Author('Xuanru Meng'), arxiv.Result.Author('Wenge Xu'), arxiv.Result.Author('Hai-Ning Liang')]","Hand-based interaction, such as using a handheld controller or making hand
gestures, has been widely adopted as the primary method for interacting with
both virtual reality (VR) and augmented reality (AR) head-mounted displays
(HMDs). In contrast, hands-free interaction avoids the need for users' hands
and although it can afford additional benefits, there has been limited research
in exploring and evaluating hands-free techniques for these HMDs. As VR HMDs
become ubiquitous, people will need to do text editing, which requires
selecting text segments. Similar to hands-free interaction, text selection is
underexplored. This research focuses on both, text selection via hands-free
interaction. Our exploration involves a user study with 24 participants to
investigate the performance, user experience, and workload of three hands-free
selection mechanisms (Dwell, Blink, Voice) to complement head-based pointing.
Results indicate that Blink outperforms Dwell and Voice in completion time.
Users' subjective feedback also shows that Blink is the preferred technique for
text selection. This work is the first to explore hands-free interaction for
text selection in VR HMDs. Our results provide a solid platform for further
research in this important area."
11272,"), further study is required to understand the reason for these
1975].","1974,     etc.",We use these results in this research and only conducted         differences.,2022-09-15 21:12:38+00:00,Color-Perception-Guided Display Power Reduction for Virtual Reality,cs.HC,['cs.HC'],"[arxiv.Result.Author('Budmonde Duinkharjav'), arxiv.Result.Author('Kenneth Chen'), arxiv.Result.Author('Abhishek Tyagi'), arxiv.Result.Author('Jiayi He'), arxiv.Result.Author('Yuhao Zhu'), arxiv.Result.Author('Qi Sun')]","Battery life is an increasingly urgent challenge for today's untethered VR
and AR devices. However, the power efficiency of head-mounted displays is
naturally at odds with growing computational requirements driven by better
resolution, refresh rate, and dynamic ranges, all of which reduce the sustained
usage time of untethered AR/VR devices. For instance, the Oculus Quest 2, under
a fully-charged battery, can sustain only 2 to 3 hours of operation time. Prior
display power reduction techniques mostly target smartphone displays. Directly
applying smartphone display power reduction techniques, however, degrades the
visual perception in AR/VR with noticeable artifacts. For instance, the
""power-saving mode"" on smartphones uniformly lowers the pixel luminance across
the display and, as a result, presents an overall darkened visual perception to
users if directly applied to VR content.
  Our key insight is that VR display power reduction must be cognizant of the
gaze-contingent nature of high field-of-view VR displays. To that end, we
present a gaze-contingent system that, without degrading luminance, minimizes
the display power consumption while preserving high visual fidelity when users
actively view immersive video sequences. This is enabled by constructing a
gaze-contingent color discrimination model through psychophysical studies, and
a display power model (with respect to pixel color) through real-device
measurements. Critically, due to the careful design decisions made in
constructing the two models, our algorithm is cast as a constrained
optimization problem with a closed-form solution, which can be implemented as a
real-time, image-space shader. We evaluate our system using a series of
psychophysical studies and large-scale analyses on natural images. Experiment
results show that our system reduces the display power by as much as 24% with
little to no perceptual fidelity degradation."
11273,"), further study is required to understand the reason for these
1975].","1974,     etc.",We use these results in this research and only conducted         differences.,2022-09-15 21:12:38+00:00,Color-Perception-Guided Display Power Reduction for Virtual Reality,cs.HC,['cs.HC'],"[arxiv.Result.Author('Budmonde Duinkharjav'), arxiv.Result.Author('Kenneth Chen'), arxiv.Result.Author('Abhishek Tyagi'), arxiv.Result.Author('Jiayi He'), arxiv.Result.Author('Yuhao Zhu'), arxiv.Result.Author('Qi Sun')]","Battery life is an increasingly urgent challenge for today's untethered VR
and AR devices. However, the power efficiency of head-mounted displays is
naturally at odds with growing computational requirements driven by better
resolution, refresh rate, and dynamic ranges, all of which reduce the sustained
usage time of untethered AR/VR devices. For instance, the Oculus Quest 2, under
a fully-charged battery, can sustain only 2 to 3 hours of operation time. Prior
display power reduction techniques mostly target smartphone displays. Directly
applying smartphone display power reduction techniques, however, degrades the
visual perception in AR/VR with noticeable artifacts. For instance, the
""power-saving mode"" on smartphones uniformly lowers the pixel luminance across
the display and, as a result, presents an overall darkened visual perception to
users if directly applied to VR content.
  Our key insight is that VR display power reduction must be cognizant of the
gaze-contingent nature of high field-of-view VR displays. To that end, we
present a gaze-contingent system that, without degrading luminance, minimizes
the display power consumption while preserving high visual fidelity when users
actively view immersive video sequences. This is enabled by constructing a
gaze-contingent color discrimination model through psychophysical studies, and
a display power model (with respect to pixel color) through real-device
measurements. Critically, due to the careful design decisions made in
constructing the two models, our algorithm is cast as a constrained
optimization problem with a closed-form solution, which can be implemented as a
real-time, image-space shader. We evaluate our system using a series of
psychophysical studies and large-scale analyses on natural images. Experiment
results show that our system reduces the display power by as much as 24% with
little to no perceptual fidelity degradation."
11295,"For further research, a mobile app can be built for
the COVID-19 vaccine registration process.","This prototype can be used not only for iOS Apps but also compatible or can be used for the
development of Android Apps or other mobile applications.","Last but not least, the Author also intends to extend the research
involving knowledge management systems (Abdillah, Sari, & Indriani, 2018) concepts.",2022-09-16 09:35:32+00:00,Mobile-Based COVID-19 Vaccination Registration Application Prototype,cs.HC,['cs.HC'],"[arxiv.Result.Author('Leon A. Abdillah'), arxiv.Result.Author('Azka Kurniasti')]","Information technology-based applications have entered the era of mobile
phones or smartphones such as those using the Android or iOS operating system.
Mobile-based application development has become a trend for today's society.
Especially during the global COVID-19 pandemic, almost all activities are
carried out remotely through mobile-based applications. To prevent the spread
of COVID-19, mass vaccines are given to the public. So that the process of
administering the vaccine does not cause crowds, it is necessary to create a
mobile-based application. So that the application can be further developed
properly, it is necessary to make a prototype. The prototype consists of 5
(steps): 1) Quick plan, 2) Modeling Quick Design, 3) Construction of prototype,
4) Deployment Delivery & feedback, and 5) Communication. In this research, the
InVision design tool is used which can help design prototypes for both mobile
and web versions. InVision has been widely used in making prototypes and is
used by many digital companies in the world. The results obtained are in the
form of a prototype application for the registration of vaccine participants
via mobile phones and also the web. The programmers will easily translate the
prototype results into a mobile-based application for the benefit of mobile
phone-based online vaccine registration."
11321,We propose several suggestions for further research on gesture-based HRI.,"Although there
is a large amount of research investigated in each domain, there are still some gaps in the gesture-
based HRI.","Suggestion 1: Gesture-based interaction is a kind of communication that is easily influenced by the
interaction scenario and context.",2022-09-17 03:18:32+00:00,Hand and Arm Gesture-based Human-Robot Interaction: A Review,cs.HC,"['cs.HC', 'cs.RO']","[arxiv.Result.Author('Xihao Wang'), arxiv.Result.Author('Hao Shen'), arxiv.Result.Author('Hui Yu'), arxiv.Result.Author('Jielong Guo'), arxiv.Result.Author('Xian Wei')]","The study of Human-Robot Interaction (HRI) aims to create close and friendly
communication between humans and robots. In the human-center HRI, an essential
aspect of implementing a successful and effective HRI is building a natural and
intuitive interaction, including verbal and nonverbal. As a prevalent
nonverbally communication approach, hand and arm gesture communication happen
ubiquitously in our daily life. A considerable amount of work on gesture-based
HRI is scattered in various research domains. However, a systematic
understanding of the works on gesture-based HRI is still lacking. This paper
intends to provide a comprehensive review of gesture-based HRI and focus on the
advanced finding in this area. Following the stimulus-organism-response
framework, this review consists of: (i) Generation of human gesture(stimulus).
(ii) Robot recognition of human gesture(organism). (iii) Robot reaction to
human gesture(response). Besides, this review summarizes the research status of
each element in the framework and analyze the advantages and disadvantages of
related works. Toward the last part, this paper discusses the current research
challenges on gesture-based HRI and provides possible future directions."
11352,further study the topic.,"agent conversation when they collaboratively accomplish a
                                                                                                                            mobile task—that lays a conceptual framework for others to
                                        ∗This work was done while the author was an intern at Google Research.","• We designed a novel method for feeding GUIs to LLMs—that           of input and output exemplars from the target tasks, it is referred
        is pre-trained for natural language—and a set of techniques       to as 𝑁 -shot learning.",2022-09-18 20:58:39+00:00,Enabling Conversational Interaction with Mobile UI using Large Language Models,cs.HC,"['cs.HC', 'cs.AI']","[arxiv.Result.Author('Bryan Wang'), arxiv.Result.Author('Gang Li'), arxiv.Result.Author('Yang Li')]","Conversational agents show the promise to allow users to interact with mobile
devices using language. However, to perform diverse UI tasks with natural
language, developers typically need to create separate datasets and models for
each specific task, which is expensive and effort-consuming. Recently,
pre-trained large language models (LLMs) have been shown capable of
generalizing to various downstream tasks when prompted with a handful of
examples from the target task. This paper investigates the feasibility of
enabling versatile conversational interactions with mobile UIs using a single
LLM. We propose a design space to categorize conversations between the user and
the agent when collaboratively accomplishing mobile tasks. We design prompting
techniques to adapt an LLM to conversational tasks on mobile UIs. The
experiments show that our approach enables various conversational interactions
with decent performances, manifesting its feasibility. We discuss the use cases
of our work and its implications for language-based mobile interaction."
11510,"Furthermore, as the coverage of driving automation function
expands from freeway to urban driving scenarios, further research is needed with the increased situation complexity and
automation parameters.","(2021)], explicit
adaptive driving styles still add extra workload on users.","To bridge this gap, this work proposes identiﬁcation of preferred driving style through multimodal data in SAE L2
automated vehicles.",2022-09-21 17:56:21+00:00,Identification of Adaptive Driving Style Preference through Implicit Inputs in SAE L2 Vehicles,cs.HC,"['cs.HC', 'cs.LG', 'cs.RO']","[arxiv.Result.Author('Zhaobo K. Zheng'), arxiv.Result.Author('Kumar Akash'), arxiv.Result.Author('Teruhisa Misu'), arxiv.Result.Author('Vidya Krishmoorthy'), arxiv.Result.Author('Miaomiao Dong'), arxiv.Result.Author('Yuni Lee'), arxiv.Result.Author('Gaojian Huang')]","A key factor to optimal acceptance and comfort of automated vehicle features
is the driving style. Mismatches between the automated and the driver preferred
driving styles can make users take over more frequently or even disable the
automation features. This work proposes identification of user driving style
preference with multimodal signals, so the vehicle could match user preference
in a continuous and automatic way. We conducted a driving simulator study with
36 participants and collected extensive multimodal data including behavioral,
physiological, and situational data. This includes eye gaze, steering grip
force, driving maneuvers, brake and throttle pedal inputs as well as foot
distance from pedals, pupil diameter, galvanic skin response, heart rate, and
situational drive context. Then, we built machine learning models to identify
preferred driving styles, and confirmed that all modalities are important for
the identification of user preference. This work paves the road for implicit
adaptive driving styles on automated vehicles."
11523,"As the final color guideline was derived
from Study 2, further study using different luminaire arrangements is also required.","Previous research has found that luminaire arrangement
influences people's affective perception (Caberletti et al., 2010, Locken et al., 2013), and it is
possible that this was the case in this study as well.","Next, due to safety concerns, the study was conducted in a parking lot with a static state.",2022-09-22 03:38:43+00:00,Affective responses to chromatic ambient light in a vehicle,cs.HC,['cs.HC'],"[arxiv.Result.Author('Taesu Kim'), arxiv.Result.Author('Kyungah Choi'), arxiv.Result.Author('Hyeon-Jeong Suk')]","This study investigates the emotional responses to the color of vehicle
interior lighting using self-assessment and electroencephalography (EEG). The
study was divided into two sessions: the first session investigated the
potential of ambient lighting colors, and the second session was used to
develop in-vehicle lighting color guidelines. Every session included thirty
subjects. In the first session, four lighting colors were assessed using
seventeen adjectives. As a result, 'Preference, Softness, Brightness, and
Uniqueness were found to be the four factors that best characterize the
atmospheric properties of interior lighting in vehicles. Ambient illumination,
according to EEG data, increased people's arousal and lowered their alpha
waves. The following session investigated a wider spectrum of colors using four
factors extracted from the previous session. As a result, bluish and purplish
lighting colors had the highest preference and uniqueness among ten lighting
colors. Green received an intermediate preference and a high uniqueness score.
With its great brightness and softness, Neutral White also achieved an
intermediate preference rating. Despite receiving a low preference rating, warm
colors were considered to be soft. Red was the least preferred color, but its
uniqueness and roughness were highly rated. This study is expected to provide a
basic theory on emotional lighting guidelines in the vehicle context, providing
manufacturers with objective rationale."
11524,"Though the verbal data included fruitful user expectations on affective vehicles, further research can com-
plement the affective role concepts by collecting additional sketch data that clarify user intentions and help organize
design elements of vehicles for affective design.","5.3 Limitation

Our study collected data with limited diversity; we gathered verbal data from interviews using an online conference
program.","Also, this study performed analytic coding processes that matches
behavioral and reflective codes with visceral codes.",2022-09-22 03:43:47+00:00,Affective Role of the Future Autonomous Vehicle Interior,cs.HC,['cs.HC'],"[arxiv.Result.Author('Taesu Kim'), arxiv.Result.Author('Gyunpyo Lee'), arxiv.Result.Author('Jiwoo Hong'), arxiv.Result.Author('Hyeon-Jeong Suk')]","Recent advancements in autonomous technology allow for new opportunities in
vehicle interior design. Such a shift in in-vehicle activity suggests vehicle
interior spaces should provide an adequate manner by considering users'
affective desires. Therefore, this study aims to investigate the affective role
of future vehicle interiors. Thirty one participants in ten focus groups were
interviewed about challenges they face regarding their current vehicle interior
and expectations they have for future vehicles. Results from content analyses
revealed the affective role of future vehicle interiors. Advanced exclusiveness
and advanced convenience were two primary aspects identified. The identified
affective roles of each aspect are a total of eight visceral levels, four
visceral levels each, including focused, stimulating, amused, pleasant, safe,
comfortable, accommodated, and organized. We expect the results from this study
to lead to the development of affective vehicle interiors by providing the
fundamental knowledge for developing conceptual direction and evaluating its
impact on user experiences."
11528,"The results
of such studies highlight the high risks connected with data availability and point to the need for further research to
protect users’ privacy better.",[40] leveraged Sharing Platforms’ reviews to predict users’ gender.,"2.3 Users Proﬁling in AR and VR applications

Privacy risks in AR and VR technologies is not deeply discussed in the current literature.",2022-09-22 08:29:32+00:00,You Can't Hide Behind Your Headset: User Profiling in Augmented and Virtual Reality,cs.HC,"['cs.HC', 'cs.CR']","[arxiv.Result.Author('Pier Paolo Tricomi'), arxiv.Result.Author('Federica Nenna'), arxiv.Result.Author('Luca Pajola'), arxiv.Result.Author('Mauro Conti'), arxiv.Result.Author('Luciano Gamberini')]","Virtual and Augmented Reality (VR, AR) are increasingly gaining traction
thanks to their technical advancement and the need for remote connections,
recently accentuated by the pandemic. Remote surgery, telerobotics, and virtual
offices are only some examples of their successes. As users interact with
VR/AR, they generate extensive behavioral data usually leveraged for measuring
human behavior. However, little is known about how this data can be used for
other purposes.
  In this work, we demonstrate the feasibility of user profiling in two
different use-cases of virtual technologies: AR everyday application ($N=34$)
and VR robot teleoperation ($N=35$). Specifically, we leverage machine learning
to identify users and infer their individual attributes (i.e., age, gender). By
monitoring users' head, controller, and eye movements, we investigate the ease
of profiling on several tasks (e.g., walking, looking, typing) under different
mental loads. Our contribution gives significant insights into user profiling
in virtual environments."
11581,"For further research, it would be interesting to incorporate the                     [Cla16] CLAVET, SIMON.",DOI: 10.1109/SMC.2016.7844777 3.,"Motion Matching and The Road to Next-Gen
upper body animations into the Motion Matching system by reduc-                            Animation.",2022-09-23 08:33:19+00:00,Combining Motion Matching and Orientation Prediction to Animate Avatars for Consumer-Grade VR Devices,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Jose Luis Ponton'), arxiv.Result.Author('Haoran Yun'), arxiv.Result.Author('Carlos Andujar'), arxiv.Result.Author('Nuria Pelechano')]","The animation of user avatars plays a crucial role in conveying their pose,
gestures, and relative distances to virtual objects or other users. Self-avatar
animation in immersive VR helps improve the user experience and provides a
Sense of Embodiment. However, consumer-grade VR devices typically include at
most three trackers, one at the Head Mounted Display (HMD), and two at the
handheld VR controllers. Since the problem of reconstruction the user pose from
such sparse data is ill-defined, especially for the lower body, the approach
adopted by most VR games consists of assuming the body orientation matches that
of the HMD, and applying animation blending and time-warping from a reduced set
of animations. Unfortunately, this approach produces noticeable mismatches
between user and avatar movements. In this work we present a new approach to
animate user avatars that is suitable for current mainstream VR devices. First,
we use a neural network to estimate the user's body orientation based on the
tracking information from the HMD and the hand controllers. Then we use this
orientation together with the velocity and rotation of the HMD to build a
feature vector that feeds a Motion Matching algorithm. We built a MoCap
database with animations of VR users wearing a HMD and used it to test our
approach on both self-avatars and other users' avatars. Our results show that
our system can provide a large variety of lower body animations while correctly
matching the user orientation, which in turn allows us to represent not only
forward movements but also stepping in any direction."
11623,"The ﬁndings sug-
using accession numbers, downloading the PDB [2] ﬁles and Al-          gest directions for further research on mutation characteristics and a
phaFold ﬁles, selecting the highest resolution models for each X-ray   better visualization system for chemical modiﬁcations on proteins.","(3D) visual representations to understand where protein modiﬁca-
                                                                       tions are most likely to occur and gain insights from the distribution
   In the R environment, we were able to create a work ﬂow by ﬁrst,    of such modiﬁcations in the protein sequence.","crystallography structure, and then linking these ﬁles at the residue
to modiﬁcation data.",2022-09-25 04:22:01+00:00,Modie Viewer: Protein Beasts and How to View Them,cs.HC,"['cs.HC', 'cs.GR', 'q-bio.BM', 'H.5.2; J.3; D.2.2']","[arxiv.Result.Author('Huyen N. Nguyen'), arxiv.Result.Author('Caleb Trujillo'), arxiv.Result.Author('Tommy Dang')]","Understanding chemical modifications on proteins opens up further
possibilities for research on rare diseases. This work proposes visualization
approaches using two-dimensional (2D) and three-dimensional (3D) visual
representations to analyze and gain insights into protein modifications. In
this work, we present the application of Modie Viewer as an attempt to address
the Bio+MedVis Challenge at IEEE VIS 2022."
11624,"This observation could be invested in further research in terms of
mutation characteristics and chemical modiﬁcations on proteins.","The corresponding positions are 296, 351, 362, and 376.","Figure 2: Eight 3D structures for four human proteins (ALDOA, DDX3X, HNRNPA1 and TGFB1) and their mouse orthologs.",2022-09-25 04:22:01+00:00,Modie Viewer: Protein Beasts and How to View Them,cs.HC,"['cs.HC', 'cs.GR', 'q-bio.BM', 'H.5.2; J.3; D.2.2']","[arxiv.Result.Author('Huyen N. Nguyen'), arxiv.Result.Author('Caleb Trujillo'), arxiv.Result.Author('Tommy Dang')]","Understanding chemical modifications on proteins opens up further
possibilities for research on rare diseases. This work proposes visualization
approaches using two-dimensional (2D) and three-dimensional (3D) visual
representations to analyze and gain insights into protein modifications. In
this work, we present the application of Modie Viewer as an attempt to address
the Bio+MedVis Challenge at IEEE VIS 2022."
11647,"words, our findings are encouraging for further research on hybrid
notions of computer-supported shift planning.",In other          important shifts.,"This notion is further supported, considering that our partici-
                                                                           pants also appreciated certain forms of automation.",2022-09-26 10:36:17+00:00,Experiential Benefits of Interactive Conflict Negotiation Practices in Computer-Supported Shift Planning,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Alarith Uhde'), arxiv.Result.Author('Matthias Laschke'), arxiv.Result.Author('Marc Hassenzahl')]","Shift planning plays a key role for the health and well-being of healthcare
workers. It determines when they work and when they can take time off to
recover or engage in social activities. Current computer-support in shift
planning is typically designed from a managerial perspective and focuses on
process efficiency, with the long-term goal of full automation. This implies
automatic resolutions of emotionally charged scheduling conflicts. In the
present study, we measured the effects of such a fully automated process on
workers' well-being, fairness, and team spirit, and compared them with a more
interactive process that directly involves workers in the decision-making. In
our experimental online study (n = 94), we found positive effects of the more
interactive process on all measures. Our findings indicate that full automation
may not be desirable from the worker perspective. We close with concrete
suggestions to design more worker-centered, hybrid shift planning systems by
optimizing worker control, considering the worker experience, and embedding
shift planning in the broader work context."
11652,"While we have demonstrated that our formulation can be used to solve problems with
up to 5 billion possible states (toolbar application), further research is necessary to overcome the complexity hurdle.","The main technical difficulty lies in 1) the exponential growth in complexity with the increased number of
items and 2) longer horizon tasks.","This will require both, algorithmic advancements, including pre-training [18] and leveraging human demonstrations to
guide exploration [15], as well as more efficient formulations of the UI adaptation problem.",2022-09-26 13:06:05+00:00,MARLUI: Multi-Agent Reinforcement Learning for Goal-Agnostic Adaptive UIs,cs.HC,['cs.HC'],"[arxiv.Result.Author('Thomas Langerak'), arxiv.Result.Author('Sammy Christen'), arxiv.Result.Author('Mert Albaba'), arxiv.Result.Author('Christoph Gebhardt'), arxiv.Result.Author('Otmar Hilliges')]","The goal of Adaptive UIs is to automatically change an interface so that the
UI better supports users in their tasks. A core challenge is to infer user
intent from user input and chose adaptations accordingly. Designing effective
online UI adaptations is challenging because it relies on tediously
hand-crafted rules or carefully collected, high-quality user data. To overcome
these challenges, we formulate UI adaptation as a multi-agent reinforcement
learning problem. In our formulation, a user agent learns to interact with a UI
to complete a task. Simultaneously, an interface agent learns UI adaptations to
maximize the user agent's performance. The interface agent is agnostic to the
goal. It learns the task structure from the behavior of the user agent and
based on that can support the user agent in completing its task. We show that
our approach leads to a significant reduction in necessary number of actions on
a photo editing task in silico. Furthermore, our user studies demonstrate the
generalization capabilities of our interface agent from a simulated user agent
to real users."
11718,"To further study realistically larger networks, we offer two new algorithms for
           improving toroidal layout that is completely autonomous and automatic panning
           the viewport to minimise the number of link wrappings across the boundary.","The result of the algorithm and
           evaluation were published in [Che+20].","The
           resulting layouts afford fewer crossings, lower “stress”, and greater visual cluster sep-
           aration (i.e.",2022-09-27 08:43:43+00:00,"It's a Wrap! Visualisations that Wrap Around Cylindrical, Toroidal, or Spherical Topologies",cs.HC,['cs.HC'],[arxiv.Result.Author('Kun-Ting Chen')],"Traditional visualisations are designed to be shown on a flat surface (screen
or page) but most data is not ""flat"". For example, the surface of the earth
exists on a sphere, however, when that surface is presented on a flat map, key
information is hidden, such as geographic paths on the spherical surface being
wrapped across the boundaries of the flat map. Similarly, cyclical time-series
data has no beginning or end. When such cyclical data is presented on a
traditional linear chart, the viewer needs to perceive continuity of the
visualisation across the chart's boundaries. Mentally reconnecting the chart
across such a boundary may induce additional cognitive load. More complex data
such as a network diagram with hundreds or thousands of links between data
points leads to a densely connected structure that is even less ""flat"" and
needs to wrap around in multiple dimensions. To improve the usability of these
visualisations, this thesis explores a novel class of interactive wrapped data
visualisations, i.e., visualisations that wrap around continuously when
interactively panned on a two-dimensional projection of surfaces of 3D shapes,
specifically, cylinder, torus, or sphere. We start with a systematic
exploration of the design space of interactive wrapped visualisations,
characterising the visualisations that help people understand the relationship
within the data. Subsequently, we investigate a series of wrappable
visualisations for cyclical time series, network, and geographic data. We show
that these interactive visualisations better preserve the spatial relations in
the case of geospatial data, and better reveal the data's underlying structure
in the case of abstract data such as networks and cyclical time series.
Furthermore, to assist future research and development, we contribute layout
algorithms and toolkits to help create pannable wrapped visualisations."
11797,"For example, existing work has        of visualizations, such as line charts, interactive visualizations, bar
shown that redundant encoding, the practice of encoding visual marks        charts, and dashboards, but further research should empirically test
via multiple channels such as color and shape, can enhance perception.","We can potentially in-
the processing ﬂuency of a visualization, which is associated with in-      tuit that lower processing ﬂuency would decrease trust in other types
creased trust in the underlying data.",such hypotheses [31].,2022-09-28 18:09:36+00:00,Using Processing Fluency as a Metric of Trust in Scatterplot Visualizations,cs.HC,['cs.HC'],"[arxiv.Result.Author('Hamza Elhamdadi'), arxiv.Result.Author('Lace Padilla'), arxiv.Result.Author('Cindy Xiong')]","Establishing trust with readers is an important first step in visual data
communication. But what makes a visualization trustworthy? Psychology and
behavioral economics research has found processing fluency (i.e., speed and
accuracy of perceiving and processing a stimulus) is central to perceived
trust. We examine the association between processing fluency and trust in
visualizations through two empirical studies. In Experiment 1, we tested the
effect of camouflaging a visualization on processing fluency. Participants
estimated the proportion of data values within a specified range for six
camouflaged visualizations and one non-camouflaged control; they also reported
their perceived difficulty for each of the visualizations. Camouflaged
visualizations produced less accurate estimations compared to the control. In
Experiment 2, we created a decision task based on trust games adapted from
behavioral economics. We asked participants to invest money in two hypothetical
companies and report how much they trust each company. One company communicates
its strategy with a camouflaged visualization, the other with a controlled
visualization. Participants tended to invest less money in the company
presenting a camouflaged visualization. Hence, we found support for the
hypothesis that processing fluency is key to the perception of trust in visual
data communication."
11798,"A. Vo, Z. Bylinskii, P. Isola, S. Sunkavalli, A. Oliva, and
facilitate visualization perception [6,19,24], and further research should
explore the connection between perceptual design decisions and trust               H. Pﬁster.","Fitting linear mixed models in r. R news, 5(1):27–30, 2005.
psychology and visualization demonstrates how some designs better            [6] M. A. Borkin, A.",What makes a visualization memorable?,2022-09-28 18:09:36+00:00,Using Processing Fluency as a Metric of Trust in Scatterplot Visualizations,cs.HC,['cs.HC'],"[arxiv.Result.Author('Hamza Elhamdadi'), arxiv.Result.Author('Lace Padilla'), arxiv.Result.Author('Cindy Xiong')]","Establishing trust with readers is an important first step in visual data
communication. But what makes a visualization trustworthy? Psychology and
behavioral economics research has found processing fluency (i.e., speed and
accuracy of perceiving and processing a stimulus) is central to perceived
trust. We examine the association between processing fluency and trust in
visualizations through two empirical studies. In Experiment 1, we tested the
effect of camouflaging a visualization on processing fluency. Participants
estimated the proportion of data values within a specified range for six
camouflaged visualizations and one non-camouflaged control; they also reported
their perceived difficulty for each of the visualizations. Camouflaged
visualizations produced less accurate estimations compared to the control. In
Experiment 2, we created a decision task based on trust games adapted from
behavioral economics. We asked participants to invest money in two hypothetical
companies and report how much they trust each company. One company communicates
its strategy with a camouflaged visualization, the other with a controlled
visualization. Participants tended to invest less money in the company
presenting a camouflaged visualization. Hence, we found support for the
hypothesis that processing fluency is key to the perception of trust in visual
data communication."
11828,"Therefore, further research is necessary to
understand what types of crowdsourcing tasks are well suited for the TruEyes system.","The form-factor of a mobile
device poses additional constraints on the type of tasks that can be executed.",Ensuring Quality Control Quality control is the one of the major challenges with crowdsourcing [48].,2022-09-29 12:09:09+00:00,TruEyes: Utilizing Microtasks in Mobile Apps for Crowdsourced Labeling of Machine Learning Datasets,cs.HC,"['cs.HC', 'cs.AI', 'cs.SE']","[arxiv.Result.Author('Chandramohan Sudar'), arxiv.Result.Author('Michael Froehlich'), arxiv.Result.Author('Florian Alt')]","The growing use of supervised machine learning in research and industry has
increased the need for labeled datasets. Crowdsourcing has emerged as a popular
method to create data labels. However, working on large batches of tasks leads
to worker fatigue, negatively impacting labeling quality. To address this, we
present TruEyes, a collaborative crowdsourcing system, enabling the
distribution of micro-tasks to mobile app users. TruEyes allows machine
learning practitioners to publish labeling tasks, mobile app developers to
integrate task ads for monetization, and users to label data instead of
watching advertisements. To evaluate the system, we conducted an experiment
with N=296 participants. Our results show that the quality of the labeled data
is comparable to traditional crowdsourcing approaches and most users prefer
task ads over traditional ads. We discuss extensions to the system and address
how mobile advertisement space can be used as a productive resource in the
future."
11962,"10 CONCLUSION

Having a portable and validated way to measure scrolling speed and accuracy can provide better insights into how well
both new and old scrolling techniques work, and can therefore support further research into new and better scrolling
mechanisms.","Finally, ScrollTest cannot currently be used to measure “infinite scrolling” like on Facebook where more content is
loaded when the user scrolls to the bottom, making the document larger, but it is not clear whether speed and accuracy
would be useful measures in that case.","We have developed ScrollTest through multiple years of iterative refinements, and believe it is now ready
for general use.",2022-10-03 06:39:54+00:00,ScrollTest: Evaluating Scrolling Speed and Accuracy,cs.HC,['cs.HC'],"[arxiv.Result.Author('Chaoran Chen'), arxiv.Result.Author('Brad A. Myers'), arxiv.Result.Author('Cem Ergin'), arxiv.Result.Author('Emily Porat'), arxiv.Result.Author('Sijia Li'), arxiv.Result.Author('Chun Wang')]","Scrolling is an essential interaction technique enabling users to display
previously off-screen content. Existing evaluation models for scrolling are
often entangled with the selection of content, e.g., when scrolling on the
phone for reading. Furthermore, some evaluation models overlook whether the
user knows the target position. We have developed ScrollTest, a general-purpose
evaluation tool for scrolling speed and accuracy that avoids the need for
selection. We tested it across four dimensions: 11 different scrolling
techniques/devices, 5 frame heights, 13 scrolling distances, and 2 scrolling
conditions (i.e., with or without knowing the target position). The results
show that flicking and two-finger scrolling are the fastest; flicking is also
relatively precise for scrolling to targets already onscreen, but pressing
arrow buttons on the scrollbar is the most accurate for scrolling to nearby
targets. Mathematical models of scrolling are highly linear when the target
position is unknown but like Fitts' law when known."
11968,"By closely studying the differences of
robotic-sounding and a human-like conversation styles, the study indicates the important concerns, such as
perceived image of the AI agent, and self-efficacy of human, for further research.","However, there is an exception that
Hwang & Won [30] locate user experiences in teamworking in ideation.","The current stage of these exciting
and new possibilities poses a good question to designers: which improvement or new possibility do we want to
focus on?",2022-10-03 11:26:39+00:00,Dancing with the Unexpected and Beyond: The Use of AI Assistance in Design Fiction Creation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yiying Wu'), arxiv.Result.Author('Yunye Yu'), arxiv.Result.Author('Pengcheng An')]","The creation process of design fiction is going participatory and inclusive
with non experts. Recognizing the potential of artificial intelligence in
creativity support, we explore the use of AI assistance in creating design
fiction. This investigation is based on a workshop on future work in 2040 with
Chinese youth. We look into fiction quality, participants experiences with the
AI agent, and their ways of incorporating those texts into writing. Our
findings show that human writers while responding to messy and unexpected
AI-generated texts, can elevate the richness and creativity in writing and
initiate joyful and inspirational interactions. Furthermore, for the design of
AI assistance in creativity support, we suggest two implications of enhancing
interactional quality between human and AI and prompt programming. Our study
indicates the potential of applying design fiction outside the design context
using a more inclusive approach for future speculation with critical reflection
on technology."
11969,"With each finding, we
propose two implications for further research of how to better design for and use AI assistance in design fiction
and similar creative work.","6 INTERACTIONAL QUALITY AND PROMPT PROGRAMING IN HUMAN-AI INTERACTION

In this session we present two findings based on the use behaviours from this study.","6.1 Enhancing Interactional Quality Between Human-AI Rather Than Improvement of AI

This section discusses the interactional quality between human and AI.",2022-10-03 11:26:39+00:00,Dancing with the Unexpected and Beyond: The Use of AI Assistance in Design Fiction Creation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yiying Wu'), arxiv.Result.Author('Yunye Yu'), arxiv.Result.Author('Pengcheng An')]","The creation process of design fiction is going participatory and inclusive
with non experts. Recognizing the potential of artificial intelligence in
creativity support, we explore the use of AI assistance in creating design
fiction. This investigation is based on a workshop on future work in 2040 with
Chinese youth. We look into fiction quality, participants experiences with the
AI agent, and their ways of incorporating those texts into writing. Our
findings show that human writers while responding to messy and unexpected
AI-generated texts, can elevate the richness and creativity in writing and
initiate joyful and inspirational interactions. Furthermore, for the design of
AI assistance in creativity support, we suggest two implications of enhancing
interactional quality between human and AI and prompt programming. Our study
indicates the potential of applying design fiction outside the design context
using a more inclusive approach for future speculation with critical reflection
on technology."
11970,"We suggest further research including the third type of process that uses non-AI assistant tools for creative
writing and ideation, in order to produce more insights on the role of AI-assistance in supporting creation of design
fiction.","However, our study only involved two conditions of using AI assistance and
not.","Next, we are open to two future enquiries.",2022-10-03 11:26:39+00:00,Dancing with the Unexpected and Beyond: The Use of AI Assistance in Design Fiction Creation,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yiying Wu'), arxiv.Result.Author('Yunye Yu'), arxiv.Result.Author('Pengcheng An')]","The creation process of design fiction is going participatory and inclusive
with non experts. Recognizing the potential of artificial intelligence in
creativity support, we explore the use of AI assistance in creating design
fiction. This investigation is based on a workshop on future work in 2040 with
Chinese youth. We look into fiction quality, participants experiences with the
AI agent, and their ways of incorporating those texts into writing. Our
findings show that human writers while responding to messy and unexpected
AI-generated texts, can elevate the richness and creativity in writing and
initiate joyful and inspirational interactions. Furthermore, for the design of
AI assistance in creativity support, we suggest two implications of enhancing
interactional quality between human and AI and prompt programming. Our study
indicates the potential of applying design fiction outside the design context
using a more inclusive approach for future speculation with critical reflection
on technology."
12004,"We further study the
                                                                                             time-efficient generalization of the pre-trained model to new users
A naïve solution to this problem is to set a cut-off threshold such                          in Section 4.4.",isting vision-based methods in Section 4.3.,"In addition, we also analyze the resulting neural in-
                                                                                             terface in terms of latency and storage for real-time applications
that the estimated values below it are treated as zero.",2022-10-03 20:51:25+00:00,Force-Aware Interface via Electromyography for Natural VR/AR Interaction,cs.HC,"['cs.HC', 'cs.GR', 'cs.LG']","[arxiv.Result.Author('Yunxiang Zhang'), arxiv.Result.Author('Benjamin Liang'), arxiv.Result.Author('Boyuan Chen'), arxiv.Result.Author('Paul Torrens'), arxiv.Result.Author('S. Farokh Atashzar'), arxiv.Result.Author('Dahua Lin'), arxiv.Result.Author('Qi Sun')]","While tremendous advances in visual and auditory realism have been made for
virtual and augmented reality (VR/AR), introducing a plausible sense of
physicality into the virtual world remains challenging. Closing the gap between
real-world physicality and immersive virtual experience requires a closed
interaction loop: applying user-exerted physical forces to the virtual
environment and generating haptic sensations back to the users. However,
existing VR/AR solutions either completely ignore the force inputs from the
users or rely on obtrusive sensing devices that compromise user experience.
  By identifying users' muscle activation patterns while engaging in VR/AR, we
design a learning-based neural interface for natural and intuitive force
inputs. Specifically, we show that lightweight electromyography sensors,
resting non-invasively on users' forearm skin, inform and establish a robust
understanding of their complex hand activities. Fuelled by a
neural-network-based model, our interface can decode finger-wise forces in
real-time with 3.3% mean error, and generalize to new users with little
calibration. Through an interactive psychophysical study, we show that human
perception of virtual objects' physical properties, such as stiffness, can be
significantly enhanced by our interface. We further demonstrate that our
interface enables ubiquitous control via finger tapping. Ultimately, we
envision our findings to push forward research towards more realistic
physicality in future VR/AR."
12009,"Since
        that we have good voting systems and you know plant-                    we do not have insights from other genders, our study does not
        ing doubt in your head by listening to what people                      provide a generalized understanding of whether and how gender
        are saying, and then sort of capitalizing on that so                    might play a role in the adoption of AI-enabled products among
        all this stuﬀ in the wrong hands be used for doing                      older adults and calls for further research investigation.","Things like, all this stuﬀ with twitter and                    Our study found that females were disinclined towards learn-
        whatnot, I don’t know to what degree, say for exam-                     ing about the inner-functionalities of the AI-enabled products but
        ple, the Russians are using AI to ﬁgure out you know                    were excited about using them, and females with partners often
        what people might be sensitive to, to make them doubt                   depended on their partners to set-up AI-enabled products.","Supple-
        underhanded things.”                                                    mentary to this result, the diﬀerence in technology adoption and
                                                                                conﬁdence between gender groups was documented in past stud-
5.4 Summary of Interview Findings                                               ies [23, 65].",2022-10-04 04:19:21+00:00,Understanding Older Adults' Perceptions and Challenges in Using AI-enabled Everyday Technologies,cs.HC,['cs.HC'],"[arxiv.Result.Author('Esha Shandilya'), arxiv.Result.Author('Mingming Fan')]","Artificial intelligence (AI)-enabled everyday technologies could help address
age-related challenges like physical impairments and cognitive decline. While
recent research studied older adults' experiences with specific AI-enabled
products (e.g., conversational agents and assistive robots), it remains unknown
how older adults perceive and experience current AI-enabled everyday
technologies in general, which could impact their adoption of future AI-enabled
products. We conducted a survey study (N=41) and semi-structured interviews
(N=15) with older adults to understand their experiences and perceptions of AI.
We found that older adults were enthusiastic about learning and using
AI-enabled products, but they lacked learning avenues. Additionally, they
worried when AI-enabled products outwitted their expectations, intruded on
their privacy, or impacted their decision-making skills. Therefore, they held
mixed views towards AI-enabled products such as AI, an aid, or an adversary. We
conclude with design recommendations that make older adults feel inclusive,
secure, and in control of their interactions with AI-enabled products."
12077,"We use an umbrella semantic
                      class ""OTHER"" to cover the semantics not covered in our proposed set of classes

Figure 1: In this paper, we annotated the RICO dataset with both icon shapes and their semantics, to encourage
further research on app automation and accessibility.","E.g.,
                      ""X"" shape may mean ""close"", ""delete text"", or ""multiply"".",The existing icon annotations from Liu et al.,2022-10-06 03:48:54+00:00,Towards Better Semantic Understanding of Mobile Interfaces,cs.HC,"['cs.HC', 'cs.CL', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Srinivas Sunkara'), arxiv.Result.Author('Maria Wang'), arxiv.Result.Author('Lijuan Liu'), arxiv.Result.Author('Gilles Baechler'), arxiv.Result.Author('Yu-Chung Hsiao'), arxiv.Result.Author('Jindong'), arxiv.Result.Author('Chen'), arxiv.Result.Author('Abhanshu Sharma'), arxiv.Result.Author('James Stout')]","Improving the accessibility and automation capabilities of mobile devices can
have a significant positive impact on the daily lives of countless users. To
stimulate research in this direction, we release a human-annotated dataset with
approximately 500k unique annotations aimed at increasing the understanding of
the functionality of UI elements. This dataset augments images and view
hierarchies from RICO, a large dataset of mobile UIs, with annotations for
icons based on their shapes and semantics, and associations between different
elements and their corresponding text labels, resulting in a significant
increase in the number of UI elements and the categories assigned to them. We
also release models using image-only and multimodal inputs; we experiment with
various architectures and study the benefits of using multimodal inputs on the
new dataset. Our models demonstrate strong performance on an evaluation set of
unseen apps, indicating their generalizability to newer screens. These models,
combined with the new dataset, can enable innovative functionalities like
referring to UI elements by their labels, improved coverage and better
semantics for icons etc., which would go a long way in making UIs more usable
for everyone."
12088,"Second, we describe how this range of facets and sub-facets can be framed as differing forms of
intermediate-level knowledge, laying the groundwork for further research and targeted knowledge production in the
co-design literature.","First, we illustrate the interactional qualities
of these facets that might encourage different attitudes towards other forms of knowledge that are leveraged when
designing for co-design.","7.1 Interactional Qualities of Facets

Each facet we have described above forms a useful set of knowledge that co-design researchers and designers could
engage with during the design of a co-design experience.",2022-10-06 15:21:42+00:00,What Do I Need to Design for Co-Design? Supporting Co-design as a Designerly Practice,cs.HC,['cs.HC'],"[arxiv.Result.Author('Shruthi Sai Chivukula'), arxiv.Result.Author('Colin M Gray')]","Co-design practices have been used for decades to support participatory
engagement in design work. However, despite a wide range of materials that
describe the design and commitments of numerous co-design experiences, few
descriptions of the knowledge that guides designers when creating these
experiences exist. Thus, we ask: What kind of knowledge do designers need to
design co-design experiences? What form(s) could intermediate-level knowledge
for co-design take? To answer these questions, we adopted a
co/auto-ethnographic and Research-through-Design approach to reflexively engage
with our design decisions, outcomes, and challenges related to two virtual
co-design workshops. We constructed a set of four multi-dimensional
facets(Rhythms of Engagement, Material Engagement, Ludic Engagement, and
Conceptual Achievement) and three roles (designer, researcher, facilitator) to
consider when creating co-design experiences. We illustrate these facets and
roles through examples, building new \textit{intermediate-level knowledge} to
support future co-design research and design, framing co-design as a designerly
practice."
12124,"In
this work, we discussed the strength and limitations of these two processes and highlighted need
for further research.","Our preliminary discussions with ML practitioners about safety engineering frameworks, such as
STPA and FMEA, showed these approaches could be adapted to provide the necessary guidance for
systematically conducting failure and hazard analysis for social and ethical risks of ML systems.",", Vol.",2022-10-06 00:09:06+00:00,From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML,cs.HC,"['cs.HC', 'cs.LG']","[arxiv.Result.Author('Shalaleh Rismani'), arxiv.Result.Author('Renee Shelby'), arxiv.Result.Author('Andrew Smart'), arxiv.Result.Author('Edgar Jatho'), arxiv.Result.Author('Joshua Kroll'), arxiv.Result.Author('AJung Moon'), arxiv.Result.Author('Negar Rostamzadeh')]","Inappropriate design and deployment of machine learning (ML) systems leads to
negative downstream social and ethical impact -- described here as social and
ethical risks -- for users, society and the environment. Despite the growing
need to regulate ML systems, current processes for assessing and mitigating
risks are disjointed and inconsistent. We interviewed 30 industry practitioners
on their current social and ethical risk management practices, and collected
their first reactions on adapting safety engineering frameworks into their
practice -- namely, System Theoretic Process Analysis (STPA) and Failure Mode
and Effects Analysis (FMEA). Our findings suggest STPA/FMEA can provide
appropriate structure toward social and ethical risk assessment and mitigation
processes. However, we also find nontrivial challenges in integrating such
frameworks in the fast-paced culture of the ML industry. We call on the ML
research community to strengthen existing frameworks and assess their efficacy,
ensuring that ML systems are safer for all people."
12134,"We highlight these burdens
on users as vital areas for further research.",with what they might have wanted.,"Despite the burdens,                     [10] Solon Barocas and Andrew D Selbst.",2022-10-07 17:25:38+00:00,"Understanding Practices, Challenges, and Opportunities for User-Driven Algorithm Auditing in Industry Practice",cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Wesley Hanwen Deng'), arxiv.Result.Author('Bill Boyuan Guo'), arxiv.Result.Author('Alicia Devos'), arxiv.Result.Author('Hong Shen'), arxiv.Result.Author('Motahhare Eslami'), arxiv.Result.Author('Kenneth Holstein')]","Recent years have seen growing interest among both researchers and
practitioners in user-driven approaches to algorithm auditing, which directly
engage users in detecting problematic behaviors in algorithmic systems.
However, we know little about industry practitioners' current practices and
challenges around user-driven auditing, nor what opportunities exist for them
to better leverage such approaches in practice. To investigate, we conducted a
series of interviews and iterative co-design activities with practitioners who
employ user-driven auditing approaches in their work. Our findings reveal
several challenges practitioners face in appropriately recruiting and
incentivizing user auditors, scaffolding user audits, and deriving actionable
insights from user-driven audit reports. Furthermore, practitioners shared
organizational obstacles to user-driven auditing, surfacing a complex
relationship between practitioners and user auditors. Based on these findings,
we discuss opportunities for future HCI research to help realize the potential
(and mitigate risks) of user-driven auditing in industry practice."
12135,"We highlight these burdens
on users as vital areas for further research.",with what they might have wanted.,"Despite the burdens,                     [10] Solon Barocas and Andrew D Selbst.",2022-10-07 17:25:38+00:00,"Understanding Practices, Challenges, and Opportunities for User-Driven Algorithm Auditing in Industry Practice",cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Wesley Hanwen Deng'), arxiv.Result.Author('Bill Boyuan Guo'), arxiv.Result.Author('Alicia DeVrio'), arxiv.Result.Author('Hong Shen'), arxiv.Result.Author('Motahhare Eslami'), arxiv.Result.Author('Kenneth Holstein')]","Recent years have seen growing interest among both researchers and
practitioners in user-driven approaches to algorithm auditing, which directly
engage users in detecting problematic behaviors in algorithmic systems.
However, we know little about industry practitioners' current practices and
challenges around user-driven auditing, nor what opportunities exist for them
to better leverage such approaches in practice. To investigate, we conducted a
series of interviews and iterative co-design activities with practitioners who
employ user-driven auditing approaches in their work. Our findings reveal
several challenges practitioners face in appropriately recruiting and
incentivizing user auditors, scaffolding user audits, and deriving actionable
insights from user-driven audit reports. Furthermore, practitioners shared
organizational obstacles to user-driven auditing, surfacing a complex
relationship between practitioners and user auditors. Based on these findings,
we discuss opportunities for future HCI research to help realize the potential
(and mitigate risks) of user-driven auditing in industry practice."
12138,"Game effects can enable designers to embed additional        an initial investigation of visual effects in games and advocate for
interactive functionality, thus allowing more “spaces” in which to        further research into the challenges and opportunities in incorporat-
present information and to create new kinds of user experiences.","Overall, we provide
and events).","ing “data feel” into visualization tools by adopting elements from
                                                                          video game design into the design of data visualization interfaces.",2022-10-07 20:09:31+00:00,Data Feel: Exploring Visual Effects in Video Games to Support Sensemaking Tasks,cs.HC,['cs.HC'],"[arxiv.Result.Author('Hongwei Zhou'), arxiv.Result.Author('Angus G. Forbes')]","This paper explores the use of visual effects common in video games that
support a range of tasks that are similar in many ways to analysis tasks
supported in visual analytics tools. While some visual effects are meant to
increase engagement or to support a game's overall visual design, we find that
in many games visual effects are used throughout gameplay in order to assist a
player in reasoning about the game world. In this work, we survey popular games
across a range of categories (from casual games to ""Triple A"" games), focusing
specifically on visual effects that support a player's sensemaking within the
game world. Based on our analysis of these games, we identify a range of tasks
that could benefit from the use of ""data feel,"" and advocate for the continued
investigation of visual effects and their application in data visualization
software tools."
12348,"Based on the outcome of this study, further research is needed with a clear separation of researchers and
meeting attendees.","All this ensures an authentic
setting, leading to high external validity.","At the cost of the insights from an autoethnographic approach, the generalizability can
be higher with controlled, balanced, and diverse samples across domains and prior experience.",2022-10-12 13:19:26+00:00,"""Seeing the Faces Is So Important"" -- Experiences From Online Team Meetings on Commercial Virtual Reality Platforms",cs.HC,"['cs.HC', 'H.5.3; H.5.2']","[arxiv.Result.Author('Michael Bonfert'), arxiv.Result.Author('Anke V. Reinschluessel'), arxiv.Result.Author('Susanne Putze'), arxiv.Result.Author('Yenchin Lai'), arxiv.Result.Author('Dmitry Alexandrovsky'), arxiv.Result.Author('Rainer Malaka'), arxiv.Result.Author('Tanja Döring')]","During the Covid-19 pandemic, online meetings became common for daily
teamwork in the home office. To understand the opportunities and challenges of
meeting in virtual reality (VR) compared to video conferences, we conducted the
weekly team meetings of our human-computer interaction research lab on five
off-the-shelf online meeting platforms over four months. After each of the 12
meetings, we asked the participants (N = 32) to share their experiences,
resulting in 200 completed online questionnaires. We evaluated the ratings of
the overall meeting experience and conducted an exploratory factor analysis of
the quantitative data to compare VR meetings and video calls in terms of
meeting involvement and co-presence. In addition, a thematic analysis of the
qualitative data revealed genuine insights covering five themes: spatial
aspects, meeting atmosphere, expression of emotions, meeting productivity, and
user needs. We reflect on our findings gained under authentic working
conditions, derive lessons learned for running successful team meetings in VR
supporting different kinds of meeting formats, and discuss the team's long-term
platform choice."
12419,"For
                                                                         further study, it could be useful to enable the system to collect
Even though H2 was not supported by questionnaire results, it            multiple types of data.","As indicated by our findings, objective user behavior data
6.2 H2: Increased attention                                              can be beneficial for supplementary and productive outcomes.","Virtual reality environments may be able to
was confirmed by the result from eye gaze data.",2022-10-13 12:50:03+00:00,Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents through Real-Time Interaction,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yuan He'), arxiv.Result.Author('André Pereira'), arxiv.Result.Author('Taras Kucherenko')]","Embodied Conversational Agents that make use of co-speech gestures can
enhance human-machine interactions in many ways. In recent years, data-driven
gesture generation approaches for ECAs have attracted considerable research
attention, and related methods have continuously improved. Real-time
interaction is typically used when researchers evaluate ECA systems that
generate rule-based gestures. However, when evaluating the performance of ECAs
based on data-driven methods, participants are often required only to watch
pre-recorded videos, which cannot provide adequate information about what a
person perceives during the interaction. To address this limitation, we
explored use of real-time interaction to assess data-driven gesturing ECAs. We
provided a testbed framework, and investigated whether gestures could affect
human perception of ECAs in the dimensions of human-likeness, animacy,
perceived intelligence, and focused attention. Our user study required
participants to interact with two ECAs - one with and one without hand
gestures. We collected subjective data from the participants' self-report
questionnaires and objective data from a gaze tracker. To our knowledge, the
current study represents the first attempt to evaluate data-driven gesturing
ECAs through real-time interaction and the first experiment using gaze-tracking
to examine the effect of ECAs' gestures."
12489,"Along with our analysis
                                            †e-mail: goenkam@carleton.edu                                      and proposal of future research questions, we provide this dataset of
                                            ‡e-mail: ealexander@carleton.edu                                   word cloud instances as an artifact for potential further study.","We have focused initially on DH and journalism as
                                                                                                               two of the most prominent arenas in which word clouds appear, but
                                            *e-mail: rmh327@cornell.edu                                        hope to broaden our search going forward.","2 METHODOLOGY

                                                                                                               We used a modiﬁed version of grounded theory to direct our data col-
                                                                                                               lection process, which aimed to document instances of word clouds
and word-cloud-adjacent ﬁgures in sources from DH academia and               • Presentation: Creators were using a word cloud to present
journalism.",2022-10-14 18:51:15+00:00,Word Clouds in the Wild,cs.HC,['cs.HC'],"[arxiv.Result.Author('Rebecca M. M. Hicke'), arxiv.Result.Author('Maanya Goenka'), arxiv.Result.Author('Eric Alexander')]","Word clouds are frequently used to analyze and communicate text data in many
domains. In order to help guide research on improving the legibility of word
clouds, we have conducted a survey of their usage in Digital Humanities
academia and journalism. Using a modified grounded theory approach, we sought
to identify the most common purposes for which word clouds were employed and
the most common visual encodings they contained. Our findings indicate that
font size, color, and word placement dominate as the primary data-encoding
channels, as we hypothesized. Perhaps more surprisingly, we found that asking
viewers to perform analytical tasks with word clouds was relatively common,
especially in DH sources. This suggests that research into the interactions of
these visual encoding channels (particularly in regards to legibility) is
warranted."
12490,further study.,"Figure 11: An example of two clouds that require users to perform
   The frequency with which direction, color, and placement were         inter-cloud comparisons; the quote provides evidence (from “Word-
used for aesthetic purposes prompts two major questions that warrant     smiths or just wordy?” by H. Siddique in The Guardian).","Is the aesthetic use of these channels affecting users’
ability to parse the relevant data?",2022-10-14 18:51:15+00:00,Word Clouds in the Wild,cs.HC,['cs.HC'],"[arxiv.Result.Author('Rebecca M. M. Hicke'), arxiv.Result.Author('Maanya Goenka'), arxiv.Result.Author('Eric Alexander')]","Word clouds are frequently used to analyze and communicate text data in many
domains. In order to help guide research on improving the legibility of word
clouds, we have conducted a survey of their usage in Digital Humanities
academia and journalism. Using a modified grounded theory approach, we sought
to identify the most common purposes for which word clouds were employed and
the most common visual encodings they contained. Our findings indicate that
font size, color, and word placement dominate as the primary data-encoding
channels, as we hypothesized. Perhaps more surprisingly, we found that asking
viewers to perform analytical tasks with word clouds was relatively common,
especially in DH sources. This suggests that research into the interactions of
these visual encoding channels (particularly in regards to legibility) is
warranted."
12523,"so general public or researchers can access them freely, e.g., for              explored the software’s role in visual art production to inform
further research [26].","Similarly, Li et al.","Based on such advancement that datasets,                 end-user programming and creativity support tools [48].",2022-10-16 08:06:38+00:00,Large-scale Text-to-Image Generation Models for Visual Artists' Creative Works,cs.HC,['cs.HC'],"[arxiv.Result.Author('Hyung-Kwon Ko'), arxiv.Result.Author('Gwanmo Park'), arxiv.Result.Author('Hyeon Jeon'), arxiv.Result.Author('Jaemin Jo'), arxiv.Result.Author('Juho Kim'), arxiv.Result.Author('Jinwook Seo')]","Large-scale Text-to-image Generation Models (LTGMs) (e.g., DALL-E),
self-supervised deep learning models trained on a huge dataset, have
demonstrated the capacity for generating high-quality open-domain images from
multi-modal input. Although they can even produce anthropomorphized versions of
objects and animals, combine irrelevant concepts in reasonable ways, and give
variation to any user-provided images, we witnessed such rapid technological
advancement left many visual artists disoriented in leveraging LTGMs more
actively in their creative works. Our goal in this work is to understand how
visual artists would adopt LTGMs to support their creative works. To this end,
we conducted an interview study as well as a systematic literature review of 72
system/application papers for a thorough examination. A total of 28 visual
artists covering 35 distinct visual art domains acknowledged LTGMs' versatile
roles with high usability to support creative works in automating the creation
process (i.e., automation), expanding their ideas (i.e., exploration), and
facilitating or arbitrating in communication (i.e., mediation). We conclude by
providing four design guidelines that future researchers can refer to in making
intelligent user interfaces using LTGMs."
12655,"The evaluation
items related to personality adaptation, ""appropriateness of
dialogue,"" ""likability of dialogue,"" ""satisfaction with a
   A direction of further research is to investigate the                                   [7] Kenta Yamamoto Koji Inoue Tatsuya Kawahara, ""Analysis of
relationship between user personality and dialogue system                                        Personality Relationship for User Adaptation of Spoken Dialogueue
personality.",round are shown in Table III and Figure 4.,"Furthermore, due to the nature of the                                               Systems,"" SIG-SLUD-093-02 2021, pp.",2022-10-18 11:22:37+00:00,Personality-adapted multimodal dialogue system,cs.HC,['cs.HC'],"[arxiv.Result.Author('Tamotsu Miyama'), arxiv.Result.Author('Shogo Okada')]","This paper describes a personality-adaptive multimodal dialogue system
developed for the Dialogue Robot Competition 2022. To realize a dialogue system
that adapts the dialogue strategy to individual users, it is necessary to
consider the user's nonverbal information and personality. In this competition,
we built a prototype of a user-adaptive dialogue system that estimates user
personality during dialogue. Pretrained DNN models are used to estimate user
personalities annotated as Big Five scores. This model is embedded in a
dialogue system to estimate user personality from face images during the
dialogue. We proposed a method for dialogue management that changed the
dialogue flow based on the estimated personality characteristics and confirmed
that the system works in a real environment in the preliminary round of this
competition. Furthermore, we implemented specific modules to enhance the
multimodal dialogue experience of the user, including personality assessment,
controlling facial expressions and movements of the android, and dialogue
management to explain the attractiveness of sightseeing spots. The aim of
dialogue based on personality assessment is to reduce the nervousness of users,
and it acts as an ice breaker. The android's facial expressions and movements
are necessary for a more natural android conversation. Since the task of this
competition was to promote the appeal of sightseeing spots and to recommend an
appropriate sightseeing spot, the dialogue process for how to explain the
attractiveness of the spot is important. All results of the subjective
evaluation by users were better than those of the baseline and other systems
developed for this competition. The proposed dialogue system ranked first in
both ""Impression Rating"" and ""Effectiveness of Android Recommendations"".
According to the total evaluation in the competition, the proposed system was
ranked first overall."
12656,"9-14
experimental environment of competition, the dialogue
system was evaluated based on the criteria of tailored tasks of                            [8] Shohei Sato Akinobu Lee, ""ANALYSIS OF RELATIONSHIP IN
the competition, and it is necessary to conduct further research                                 PSYCHOLOGICAL CHARACTERISTICS AT SHORT MEETINGS
and experiments in personality adaptive dialogue systems.","Furthermore, due to the nature of the                                               Systems,"" SIG-SLUD-093-02 2021, pp.","FOR AFFABLE SPOKEN DIALOGUEUE SYSTEMS,""
                                                                                                 SIG-SLUD-B505-34, 2016, pp.",2022-10-18 11:22:37+00:00,Personality-adapted multimodal dialogue system,cs.HC,['cs.HC'],"[arxiv.Result.Author('Tamotsu Miyama'), arxiv.Result.Author('Shogo Okada')]","This paper describes a personality-adaptive multimodal dialogue system
developed for the Dialogue Robot Competition 2022. To realize a dialogue system
that adapts the dialogue strategy to individual users, it is necessary to
consider the user's nonverbal information and personality. In this competition,
we built a prototype of a user-adaptive dialogue system that estimates user
personality during dialogue. Pretrained DNN models are used to estimate user
personalities annotated as Big Five scores. This model is embedded in a
dialogue system to estimate user personality from face images during the
dialogue. We proposed a method for dialogue management that changed the
dialogue flow based on the estimated personality characteristics and confirmed
that the system works in a real environment in the preliminary round of this
competition. Furthermore, we implemented specific modules to enhance the
multimodal dialogue experience of the user, including personality assessment,
controlling facial expressions and movements of the android, and dialogue
management to explain the attractiveness of sightseeing spots. The aim of
dialogue based on personality assessment is to reduce the nervousness of users,
and it acts as an ice breaker. The android's facial expressions and movements
are necessary for a more natural android conversation. Since the task of this
competition was to promote the appeal of sightseeing spots and to recommend an
appropriate sightseeing spot, the dialogue process for how to explain the
attractiveness of the spot is important. All results of the subjective
evaluation by users were better than those of the baseline and other systems
developed for this competition. The proposed dialogue system ranked first in
both ""Impression Rating"" and ""Effectiveness of Android Recommendations"".
According to the total evaluation in the competition, the proposed system was
ranked first overall."
13383,"Speciﬁcally, it
further research.","Moreover, we focus on analyz-
and proposed to follow Javed et al.’s theory of compos-          ing visualizations in the context of visual analytics, which
ite visualization [14] to characterize the visual designs in     poses higher requirements for data labeling.","Based on this reﬂection, we regard the         not only requires labeling the meta information like chart
visualizations in VA systems as composite visualizations         positions but the information related to visualization lit-
and characterize the relations between the components with       eracy (e.g., visual encodings and tasks).",2022-11-03 01:58:13+00:00,KB4VA: A Knowledge Base of Visualization Designs for Visual Analytics,cs.HC,['cs.HC'],"[arxiv.Result.Author('Dazhen Deng'), arxiv.Result.Author('Aoyu Wu'), arxiv.Result.Author('Haotian Li'), arxiv.Result.Author('Ji Lan'), arxiv.Result.Author('Yong Wang'), arxiv.Result.Author('Huamin Qu'), arxiv.Result.Author('Yingcai Wu')]","Visual analytics (VA) systems have been widely used to facilitate
decision-making and analytical reasoning in various application domains. VA
involves visual designs, interaction designs, and data mining, which is a
systematic and complex paradigm. In this work, we focus on the design of
effective visualizations for complex data and analytical tasks, which is a
critical step in designing a VA system. This step is challenging because it
requires extensive knowledge about domain problems and visualization to design
effective encodings. Existing visualization designs published in top venues are
valuable resources to inspire designs for problems with similar data structures
and tasks. However, those designs are hard to understand, parse, and retrieve
due to the lack of specifications. To address this problem, we build KB4VA, a
knowledge base of visualization designs in VA systems with comprehensive labels
about their analytical tasks and visual encodings. Our labeling scheme is
inspired by a workshop study with 12 VA researchers to learn user requirements
in understanding and retrieving professional visualization designs in VA
systems. The theme extends Vega-Lite specifications for describing advanced and
composited visualization designs in a declarative manner, thus facilitating
human understanding and automatic indexing. To demonstrate the usefulness of
our knowledge base, we present a user study about design inspirations for VA
tasks. In summary, our work opens new perspectives for enhancing the
accessibility and reusability of professional visualization designs."
13384,"The relationships between different vi-       speciﬁcation, knowledge base, and lessons learned could
sual components are often reﬂected by their sizes, positions     provide a helpful foundation for further research.","We hope that our
tive sense-making.",as well as interactions.,2022-11-03 01:58:13+00:00,KB4VA: A Knowledge Base of Visualization Designs for Visual Analytics,cs.HC,['cs.HC'],"[arxiv.Result.Author('Dazhen Deng'), arxiv.Result.Author('Aoyu Wu'), arxiv.Result.Author('Haotian Li'), arxiv.Result.Author('Ji Lan'), arxiv.Result.Author('Yong Wang'), arxiv.Result.Author('Huamin Qu'), arxiv.Result.Author('Yingcai Wu')]","Visual analytics (VA) systems have been widely used to facilitate
decision-making and analytical reasoning in various application domains. VA
involves visual designs, interaction designs, and data mining, which is a
systematic and complex paradigm. In this work, we focus on the design of
effective visualizations for complex data and analytical tasks, which is a
critical step in designing a VA system. This step is challenging because it
requires extensive knowledge about domain problems and visualization to design
effective encodings. Existing visualization designs published in top venues are
valuable resources to inspire designs for problems with similar data structures
and tasks. However, those designs are hard to understand, parse, and retrieve
due to the lack of specifications. To address this problem, we build KB4VA, a
knowledge base of visualization designs in VA systems with comprehensive labels
about their analytical tasks and visual encodings. Our labeling scheme is
inspired by a workshop study with 12 VA researchers to learn user requirements
in understanding and retrieving professional visualization designs in VA
systems. The theme extends Vega-Lite specifications for describing advanced and
composited visualization designs in a declarative manner, thus facilitating
human understanding and automatic indexing. To demonstrate the usefulness of
our knowledge base, we present a user study about design inspirations for VA
tasks. In summary, our work opens new perspectives for enhancing the
accessibility and reusability of professional visualization designs."
13564,"By sliding a cutting plane through the whole genome             The described visualization framework gives us a solid
3D structure (Figure 10c3), we can uncover the rest of genes,   basis for further research.",visualization experts in adopting our solutions.,"Several topics already came up
located on chromosomes buried deeply inside the chromatin
core.",2022-11-09 12:37:52+00:00,ChromoSkein: Untangling Three-Dimensional Chromatin Fiber With a Web-Based Visualization Framework,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Matúš Talčík'), arxiv.Result.Author('Filip Opálený'), arxiv.Result.Author('Tereza Clarence'), arxiv.Result.Author('Katarína Furmanová'), arxiv.Result.Author('Jan Byška'), arxiv.Result.Author('Barbora Kozlíková'), arxiv.Result.Author('David Kouřil')]","We present ChromoSkein, a web-based tool for visualizing three-dimensional
chromatin models. The spatial organization of chromatin is essential to its
function. Experimental methods, namely Hi-C, reveal the spatial conformation
but output a 2D matrix representation. Biologists leverage simulation to bring
this information back to 3D, assembling a 3D chromatin shape prediction using
the 2D matrices as constraints. Our overview of existing chromatin
visualization software shows that the available tools limit the utility of 3D
through ineffective shading and a lack of advanced interactions. We designed
ChromoSkein to encourage analytical work directly with the 3D representation.
Our tool features a 3D view that supports understanding the shape of the highly
tangled chromatin fiber and the spatial relationships of its parts. Users can
explore and filter the 3D model using two interactions. First, they can manage
occlusion both by toggling the visibility of semantic parts and by adding
cutting planes. Second, they can segment the model through the creation of
custom selections. To complement the 3D view, we link the spatial
representation with non-spatial genomic data, such as 2D Hi-C maps and 1D
genomic signals. We demonstrate the utility of ChromoSkein in two exemplary use
cases that examine functional genomic loci in the spatial context of
chromosomes and the whole genome."
13604,"5 Technical challenges & considera-
                                                                       tions

Figure 3: Holodeck experiment in which we spoke a bed-             While implementing our demonstration, we encountered
room into existence by the simple command ”Change the              several technical challenges in need of further research.",models.,scene into a bedroom”.,2022-11-10 21:13:04+00:00,Steps towards prompt-based creation of virtual worlds,cs.HC,"['cs.HC', 'cs.AI', 'cs.LG', 'cs.MM']","[arxiv.Result.Author('Jasmine Roberts'), arxiv.Result.Author('Andrzej Banburski-Fahey'), arxiv.Result.Author('Jaron Lanier')]","Large language models trained for code generation can be applied to speaking
virtual worlds into existence (creating virtual worlds). In this work we show
that prompt-based methods can both accelerate in-VR level editing, as well as
can become part of gameplay rather than just part of game development. As an
example, we present Codex VR Pong which shows non-deterministic game mechanics
using generative processes to not only create static content but also
non-trivial interactions between 3D objects. This demonstration naturally leads
to an integral discussion on how one would evaluate and benchmark experiences
created by generative models - as there are no qualitative or quantitative
metrics that apply in these scenarios. We conclude by discussing impending
challenges of AI-assisted co-creation in VR."
13618,"Therefore, further research is required to investigate
the potential feasibility of applying an EEG-based BCI to furnish a performance-driven adaptive aiding
system for hazard inspection.","8
This leads to the hypothesis that an EEG-enabled BCI can be established to predict construction hazard
recognition performance; however, there is no direct evidence of whether EEG signals from individuals
with high, medium, and low hazard recognition performance levels can be differentiated with
classification accuracy exceeding the change level.","2.3 Environmentally determined and continual learning
Suitable alert thresholds for automated diagnostic systems vary significantly depending on external
hazardous conditions.",2022-11-09 13:05:12+00:00,EEG-based performance-driven adaptive automated hazard alerting system in security surveillance support,cs.HC,['cs.HC'],"[arxiv.Result.Author('Xiaoshan Zhou'), arxiv.Result.Author('Pin-Chao Liao')]","Computer-vision technologies have emerged to assist security surveillance.
However, automation alert/alarm systems often apply a low-beta threshold to
avoid misses and generates excessive false alarms. This study proposed an
adaptive hazard diagnosis and alarm system with adjustable alert threshold
levels based on environmental scenarios and operator's hazard recognition
performance. We recorded electroencephalogram (EEG) data during hazard
recognition tasks. The linear ballistic accumulator model was used to decompose
the response time into several psychological subcomponents, which were further
estimated by a Markov chain Monte Carlo algorithm and compared among different
types of hazardous scenarios. Participants were most cautious about falling
hazards, followed by electricity hazards, and had the least conservative
attitude toward structural hazards. Participants were classified into three
performance-level subgroups using a latent profile analysis based on task
accuracy. We applied the transfer learning paradigm to classify subgroups based
on their time-frequency representations of EEG data. Additionally, two
continual learning strategies were investigated to ensure a robust adaptation
of the model to predict participants' performance levels in different hazardous
scenarios. These findings can be leveraged in real-world brain-computer
interface applications, which will provide human trust in automation and
promote the successful implementation of alarm technologies."
13619,"Although misses and excessive false alarms both
degrade trust and adversely affect performance (Yamada & Kuchar, 2006), further research suggested
that the degree of difficulty of the task, rather than the type of error, appears to influence the trust level.","Selecting an appropriate threshold involves making a trade-off between miss and
false alarm rates (Molloy, Ford, & Mejias, 2017).","Trust has been found to degrade, particularly when automation misses or provides a false alarm while
detecting a target that the operator perceives to be easily identifiable.",2022-11-09 13:05:12+00:00,EEG-based performance-driven adaptive automated hazard alerting system in security surveillance support,cs.HC,['cs.HC'],"[arxiv.Result.Author('Xiaoshan Zhou'), arxiv.Result.Author('Pin-Chao Liao')]","Computer-vision technologies have emerged to assist security surveillance.
However, automation alert/alarm systems often apply a low-beta threshold to
avoid misses and generates excessive false alarms. This study proposed an
adaptive hazard diagnosis and alarm system with adjustable alert threshold
levels based on environmental scenarios and operator's hazard recognition
performance. We recorded electroencephalogram (EEG) data during hazard
recognition tasks. The linear ballistic accumulator model was used to decompose
the response time into several psychological subcomponents, which were further
estimated by a Markov chain Monte Carlo algorithm and compared among different
types of hazardous scenarios. Participants were most cautious about falling
hazards, followed by electricity hazards, and had the least conservative
attitude toward structural hazards. Participants were classified into three
performance-level subgroups using a latent profile analysis based on task
accuracy. We applied the transfer learning paradigm to classify subgroups based
on their time-frequency representations of EEG data. Additionally, two
continual learning strategies were investigated to ensure a robust adaptation
of the model to predict participants' performance levels in different hazardous
scenarios. These findings can be leveraged in real-world brain-computer
interface applications, which will provide human trust in automation and
promote the successful implementation of alarm technologies."
13620,"In general, however,
6.1 Limitations                                                                 further research and extensive studies should be conducted to find
                                                                                what shapes and metrics allow for the most accurate visuals created
For this study we surveyed 25 participants using MTurk.","and compared with one another as data values may exceed the hu-
                                                                                man eyes limitation to preserve visualizations.","However,
with 9 participants failing the attention check question, we only
retained 16 responses to use in analysis.",2022-11-11 02:26:10+00:00,Using dynamic circles and squares to visualize spatio-temporal variation,cs.HC,"['cs.HC', 'cs.IR']","[arxiv.Result.Author('Harsh Patel'), arxiv.Result.Author('Nicole Schneider'), arxiv.Result.Author('Hanan Samet')]","Visualizations such as bar charts, scatter plots, and objects on geographical
maps often convey critical information, including exact and relative numeric
values, using shapes. The choice of shape and method of encoding information is
often arbitrarily, or based on convention. However, past studies have shown
that the human eye can be fooled by visual representations. The Ebbinghaus
illusion demonstrates that the perceived relative sizes of shapes depends on
their configuration, which in turn can affect judgements, especially in
visualizations like proportional symbol maps. In this study we evaluate the
effects of varying the type of shapes and metrics for encoding data in visual
representations on a spatio-temporal map interface. We find that some
combinations of shape and metric are more conducive to accurate human
judgements than others, and provide recommendations for applying these findings
in future visualization designs."
13621,"As a result, we hope that
these findings spur further research along the lines we have sug-                          //doi.org/10.1111/j.1467- 8306.1981.tb01351.x
gested and encourage scientists as well as cartographers to consider
carefully how they present numerical data in map visualizations                            [15] Richard E Groop and Daniel Cole.","https:
visualizations are perceived by viewers.",1978.,2022-11-11 02:26:10+00:00,Using dynamic circles and squares to visualize spatio-temporal variation,cs.HC,"['cs.HC', 'cs.IR']","[arxiv.Result.Author('Harsh Patel'), arxiv.Result.Author('Nicole Schneider'), arxiv.Result.Author('Hanan Samet')]","Visualizations such as bar charts, scatter plots, and objects on geographical
maps often convey critical information, including exact and relative numeric
values, using shapes. The choice of shape and method of encoding information is
often arbitrarily, or based on convention. However, past studies have shown
that the human eye can be fooled by visual representations. The Ebbinghaus
illusion demonstrates that the perceived relative sizes of shapes depends on
their configuration, which in turn can affect judgements, especially in
visualizations like proportional symbol maps. In this study we evaluate the
effects of varying the type of shapes and metrics for encoding data in visual
representations on a spatio-temporal map interface. We find that some
combinations of shape and metric are more conducive to accurate human
judgements than others, and provide recommendations for applying these findings
in future visualization designs."
13711,"challenges that escalate the need for further research to de-
                                        Development of AER capabilities can have a transformative       sign more trustful and beneﬁcial systems [11].","tidisciplinary research area that leverages advances in ar-
                                        tiﬁcial intelligence (AI) to algorithmically retrieve a per-        AER has evolved over the years and achieved remark-
                                        son’s emotional state using knowledge from psychology,          able advances; however, it faces various complex and critical
                                        linguistics, signal processing, and machine learning (ML).","Some major
                                        effect on society with wide-ranging implications due to the     challenges faced in AER are:
                                        critical role emotions play in human lives ranging from
                                        perception, learning, and decision-making [1] [2] [3].",2022-11-14 11:43:10+00:00,"AI-Based Emotion Recognition: Promise, Peril, and Prescriptions for Prosocial Path",cs.HC,['cs.HC'],"[arxiv.Result.Author('Siddique Latif'), arxiv.Result.Author('Hafiz Shehbaz Ali'), arxiv.Result.Author('Muhammad Usama'), arxiv.Result.Author('Rajib Rana'), arxiv.Result.Author('Björn Schuller'), arxiv.Result.Author('Junaid Qadir')]","Automated emotion recognition (AER) technology can detect humans' emotional
states in real-time using facial expressions, voice attributes, text, body
movements, and neurological signals and has a broad range of applications
across many sectors. It helps businesses get a much deeper understanding of
their customers, enables monitoring of individuals' moods in healthcare,
education, or the automotive industry, and enables identification of violence
and threat in forensics, to name a few. However, AER technology also risks
using artificial intelligence (AI) to interpret sensitive human emotions. It
can be used for economic and political power and against individual rights.
Human emotions are highly personal, and users have justifiable concerns about
privacy invasion, emotional manipulation, and bias. In this paper, we present
the promises and perils of AER applications. We discuss the ethical challenges
related to the data and AER systems and highlight the prescriptions for
prosocial perspectives for future AER applications. We hope this work will help
AI researchers and developers design prosocial AER applications."
13715,"Thus, a direction for further research could be to combine FL with
formal privacy technologies (e.g.","Limitations and Future Work Apart from the privacy guarantees presented in this paper,
a limitation of our work resides in the fact that FL does not provide provable (cryptographic)
privacy guarantees.","diﬀerential privacy and secure aggregation (Bonawitz et al.,
2017)).",2022-11-14 13:13:01+00:00,Federated Learning for Appearance-based Gaze Estimation in the Wild,cs.HC,['cs.HC'],"[arxiv.Result.Author('Mayar Elfares'), arxiv.Result.Author('Zhiming Hu'), arxiv.Result.Author('Pascal Reisert'), arxiv.Result.Author('Andreas Bulling'), arxiv.Result.Author('Ralf Küsters')]","Gaze estimation methods have significantly matured in recent years, but the
large number of eye images required to train deep learning models poses
significant privacy risks. In addition, the heterogeneous data distribution
across different users can significantly hinder the training process. In this
work, we propose the first federated learning approach for gaze estimation to
preserve the privacy of gaze data. We further employ pseudo-gradient
optimisation to adapt our federated learning approach to the divergent model
updates to address the heterogeneous nature of in-the-wild gaze data in
collaborative setups. We evaluate our approach on a real-world dataset
(MPIIGaze) and show that our work enhances the privacy guarantees of
conventional appearance-based gaze estimation methods, handles the convergence
issues of gaze estimators, and significantly outperforms vanilla federated
learning by 15.8% (from a mean error of 10.63 degrees to 8.95 degrees). As
such, our work paves the way to develop privacy-aware collaborative learning
setups for gaze estimation while maintaining the model's performance."
13817,"The objective is to
show multitude of opportunities such concepts could provide for further research and development.",The authors aim at opening new paths for the community to explore rather than describing end-to-end solutions.,"Index Terms—Mixed Reality, Augmented Reality, Object Alignment, Visualization, Perception

1 INTRODUCTION                                                                tion and placement of real objects.",2022-11-16 16:50:21+00:00,Complementary Textures. A Novel Approach to Object Alignment in Mixed Reality,cs.HC,"['cs.HC', 'cs.GR']","[arxiv.Result.Author('Alejandro Martin-Gomez'), arxiv.Result.Author('Alexander Winkler'), arxiv.Result.Author('Rafael de la Tijera Obert'), arxiv.Result.Author('Javad Fotouhi'), arxiv.Result.Author('Daniel Roth'), arxiv.Result.Author('Ulrich Eck'), arxiv.Result.Author('Nassir Navab')]","Alignment between real and virtual objects is a challenging task required for
the deployment of Mixed Reality (MR) into manufacturing, medical, and
construction applications. To face this challenge, a series of methods have
been proposed. While many approaches use dynamic augmentations such as
animations, arrows, or text to assist users, they require tracking the position
of real objects. In contrast, when tracking of the real objects is not
available or desired, alternative approaches use virtual replicas of real
objects to allow for interactive, perceptual virtual-to-real, and/or
real-to-virtual alignment. In these cases, the accuracy achieved strongly
depends on the quality of the perceptual information provided to the user. This
paper proposes a novel set of perceptual alignment concepts that go beyond the
use of traditional visualization of virtual replicas, introducing the concept
of COMPLEMENTARY TEXTURES to improve interactive alignment in MR applications.
To showcase the advantages of using COMPLEMENTARY TEXTURES, we describe three
different implementations that provide highly salient visual cues when
misalignment is observed; or present semantic augmentations that, when combined
with a real object, provide contextual information that can be used during the
alignment process. The authors aim to open new paths for the community to
explore rather than describing end-to-end solutions. The objective is to show
the multitude of opportunities such concepts could provide for further research
and development."
13889,"While the feedback we received from the experts is promising,
   We proposed a cloud-based visual analytics approach,             we identiﬁed several future directions for further research.",DISCUSSION AND LIMITATIONS                       utilized to evaluate the proposed visual analytics approach.,"Our
DCPViz, for making sense of DCP datasets that beneﬁts ex-           future work will encompass a data mining architecture that
ploratory analysis by climate scientists.",2022-11-18 01:51:11+00:00,DCPViz: A Visual Analytics Approach for Downscaled Climate Projections,cs.HC,['cs.HC'],"[arxiv.Result.Author('Abdullah-Al-Raihan Nayeem'), arxiv.Result.Author('Huikyo Lee'), arxiv.Result.Author('Dongyun Han'), arxiv.Result.Author('Mohammad Elshambakey'), arxiv.Result.Author('William J. Tolone'), arxiv.Result.Author('Todd Dobbs'), arxiv.Result.Author('Daniel Crichton'), arxiv.Result.Author('Isaac Cho')]","This paper introduces a novel visual analytics approach, DCPViz, to enable
climate scientists to explore massive climate data interactively without
requiring the upfront movement of massive data. Thus, climate scientists are
afforded more effective approaches to support the identification of potential
trends and patterns in climate projections and their subsequent impacts. We
designed the DCPViz pipeline to fetch and extract NEX-DCP30 data with minimal
data transfer from their public sources. We implemented DCPViz to demonstrate
its scalability and scientific value and to evaluate its utility under three
use cases based on different models and through domain expert feedback."
13956,"Here, further research might consider
chemicals.","For example, P8’s technique of plastic sheet-      related content as one way to support a sense of community
ing was based on how farmers discouraged weeds without             and civic engagement.","P3 and P1’s ideas of placing antlers in the garden      how sociality varies across different activities or types of in-
came from an understanding of the necessity to nourish the         teractions and how this relates to activities seen as social or
soil and other animals.",2022-11-19 18:34:11+00:00,Sociality and Skill Sharing in the Garden,cs.HC,"['cs.HC', 'cs.SI', 'H.5.0; K.3.1; K.4.2']","[arxiv.Result.Author('Hanuma Teja Maddali'), arxiv.Result.Author('Amanda Lazar')]","Gardening is an activity that involves a number of dimensions of increasing
interest to HCI and CSCW researchers, including recreation, sustainability, and
engagement with nature. This paper considers the garden setting in order to
understand the role that collaborative and social computing technologies might
play for practitioners engaging in outdoor skilled activities. We conducted
participant observations with nine experienced gardeners aged 22-71 years.
Through this process, we find that gardeners continuously configure their
environments to accommodate their preferences for sociality. They share
embodied skills and help others attune to sensory information in person, but
also influence learning through the features in their garden that are observed
by others. This paper provides an understanding of sociality in the garden,
highlights skill sharing as a key domain for design in this space, and
contributes design considerations for collaborative technologies in outdoor
settings."
14102,"However, the digital transformations
of classrooms reflect an important and critical step when developing VR environments for
learning purposes and require further research.","Digital Transformations of Classrooms in Virtual Reality

   While VR technology has a long history in the education domain [26, 166], the current
availability of consumer-grade head-mounted displays (HMDs) allows for the creation of
immersive experiences at a reasonable cost, making it possible to employ immersive personal-
ized VR experiences in classrooms in the near future [11].","A unique opportunity to understand the
gaze-based behavior, and consequently, attention distribution of learners in such VR settings
is provided through the analysis of the eye movement of learners [167].",2022-11-23 10:49:03+00:00,Assessment of Human Behavior in Virtual Reality by Eye Tracking,cs.HC,"['cs.HC', 'I.0']",[arxiv.Result.Author('Hong Gao')],"Virtual reality (VR) is not a new technology but has been in development for
decades, driven by advances in computer technology. Currently, VR technology is
increasingly being used in applications to enable immersive, yet controlled
research settings. Education and entertainment are two important application
areas, where VR has been considered a key enabler of immersive experiences and
their further advancement. At the same time, the study of human behavior in
such innovative environments is expected to contribute to a better design of VR
applications. Therefore, modern VR devices are consistently equipped with
eye-tracking technology, enabling thus further studies of human behavior
through the collection of process data. In particular, eye-tracking technology
in combination with machine learning techniques and explainable models can
provide new insights for a deeper understanding of human behavior during
immersion in virtual environments.
  In this work, a systematic computational framework based on eye-tracking and
behavioral user data and state-of-the-art machine learning approaches is
proposed to understand human behavior and individual differences in VR
contexts. This computational framework is then employed in three user studies
across two different domains. In the educational domain, two different
immersive VR classrooms were created where students can learn and teachers can
train. In terms of VR entertainment, eye movements open a new avenue to
evaluate VR locomotion techniques from the perspective of user cognitive load
and user experience. This work paves the way for assessing human behavior in VR
scenarios and provides profound insights into the way of designing, evaluating,
and improving interactive VR systems. In particular, more effective and
customizable virtual environments can be created to provide users with tailored
experiences."
14103,"In a further study, deep learning approaches
using neural networks such as Long Short-Term Memory (LSTM), which are good at handling
temporal data, could be explored with the aim of achieving better performance.","In addition, in our work, we used SVM, Random Forest, and LightGBM, which have been
commonly used in many previous studies.","However,
such approaches require more data compared to the classifiers we use, since there are many
more parameters to optimize.",2022-11-23 10:49:03+00:00,Assessment of Human Behavior in Virtual Reality by Eye Tracking,cs.HC,"['cs.HC', 'I.0']",[arxiv.Result.Author('Hong Gao')],"Virtual reality (VR) is not a new technology but has been in development for
decades, driven by advances in computer technology. Currently, VR technology is
increasingly being used in applications to enable immersive, yet controlled
research settings. Education and entertainment are two important application
areas, where VR has been considered a key enabler of immersive experiences and
their further advancement. At the same time, the study of human behavior in
such innovative environments is expected to contribute to a better design of VR
applications. Therefore, modern VR devices are consistently equipped with
eye-tracking technology, enabling thus further studies of human behavior
through the collection of process data. In particular, eye-tracking technology
in combination with machine learning techniques and explainable models can
provide new insights for a deeper understanding of human behavior during
immersion in virtual environments.
  In this work, a systematic computational framework based on eye-tracking and
behavioral user data and state-of-the-art machine learning approaches is
proposed to understand human behavior and individual differences in VR
contexts. This computational framework is then employed in three user studies
across two different domains. In the educational domain, two different
immersive VR classrooms were created where students can learn and teachers can
train. In terms of VR entertainment, eye movements open a new avenue to
evaluate VR locomotion techniques from the perspective of user cognitive load
and user experience. This work paves the way for assessing human behavior in VR
scenarios and provides profound insights into the way of designing, evaluating,
and improving interactive VR systems. In particular, more effective and
customizable virtual environments can be created to provide users with tailored
experiences."
14344,"However, systems
for supporting exploration such as the concept expressed in Figure 2 requires further research and
development.","Research in robot navigation and computer vision has made significant progress in perceiving
the environment using navigation stacks [49] and deep learning models [11, 68].","Technical challenges may be caused by several things: (1) occluding objects or other
people within the space: making it hard to perceive the actual shape of the environment, (2) finite
range of sensors: limiting applicability of such systems to large open spaces such as shopping malls,
and (3) camera instability of on-body sensors: causing blur and severely affecting the accuracy of
vision algorithms as the user walks around.",2022-11-29 18:43:09+00:00,"""I Want to Figure Things Out"": Supporting Exploration in Navigation for People with Visual Impairments",cs.HC,['cs.HC'],"[arxiv.Result.Author('Gaurav Jain'), arxiv.Result.Author('Yuanyang Teng'), arxiv.Result.Author('Dong Heon Cho'), arxiv.Result.Author('Yunhao Xing'), arxiv.Result.Author('Maryam Aziz'), arxiv.Result.Author('Brian A. Smith')]","Navigation assistance systems (NASs) aim to help visually impaired people
(VIPs) navigate unfamiliar environments. Most of today's NASs support VIPs via
turn-by-turn navigation, but a growing body of work highlights the importance
of exploration as well. It is unclear, however, how NASs should be designed to
help VIPs explore unfamiliar environments. In this paper, we perform a
qualitative study to understand VIPs' information needs and challenges with
respect to exploring unfamiliar environments, with the aim of informing the
design of NASs that support exploration. Our findings reveal the types of
spatial information that VIPs need as well as factors that affect VIPs'
information preferences. We also discover specific challenges that VIPs face
that future NASs can address such as orientation and mobility education and
collaborating effectively with others. We present design implications for NASs
that support exploration, and we identify specific research opportunities and
discuss open socio-technical challenges for making such NASs possible. We
conclude by reflecting on our study procedure to inform future approaches in
research on ethical considerations that may be adopted while interacting with
the broader VIP community."
14345,"Analogously, we can imagine further research into identifying and resolving user errors
that arise during in-situ exploration assistance.",perform.,6.1.4 O&M education assistance as a means of empowering VIPs to explore.,2022-11-29 18:43:09+00:00,"""I Want to Figure Things Out"": Supporting Exploration in Navigation for People with Visual Impairments",cs.HC,['cs.HC'],"[arxiv.Result.Author('Gaurav Jain'), arxiv.Result.Author('Yuanyang Teng'), arxiv.Result.Author('Dong Heon Cho'), arxiv.Result.Author('Yunhao Xing'), arxiv.Result.Author('Maryam Aziz'), arxiv.Result.Author('Brian A. Smith')]","Navigation assistance systems (NASs) aim to help visually impaired people
(VIPs) navigate unfamiliar environments. Most of today's NASs support VIPs via
turn-by-turn navigation, but a growing body of work highlights the importance
of exploration as well. It is unclear, however, how NASs should be designed to
help VIPs explore unfamiliar environments. In this paper, we perform a
qualitative study to understand VIPs' information needs and challenges with
respect to exploring unfamiliar environments, with the aim of informing the
design of NASs that support exploration. Our findings reveal the types of
spatial information that VIPs need as well as factors that affect VIPs'
information preferences. We also discover specific challenges that VIPs face
that future NASs can address such as orientation and mobility education and
collaborating effectively with others. We present design implications for NASs
that support exploration, and we identify specific research opportunities and
discuss open socio-technical challenges for making such NASs possible. We
conclude by reflecting on our study procedure to inform future approaches in
research on ethical considerations that may be adopted while interacting with
the broader VIP community."
14346,"Involving representative users in
different roles also calls for further research to better understand and establish the best practices for
ensuring appropriate compensation and due credit for the representative users’ contributions [70].","Future research approaches should consider including representative users for
interpreting study data, especially for research in accessibility.","Additionally, we note that using CIT [36] during the interviews leads to discussion around
actual examples of participants’ past experiences, which sometimes may include private identifiable
information such as locations of places participants visit, names of their friends and family members.",2022-11-29 18:43:09+00:00,"""I Want to Figure Things Out"": Supporting Exploration in Navigation for People with Visual Impairments",cs.HC,['cs.HC'],"[arxiv.Result.Author('Gaurav Jain'), arxiv.Result.Author('Yuanyang Teng'), arxiv.Result.Author('Dong Heon Cho'), arxiv.Result.Author('Yunhao Xing'), arxiv.Result.Author('Maryam Aziz'), arxiv.Result.Author('Brian A. Smith')]","Navigation assistance systems (NASs) aim to help visually impaired people
(VIPs) navigate unfamiliar environments. Most of today's NASs support VIPs via
turn-by-turn navigation, but a growing body of work highlights the importance
of exploration as well. It is unclear, however, how NASs should be designed to
help VIPs explore unfamiliar environments. In this paper, we perform a
qualitative study to understand VIPs' information needs and challenges with
respect to exploring unfamiliar environments, with the aim of informing the
design of NASs that support exploration. Our findings reveal the types of
spatial information that VIPs need as well as factors that affect VIPs'
information preferences. We also discover specific challenges that VIPs face
that future NASs can address such as orientation and mobility education and
collaborating effectively with others. We present design implications for NASs
that support exploration, and we identify specific research opportunities and
discuss open socio-technical challenges for making such NASs possible. We
conclude by reflecting on our study procedure to inform future approaches in
research on ethical considerations that may be adopted while interacting with
the broader VIP community."
14347,"Thus, further research is
needed to confirm and adapt some of our results to offer a more comprehensive picture of how
assistive technologies might facilitate exploration for a variety of populations.","Last, we do not yet know
how our study results might generalize to other types of impairments.","8 CONCLUSION

In this paper, we conducted semi-structured interviews with 12 VIPs and others who affect VIPs’
navigation behaviors to investigate VIPs’ information needs and challenges with respect to exploring
unfamiliar environments.",2022-11-29 18:43:09+00:00,"""I Want to Figure Things Out"": Supporting Exploration in Navigation for People with Visual Impairments",cs.HC,['cs.HC'],"[arxiv.Result.Author('Gaurav Jain'), arxiv.Result.Author('Yuanyang Teng'), arxiv.Result.Author('Dong Heon Cho'), arxiv.Result.Author('Yunhao Xing'), arxiv.Result.Author('Maryam Aziz'), arxiv.Result.Author('Brian A. Smith')]","Navigation assistance systems (NASs) aim to help visually impaired people
(VIPs) navigate unfamiliar environments. Most of today's NASs support VIPs via
turn-by-turn navigation, but a growing body of work highlights the importance
of exploration as well. It is unclear, however, how NASs should be designed to
help VIPs explore unfamiliar environments. In this paper, we perform a
qualitative study to understand VIPs' information needs and challenges with
respect to exploring unfamiliar environments, with the aim of informing the
design of NASs that support exploration. Our findings reveal the types of
spatial information that VIPs need as well as factors that affect VIPs'
information preferences. We also discover specific challenges that VIPs face
that future NASs can address such as orientation and mobility education and
collaborating effectively with others. We present design implications for NASs
that support exploration, and we identify specific research opportunities and
discuss open socio-technical challenges for making such NASs possible. We
conclude by reflecting on our study procedure to inform future approaches in
research on ethical considerations that may be adopted while interacting with
the broader VIP community."
14370,"Although the presented framework makes a further step to support and im-
prove working processes of humans in times of Industry 4.0, further research
according to assistance systems has to be done to reach a better degree of ac-
ceptance.","context-aware maintenance application in augmented reality
or warehouse management training in virtual reality.","For reaching this, further improvements in the areas of hardware and
display technology are required so that dynamic 3d objects and information can
be visualized on smart glasses or similar wearables.",2022-11-30 10:47:40+00:00,Self-Adaptive Digital Assistance Systems for Work 4.0,cs.HC,"['cs.HC', 'cs.SE']","[arxiv.Result.Author('Enes Yigitbas'), arxiv.Result.Author('Stefan Sauer'), arxiv.Result.Author('Gregor Engels')]","In the era of digital transformation, new technological foundations and
possibilities for collaboration, production as well as organization open up
many opportunities to work differently in the future. The digitization of
workflows results in new forms of working which is denoted by the term Work
4.0. In the context of Work 4.0, digital assistance systems play an important
role as they give users additional situation-specific information about a
workflow or a product via displays, mobile devices such as tablets and
smartphones, or data glasses. Furthermore, such digital assistance systems can
be used to provide instructions and technical support in the working process as
well as for training purposes. However, existing digital assistance systems are
mostly created focusing on the ""design for all"" paradigm neglecting the
situation-specific tasks, skills, preferences, or environments of an individual
human worker. To overcome this issue, we present a monitoring and adaptation
framework for supporting self-adaptive digital assistance systems for Work 4.0.
Our framework supports context monitoring as well as UI adaptation for
augmented (AR) and virtual reality (VR)-based digital assistance systems. The
benefit of our framework is shown based on exemplary case studies from
different domains, e.g. context-aware maintenance application in AR or
warehouse management training in VR."
14523,"The results of the user study suggest that the risk awareness paradigm has the potential to improve
online discourse and motivate further research in this direction.","Additionally, we used a two-phase study design,
starting with a larger phase in which we sought feedback from the participants after using the fully
functional tool for one month, and continuing with a second phase in which we implemented a
within-participant randomized controlled experiment lasting two months.","In exit surveys, the majority of
participants report that they found ConvoWizard helpful for identifying tense situations, with
the tool both supplementing their intuitions—catching types of tension that they may not have
known to look for—and activating their existing intuitions—reminding them to be on the lookout
for tension in situations where they may not have been paying attention.",2022-12-02 19:00:03+00:00,Thread With Caution: Proactively Helping Users Assess and Deescalate Tension in Their Online Discussions,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Author('Jonathan P. Chang'), arxiv.Result.Author('Charlotte Schluger'), arxiv.Result.Author('Cristian Danescu-Niculescu-Mizil')]","Incivility remains a major challenge for online discussion platforms, to such
an extent that even conversations between well-intentioned users can often
derail into uncivil behavior. Traditionally, platforms have relied on
moderators to -- with or without algorithmic assistance -- take corrective
actions such as removing comments or banning users. In this work we propose a
complementary paradigm that directly empowers users by proactively enhancing
their awareness about existing tension in the conversation they are engaging in
and actively guides them as they are drafting their replies to avoid further
escalation.
  As a proof of concept for this paradigm, we design an algorithmic tool that
provides such proactive information directly to users, and conduct a user study
in a popular discussion platform. Through a mixed methods approach combining
surveys with a randomized controlled experiment, we uncover qualitative and
quantitative insights regarding how the participants utilize and react to this
information. Most participants report finding this proactive paradigm valuable,
noting that it helps them to identify tension that they may have otherwise
missed and prompts them to further reflect on their own replies and to revise
them. These effects are corroborated by a comparison of how the participants
draft their reply when our tool warns them that their conversation is at risk
of derailing into uncivil behavior versus in a control condition where the tool
is disabled. These preliminary findings highlight the potential of this
user-centered paradigm and point to concrete directions for future
implementations."
14610,"329–345, 2020.
further research on this topic is necessary.","1, pp.","Second, due to            [7] H. S. M. Lim and A. Taeihagh, “Algorithmic decision-making
the capacity of people the event could hold, the number of                     in AVs: Understanding ethical and technical concerns for smart
participants in the current study was limited (68, 68 and 65                   cities,” Sustainability, vol.",2022-12-06 12:06:34+00:00,Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL']","[arxiv.Result.Author('Zhaoning Li'), arxiv.Result.Author('Qiaoli Jiang'), arxiv.Result.Author('Zhengming Wu'), arxiv.Result.Author('Anqi Liu'), arxiv.Result.Author('Haiyan Wu'), arxiv.Result.Author('Miner Huang'), arxiv.Result.Author('Kai Huang'), arxiv.Result.Author('Yixuan Ku')]","Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving."
14611,"329–345, 2020.
further research on this topic is necessary.","1, pp.","Second, due to            [7] H. S. M. Lim and A. Taeihagh, “Algorithmic decision-making
the capacity of people the event could hold, the number of                     in AVs: Understanding ethical and technical concerns for smart
participants in the current study was limited (68, 68 and 65                   cities,” Sustainability, vol.",2022-12-06 12:06:34+00:00,Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL']","[arxiv.Result.Author('Zhaoning Li'), arxiv.Result.Author('Qiaoli Jiang'), arxiv.Result.Author('Zhengming Wu'), arxiv.Result.Author('Anqi Liu'), arxiv.Result.Author('Haiyan Wu'), arxiv.Result.Author('Miner Huang'), arxiv.Result.Author('Kai Huang'), arxiv.Result.Author('Yixuan Ku')]","Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving."
14612,"329–345, 2020.
further research on this topic is necessary.","1, pp.","Second, due to            [7] H. S. M. Lim and A. Taeihagh, “Algorithmic decision-making
the capacity of people the event could hold, the number of                     in AVs: Understanding ethical and technical concerns for smart
participants in the current study was limited (68, 68 and 65                   cities,” Sustainability, vol.",2022-12-06 12:06:34+00:00,Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL']","[arxiv.Result.Author('Zhaoning Li'), arxiv.Result.Author('Qiaoli Jiang'), arxiv.Result.Author('Zhengming Wu'), arxiv.Result.Author('Anqi Liu'), arxiv.Result.Author('Haiyan Wu'), arxiv.Result.Author('Miner Huang'), arxiv.Result.Author('Kai Huang'), arxiv.Result.Author('Yixuan Ku')]","Autonomous cars are indispensable when humans go further down the hands-free
route. Although existing literature highlights that the acceptance of the
autonomous car will increase if it drives in a human-like manner, sparse
research offers the naturalistic experience from a passenger's seat perspective
to examine the human likeness of current autonomous cars. The present study
tested whether the AI driver could create a human-like ride experience for
passengers based on 69 participants' feedback in a real-road scenario. We
designed a ride experience-based version of the non-verbal Turing test for
automated driving. Participants rode in autonomous cars (driven by either human
or AI drivers) as a passenger and judged whether the driver was human or AI.
The AI driver failed to pass our test because passengers detected the AI driver
above chance. In contrast, when the human driver drove the car, the passengers'
judgement was around chance. We further investigated how human passengers
ascribe humanness in our test. Based on Lewin's field theory, we advanced a
computational model combining signal detection theory with pre-trained language
models to predict passengers' humanness rating behaviour. We employed affective
transition between pre-study baseline emotions and corresponding post-stage
emotions as the signal strength of our model. Results showed that the
passengers' ascription of humanness would increase with the greater affective
transition. Our study suggested an important role of affective transition in
passengers' ascription of humanness, which might become a future direction for
autonomous driving."
14633,"International Journal of Information
technologies for their inclusion in the early stages of the metaverse,         Management 66 (2022), 102542.
although further research is needed to achieve more immersive
scenarios.","This demonstrator highlights that BCIs are promising            and agenda for research, practice and policy.",[6] Jos J. Eggermont.,2022-12-06 17:44:03+00:00,"When Brain-Computer Interfaces Meet the Metaverse: Landscape, Demonstrator, Trends, Challenges, and Concerns",cs.HC,['cs.HC'],"[arxiv.Result.Author('Sergio López Bernal'), arxiv.Result.Author('Mario Quiles Pérez'), arxiv.Result.Author('Enrique Tomás Martínez Beltrán'), arxiv.Result.Author('Gregorio Martínez Pérez'), arxiv.Result.Author('Alberto Huertas Celdrán')]","The metaverse has gained tremendous popularity in recent years, allowing the
interconnection of users worldwide. However, current systems used in metaverse
scenarios, such as virtual reality glasses, offer a partial immersive
experience. In this context, Brain-Computer Interfaces (BCIs) can introduce a
revolution in the metaverse, although a study of the applicability and
implications of BCIs in these virtual scenarios is required. Based on the
absence of literature, this work studies, for the first time, the applicability
of BCIs in the metaverse, analyzing the current status of this integration
based on different categories related to virtual worlds and the evolution of
BCIs in these scenarios in the medium and long term. This work also presents a
demonstration of what current BCI solutions can provide to the metaverse. It
uses a metaverse consisting in driving a car within a simulation, using VR, a
steering wheel and pedals, and a BCI for neural data acquisition. Four use
cases are selected, focusing on cognitive and emotional assessment of the
driver, detection of drowsiness, and driver authentication while using the
vehicle. Then, it offers an analysis of BCI trends in the metaverse, also
identifying future challenges that the intersection of these technologies will
face. Finally, it reviews the concerns that the use of BCIs in virtual world
applications could generate according to different categories: accessibility,
user inclusion, privacy, cybersecurity, physical safety, and ethics."
14655,"Type 4 also considers chat-      Based on the existing consensus and the diﬀerent per-
bots to facilitate collaboration activities by concentrating on   spectives of the four collaborator types, three recommenda-
immediate responses, delivering user awareness, and demon-        tions for further research on chatbots and new technologies
strating empathy.","apprenticeship, the use of chatbots for intergenerational col-
laboration can be useful for type 4.",Type 4’s top-rank statements are as follows:    to facilitate intergenerational collaboration can be made.,2022-12-07 06:56:39+00:00,Patterns of Sociotechnical Design Preferences of Chatbots for Intergenerational Collaborative Innovation : A Q Methodology Study,cs.HC,"['cs.HC', 'H.5.3']","[arxiv.Result.Author('Irawan Nurhas'), arxiv.Result.Author('Pouyan Jahanbin'), arxiv.Result.Author('Jan Pawlowski'), arxiv.Result.Author('Stephen Wingreen'), arxiv.Result.Author('Stefan Geisler')]","Chatbot technology is increasingly emerging as a virtual assistant. Chatbots
could allow individuals and organizations to accomplish objectives that are
currently not fully optimized for collaboration across an intergenerational
context. This paper explores the preferences of chatbots as a companion in
intergenerational innovation. The Q methodology was used to investigate
different types of collaborators and determine how different choices occur
between collaborators that merge the problem and solution domains of chatbots'
design within intergenerational settings. The study's findings reveal that
various chatbot design priorities are more diverse among younger adults than
senior adults. Additionally, our research further outlines the principles of
chatbot design and how chatbots will support both generations. This research is
the first step towards cultivating a deeper understanding of different age
groups' subjective design preferences for chatbots functioning as a companion
in the workplace. Moreover, this study demonstrates how the Q methodology can
guide technological development by shifting the approach from an age-focused
design to a common goal-oriented design within a multigenerational context."
14704,"https://doi.org/10.1145/1958824.1958836
Baxter K, Courage C, Caine K (2015) Understanding Your Users A Practical Guide to User
       Research Methods
Busalim AH, Hussin ARC, Razak A, Hussin C (2016) Understanding social commerce: A
       systematic literature review and directions for further research.","Proc ACM 2011 Conf Comput Support
       Coop Work (CSCW ’11) 75–84.","Int J Inf Manage 36:1075–
       1088. https://doi.org/10.1016/j.ijinfomgt.2016.06.005
Chen L (2010) Understanding Buyers’ Social Information Needs during Purchase Decision
       Process.",2022-12-08 12:28:33+00:00,Comparing different qualitative methods to understand user experience in Saudi Arabia,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Aisha Ahmed AlArfaj'), arxiv.Result.Author('Ellis Solaiman')]","The HCI field has seen a growing body of qualitative research, making use of
a wide range of activities and methods. Interviews and workshops are some of
the main techniques used to help understand user needs and to conduct co-design
activities with them. However, these methods might be conducted in various ways
and have different advantage and disadvantages. An important aspect influencing
the types of activities and methods used is the culture of research
participants. This paper aims to compare the research methods conducted in the
context of the Saudi Arabian culture. It provides a reflection on the methods
used to understand user needs when designing social commerce platforms,
including interviews, co-design workshops and critique design workshops. We
found that each method has its positives and negatives in terms of user
preferences, and can help to obtain useful information at different levels of
detail. For example, conducting semi-structured interviews by text was
preferred by participants who are at home with their families. However, they
can be slower than other methods."
14720,"For further research and projects,                                 V. METHODOLOGY
it is essential to know in advance that Unity 2020 does not
support targeting HoloLens (1st gen) anymore [14].","Only guidelines given in Microsoft’s ofﬁcial
documentation were used.","The HMD            To obtain two objective performance parameters, the time
                                                                   and score of the user per assignment for each interaction
                                                                   method is measured.",2022-12-08 16:06:33+00:00,Haptic Interactions for Extended Reality,cs.HC,"['cs.HC', 'cs.MM']","[arxiv.Result.Author('Yentl Vermeulen'), arxiv.Result.Author('Sam Van Damme'), arxiv.Result.Author('Glenn Van Wallendael'), arxiv.Result.Author('Filip De Turck'), arxiv.Result.Author('Maria Torres Vega')]","This research investigates whether the interaction methods of XR headsets can
be improved by using haptic feedback. As a first and most common technique,
indirect interactions are considered. Indirect interactions correspond to
manipulations of virtual objects from a virtual distance using pre-defined hand
gestures. As a second interaction technique, direct interaction (namely DIM)
has been implemented where the user manipulates objects by virtually touching
these with their hands. A third interaction method extends the previous one
with haptic feedback (namely HEDIM). These 3 methods are compared with each
other based on objective and subjective user tests, also taking into account
financial considerations. This research concludes that the DIM improves upon
the standard indirect method. Additionally, it has been observed that haptic
feedback could enhance the DIM in specific situations. Nevertheless, when
considering the current financial cost, our subjects were not convinced of the
small improvements haptic feedback brings."
14780,"In addition, there appear to be use cases that need further research before
implementation to verify whether their purportedly positive aspects are not in fact harmful in the long
term [28,29].","However, while positive use cases exist, there clearly are
harmful applications, such as the manipulation of specific visual segments of surveillance camera
footage in real-time [8].","Perhaps most disturbing is the fact that deepfakes enable extensions of existing criminal threats
(“cyber-enabled” crimes), and new vectors of crime (“cyber-dependent” crimes) [30,31].",2022-12-07 14:48:25+00:00,Testing Human Ability To Detect Deepfake Images of Human Faces,cs.HC,"['cs.HC', 'cs.CR', 'cs.CV', 'cs.CY']","[arxiv.Result.Author('Sergi D. Bray'), arxiv.Result.Author('Shane D. Johnson'), arxiv.Result.Author('Bennett Kleinberg')]","Deepfakes are computationally-created entities that falsely represent
reality. They can take image, video, and audio modalities, and pose a threat to
many areas of systems and societies, comprising a topic of interest to various
aspects of cybersecurity and cybersafety. In 2020 a workshop consulting AI
experts from academia, policing, government, the private sector, and state
security agencies ranked deepfakes as the most serious AI threat. These experts
noted that since fake material can propagate through many uncontrolled routes,
changes in citizen behaviour may be the only effective defence. This study aims
to assess human ability to identify image deepfakes of human faces
(StyleGAN2:FFHQ) from nondeepfake images (FFHQ), and to assess the
effectiveness of simple interventions intended to improve detection accuracy.
Using an online survey, 280 participants were randomly allocated to one of four
groups: a control group, and 3 assistance interventions. Each participant was
shown a sequence of 20 images randomly selected from a pool of 50 deepfake and
50 real images of human faces. Participants were asked if each image was
AI-generated or not, to report their confidence, and to describe the reasoning
behind each response. Overall detection accuracy was only just above chance and
none of the interventions significantly improved this. Participants' confidence
in their answers was high and unrelated to accuracy. Assessing the results on a
per-image basis reveals participants consistently found certain images harder
to label correctly, but reported similarly high confidence regardless of the
image. Thus, although participant accuracy was 62% overall, this accuracy
across images ranged quite evenly between 85% and 30%, with an accuracy of
below 50% for one in every five images. We interpret the findings as suggesting
that there is a need for an urgent call to action to address this threat."
14781,"In addition, there appear to be use cases that need further research before
implementation to verify whether their purportedly positive aspects are not in fact harmful in the long
term [28,29].","However, while positive use cases exist, there clearly are
harmful applications, such as the manipulation of specific visual segments of surveillance camera
footage in real-time [8].","Perhaps most disturbing is the fact that deepfakes enable extensions of existing criminal threats
(“cyber-enabled” crimes), and new vectors of crime (“cyber-dependent” crimes) [30,31].",2022-12-07 14:48:25+00:00,Testing Human Ability To Detect Deepfake Images of Human Faces,cs.HC,"['cs.HC', 'cs.CR', 'cs.CV', 'cs.CY']","[arxiv.Result.Author('Sergi D. Bray'), arxiv.Result.Author('Shane D. Johnson'), arxiv.Result.Author('Bennett Kleinberg')]","Deepfakes are computationally-created entities that falsely represent
reality. They can take image, video, and audio modalities, and pose a threat to
many areas of systems and societies, comprising a topic of interest to various
aspects of cybersecurity and cybersafety. In 2020 a workshop consulting AI
experts from academia, policing, government, the private sector, and state
security agencies ranked deepfakes as the most serious AI threat. These experts
noted that since fake material can propagate through many uncontrolled routes,
changes in citizen behaviour may be the only effective defence. This study aims
to assess human ability to identify image deepfakes of human faces
(StyleGAN2:FFHQ) from nondeepfake images (FFHQ), and to assess the
effectiveness of simple interventions intended to improve detection accuracy.
Using an online survey, 280 participants were randomly allocated to one of four
groups: a control group, and 3 assistance interventions. Each participant was
shown a sequence of 20 images randomly selected from a pool of 50 deepfake and
50 real images of human faces. Participants were asked if each image was
AI-generated or not, to report their confidence, and to describe the reasoning
behind each response. Overall detection accuracy was only just above chance and
none of the interventions significantly improved this. Participants' confidence
in their answers was high and unrelated to accuracy. Assessing the results on a
per-image basis reveals participants consistently found certain images harder
to label correctly, but reported similarly high confidence regardless of the
image. Thus, although participant accuracy was 62% overall, this accuracy
across images ranged quite evenly between 85% and 30%, with an accuracy of
below 50% for one in every five images. We interpret the findings as suggesting
that there is a need for an urgent call to action to address this threat."
14848,"Provide an expectation on the future trends and challenges of HDT, to
   promote further research.","Springer Nature 2021 LATEX template

                                                                              Article Title 3

3.","The overall structure of the paper takes the form of seven sections, includ-
ing this Introductory Section.",2022-12-12 14:46:07+00:00,Human Digital Twin: A Survey,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yujia Lin'), arxiv.Result.Author('Liming Chen'), arxiv.Result.Author('Aftab Ali'), arxiv.Result.Author('Christopher Nugent'), arxiv.Result.Author('Cleland Ian'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Dazhi Gao'), arxiv.Result.Author('Hang Wang'), arxiv.Result.Author('Yajie Wang'), arxiv.Result.Author('Huansheng Ning')]","Digital twin has recently attracted growing attention, leading to intensive
research and applications. Along with this, a new research area, dubbed as
""human digital twin"" (HDT), has emerged. Similar to the conception of digital
twin, HDT is referred to as the replica of a physical-world human in the
digital world. Nevertheless, HDT is much more complicated and delicate compared
to digital twins of any physical systems and processes, due to humans' dynamic
and evolutionary nature, including physical, behavioral, social, physiological,
psychological, cognitive, and biological dimensions. Studies on HDT are
limited, and the research is still in its infancy. In this paper, we first
examine the inception, development, and application of the digital twin
concept, providing a context within which we formally define and characterize
HDT based on the similarities and differences between digital twin and HDT.
Then we conduct an extensive literature review on HDT research, analyzing
underpinning technologies and establishing typical frameworks in which the core
HDT functions or components are organized. Built upon the findings from the
above work, we propose a generic architecture for the HDT system and describe
the core function blocks and corresponding technologies. Following this, we
present the state of the art of HDT technologies and applications in the
healthcare, industry, and daily life domain. Finally, we discuss various issues
related to the development of HDT and point out the trends and challenges of
future HDT research and development."
14849,"Designing a generic
model is intriguing and valuable to be usefully explored in further research.","A limitation of this study is that we only present the state-of-the-art in
HDT technologies and applications and discuss open issues; we do not, how-
ever, propose a practical approach for generic HDT modelling technologies
that would enable us to build HDT models that are appropriate for anyone
regardless of location, age, gender, or other characteristics.","Despite its limitations, the study certainly adds to our understanding of the
HDT concept, state of the art technologies, applications and challenges.",2022-12-12 14:46:07+00:00,Human Digital Twin: A Survey,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yujia Lin'), arxiv.Result.Author('Liming Chen'), arxiv.Result.Author('Aftab Ali'), arxiv.Result.Author('Christopher Nugent'), arxiv.Result.Author('Cleland Ian'), arxiv.Result.Author('Rongyang Li'), arxiv.Result.Author('Dazhi Gao'), arxiv.Result.Author('Hang Wang'), arxiv.Result.Author('Yajie Wang'), arxiv.Result.Author('Huansheng Ning')]","Digital twin has recently attracted growing attention, leading to intensive
research and applications. Along with this, a new research area, dubbed as
""human digital twin"" (HDT), has emerged. Similar to the conception of digital
twin, HDT is referred to as the replica of a physical-world human in the
digital world. Nevertheless, HDT is much more complicated and delicate compared
to digital twins of any physical systems and processes, due to humans' dynamic
and evolutionary nature, including physical, behavioral, social, physiological,
psychological, cognitive, and biological dimensions. Studies on HDT are
limited, and the research is still in its infancy. In this paper, we first
examine the inception, development, and application of the digital twin
concept, providing a context within which we formally define and characterize
HDT based on the similarities and differences between digital twin and HDT.
Then we conduct an extensive literature review on HDT research, analyzing
underpinning technologies and establishing typical frameworks in which the core
HDT functions or components are organized. Built upon the findings from the
above work, we propose a generic architecture for the HDT system and describe
the core function blocks and corresponding technologies. Following this, we
present the state of the art of HDT technologies and applications in the
healthcare, industry, and daily life domain. Finally, we discuss various issues
related to the development of HDT and point out the trends and challenges of
future HDT research and development."
14884,"The ﬁndings in this paper point to a need for further research into the d/Deaf and Hard of Hearing
community’s organizational eﬀorts and infrastructuring practices on TikTok to enforce bottom-up development of
community norms for support, as well as a need to further examine the creative processes and everyday routines
around creativity, as well as concerns around access and ease of use, that neurodivergent people have on visual-media
sharing applications like TikTok.","The infrastructuring practices described in this paper around access and ease of use described
in this paper are beneﬁcial to neurodiverse people, a community whose everyday, routine encounters with technology
in creative contexts around visual media is understudied or largely presented in ways that frame such divergences
as a deﬁcit[81].","22
""Hey, Can You Add Captions?",2022-12-12 19:27:20+00:00,"""Hey, Can You Add Captions?"": The Critical Infrastructuring Practices of Neurodiverse People on TikTok",cs.HC,['cs.HC'],"[arxiv.Result.Author('Ellen Simpson'), arxiv.Result.Author('Samantha Dalal'), arxiv.Result.Author('Bryan Semaan')]","Accessibility efforts, how we can make the world usable and useful to as many
people as possible, have explicitly focused on how we can support and allow for
the autonomy and independence of people with disabilities, neurotypes, chronic
conditions, and older adults. Despite these efforts, not all technology is
designed or implemented to support everyone's needs. Recently, a
community-organized push by creators and general users of TikTok urged the
platform to add accessibility features, such as closed captioning to
user-generated content, allowing more people to use the platform with greater
ease. Our work focuses on an understudied population -- people with ADHD and
those who experience similar challenges -- exploring the creative practices
people from this community engage in, focusing on the kinds of accessibility
they create through their creative work. Through an interview study exploring
the experiences of creatives on TikTok, we find that creatives engage in
critical infrastructuring -- a process of bottom-up (re)design -- to make the
platform more accessible despite the challenges the platform presents to them
as creators. We present these critical infrastructuring practices through the
themes of: creating and augmenting video editing infrastructures and creating
and augmenting video captioning infrastructures. We reflect on the introduction
of a top-down infrastructure - the implementation of an auto-captioning feature
- shifts the critical infrastructure practices of content creators. Through
their infrastructuring, creatives revised sociotechnical capabilities of TikTok
to support their own needs as well as the broader needs of the TikTok
community. We discuss how the routine of infrastructuring accessibility is
actually best conceptualized as incidental care work. We further highlight how
accessibility is an evolving sociotechnical construct, and forward the concept
of contextual accessibility."
14924,"We encourage further research
the death of citizens of Georgia.","One reason for this could be that there is no incentive to write
A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist

and publish an article that explains why the U.S. does not pay for        have users from all over the world.","This could, however, imply that         on why source labels did not lead to better article ratings in the U.S.
the recommendation to consult trusted fact-checking organizations         even though they were perceived as helpful.",2022-12-13 16:09:19+00:00,A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Hendrik Heuer'), arxiv.Result.Author('Elena Leah Glassman')]","During the COVID-19 pandemic, the World Health Organization provided a
checklist to help people distinguish between accurate and misinformation. In
controlled experiments in the United States and Germany, we investigated the
utility of this ordered checklist and designed an interactive version to lower
the cost of acting on checklist items. Across interventions, we observe
non-trivial differences in participants' performance in distinguishing accurate
and misinformation between the two countries and discuss some possible reasons
that may predict the future helpfulness of the checklist in different
environments. The checklist item that provides source labels was most
frequently followed and was considered most helpful. Based on our empirical
findings, we recommend practitioners focus on providing source labels rather
than interventions that support readers performing their own fact-checks, even
though this recommendation may be influenced by the WHO's chosen order. We
discuss the complexity of providing such source labels and provide design
recommendations."
14925,"Third, the source labels can be easily     der effects, we invite further research that examines the impact of
integrated into existing user interfaces, both by those who operate       source labels in more detail.","Considering the possible influence of or-
like turning to fact-checkers.",a platform as well as by providers of third-party browser extensions.,2022-12-13 16:09:19+00:00,A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Hendrik Heuer'), arxiv.Result.Author('Elena Leah Glassman')]","During the COVID-19 pandemic, the World Health Organization provided a
checklist to help people distinguish between accurate and misinformation. In
controlled experiments in the United States and Germany, we investigated the
utility of this ordered checklist and designed an interactive version to lower
the cost of acting on checklist items. Across interventions, we observe
non-trivial differences in participants' performance in distinguishing accurate
and misinformation between the two countries and discuss some possible reasons
that may predict the future helpfulness of the checklist in different
environments. The checklist item that provides source labels was most
frequently followed and was considered most helpful. Based on our empirical
findings, we recommend practitioners focus on providing source labels rather
than interventions that support readers performing their own fact-checks, even
though this recommendation may be influenced by the WHO's chosen order. We
discuss the complexity of providing such source labels and provide design
recommendations."
14926,"We invite further research to examine why the rat-
the reliance on biased sources in the United States, could be an       ings of young adults deviated from the other groups so strongly in
increasing commodification of truth.","Another possible interpretation, especially considering      elderly people.","People may not seek an inter-     our investigation in the United States, especially since we did not
subjective agreement [34] on facts, but rather see information like    observe a similar trend in Germany.",2022-12-13 16:09:19+00:00,A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Hendrik Heuer'), arxiv.Result.Author('Elena Leah Glassman')]","During the COVID-19 pandemic, the World Health Organization provided a
checklist to help people distinguish between accurate and misinformation. In
controlled experiments in the United States and Germany, we investigated the
utility of this ordered checklist and designed an interactive version to lower
the cost of acting on checklist items. Across interventions, we observe
non-trivial differences in participants' performance in distinguishing accurate
and misinformation between the two countries and discuss some possible reasons
that may predict the future helpfulness of the checklist in different
environments. The checklist item that provides source labels was most
frequently followed and was considered most helpful. Based on our empirical
findings, we recommend practitioners focus on providing source labels rather
than interventions that support readers performing their own fact-checks, even
though this recommendation may be influenced by the WHO's chosen order. We
discuss the complexity of providing such source labels and provide design
recommendations."
14927,"We, therefore, encourage further research to study the order
bility of a source can also be explained without the user directly       effects of checklists against misinformation.",The relia-      nents.,"Our results indicate
engaging with the misinformation, which limits the risk of backfire      that the WHO successfully prioritized the different components in
effects [102].",2022-12-13 16:09:19+00:00,A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Hendrik Heuer'), arxiv.Result.Author('Elena Leah Glassman')]","During the COVID-19 pandemic, the World Health Organization provided a
checklist to help people distinguish between accurate and misinformation. In
controlled experiments in the United States and Germany, we investigated the
utility of this ordered checklist and designed an interactive version to lower
the cost of acting on checklist items. Across interventions, we observe
non-trivial differences in participants' performance in distinguishing accurate
and misinformation between the two countries and discuss some possible reasons
that may predict the future helpfulness of the checklist in different
environments. The checklist item that provides source labels was most
frequently followed and was considered most helpful. Based on our empirical
findings, we recommend practitioners focus on providing source labels rather
than interventions that support readers performing their own fact-checks, even
though this recommendation may be influenced by the WHO's chosen order. We
discuss the complexity of providing such source labels and provide design
recommendations."
14928,"ing the limitations that we identified for fact-checks, even though
                                                                         further research is needed on the effect of the order in which com-
   We relied on Lucid, a professional market research company, to        ponents are presented in checklists against misinformation.","And while they may not have had to ex-          source labels are perceived favorably by users, they are a promising
plicitly rate the reliability of news articles before, they have to      direction in the fight against misinformation, especially consider-
implicitly do this many times every day.","We
recruit a gender-balanced sample that is diverse in regards to the po-   hope that the insights presented in this paper motivate social media
litical opinions, education, and age of users.",2022-12-13 16:09:19+00:00,A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Hendrik Heuer'), arxiv.Result.Author('Elena Leah Glassman')]","During the COVID-19 pandemic, the World Health Organization provided a
checklist to help people distinguish between accurate and misinformation. In
controlled experiments in the United States and Germany, we investigated the
utility of this ordered checklist and designed an interactive version to lower
the cost of acting on checklist items. Across interventions, we observe
non-trivial differences in participants' performance in distinguishing accurate
and misinformation between the two countries and discuss some possible reasons
that may predict the future helpfulness of the checklist in different
environments. The checklist item that provides source labels was most
frequently followed and was considered most helpful. Based on our empirical
findings, we recommend practitioners focus on providing source labels rather
than interventions that support readers performing their own fact-checks, even
though this recommendation may be influenced by the WHO's chosen order. We
discuss the complexity of providing such source labels and provide design
recommendations."
15045,"of SemanCom to low-cost IoT devices is worthy of
      further study.","Meanwhile, the applicability     opportunities are envisioned as well.","Hence, it is of signiﬁcant importance by         Through exchanging the most informative, timely, and effec-
      developing lightweight algorithms and improving the          tive information, SemanCom is capable of improving resource
      hardware design.",2022-12-16 14:00:37+00:00,Semantics-Empowered Communication: A Tutorial-cum-Survey,cs.HC,"['cs.HC', 'cs.AI', 'cs.NI', 'eess.SP']","[arxiv.Result.Author('Zhilin Lu'), arxiv.Result.Author('Rongpeng Li'), arxiv.Result.Author('Kun Lu'), arxiv.Result.Author('Xianfu Chen'), arxiv.Result.Author('Ekram Hossain'), arxiv.Result.Author('Zhifeng Zhao'), arxiv.Result.Author('Honggang Zhang')]","Along with the springing up of semantics-empowered communication research
spanning from theories, applications, metrics to implementation, it is now
witnessing an unprecedented growing interest in both academia and industry. In
this work, we primarily aim to provide a comprehensive survey on both the
background and research taxonomy, as well as a detailed technical tutorial for
potential participants. Specifically, we start by reviewing the literature and
answering the ""what"" and ""why"" questions in semantic transmissions. Afterwards,
we present corresponding ecosystems, including theories, metrics, datasets and
toolkits, on top of which the taxonomy for macro research directions is
presented. Furthermore, we propose to categorize the critical enabling
techniques by explicit and implicit reasoning-based methods, and elaborate on
how they evolve and contribute to modern content & channel semantics-empowered
communications. Besides reviewing and summarizing the latest efforts in
semantics-empowered communications, we discuss the relations with other
communication levels (e.g., reliable and goal-oriented communications) from a
holistic and unified viewpoint. Subsequently, in order to facilitate the future
developments and industrial applications, we also highlight advanced practical
techniques for boosting semantic accuracy, robustness, and large-scale
scalability, just to mention a few. Finally, we discuss the technical
challenges that shed light on future research opportunities. Considering the
growing yet the ever-updating status of semantics-empowered communications, we
hope this work would benefit not only sophisticated but also intended
practitioners."
15046,"Belonging to the last               • (Future) What are the major technical and business
category, this paper focuses on the summary and tutorials for            challenges in the current SemCom system, and what is
facilitating further research.",towards enabling a SemCom system.,beyond the prototype of end-to-end SemCom?,2022-12-16 14:00:37+00:00,Semantics-Empowered Communication: A Tutorial-cum-Survey,cs.HC,"['cs.HC', 'cs.AI', 'cs.NI', 'eess.SP']","[arxiv.Result.Author('Zhilin Lu'), arxiv.Result.Author('Rongpeng Li'), arxiv.Result.Author('Kun Lu'), arxiv.Result.Author('Xianfu Chen'), arxiv.Result.Author('Ekram Hossain'), arxiv.Result.Author('Zhifeng Zhao'), arxiv.Result.Author('Honggang Zhang')]","Along with the springing up of semantics-empowered communication (SemCom)
researches, it is now witnessing an unprecedentedly growing interest towards a
wide range of aspects (e.g., theories, applications, metrics and
implementations) in both academia and industry. In this work, we primarily aim
to provide a comprehensive survey on both the background and research taxonomy,
as well as a detailed technical tutorial. Specifically, we start by reviewing
the literature and answering the ""what"" and ""why"" questions in semantic
transmissions. Afterwards, we present corresponding ecosystems, including
theories, metrics, datasets and toolkits, on top of which the taxonomy for
research directions is presented. Furthermore, we propose to categorize the
critical enabling techniques by explicit and implicit reasoning-based methods,
and elaborate on how they evolve and contribute to modern content \& channel
semantics-empowered communications. Besides reviewing and summarizing the
latest efforts in SemCom, we discuss the relations with other communication
levels (e.g., reliable and goal-oriented communications) from a holistic and
unified viewpoint. Subsequently, in order to facilitate the future developments
and industrial applications, we also highlight advanced practical techniques
for boosting semantic accuracy, robustness, and large-scale scalability, just
to mention a few. Finally, we discuss the technical challenges that shed light
on future research opportunities."
15047,"Meanwhile, the applicability of SemCom to low-
UAV system can be regarded as an implementation of DRL-                  cost IoT devices is worthy of further study.","In other words, a ﬂying              process.","Hence, it
based EL-SemCom.",2022-12-16 14:00:37+00:00,Semantics-Empowered Communication: A Tutorial-cum-Survey,cs.HC,"['cs.HC', 'cs.AI', 'cs.NI', 'eess.SP']","[arxiv.Result.Author('Zhilin Lu'), arxiv.Result.Author('Rongpeng Li'), arxiv.Result.Author('Kun Lu'), arxiv.Result.Author('Xianfu Chen'), arxiv.Result.Author('Ekram Hossain'), arxiv.Result.Author('Zhifeng Zhao'), arxiv.Result.Author('Honggang Zhang')]","Along with the springing up of semantics-empowered communication (SemCom)
researches, it is now witnessing an unprecedentedly growing interest towards a
wide range of aspects (e.g., theories, applications, metrics and
implementations) in both academia and industry. In this work, we primarily aim
to provide a comprehensive survey on both the background and research taxonomy,
as well as a detailed technical tutorial. Specifically, we start by reviewing
the literature and answering the ""what"" and ""why"" questions in semantic
transmissions. Afterwards, we present corresponding ecosystems, including
theories, metrics, datasets and toolkits, on top of which the taxonomy for
research directions is presented. Furthermore, we propose to categorize the
critical enabling techniques by explicit and implicit reasoning-based methods,
and elaborate on how they evolve and contribute to modern content \& channel
semantics-empowered communications. Besides reviewing and summarizing the
latest efforts in SemCom, we discuss the relations with other communication
levels (e.g., reliable and goal-oriented communications) from a holistic and
unified viewpoint. Subsequently, in order to facilitate the future developments
and industrial applications, we also highlight advanced practical techniques
for boosting semantic accuracy, robustness, and large-scale scalability, just
to mention a few. Finally, we discuss the technical challenges that shed light
on future research opportunities."
15156,"However, further research is needed
a much shorter time period available to view it as well as a shorter                    in terms of accurate risk communication and perception.",People that accidentally come across such a story might have                     them to minimize their risk factors.,"Additional
attention span.",2022-12-20 09:39:57+00:00,Narrative Visualization to Communicate Neurological Diseases,cs.HC,"['cs.HC', 'cs.CY']","[arxiv.Result.Author('Sarah Mittenentzwei'), arxiv.Result.Author('Veronika Weiß'), arxiv.Result.Author('Stefanie Schreiber'), arxiv.Result.Author('Laura A. Garrison'), arxiv.Result.Author('Stefan Bruckner'), arxiv.Result.Author('Malte Pfister'), arxiv.Result.Author('Bernhard Preim'), arxiv.Result.Author('Monique Meuschke')]","While narrative visualization has been used successfully in various
applications to communicate scientific data in the format of a story to a
general audience, the same has not been true for medical data. There are only a
few exceptions that present tabular medical data to non-experts. However, a key
component of medical visualization is the interactive analysis of 3D data, such
as 3D models of anatomical structures, which were rarely included in narrative
visualizations so far. In this design study, we investigate how neurological
disease data can be communicated through narrative visualization techniques to
a general audience in an understandable way. We designed a narrative
visualization explaining cerebral small vessel disease. Learning about its
avoidable risk factors serves to motivate the audience watching the resulting
visual data story. Using this example, we discuss the adaption of basic
narrative components. This includes the conflict and characters of a story, as
well as the story's structure and content to address and communicate specific
characteristics of medical data. Furthermore, we explore the extent to which
complex medical relationships need to be simplified to be understandable to a
general audience without distorting the underlying data and evidence. In
particular, the data needs to be preprocessed for non-experts and appropriate
forms of interaction must be found. We explore approaches to make the data more
personally relatable, such as including a fictional patient. We evaluated our
approach in a user study with 40 participants in a web-based implementation of
the designed story. We found that the combination of a carefully thought-out
storyline with a clear key message, appealing visualizations combined with
easy-to-use interactions, and credible references are crucial for creating a
narrative visualization about a neurological disease that engages an audience."
15283,"The
different user behaviors and power dynamics between occupants of a smart ofﬁce building motivates further research into user
perceptions of privacy within these buildings.","Potential consequences can
                                        be explained through the concern that people in positions of authority can use the data against their subordinates23,24.","With the complex nature of privacy, many studies are conducted to deﬁne privacy norms despite no central deﬁnition of
privacy16,22.",2022-12-22 15:05:17+00:00,"Occupant Privacy Perception, Awareness, and Preferences in Smart Office Environments",cs.HC,['cs.HC'],"[arxiv.Result.Author('Beatrice Li'), arxiv.Result.Author('Arash Tavakoli'), arxiv.Result.Author('Arsalan Heydarian')]","Building management systems tout numerous benefits, such as energy efficiency
and occupant comfort but rely on vast amounts of data from various sensors.
Advancements in machine learning algorithms make it possible to extract
personal information about occupants and their activities beyond the intended
design of a non-intrusive sensor. However, occupants are not informed of data
collection and possess different privacy preferences and thresholds for privacy
loss. While privacy perceptions and preferences are most understood in smart
homes, limited studies have evaluated these factors in smart office buildings,
where there are more users and different privacy risks. To better understand
occupants' perceptions and privacy preferences, we conducted twenty-four
semi-structured interviews between April 2022 and May 2022 on occupants of a
smart office building. We found that data modality features and personal
features contribute to people's privacy preferences. The features of the
collected modality define data modality features -- spatial, security, and
temporal context. In contrast, personal features consist of one's awareness of
data modality features and data inferences, definitions of privacy and
security, and the available rewards and utility. Our proposed model of people's
privacy preferences in smart office buildings helps design more effective
measures to improve people's privacy."
15284,"Since there were signiﬁcant gaps between the perceptions and reality of smart
building privacy found in this participant pool, it warrants further research into people who may not necessarily work in
a smart building.","A limitation of our study was that the participants were highly educated with a speciﬁc background in cyber-physical
systems, including smart cities and buildings.","Other studies37,38 have found that individual differences, such as demographics and cultural differences,
can contribute to different privacy concerns and preferences.",2022-12-22 15:05:17+00:00,"Occupant Privacy Perception, Awareness, and Preferences in Smart Office Environments",cs.HC,['cs.HC'],"[arxiv.Result.Author('Beatrice Li'), arxiv.Result.Author('Arash Tavakoli'), arxiv.Result.Author('Arsalan Heydarian')]","Building management systems tout numerous benefits, such as energy efficiency
and occupant comfort but rely on vast amounts of data from various sensors.
Advancements in machine learning algorithms make it possible to extract
personal information about occupants and their activities beyond the intended
design of a non-intrusive sensor. However, occupants are not informed of data
collection and possess different privacy preferences and thresholds for privacy
loss. While privacy perceptions and preferences are most understood in smart
homes, limited studies have evaluated these factors in smart office buildings,
where there are more users and different privacy risks. To better understand
occupants' perceptions and privacy preferences, we conducted twenty-four
semi-structured interviews between April 2022 and May 2022 on occupants of a
smart office building. We found that data modality features and personal
features contribute to people's privacy preferences. The features of the
collected modality define data modality features -- spatial, security, and
temporal context. In contrast, personal features consist of one's awareness of
data modality features and data inferences, definitions of privacy and
security, and the available rewards and utility. Our proposed model of people's
privacy preferences in smart office buildings helps design more effective
measures to improve people's privacy."
15363,"Another reason could be that when the               further research is needed to determine how music vibration
target is directly behind the participant (Fig.","These are only speculations, and
to the other side.","4(a)), the left-right  affects auditory listening in the context of music listening.",2022-12-26 11:02:22+00:00,Navigation Method Enhancing Music Listening Experience by Stimulating Both Neck Sides with Modulated Music Vibration,cs.HC,['cs.HC'],"[arxiv.Result.Author('Yusuke Yamazaki'), arxiv.Result.Author('Shoichi Hasegawa')]","We propose a method that stimulates music vibration (generated from and
synchronized with musical signals), modulated by the direction and distance to
the target, on both sides of a user's neck with Hapbeat, a necklace-type haptic
device. We conducted three experiments to confirm that the proposed method can
achieve both haptic navigation and enhance the music listening experience.
Experiment 1 consisted of conducting a questionnaire survey to examine the
effect of stimulating music vibrations. Experiment 2 evaluated the accuracy
(deg) of users' ability to adjust their direction toward a target using the
proposed method. Experiment 3 examined the ability of four different navigation
methods by performing navigation tasks in a virtual environment. The results of
the experiments showed that stimulating music vibration enhanced the music
listening experience, and that the proposed method is able to provide
sufficient information to guide the users: accuracy in identifying directions
was about 20\textdegree, participants reached the target in all navigation
tasks, and in about 80\% of all trials participants reached the target using
the shortest route. Furthermore, the proposed method succeeded in conveying
distance information, and Hapbeat can be combined with conventional navigation
methods without interfering with music listening."
