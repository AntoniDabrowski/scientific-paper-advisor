,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract
1415,"In the          We hope this work will encourage further research in the
                                                                 direction of regime detection in ﬁnancial markets and the
case of a buy execution parent order, we aim to minimize         study of regime-awareness impact on policies to achieve ﬁ-
                                                                 nancial tasks.",the executed quantity of order oi and Pi its price.,this quantity.,2022-02-02 10:27:12+00:00,CTMSTOU driven markets: simulated environment for regime-awareness in trading policies,cs.MA,"['cs.MA', 'cs.AI', 'econ.GN', 'q-fin.EC', 'q-fin.MF']","[arxiv.Result.Author('Selim Amrouni'), arxiv.Result.Author('Aymeric Moulin'), arxiv.Result.Author('Tucker Balch')]","Market regimes is a popular topic in quantitative finance even though there
is little consensus on the details of how they should be defined. They arise as
a feature both in financial market prediction problems and financial market
task performing problems.
  In this work we use discrete event time multi-agent market simulation to
freely experiment in a reproducible and understandable environment where
regimes can be explicitly switched and enforced.
  We introduce a novel stochastic process to model the fundamental value
perceived by market participants: Continuous-Time Markov Switching Trending
Ornstein-Uhlenbeck (CTMSTOU), which facilitates the study of trading policies
in regime switching markets.
  We define the notion of regime-awareness for a trading agent as well and
illustrate its importance through the study of different order placement
strategies in the context of order execution problems."
1416,"In the          We hope this work will encourage further research in the
                                                                 direction of regime detection in ﬁnancial markets and the
case of a buy execution parent order, we aim to minimize         study of regime-awareness impact on policies to achieve ﬁ-
                                                                 nancial tasks.",the executed quantity of order oi and Pi its price.,this quantity.,2022-02-02 10:27:12+00:00,CTMSTOU driven markets: simulated environment for regime-awareness in trading policies,cs.MA,"['cs.MA', 'cs.AI', 'econ.GN', 'q-fin.EC', 'q-fin.MF']","[arxiv.Result.Author('Selim Amrouni'), arxiv.Result.Author('Aymeric Moulin'), arxiv.Result.Author('Tucker Balch')]","Market regimes is a popular topic in quantitative finance even though there
is little consensus on the details of how they should be defined. They arise as
a feature both in financial market prediction problems and financial market
task performing problems.
  In this work we use discrete event time multi-agent market simulation to
freely experiment in a reproducible and understandable environment where
regimes can be explicitly switched and enforced.
  We introduce a novel stochastic process to model the fundamental value
perceived by market participants: Continuous-Time Markov Switching Trending
Ornstein-Uhlenbeck (CTMSTOU), which facilitates the study of trading policies
in regime switching markets.
  We define the notion of regime-awareness for a trading agent as well and
illustrate its importance through the study of different order placement
strategies in the context of order execution problems."
1493,"Prior work considered bounded ratio-
nality assumptions but found it to be analytically difﬁcult (Mirrlees, 1976) and further research in
this direction is sparse.","Real-world PA experiments have shown that bounded
rationality is key to explaining marked deviations between equilibria reached by human participants
and theoretical predictions (Erlei & Schenk-Mathes, 2017).","We show that RIRL allows us to analyze generalized PA problems that are
analytically intractable, such as a sequential PA problem with multiple Agents and heterogeneous in-
formation channels.",2022-01-18 20:54:00+00:00,Modeling Bounded Rationality in Multi-Agent Simulations Using Rationally Inattentive Reinforcement Learning,cs.MA,"['cs.MA', 'cs.AI']","[arxiv.Result.Author('Tong Mu'), arxiv.Result.Author('Stephan Zheng'), arxiv.Result.Author('Alexander Trott')]","Multi-agent reinforcement learning (MARL) is a powerful framework for
studying emergent behavior in complex agent-based simulations. However, RL
agents are often assumed to be rational and behave optimally, which does not
fully reflect human behavior. Here, we study more human-like RL agents which
incorporate an established model of human-irrationality, the Rational
Inattention (RI) model. RI models the cost of cognitive information processing
using mutual information. Our RIRL framework generalizes and is more flexible
than prior work by allowing for multi-timestep dynamics and information
channels with heterogeneous processing costs. We evaluate RIRL in
Principal-Agent (specifically manager-employee relations) problem settings of
varying complexity where RI models information asymmetry (e.g. it may be costly
for the manager to observe certain information about the employees). We show
that using RIRL yields a rich spectrum of new equilibrium behaviors that differ
from those found under rational assumptions. For instance, some forms of a
Principal's inattention can increase Agent welfare due to increased
compensation, while other forms of inattention can decrease Agent welfare by
encouraging extra work effort. Additionally, new strategies emerge compared to
those under rationality assumptions, e.g., Agents are incentivized to increase
work effort. These results suggest RIRL is a powerful tool towards building AI
agents that can mimic real human behavior."
2274,"We seek to address this lim-
                                        agents without prior coordination (an intricate concept which    itation and help foster further research in AHT.","However, to date there is no
                                        veloping agents capable of cooperating on the ﬂy with other      comprehensive survey on AHT.",we elaborate on in section 3).,2022-02-16 18:16:27+00:00,"A Survey of Ad Hoc Teamwork: Definitions, Methods, and Open Problems",cs.MA,"['cs.MA', 'cs.AI']","[arxiv.Result.Author('Reuth Mirsky'), arxiv.Result.Author('Ignacio Carlucho'), arxiv.Result.Author('Arrasy Rahman'), arxiv.Result.Author('Elliot Fosong'), arxiv.Result.Author('William Macke'), arxiv.Result.Author('Mohan Sridharan'), arxiv.Result.Author('Peter Stone'), arxiv.Result.Author('Stefano V. Albrecht')]","Ad hoc teamwork is the well-established research problem of designing agents
that can collaborate with new teammates without prior coordination. This survey
makes a two-fold contribution. First, it provides a structured description of
the different facets of the ad hoc teamwork problem. Second, it discusses the
progress that has been made in the field so far, and identifies the immediate
and long-term open problems that need to be addressed in the field of ad hoc
teamwork."
2275,"We seek to address this gap in the literature and
help foster further research in AHT.","However, to date there
is no comprehensive survey on AHT.","2 Background

This section provides a basic formulation of the AHT problem.",2022-02-16 18:16:27+00:00,A Survey of Ad Hoc Teamwork Research,cs.MA,"['cs.MA', 'cs.AI']","[arxiv.Result.Author('Reuth Mirsky'), arxiv.Result.Author('Ignacio Carlucho'), arxiv.Result.Author('Arrasy Rahman'), arxiv.Result.Author('Elliot Fosong'), arxiv.Result.Author('William Macke'), arxiv.Result.Author('Mohan Sridharan'), arxiv.Result.Author('Peter Stone'), arxiv.Result.Author('Stefano V. Albrecht')]","Ad hoc teamwork is the research problem of designing agents that can
collaborate with new teammates without prior coordination. This survey makes a
two-fold contribution: First, it provides a structured description of the
different facets of the ad hoc teamwork problem. Second, it discusses the
progress that has been made in the field so far, and identifies the immediate
and long-term open problems that need to be addressed in ad hoc teamwork."
2276,We seek to address this gap in the literature and help foster further research in AHT.,"However, to date there is no comprehensive survey on AHT.","2 Background

This section provides a basic formulation of the AHT problem.",2022-02-16 18:16:27+00:00,A Survey of Ad Hoc Teamwork Research,cs.MA,"['cs.MA', 'cs.AI']","[arxiv.Result.Author('Reuth Mirsky'), arxiv.Result.Author('Ignacio Carlucho'), arxiv.Result.Author('Arrasy Rahman'), arxiv.Result.Author('Elliot Fosong'), arxiv.Result.Author('William Macke'), arxiv.Result.Author('Mohan Sridharan'), arxiv.Result.Author('Peter Stone'), arxiv.Result.Author('Stefano V. Albrecht')]","Ad hoc teamwork is the research problem of designing agents that can
collaborate with new teammates without prior coordination. This survey makes a
two-fold contribution: First, it provides a structured description of the
different facets of the ad hoc teamwork problem. Second, it discusses the
progress that has been made in the field so far, and identifies the immediate
and long-term open problems that need to be addressed in ad hoc teamwork."
2367,"The key message we can draw from this analysis is that further research must take
the presence of passengers with movement limitations into account, especially in regard to situations
involving non-standard exit types.","The inﬂuence of crowd heterogeneity (presence of passengers with limitations) is even more evident
from sensitivity analysis conducted for the third phase of simulations, in which the ratio of agents of
the types with limitations (“Children”, “Carrying a toddler”, “Seniors”, and “With disabilities”, ranged
from 0% to 60%.","The performed analysis indicates that a non-standard exit path during a railcar evacuation is an
important factor inﬂuencing the evacuation time, particularly when the railcar is occupied by a het-
erogeneous population of passengers with respect to their movement abilities.",2022-02-23 12:25:06+00:00,Evacuation trials from a double-deck electric train unit: Experimental data and sensitivity analysis,cs.MA,"['cs.MA', 'physics.soc-ph']","[arxiv.Result.Author('Hana Najmanová'), arxiv.Result.Author('Veronika Pešková'), arxiv.Result.Author('Lukáš Kuklík'), arxiv.Result.Author('Marek Bukáček'), arxiv.Result.Author('Pavel Hrabák'), arxiv.Result.Author('Daniel Vašata')]","Passenger trains represent a challenging environment in emergencies, with
specific evacuation conditions resulting from the typical layout and interior
design inherent to public transportation vehicles. This paper describes a
dataset obtained in a full-scale controlled experiment emulating the emergency
evacuation of a double-deck electric unit railcar carried out in Prague in
2018. 15 evacuation trials involving 91 participants were conducted under
various evacuation scenarios considering different compositions of passenger
crowd, exit widths, and exit types (e.g. egress to a high platform, to an open
rail line using stairs, and a 750 mm jump without any supporting equipment).
The study's main goals were to collect experimental data on the movement
conditions in the railcar and to study the impact of various boundary
conditions on evacuation process and total evacuation time. Movement
characteristics (exit flows, speeds) and human behaviour (pre-movement
activities, exiting behaviours) were also analysed.
  The data obtained was used to validate and adjust a Pathfinder model to
capture important aspects of evacuation from the railcar. Furthermore, a series
of simulations using this model was performed to provide sensitivity analysis
of the influence of crowd composition, exit width, and exit type on total
evacuation time. As a key finding, we can conclude that for the case of a
standard exit path (platform or stairs) the width of the main exit had the
greatest impact on total evacuation time, however, crowd composition played the
prevailing role in evacuation scenarios involving a jump."
2600,Such ideas merit further study.,"As
divorced people may have joint custody of their children and may      the foregoing examples demonstrate, Pippi supports both discov-
thus function together in a MAS, albeit not the same MAS as when      ery and role binding and thus enables the realization of arbitrary
they were married.",applications as a peer-peer system.,2022-02-28 20:44:23+00:00,Pippi: Practical Protocol Instantiation,cs.MA,['cs.MA'],"[arxiv.Result.Author('Samuel H. Christie V'), arxiv.Result.Author('Amit K. Chopra'), arxiv.Result.Author('Munindar P. Singh')]","A protocol specifies interactions between roles, which together constitute a
multiagent system (MAS). Enacting a protocol presupposes that agents are bound
to the its roles. Existing protocol-based approaches, however, do not
adequately treat the practical aspects of how roles bindings come about.
  Pippi addresses this problem of MAS instantiation. It proposes the notion of
a metaprotocol, enacting which instantiates a MAS suitable for enacting a given
protocol. Pippi demonstrates the subtleties involved in instantiating MAS
arising from protocol composition, correlation, and decentralization. To
address these subtleties and further support practical application patterns, we
introduce an enhanced protocol language, with support for parameter types
(including role and protocol typed parameters, for metaprotocols), interface
flexibility, and binding constraints. We discuss the realization of our
approach through an extended agent architecture, including the novel concept of
a MAS adapter for contact management. We evaluate Pippi's expressiveness by
demonstrating common patterns for agent discovery."
3386,"Necessity of Du-PCB (RQ3)

                                                                                                          To address RQ3, we consider whether the positive and nega-
                                                                                                          tive buffers in Du-PCB can be replaced with a normal replay
PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration

                       &RRSHUDWLYH1DYLJDWLRQ                   other hand, extending PMIC with advanced techniques, like
                                                                hybrid action space (Li et al., 2021), evolutionary RL (Shen
                                                             et al., 2020), or prior human knowledge (Zhang et al., 2020),
                                                                is worth further study.","Due to the space limitation,
                                                                                                          these ablation experiments are put in Appendix E.

                                                                                                          5.4.","
                                                                Acknowledgements
/
                                                                The work is supported by the National Natural Science
/  5HZDUG                                                    Foundation of China (Grant Nos.",2022-03-16 11:28:23+00:00,PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration,cs.MA,"['cs.MA', 'cs.AI']","[arxiv.Result.Author('Pengyi Li'), arxiv.Result.Author('Hongyao Tang'), arxiv.Result.Author('Tianpei Yang'), arxiv.Result.Author('Xiaotian Hao'), arxiv.Result.Author('Tong Sang'), arxiv.Result.Author('Yan Zheng'), arxiv.Result.Author('Jianye Hao'), arxiv.Result.Author('Matthew E. Taylor'), arxiv.Result.Author('Wenyuan Tao'), arxiv.Result.Author('Zhen Wang')]","Learning to collaborate is critical in Multi-Agent Reinforcement Learning
(MARL). Previous works promote collaboration by maximizing the correlation of
agents' behaviors, which is typically characterized by Mutual Information (MI)
in different forms. However, we reveal sub-optimal collaborative behaviors also
emerge with strong correlations, and simply maximizing the MI can,
surprisingly, hinder the learning towards better collaboration. To address this
issue, we propose a novel MARL framework, called Progressive Mutual Information
Collaboration (PMIC), for more effective MI-driven collaboration. PMIC uses a
new collaboration criterion measured by the MI between global states and joint
actions. Based on this criterion, the key idea of PMIC is maximizing the MI
associated with superior collaborative behaviors and minimizing the MI
associated with inferior ones. The two MI objectives play complementary roles
by facilitating better collaborations while avoiding falling into sub-optimal
ones. Experiments on a wide range of MARL benchmarks show the superior
performance of PMIC compared with other algorithms."
3827,"A further study by UberEats from
February through May 2020 shows that restaurants that used delivery platforms saw ”signiﬁcant
and economically meaningful” increases in orders, which may have kept some restaurants alive [22].","An empirical study indeed
shows that low proﬁt-margin restaurants which did not ﬁnd platform services to be economical pre-
pandemic, turned to these platforms in order to survive [29].","On the other hand, as an increasing number of customers turns to adopt platforms due to the
higher oﬀ-platform transaction costs, platforms possess larger market power, and thus have driven
up the on-platform service and commission fees.",2022-03-25 00:21:41+00:00,Using Reinforcement Learning to Study Platform Economies under Market Shocks,cs.MA,"['cs.MA', 'cs.GT']","[arxiv.Result.Author('Xintong Wang'), arxiv.Result.Author('Gary Qiurui Ma'), arxiv.Result.Author('Alon Eden'), arxiv.Result.Author('Clara Li'), arxiv.Result.Author('Alexander Trott'), arxiv.Result.Author('Stephan Zheng'), arxiv.Result.Author('David C. Parkes')]","Driven by rapid digitization and expansive internet access, market-driven
platforms (e.g., Amazon, DoorDash, Uber, TaskRabbit) are increasingly prevalent
and becoming key drivers of the economy. Across many industries, platforms
leverage digital infrastructure to efficiently match producers and consumers,
dynamically set prices, and enable economies of scale. This increasing
prominence makes it important to understand the behavior of platforms, which
induces complex phenomenon especially in the presence of severe market shocks
(e.g., during pandemics). In this work, we develop a multi-agent simulation
environment to capture key elements of a platform economy, including the kinds
of economic shocks that disrupt a traditional, off-platform market. We use deep
reinforcement learning (RL) to model the pricing and matching behavior of a
platform that optimizes for revenue and various socially-aware objectives. We
start with tractable motivating examples to establish intuitions about the
dynamics and function of optimal platform policies. We then conduct extensive
empirical simulations on multi-period environments, including settings with
market shocks. We characterize the effect of a platform on the efficiency and
resilience of an economic system under different platform design objectives. We
further analyze the consequences of regulation fixing platform fees, and study
the alignment of a revenue-maximizing platform with social welfare under
different platform matching policies. As such, our RL-based framework provides
a foundation for understanding platform economies under different designs and
for yielding new economic insights that are beyond analytical tractability."
5082,"The issue is an intriguing one
which could be usefully explored in further research.","In our future research, we
intend to concentrate on how to choose the appropriate rollout horizon.","9
References

 [1] Zaheer Abbas, Samuel Sokota, Erin Talvitie, and Martha White.",2022-04-20 12:16:27+00:00,Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent Reinforcement Learning,cs.MA,"['cs.MA', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Zhiwei Xu'), arxiv.Result.Author('Dapeng Li'), arxiv.Result.Author('Bin Zhang'), arxiv.Result.Author('Yuan Zhan'), arxiv.Result.Author('Yunpeng Bai'), arxiv.Result.Author('Guoliang Fan')]","Recently, model-based agents have achieved better performance than model-free
ones using the same computational budget and training time in single-agent
environments. However, due to the complexity of multi-agent systems, it is
tough to learn the model of the environment. The significant compounding error
may hinder the learning process when model-based methods are applied to
multi-agent tasks. This paper proposes an implicit model-based multi-agent
reinforcement learning method based on value decomposition methods. Under this
method, agents can interact with the learned virtual environment and evaluate
the current state value according to imagined future states in the latent
space, making agents have the foresight. Our approach can be applied to any
multi-agent value decomposition method. The experimental results show that our
method improves the sample efficiency in different partially observable Markov
decision process domains."
5083,"The issue is an intriguing one
which could be usefully explored in further research.","In our future research, we
intend to concentrate on how to choose the appropriate rollout horizon.","Acknowledgments and Disclosure of Funding

The work is supported by the National Defence Foundation Reinforcement Fund.",2022-04-20 12:16:27+00:00,Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent Reinforcement Learning,cs.MA,"['cs.MA', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Zhiwei Xu'), arxiv.Result.Author('Dapeng Li'), arxiv.Result.Author('Bin Zhang'), arxiv.Result.Author('Yuan Zhan'), arxiv.Result.Author('Yunpeng Bai'), arxiv.Result.Author('Guoliang Fan')]","Recently, model-based agents have achieved better performance than model-free
ones using the same computational budget and training time in single-agent
environments. However, due to the complexity of multi-agent systems, it is
tough to learn the model of the environment. The significant compounding error
may hinder the learning process when model-based methods are applied to
multi-agent tasks. This paper proposes an implicit model-based multi-agent
reinforcement learning method based on value decomposition methods. Under this
method, agents can interact with the learned virtual environment and evaluate
the current state value according to imagined future states in the latent
space, making agents have the foresight. Our approach can be applied to any
multi-agent value decomposition method. The experimental results show that our
method improves the sample efficiency in different partially observable Markov
decision process domains."
7152,"Whilst this shows the versatility of these al-
gorithms, further research could be placed into the use of deep                                                                                             ANN                                                           6.5
reinforcement learning (DRL) to improve results.","Second is the Roth-Erev algorithm, which is used                                                                                            Roth-Erev                                                     9.7
by 9.7% of papers.","DRL uses deep
neural networks to act as function approximators.",2022-06-05 14:52:26+00:00,Machine learning applications for electricity market agent-based models: A systematic literature review,cs.MA,"['cs.MA', 'cs.LG']","[arxiv.Result.Author('Alexander J. M. Kell'), arxiv.Result.Author('Stephen McGough'), arxiv.Result.Author('Matthew Forshaw')]","The electricity market has a vital role to play in the decarbonisation of the
energy system. However, the electricity market is made up of many different
variables and data inputs. These variables and data inputs behave in sometimes
unpredictable ways which can not be predicted a-priori. It has therefore been
suggested that agent-based simulations are used to better understand the
dynamics of the electricity market. Agent-based models provide the opportunity
to integrate machine learning and artificial intelligence to add intelligence,
make better forecasts and control the power market in better and more efficient
ways. In this systematic literature review, we review 55 papers published
between 2016 and 2021 which focus on machine learning applied to agent-based
electricity market models. We find that research clusters around popular
topics, such as bidding strategies. However, there exists a long-tail of
different research applications that could benefit from the high intensity
research from the more investigated applications."
7241,"Another review in
favour of a synergistic exploitation of MAS and DTs, while recognising the need
for further research along this line, argues that agents and MAS are good ex-
amples of how autonomous decision-making can be modelled and implemented
based on digital representations of physical entities [17]—as DTs are.","Also reference [12] promotes the idea that through a MAS a
set of DTs can create a network named as “asset ﬂeet”, essentially enabling DTs
to obtain information about events that have not aﬀected them yet, as a away
to improve their individual knowledge of the environment.","Another literature review [28], explicitly targeting the supply chain business
domain, sums up well how MAS and DTs are currently mostly exploited in
synergy (emphasis added)—also outside of the supply chain domain:

     “Since supply chains are now building with increasingly complex and col-
     laborative interdependencies, Agent-Based Models are an extremely use-
     ful tool when representing such relationships [.",2022-06-07 13:08:46+00:00,"About Digital Twins, agents, and multiagent systems: a cross-fertilisation journey",cs.MA,"['cs.MA', 'I.2.11; D.2.10; D.2.11']","[arxiv.Result.Author('Stefano Mariani'), arxiv.Result.Author('Marco Picone'), arxiv.Result.Author('Alessandro Ricci')]","Digital Twins (DTs) are rapidly emerging as a fundamental brick of
engineering cyber-physical systems, but their notion is still mostly bound to
specific business domains (e.g. manufacturing), goals (e.g. product design), or
application domains (e.g. the Internet of Things). As such, their value as
general purpose engineering abstractions is yet to be fully revealed. In this
paper, we relate DTs with agents and multiagent systems, as the latter are
arguably the most rich abstractions available for the engineering of complex
socio-technical and cyber-physical systems, and the former could both fill in
some gaps in agent-oriented engineering and benefit from an agent-oriented
interpretation -- in a cross-fertilisation journey."
7837,"Moreover, We plan to open-source the
realistic simulation environments and design of our platform                    [16] M. Hoffman, B. Shahriari, J. Aslanides, G. Barth-Maron, F. Behbahani,
to encourage further research on multi-robot reinforcement                            T. Norman, A. Abdolmaleki, A. Cassirer, F. Yang, K. Baumli et al.,
learning.","abs/1606.01540,
and discuss several challenges in multi-robot reinforcement                           2016.
learning research.","“Acme: A research framework for distributed reinforcement learning,”
                                                                                      CoRR, vol.",2022-06-20 06:36:45+00:00,From Multi-agent to Multi-robot: A Scalable Training and Evaluation Platform for Multi-robot Reinforcement Learning,cs.MA,"['cs.MA', 'cs.AI', 'cs.RO', 'I.2.9; I.2.11']","[arxiv.Result.Author('Zhiuxan Liang'), arxiv.Result.Author('Jiannong Cao'), arxiv.Result.Author('Shan Jiang'), arxiv.Result.Author('Divya Saxena'), arxiv.Result.Author('Jinlin Chen'), arxiv.Result.Author('Huafeng Xu')]","Multi-agent reinforcement learning (MARL) has been gaining extensive
attention from academia and industries in the past few decades. One of the
fundamental problems in MARL is how to evaluate different approaches
comprehensively. Most existing MARL methods are evaluated in either video games
or simplistic simulated scenarios. It remains unknown how these methods perform
in real-world scenarios, especially multi-robot systems. This paper introduces
a scalable emulation platform for multi-robot reinforcement learning (MRRL)
called SMART to meet this need. Precisely, SMART consists of two components: 1)
a simulation environment that provides a variety of complex interaction
scenarios for training and 2) a real-world multi-robot system for realistic
performance evaluation. Besides, SMART offers agent-environment APIs that are
plug-and-play for algorithm implementation. To illustrate the practicality of
our platform, we conduct a case study on the cooperative driving lane change
scenario. Building off the case study, we summarize several unique challenges
of MRRL, which are rarely considered previously. Finally, we open-source the
simulation environments, associated benchmark tasks, and state-of-the-art
baselines to encourage and empower MRRL research."
10040,"We have every conﬁdence that this new domain lays down the blueprints for
much further research in the future.","Thus, we add to the initial SVRP research from
[1,2,3,4].","Our inspiration is in line with multiple programmes across Europe in regard to
emerging VRPs.",2022-08-15 09:53:50+00:00,Fair Division meets Vehicle Routing: Fairness for Drivers with Monotone Profits,cs.MA,['cs.MA'],[arxiv.Result.Author('Martin Damyanov Aleksandrov')],"We propose a new model for fair division and vehicle routing, where drivers
have monotone profit preferences, and their vehicles have feasibility
constraints, for customer requests. For this model, we design two new axiomatic
notions for fairness for drivers: FEQ1 and FEF1. FEQ1 encodes driver pairwise
bounded equitability. FEF1 encodes driver pairwise bounded envy freeness. We
compare FEQ1 and FEF1 with popular fair division notions such as EQ1 and EF1.
We also give algorithms for guaranteeing FEQ1 and FEF1, respectively."
10957,"We
both algorithms are shown to be scalable to a large real-        imagine that further research into more tractable algorithms
world trafﬁc network of Monaco city.","For    the cooperative case of MFC has only been formulated in
example, recent work utilizes actor-critic methods combined      discrete-time very recently [97] and learning algorithms go-
with communication [285] and graph attention networks [286]      ing beyond discretization-based MFC MDPs [97] or locally-
to help with partial observability in such problems, where       optimal solutions [188] remain yet to be developed.","Another way to deal         such as ones based on function-valued reinforcement learning
with trafﬁc congestion through MARL is trafﬁc routing.",2022-09-08 14:58:50+00:00,A Survey on Large-Population Systems and Scalable Multi-Agent Reinforcement Learning,cs.MA,"['cs.MA', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Kai Cui'), arxiv.Result.Author('Anam Tahir'), arxiv.Result.Author('Gizem Ekinci'), arxiv.Result.Author('Ahmed Elshamanhory'), arxiv.Result.Author('Yannick Eich'), arxiv.Result.Author('Mengguang Li'), arxiv.Result.Author('Heinz Koeppl')]","The analysis and control of large-population systems is of great interest to
diverse areas of research and engineering, ranging from epidemiology over
robotic swarms to economics and finance. An increasingly popular and effective
approach to realizing sequential decision-making in multi-agent systems is
through multi-agent reinforcement learning, as it allows for an automatic and
model-free analysis of highly complex systems. However, the key issue of
scalability complicates the design of control and reinforcement learning
algorithms particularly in systems with large populations of agents. While
reinforcement learning has found resounding empirical success in many scenarios
with few agents, problems with many agents quickly become intractable and
necessitate special consideration. In this survey, we will shed light on
current approaches to tractably understanding and analyzing large-population
systems, both through multi-agent reinforcement learning and through adjacent
areas of research such as mean-field games, collective intelligence, or complex
network theory. These classically independent subject areas offer a variety of
approaches to understanding or modeling large-population systems, which may be
of great use for the formulation of tractable MARL algorithms in the future.
Finally, we survey potential areas of application for large-scale control and
identify fruitful future applications of learning algorithms in practical
systems. We hope that our survey could provide insight and future directions to
junior and senior researchers in theoretical and applied sciences alike."
11022,"For multi-agent
tasks similar to ﬂocking [7], we would further study on the relationship between
the number of agents, the ratio of senior and junior agents, and the degree of
emergence, making our method conducive to more complex environments.","Experimental results in a range of challenging and self-
contrast benchmarks indicate this algorithm with eﬀectiveness.","References

 1.",2022-09-10 15:35:20+00:00,Cooperation and Competition: Flocking with Evolutionary Multi-Agent Reinforcement Learning,cs.MA,"['cs.MA', 'cs.AI', 'cs.RO']","[arxiv.Result.Author('Yunxiao Guo'), arxiv.Result.Author('Xinjia Xie'), arxiv.Result.Author('Runhao Zhao'), arxiv.Result.Author('Chenglan Zhu'), arxiv.Result.Author('Jiangting Yin'), arxiv.Result.Author('Han Long')]","Flocking is a very challenging problem in a multi-agent system; traditional
flocking methods also require complete knowledge of the environment and a
precise model for control. In this paper, we propose Evolutionary Multi-Agent
Reinforcement Learning (EMARL) in flocking tasks, a hybrid algorithm that
combines cooperation and competition with little prior knowledge. As for
cooperation, we design the agents' reward for flocking tasks according to the
boids model. While for competition, agents with high fitness are designed as
senior agents, and those with low fitness are designed as junior, letting
junior agents inherit the parameters of senior agents stochastically. To
intensify competition, we also design an evolutionary selection mechanism that
shows effectiveness on credit assignment in flocking tasks. Experimental
results in a range of challenging and self-contrast benchmarks demonstrate that
EMARL significantly outperforms the full competition or cooperation methods."
11091,"The mutual interaction
between different failures is only partially discussed and merits further research.","The above discussion shows the Single Layer Coverage algorithms are fault
tolerant to failures of drones – mobile and settled – alike.","65
6 Results and Discussion
     Seven different exploration algorithms were presented in sections 4 and 5 above.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11092,These results merit further research.,"As evident, doubling of 𝛥𝑇 results in close to a doubling

of the 𝑛 coefficient hinting that 𝐸      is a linear function of 𝛥𝑇 as well as a

quadratic function of 𝑛 when 𝛥𝑇 ≥ 2.","73
           (a)

Figure 52                               (b)

           Ratio of termination time to 𝛥𝑇 as a function of 𝛥𝑇 using Dual Layer Coverage
                           algorithms (a) DLLG; (b) DLUG

     Figure 53 shows the total energy for the different regions using 𝛥𝑇 = 4, 8 and 16.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11093,These results merit further research.,"As evident, doubling of 𝛥𝑇 results in close to a doubling of the
𝑛 coefficient hinting that 𝐸 is a linear function of 𝛥𝑇 as well as a quadratic
function of 𝑛 when 𝛥𝑇 ≥ 2.","74
           (a)

           (b)

Figure 53                                     (c)

                  Total energy as a function of region size using Dual Layer Coverage algorithms
                                 (a) 𝛥𝑇 = 4; (b) 𝛥𝑇 = 8; (c) 𝛥𝑇 = 16

           The equations and 𝑅 values of the trendlines are in the bottom-left corner

     Summing, the results indicate that when 𝛥𝑇 ≥ 2 the termination time of the Dual
Layer Coverage algorithms is linear with 𝑛 and 𝛥𝑇 while 𝐸 is linear with 𝛥𝑇 and

           75
quadratic with respect to 𝑛.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11094,"The Single Layer Coverage algorithms are fault tolerant with a couple of minor
modification however the topic as a whole and specifically the interaction between the
different failure modes merits further research.","This is especially true regarding the case of 𝛥𝑇 = 1 and/or the unlimited steepness
version of the algorithms.","97
References

[1] J. F. Kennedy, R. C. Eberhart, and Y. Shi, Swarm intelligence.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11095,"The mutual interaction
between different failures is only partially discussed and merits further research.","The above discussion shows the Single Layer Coverage algorithms are fault
tolerant to failures of drones – mobile and settled – alike.","64
6 Results and Discussion
     Seven different exploration algorithms were presented in sections 4 and 5 above.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11096,These results merit further research.,"As evident, doubling of 𝛥𝑇 results in close to a doubling of the 𝑛2

coefficient hinting that 𝐸𝑇𝑜𝑡𝑎𝑙 is a linear function of 𝛥𝑇 as well as a quadratic
function of 𝑛2 when 𝛥𝑇 ≥ 2.","72
           (a)

Figure 51                               (b)

           Ratio of termination time to 𝛥𝑇 as a function of 𝛥𝑇 using Dual Layer Coverage
                           algorithms (a) DLLG; (b) DLUG

     Figure 52 shows the total energy for the different regions using 𝛥𝑇 = 4, 8 and 16.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11097,These results merit further research.,"As evident, doubling of 𝛥𝑇 results in close to a doubling of the 𝑛2

coefficient hinting that 𝐸𝑇𝑜𝑡𝑎𝑙 is a linear function of 𝛥𝑇 as well as a quadratic
function of 𝑛2 when 𝛥𝑇 ≥ 2.","73
           (a)

           (b)

Figure 52                                     (c)

                  Total energy as a function of region size using Dual Layer Coverage algorithms
                                 (a) 𝛥𝑇 = 4; (b) 𝛥𝑇 = 8; (c) 𝛥𝑇 = 16

           The equations and 𝑅2values of the trendlines are in the bottom-left corner

     Summing, the results indicate that when 𝛥𝑇 ≥ 2 the termination time of the Dual
Layer Coverage algorithms is linear with 𝑛 and 𝛥𝑇 while 𝐸𝑇𝑜𝑡𝑎𝑙 is linear with 𝛥𝑇 and

           74
quadratic with respect to 𝑛.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11098,"Another issue that merits further research is the effect of
multiple entry points on the various metrics.","This is especially true regarding the case of 𝛥𝑇 = 1 and/or the unlimited steepness
version of the algorithms.","While the algorithms presented were
designed with multiple entry points in mind, both the mathematical analysis and
numerical experiments in this research dealt with the case of a single door.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11099,"The Single Layer Coverage algorithms are fault tolerant with a couple of minor
modification however the topic as a whole and specifically the interaction between the
different failure modes merits further research.","While the algorithms presented were
designed with multiple entry points in mind, both the mathematical analysis and
numerical experiments in this research dealt with the case of a single door.","96
References

[1] J. F. Kennedy, R. C. Eberhart, and Y. Shi, Swarm intelligence.",2022-09-12 18:03:44+00:00,Exploration and Coverage with Swarms of Settling Agents,cs.MA,['cs.MA'],"[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Joseph Ben-Asher'), arxiv.Result.Author('Alfred Bruckstein')]","We consider several algorithms for exploring and filling an unknown,
connected region, by simple, airborne agents. The agents are assumed to be
identical, autonomous, anonymous and to have a finite amount of memory. The
region is modeled as a connected sub-set of a regular grid composed of square
cells. The algorithms described herein are suited for Micro Air Vehicles (MAV)
since these air vehicles enable unobstructed views of the ground below and can
move freely in space at various heights. The agents explore the region by
applying various action-rules based on locally acquired information Some of
them may settle in unoccupied cells as the exploration progresses. Settled
agents become virtual pheromones for the exploration and coverage process,
beacons that subsequently aid the remaining, and still exploring, mobile
agents. We introduce a backward propagating information diffusion process as a
way to implement a deterministic indicator of process termination and guide the
mobile agents. For the proposed algorithms, complete covering of the graph in
finite time is guaranteed when the size of the region is fixed. Bounds on the
coverage times are also derived. Extensive simulation results exhibit good
agreement with the theoretical predictions."
11152,"that further research is required to understand the phenomenon
                                                                  [14].","Although it is      Based on thorough research on the initial rules and conditions
possible to consider such co-self-organizing systems, they        that facilitate grouping behavior, it has been concluded that
also tend to settle into ”mediocre stable states” where neither   there is no clear explanation of the emergence process and
predator nor prey performs well, nor does it improve [37].","D. Simulating Multi-agent Systems
                                                                     Furthermore, Chang et al.",2022-09-13 22:53:23+00:00,Collective Adaptation in Multi-Agent Systems: How Predator Confusion Shapes Swarm-Like Behaviors,cs.MA,['cs.MA'],"[arxiv.Result.Author('Georgi Ivanov'), arxiv.Result.Author('George Palamas')]","Popular hypotheses about the origins of collective adaptation are related to
two basic behaviours: protection from predators and a combined search for food
resources. Among the anti-predator explanations, the predator confusion
hypothesis suggests that groups of individuals moving in a swarm aim to
overwhelm the predator while the dilution of risk hypothesis suggests that the
probability of a single prey being targeted by a predator is lower in larger
groups. In this paper, we explore how emergent behaviors arise from a
predator-driven process as an adaptive response to external stimuli perceived
as threatening. Moreover, we suggest a predator confusion process to provide a
selective pressure for the prey to evolve group formations. We analyze the
foraging and prey-predator dynamics evolved in terms of group density and
formation, behavior consistency, predator evasion and success rate, and
foraging rate. Two agents' perceptual models are compared. A local observation
model, where agents can only see what's in their immediate vicinity, and a
global observation model, where agents are able to see the predator at all
times. Both models were evolved for predator avoidance, foraging and collision
avoidance, using reinforcement learning in a simulated game environment. Our
results suggest that the dilution of risk factor is sufficient to evolve group
formations, and the predator confusion effect could play an important role in
the evolution of collaborative behaviors. Finally, we show how variations in
the information exchange of this social order can impact the global collective
behaviors."
11345,"We believe much further research should be done regarding the time
and energy costs of agent recovery upon mission termination, both in this and
broader contexts.","However,
we did not formally model this process in this paper nor consider its impact on
energy.","Finally, given that we’ve shown several beneﬁcial eﬀects of
agent-beacon duality in swarm-robotic coverage tasks, we would be remiss if we
did not ask what other swarm robotics-related problems can beneﬁt from this
concept, and in what other ways this idea can be developed.",2022-09-18 14:18:30+00:00,"Stigmergy-based, Dual-Layer Coverage of Unknown Indoor Regions",cs.MA,"['cs.MA', 'cs.DM', '68W15']","[arxiv.Result.Author('Ori Rappel'), arxiv.Result.Author('Michael Amir'), arxiv.Result.Author('Alfred M. Bruckstein')]","We present algorithms for uniformly covering an unknown indoor region with a
swarm of simple, anonymous and autonomous mobile agents. The exploration of
such regions is made difficult by the lack of a common global reference frame,
severe degradation of radio-frequency communication, and numerous ground
obstacles. We propose addressing these challenges by using airborne agents,
such as Micro Air Vehicles, in dual capacity, both as mobile explorers and
(once they land) as beacons that help other agents navigate the region.
  The algorithms we propose are designed for a swarm of simple, identical,
ant-like agents with local sensing capabilities. The agents enter the region,
which is discretized as a graph, over time from one or more entry points and
are tasked with occupying all of its vertices. Unlike many works in this area,
we consider the requirement of informing an outside operator with limited
information that the coverage mission is complete. Even with this additional
requirement we show, both through simulations and mathematical proofs, that the
dual role concept results in linear-time termination, while also besting many
well-known algorithms in the literature in terms of energy use."
11870,"However, those methods remain
under the upper bound reached by the Early stopping listener, which suggests that further research
on regularization in cooperative games is warranted.","These trends corroborate our hypothesis that controlling the listener’s learning is
key to encourage the speaker to develop more structured languages.","8
                   Gen. ↑   Compo.",2022-09-30 09:50:46+00:00,Emergent Communication: Generalization and Overfitting in Lewis Games,cs.MA,"['cs.MA', 'cs.CL', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Mathieu Rita'), arxiv.Result.Author('Corentin Tallec'), arxiv.Result.Author('Paul Michel'), arxiv.Result.Author('Jean-Bastien Grill'), arxiv.Result.Author('Olivier Pietquin'), arxiv.Result.Author('Emmanuel Dupoux'), arxiv.Result.Author('Florian Strub')]","Lewis signaling games are a class of simple communication games for
simulating the emergence of language. In these games, two agents must agree on
a communication protocol in order to solve a cooperative task. Previous work
has shown that agents trained to play this game with reinforcement learning
tend to develop languages that display undesirable properties from a linguistic
point of view (lack of generalization, lack of compositionality, etc). In this
paper, we aim to provide better understanding of this phenomenon by
analytically studying the learning problem in Lewis games. As a core
contribution, we demonstrate that the standard objective in Lewis games can be
decomposed in two components: a co-adaptation loss and an information loss.
This decomposition enables us to surface two potential sources of overfitting,
which we show may undermine the emergence of a structured communication
protocol. In particular, when we control for overfitting on the co-adaptation
loss, we recover desired properties in the emergent languages: they are more
compositional and generalize better."
11871,"However, those methods remain
under the upper bound reached by the Early stopping listener, which suggests that further research
on regularization in cooperative games is warranted.","These trends corroborate our hypothesis that controlling the listener’s learning is
key to encourage the speaker to develop more structured languages.","We complement this analysis in Appendix C.2 by studying the impact of regularization on the
speaker’s side, and show that such regularization does not result in similar improvements.",2022-09-30 09:50:46+00:00,Emergent Communication: Generalization and Overfitting in Lewis Games,cs.MA,"['cs.MA', 'cs.CL', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Mathieu Rita'), arxiv.Result.Author('Corentin Tallec'), arxiv.Result.Author('Paul Michel'), arxiv.Result.Author('Jean-Bastien Grill'), arxiv.Result.Author('Olivier Pietquin'), arxiv.Result.Author('Emmanuel Dupoux'), arxiv.Result.Author('Florian Strub')]","Lewis signaling games are a class of simple communication games for
simulating the emergence of language. In these games, two agents must agree on
a communication protocol in order to solve a cooperative task. Previous work
has shown that agents trained to play this game with reinforcement learning
tend to develop languages that display undesirable properties from a linguistic
point of view (lack of generalization, lack of compositionality, etc). In this
paper, we aim to provide better understanding of this phenomenon by
analytically studying the learning problem in Lewis games. As a core
contribution, we demonstrate that the standard objective in Lewis games can be
decomposed in two components: a co-adaptation loss and an information loss.
This decomposition enables us to surface two potential sources of overfitting,
which we show may undermine the emergence of a structured communication
protocol. In particular, when we control for overfitting on the co-adaptation
loss, we recover desired properties in the emergent languages: they are more
compositional and generalize better."
14179,"are fixed due to the main research focus, which is the exploration of whether
and how BNE affects pedestrian emergency evacuation, but variations in these global parameters
could be evaluated in further research.","door-width,
follow-radius, etc.)","2.3.3 Input data
So far, no input is read in this initial model.",2022-11-25 17:41:03+00:00,An agent-based simulation model of pedestrian evacuation based on Bayesian Nash Equilibrium,cs.MA,['cs.MA'],"[arxiv.Result.Author('Yiyu Wang'), arxiv.Result.Author('Jiaqi Ge'), arxiv.Result.Author('Alexis Comber')]","This research incorporates Bayesian game theory into pedestrian evacuation in
an agent-based model. Three pedestrian behaviours were compared: Random Follow,
Shortest Route and Bayesian Nash Equilibrium (BNE), as well as combinations of
these. The results showed that BNE pedestrians were able to evacuate more
quickly as they predict congestion levels in their next step and adjust their
directions to avoid congestion, closely matching the behaviours of evacuating
pedestrians in reality. A series of simulation experiments were conducted to
evaluate whether and how BNE affects pedestrian evacuation procedures. The
results showed that: 1) BNE has a large impact on reducing evacuation time; 2)
BNE pedestrians displayed more intelligent and efficient evacuating behaviours;
3) As the proportion of BNE users rises, average evacuation time decreases, and
average comfort level increases. A detailed description of the model and
relevant experimental results is provided in this paper. Several limitations as
well as further works are also identified."
