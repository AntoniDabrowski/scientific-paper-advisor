,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract
43,"However, it is subject to further research to assign more expressive
   weights.","Currently SMART applies equal weight to each of the ques-
   tions.","We expect that there is no one size ﬁts all weighting exists and
   that scoring wights will depend on the application domain.",2022-01-03 09:31:59+00:00,SMART: a Technology Readiness Methodology in the Frame of the NIS Directive,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Author('Archana Kumari'), arxiv.Result.Author('Stefan Schiffner'), arxiv.Result.Author('Sandra Schmitz')]","An ever shorter technology lifecycle engendered the need for assessing new
technologies w.r.t. their market readiness. Knowing the Technology readiness
level (TRL) of a given target technology proved to be useful to mitigate risks
such as cost overrun, product roll out delays, or early launch failures.
Originally developed for space programmes by NASA, TRL became a de facto
standard among technology and manufacturing companies and even among research
funding agencies. However, while TRL assessments provide a systematic
evaluation process resulting in meaningful metric, they are one dimensional:
they only answer the question if a technology can go into production. Hence
they leave an inherent gap, i.e., if a technology fulfils requirements with a
certain quality. This gap becomes intolerable when this metric is applied
software such as technological cybersecurity measures. With legislation such as
the General Data Protection Regulation4 (GDPR) and the Network and Information
Systems Directive5 (NIS-D) making reference to state of the art when requiring
appropriate protection measures, software designers are faced with the question
how to measure if a technology is suitable to use. We argue that there is a
potential mismatch of legal aim and technological reality which not only leads
to a risk of non-compliance, but also might lead to weaker protected systems
than possible. In that regard, we aim to address the gaps identified with
existing Technology Readiness Assessment (TRA)s and aim to overcome these by
developing standardised method which is suitable for assessing software w.r.t.
its market readiness and quality (in sum maturity)."
348,"Big data in humanitarian supply chain man-
   agement: A review and further research directions.","S. Gupta, N. Altay, and Z. Luo.","Annals of Operations
   Research, 283(1):1153–1173, 2019.",2022-01-10 18:05:18+00:00,On the interplay of data and cognitive bias in crisis information management -- An exploratory study on epidemic response,cs.CY,['cs.CY'],"[arxiv.Result.Author('David Paulus'), arxiv.Result.Author('Ramian Fathi'), arxiv.Result.Author('Frank Fiedrich'), arxiv.Result.Author('Bartel Van de Walle'), arxiv.Result.Author('Tina Comes')]","Humanitarian crises, such as the 2014 West Africa Ebola epidemic, challenge
information management and thereby threaten the digital resilience of the
responding organizations. Crisis information management (CIM) is characterised
by the urgency to respond despite the uncertainty of the situation. Coupled
with high stakes, limited resources and a high cognitive load, crises are prone
to induce biases in the data and the cognitive processes of analysts and
decision-makers. When biases remain undetected and untreated in CIM, they may
lead to decisions based on biased information, increasing the risk of an
inefficient response. Literature suggests that crisis response needs to address
the initial uncertainty and possible biases by adapting to new and better
information as it becomes available. However, we know little about whether
adaptive approaches mitigate the interplay of data and cognitive biases.
  We investigated this question in an exploratory, three-stage experiment on
epidemic response. Our participants were experienced practitioners in the
fields of crisis decision-making and information analysis. We found that
analysts fail to successfully debias data, even when biases are detected, and
that this failure can be attributed to undervaluing debiasing efforts in favor
of rapid results. This failure leads to the development of biased information
products that are conveyed to decision-makers, who consequently make decisions
based on biased information. Confirmation bias reinforces the reliance on
conclusions reached with biased data, leading to a vicious cycle, in which
biased assumptions remain uncorrected. We suggest mindful debiasing as a
possible counter-strategy against these bias effects in CIM."
465,"The need for more secure and robust communication is very high in
smart agriculture applications and requires further research and new affordable technologies.","Additionally, some research has integrated communication equipment with
other smart devices making it viable for uninterrupted communication such as Solar Insecticidal Lamps (SIL) and WSN
to create a novel agriculture thing, SIL-IoT [78].","6.6 Connectivity Issues

In many rural areas across the globe reliable high bandwidth Internet connection is not available, which stalls the
existing cloud based computing and prevents the advancement of smart agriculture.",2022-01-13 00:48:36+00:00,Everything You wanted to Know about Smart Agriculture,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alakananda Mitra'), arxiv.Result.Author('Sukrutha L. T. Vangipuram'), arxiv.Result.Author('Anand K. Bapatla'), arxiv.Result.Author('Venkata K. V. V. Bathalapalli'), arxiv.Result.Author('Saraju P. Mohanty'), arxiv.Result.Author('Elias Kougianos'), arxiv.Result.Author('Chittaranjan Ray')]","The world population is anticipated to increase by close to 2 billion by 2050
causing a rapid escalation of food demand. A recent projection shows that the
world is lagging behind accomplishing the ""Zero Hunger"" goal, in spite of some
advancements. Socio-economic and well being fallout will affect the food
security. Vulnerable groups of people will suffer malnutrition. To cater to the
needs of the increasing population, the agricultural industry needs to be
modernized, become smart, and automated. Traditional agriculture can be remade
to efficient, sustainable, eco-friendly smart agriculture by adopting existing
technologies. In this survey paper the authors present the applications,
technological trends, available datasets, networking options, and challenges in
smart agriculture. How Agro Cyber Physical Systems are built upon the
Internet-of-Agro-Things is discussed through various application fields.
Agriculture 4.0 is also discussed as a whole. We focus on the technologies,
such as Artificial Intelligence (AI) and Machine Learning (ML) which support
the automation, along with the Distributed Ledger Technology (DLT) which
provides data integrity and security. After an in-depth study of different
architectures, we also present a smart agriculture framework which relies on
the location of data processing. We have divided open research problems of
smart agriculture as future research work in two groups - from a technological
perspective and from a networking perspective. AI, ML, the blockchain as a DLT,
and Physical Unclonable Functions (PUF) based hardware security fall under the
technology group, whereas any network related attacks, fake data injection and
similar threats fall under the network research problem group."
466,"The stored data can help further research into the availability of resources in farming for
next generations.","8 Datasets for Smart Agriculture Research

Smart agriculture makes use of intelligent devices to collect data to analyze crop yields, livestock management, and
economics related to supply.","Table 1 shows different datasets of multiple formats that we have studied and collected for the current
survey paper.",2022-01-13 00:48:36+00:00,Everything You wanted to Know about Smart Agriculture,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alakananda Mitra'), arxiv.Result.Author('Sukrutha L. T. Vangipuram'), arxiv.Result.Author('Anand K. Bapatla'), arxiv.Result.Author('Venkata K. V. V. Bathalapalli'), arxiv.Result.Author('Saraju P. Mohanty'), arxiv.Result.Author('Elias Kougianos'), arxiv.Result.Author('Chittaranjan Ray')]","The world population is anticipated to increase by close to 2 billion by 2050
causing a rapid escalation of food demand. A recent projection shows that the
world is lagging behind accomplishing the ""Zero Hunger"" goal, in spite of some
advancements. Socio-economic and well being fallout will affect the food
security. Vulnerable groups of people will suffer malnutrition. To cater to the
needs of the increasing population, the agricultural industry needs to be
modernized, become smart, and automated. Traditional agriculture can be remade
to efficient, sustainable, eco-friendly smart agriculture by adopting existing
technologies. In this survey paper the authors present the applications,
technological trends, available datasets, networking options, and challenges in
smart agriculture. How Agro Cyber Physical Systems are built upon the
Internet-of-Agro-Things is discussed through various application fields.
Agriculture 4.0 is also discussed as a whole. We focus on the technologies,
such as Artificial Intelligence (AI) and Machine Learning (ML) which support
the automation, along with the Distributed Ledger Technology (DLT) which
provides data integrity and security. After an in-depth study of different
architectures, we also present a smart agriculture framework which relies on
the location of data processing. We have divided open research problems of
smart agriculture as future research work in two groups - from a technological
perspective and from a networking perspective. AI, ML, the blockchain as a DLT,
and Physical Unclonable Functions (PUF) based hardware security fall under the
technology group, whereas any network related attacks, fake data injection and
similar threats fall under the network research problem group."
709,"The article in [26] on cognitive AI systems provided a discussion on important
bottlenecks and topics for further research targeting human-level functionality AI [26].","From that perspective, computer-augmented design was identified as a next step
beyond merely computer-aided design.","Many AI or CI systems that intend to aid humans cognitively can be categorized as: (i)
Cognitive prosthesis or (ii) Cognitive orthotics.",2021-12-27 19:11:34+00:00,Computational Rational Engineering and Development: Synergies and Opportunities,cs.CY,"['cs.CY', 'cs.SY', 'eess.SY']",[arxiv.Result.Author('Ramses Sala')],"Research and development in computer technology and computational methods
have resulted in a wide variety of valuable tools for Computer-Aided
Engineering (CAE) and Industrial Engineering. However, despite the exponential
increase in computational capabilities and Artificial Intelligence (AI)
methods, many of the visionary perspectives on cybernetic automation of design,
engineering, and development have not been successfully pursued or realized
yet. While contemporary research trends and movements such as Industry 4.0
primarily target progress by connected automation in manufacturing and
production, the objective of this paper is to survey progress and formulate
perspectives targeted on the automation and autonomization of engineering
development processes. Based on an interdisciplinary mini-review, this work
identifies open challenges, synergies, and research opportunities towards the
realization of resource-efficient cooperative engineering and development
systems. In order to go beyond conventional human-centered, tool-based CAE
approaches and realize Computational Intelligence Driven Development processes,
it is suggested to extend the framework of Computational Rationality to
challenges in design, engineering and development."
710,"Education and
further research on general formal design theories and engineering science seem
therefore of crucial importance for automation of engineering design and development.","There
are still many aspects of design and engineering which have not yet been rigorously
formalized and which thus still pose open challenges and opportunities.",Computational physics and uncertainty quantification.,2021-12-27 19:11:34+00:00,Computational Rational Engineering and Development: Synergies and Opportunities,cs.CY,"['cs.CY', 'cs.SY', 'eess.SY']",[arxiv.Result.Author('Ramses Sala')],"Research and development in computer technology and computational methods
have resulted in a wide variety of valuable tools for Computer-Aided
Engineering (CAE) and Industrial Engineering. However, despite the exponential
increase in computational capabilities and Artificial Intelligence (AI)
methods, many of the visionary perspectives on cybernetic automation of design,
engineering, and development have not been successfully pursued or realized
yet. While contemporary research trends and movements such as Industry 4.0
primarily target progress by connected automation in manufacturing and
production, the objective of this paper is to survey progress and formulate
perspectives targeted on the automation and autonomization of engineering
development processes. Based on an interdisciplinary mini-review, this work
identifies open challenges, synergies, and research opportunities towards the
realization of resource-efficient cooperative engineering and development
systems. In order to go beyond conventional human-centered, tool-based CAE
approaches and realize Computational Intelligence Driven Development processes,
it is suggested to extend the framework of Computational Rationality to
challenges in design, engineering and development."
711,"General frameworks for MSO-workflows that include automated agents for decisions
regarding modeling accuracy, model parameterization, algorithm selection, and
computational resources, are however still lacking, and seem a promising direction for
further research.","These
examples demonstrate the use and potential of automated Modeling Simulation and
Optimization (MSO) workflows for specific applications of industrial relevance.","In the context of massive complex software systems, the use of
Bayesian Optimization was proposed relatively recently in [97].",2021-12-27 19:11:34+00:00,Computational Rational Engineering and Development: Synergies and Opportunities,cs.CY,"['cs.CY', 'cs.SY', 'eess.SY']",[arxiv.Result.Author('Ramses Sala')],"Research and development in computer technology and computational methods
have resulted in a wide variety of valuable tools for Computer-Aided
Engineering (CAE) and Industrial Engineering. However, despite the exponential
increase in computational capabilities and Artificial Intelligence (AI)
methods, many of the visionary perspectives on cybernetic automation of design,
engineering, and development have not been successfully pursued or realized
yet. While contemporary research trends and movements such as Industry 4.0
primarily target progress by connected automation in manufacturing and
production, the objective of this paper is to survey progress and formulate
perspectives targeted on the automation and autonomization of engineering
development processes. Based on an interdisciplinary mini-review, this work
identifies open challenges, synergies, and research opportunities towards the
realization of resource-efficient cooperative engineering and development
systems. In order to go beyond conventional human-centered, tool-based CAE
approaches and realize Computational Intelligence Driven Development processes,
it is suggested to extend the framework of Computational Rationality to
challenges in design, engineering and development."
717,Answers to these concerns could be considered for further research and studies.,"Further, a record might
belong to privileged class in one use case and unprivileged class in another, making it difﬁcult to have strict guidelines
for privileged class selection.","12
                                Fairness Score and Certiﬁcation Standardization in AI Systems

11 Declarations

Funding The authors did not receive support from any organization for the submitted work.",2022-01-10 15:45:12+00:00,Fairness Score and Process Standardization: Framework for Fairness Certification in Artificial Intelligence Systems,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Avinash Agarwal'), arxiv.Result.Author('Harsh Agarwal'), arxiv.Result.Author('Nihaarika Agarwal')]","Decisions made by various Artificial Intelligence (AI) systems greatly
influence our day-to-day lives. With the increasing use of AI systems, it
becomes crucial to know that they are fair, identify the underlying biases in
their decision-making, and create a standardized framework to ascertain their
fairness. In this paper, we propose a novel Fairness Score to measure the
fairness of a data-driven AI system and a Standard Operating Procedure (SOP)
for issuing Fairness Certification for such systems. Fairness Score and audit
process standardization will ensure quality, reduce ambiguity, enable
comparison and improve the trustworthiness of the AI systems. It will also
provide a framework to operationalise the concept of fairness and facilitate
the commercial deployment of such systems. Furthermore, a Fairness Certificate
issued by a designated third-party auditing agency following the standardized
process would boost the conviction of the organizations in the AI systems that
they intend to deploy. The Bias Index proposed in this paper also reveals
comparative bias amongst the various protected attributes within the dataset.
To substantiate the proposed framework, we iteratively train a model on biased
and unbiased data using multiple datasets and check that the Fairness Score and
the proposed process correctly identify the biases and judge the fairness."
718,"Arguably, further research
could utilize a subset of reviews that would provide more context, and ergo
the results of a new topic labeling system could provide more nuance for the
student.","Moreover, the reviews considered for the analysis were not
further ﬁltered by length and contextual richness.","There are reasons to believe artiﬁcial intelligence and community-driven
tools can help improve the overall system.",2022-01-11 10:24:49+00:00,Large Scale Analysis of Open MOOC Reviews to Support Learners' Course Selection,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('Mario Calderón'), arxiv.Result.Author('Victor Sánchez'), arxiv.Result.Author('Félix J. García Clemente'), arxiv.Result.Author('José A. Ruipérez-Valiente')]","The recent pandemic has changed the way we see education. It is not
surprising that children and college students are not the only ones using
online education. Millions of adults have signed up for online classes and
courses during last years, and MOOC providers, such as Coursera or edX, are
reporting millions of new users signing up in their platforms. However,
students do face some challenges when choosing courses. Though online review
systems are standard among many verticals, no standardized or fully
decentralized review systems exist in the MOOC ecosystem. In this vein, we
believe that there is an opportunity to leverage available open MOOC reviews in
order to build simpler and more transparent reviewing systems, allowing users
to really identify the best courses out there. Specifically, in our research we
analyze 2.4 million reviews (which is the largest MOOC reviews dataset used
until now) from five different platforms in order to determine the following:
(1) if the numeric ratings provide discriminant information to learners, (2) if
NLP-driven sentiment analysis on textual reviews could provide valuable
information to learners, (3) if we can leverage NLP-driven topic finding
techniques to infer themes that could be important for learners, and (4) if we
can use these models to effectively characterize MOOCs based on the open
reviews. Results show that numeric ratings are clearly biased (63\% of them are
5-star ratings), and the topic modeling reveals some interesting topics related
with course advertisements, the real applicability, or the difficulty of the
different courses. We expect our study to shed some light on the area and
promote a more transparent approach in online education reviews, which are
becoming more and more popular as we enter the post-pandemic era."
719,"For
the further study, the dataset is normalized between 0 & 1 by     No.","of Input Output MAE
for the prediction of active cases per day in Maharashtra.","Learning hidden layers window window
MinMax scaler.",2022-01-12 16:26:14+00:00,Explainable AI Framework for COVID-19 Prediction in Different Provinces of India,cs.CY,['cs.CY'],"[arxiv.Result.Author('Mredulraj S. Pandianchery'), arxiv.Result.Author('Gopalakrishnan E. A'), arxiv.Result.Author('Sowmya V'), arxiv.Result.Author('Vinayakumar Ravi'), arxiv.Result.Author('Soman K. P')]","In 2020, covid-19 virus had reached more than 200 countries. Till December
20th 2021, 221 nations in the world had collectively reported 275M confirmed
cases of covid-19 & total death toll of 5.37M. Many countries which include
United States, India, Brazil, United Kingdom, Russia etc were badly affected by
covid-19 pandemic due to the large population. The total confirmed cases
reported in this country are 51.7M, 34.7M, 22.2M, 11.3M, 10.2M respectively
till December 20, 2021. This pandemic can be controlled with the help of
precautionary steps by government & civilians of the country. The early
prediction of covid-19 cases helps to track the transmission dynamics & alert
the government to take the necessary precautions. Recurrent Deep learning
algorithms is a data driven model which plays a key role to capture the
patterns present in time series data. In many literatures, the Recurrent Neural
Network (RNN) based model are proposed for the efficient prediction of COVID-19
cases for different provinces. The study in the literature doesnt involve the
interpretation of the model behavior & robustness. In this study, The LSTM
model is proposed for the efficient prediction of active cases in each
provinces of India. The active cases dataset for each province in India is
taken from John Hopkins publicly available dataset for the duration from 10th
June, 2020 to 4th August, 2021. The proposed LSTM model is trained on one state
i.e., Maharashtra and tested for rest of the provinces in India. The concept of
Explainable AI is involved in this study for the better interpretation &
understanding of the model behavior. The proposed model is used to forecast the
active cases in India from 16th December, 2021 to 5th March, 2022. It is
notated that there will be a emergence of third wave on January, 2022 in India."
720,"In proposed approach-2, the large value of      75th to 203rd day of prediction is considered for further study
absolute error between actual & predicted data has been     of proposed approach-1&2.",LSTM model.,"It is difﬁcult to differentiate the
notated between 75th and 203rd day of prediction while the  heatmaps of proposed approach-1&2 visually.",2022-01-12 16:26:14+00:00,Explainable AI Framework for COVID-19 Prediction in Different Provinces of India,cs.CY,['cs.CY'],"[arxiv.Result.Author('Mredulraj S. Pandianchery'), arxiv.Result.Author('Gopalakrishnan E. A'), arxiv.Result.Author('Sowmya V'), arxiv.Result.Author('Vinayakumar Ravi'), arxiv.Result.Author('Soman K. P')]","In 2020, covid-19 virus had reached more than 200 countries. Till December
20th 2021, 221 nations in the world had collectively reported 275M confirmed
cases of covid-19 & total death toll of 5.37M. Many countries which include
United States, India, Brazil, United Kingdom, Russia etc were badly affected by
covid-19 pandemic due to the large population. The total confirmed cases
reported in this country are 51.7M, 34.7M, 22.2M, 11.3M, 10.2M respectively
till December 20, 2021. This pandemic can be controlled with the help of
precautionary steps by government & civilians of the country. The early
prediction of covid-19 cases helps to track the transmission dynamics & alert
the government to take the necessary precautions. Recurrent Deep learning
algorithms is a data driven model which plays a key role to capture the
patterns present in time series data. In many literatures, the Recurrent Neural
Network (RNN) based model are proposed for the efficient prediction of COVID-19
cases for different provinces. The study in the literature doesnt involve the
interpretation of the model behavior & robustness. In this study, The LSTM
model is proposed for the efficient prediction of active cases in each
provinces of India. The active cases dataset for each province in India is
taken from John Hopkins publicly available dataset for the duration from 10th
June, 2020 to 4th August, 2021. The proposed LSTM model is trained on one state
i.e., Maharashtra and tested for rest of the provinces in India. The concept of
Explainable AI is involved in this study for the better interpretation &
understanding of the model behavior. The proposed model is used to forecast the
active cases in India from 16th December, 2021 to 5th March, 2022. It is
notated that there will be a emergence of third wave on January, 2022 in India."
721,"For
interpretation and understanding from the analysis of the deep    the further study, the dataset is normalized between 0 & 1 by
learning models.","GRU, Stacked RNN, Stacked LSTM & Stacked GRU are used
The term “Explainable Artiﬁcial Intelligence” helps to do the     for the prediction of active cases per day in Maharashtra.",It helps to interpret the decision made in the   MinMax scaler.,2022-01-12 16:26:14+00:00,Explainable AI Framework for COVID-19 Prediction in Different Provinces of India,cs.CY,['cs.CY'],"[arxiv.Result.Author('Mredulraj S. Pandianchery'), arxiv.Result.Author('Gopalakrishnan E. A'), arxiv.Result.Author('Sowmya V'), arxiv.Result.Author('Vinayakumar Ravi'), arxiv.Result.Author('Soman K. P')]","In 2020, covid-19 virus had reached more than 200 countries. Till December
20th 2021, 221 nations in the world had collectively reported 275M confirmed
cases of covid-19 & total death toll of 5.37M. Many countries which include
United States, India, Brazil, United Kingdom, Russia etc were badly affected by
covid-19 pandemic due to the large population. The total confirmed cases
reported in this country are 51.7M, 34.7M, 22.2M, 11.3M, 10.2M respectively
till December 20, 2021. This pandemic can be controlled with the help of
precautionary steps by government & civilians of the country. The early
prediction of covid-19 cases helps to track the transmission dynamics & alert
the government to take the necessary precautions. Recurrent Deep learning
algorithms is a data driven model which plays a key role to capture the
patterns present in time series data. In many literatures, the Recurrent Neural
Network (RNN) based model are proposed for the efficient prediction of COVID-19
cases for different provinces. The study in the literature doesnt involve the
interpretation of the model behavior & robustness. In this study, The LSTM
model is proposed for the efficient prediction of active cases in each
provinces of India. The active cases dataset for each province in India is
taken from John Hopkins publicly available dataset for the duration from 10th
June, 2020 to 4th August, 2021. The proposed LSTM model is trained on one state
i.e., Maharashtra and tested for rest of the provinces in India. The concept of
Explainable AI is involved in this study for the better interpretation &
understanding of the model behavior. The proposed model is used to forecast the
active cases in India from 16th December, 2021 to 5th March, 2022. It is
notated that there will be a emergence of third wave on January, 2022 in India."
722,"So, the output value of LSTM layer from
                                                                   75th to 203rd day of prediction is considered for further study
                                                                   of proposed approach-1&2.","In proposed approach-2, the large value of
                                                                   absolute error between actual & predicted data has been
                                                                   notated between 75th and 203rd day of prediction while the
                                                                   model is tested.","It is difﬁcult to differentiate the
                                                                   heatmaps of proposed approach-1&2 visually.",2022-01-12 16:26:14+00:00,Explainable AI Framework for COVID-19 Prediction in Different Provinces of India,cs.CY,['cs.CY'],"[arxiv.Result.Author('Mredulraj S. Pandianchery'), arxiv.Result.Author('Gopalakrishnan E. A'), arxiv.Result.Author('Sowmya V'), arxiv.Result.Author('Vinayakumar Ravi'), arxiv.Result.Author('Soman K. P')]","In 2020, covid-19 virus had reached more than 200 countries. Till December
20th 2021, 221 nations in the world had collectively reported 275M confirmed
cases of covid-19 & total death toll of 5.37M. Many countries which include
United States, India, Brazil, United Kingdom, Russia etc were badly affected by
covid-19 pandemic due to the large population. The total confirmed cases
reported in this country are 51.7M, 34.7M, 22.2M, 11.3M, 10.2M respectively
till December 20, 2021. This pandemic can be controlled with the help of
precautionary steps by government & civilians of the country. The early
prediction of covid-19 cases helps to track the transmission dynamics & alert
the government to take the necessary precautions. Recurrent Deep learning
algorithms is a data driven model which plays a key role to capture the
patterns present in time series data. In many literatures, the Recurrent Neural
Network (RNN) based model are proposed for the efficient prediction of COVID-19
cases for different provinces. The study in the literature doesnt involve the
interpretation of the model behavior & robustness. In this study, The LSTM
model is proposed for the efficient prediction of active cases in each
provinces of India. The active cases dataset for each province in India is
taken from John Hopkins publicly available dataset for the duration from 10th
June, 2020 to 4th August, 2021. The proposed LSTM model is trained on one state
i.e., Maharashtra and tested for rest of the provinces in India. The concept of
Explainable AI is involved in this study for the better interpretation &
understanding of the model behavior. The proposed model is used to forecast the
active cases in India from 16th December, 2021 to 5th March, 2022. It is
notated that there will be a emergence of third wave on January, 2022 in India."
723,"Since augmented reality in this paper is considered in the process of distance
learning, further research should focus on the feasibility of using augmented reality in the
process of blended learning.","In [10] the elements of the
methodology of using the mobile application Electricity AR in the process of laboratory work
were developed.","According to J. J. Stephan, A. S. Ahmed, A. H. Omran [11] there is a need to improve
and develop the theory of blended learning through the use of a virtual reality environment to
make it more effective.",2022-01-13 16:54:36+00:00,Use of augmented and virtual reality tools in a general secondary education institution in the context of blended learning,cs.CY,['cs.CY'],"[arxiv.Result.Author('Valentyna Kovalenko'), arxiv.Result.Author('Maiia Marienko'), arxiv.Result.Author('Alisa Sukhikh')]","The study examines the problem of using augmented and virtual reality in the
process of blended learning in general secondary education. The study analyzes
the meaning of the concept of ""blended learning"". The conceptual principles of
blended learning are considered. The definition of augmented and virtual
reality is given. The mixed reality is considered as a separate kind of notion.
Separate applications of virtual and augmented reality that can be used in the
process of blended learning are considered. As a result of the study, the
authors propose possible ways to use augmented reality in the educational
process. The model of using augmented and virtual reality in blended learning
in general secondary education institutions was designed. It consists of the
following blocks: goal; teacher's activity; forms of education; teaching
methods; teaching aids; organizational forms of education; pupil activity and
results. Based on the model, the methodology of using augmented and virtual
reality in blended learning in general secondary education was developed. The
methodology contains the following components: target component, content
component, technological component and resultant component. The methodology is
quite universal and can be used for any subject in general secondary education.
The types of lessons in which it is expedient to use augmented (AR) and virtual
reality(VR) are determined. Recommendations are given at which stage of the
lesson it is better to use AR and VR tools (depending on the type of lesson)."
724,"Therefore, the use of virtual and auxiliary reality technologies in the educational process is
poorly understood, but nevertheless relevant for further research.","In Ukraine, the above mentioned technologies are used in small quantities today,
because these devices and their software are too expensive for most educational institutions.","78
DOI: 10.33407/itlt.v86i6.4664  ISSN: 2076-8184.",2022-01-13 16:54:36+00:00,Use of augmented and virtual reality tools in a general secondary education institution in the context of blended learning,cs.CY,['cs.CY'],"[arxiv.Result.Author('Valentyna Kovalenko'), arxiv.Result.Author('Maiia Marienko'), arxiv.Result.Author('Alisa Sukhikh')]","The study examines the problem of using augmented and virtual reality in the
process of blended learning in general secondary education. The study analyzes
the meaning of the concept of ""blended learning"". The conceptual principles of
blended learning are considered. The definition of augmented and virtual
reality is given. The mixed reality is considered as a separate kind of notion.
Separate applications of virtual and augmented reality that can be used in the
process of blended learning are considered. As a result of the study, the
authors propose possible ways to use augmented reality in the educational
process. The model of using augmented and virtual reality in blended learning
in general secondary education institutions was designed. It consists of the
following blocks: goal; teacher's activity; forms of education; teaching
methods; teaching aids; organizational forms of education; pupil activity and
results. Based on the model, the methodology of using augmented and virtual
reality in blended learning in general secondary education was developed. The
methodology contains the following components: target component, content
component, technological component and resultant component. The methodology is
quite universal and can be used for any subject in general secondary education.
The types of lessons in which it is expedient to use augmented (AR) and virtual
reality(VR) are determined. Recommendations are given at which stage of the
lesson it is better to use AR and VR tools (depending on the type of lesson)."
725,"We see the prospects of further research in the elaboration of guidelines on the use of
augmented reality in the process of blended learning in general secondary education.","The possible ways to use augmented reality suggest:
        the need to transform expensive technologies into budget options suitable for

          smartphones and simple computers;
        augmented reality technologies should be aimed at acquiring skills, transferring and

          controlling knowledge.","FINANCING

       The article presents the results of the study ""Use of digital technologies in the process of
blended learning in general secondary education"", the winner of the competitive selection for
2021 applied research to support young scientists working (studying) in subordinate
institutions of NAES of Ukraine (Resolution of the Presidium of NAES of Ukraine of
February 1, 2021, No 1-2 / 2-13).",2022-01-13 16:54:36+00:00,Use of augmented and virtual reality tools in a general secondary education institution in the context of blended learning,cs.CY,['cs.CY'],"[arxiv.Result.Author('Valentyna Kovalenko'), arxiv.Result.Author('Maiia Marienko'), arxiv.Result.Author('Alisa Sukhikh')]","The study examines the problem of using augmented and virtual reality in the
process of blended learning in general secondary education. The study analyzes
the meaning of the concept of ""blended learning"". The conceptual principles of
blended learning are considered. The definition of augmented and virtual
reality is given. The mixed reality is considered as a separate kind of notion.
Separate applications of virtual and augmented reality that can be used in the
process of blended learning are considered. As a result of the study, the
authors propose possible ways to use augmented reality in the educational
process. The model of using augmented and virtual reality in blended learning
in general secondary education institutions was designed. It consists of the
following blocks: goal; teacher's activity; forms of education; teaching
methods; teaching aids; organizational forms of education; pupil activity and
results. Based on the model, the methodology of using augmented and virtual
reality in blended learning in general secondary education was developed. The
methodology contains the following components: target component, content
component, technological component and resultant component. The methodology is
quite universal and can be used for any subject in general secondary education.
The types of lessons in which it is expedient to use augmented (AR) and virtual
reality(VR) are determined. Recommendations are given at which stage of the
lesson it is better to use AR and VR tools (depending on the type of lesson)."
1000,"One of the most interesting questions that can arise from the analysis of the re-
               sults, and that should require further study, is: Are teachers really aware of the
               possibilities of chatbots in the classroom?","We do not have any kind of expla-
               nation for this behaviour, other than technologies are perceived, and adopted, in a
               diﬀerent way depending on background and, apparently, gender.","The survey only listed a few function-
               alities for the chatbots and just a few subjects selected the option ”Others”.",2022-01-25 13:04:45+00:00,Chatbots and messaging platforms in the classroom: an analysis from the teacher's perspective,cs.CY,"['cs.CY', 'cs.HC', 'K.3.1; J.0']","[arxiv.Result.Author('J. J. Merelo'), arxiv.Result.Author('P. A. Castillo'), arxiv.Result.Author('Antonio M. Mora'), arxiv.Result.Author('Francisco Barranco'), arxiv.Result.Author('Noorhan Abbas'), arxiv.Result.Author('Alberto Guillen'), arxiv.Result.Author('Olia Tsivitanidou')]","Introducing new technologies such as messaging platforms, and the chatbots
attached to them, in higher education, is rapidly growing. This introduction
entails a careful consideration of the potential opportunities and/or
challenges of adopting these tools. Hence, a thorough examination of the
teachers' experiences in this discipline can shed light on the effective ways
of enhancing students' learning and boosting their progress. In this
contribution, we have surveyed the opinions of tertiary education teachers
based in Spain (mainly) and Spanish-speaking countries. The focus of these
surveys is to collect teachers' feedback about their opinions regarding the
introduction of the messaging platforms and chatbots in their classes,
understand their needs and to gather information about the various educational
use cases where these tools are valuable. In addition, an analysis of how and
when teachers' opinions towards the use of these tools can vary across gender,
experience, and their discipline of specialisation is presented. The key
findings of this study highlight the factors that can contribute to the
advancement of the adoption of messaging platforms and chatbots in higher
education institutions to achieve the desired learning outcomes."
1001,"This will probably require further study, but also will need to be taken
               into account when introducing chatbot technologies in the classroom: it will have
               to be as simple, and as satisfactory, as possible, to (possibly) change this existing
               perception.","We can speculate that their opinions towards chatbots are informed by negative
               experiences with customer support chatbots, which is what most people will have
               experienced.","Regarding gender grouping, both genders agree in their uses, so it seems not rel-
               evant at all.",2022-01-25 13:04:45+00:00,Chatbots and messaging platforms in the classroom: an analysis from the teacher's perspective,cs.CY,"['cs.CY', 'cs.HC', 'K.3.1; J.0']","[arxiv.Result.Author('J. J. Merelo'), arxiv.Result.Author('P. A. Castillo'), arxiv.Result.Author('Antonio M. Mora'), arxiv.Result.Author('Francisco Barranco'), arxiv.Result.Author('Noorhan Abbas'), arxiv.Result.Author('Alberto Guillen'), arxiv.Result.Author('Olia Tsivitanidou')]","Introducing new technologies such as messaging platforms, and the chatbots
attached to them, in higher education, is rapidly growing. This introduction
entails a careful consideration of the potential opportunities and/or
challenges of adopting these tools. Hence, a thorough examination of the
teachers' experiences in this discipline can shed light on the effective ways
of enhancing students' learning and boosting their progress. In this
contribution, we have surveyed the opinions of tertiary education teachers
based in Spain (mainly) and Spanish-speaking countries. The focus of these
surveys is to collect teachers' feedback about their opinions regarding the
introduction of the messaging platforms and chatbots in their classes,
understand their needs and to gather information about the various educational
use cases where these tools are valuable. In addition, an analysis of how and
when teachers' opinions towards the use of these tools can vary across gender,
experience, and their discipline of specialisation is presented. The key
findings of this study highlight the factors that can contribute to the
advancement of the adoption of messaging platforms and chatbots in higher
education institutions to achieve the desired learning outcomes."
1162,They constitute major agendas for further research.,"At this stage, we do not claim to be able to answer these difﬁcult but
unavoidable questions.","6 Conclusions

Supporting the decision activities of some client (potentially a decision maker)
can certainly be characterised by the use of formal and abstract models.",2022-01-28 12:20:18+00:00,What is Legitimate Decision Support?,cs.CY,['cs.CY'],"[arxiv.Result.Author('Yves Meinard'), arxiv.Result.Author('Alexis Tsoukiàs')]","Decision support is the science and associated practice that consist in
providing recommendations to decision makers facing problems, based on
available theoretical knowledge and empirical data. Although this activity is
often seen as being concerned with solving mathematical problems and conceiving
algorithms, it is essentially an empirical and socially framed activity, where
interactions between clients and analysts, and between them and concerned third
parties, play a crucial role. Since the 80s, two concepts have structured the
literature devoted to analysing this aspect of decision support: validity and
legitimacy. Whereas validity is focused on the interactions between the client
and the analyst, legitimacy refers to the broader picture: the organisational
context, the overall problem situation, the environment, culture, history.
Despite its importance, this concept has not received the attention it deserves
in the literature in decision support. The present paper aims at filling this
gap. For that purpose, we review the literature in other disciplines relevant
to elaborate a concept of legitimacy useful in decision support contexts. Based
on this review, we propose a general theory of legitimacy, adapted to decision
support contexts, encompassing the relevant contributions we found in the
literature. According to this general theory, a legitimate decision support
intervention is one for which the decision support provider produces a
justification that satisfies two conditions: (i) it effectively convinces the
decision support provider's interlocutors (effectiveness condition) and (ii) it
is organised around the active elicitation of as many and as diverse
counterarguments as possible (truthfulness condition). Despite its conceptual
simplicity, legitimacy, understood in this sense, is a very exacting
requirement, opening ambitious research avenues that we delineate."
1298,"Predatory venues have the consequence of decreasing diversity in
the ﬁeld of AI because those in underrepresented populations attend low-quality conferences
and are discouraged from further research.","The seeming pressure and
need to present at ”prestigious” venues perpetuates the cycle of students being drawn into
predatory conferences.","By not being able to present at and participate
in mainstream ML conferences such as NeurIPS, ICML, ICLR, etc.",2022-01-26 02:04:19+00:00,PreDefense: Defending Underserved AI Students and Researchers from Predatory Conferences,cs.CY,['cs.CY'],[arxiv.Result.Author('Thomas Y. Chen')],"Mentorship in the AI community is crucial to maintaining and increasing
diversity, especially with respect to fostering the academic growth of
underserved students. While the research process itself is important, there is
not sufficient emphasis on the submission, presentation, and publication
process, which is a cause for concern given the meteoric rise of predatory
scientific conferences, which are based on profit only and have little to no
peer review. These conferences are a direct threat to integrity in science by
promoting work with little to no scientific merit. However, they also threaten
diversity in the AI community by marginalizing underrepresented groups away
from legitimate conferences due to convenience and targeting mechanisms like
e-mail invitations. Due to the importance of conference presentation in AI
research, this very specific problem must be addressed through direct
mentorship. In this work, we propose PreDefense, a mentorship program that
seeks to guide underrepresented students through the scientific conference and
workshop process, with an emphasis on choosing legitimate venues that align
with the specific work that the students are focused in and preparing students
of all backgrounds for future successful, integrous AI research careers."
1443,"considered, including loss of immunity induced by time, and perhaps booster
doses of the vaccine — we leave this as a direction for further research.","Simulations with cases-imposed lockdown, for dif-
ferent combinations of parameters hlock and tlock (see Table 4).We present
cumulative cases, hospitalized and deceased for both GBR (on the left) and
ISR (on the right).","Furthermore, we have investigated the eﬀects of diﬀerent containment
measures w.r.t.",2022-02-02 18:43:05+00:00,A Hybrid Compartmental Model with a Case Study of COVID-19 in Great Britain and Israel,cs.CY,"['cs.CY', 'physics.soc-ph', 'q-bio.PE']","[arxiv.Result.Author('Greta Malaspina'), arxiv.Result.Author('Stevo Racković'), arxiv.Result.Author('Filipa Valdeira')]","Given the severe impact of COVID-19 on several societal levels, it is of
crucial importance to model the impact of restriction measures on the pandemic
evolution, so that governments are able to take informed decisions. Even though
there have been countless attempts to propose diverse models since the raise of
the outbreak, the increase in data availability and start of vaccination
campaigns calls for updated models and studies. Furthermore, most of the works
are focused on a very particular place or application and we strive to attain a
more general model, resorting to data from different countries. In particular,
we compare Great Britain and Israel, two highly different scenarios in terms of
vaccination plans and social structure. We build a network-based model, complex
enough to model different scenarios of government-mandated restrictions, but
generic enough to be applied to any population. To ease the computational load
we propose a decomposition strategy for our model."
1463,"The study determined that
Gen Alpha is similar to its predecessors, but that it carries on their ""legacy"" (Nagy &
Kö lcsey, 2017), despite the fact that further research is needed to fully comprehend this
new generation.","The study concludes that the label given
to this generation is based on marketing rather than science.",3.2.,2022-02-03 05:47:43+00:00,Generation Alpha: Understanding the Next Cohort of University Students,cs.CY,"['cs.CY', 'cs.SI']","[arxiv.Result.Author('Rushan Ziatdinov'), arxiv.Result.Author('Juanee Cilliers')]","Technology is changing at a blistering pace and is impacting on the way we
consider knowledge as a free commodity, along with the ability to apply skills,
concepts and understandings. Technology is aiding the way the world is
evolving, and its contributions to education are not an exemption. While
technology advances will play a crucial part in future teaching-learning
approaches, educators will also be challenged by the next higher-education
generation, the Alpha Generation. This entrepreneurial generation will embrace
the innovation, progressiveness, and advancement with the expectation that one
in two Generation Alphas will obtain a university degree. In anticipating the
educational challenges and opportunities of the future higher education
environment, this research reflected on Generation Alpha as the next cohort of
university students, considering their preferred learning styles, perceptions
and expectations relating to education. The research employed a theoretical
analysis based on the characteristics and traits that distinguishes Generation
Alpha, spearheaded by technology advances. The empirical investigation
considered three independent studies that were previous conducted by authors
from Slovakia, Hungary, Australia, and Turkey to understand the challenges and
opportunities pertaining to Generation Alpha. The research identified the
influence of social media, social connections, high levels of perceptions and
the Generation Alpha's ability to interpret information as strengths to
consider in future teaching-learning approaches in the higher education
environment. This research concluded with recommendations on how universities
could be transformed to ensure a better learning experience for Generation
Alpha students, aligned with their characteristics, perceptions and
expectations."
1495,"Some examples of accessible language and open
explanations include the following:

 – “You have the right to refuse to allow your data and samples to be used
    or shared for further research.","Before the consent boxes, a
well-structured document informs participants on the reasons for this study,
clariﬁes that they can choose to drop out without penalties at any point, pro-
vides a point of contact, explains what will happen in the study and what
are the risks to the subject.","Please check the appropriate box in the
    selection below.”

 – “There is a potential risk that your genetic information could be used
    to your disadvantage.",2022-02-03 17:25:46+00:00,Algorithmic Fairness Datasets: the Story so Far,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alessandro Fabris'), arxiv.Result.Author('Stefano Messina'), arxiv.Result.Author('Gianmaria Silvello'), arxiv.Result.Author('Gian Antonio Susto')]","Data-driven algorithms are being studied and deployed in diverse domains to
support critical decisions, directly impacting on people's well-being. As a
result, a growing community of algorithmic fairness researchers has been
investigating the equity of existing algorithms and proposing novel ones,
advancing the understanding of the risks and opportunities of automated
decision-making for different populations. Algorithmic fairness progress hinges
on data, which can be used appropriately only if adequately documented.
Unfortunately, the algorithmic fairness community, as a whole, suffers from a
collective data documentation debt caused by a lack of information on specific
resources (opacity) and scatteredness of available information (sparsity). In
this work, we survey over two hundred datasets employed in algorithmic fairness
research, producing standardized and searchable documentation for each of them,
along with in-depth documentation for the three most popular fairness datasets,
namely Adult, COMPAS and German Credit. These documentation efforts support
multiple contributions. Firstly, we summarize the merits and limitations of
popular algorithmic fairness datasets, questioning their suitability as
general-purpose fairness benchmarks. Secondly, we document hundreds of
available alternatives, annotating their domain and supported fairness tasks,
to assist dataset users in task-oriented and domain-oriented search. Finally,
we analyze these resources from the perspective of five important data curation
topics: anonymization, consent, inclusivity, labeling of sensitive attributes,
and transparency. We discuss different approaches and levels of attention to
these topics, making them tangible, and distill them into a set of best
practices for the curation of novel datasets."
1496,"Some examples of accessible language and open
explanations include the following:

 – “You have the right to refuse to allow your data and samples to be used
    or shared for further research.","Before the consent boxes,
a well-structured document informs participants on the reasons for this study,
clariﬁes that they can choose to drop out without penalties at any point, pro-
vides a point of contact, explains what will happen in the study and what
are the risks to the subject.","Please check the appropriate box in the
    selection below.”

  7 https://www.consentfultech.io/
36  Fabris, Messina, Silvello, Susto

 – “There is a potential risk that your genetic information could be used
    to your disadvantage.",2022-02-03 17:25:46+00:00,Algorithmic Fairness Datasets: the Story so Far,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alessandro Fabris'), arxiv.Result.Author('Stefano Messina'), arxiv.Result.Author('Gianmaria Silvello'), arxiv.Result.Author('Gian Antonio Susto')]","Data-driven algorithms are studied in diverse domains to support critical
decisions, directly impacting people's well-being. As a result, a growing
community of researchers has been investigating the equity of existing
algorithms and proposing novel ones, advancing the understanding of risks and
opportunities of automated decision-making for historically disadvantaged
populations. Progress in fair Machine Learning hinges on data, which can be
appropriately used only if adequately documented. Unfortunately, the
algorithmic fairness community suffers from a collective data documentation
debt caused by a lack of information on specific resources (opacity) and
scatteredness of available information (sparsity). In this work, we target data
documentation debt by surveying over two hundred datasets employed in
algorithmic fairness research, and producing standardized and searchable
documentation for each of them. Moreover we rigorously identify the three most
popular fairness datasets, namely Adult, COMPAS and German Credit, for which we
compile in-depth documentation.
  This unifying documentation effort supports multiple contributions. Firstly,
we summarize the merits and limitations of Adult, COMPAS and German Credit,
adding to and unifying recent scholarship, calling into question their
suitability as general-purpose fairness benchmarks. Secondly, we document and
summarize hundreds of available alternatives, annotating their domain and
supported fairness tasks, along with additional properties of interest for
fairness researchers. Finally, we analyze these datasets from the perspective
of five important data curation topics: anonymization, consent, inclusivity,
sensitive attributes, and transparency. We discuss different approaches and
levels of attention to these topics, making them tangible, and distill them
into a set of best practices for the curation of novel resources."
1497,"Some examples of accessible language and open
explanations include the following:

 – “You have the right to refuse to allow your data and samples to be used
    or shared for further research.","Before the consent boxes,
a well-structured document informs participants on the reasons for this study,
clariﬁes that they can choose to drop out without penalties at any point, pro-
vides a point of contact, explains what will happen in the study and what
are the risks to the subject.","Please check the appropriate box in the
    selection below.”

  7 https://www.consentfultech.io/
36  Fabris, Messina, Silvello, Susto

 – “There is a potential risk that your genetic information could be used
    to your disadvantage.",2022-02-03 17:25:46+00:00,Algorithmic Fairness Datasets: the Story so Far,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alessandro Fabris'), arxiv.Result.Author('Stefano Messina'), arxiv.Result.Author('Gianmaria Silvello'), arxiv.Result.Author('Gian Antonio Susto')]","Data-driven algorithms are studied in diverse domains to support critical
decisions, directly impacting people's well-being. As a result, a growing
community of researchers has been investigating the equity of existing
algorithms and proposing novel ones, advancing the understanding of risks and
opportunities of automated decision-making for historically disadvantaged
populations. Progress in fair Machine Learning hinges on data, which can be
appropriately used only if adequately documented. Unfortunately, the
algorithmic fairness community suffers from a collective data documentation
debt caused by a lack of information on specific resources (opacity) and
scatteredness of available information (sparsity). In this work, we target data
documentation debt by surveying over two hundred datasets employed in
algorithmic fairness research, and producing standardized and searchable
documentation for each of them. Moreover we rigorously identify the three most
popular fairness datasets, namely Adult, COMPAS and German Credit, for which we
compile in-depth documentation.
  This unifying documentation effort supports multiple contributions. Firstly,
we summarize the merits and limitations of Adult, COMPAS and German Credit,
adding to and unifying recent scholarship, calling into question their
suitability as general-purpose fairness benchmarks. Secondly, we document and
summarize hundreds of available alternatives, annotating their domain and
supported fairness tasks, along with additional properties of interest for
fairness researchers. Finally, we analyze these datasets from the perspective
of five important data curation topics: anonymization, consent, inclusivity,
sensitive attributes, and transparency. We discuss different approaches and
levels of attention to these topics, making them tangible, and distill them
into a set of best practices for the curation of novel resources."
1498,"Some examples of accessible language and open
explanations include the following:

 – “You have the right to refuse to allow your data and samples to be used
    or shared for further research.","Before the consent boxes,
a well-structured document informs participants on the reasons for this study,
clariﬁes that they can choose to drop out without penalties at any point, pro-
vides a point of contact, explains what will happen in the study and what
are the risks to the subject.","Please check the appropriate box in the
    selection below.”

  6 https://www.consentfultech.io/
Algorithmic Fairness Datasets: the Story so Far  37

 – “There is a potential risk that your genetic information could be used
    to your disadvantage.",2022-02-03 17:25:46+00:00,Algorithmic Fairness Datasets: the Story so Far,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alessandro Fabris'), arxiv.Result.Author('Stefano Messina'), arxiv.Result.Author('Gianmaria Silvello'), arxiv.Result.Author('Gian Antonio Susto')]","Data-driven algorithms are studied in diverse domains to support critical
decisions, directly impacting people's well-being. As a result, a growing
community of researchers has been investigating the equity of existing
algorithms and proposing novel ones, advancing the understanding of risks and
opportunities of automated decision-making for historically disadvantaged
populations. Progress in fair Machine Learning hinges on data, which can be
appropriately used only if adequately documented. Unfortunately, the
algorithmic fairness community suffers from a collective data documentation
debt caused by a lack of information on specific resources (opacity) and
scatteredness of available information (sparsity). In this work, we target data
documentation debt by surveying over two hundred datasets employed in
algorithmic fairness research, and producing standardized and searchable
documentation for each of them. Moreover we rigorously identify the three most
popular fairness datasets, namely Adult, COMPAS and German Credit, for which we
compile in-depth documentation.
  This unifying documentation effort supports multiple contributions. Firstly,
we summarize the merits and limitations of Adult, COMPAS and German Credit,
adding to and unifying recent scholarship, calling into question their
suitability as general-purpose fairness benchmarks. Secondly, we document and
summarize hundreds of available alternatives, annotating their domain and
supported fairness tasks, along with additional properties of interest for
fairness researchers. Finally, we analyze these datasets from the perspective
of five important data curation topics: anonymization, consent, inclusivity,
sensitive attributes, and transparency. We discuss different approaches and
levels of attention to these topics, making them tangible, and distill them
into a set of best practices for the curation of novel resources."
1575,"It will also be shown that identifying
such activity is an open problem and therefore is worthy of further research.","Then, some common challenges experienced by
practitioners trying to conduct reliable digital forensics will be examined and the specific
aspect of potential tampering of digital artefacts proposed as a useful example of an aspect of
digital forensic investigations that is contingent on trust.","3.1 The role of trust in digital forensics

Trust is a phenomenon experienced by all and is a fundamental part of the human experience,
providing a means for understanding and adapting to the complexity of our environment in
the face of uncertainty (Marsh, 1994).",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1576,"(2016) emphasise the potential
dangers, stating that detection of anti-forensic activity was worthy of further research and
initiatives.",Conlan et al.,"Their paper offered a new taxonomy on the subject, as well as a practical resource
to help digital forensic practitioners identify when it might have taken place.",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1577,"3.3 Shortcomings in identifying artefact tampering

Current literature also demonstrates that the issue identified in section 3.2, specifically the
identification of evidence tampering activity, is not a solved problem and therefore it requires
further research.","(2015), it could well be that it is also a common source of
misplaced trust and is therefore the reason this paper will study it in more detail in order to
consider the wider role of trust in digital forensics.","For example, Garfinkel (2007) provided details of some common ‘anti-
forensic’ techniques, stating that a major factor behind their supposed success was the limited
resources devoted to finding them by law enforcement agencies.",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1578,"(2016) noted
that a significant limitation of their work to provide an extended taxonomy on artefact
tampering techniques was the sheer number of tools available to conduct them, calling for
further research into anti-forensics to produce and accessible body of knowledge which they
feel is likely to be useful to practitioners in aiding them in their attempts at detection.",Conlan et al.,"Furthermore Casey (2018) proposes using what he terms ‘Digital Stratigraphy’ techniques to
improve the contextual analysis of digital artefacts during investigations to root out artefact
tampering, however he points out the need for tools to provide the relevant information in
order for this to be successful.",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1579,"This practical application of the theoretical
definition of Zero Trust Digital Forensics necessarily requires further research, but such work
is out of scope for this paper.","Certainly, challenges exist in understanding how the theoretical definition can be applied,
such as whether the strategy is too financially and computationally expensive for typical
investigations, whether adequate verification techniques exist and can be effectively
designed, and whether any remaining uncertainty can be properly understood and explained
correctly to a wide range of stakeholders.","As an aside Zero Trust Digital Forensics is here described as a strategy rather than a model to
be followed by practitioners.",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1580,"Thirdly, the practical application of Zero Trust Digital Forensics as a holistic strategy for
investigation requires further study.","To become a
reality however, practitioners need to be able to easily identify suitable verification
techniques, something which is non-trivial given the scale of digital forensics research, and
then apply those techniques to real cases.","The strategy as presented in this paper is purely
theoretical, and understanding its practical application is left for future work but it is argued
here that this is a crucial next step.",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1581,"Avenues such as these highlight the richness and potential gains that could be achieved with
further research into the application of Zero Trust Digital Forensics.","Applications of existing technologies, such as machine learning and
zero-knowledge proofs could potentially also be used in supporting artefact verification.","5.2 Current viability of Zero Trust Digital Forensics in relation to identifying artefact
    tampering

In this section, the specific aspect of identifying artefact tampering will again be the focus.",2022-02-05 19:54:57+00:00,The case for Zero Trust Digital Forensics,cs.CY,['cs.CY'],"[arxiv.Result.Author('Christoper Neale'), arxiv.Result.Author('Ian Kennedy'), arxiv.Result.Author('Blain Price'), arxiv.Result.Author('Bashar Nuseibeh')]","It is imperative for all stakeholders that digital forensics investigations
produce reliable results to ensure the field delivers a positive contribution
to the pursuit of justice across the globe. Some aspects of these
investigations are inevitably contingent on trust, however this is not always
explicitly considered or critically evaluated. Erroneously treating features of
the investigation as trusted can be enormously damaging to the overall
reliability of an investigations findings as well as the confidence that
external stakeholders can have in it. As an example, digital crime scenes can
be manipulated by tampering with the digital artefacts left on devices, yet
recent studies have shown that efforts to detect occurrences of this are rare
and argue that this leaves digital forensics investigations vulnerable to
accusations of inaccuracy. In this paper a new approach to digital forensics is
considered based on the concept of Zero Trust, an increasingly popular design
in network security. Zero Trust describes the practitioner mindset and
principles upon which the reliance on trust in network components is eliminated
in favour of dynamic verification of network interactions. An initial
definition of Zero Trust Digital Forensics will be proposed and then a specific
example considered showing how this strategy can be applied to digital forensic
investigations to mitigate against the specific risk of evidence tampering. A
definition of Zero Trust Digital Forensics is proposed, specifically that it is
a strategy adopted by investigators whereby each aspect of an investigation is
assumed to be unreliable until verified. A new principle will be introduced,
namely the multifaceted verification of digital artefacts that can be used by
practitioners who wish to adopt a Zero Trust Digital Forensics strategy during
their investigations..."
1806,"our results [36] publicly available to support further research     When a user creates a Google Analytics account, a unique identifier
        on this topic.","We make our implementation [35] along with             uniquely identified by a Tracking ID, formatted as UA-000000-1.","is created that acts as a prefix of Tracking IDs (i.e., the first set
                                                                            of numbers).",2022-02-10 14:59:17+00:00,Leveraging Google's Publisher-specific IDs to Detect Website Administration,cs.CY,"['cs.CY', 'K.4.2']","[arxiv.Result.Author('Emmanouil Papadogiannakis'), arxiv.Result.Author('Panagiotis Papadopoulos'), arxiv.Result.Author('Evangelos P. Markatos'), arxiv.Result.Author('Nicolas Kourtellis')]","Digital advertising is the most popular way for content monetization on the
Internet. Publishers spawn new websites, and older ones change hands with the
sole purpose of monetizing user traffic. In this ever-evolving ecosystem, it is
challenging to effectively answer questions such as: Which entities monetize
what websites? What categories of websites does an average entity typically
monetize on and how diverse are these websites? How has this website
administration ecosystem changed across time?
  In this paper, we propose a novel, graph-based methodology to detect
administration of websites on the Web, by exploiting the ad-related
publisher-specific IDs. We apply our methodology across the top 1 million
websites and study the characteristics of the created graphs of website
administration. Our findings show that approximately 90% of the websites are
associated each with a single publisher, and that small publishers tend to
manage less popular websites. We perform a historical analysis of up to 8
million websites, and find a new, constantly rising number of (intermediary)
publishers that control and monetize traffic from hundreds of websites, seeking
a share of the ad-market pie. We also observe that over time, websites tend to
move from big to smaller administrators."
1807,"Even though our              To support and enable further research on fake news, and
methodology has a high Precision score, we acknowledge               extensibility of our work, we make publicly available [29]:
that it might fail to detect some advertisements in websites.","7 Limitations
                                                                     Data & Code Availability
The analysis of funding received by advertisers relies on the
methodology presented in Section 3.2.1.",1.,2022-02-10 15:07:33+00:00,Who Funds Misinformation? A Systematic Analysis of the Ad-related Profit Routines of Fake News sites,cs.CY,"['cs.CY', 'K.4.2']","[arxiv.Result.Author('Emmanouil Papadogiannakis'), arxiv.Result.Author('Panagiotis Papadopoulos'), arxiv.Result.Author('Evangelos P. Markatos'), arxiv.Result.Author('Nicolas Kourtellis')]","Fake news is an age-old phenomenon, widely assumed to be associated with
political propaganda published to sway public opinion. Yet, with the growth of
social media it has become a lucrative business for web publishers. Despite
many studies performed and countermeasures deployed from researchers and
stakeholders, unreliable news sites have increased their share of engagement
among the top performing news sources in last years. Indeed, stifling fake news
impact depends on the efforts from the society, and the market, in limiting the
(economic) incentives of fake news producers.
  In this paper, we aim at enhancing the transparency around these exact
incentives and explore the following main questions: Who supports the existence
of fake news websites via paid ads, either as an advertiser or an ad seller?
Who owns these websites and what other Web business are they into? What
tracking activity do they perform in these websites?
  Aiming to answer these questions, we are the first to systematize the
auditing process of fake news revenue flows. We develop a novel ad detection
methodology to identify the companies that advertise in fake news websites and
the intermediary companies responsible for facilitating those ad revenues. We
study more than 2400 popular fake and real news websites and show that
well-known legitimate ad networks, such as of Google, IndexExchange, and
AppNexus, have a direct advertising relation with more than 40% of these fake
news websites, and a re-seller advertising relation with more than 60% of them.
Using a graph clustering approach on an extended set of 114.5K sites connected
with 443K edges, we show that entities who own fake news websites, also own (or
operate) other types of websites for entertainment, business, and politics,
pointing to the fact that owning a fake news website is part of a broader
business operation."
2007,"While the authors do touch on the subject of algorithmic literacy in this paper, further research
could investigate the implications of divisions in algorithmic awareness.","By drawing on established theories from multiple domains, it could also
foster more interdisciplinary collaboration.","For example, one survey
of internet users in Norway (where 98% of the population has internet access), found that
education is strongly linked to algorithm awareness, with low awareness highest among the
least educated group.",2022-02-12 14:14:32+00:00,"State of AI Ethics Report (Volume 6, February 2022)",cs.CY,"['cs.CY', 'cs.AI', 'K.4; I.2; A.1']","[arxiv.Result.Author('Abhishek Gupta'), arxiv.Result.Author('Connor Wright'), arxiv.Result.Author('Marianna Bergamaschi Ganapini'), arxiv.Result.Author('Masa Sweidan'), arxiv.Result.Author('Renjie Butalid')]","This report from the Montreal AI Ethics Institute (MAIEI) covers the most
salient progress in research and reporting over the second half of 2021 in the
field of AI ethics. Particular emphasis is placed on an ""Analysis of the AI
Ecosystem"", ""Privacy"", ""Bias"", ""Social Media and Problematic Information"", ""AI
Design and Governance"", ""Laws and Regulations"", ""Trends"", and other areas
covered in the ""Outside the Boxes"" section. The two AI spotlights feature
application pieces on ""Constructing and Deconstructing Gender with AI-Generated
Art"" as well as ""Will an Artificial Intellichef be Cooking Your Next Meal at a
Michelin Star Restaurant?"". Given MAIEI's mission to democratize AI,
submissions from external collaborators have featured, such as pieces on the
""Challenges of AI Development in Vietnam: Funding, Talent and Ethics"" and using
""Representation and Imagination for Preventing AI Harms"". The report is a
comprehensive overview of what the key issues in the field of AI ethics were in
2021, what trends are emergent, what gaps exist, and a peek into what to expect
from the field of AI ethics in 2022. It is a resource for researchers and
practitioners alike in the field to set their research and development agendas
to make contributions to the field of AI ethics."
2008,"In order to proceed
with its objective, the paper builds on recent academic calls for an international governance
coordinating committee for AI, for an international regulatory agency for AI etc., and draws on
existing scholarship in the area, and addresses itself to those individuals who will be involved in
setting up new institutions and those who are interested in conducting further research on
pragmatic institution building for AI governance.","This paper puts emphasis on the latter type of

The State of AI Ethics Report, Volume 6 (January 2022)  194
institutions, with particular focus on institutions set up by governments.","Building new AI governance institutions
The paper states that AI-specific governance institutions working on soft governance
mechanisms with non-binding rules have already come into existence.",2022-02-12 14:14:32+00:00,"State of AI Ethics Report (Volume 6, February 2022)",cs.CY,"['cs.CY', 'cs.AI', 'K.4; I.2; A.1']","[arxiv.Result.Author('Abhishek Gupta'), arxiv.Result.Author('Connor Wright'), arxiv.Result.Author('Marianna Bergamaschi Ganapini'), arxiv.Result.Author('Masa Sweidan'), arxiv.Result.Author('Renjie Butalid')]","This report from the Montreal AI Ethics Institute (MAIEI) covers the most
salient progress in research and reporting over the second half of 2021 in the
field of AI ethics. Particular emphasis is placed on an ""Analysis of the AI
Ecosystem"", ""Privacy"", ""Bias"", ""Social Media and Problematic Information"", ""AI
Design and Governance"", ""Laws and Regulations"", ""Trends"", and other areas
covered in the ""Outside the Boxes"" section. The two AI spotlights feature
application pieces on ""Constructing and Deconstructing Gender with AI-Generated
Art"" as well as ""Will an Artificial Intellichef be Cooking Your Next Meal at a
Michelin Star Restaurant?"". Given MAIEI's mission to democratize AI,
submissions from external collaborators have featured, such as pieces on the
""Challenges of AI Development in Vietnam: Funding, Talent and Ethics"" and using
""Representation and Imagination for Preventing AI Harms"". The report is a
comprehensive overview of what the key issues in the field of AI ethics were in
2021, what trends are emergent, what gaps exist, and a peek into what to expect
from the field of AI ethics in 2022. It is a resource for researchers and
practitioners alike in the field to set their research and development agendas
to make contributions to the field of AI ethics."
2010,"Experts also suggested encouraging or allowing    further research is needed to ascertain how important it is to
students to tangibly collaborate across disciplines as part of  embed education to develop the broad TAS skillset (i.e.","We believe
perspectives.",their required assessment for the class.,2022-02-04 14:55:15+00:00,Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum design,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Mohammad Naiseh'), arxiv.Result.Author('Caitlin Bentley'), arxiv.Result.Author('Sarvapali D. Ramchurn')]","Recent advances in artificial intelligence, specifically machine learning,
contributed positively to enhancing the autonomous systems industry, along with
introducing social, technical, legal and ethical challenges to make them
trustworthy. Although Trustworthy Autonomous Systems (TAS) is an established
and growing research direction that has been discussed in multiple disciplines,
e.g., Artificial Intelligence, Human-Computer Interaction, Law, and Psychology.
The impact of TAS on education curricula and required skills for future TAS
engineers has rarely been discussed in the literature. This study brings
together the collective insights from a number of TAS leading experts to
highlight significant challenges for curriculum design and potential TAS
required skills posed by the rapid emergence of TAS. Our analysis is of
interest not only to the TAS education community but also to other researchers,
as it offers ways to guide future research toward operationalising TAS
education."
2011,"We believe further research is needed
students to tangibly collaborate across disciplines as part of   to ascertain how important it is to embed education to develop
their required assessment for coursework.",Experts also suggested encouraging or allowing     for diverse TAS roles.,Multi-disciplinary     the broad TAS skillset (i.e.,2022-02-04 14:55:15+00:00,Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum design,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Mohammad Naiseh'), arxiv.Result.Author('Caitlin Bentley'), arxiv.Result.Author('Sarvapali D. Ramchurn')]","Recent advances in artificial intelligence, specifically machine learning,
contributed positively to enhancing the autonomous systems industry, along with
introducing social, technical, legal and ethical challenges to make them
trustworthy. Although Trustworthy Autonomous Systems (TAS) is an established
and growing research direction that has been discussed in multiple disciplines,
e.g., Artificial Intelligence, Human-Computer Interaction, Law, and Psychology.
The impact of TAS on education curricula and required skills for future TAS
engineers has rarely been discussed in the literature. This study brings
together the collective insights from a number of TAS leading experts to
highlight significant challenges for curriculum design and potential TAS
required skills posed by the rapid emergence of TAS. Our analysis is of
interest not only to the TAS education community but also to other researchers,
as it offers ways to guide future research toward operationalising TAS
education."
2012,"We believe further research is needed
to ascertain how important it is to embed education to develop     [5] Miller, R.A. and Luse, D.W., 2004.",for diverse TAS roles.,"Advancing the IS curricula: The
the broad TAS skillset (i.e.",2022-02-04 14:55:15+00:00,Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum design,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Mohammad Naiseh'), arxiv.Result.Author('Caitlin Bentley'), arxiv.Result.Author('Sarvapali D. Ramchurn')]","Recent advances in artificial intelligence, specifically machine learning,
contributed positively to enhancing the autonomous systems industry, along with
introducing social, technical, legal and ethical challenges to make them
trustworthy. Although Trustworthy Autonomous Systems (TAS) is an established
and growing research direction that has been discussed in multiple disciplines,
e.g., Artificial Intelligence, Human-Computer Interaction, Law, and Psychology.
The impact of TAS on education curricula and required skills for future TAS
engineers has rarely been discussed in the literature. This study brings
together the collective insights from a number of TAS leading experts to
highlight significant challenges for curriculum design and potential TAS
required skills posed by the rapid emergence of TAS. Our analysis is of
interest not only to the TAS education community but also to other researchers,
as it offers ways to guide future research toward operationalising TAS
education."
2014,"As        And Challenges,” Proceedings of the ASME 2021International
illustrated in Figure 8, it becomes essential to further study and   Design Engineering Technical Conferences and Computers and
quantify the potential correlations or mismatches between: (i) the   Information in Engineering Conference, IDETC/CIE2021,
environmental claims made by manufacturers or retailers (e.g.,       August 17-20, 2021, Virtual, Online.","Opportunities
sustainability attributes cannot guarantee their veracity.","in the product description or through an ecolabel), (ii) the              [9] McLennan, J.F., 2004, “The Philosophy of Sustainable
perception [21] of sustainable features by consumers (e.g.,          Design,” Ecotone Publishing Company LLC: Bainbridge Island,
captured through online product reviews), and (iii) the real         WA, USA.",2021-12-20 08:57:37+00:00,Can Online Customer Reviews Help Design More Sustainable Products? A Preliminary Study on Amazon Climate Pledge Friendly Products,cs.CY,"['cs.CY', 'cs.IR', 'cs.LG']","[arxiv.Result.Author('Michael Saidani'), arxiv.Result.Author('Harrison Kim'), arxiv.Result.Author('Nawres Ayadhi'), arxiv.Result.Author('Bernard Yannou')]","Online product reviews are a valuable resource for product developers to
improve the design of their products. Yet, the potential value of customer
feedback to improve the sustainability performance of products is still to be
exploited. The present paper investigates and analyzes Amazon product reviews
to bring new light on the following question: ``What sustainable design
insights can be identified or interpreted from online product reviews?''. To do
so, the top 100 reviews, evenly distributed by star ratings, for three product
categories (laptop, printer, cable) are collected, manually annotated, analyzed
and interpreted. For each product category, the reviews of two similar products
(one with environmental certification and one standard version) are compared
and combined to come up with sustainable design solutions. In all, for the six
products considered, between 12% and 20% of the reviews mentioned directly or
indirectly aspects or attributes that could be exploited to improve the design
of these products from a sustainability perspective. Concrete examples of
sustainable design leads that could be elicited from product reviews are given
and discussed. As such, this contribution provides a baseline for future work
willing to automate this process to gain further insights from online product
reviews. Notably, the deployment of machine learning tools and the use of
natural language processing techniques to do so are discussed as promising
lines for future research."
2016,"Recommendations – It is suggested that further research must be conducted to
understand how self-employed Filipino income earners comprehend NFT gaming and
cryptocurrency, impacting their level of interest and participation.","Conclusion – Understanding the cryptocurrency market requires comprehending the
perspective of the people who are engaged in a play-to-earn game, and their concerns
are critical for any government actions aimed at regulating self-employed income earners
playing (Non-fungible Tokens) NFT games in the Philippines.","Research Implications – Taxing NFT games without sound regulatory frameworks may
result in the disarray of this alternative income source.",2022-02-13 05:15:05+00:00,The Perception of Filipinos on the Advent of Cryptocurrency and Non-Fungible Token (NFT) Games,cs.CY,['cs.CY'],"[arxiv.Result.Author('Ryan Francisco'), arxiv.Result.Author('Nelson Rodelas'), arxiv.Result.Author('John Edison Ubaldo')]","This study aims to shed light on the rise of play-to-earn games in the
Philippines alongside cryptocurrency. The lack of research and public
understanding of its benefits and drawbacks prompted the researchers to
investigate its market. As such, the study tried to look into the risks and
benefits of crypto gaming if it would be regulated by the government, and how
market volatility influences the churn rate of crypto games. The research used
a descriptive study to determine the perception of people who are engaged in
playing a crypto-game named as Axie Infinity. The results showed that most
players spend their time playing Axie Infinity for about 1 to 4 hours a day.
Predominantly, the return of investments for playing the game will take about 1
to 3 months. It also showed that these players agreed that there is a possible
financial instability in a volatile market. With this, they have a high trust
issue in terms of price manipulation, privacy and security, and its design and
usability. Understanding the cryptocurrency market requires comprehending the
perspective of the people who are engaged in a play-to-earn game, and their
concerns are critical for any government actions aimed at regulating
self-employed income earners playing (Non-fungible Tokens) NFT games in the
Philippines."
2017,"It is suggested that further research must be conducted to understand how self-
employed Filipino income earners comprehend NFT gaming and cryptocurrency,
impacting their level of interest and participation.","Furthermore, the unregulated income-generating
crypto game and the lack of knowledge about the market resulted in a high trust issue
level in the cryptocurrency market.","It is also recommended to compare
how government regulation affected other investment markets to juxtapose to the
existing status quo within the cryptocurrency market.",2022-02-13 05:15:05+00:00,The Perception of Filipinos on the Advent of Cryptocurrency and Non-Fungible Token (NFT) Games,cs.CY,['cs.CY'],"[arxiv.Result.Author('Ryan Francisco'), arxiv.Result.Author('Nelson Rodelas'), arxiv.Result.Author('John Edison Ubaldo')]","This study aims to shed light on the rise of play-to-earn games in the
Philippines alongside cryptocurrency. The lack of research and public
understanding of its benefits and drawbacks prompted the researchers to
investigate its market. As such, the study tried to look into the risks and
benefits of crypto gaming if it would be regulated by the government, and how
market volatility influences the churn rate of crypto games. The research used
a descriptive study to determine the perception of people who are engaged in
playing a crypto-game named as Axie Infinity. The results showed that most
players spend their time playing Axie Infinity for about 1 to 4 hours a day.
Predominantly, the return of investments for playing the game will take about 1
to 3 months. It also showed that these players agreed that there is a possible
financial instability in a volatile market. With this, they have a high trust
issue in terms of price manipulation, privacy and security, and its design and
usability. Understanding the cryptocurrency market requires comprehending the
perspective of the people who are engaged in a play-to-earn game, and their
concerns are critical for any government actions aimed at regulating
self-employed income earners playing (Non-fungible Tokens) NFT games in the
Philippines."
2018,"We trust this system can both contribute to har-
                                                 vesting of global landslide data for further research and support global
                                                 landslide maps to facilitate emergency response and decision making.","The system was de-
                                                 ployed in February 2020 online at https://landslide-aidr.qcri.org/
                                                 landslide_system.php to monitor live Twitter data stream and has been
                                                 running continuously since then to provide time-critical information to
                                                 partners such as British Geological Survey and European Mediterranean
                                                 Seismological Centre.","Keywords: Landslide detection · Social media · Online system · Real
                                                 time · Image classiﬁcation · Computer vision · Artiﬁcial intelligence

                                        1 Introduction

                                        Landslides cause thousands of deaths and billions of dollars in infrastructural
                                        damage worldwide every year [13].",2022-02-14 14:24:57+00:00,A Real-time System for Detecting Landslide Reports on Social Media using Artificial Intelligence,cs.CY,"['cs.CY', 'cs.CV']","[arxiv.Result.Author('Ferda Ofli'), arxiv.Result.Author('Umair Qazi'), arxiv.Result.Author('Muhammad Imran'), arxiv.Result.Author('Julien Roch'), arxiv.Result.Author('Catherine Pennington'), arxiv.Result.Author('Vanessa Banks'), arxiv.Result.Author('Remy Bossu')]","This paper presents an online system that leverages social media data in real
time to identify landslide-related information automatically using
state-of-the-art artificial intelligence techniques. The designed system can
(i) reduce the information overload by eliminating duplicate and irrelevant
content, (ii) identify landslide images, (iii) infer geolocation of the images,
and (iv) categorize the user type (organization or person) of the account
sharing the information. The system was deployed in February 2020 online at
https://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter
data stream and has been running continuously since then to provide
time-critical information to partners such as British Geological Survey and
European Mediterranean Seismological Centre. We trust this system can both
contribute to harvesting of global landslide data for further research and
support global landslide maps to facilitate emergency response and decision
making."
2077,"Note that the number of distinct MIME types         To further study the usage of images and application-related
is different from the actual prevalance of web resources (URLs) with  MIME types, we explore how their usage varies across websites
these MIME types.","also see a rapid increase in the number of different application-
specific MIME types.",Figure 4b shows the total raw numbers of new        of different categories in Figure 5a and Figure 5b respectively.,2022-02-16 18:36:03+00:00,"""Way back then"": A Data-driven View of 25+ years of Web Evolution",cs.CY,['cs.CY'],"[arxiv.Result.Author('Vibhor Agarwal'), arxiv.Result.Author('Nishanth Sastry')]","Since the inception of the first web page three decades back, the Web has
evolved considerably, from static HTML pages in the beginning to the dynamic
web pages of today, from mainly the text-based pages of the 1990s to today's
multimedia rich pages, etc. Although much of this is known anecdotally, to our
knowledge, there is no quantitative documentation of the extent and timing of
these changes. This paper attempts to address this gap in the literature by
looking at the top 100 Alexa websites for over 25 years from the Internet
Archive or the ""Wayback Machine"", archive.org. We study the changes in
popularity, from Geocities and Yahoo! in the mid-to-late 1990s to the likes of
Google, Facebook, and Tiktok of today. We also look at different categories of
websites and their popularity over the years and find evidence for the decline
in popularity of news and education-related websites, which have been replaced
by streaming media and social networking sites. We explore the emergence and
relative prevalence of different MIME-types (text vs. image vs. video vs.
javascript and json) and study whether the use of text on the Internet is
declining."
2115,"We recommend further research to empirically understand individual choices to give an evaluative
  understanding of the interactions citizens have a reason to value.",Agenda.,"Our recommendation is for a rigorous under-
  standing of people’s choices, intentions, values, and motivations, irrespective of what developers/regulators think
  are good for citizens.",2022-02-17 09:48:12+00:00,The Political Economy of Privacy Enhancing Technologies,cs.CY,"['cs.CY', 'NA', 'K.4']","[arxiv.Result.Author('Partha Das Chowdhury'), arxiv.Result.Author('Andres Dominguez'), arxiv.Result.Author('Marvin Kopo Ramkapane'), arxiv.Result.Author('Awais Rashid')]","\ac{PETs} have increasingly become vital empowering tools in today's highly
datafied society. However, their development has been primarily concerned with
improving usability and ensuring confidentiality online. Privileging these
considerations might unintendedly lead to fixed ideas about users, but
diversity of thought, action, ability, and circumstance play a fundamental role
in the distortion and acceptance of any \ac{PETs}. In this paper we elaborate
some of the manifestations of the distortions, like inadequate and exclusory
design, and uneven distribution of costs and benefits. Drawing on Amartya Sen's
\emph{capability approach} we propose that a normative evaluation of personal,
social, and political diversities can be used as a foundation to conceptualize
and develop \ac{PETs}. We outline a research agenda based on this proposition
and suggest pertinent empirical and methodological research paths. Our
contribution offers an evaluative space to make inter-personal comparisons to
inform the development of \ac{PETs}."
2116,"We recommend further research to empirically understand individual choices to give an evaluative
  understanding of the interactions citizens have a reason to value.",Agenda.,"Our recommendation is for a rigorous under-
  standing of people’s choices, intentions, values, and motivations, irrespective of what developers/regulators think
  are good for citizens.",2022-02-17 09:48:12+00:00,The Political Economy of Privacy Enhancing Technologies,cs.CY,"['cs.CY', 'NA', 'K.4']","[arxiv.Result.Author('Partha Das Chowdhury'), arxiv.Result.Author('Andres Dominguez'), arxiv.Result.Author('Kopo M. Ramkapane'), arxiv.Result.Author('Awais Rashid')]","\ac{PETs} have increasingly become vital empowering tools in today's highly
datafied society. However, their development has been primarily concerned with
improving usability and ensuring confidentiality online. Privileging these
considerations might unintendedly lead to fixed ideas about users, but
diversity of thought, action, ability, and circumstance play a fundamental role
in the distortion and acceptance of any \ac{PETs}. In this paper we elaborate
some of the manifestations of the distortions, like inadequate and exclusory
design, and uneven distribution of costs and benefits. Drawing on Amartya Sen's
\emph{capability approach} we propose that a normative evaluation of personal,
social, and political diversities can be used as a foundation to conceptualize
and develop \ac{PETs}. We outline a research agenda based on this proposition
and suggest pertinent empirical and methodological research paths. Our
contribution offers an evaluative space to make inter-personal comparisons to
inform the development of \ac{PETs}."
2117,"We recommend further research to empirically understand individual choices to give an evaluative
  understanding of the interactions citizens have a reason to value.",Agenda.,"Our recommendation is for a rigorous under-
  standing of people’s choices, intentions, values, and motivations, irrespective of what developers/regulators think
  are good for citizens.",2022-02-17 09:48:12+00:00,The Political Economy of Privacy Enhancing Technologies,cs.CY,"['cs.CY', 'NA', 'K.4']","[arxiv.Result.Author('Partha Das Chowdhury'), arxiv.Result.Author('Andres Dominguez'), arxiv.Result.Author('Kopo M. Ramokapane'), arxiv.Result.Author('Awais Rashid')]","\ac{PETs} have increasingly become vital empowering tools in today's highly
datafied society. However, their development has been primarily concerned with
improving usability and ensuring confidentiality online. Privileging these
considerations might unintendedly lead to fixed ideas about users, but
diversity of thought, action, ability, and circumstance play a fundamental role
in the distortion and acceptance of any \ac{PETs}. In this paper we elaborate
some of the manifestations of the distortions, like inadequate and exclusory
design, and uneven distribution of costs and benefits. Drawing on Amartya Sen's
\emph{capability approach} we propose that a normative evaluation of personal,
social, and political diversities can be used as a foundation to conceptualize
and develop \ac{PETs}. We outline a research agenda based on this proposition
and suggest pertinent empirical and methodological research paths. Our
contribution offers an evaluative space to make inter-personal comparisons to
inform the development of \ac{PETs}."
2118,"We recommend further research to empirically under-                          is (and should be) in a position to devise and recommend said pri-
   stand individual choices to give an evaluative understanding                         vacy protections without conflict of interest, and which regulatory
   of the interactions citizens have a reason to value.","More apt termi-          to themhttps://www.theverge.com/2021/7/20/22576352/duckduckgo-email-protection-
   nologies, beyond monolithic categories such as ‘users’, are           privacy-trackers-apple-alternative
                                                                         8 https://eur-lex.europa.eu/eli/reg/2016/679/o
                                                                         9 https://ico.org.uk/media/action-weve-taken/enforcement-
                                                                         notices/2620027/emailmovers-limited-en.pdf
From Utility to Capability: A New Paradigm to Conceptualize and Develop Inclusive PETs  NSPW 2022, DATE, LOCATION

   Agenda.","Our recom-                      interventions and political supports are needed to further the tech-
   mendation is for a rigorous understanding of people’s choices,                       nical goals of PETs.",2022-02-17 09:48:12+00:00,From Utility to Capability: A New Paradigm to Conceptualize and Develop Inclusive PETs,cs.CY,"['cs.CY', 'NA', 'K.4']","[arxiv.Result.Author('Partha Das Chowdhury'), arxiv.Result.Author('Andres Dominguez'), arxiv.Result.Author('Kopo M. Ramokapane'), arxiv.Result.Author('Awais Rashid')]","The wider adoption of PETs has relied on usability studies, which focus
mainly on an assessment of how a specified group of users interface, in
particular contexts, with the technical properties of a system. While human
centred efforts in usability aim to achieve important technical improvements
and drive technology adoption, a focus on the usability of PETs alone is not
enough. PETs development and adoption requires a broadening of focus to
adequately capture the specific needs of individuals, particularly of
vulnerable individuals and or individuals in marginalized populations. We argue
for a departure, from the utilitarian evaluation of surface features aimed at
maximizing adoption, towards a bottom up evaluation of what real opportunities
humans have to use a particular system. We delineate a new paradigm for the way
PETs are conceived and developed. To that end, we propose that Amartya Sen s
capability approach offers a foundation for the comprehensive evaluation of the
opportunities individuals have based on their personal and environmental
circumstances which can, in turn, inform the evolution of PETs. This includes
considerations of vulnerability, age, education, physical and mental ability,
language barriers, gender, access to technology, freedom from oppression among
many important contextual factors."
2155,"Having a mask
stratum experiences significantly more reclassifications while    requirement results in a non-significant rating change (means
the 60-80% income stratum experiences significantly less than     3.89 and 4.00, Spearman correlation 𝜌 = −0.04, p = 0.06), and
its neighbors, but on par with the top income stratum, which      this relationship vanishes after removing Not Recommended
warrants further research.","The 60-    ing masks have a lower rating, and this relationship remains
80% strata are an outlier in both cases—the 60-80% density        after removing Not Recommended reviews.","These disparities invite questions     reviews (mean 3.92 and 3.90, Spearman correlation 𝜌 = −0.01,
as to why they arise: is there something inherent about these     p = 0.79).",2022-02-18 03:27:53+00:00,"Reviews in motion: a large scale, longitudinal study of review recommendations on Yelp",cs.CY,['cs.CY'],"[arxiv.Result.Author('Ryan Amos'), arxiv.Result.Author('Roland Maio'), arxiv.Result.Author('Prateek Mittal')]","The United Nations Consumer Protection Guidelines lists ""access ... to
adequate information ... to make informed choices"" as a core consumer
protection right. However, problematic online reviews and imperfections in
algorithms that detect those reviews pose obstacles to the fulfillment of this
right. Research on reviews and review platforms often derives insights from a
single web crawl, but the decisions those crawls observe may not be static. A
platform may feature a review one day and filter it from view the next day. An
appreciation for these dynamics is necessary to understand how a platform
chooses which reviews consumers encounter and which reviews may be unhelpful or
suspicious. We introduce a novel longitudinal angle to the study of reviews. We
focus on ""reclassification,"" wherein a platform changes its filtering decision
for a review. To that end, we perform repeated web crawls of Yelp to create
three longitudinal datasets. These datasets highlight the platform's dynamic
treatment of reviews. We compile over 12.5M reviews--more than 2M
unique--across over 10k businesses. Our datasets are available for researchers
to use.
  Our longitudinal approach gives us a unique perspective on Yelp's classifier
and allows us to explore reclassification. We find that reviews routinely move
between Yelp's two main classifier classes (""Recommended"" and ""Not
Recommended"")--up to 8% over eight years--raising concerns about prior works'
use of Yelp's classes as ground truth. These changes have impacts on small
scales; for example, a business going from a 3.5 to 4.5 star rating despite no
new reviews. Some reviews move multiple times: we observed up to five
reclassifications in eleven months. Our data suggests demographic disparities
in reclassifications, with more changes in lower density and low-middle income
areas."
2169,"In order to understand better the transfer of knowledge through virtual and AR and
to be able to develop appropriate methods for using these technologies, further research
is needed.","Most of these problems were related to ensuring
stable access to the Internet, improper operation of QR scanners and the lack of some
software installation skills.","In particular, it is advisable to compare augmented and virtual reality
technologies with traditional teaching methods and other latest information processing
tools, as well as study and compare various methods that offer augmented and virtual
reality.",2022-02-18 12:22:10+00:00,The use of AR elements in the study of foreign languages at the university,cs.CY,['cs.CY'],"[arxiv.Result.Author('Rostyslav Tarasenko'), arxiv.Result.Author('Svitlana Amelina'), arxiv.Result.Author('Yuliya Kazhan'), arxiv.Result.Author('Olga Bondarenko')]","The article deals with the analysis of the impact of the using AR technology
in the study of a foreign language by university students. It is stated out
that AR technology can be a good tool for learning a foreign language. The use
of elements of AR in the course of studying a foreign language, in particular
in the form of virtual excursions, is proposed. Advantages of using AR
technology in the study of the German language are identified, namely: the
possibility of involvement of different channels of information perception, the
integrity of the representation of the studied object, the faster and better
memorization of new vocabulary, the development of communicative foreign
language skills. The ease and accessibility of using QR codes to obtain
information about the object of study from open Internet sources is shown. The
results of a survey of students after virtual tours are presented. A
reorientation of methodological support for the study of a foreign language at
universities is proposed. Attention is drawn to the use of AR elements in order
to support students with different learning styles (audio, visual,
kinesthetic)."
2202,"Communication and outreach technologies for minor abuse warrants further study, building on existing CSCW research on
the algorithms used to mitigate sexual abuse of minors [68].","17By law in the United States, all minors encountered by TechnologyOrganization are referred to the National Center
for Missing and Exploited Children, not service organizations, making minors a special case not included in our study.","18However, those without digital contact are largely outside the scope of this research as they are unlikely to be reached
through technology-based outreach [34] which relies on being able to digitally contact those whose advertisements are
scraped.",2022-02-19 05:12:34+00:00,Ethics and Efficacy of Unsolicited Anti-Trafficking SMS Outreach,cs.CY,['cs.CY'],"[arxiv.Result.Author('Rasika Bhalerao'), arxiv.Result.Author('Nora McDonald'), arxiv.Result.Author('Hanna Barakat'), arxiv.Result.Author('Vaughn Hamilton'), arxiv.Result.Author('Damon McCoy'), arxiv.Result.Author('Elissa M. Redmiles')]","The sex industry exists on a continuum based on the degree of work autonomy
present in labor conditions: a high degree exists on one side of the continuum
where independent sex workers have a great deal of agency, while much less
autonomy exists on the other side, where sex is traded under conditions of
human trafficking. Organizations across North America perform outreach to sex
industry workers to offer assistance in the form of services (e.g., healthcare,
financial assistance, housing), prayer, and intervention. Increasingly,
technology is used to look for trafficking victims or facilitate the provision
of assistance or services, for example through scraping and parsing sex
industry workers' advertisements into a database of contact information that
can be used by outreach organizations. However, little is known about the
efficacy of anti-trafficking outreach technology, nor the potential risks of
using it to identify and contact the highly stigmatized and marginalized
population of those working in the sex industry.
  In this work, we investigate the use, context, benefits, and harms of an
anti-trafficking technology platform via qualitative interviews with multiple
stakeholders: the technology developers (n=6), organizations that use the
technology (n=17), and sex industry workers who have been contacted or wish to
be contacted (n=24). Our findings illustrate misalignment between developers,
users of the platform, and sex industry workers they are attempting to assist.
In their current state, anti-trafficking outreach tools such as the one we
investigate are ineffective and, at best, serve as a mechanism for spam and, at
worst, scale and exacerbate harm against the population they aim to serve. We
conclude with a discussion of best practices for technology-facilitated
outreach efforts to minimize risk or harm to sex industry workers while
efficiently providing needed services."
2203,"Third, further research similar to that conducted here is needed to measure the
efficacy of the technological through analog approaches (e.g., posters in transit stations) [70].","Second, development of alternative
forms of outreach and service provision should be done in collaboration with sex industry workers
across the full spectrum of autonomy, in line with suggestions for community-driven technology
development [19].","Only
with this data can we effectively prioritize the strategies that are most effective and have the lowest
risk of harm.",2022-02-19 05:12:34+00:00,Ethics and Efficacy of Unsolicited Anti-Trafficking SMS Outreach,cs.CY,['cs.CY'],"[arxiv.Result.Author('Rasika Bhalerao'), arxiv.Result.Author('Nora McDonald'), arxiv.Result.Author('Hanna Barakat'), arxiv.Result.Author('Vaughn Hamilton'), arxiv.Result.Author('Damon McCoy'), arxiv.Result.Author('Elissa M. Redmiles')]","The sex industry exists on a continuum based on the degree of work autonomy
present in labor conditions: a high degree exists on one side of the continuum
where independent sex workers have a great deal of agency, while much less
autonomy exists on the other side, where sex is traded under conditions of
human trafficking. Organizations across North America perform outreach to sex
industry workers to offer assistance in the form of services (e.g., healthcare,
financial assistance, housing), prayer, and intervention. Increasingly,
technology is used to look for trafficking victims or facilitate the provision
of assistance or services, for example through scraping and parsing sex
industry workers' advertisements into a database of contact information that
can be used by outreach organizations. However, little is known about the
efficacy of anti-trafficking outreach technology, nor the potential risks of
using it to identify and contact the highly stigmatized and marginalized
population of those working in the sex industry.
  In this work, we investigate the use, context, benefits, and harms of an
anti-trafficking technology platform via qualitative interviews with multiple
stakeholders: the technology developers (n=6), organizations that use the
technology (n=17), and sex industry workers who have been contacted or wish to
be contacted (n=24). Our findings illustrate misalignment between developers,
users of the platform, and sex industry workers they are attempting to assist.
In their current state, anti-trafficking outreach tools such as the one we
investigate are ineffective and, at best, serve as a mechanism for spam and, at
worst, scale and exacerbate harm against the population they aim to serve. We
conclude with a discussion of best practices for technology-facilitated
outreach efforts to minimize risk or harm to sex industry workers while
efficiently providing needed services."
2334,"Unlike [12], which only shows real-time outages, the devel-                       Next, if an outage exists in the table for processed outages,
oped dashboard stores the captured data to create a com-                          but not anymore in the table for currently crawled outages, it
prehensive archive of outages, which is publicly available to                     is inserted into the historical outage table and removed from
facilitate further research.",outages and inserts them into the table for processed outages.,"On an interactive map, it shows                      the processed outage table.",2022-02-22 17:51:00+00:00,Outing Power Outages: Real-time and Predictive Socio-demographic Analytics for New York City,cs.CY,['cs.CY'],"[arxiv.Result.Author('Samuel Eckstrom'), arxiv.Result.Author('Graham Murphy'), arxiv.Result.Author('Eileen Ye'), arxiv.Result.Author('Samrat Acharya'), arxiv.Result.Author('Robert Mieth'), arxiv.Result.Author('Yury Dvorkin')]","Electrical outages continue to occur despite technological innovations and
improvements to electric power distribution infrastructure. In this paper, we
describe a tool that was designed to acquire and collect data on electric power
outages in New York City since July 2020. The electrical outages are then
displayed on a front-end application, which is publicly available. We use the
collected outage data to analyze these outages and their socio-economic impacts
on electricity vulnerable population groups. We determined that there was a
slightly negative linear relationship between income and number of outages.
Finally, a Markov Influence Graph was created to better understand the spatial
and temporal relationships between outages."
2502,"CPU runtimes for the Python-based portion of the process chain
differed starkly for both tracks, pointing to avenues for further research.","Formal
and informal documentation channels are highlighted to outline available resources for
flattening learning curves.","These results
demonstrate that the Python ecosystem offers local governments powerful tools, free of
vendor lock-in and licensing fees, to produce performant and consistently formatted
visualisations for both internal and public distribution.",2022-02-26 10:23:29+00:00,Python for Smarter Cities: Comparison of Python libraries for static and interactive visualisations of large vector data,cs.CY,['cs.CY'],"[arxiv.Result.Author('Gregor Herda'), arxiv.Result.Author('Robert McNabb')]","Local governments, as part of 'smart city' initiatives and to promote
interoperability, are increasingly incorporating open-source software into
their data management, analysis, and visualisation workflows. Python, with its
concise and natural syntax, presents a low barrier to entry for municipal staff
without computer science backgrounds. However, with regard to geospatial
visualisations in particular, the range of available Python libraries has
diversified to such an extent that identifying candidate libraries for specific
use cases is a challenging undertaking. This study therefore assesses
prominent, actively-developed visualisation libraries in the Python ecosystem
with respect to their suitability for producing visualisations of large vector
datasets. A simple visualisation task common in urban development is used to
produce near-identical thematic maps across static and an interactive 'tracks'
of comparison. All short-listed libraries were able to generate the sample map
products for both a small and larger dataset. Code complexity differed more
strongly for interactive visualisations. Formal and informal documentation
channels are highlighted to outline available resources for flattening learning
curves. CPU runtimes for the Python-based portion of the process chain differed
starkly for both tracks, pointing to avenues for further research. These
results demonstrate that the Python ecosystem offers local governments powerful
tools, free of vendor lock-in and licensing fees, to produce performant and
consistently formatted visualisations for both internal and public
distribution."
2512,"The selected user profiles and the granted rights, on the other hand,
are only examples that are up for discussion and which need to be specified and challenged in further research.","Here, the attributed-based access control shall be emphasized because this represents non-rigid boundary
conditions in preparation for future regulations.","However, the data integration scenario distinguishes four levels of action layering data storage, data harmonization,
interfaces and the data input/data output layer, which harmonizes the application scenario and the digital
ecosystem.",2022-02-26 19:45:31+00:00,Unique Device Identification Based Linkage of Hierarchically Accessible Data Domains in Prospective Hospital Data Ecosystems,cs.CY,['cs.CY'],"[arxiv.Result.Author('Karol Kozak'), arxiv.Result.Author('André Seidel'), arxiv.Result.Author('Nataliia Matvieieva'), arxiv.Result.Author('Constanze Neupetsch'), arxiv.Result.Author('Uwe Teicher'), arxiv.Result.Author('Gordon Lemme'), arxiv.Result.Author('Anas Ben Achour'), arxiv.Result.Author('Martin Barth'), arxiv.Result.Author('Steffen Ihlenfeldt'), arxiv.Result.Author('Welf-Guntram Drossel')]","The electronic health record (EHR) targets the systematized collection of
patient-specific electronically-stored health data. Currently the EHR is an
evolving concept driven by ongoing technical developments and open or unclear
legal issues concerning used medical technologies, data integration from other
domains and unclear access roles. This paper addresses cross-domain data
integration, data fusion and access control using the specific example of a
Unique Device Identification (UDI) expanded hip implant. In fact, the
integration of technical focus data into the hospital information system (HIS)
is discussed and presented based on surgically relevant information. Moreover,
the acquisition of social focus databased on mHealth is approached, which also
covers data integration and networking with therapeutic intervention or acute
diagnostics data. Data integration from heterogeneous domains is covered while
using a data ecosystem with hierarchical access based on a shell embedded role
model, which includes staggered access scenarios."
2669,"Understanding social commerce: A systematic
                                                                                  literature review and directions for further research.",2016.,"International Journal of
                                                                                  Information Management 36, 6 (2016), 1075–1088.",2022-03-02 04:25:52+00:00,Beyond Virtual Bazaar: How Social Commerce Promotes Inclusivity for the Traditionally Underserved Community in Chinese Developing Regions,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Author('Zhilong Chen'), arxiv.Result.Author('Hancheng Cao'), arxiv.Result.Author('Xiaochong Lan'), arxiv.Result.Author('Zhicong Lu'), arxiv.Result.Author('Yong Li')]","The disadvantaged population is often underserved and marginalized in
technology engagement: prior works show they are generally more reluctant and
experience more barriers in adopting and engaging with mainstream technology.
Here, we contribute to the HCI4D and ICTD literature through a novel ""counter""
case study on Chinese social commerce (e.g., Pinduoduo), which 1) first
prospers among the traditionally underserved community from developing regions
ahead of the more technologically advantaged communities, and 2) has been
heavily engaged by this community. Through 12 in-depth interviews with social
commerce users from the traditionally underserved community in Chinese
developing regions, we demonstrate how social commerce, acting as a ""counter"",
brings online the traditional offline socioeconomic lives the community has
lived for ages, fits into the community's social, cultural, and economic
context, and thus effectively promotes technology inclusivity. Our work
provides novel insights and implications for building inclusive technology for
the ""next billion"" population."
2943,"3.2 Health Information Disorder Detection

   Finally, we also advocate further research on the design        Due to the spread of online information disorder, a second as-
and evaluation of alternative interaction protocols [Cabitza et    pect that needs to be addressed is to identify different forms
al., 2021] stipulating how human decision makers could use,
and in some case even collaborate, with AI-based decision
support systems, in order to mitigate the risk of having cog-
nitive biases, like automation bias, automation complacency,
AI over-reliance and its opposite, the prejudice against the
machine [Cabitza, 2019], which undermine the effectiveness
of communication pollution in different media formats, in-        5 Organized Research Initiatives
cluding in the health domain; in this context several solu-
tions have been proposed in recent years [Cui et al., 2020;          • CLEFeHealth 2021 – Task 2: Consumer Health Search.","tiple right and complementary interpretations are possible to
coexist for a single case [Basile et al., 2021].","Dharawat et al., 2020; Hou et al., 2019; Upadhyay et al.,               Evaluation Lab held in conjunction with CLEF 2021:
2021; Zhao et al., 2021].",2022-02-19 14:48:22+00:00,Responsible AI in Healthcare,cs.CY,"['cs.CY', 'cs.AI', 'cs.IR', 'cs.LG']","[arxiv.Result.Author('Federico Cabitza'), arxiv.Result.Author('Davide Ciucci'), arxiv.Result.Author('Gabriella Pasi'), arxiv.Result.Author('Marco Viviani')]","This article discusses open problems, implemented solutions, and future
research in the area of responsible AI in healthcare. In particular, we
illustrate two main research themes related to the work of two laboratories
within the Department of Informatics, Systems, and Communication at the
University of Milano-Bicocca. The problems addressed concern, in particular,
{uncertainty in medical data and machine advice}, and the problem of online
health information disorder."
2955,"Finally, challenges and future directions are provided for    of different policies of incentives, Alberto L opez Santiago,
                                        further research.","Focusing on the impacts
                                        works.",et al.,2022-01-19 07:46:32+00:00,All one needs to know about shared micromobility simulation: a complete survey,cs.CY,"['cs.CY', 'physics.soc-ph']","[arxiv.Result.Author('Yixuan Liu'), arxiv.Result.Author('Yuhan Tang'), arxiv.Result.Author('Yati Liu')]","As the shared micromobility becomes a part of our daily life and environment,
we expect the number of low-speed modes for first-and-last mile trips to grow
rapidly. The shared micomobility is expected to serve billions of humans,
bringing us considerable advantages. With this growth, shared micromobility
simulation such as docked stations based shared bikes, dockless shared bikes
and e-scooters, are regarded as promising solutions to deal with a large number
of first-and-last mile trips. In this paper, we first provide a comprehensive
overview of shared micromobility simulation and its related validation metrics.
Next, we classify the research topics of shared micromobility simulation,
summarize, and classify the existing works. Finally, challenges and future
directions are provided for further research."
2956,"Recommendation – It is recommended to have further research on how critical and auto
ticket affects the mental health of resources and its direct impact to businesses.","Researchers provided solutions such as knowledge Management and Dashboard to
document all the solutions encountered and monitor the SLA’s and incoming tickets.","It is also
recommended to have a study on how knowledge management work and help resources
to identify correct workaround despite of having a lot of troubleshooting guides.",2022-02-13 05:06:47+00:00,Impact of Critical and Auto Ticket: Analysis for Management and Workers Productivity in using a Ticketing System,cs.CY,['cs.CY'],"[arxiv.Result.Author('Kent Darryl Aglibar'), arxiv.Result.Author('Nelson Rodelas')]","Ticketing system is common in Technical Support in Information Technology
Industry. At present time, even management is using it. It serves as a way to
connect the company and the client, end to end. The researchers conducted
research where it aims to come up with a solution on how we are going to
prevent, troubleshoot, and give insight for possible business impact to those
everyday issues. Researchers used data collection to gather data from
management, support workers, and Service Now open-source ticketing system to
visualize the ticketing system application. Critical ticket gives a lot of
pressure to the resources as they needed to resolve the incident in accordance
with the service level agreement. Having knowledge management helps resource to
find references on how to deal with the incident. It helps them to execute
workaround quickly and think of a way on how to resolve it permanently. It is
concluded that critical and auto ticket affects the everyday productivity of
the worker especially teaching new employees despite ongoing critical
incidents. Researchers provided solutions such as knowledge Management and
Dashboard to document all the solutions encountered and monitor the SLA and
incoming tickets. It is recommended to have further research on how critical
and auto ticket affects the mental health of resources and its direct impact to
businesses. It is also recommended to have a study on how knowledge management
work and help resources to identify correct workaround despite of having a lot
of troubleshooting guides."
2957,"Lastly, for further study, researchers will survey other IT
companies who are using or not a Ticketing System.","This is helpful especially for both live production and a
management-related team that supports manufacturing companies and real-time
application consumer use.","1002
REFERENCES

Al-Hawari, F., &amp; Barham, H. (2019).",2022-02-13 05:06:47+00:00,Impact of Critical and Auto Ticket: Analysis for Management and Workers Productivity in using a Ticketing System,cs.CY,['cs.CY'],"[arxiv.Result.Author('Kent Darryl Aglibar'), arxiv.Result.Author('Nelson Rodelas')]","Ticketing system is common in Technical Support in Information Technology
Industry. At present time, even management is using it. It serves as a way to
connect the company and the client, end to end. The researchers conducted
research where it aims to come up with a solution on how we are going to
prevent, troubleshoot, and give insight for possible business impact to those
everyday issues. Researchers used data collection to gather data from
management, support workers, and Service Now open-source ticketing system to
visualize the ticketing system application. Critical ticket gives a lot of
pressure to the resources as they needed to resolve the incident in accordance
with the service level agreement. Having knowledge management helps resource to
find references on how to deal with the incident. It helps them to execute
workaround quickly and think of a way on how to resolve it permanently. It is
concluded that critical and auto ticket affects the everyday productivity of
the worker especially teaching new employees despite ongoing critical
incidents. Researchers provided solutions such as knowledge Management and
Dashboard to document all the solutions encountered and monitor the SLA and
incoming tickets. It is recommended to have further research on how critical
and auto ticket affects the mental health of resources and its direct impact to
businesses. It is also recommended to have a study on how knowledge management
work and help resources to identify correct workaround despite of having a lot
of troubleshooting guides."
2958,"Others include supporting the development of AI literacy21 in the
social sciences and humanities so that the next generation of students, schol-
ars, and practitioners are well versed in the technical and social aspects of

   20using quantitative, qualitative, and/or mixed methodologies
   21which itself requires further research, see e.g.","Some of the required actions are
traditional academic endeavours, such as writing articles, creating discussion
forums, writing blogs, holding conferences (and conferences within confer-
ences), teaching about needs in courses, and of course conducting rigorous
research.","[59] for an initial attempt
                          Springer Nature 2021 LATEX template

                                                  Needs and Artiﬁcial Intelligence 21

conversations.",2022-02-18 15:16:22+00:00,Needs and Artificial Intelligence,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Soheil Human'), arxiv.Result.Author('Ryan Watkins')]","Throughout their history, homo sapiens have used technologies to better
satisfy their needs. The relation between needs and technology is so
fundamental that the US National Research Council defined the distinguishing
characteristic of technology as its goal ""to make modifications in the world to
meet human needs"". Artificial intelligence (AI) is one of the most promising
emerging technologies of our time. Similar to other technologies, AI is
expected ""to meet [human] needs"". In this article, we reflect on the
relationship between needs and AI, and call for the realisation of needs-aware
AI systems. We argue that re-thinking needs for, through, and by AI can be a
very useful means towards the development of realistic approaches for
Sustainable, Human-centric, Accountable, Lawful, and Ethical (HALE) AI systems.
We discuss some of the most critical gaps, barriers, enablers, and drivers of
co-creating future AI-based socio-technical systems in which [human] needs are
well considered and met. Finally, we provide an overview of potential threats
and HALE considerations that should be carefully taken into account, and call
for joint, immediate, and interdisciplinary efforts and collaborations."
2980,"Regardless, an overhaul at the
global level overtime is needed to strengthen data privacy              The dataset and the source code for the project will be
                                                                     made openly available for further research in this area.",between these variables.,"ACKNOWLEDGMENT

                                                                               While he was unable to be included in this paper's
                                                                     authorship due to his current research obligations and
                                                                     guidelines, we, the authors, would like to acknowledge the
                                                                     help, guidance, and support received from Mr. FirstName
                                                                     LastName.",2022-02-27 21:22:48+00:00,Associating eHealth Policies and National Data Privacy Regulations,cs.CY,"['cs.CY', 'cs.CR']","[arxiv.Result.Author('Saurav K. Aryal'), arxiv.Result.Author('Peter A. Keiller')]","As electronic data becomes the lifeline of modern society, privacy concerns
increase. These concerns are reflected by the European Union's enactment of the
General Data Protection Regulation (GDPR), one of the most comprehensive and
robust privacy regulations globally. This project aims to evaluate and
highlight associations between eHealth systems' policies and personal data
privacy regulations. Using bias-corrected Cramer's V and Thiel's U tests, we
found weak and zero associations between e-health systems' rules and
protections for data privacy. A simple decision tree model is trained, which
validates the association scores obtained"
3025,"First, further research is required for establishing specific and full-fledged guidelines or automated tools to
evaluate individual criteria proposed in the framework.","The system accountability benchmark paves the way for three major lines of future work that are also sequentially
linked.","The second line of work would be towards developing mature
auditing procedures that elaborate on what to audit, when to audit, who audits, and how audits must be conducted.",2022-03-01 18:56:45+00:00,System Cards for AI-Based Decision-Making for Public Policy,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Furkan Gursoy'), arxiv.Result.Author('Ioannis A. Kakadiaris')]","Decisions in public policy are increasingly being made or assisted by
automated decision-making algorithms. Many of these algorithms process personal
data for tasks such as predicting recidivism, assisting welfare decisions,
identifying individuals using face recognition, and more. While potentially
improving efficiency and effectiveness, such algorithms are not inherently free
from issues such as bias, opaqueness, lack of explainability, maleficence, and
the like. Given that the outcomes of these algorithms have significant impacts
on individuals and society and are open to analysis and contestation after
deployment, such issues must be accounted for before deployment. Formal audits
are a way towards ensuring algorithms that are used in public policy meet the
appropriate accountability standards. This work, based on an extensive analysis
of the literature, proposes a unifying framework for system accountability
benchmark for formal audits of artificial intelligence-based decision-aiding
systems in public policy as well as system cards that serve as scorecards
presenting the outcomes of such audits. The benchmark consists of 50 criteria
organized within a four by four matrix consisting of the dimensions of (i)
data, (ii) model, (iii) code, (iv) system and (a) development, (b) assessment,
(c) mitigation, (d) assurance. Each criterion is described and discussed
alongside a suggested measurement scale indicating whether the evaluations are
to be performed by humans or computers and whether the evaluation outcomes are
binary or on an ordinal scale. The proposed system accountability benchmark
reflects the state-of-the-art developments for accountable systems, serves as a
checklist for future algorithm audits, and paves the way for sequential work as
future research."
3026,"First, further research is required to establish speciﬁc
and full-ﬂedged guidelines or automated tools to evaluate                  [6] B. J. Dietvorst, J. P. Simmons, and C. Massey, “Algorithm aversion:
the proposed criteria.","571–582, 1979.
linked.","The second line of work is towards                       People erroneously avoid algorithms after seeing them err.” Journal of
developing mature auditing procedures that elaborate on what                    Experimental Psychology: General, vol.",2022-03-01 18:56:45+00:00,System Cards for AI-Based Decision-Making for Public Policy,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Furkan Gursoy'), arxiv.Result.Author('Ioannis A. Kakadiaris')]","Decisions impacting human lives are increasingly being made or assisted by
automated decision-making algorithms. Many of these algorithms process personal
data for predicting recidivism, credit risk analysis, identifying individuals
using face recognition, and more. While potentially improving efficiency and
effectiveness, such algorithms are not inherently free from bias, opaqueness,
lack of explainability, maleficence, and the like. Given that the outcomes of
these algorithms have a significant impact on individuals and society and are
open to analysis and contestation after deployment, such issues must be
accounted for before deployment. Formal audits are a way of ensuring algorithms
meet the appropriate accountability standards. This work, based on an extensive
analysis of the literature and an expert focus group study, proposes a unifying
framework for a system accountability benchmark for formal audits of artificial
intelligence-based decision-aiding systems. This work also proposes system
cards to serve as scorecards presenting the outcomes of such audits. It
consists of 56 criteria organized within a four-by-four matrix composed of rows
focused on (i) data, (ii) model, (iii) code, (iv) system, and columns focused
on (a) development, (b) assessment, (c) mitigation, and (d) assurance. The
proposed system accountability benchmark reflects the state-of-the-art
developments for accountable systems, serves as a checklist for algorithm
audits, and paves the way for sequential work in future research."
3172,"Future work will further study the impact        adoption in healthcare, 2018.                https:
of predatory research, including retracted publication
on MedAI solutions.","Overcoming barriers in ai
tion will have more signiﬁcant challenges and higher
stakes.","We plan to look at other secu-       //newsroom.intel.com/wp-content/uploads/
rity vulnerabilities to better defend against informa-
tion pollution.",2022-03-08 16:13:41+00:00,Predatory Medicine: Exploring and Measuring the Vulnerability of Medical AI to Predatory Science,cs.CY,"['cs.CY', 'I.2.1; J.3']","[arxiv.Result.Author('Shalini Saini'), arxiv.Result.Author('Nitesh Saxena')]","Medical Artificial Intelligence (MedAI) for diagnosis, treatment options, and
drug development represents the new age of healthcare. The security, integrity,
and credibility of MedAI tools are paramount issues because human lives are at
stake. MedAI solutions are often heavily dependent on scientific medical
research literature as a primary data source that draws the attacker's
attention as a potential target. We present a first study of how the output of
MedAI can be polluted with Predatory Publications Presence (PPP). We study two
MedAI systems: mediKanren (disease independent) and CancerMine
(Disease-specific), which use research literature as primary data input from
the research repository PubMed, PubMed derived database SemMedDB, and NIH
translational Knowledge Graphs (KGs). Our study has a three-pronged focus: (1)
identifying the PPP in PubMed; (2) verifying the PPP in SemMedDB and the KGs;
(3) demonstrating the existing vulnerability of PPP traversing to the MedAI
output. Our contribution lies in identifying the existing PPP in the MedAI
inputs and demonstrating how predatory science can jeopardize the credibility
of MedAI solutions, making their real-life deployment questionable."
3173,"Future work will further study the impact
smaller datasets for selected concepts to highlight the       of predatory research, including retracted publication
threat.","All the mediKanren queries for             tion will have more signiﬁcant challenges and higher
the code prototype are executed with targeted much            stakes.",We believe that results will be comparable            on MedAI solutions.,2022-03-08 16:13:41+00:00,Predatory Medicine: Exploring and Measuring the Vulnerability of Medical AI to Predatory Science,cs.CY,"['cs.CY', 'I.2.1; J.3']","[arxiv.Result.Author('Shalini Saini'), arxiv.Result.Author('Nitesh Saxena')]","Medical Artificial Intelligence (MedAI) for diagnosis, treatment options, and
drug development represents the new age of healthcare. The security, integrity,
and credibility of MedAI tools are paramount issues because human lives are at
stake. MedAI solutions are often heavily dependent on scientific medical
research literature as a primary data source that draws the attacker's
attention as a potential target. We present a first study of how the output of
MedAI can be polluted with Predatory Publications Presence (PPP). We study two
MedAI systems: mediKanren (disease independent) and CancerMine
(Disease-specific), which use research literature as primary data input from
the research repository PubMed, PubMed derived database SemMedDB, and NIH
translational Knowledge Graphs (KGs). Our study has a three-pronged focus: (1)
identifying the PPP in PubMed; (2) verifying the PPP in SemMedDB and the KGs;
(3) demonstrating the existing vulnerability of PPP traversing to the MedAI
output. Our contribution lies in identifying the existing PPP in the MedAI
inputs and demonstrating how predatory science can jeopardize the credibility
of MedAI solutions, making their real-life deployment questionable."
3463,"A novel result concerns the strong     less, we did our best to account for the representative
association between the gender-cycling-gap and the air          challenge of this data set, ﬁrst by comparing only cities in
quality of a city, which however requires further research      the same region, and second by comparing streets only in
within a (quasi-)experimental setting.","Neverthe-
the adoption of e-bikes.","the same city, aiming to minimize user and trip purpose
                                                                variation.",2022-03-17 15:07:38+00:00,Revealing the determinants of gender inequality in urban cycling with large-scale data,cs.CY,['cs.CY'],"[arxiv.Result.Author('Alice Battiston'), arxiv.Result.Author('Ludovico Napoli'), arxiv.Result.Author('Paolo Bajardi'), arxiv.Result.Author('André Panisson'), arxiv.Result.Author('Alan Perotti'), arxiv.Result.Author('Michael Szell'), arxiv.Result.Author('Rossano Schifanella')]","Cycling is an outdoor activity with massive health benefits, and an effective
solution towards sustainable urban transport. Despite these benefits and the
recent rising popularity of cycling, most countries still have a negligible
uptake. This uptake is especially low for women: there is a largely
unexplained, persistent gender gap in cycling. To understand the determinants
of this gender gap in cycling at scale, here we use massive,
automatically-collected data from the tracking application Strava on outdoor
cycling for 61 cities across the United States, the United Kingdom, Italy and
the Benelux area. Leveraging the associated gender and usage information, we
first quantify the emerging gender gap in recreational cycling at city-level. A
comparison of cycling rates of women across cities within similar geographical
areas unveils a broad range of gender gaps. On a macroscopic level, we link
this heterogeneity to a variety of urban indicators and provide evidence for
traditional hypotheses on the determinants of the gender-cycling-gap. We find a
positive association between female cycling rate and urban road safety. On a
microscopic level, we identify female preferences for street-specific features
in the city of New York. Enhancing the quality of the dedicated cycling
infrastructure may be a way to make urban environments more accessible for
women, thereby making urban transport more sustainable for everyone."
3554,"On the basis of our successful results we believe                         regulated learning processing using statistical models for count
that further study and exploration of zero-inﬂated learner                          data.","Analysis of self-
rameters.","Metacognition and Learning, 6(3):275–301, 2011.
models can yield an inclusive framework for equitable, ex-
plainable, and reliable learner models in diverse educational                [19] K. Holstein and S. Doroudi.",2022-03-18 21:47:01+00:00,Equitable Ability Estimation in Neurodivergent Student Populations with Zero-Inflated Learner Models,cs.CY,"['cs.CY', 'cs.LG']","[arxiv.Result.Author('Niall Twomey'), arxiv.Result.Author('Sarah McMullan'), arxiv.Result.Author('Anat Elhalal'), arxiv.Result.Author('Rafael Poyiadzi'), arxiv.Result.Author('Luis Vaquero')]","At present, the educational data mining community lacks many tools needed for
ensuring equitable ability estimation for Neurodivergent (ND) learners. On one
hand, most learner models are susceptible to under-estimating ND ability since
confounding contexts cannot be held accountable (e.g. consider dyslexia and
text-heavy assessments), and on the other, few (if any) existing datasets are
suited for appraising model and data bias in ND contexts. In this paper we
attempt to model the relationships between context (delivery and response
types) and performance of ND students with zero-inflated learner models. This
approach facilitates simulation of several expected ND behavioural traits,
provides equitable ability estimates across all student groups from generated
datasets, increases interpretability confidence, and can double the number of
learning opportunities for ND students in some cases. Our approach consistently
out-performs baselines in our experiments and can also be applied to many other
learner modelling frameworks"
4224,We then find that toxic language is not randomly distributed       further research to disentangle the mechanisms at play.,"teams) in the     showcase the value of merging social communication data like mail-
community using the Louvain modularity maximization algorithm           ing lists with technical data from the repository itself, but warrant
[4].","within the collaboration network of CPython, with 6 of the top
10 nodes ranked by counts of toxic words found within a single          4 ADDITIONAL RELATED WORK
central module.",2022-04-01 17:50:15+00:00,The OCEAN mailing list data set: Network analysis spanning mailing lists and code repositories,cs.CY,"['cs.CY', 'cs.SE']","[arxiv.Result.Author('Melanie Warrick'), arxiv.Result.Author('Samuel F. Rosenblatt'), arxiv.Result.Author('Jean-Gabriel Young'), arxiv.Result.Author('Amanda Casari'), arxiv.Result.Author('Laurent Hébert-Dufresne'), arxiv.Result.Author('James Bagrow')]","Communication surrounding the development of an open source project largely
occurs outside the software repository itself. Historically, large communities
often used a collection of mailing lists to discuss the different aspects of
their projects. Multimodal tool use, with software development and
communication happening on different channels, complicates the study of open
source projects as a sociotechnical system. Here, we combine and standardize
mailing lists of the Python community, resulting in 954,287 messages from 1995
to the present. We share all scraping and cleaning code to facilitate
reproduction of this work, as well as smaller datasets for the Golang (122,721
messages), Angular (20,041 messages) and Node.js (12,514 messages) communities.
To showcase the usefulness of these data, we focus on the CPython repository
and merge the technical layer (which GitHub account works on what file and with
whom) with the social layer (messages from unique email addresses) by
identifying 33% of GitHub contributors in the mailing list data. We then
explore correlations between the valence of social messaging and the structure
of the collaboration network. We discuss how these data provide a laboratory to
test theories from standard organizational science in large open source
projects."
4249,"Therefore, further research should focus on exploring the
circumstances in which machine-readable laws can be advantageous and in which
circumstances such laws do not apply.","However, the drawbacks of machine-readable rules are also apparent due
to a lack of ﬂexibility.","A case-by-case analysis may be required to
explore the function of machine-readable laws in diﬀerent sectors.",2022-04-02 09:16:34+00:00,"Recordism: A social-scientific prospect of blockchain from social, legal, financial, and technological perspectives",cs.CY,['cs.CY'],"[arxiv.Result.Author('Zihao Li'), arxiv.Result.Author('Hao Xu'), arxiv.Result.Author('Yang Fang'), arxiv.Result.Author('Boyuan Zhao'), arxiv.Result.Author('Lei Zhang')]","Blockchain has the potential to reform the architecture of cyberspace and
transform the storage, circulation and exchange of information through
decentralization, transparency and de-identification. Meaning that ordinary
participants can become traders, miners, retailers, and customers
simultaneously, breaking the barriers and reducing the information gap between
participants in the community, contributing to the futuristic metaverse with an
open progressive and equal ideology. Such information transformation empowered
by blockchain also profoundly impacts our methodological cognition, legal
governance on cyberspace and financial and technological development.
  This study explores the main question: what are the implications of the
blockchain-driven information revolution for society and social sciences? In
order to answer this main question, this paper chooses four perspectives, which
are methodological, legal, financial and technical. By analysis of these four
perspectives, this paper is expected to provide a more comprehensive analysis
of the blockchain-driven impact on society, social sciences, and technology to
contribute to current scholarships. Additionally, regarding blockchain as an
innovative methodological cognition, it grows on top of other technologies
while helping advance other technologies. This paper concludes that although
there are few frictions between blockchain and current social architecture,
blockchain is so much more than the technology itself, that can be a
representative of the community, acting as the source of trust, watcher of
governance, law enforcer for virtual activities, and an incubator for future
technologies."
4311,"For further study regarding this, try other statistical treatments.","Consider adding other LPSU campuses such as Sta Cruz, Los Banos and Siniloan to
         determine the readiness of their students;

    2.",3.,2022-04-04 09:07:11+00:00,Assessment on LSPU-SPCC Students Readiness towards M-learning,cs.CY,['cs.CY'],[arxiv.Result.Author('Joanna E. De Torres')],"Today, the use of technology is a powerful advantage in every field in the
society. With the advent of development in information and communications
technology (ICT), the process of learning and acquiring new knowledge had
undergone a shift marked by a transition from desktop computing to the
widespread use of mobile technology. In light of the COVID-19 pandemic, the
Commission on Higher Education said that colleges and universities following
the new school calendar will no longer require students to attend face-to-face
classes. One of the state universities that had been affected by this
inevitable situation is the Laguna State Polytechnic University. This study
aims to determine the readiness of the students in shifting to m-learning.
Specifically, it aims to determine the availability of mobile devices,
equipment readiness, technological skills readiness and psychological
readiness. A survey-based methodology was used to obtain the data and
descriptive statistics to analyze the results. It was determined that almost
all of the students own mobile devices, are fully equipped with applications,
have high technological skills and are quite ready in terms of psychological
readiness."
4402,"ethics, including how it is eminently compatible with emerging           Finally, opportunities are pointed out for further research to take
ethical theories under discussion such as pragmatic ethics and           the existing work in a more virtue-oriented direction.","Next,
is in need of a more accurate and complete understanding of virtue       connections to existing HCI literature are described for illustration.","care ethics, as well as more guidance for applying virtue ethics to
existing frameworks.",2022-04-05 14:18:35+00:00,Designing a Future Worth Wanting: Applying Virtue Ethics to HCI,cs.CY,"['cs.CY', 'cs.HC']",[arxiv.Result.Author('Tim Gorichanaz')],"Out of the three major approaches to ethics, virtue ethics is uniquely well
suited as a moral guide in the digital age, given the pace of sociotechnical
change and the complexity of society. Virtue ethics focuses on the traits,
situations and actions of moral agents, rather than on rules (as in deontology)
or outcomes (consequentialism). Even as interest in ethics has grown within
HCI, there has been little engagement with virtue ethics. To address this
lacuna and demonstrate further opportunities for ethical design, this paper
provides an overview of virtue ethics for application in HCI. It reviews
existing HCI work engaging with virtue ethics, provides a primer on virtue
ethics to correct widespread misapprehensions within HCI, and presents a
deductive literature review illustrating how existing lines of HCI research
resonate with the practices of virtue cultivation, paving the way for further
work in virtue-oriented design."
4516,"Therefore, further research should investigate the
inﬂuence of the kind of video in the optimal duration time to maximize student retention.","Different styles of videos might
have a distinct retention from students.",Figure 6.,2022-04-07 12:41:50+00:00,Recommended Guidelines for Effective MOOCs based on a Multiple-Case Study,cs.CY,['cs.CY'],"[arxiv.Result.Author('Eduardo Guerra'), arxiv.Result.Author('Fabio Kon'), arxiv.Result.Author('Paulo Lemos')]","Massive Open Online Courseware (MOOCs) appeared in 2008 and grew considerably
in the past decade, now reaching millions of students and professionals all
over the world. MOOCs do not replace other educational forms. Instead, they
complement them by offering a powerful educational tool that can reach students
that, otherwise, would not have access to that information. Nevertheless,
designing and implementing a successful MOOC is not straightforward. Simply
recording traditional classes is an approach that does not work, since the
conditions in which a MOOC student learns are very different from the
conventional classroom. In particular, dropout rates in MOOCs are, normally, at
least an order of magnitude higher than in conventional courses. In this paper,
we analyze data from 7 successful MOOCs that have attracted over 150,000
students in the past years. The analysis led to the proposal of a set of
guidelines to help instructors in designing more effective MOOCs. These results
contribute to the existing body of knowledge in the field, bring new insights,
and pose new questions for future research."
4522,"Conclusions and recommendations for further research

   At the moment the primary school system is not only in the process of completing the reform, but
also in the process of benchmarking – finding a reference, cost-effective solution to effectively
implement distance learning, adopting best practices and implementing best pedagogical practices that
will lay the foundations for primary school to provide quality education.",7.,"Since EER can be used both in full-time and distance learning, the global experiment on the
introduction of distance learning in the pedagogical practice of primary school teachers within the
framework of the “Smart Kids technology of teaching primary school students” experiment is a positive
example of providing continuous and high-quality student learning.",2022-04-07 14:41:41+00:00,"Distance Learning in Primary School During the COVID 19 Pandemic: Results of the ""SMART KIDS"" Experiment",cs.CY,['cs.CY'],"[arxiv.Result.Author('Svitlana Lytvynova'), arxiv.Result.Author('Nataliia Demeshkant')]","The paper analyzes the results of the introduction of the distance learning
form (DLF) using electronic educational resources (EER) and the teacher's
virtual classroom in primary school. The experiment took place within the
framework of the ""Smart Kids"" All-Ukrainian project during the long quarantine
caused by the COVID-19 pandemic. The educational process took place both
synchronously and asynchronously. The present paper substantiates the model of
organization of distance learning of primary school students using EER and
outlines its three main components: the organization of learning, conducting
online classes (explaining new material or practicing skills by students) and
monitoring the quality of students' independent performance of tasks. The
results of the experiment prove that it is necessary to provide teachers and
students with computer equipment, Internet access, digital resources for
teaching and assessment to implement DLF. It has been established that EER in
distance learning can be used both on a regular basis - in each class, and
periodically - to explain new material or train skills, the quality of tasks
performed by students can be monitored in the virtual office of the teacher and
shape an individual trajectory of students' development. The teachers
identified the following main problems of DLF implementation: internet
interruptions, problems with providing new computer equipment to students and
some teachers; lack of state aid in providing EER to all participants in the
educational process; limited access to students' computers during complete
isolation due to online work of parents. Despite the outlined problems, the
quality of distance learning of primary school students during the pandemic
using EER was positively and highly assessed by teachers."
4548,An analysis of specific works of Indian art could potentially offer a rich avenue for further research.,"The technical aspects addressed here are thus only a subset of the larger requirements of ethical AI
systems.","The study
focused on one non-Western art form, inclusion of other non-Western art forms (beyond Indian arts) can shed light on
other valuable abstractions for ethical AI system design and development.",2022-04-08 00:35:14+00:00,Broadening AI Ethics Narratives: An Indic Art View,cs.CY,['cs.CY'],"[arxiv.Result.Author('Ajay Divakaran'), arxiv.Result.Author('Aparna Sridhar'), arxiv.Result.Author('Ramya Srinivasan')]","Incorporating interdisciplinary perspectives is seen as an essential step
towards enhancing artificial intelligence (AI) ethics. In this regard, the
field of arts is perceived to play a key role in elucidating diverse historical
and cultural narratives, serving as a bridge across research communities. Most
of the works that examine the interplay between the field of arts and AI ethics
concern digital artworks, largely exploring the potential of computational
tools in being able to surface biases in AI systems. In this paper, we
investigate a complementary direction--that of uncovering the unique
socio-cultural perspectives embedded in human-made art, which in turn, can be
valuable in expanding the horizon of AI ethics. Through qualitative interviews
of sixteen artists, art scholars, and researchers of diverse Indian art forms
like music, sculpture, painting, floor drawings, dance, etc., we explore how
{\it non-Western} ethical abstractions, methods of learning, and participatory
practices observed in Indian arts, one of the most ancient yet perpetual and
influential art traditions, can inform the FAccT community. Insights from our
study suggest (1) the need for incorporating holistic perspectives (that are
informed both by data-driven observations and prior beliefs encapsulating the
structural models of the world) in designing ethical AI algorithms, (2) the
need for integrating multimodal data formats for design, development, and
evaluation of ethical AI systems, (3) the need for viewing AI ethics as a
dynamic, cumulative, shared process rather than as a self contained framework
to facilitate adaptability without annihilation of values, (4) the need for
consistent life-long learning to enhance AI accountability, and (5) the need
for identifying ethical commonalities across cultures and infusing the same
into AI system design, so as to enhance applicability across geographies."
4549,An analysis of specific works of Indian art could potentially offer a rich avenue for further research.,"The technical aspects addressed here are thus only a subset of the larger requirements of ethical AI
systems.","The study
focused on one non-Western art form, inclusion of other non-Western art forms (beyond Indian arts) can shed light on
other valuable abstractions for ethical AI system design and development.",2022-04-08 00:35:14+00:00,Broadening AI Ethics Narratives: An Indic Art View,cs.CY,['cs.CY'],"[arxiv.Result.Author('Ajay Divakaran'), arxiv.Result.Author('Aparna Sridhar'), arxiv.Result.Author('Ramya Srinivasan')]","Incorporating interdisciplinary perspectives is seen as an essential step
towards enhancing artificial intelligence (AI) ethics. In this regard, the
field of arts is perceived to play a key role in elucidating diverse historical
and cultural narratives, serving as a bridge across research communities. Most
of the works that examine the interplay between the field of arts and AI ethics
concern digital artworks, largely exploring the potential of computational
tools in being able to surface biases in AI systems. In this paper, we
investigate a complementary direction--that of uncovering the unique
socio-cultural perspectives embedded in human-made art, which in turn, can be
valuable in expanding the horizon of AI ethics. Through qualitative interviews
of sixteen artists, art scholars, and researchers of diverse Indian art forms
like music, sculpture, painting, floor drawings, dance, etc., we explore how
{\it non-Western} ethical abstractions, methods of learning, and participatory
practices observed in Indian arts, one of the most ancient yet perpetual and
influential art traditions, can inform the FAccT community. Insights from our
study suggest (1) the need for incorporating holistic perspectives (that are
informed both by data-driven observations and prior beliefs encapsulating the
structural models of the world) in designing ethical AI algorithms, (2) the
need for integrating multimodal data formats for design, development, and
evaluation of ethical AI systems, (3) the need for viewing AI ethics as a
dynamic, cumulative, shared process rather than as a self contained framework
to facilitate adaptability without annihilation of values, (4) the need for
consistent life-long learning to enhance AI accountability, and (5) the need
for identifying ethical commonalities across cultures and infusing the same
into AI system design, so as to enhance applicability across geographies."
4550,An analysis of specific works of Indian art could potentially offer a rich avenue for further research.,"The technical aspects addressed here are thus only a subset of the larger requirements of ethical AI
systems.","The study
focused on one non-Western art form, inclusion of other non-Western art forms (beyond Indian arts) can shed light on
other valuable abstractions for ethical AI system design and development.",2022-04-08 00:35:14+00:00,Broadening AI Ethics Narratives: An Indic Art View,cs.CY,['cs.CY'],"[arxiv.Result.Author('Ajay Divakaran'), arxiv.Result.Author('Aparna Sridhar'), arxiv.Result.Author('Ramya Srinivasan')]","Incorporating interdisciplinary perspectives is seen as an essential step
towards enhancing artificial intelligence (AI) ethics. In this regard, the
field of arts is perceived to play a key role in elucidating diverse historical
and cultural narratives, serving as a bridge across research communities. Most
of the works that examine the interplay between the field of arts and AI ethics
concern digital artworks, largely exploring the potential of computational
tools in being able to surface biases in AI systems. In this paper, we
investigate a complementary direction--that of uncovering the unique
socio-cultural perspectives embedded in human-made art, which in turn, can be
valuable in expanding the horizon of AI ethics. Through semi-structured
interviews across sixteen artists, art scholars, and researchers of diverse
Indian art forms like music, sculpture, painting, floor drawings, dance, etc.,
we explore how {\it non-Western} ethical abstractions, methods of learning, and
participatory practices observed in Indian arts, one of the most ancient yet
perpetual and influential art traditions, can shed light on aspects related to
ethical AI systems. Through a case study concerning the Indian dance system
(i.e. the {\it `Natyashastra'}), we analyze potential pathways towards
enhancing ethics in AI systems. Insights from our study outline the need for
(1) incorporating empathy in ethical AI algorithms, (2) integrating multimodal
data formats for ethical AI system design and development, (3) viewing AI
ethics as a dynamic, diverse, cumulative, and shared process rather than as a
static, self-contained framework to facilitate adaptability without
annihilation of values (4) consistent life-long learning to enhance AI
accountability"
4586,"We conclude by
outlining possible directions for further research.","In the third part of the paper, we discuss the main ﬁndings and limitations of the current work.","2 Material and methods

2.1 Data collection

Data for this study were collected from two “Open Education” MOOCs.",2022-04-08 18:34:52+00:00,How does online teamwork change student communication patterns in programming courses?,cs.CY,['cs.CY'],[arxiv.Result.Author('Natalya Kozhevnikova')],"Online teaching has become a new reality due to the COVID-19 pandemic raising
a lot of questions about its learning outcomes. Recent studies have shown that
peer communication positively affects learning outcomes of online teaching.
However, it is not clear how collaborative programming tasks change peer
communication patterns in the learning process. In this study, we compare
communication patterns in MOOCs where peer communication is limited with those
of a blended course in which students are involved in online peer instruction.
We used a mixed-method approach comprising automated text analysis and
community extraction with further qualitative analysis. The results show that
students prefer to seek help in programming from peers and not the teacher.
Team assignment helped to support this habit. Students communicated more
positively and intensively with each other, while only team leaders
communicated with the instructor reducing teacher overload. This shift could
explain how peer communication improves learning outcomes, as has been shown in
previous studies on MOOCs."
4823,"Overall, the few efforts to use AI and
machine/deep learning for migration data analysis have been promising and there seems
to be a strong potential for further research in this area.","(2018) used
deep learning for urban resident recognition.","These can be to model various
migration trends for prediction purposes or recognize and classify patterns to support
evidence-based decision making.",2022-04-13 19:02:42+00:00,"Information and Communication Technology in Migration: A Framework for Applications, Customization, and Research",cs.CY,['cs.CY'],"[arxiv.Result.Author('Ali Arya'), arxiv.Result.Author('Luciara Nardon'), arxiv.Result.Author('Md Riyadh')]","This paper addresses the role of Information and Communication Technology
(ICT) in migration governance, support, and experience with particular
attention to emerging technologies such as artificial intelligence, social
media, and virtual reality. We propose a framework for technology use based on
user groups and process types. We provide examples of using emerging
technologies for migration-related tasks within the context of this framework.
We then identify how such technologies can be applied to migration-related
tasks, developed for customized use, and improved through research to add new
features that can help different migration stakeholders. We suggest a series of
possible directions for future research and development to take advantage of
specific affordances of those emerging technologies more effectively."
4824,"Longer-term studies, increasing
visceral engagement, and reflective abilities are among particular areas that require such
further research.","Such use of VR has strong potential to establish
connection to migrants and is a subject of future research.",4.2.,2022-04-13 19:02:42+00:00,"Information and Communication Technology in Migration: A Framework for Applications, Customization, and Research",cs.CY,['cs.CY'],"[arxiv.Result.Author('Ali Arya'), arxiv.Result.Author('Luciara Nardon'), arxiv.Result.Author('Md Riyadh')]","This paper addresses the role of Information and Communication Technology
(ICT) in migration governance, support, and experience with particular
attention to emerging technologies such as artificial intelligence, social
media, and virtual reality. We propose a framework for technology use based on
user groups and process types. We provide examples of using emerging
technologies for migration-related tasks within the context of this framework.
We then identify how such technologies can be applied to migration-related
tasks, developed for customized use, and improved through research to add new
features that can help different migration stakeholders. We suggest a series of
possible directions for future research and development to take advantage of
specific affordances of those emerging technologies more effectively."
5045,further research to validate this finding.,"How-
attempts with hints (13%) and the attempts that did not use hints         ever, the small size of this group and the weak effect size require
(15%).","The interviews with the
                                                                          teaching staff indicated that the main advantage of introducing
                                                                          Preg formative quizzes was significantly reducing the number of
Pattern Matching and String Completion for Teaching Programming                                             ICSE-SEET ’22, May 21–29, 2022, Pittsburgh, PA, USA

Table 4: The exam quiz score by the activity in using forma-          be automated, developing a special tool for creating this question
tive quizzes during the semester                                      bank was found unnecessary.",2022-04-19 17:53:35+00:00,Write a Line: Tests with Answer Templates and String Completion Hints for Self-Learning in a CS1 Course,cs.CY,"['cs.CY', 'K.3.2']",[arxiv.Result.Author('Oleg Sychev')],"One of the important scaffolding tasks in programming learning is writing a
line of code performing the necessary action. This allows students to practice
skills in a playground with instant feedback before writing more complex
programs and increases their proficiency when solving programming problems.
However, answers in the form of program code have high variability. Among the
possible approaches to grading and providing feedback, we chose template
matching. This paper reports the results of using regular-expression-based
questions with string completion hints in a CS1 course for 4 years with 497
students. The evaluation results show that Perl-compatible regular expressions
provide good precision and recall (more than 99\%) when used for questions
requiring writing a single line of code while being able to provide
string-completion feedback regardless of how wrong the initial student's answer
is. After introducing formative quizzes with string-completion hints to the
course, the number of questions that teachers and teaching assistants received
about questions in the formative quizzes dropped considerably: most of the
training question attempts resulted in finding the correct answer without help
from the teaching staff. However, some of the students use formative quizzes
just to learn correct answers without actually trying to answer the questions."
5046,"EURCON.2007.4400374
This requires further research.","https://doi.org/10.1109/
as a marker of poorly-performing students needing more attention.","The main effect of training with
hints seems to be saving teachers’ time rather than learning gains      [7] Steven Burrows, Iryna Gurevych, and Benno Stein.",2022-04-19 17:53:35+00:00,Write a Line: Tests with Answer Templates and String Completion Hints for Self-Learning in a CS1 Course,cs.CY,"['cs.CY', 'K.3.2']",[arxiv.Result.Author('Oleg Sychev')],"One of the important scaffolding tasks in programming learning is writing a
line of code performing the necessary action. This allows students to practice
skills in a playground with instant feedback before writing more complex
programs and increases their proficiency when solving programming problems.
However, answers in the form of program code have high variability. Among the
possible approaches to grading and providing feedback, we chose template
matching. This paper reports the results of using regular-expression-based
questions with string completion hints in a CS1 course for 4 years with 497
students. The evaluation results show that Perl-compatible regular expressions
provide good precision and recall (more than 99\%) when used for questions
requiring writing a single line of code while being able to provide
string-completion feedback regardless of how wrong the initial student's answer
is. After introducing formative quizzes with string-completion hints to the
course, the number of questions that teachers and teaching assistants received
about questions in the formative quizzes dropped considerably: most of the
training question attempts resulted in finding the correct answer without help
from the teaching staff. However, some of the students use formative quizzes
just to learn correct answers without actually trying to answer the questions."
5206,"Finally, the operational phase indicates a period
and motivate further research.","Below we discuss how our ﬁndings           phases over time, change not just their beliefs but also their
may impact the understanding of online CT participation         behaviors.","in which individuals get mentally or physically prepared to
                                                                commit acts that advance their radical objectives in the real
Monologicality as a varying process: While not all con-         world.",2022-04-22 14:31:53+00:00,Pathways through Conspiracy: The Evolution of Conspiracy Radicalization through Engagement in Online Conspiracy Discussions,cs.CY,"['cs.CY', 'cs.CL', 'cs.SI']","[arxiv.Result.Author('Shruti Phadke'), arxiv.Result.Author('Mattia Samory'), arxiv.Result.Author('Tanushree Mitra')]","The disruptive offline mobilization of participants in online conspiracy
theory (CT) discussions has highlighted the importance of understanding how
online users may form radicalized conspiracy beliefs. While prior work
researched the factors leading up to joining online CT discussions and provided
theories of how conspiracy beliefs form, we have little understanding of how
conspiracy radicalization evolves after users join CT discussion communities.
In this paper, we provide the empirical modeling of various radicalization
phases in online CT discussion participants. To unpack how conspiracy
engagement is related to radicalization, we first characterize the users'
journey through CT discussions via conspiracy engagement pathways.
Specifically, by studying 36K Reddit users through their 169M contributions, we
uncover four distinct pathways of conspiracy engagement: steady high,
increasing, decreasing, and steady low. We further model three successive
stages of radicalization guided by prior theoretical works. Specific
sub-populations of users, namely those on steady high and increasing conspiracy
engagement pathways, progress successively through various radicalization
stages. In contrast, users on the decreasing engagement pathway show distinct
behavior: they limit their CT discussions to specialized topics, participate in
diverse discussion groups, and show reduced conformity with conspiracy
subreddits. By examining users who disengage from online CT discussions, this
paper provides promising insights about conspiracy recovery process."
5237,"An abnormal conﬁguration hunting method is then
knowledge bases for protection and further research.","Together        proposed in [178] to account for user similarities and abnor-
these tools provide cybersecurity professionals with strong     malities.","introduced to search for improper assignments and then
                                                                make suggestions for the proper conﬁguration regarding
6.3.2 Documents                                                 the clustering results [178].",2022-04-23 14:03:36+00:00,"Turning the Hunted into the Hunter via Threat Hunting: Life Cycle, Ecosystem, Challenges and the Great Promise of AI",cs.CY,['cs.CY'],"[arxiv.Result.Author('Caroline Hillier'), arxiv.Result.Author('Talieh Karroubi')]","The threat hunting lifecycle is a complex atmosphere that requires special
attention from professionals to maintain security. This paper is a collection
of recent work that gives a holistic view of the threat hunting ecosystem,
identifies challenges, and discusses the future with the integration of
artificial intelligence (AI). We specifically establish a life cycle and
ecosystem for privacy-threat hunting in addition to identifying the related
challenges. We also discovered how critical the use of AI is in threat hunting.
This work paves the way for future work in this area as it provides the
foundational knowledge to make meaningful advancements for threat hunting."
5268,"2829, 2021.
work, we aim at conducting a further study on multimodal
emotional feature fusion in rumor detection.","In future                      Proceedings, vol.","[14] Z. Jin, J. Cao, H. Guo, Y. Zhang, and J. Luo, “Multimodal fusion
                                                                                  with recurrent neural networks for rumor detection on microblogs,” in
                        ACKNOWLEDGMENTS                                           Proceedings of the 25th ACM international conference on Multimedia,
                                                                                  2017, pp.",2022-04-25 08:53:05+00:00,Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor Detection,cs.CY,"['cs.CY', 'cs.CV']","[arxiv.Result.Author('Ge Wang'), arxiv.Result.Author('Li Tan'), arxiv.Result.Author('Ziliang Shang'), arxiv.Result.Author('He Liu')]","In recent years, rumors have had a devastating impact on society, making
rumor detection a significant challenge. However, the studies on rumor
detection ignore the intense emotions of images in the rumor content. This
paper verifies that the image emotion improves the rumor detection efficiency.
A Multimodal Dual Emotion feature in rumor detection, which consists of visual
and textual emotions, is proposed. To the best of our knowledge, this is the
first study which uses visual emotion in rumor detection. The experiments on
real datasets verify that the proposed features outperform the state-of-the-art
sentiment features, and can be extended in rumor detectors while improving
their performance."
5269,"In future
   In order to further compare the importance of image emo-       work, we aim at conducting a further study on multimodal
tion for rumor detection, the part of the rumor detector is       emotional feature fusion in rumor detection.","This study will also bring a novel idea of exploring
                                                                  multimodal emotion to the ﬁeld of rumor detection.",removed in the experiment.,2022-04-25 08:53:05+00:00,Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor Detection,cs.CY,"['cs.CY', 'cs.CV']","[arxiv.Result.Author('Ge Wang'), arxiv.Result.Author('Li Tan'), arxiv.Result.Author('Ziliang Shang'), arxiv.Result.Author('He Liu')]","In recent years, rumors have had a devastating impact on society, making
rumor detection a significant challenge. However, the studies on rumor
detection ignore the intense emotions of images in the rumor content. This
paper verifies that the image emotion improves the rumor detection efficiency.
A Multimodal Dual Emotion feature in rumor detection, which consists of visual
and textual emotions, is proposed. To the best of our knowledge, this is the
first study which uses visual emotion in rumor detection. The experiments on
real datasets verify that the proposed features outperform the state-of-the-art
sentiment features, and can be extended in rumor detectors while improving
their performance."
5270,"at conducting a further study on multimodal emotional feature
fusion in rumor detection.",849–857.,"D. Khattar, J. S. Goud, M. Gupta, V. Varma, Mvae: Multimodal variational
                                                                                    autoencoder for fake news detection, in: The world wide web conference,
ACKNOWLEDGMENTS                                                                     2019, pp.",2022-04-25 08:53:05+00:00,Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor Detection,cs.CY,"['cs.CY', 'cs.CV']","[arxiv.Result.Author('Ge Wang'), arxiv.Result.Author('Li Tan'), arxiv.Result.Author('Ziliang Shang'), arxiv.Result.Author('He Liu')]","In recent years, rumors have had a devastating impact on society, making
rumor detection a significant challenge. However, the studies on rumor
detection ignore the intense emotions of images in the rumor content. This
paper verifies that the image emotion improves the rumor detection efficiency.
A Multimodal Dual Emotion feature in rumor detection, which consists of visual
and textual emotions, is proposed. To the best of our knowledge, this is the
first study which uses visual emotion in rumor detection. The experiments on
real datasets verify that the proposed features outperform the state-of-the-art
sentiment features, and can be extended in rumor detectors while improving
their performance."
5271,"Fields such as real-time visu-
alization and learning, unsuprevised learning, and early detection of rumors are
challenging work that have not yet been resolved and require further research.","To some extent, this work helps new researchers understand the latest
developments in the direction of rumor detection and helps newcomers adapt
to the ﬁeld more quickly and sort out their ideas.","There is still a long way to improve the accuracy of rumor detection and apply
the research content.",2022-04-25 10:21:23+00:00,Research Status of Deep Learning Methods for Rumor Detection,cs.CY,['cs.CY'],"[arxiv.Result.Author('Li Tan'), arxiv.Result.Author('Ge Wang'), arxiv.Result.Author('Feiyang Jia'), arxiv.Result.Author('Xiaofeng Lian')]","To manage the rumors in social media to reduce the harm of rumors in society.
Many studies used methods of deep learning to detect rumors in open networks.
To comprehensively sort out the research status of rumor detection from
multiple perspectives, this paper analyzes the highly focused work from three
perspectives: Feature Selection, Model Structure, and Research Methods. From
the perspective of feature selection, we divide methods into content feature,
social feature, and propagation structure feature of the rumors. Then, this
work divides deep learning models of rumor detection into CNN, RNN, GNN,
Transformer based on the model structure, which is convenient for comparison.
Besides, this work summarizes 30 works into 7 rumor detection methods such as
propagation trees, adversarial learning, cross-domain methods, multi-task
learning, unsupervised and semi-supervised methods, based knowledge graph, and
other methods for the first time. And compare the advantages of different
methods to detect rumors. In addition, this review enumerate datasets available
and discusses the potential issues and future work to help researchers advance
the development of field."
5370,"However, the data has been compiled for all
                   these countries and is presented in this dataset to support further research and
                   development in this field.","For paucity
                   of space, we could not provide the results representing this classification for the
                   remaining 37 countries in this paper.","CONCLUSIONS

                   The E-learning industry, one of the largest and fastest-growing industries on a global
                   scale, has experienced several developments and the emergence of technologies in
                   the last decade and a half.",2022-04-27 01:29:31+00:00,Investigating the Emergence of Online Learning in Different Countries using the 5 W's and 1 H Approach,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC', 'cs.NI']","[arxiv.Result.Author('Nirmalya Thakur'), arxiv.Result.Author('Isabella Hall'), arxiv.Result.Author('Chia Y. Han')]","The rise of the Internet of Everything lifestyle in the last decade has had a
significant impact on the increased emergence and adoption of online learning
in almost all countries across the world. E-learning 3.0 is expected to become
the norm of learning globally in almost all sectors in the next few years. The
pervasiveness of the Semantic Web powered by the Internet of Everything
lifestyle is expected to play a huge role towards seamless and faster adoption
of the emerging paradigms of E-learning 3.0. Therefore, this paper presents an
exploratory study to analyze multimodal components of Semantic Web behavior
data to investigate the emergence of online learning in different countries
across the world. The work specifically involved investigating relevant web
behavior data to interpret the 5 W's and 1 H - Who, What, When Where, Why, and
How related to online learning. Based on studying the E-learning Index of 2021,
the study was performed for all the countries that are member states of the
Organization for Economic Cooperation and Development. The results presented
and discussed help to interpret the emergence of online learning in each of
these countries in terms of the associated public perceptions, queries,
opinions, behaviors, and perspectives. Furthermore, to support research and
development in this field, we have published the web behavior-based Big Data
related to online learning that was mined for all these 38 countries, in the
form of a dataset, which is avail-able at
https://dx.doi.org/10.21227/xbvs-0198."
5392,This survey hopes to provide a starting point for further research.,"Third school of thought believes that bounds of bounded rationality will be extended
                                        by advances in AI and various other ﬁelds.","Additional Key Words and Phrases: rationality, bounded, data, information, knowledge, intelligence, artiﬁcial

                                        1 INTRODUCTION

                                        Rationality has been an intriguing topic for a long time.",2022-04-27 12:09:41+00:00,Rationality in current era -- A recent survey,cs.CY,['cs.CY'],[arxiv.Result.Author('Dibakar Das')],"Rationality has been an intriguing topic for several decades. Even the scope
of definition of rationality across different subjects varies. Several theories
(e.g., game theory) initially evolved on the basis that agents (e.g., humans)
are perfectly rational. One interpretation of perfect rationality is that
agents always make the optimal decision which maximizes their expected
utilities. However, subsequently this assumption was relaxed to include bounded
rationality where agents have limitations in terms of computing resources and
biases which prevents them to take the optimal decision. However, with recent
advances in (quantum) computing, artificial intelligence (AI), science and
technology etc., has led to the thought that perhaps the concept of rationality
would be augmented with machine intelligence which will enable agents to take
decision optimally with higher regularity. However, there are divergent views
on this topic. The paper attempts to put forward a recent survey (last five
years) of research on these divergent views. These viewsmay be grouped into
three schools of thoughts. The first school is the one which is sceptical of
progress of AI and believes that human intelligencewill always supersede
machine intelligence. The second school of thought thinks that advent of AI and
advances in computing will help in better understanding of bounded rationality.
Third school of thought believes that bounds of bounded rationality will be
extended by advances in AI and various other fields. This survey hopes to
provide a starting point for further research."
5393,"The degrees and the dimensions of enhanced rationality that are going to impact mankind either way is an open
question for further research.","There are several
models which are limited in scope and have to be broadened to understand the implications on mankind in a holistic
sense.","Whereas the hope is always for the best, but, time will show the consequences, and
mankind will experience those changes whichever way these developments proceed in future.",2022-04-27 12:09:41+00:00,Rationality in current era -- A recent survey,cs.CY,['cs.CY'],[arxiv.Result.Author('Dibakar Das')],"Rationality has been an intriguing topic for several decades. Even the scope
of definition of rationality across different subjects varies. Several theories
(e.g., game theory) initially evolved on the basis that agents (e.g., humans)
are perfectly rational. One interpretation of perfect rationality is that
agents always make the optimal decision which maximizes their expected
utilities. However, subsequently this assumption was relaxed to include bounded
rationality where agents have limitations in terms of computing resources and
biases which prevents them to take the optimal decision. However, with recent
advances in (quantum) computing, artificial intelligence (AI), science and
technology etc., has led to the thought that perhaps the concept of rationality
would be augmented with machine intelligence which will enable agents to take
decision optimally with higher regularity. However, there are divergent views
on this topic. The paper attempts to put forward a recent survey (last five
years) of research on these divergent views. These viewsmay be grouped into
three schools of thoughts. The first school is the one which is sceptical of
progress of AI and believes that human intelligencewill always supersede
machine intelligence. The second school of thought thinks that advent of AI and
advances in computing will help in better understanding of bounded rationality.
Third school of thought believes that bounds of bounded rationality will be
extended by advances in AI and various other fields. This survey hopes to
provide a starting point for further research."
5437,"The reason for these differences in propensity of keeping
various records in an electronic or hardcopy format will require further research.","Conversely, only 10% of respondents kept receipts and warranties for appliances or
medical records in an electronic format.","Keywords: Personal Electronic Records Management, (PERM), Personal information management
(PIM), Records management, email, folders

Introduction

Prior research (Balogh, Kennan, Billingsley, & Paul, 2022) has found a diversity of ways in which
respondents manage their personal records.",2022-04-28 04:33:39+00:00,The Paper Pile at Home: Adopting Personal Electronic Records,cs.CY,['cs.CY'],[arxiv.Result.Author('Matt Balogh')],"Research has found that if respondents do not manage their personal records
such as bills, receipts and tax-related documents efficiently, they risk not
being able to re-find them when needed, resulting in significant problems. A
significant gap in understanding and addressing this problem stems from a lack
of knowledge of the format of these records, particularly in the context of the
COVID-19 pandemic, that may have caused an increase in managing personal
records in an electronic format, rather than by hardcopy. This paper provides
results of quantitative research conducted in 2018, thereby providing a
valuable benchmark for future research on the same and related topics. This
measurement was achieved by means of an online survey distributed via social
media amongst 205 respondents. The results revealed that nearly all respondents
(97%) retained at least some records, and more than 80% kept some of those
records in an electronic format, particularly travel reservations and payslips.
Conversely, only 10% of respondents kept receipts and warranties for appliances
or medical records in an electronic format. The reason for these differences in
propensity of keeping various records in an electronic or hardcopy format will
require further research."
5438,"P a g e 3 | 11
                      Tax returns and tax assessments                                                           97%
              Receipts and warranties for appliances                                                          95%
                                                                                                              94%
                                       Hotel reservations                                                    94%
                 Travel reservations, eg airline tickets                                                    93%
                                                                                                       85%
                       Vehicle registration documents                                                  85%
                                      Appliance manuals                                             81%
                                         Bank statements                                          79%
                                                                                                76%
   Other tax deductible receipts such as donations                                      64%
                                                    Payslips                    54%
                                                                              52%
Home utility bills, eg electricity, gas, water, council       29% sorted in descending order
                              Business expense receipts                     (from pre-determined list)
                                         Medical receipts                               n=205
                             Share dividend statements

                 Rental statements from investments

Figure 1: Propensity to retain personal records

Amongst the most prevalently retained records were travel and accommodation bookings, although
further research would need to be conducted to determine whether these are kept after the travel event
has occurred.","The vast majority also kept manuals for appliances (85%), a similar
proportion keep bank statements and eight-in-ten kept receipts for tax deductible expenses (81%) and
payslips (79%).","The graph in figure 1 shows that most respondents in this research retained all but one of the types of
records asked about in the question.",2022-04-28 04:33:39+00:00,The Paper Pile at Home: Adopting Personal Electronic Records,cs.CY,['cs.CY'],[arxiv.Result.Author('Matt Balogh')],"Research has found that if respondents do not manage their personal records
such as bills, receipts and tax-related documents efficiently, they risk not
being able to re-find them when needed, resulting in significant problems. A
significant gap in understanding and addressing this problem stems from a lack
of knowledge of the format of these records, particularly in the context of the
COVID-19 pandemic, that may have caused an increase in managing personal
records in an electronic format, rather than by hardcopy. This paper provides
results of quantitative research conducted in 2018, thereby providing a
valuable benchmark for future research on the same and related topics. This
measurement was achieved by means of an online survey distributed via social
media amongst 205 respondents. The results revealed that nearly all respondents
(97%) retained at least some records, and more than 80% kept some of those
records in an electronic format, particularly travel reservations and payslips.
Conversely, only 10% of respondents kept receipts and warranties for appliances
or medical records in an electronic format. The reason for these differences in
propensity of keeping various records in an electronic or hardcopy format will
require further research."
5439,"There
is a clear opportunity to conduct further research on the incidence of personal records management
and the propensity to maintain personal records in an electronic format at home in order to identify
changes since the data for this research was collected in August 2018.","Against this backdrop, we can expect that the adoption of electronic
transactions and electronic keeping may well have increased substantially over 2020 to 2022.","Conclusion

This research provides a comparative measure of the incidence of retaining various personal records
in an electronic format.",2022-04-28 04:33:39+00:00,The Paper Pile at Home: Adopting Personal Electronic Records,cs.CY,['cs.CY'],[arxiv.Result.Author('Matt Balogh')],"Research has found that if respondents do not manage their personal records
such as bills, receipts and tax-related documents efficiently, they risk not
being able to re-find them when needed, resulting in significant problems. A
significant gap in understanding and addressing this problem stems from a lack
of knowledge of the format of these records, particularly in the context of the
COVID-19 pandemic, that may have caused an increase in managing personal
records in an electronic format, rather than by hardcopy. This paper provides
results of quantitative research conducted in 2018, thereby providing a
valuable benchmark for future research on the same and related topics. This
measurement was achieved by means of an online survey distributed via social
media amongst 205 respondents. The results revealed that nearly all respondents
(97%) retained at least some records, and more than 80% kept some of those
records in an electronic format, particularly travel reservations and payslips.
Conversely, only 10% of respondents kept receipts and warranties for appliances
or medical records in an electronic format. The reason for these differences in
propensity of keeping various records in an electronic or hardcopy format will
require further research."
5440,"The reason for these differences in propensity of keeping
various records in an electronic or hardcopy format will require further research.","Conversely, only 10% of respondents kept receipts and warranties for appliances or
medical records in an electronic format.","Keywords: Personal Electronic Records Management, (PERM), Personal information management
(PIM), Records management, email, folders

Introduction

Prior research (Balogh, Kennan, Billingsley, & Paul, 2022) has found a diversity of ways in which
respondents manage their personal records.",2022-04-28 04:33:39+00:00,The Paper Pile at Home: Adopting Personal Electronic Records,cs.CY,['cs.CY'],[arxiv.Result.Author('Matt Balogh')],"Research has found that if respondents do not manage their personal records
such as bills, receipts and tax-related documents efficiently, they risk not
being able to re-find them when needed, resulting in significant problems. A
significant gap in understanding and addressing this problem stems from a lack
of knowledge of the format of these records, particularly in the context of the
COVID-19 pandemic, that may have caused an increase in managing personal
records in an electronic format, rather than by hardcopy. This paper provides
results of quantitative research conducted in 2018, thereby providing a
valuable benchmark for future research on the same and related topics. This
measurement was achieved by means of an online survey distributed via social
media amongst 205 respondents. The results revealed that nearly all respondents
(97%) retained at least some records, and more than 80% kept some of those
records in an electronic format, particularly travel reservations and payslips.
Conversely, only 10% of respondents kept receipts and warranties for appliances
or medical records in an electronic format. The reason for these differences in
propensity of keeping various records in an electronic or hardcopy format will
require further research."
5441,"P a g e 3 | 11
                      Tax returns and tax assessments                                                           97%
              Receipts and warranties for appliances                                                          95%
                                                                                                              94%
                                       Hotel reservations                                                    94%
                 Travel reservations, eg airline tickets                                                    93%
                                                                                                       85%
                       Vehicle registration documents                                                  85%
                                      Appliance manuals                                             81%
                                         Bank statements                                          79%
                                                                                                76%
   Other tax deductible receipts such as donations                                      64%
                                                    Payslips                    54%
                                                                              52%
Home utility bills, eg electricity, gas, water, council       29% sorted in descending order
                              Business expense receipts                     (from pre-determined list)
                                         Medical receipts                               n=205
                             Share dividend statements

                 Rental statements from investments

Figure 1: Propensity to retain personal records

Amongst the most prevalently retained records were travel and accommodation bookings, although
further research would need to be conducted to determine whether these are kept after the travel event
has occurred.","The vast majority also kept manuals for appliances (85%), a similar
proportion keep bank statements and eight-in-ten kept receipts for tax deductible expenses (81%) and
payslips (79%).","The graph in figure 1 shows that most respondents in this research retained all but one of the types of
records asked about in the question.",2022-04-28 04:33:39+00:00,The Paper Pile at Home: Adopting Personal Electronic Records,cs.CY,['cs.CY'],[arxiv.Result.Author('Matt Balogh')],"Research has found that if respondents do not manage their personal records
such as bills, receipts and tax-related documents efficiently, they risk not
being able to re-find them when needed, resulting in significant problems. A
significant gap in understanding and addressing this problem stems from a lack
of knowledge of the format of these records, particularly in the context of the
COVID-19 pandemic, that may have caused an increase in managing personal
records in an electronic format, rather than by hardcopy. This paper provides
results of quantitative research conducted in 2018, thereby providing a
valuable benchmark for future research on the same and related topics. This
measurement was achieved by means of an online survey distributed via social
media amongst 205 respondents. The results revealed that nearly all respondents
(97%) retained at least some records, and more than 80% kept some of those
records in an electronic format, particularly travel reservations and payslips.
Conversely, only 10% of respondents kept receipts and warranties for appliances
or medical records in an electronic format. The reason for these differences in
propensity of keeping various records in an electronic or hardcopy format will
require further research."
5442,"There
is a clear opportunity to conduct further research on the incidence of personal records management
and the propensity to maintain personal records in an electronic format at home in order to identify
changes since the data for this research was collected in August 2018.","Against this backdrop, we can expect that the adoption of electronic
transactions and electronic keeping may well have increased substantially over 2020 to 2022.","Conclusion

This research provides a comparative measure of the incidence of retaining various personal records
in an electronic format.",2022-04-28 04:33:39+00:00,The Paper Pile at Home: Adopting Personal Electronic Records,cs.CY,['cs.CY'],[arxiv.Result.Author('Matt Balogh')],"Research has found that if respondents do not manage their personal records
such as bills, receipts and tax-related documents efficiently, they risk not
being able to re-find them when needed, resulting in significant problems. A
significant gap in understanding and addressing this problem stems from a lack
of knowledge of the format of these records, particularly in the context of the
COVID-19 pandemic, that may have caused an increase in managing personal
records in an electronic format, rather than by hardcopy. This paper provides
results of quantitative research conducted in 2018, thereby providing a
valuable benchmark for future research on the same and related topics. This
measurement was achieved by means of an online survey distributed via social
media amongst 205 respondents. The results revealed that nearly all respondents
(97%) retained at least some records, and more than 80% kept some of those
records in an electronic format, particularly travel reservations and payslips.
Conversely, only 10% of respondents kept receipts and warranties for appliances
or medical records in an electronic format. The reason for these differences in
propensity of keeping various records in an electronic or hardcopy format will
require further research."
5490,"I suggest a number of areas for further research that will assess the extent to which the granting
    of this option is driven by nonﬁnancial considerations.","It also suggests that the value of the innovation should be attributed primarily to the value
                                                                                                                of the tax arbitrage and to the reduction in after-tax transaction costs it made possible.","The Republic of Austria used approximately 30% of the $9.50 net proceeds from the sale of the
                                                                                                                SIGNs issue to hedge its contingent S&P 500 liability, leaving proceeds net of hedging costs amounting
                                                                                                                to $6.65.",2022-04-28 22:33:36+00:00,Investigating writing style as a contributor to gender gaps in science and technology,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Ekaterina Levitskaya'), arxiv.Result.Author('Kara Kedrick'), arxiv.Result.Author('Russell J. Funk')]","While universalism is a foundational principle of science, a growing stream
of research finds that scientific contributions are evaluated differently
depending on the gender of the author, with women tending to receive fewer
citations relative to men, even for work of comparable quality. Strikingly,
research also suggests that these gender gaps are visible even under blinded
review, wherein the evaluator is not aware of the gender of the author. In this
article, we consider whether gender differences in writing styles -- how men
and women communicate their work -- may contribute to these observed gender
gaps. We ground our investigation in a previously established framework for
characterizing the linguistic style of written text, which distinguishes
between two sets of features -- informational (i.e., features that emphasize
facts) and involved (i.e., features that emphasize relationships). Using a
large, matched sample of academic papers and patents, we find significant
differences in writing style by gender; women use more involved features in
their writing, a pattern that holds universally across fields. The magnitude of
the effect varies across fields, with larger gender differences observed in the
social sciences and arts humanities and smaller gaps in the physical sciences
and technology. Subsequently, we show that gender differences in writing style
may have parallels in reading preferences; papers and patents with more
informational features tend to be cited more by men, while those with more
involved features tend to be cited more by women, even after controlling for
the gender of the author, inventor, and patent attorney. Our findings suggest
that formal written text is not devoid of personal character, which could
contribute to bias in evaluation, thereby compromising the norm of
universalism."
5691,"This article’s purpose is to shed insight on the motivations for trans individuals choosing
computer science paths, while acting as a basis and call to action for further research.","As computer science education (traditional schooling or self-taught methods) is
integral to working in computer science fields, a simple research survey was conducted to gather
data on 138 trans people’s experiences with computer science & computer science education.","Introduction                                     states averaging roughly a 0.3% to 0.78%
Although not always the case [1], a binary       trans populous.",2022-05-03 15:06:23+00:00,Why The Trans Programmer?,cs.CY,['cs.CY'],[arxiv.Result.Author('Skye Kychenthal')],"Through online anecdotal evidence and online communities, there is an
in-group idea of trans people (specifically trans-feminine individuals)
disproportionately entering computer science education & fields. Existing data
suggests this is a plausible trend, yet no research has been done into exactly
why. As computer science education (traditional schooling or self-taught
methods) is integral to working in computer science fields, a simple research
survey was conducted to gather data on 138 trans people's experiences with
computer science & computer science education. This article's purpose is to
shed insight on the motivations for trans individuals choosing computer science
paths, while acting as a basis and call to action for further research."
6128,"But the partial results confirm that the proposed system is a good choice for microlearning
management and encourage us to continue with further research.","Also, the grades of
the final exams could not be considered.","5 FUTURE RESEARCH

For future research, we propose to investigate the following important question: How can we extend
the use of the proposed system in the future?",2022-05-11 11:58:22+00:00,An Approach to Adaptive Microlearning in Higher Education,cs.CY,['cs.CY'],"[arxiv.Result.Author('Ovidiu Gherman'), arxiv.Result.Author('Cristina Elena Turcu'), arxiv.Result.Author('Corneliu Octavian Turcu')]","Current changes in society and the education system, cumulated with the
accelerated development of new technologies, entail inherent changes in the
educational process. Numerous studies have shown that the pandemic has forced a
rapid transformation of higher education. Thus, if before the pandemic digital
technologies were used to supplement the learning process, now they are the
main means of learning delivery. In addition, as previous research has shown,
new pedagogical strategies and new ways of teaching and learning are needed for
the current generation of students, the so-called Generation Z, to acquire new
knowledge and develop new skills. In this necessary evolution of the
educational process, a possible solution to increase the effectiveness of the
learning process for the Generation Z students is to use microlearning to
extend the traditional ways of learning. Many studies have shown that
microlearning, based on how today's students learn and memorize, facilitates
learning. In recent years there has been a growing trend in their use of
microlearning in the educational process. But, in order to be effective, this
approach must allow the individual knowledge building, by indicating a guiding
direction of the optimal path to achieve the proposed objectives. We propose a
system for personalized learning using microlearning, which provides support
and guidance to students based on their individual needs, in order to increase
their interest in learning, but also to compensate for various deficiencies in
their educational background. We also present a case study from the higher
education sector. Feedback from students and data collected during the semester
as a result of the students' behavioural analysis and their real learning
motivations will be used to improve the proposed system."
6785,"Focusing on the people-process-product constituting a creative system, we develop a taxonomy to stimulate exchange
and further research among the sociology of arts and the ML community.","In the context of ML creative systems, fashion
        designs [68], music recommendation systems [71], and animations [60] could be some example products.","Our study is informed by an multidisciplinary
perspective [65], comprising of a team whose expertise spans diverse fields such as sociology of music, film making,

                                                                                            2
Looking at Creative ML Blindspots with a Sociological Lens  Conference acronym ’XX, June 03–05, 2018, Woodstock, NY

visual and performing arts, computer vision, machine learning, and applied ethics.",2022-05-27 00:03:47+00:00,Looking at Creative ML Blindspots with a Sociological Lens,cs.CY,['cs.CY'],"[arxiv.Result.Author('Katharina Burgdorf'), arxiv.Result.Author('Negar Rostamzadeh'), arxiv.Result.Author('Ramya Srinivasan'), arxiv.Result.Author('Jennifer Lena')]","How can researchers from the creative ML/AI community and sociology of
culture engage in fruitful collaboration? How do researchers from both fields
think (differently) about creativity and the production of creative work? While
the ML community considers creativity as a matter of technical expertise and
acumen, social scientists have emphasized the role of embeddedness in cultural
production. This perspective aims to bridge both disciplines and proposes a
conceptual and methodological toolkit for collaboration. We provide a
systematic review of recent research in both fields and offer three
perspectives around which to structure interdisciplinary research on cultural
production: people, processes, and products. We thereby provide necessary
grounding work to support multidisciplinary researchers to navigate conceptual
and methodological hurdles in their collaboration. Our research will be of
interest to ML researchers and sociologists interested in creativity that aim
to conduct innovative research by bridging both fields."
6840,"Albeit this is assuming prices are within reasonable
12

bounds; and further research is warranted to truly understand how consumers will react
to prices that go beyond such bounds.","This means that organizations should make
sure that the technology is one that consumers find useful at the same time, knowing
that they can charge for this service without worrying that it may lead to disenfranchise-
ment on the part of the consumer.","Second, consumers are influenced by the opinion
of their peers when it comes to accepting this technology; consequently, “peer pressure
can be taken into consideration for marketing purposes” [15].",2022-05-28 00:36:27+00:00,Investigating End-user Acceptance of Last-mile Delivery by Autonomous Vehicles in the United States,cs.CY,"['cs.CY', 'cs.HC', 'cs.RO']","[arxiv.Result.Author('Antonios Saravanos'), arxiv.Result.Author('Olivia Verni'), arxiv.Result.Author('Ian Moore'), arxiv.Result.Author('Sall Aboubacar'), arxiv.Result.Author('Jen Arriaza'), arxiv.Result.Author('Sabrina Jivani'), arxiv.Result.Author('Audrey Bennett'), arxiv.Result.Author('Siqi Li'), arxiv.Result.Author('Dongnanzi Zheng'), arxiv.Result.Author('Stavros Zervoudakis')]","This paper investigates the end-user acceptance of last-mile delivery carried
out by autonomous vehicles within the United States. A total of 296
participants were presented with information on this technology and then asked
to complete a questionnaire on their perceptions to gauge their behavioral
intention concerning acceptance. Structural equation modeling of the partial
least squares flavor (PLS-SEM) was employed to analyze the collected data. The
results indicated that the perceived usefulness of the technology played the
greatest role in end-user acceptance decisions, followed by the influence of
others, and then the enjoyment received by interacting with the technology.
Furthermore, the perception of risk associated with using autonomous delivery
vehicles for last-mile delivery led to a decrease in acceptance. However, most
participants did not perceive the use of this technology to be risky. The paper
concludes by summarizing the implications our findings have on the respective
stakeholders and proposing the next steps in this area of research."
6841,"However, this is assuming prices are within
12

reasonable bounds, and further research is warranted to truly understand how consum-
ers will react to prices that go beyond such bounds.","This means that organizations should make
sure that the technology is one that consumers find useful at the same time, knowing
that they can charge for this service without worrying that it may lead to disenfranchise-
ment on the part of the consumer.","Second, consumers are influenced
by the opinion of their peers when it comes to accepting this technology; consequently,
“peer pressure can be taken into consideration for marketing purposes” [15].",2022-05-28 00:36:27+00:00,Investigating End-user Acceptance of Last-mile Delivery by Autonomous Vehicles in the United States,cs.CY,"['cs.CY', 'cs.HC', 'cs.RO']","[arxiv.Result.Author('Antonios Saravanos'), arxiv.Result.Author('Olivia Verni'), arxiv.Result.Author('Ian Moore'), arxiv.Result.Author('Sall Aboubacar'), arxiv.Result.Author('Jen Arriaza'), arxiv.Result.Author('Sabrina Jivani'), arxiv.Result.Author('Audrey Bennett'), arxiv.Result.Author('Siqi Li'), arxiv.Result.Author('Dongnanzi Zheng'), arxiv.Result.Author('Stavros Zervoudakis')]","This paper investigates the end-user acceptance of last-mile delivery carried
out by autonomous vehicles within the United States. A total of 296
participants were presented with information on this technology and then asked
to complete a questionnaire on their perceptions to gauge their behavioral
intention concerning acceptance. Structural equation modeling of the partial
least squares flavor (PLS-SEM) was employed to analyze the collected data. The
results indicated that the perceived usefulness of the technology played the
greatest role in end-user acceptance decisions, followed by the influence of
others, and then the enjoyment received by interacting with the technology.
Furthermore, the perception of risk associated with using autonomous delivery
vehicles for last-mile delivery led to a decrease in acceptance. However, most
participants did not perceive the use of this technology to be risky. The paper
concludes by summarizing the implications our findings have on the respective
stakeholders and proposing the next steps in this area of research."
6842,"However, this is assuming prices are within
12

reasonable bounds, and further research is warranted to truly understand how consum-
ers will react to prices that go beyond such bounds.","This means that organizations should make
sure that the technology is one that consumers find useful at the same time, knowing
that they can charge for this service without worrying that it may lead to disenfranchise-
ment on the part of the consumer.","Second, consumers are influenced
by the opinion of their peers when it comes to accepting this technology; consequently,
“peer pressure can be taken into consideration for marketing purposes” [15].",2022-05-28 00:36:27+00:00,Investigating End-user Acceptance of Last-mile Delivery by Autonomous Vehicles in the United States,cs.CY,"['cs.CY', 'cs.HC', 'cs.RO']","[arxiv.Result.Author('Antonios Saravanos'), arxiv.Result.Author('Olivia Verni'), arxiv.Result.Author('Ian Moore'), arxiv.Result.Author('Sall Aboubacar'), arxiv.Result.Author('Jen Arriaza'), arxiv.Result.Author('Sabrina Jivani'), arxiv.Result.Author('Audrey Bennett'), arxiv.Result.Author('Siqi Li'), arxiv.Result.Author('Dongnanzi Zheng'), arxiv.Result.Author('Stavros Zervoudakis')]","This paper investigates the end-user acceptance of last-mile delivery carried
out by autonomous vehicles within the United States. A total of 296
participants were presented with information on this technology and then asked
to complete a questionnaire on their perceptions to gauge their behavioral
intention concerning acceptance. Structural equation modeling of the partial
least squares flavor (PLS-SEM) was employed to analyze the collected data. The
results indicated that the perceived usefulness of the technology played the
greatest role in end-user acceptance decisions, followed by the influence of
others, and then the enjoyment received by interacting with the technology.
Furthermore, the perception of risk associated with using autonomous delivery
vehicles for last-mile delivery led to a decrease in acceptance. However, most
participants did not perceive the use of this technology to be risky. The paper
concludes by summarizing the implications our findings have on the respective
stakeholders and proposing the next steps in this area of research."
7075,"Regarding our
                                                                 future work, we intend to delve deeper into the available
   For the second lockdown, starting in November 2020, the       datasets and further study the impact of the pandemic on
PMV value started again from a value around -1 to a slightly     school operation, and especially as regards potential behavior
lower value.",have shifted considerable during the lockdown.,This time around the conditions did not deterio-    changes in students and educators.,2022-05-31 07:31:27+00:00,Understanding the Effect of the COVID-19 Pandemic on the Usage of School Buildings in Greece Using an IoT Data-Driven Analysis,cs.CY,"['cs.CY', 'cs.DC']","[arxiv.Result.Author('Georgios Mylonas'), arxiv.Result.Author('Dimitrios Amaxilatis'), arxiv.Result.Author('Ioannis Chatzigiannakis')]","The COVID-19 pandemic has brought profound change in the daily lives of a
large part of the global population during 2020 and 2021. Such changes were
mirrored in aspects such as changes to the overall energy consumption, or long
periods of sustained inactivity inside public buildings. At the same time, due
to the large proliferation of IoT, sensors and smartphones in the past few
years, we are able to monitor such changes to a certain degree over time. In
this paper, we focus on the effect of the pandemic on school buildings and
certain aspects in the operation of schools. Our study is based on data from a
number of school buildings equipped with an IoT infrastructure. The buildings
were situated in Greece, a country that faced an extended lockdown during both
2020 and 2021. Our results show that as regards power consumption there is room
for energy efficiency improvements since there was significant power
consumption during lockdown, and that using other sensor data we can also infer
interesting points regarding the buildings and activity during the lockdown."
7235,"In addition,
it illustrates the usability of self-determination theory to test      To conclude, further research by the cryptoeconomics com-
hypotheses of token designs on human behavior.",in the ﬁeld of Token Engineering and Economics.,"munity is required to identify why, how and in which situations
                                                                    cryptoeconomic incentives should be applied.",2022-05-10 11:36:57+00:00,To incentivize or not: Impact of blockchain-based cryptoeconmic tokens on human information sharing behavior,cs.CY,"['cs.CY', 'cs.HC', 'cs.SI']",[arxiv.Result.Author('Mark Christopher Ballandies')],"Cryptoeconomic incentives in the form of blockchain-based tokens are seen as
an enabler of the sharing economy which could shift society towards greater
sustainability. Nevertheless, knowledge about the impact of those tokens on
human sharing behavior is still limited, which challenges the design of
effective cryptoeconomic incentives. This study applies the theory of
self-determination to investigate the impact of those tokens on human behavior
in an information sharing scenario. By utilising an experimental methodology in
the form of a randomized control trial with a 2x2 factorial design involving
132 participants, the effects of two token incentives on human information
sharing behavior are analysed. Individuals obtain these tokens in exchange for
their shared information. Based on the collected tokens, individuals receive a
monetary payment and build reputation. Besides investigating the effect of
these incentives on the quantity of shared information, the study includes
quality characteristics of information, such as accuracy and contextualisation.
The focus on quantity while excluding quality has been identified as a
limitation in previous work. Besides confirming previously known effects such
as a crowding out of intrinsic motivation by incentives which also exists for
blockchain-based tokens, the findings of this work show a until now unreported
interaction effect between multiple tokens when applied simultaneously. The
findings are critically discussed and put into context of recent work and
ethical considerations. The theory-based, empirical study is of interest to
those investigating the effect of cryptoeconomic tokens or digital currencies
on human behavior and supports the community to design effective personalized
incentives for sharing economies."
7236,"Consequently, including these effects could        Thus, to conclude, further research by the cryptoeconomics
improve the correspondence of ﬁndings from these methodolo-        community is required to identify why, how, and in which
gies with reality.","the identiﬁed effects of this work on human behavior in
their assumptions.","Thus, this paper demonstrates the importance    situations cryptoeconomic incentives should be applied.",2022-05-10 11:36:57+00:00,To incentivize or not: Impact of blockchain-based cryptoeconomic tokens on human information sharing behavior,cs.CY,"['cs.CY', 'cs.HC', 'cs.SI']",[arxiv.Result.Author('Mark Christopher Ballandies')],"Cryptoeconomic incentives in the form of blockchain-based tokens are seen as
an enabler of the sharing economy that could shift society towards greater
sustainability. Nevertheless, knowledge of the impact of these tokens on human
sharing behavior is still limited and this poses a challenge to the design of
effective cryptoeconomic incentives. This study applies the theory of
self-determination to investigate the impact of such tokens on human behavior
in an information-sharing scenario. By utilizing an experimental methodology in
the form of a randomized control trial with a 2x2 factorial design involving
132 participants, the effects of two token incentives on human
information-sharing behavior are analyzed. Individuals obtain these tokens in
exchange for their shared information. Based on the collected tokens,
individuals receive a monetary payment and build reputation. Besides
investigating the effect of these incentives on the quantity of shared
information, the study includes quality characteristics of the information,
such as accuracy and contextualization. The focus on quantity while excluding
quality has been identified as a limitation in previous work. In addition to
confirming previously known effects such as a crowding-out of intrinsic
motivation by incentives, which also exists for blockchain-based tokens, the
findings of this paper point to a hitherto unreported interaction effect
between multiple tokens when applied simultaneously. The findings are
critically discussed and put into the context of recent work and ethical
considerations. The theory-based-empirical study is of interest to those
investigating the effect of cryptoeconomic tokens or digital currencies on
human behavior and supports the community in the design of effective
personalized incentives for sharing economies."
7237,"Consequently, including these effects could        Thus, to conclude, further research by the cryptoeconomics
improve the correspondence of ﬁndings from these methodolo-        community is required to identify why, how, and in which
gies with reality.","the identiﬁed effects of this work on human behavior in
their assumptions.","Thus, this paper demonstrates the importance    situations cryptoeconomic incentives should be applied.",2022-05-10 11:36:57+00:00,To incentivize or not: Impact of blockchain-based cryptoeconomic tokens on human information sharing behavior,cs.CY,"['cs.CY', 'cs.HC', 'cs.SI']",[arxiv.Result.Author('Mark Christopher Ballandies')],"Cryptoeconomic incentives in the form of blockchain-based tokens are seen as
an enabler of the sharing economy that could shift society towards greater
sustainability. Nevertheless, knowledge of the impact of these tokens on human
sharing behavior is still limited and this poses a challenge to the design of
effective cryptoeconomic incentives. This study applies the theory of
self-determination to investigate the impact of such tokens on human behavior
in an information-sharing scenario. By utilizing an experimental methodology in
the form of a randomized control trial with a 2x2 factorial design involving
132 participants, the effects of two token incentives on human
information-sharing behavior are analyzed. Individuals obtain these tokens in
exchange for their shared information. Based on the collected tokens,
individuals receive a monetary payment and build reputation. Besides
investigating the effect of these incentives on the quantity of shared
information, the study includes quality characteristics of the information,
such as accuracy and contextualization. The focus on quantity while excluding
quality has been identified as a limitation in previous work. In addition to
confirming previously known effects such as a crowding-out of intrinsic
motivation by incentives, which also exists for blockchain-based tokens, the
findings of this paper point to a hitherto unreported interaction effect
between multiple tokens when applied simultaneously. The findings are
critically discussed and put into the context of recent work and ethical
considerations. The theory-based-empirical study is of interest to those
investigating the effect of cryptoeconomic tokens or digital currencies on
human behavior and supports the community in the design of effective
personalized incentives for sharing economies."
7239,All these questions merit further research.,"Sky Arts
to guide their creative process rather than merely enabling     www.wingspanproductions.co.uk
it, or whether the musical was a popular and/or critical suc-
cess.","However,      Llano, M. T.; Colton, S.; Hepworth, R.; and Gow, J.",2022-05-11 13:36:02+00:00,The Beyond the Fence Musical and Computer Says Show Documentary,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']","[arxiv.Result.Author('Simon Colton'), arxiv.Result.Author('Maria Teresa Llano'), arxiv.Result.Author('Rose Hepworth'), arxiv.Result.Author('John Charnley'), arxiv.Result.Author('Catherine V. Gale'), arxiv.Result.Author('Archie Baron'), arxiv.Result.Author('Francois Pachet'), arxiv.Result.Author('Pierre Roy'), arxiv.Result.Author('Pablo Gervas'), arxiv.Result.Author('Nick Collins'), arxiv.Result.Author('Bob Sturm'), arxiv.Result.Author('Tillman Weyde'), arxiv.Result.Author('Daniel Wolff'), arxiv.Result.Author('James Robert Lloyd')]","During 2015 and early 2016, the cultural application of Computational
Creativity research and practice took a big leap forward, with a project where
multiple computational systems were used to provide advice and material for a
new musical theatre production. Billed as the world's first 'computer
musical... conceived by computer and substantially crafted by computer', Beyond
The Fence was staged in the Arts Theatre in London's West End during February
and March of 2016. Various computational approaches to analytical and
generative sub-projects were used to bring about the musical, and these efforts
were recorded in two 1-hour documentary films made by Wingspan Productions,
which were aired on SkyArts under the title Computer Says Show. We provide
details here of the project conception and execution, including details of the
systems which took on some of the creative responsibility in writing the
musical, and the contributions they made. We also provide details of the impact
of the project, including a perspective from the two (human) writers with
overall control of the creative aspects the musical."
7240,"The conclusion proposes directions
        for further research.","Section 3 is devoted to the explainability of algorith-
        mic decisions; it will confront and attempt to cross-reference legal concepts
        (in European and French law) with technical concepts and will highlight the
        plurality, even polysemy, of European and French legal texts relating to the
        explicability of algorithmic decisions.","1 Introduction

The fairness of algorithmic decisions based on machine learning has been a fun-
damental issue in computer science research for more than two decades; more re-

                                                1
cently, it has been the object of increasingly multidisciplinary research, to which
legal specialists and social scientists contribute.",2022-05-14 01:08:47+00:00,Fairness and Explainability in Automatic Decision-Making Systems. A challenge for computer science and law,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Thierry Kirat'), arxiv.Result.Author('Olivia Tambou'), arxiv.Result.Author('Virginie Do'), arxiv.Result.Author('Alexis Tsoukiàs')]","The paper offers a contribution to the interdisciplinary constructs of
analyzing fairness issues in automatic algorithmic decisions. Section 1 shows
that technical choices in supervised learning have social implications that
need to be considered. Section 2 proposes a contextual approach to the issue of
unintended group discrimination, i.e. decision rules that are facially neutral
but generate disproportionate impacts across social groups (e.g., gender, race
or ethnicity). The contextualization will focus on the legal systems of the
United States on the one hand and Europe on the other. In particular,
legislation and case law tend to promote different standards of fairness on
both sides of the Atlantic. Section 3 is devoted to the explainability of
algorithmic decisions; it will confront and attempt to cross-reference legal
concepts (in European and French law) with technical concepts and will
highlight the plurality, even polysemy, of European and French legal texts
relating to the explicability of algorithmic decisions. The conclusion proposes
directions for further research."
7244,"In terms of indirect control systems, explainability of recommendations
remains an issue that needs further study.",(2021)).,"The lack of explainable recom-
mendations lead users to ignore advice, reducing the eﬀectiveness of a system
and the trustworthiness of it (Zhang, Chen, et al.",2022-05-16 20:10:20+00:00,Intelligent Energy Management Systems -- A Review,cs.CY,['cs.CY'],"[arxiv.Result.Author('Stavros Mischos'), arxiv.Result.Author('Eleanna Dalagdi'), arxiv.Result.Author('Dimitris Vrakas')]","Climate change has become a major problem for humanity in the last two
decades. One of the reasons that caused it, is our daily energy waste. People
consume electricity in order to use home/work appliances and devices and also
reach certain levels of comfort while working or being at home. However, even
though the environmental impact of this behavior is not immediately observed,
it leads to increased CO2 emissions coming from energy generation from power
plants. Confronting such a problem efficiently will affect both the environment
and our society. Monitoring energy consumption in real-time, changing energy
wastage behavior of occupants and using automations with incorporated energy
savings scenarios, are ways to decrease global energy footprint. In this
review, we study intelligent systems for energy management in residential,
commercial and educational buildings, classifying them in two major categories
depending on whether they provide direct or indirect control. The article also
discusses what the strengths and weaknesses are, which optimization techniques
do they use and finally, provide insights about how these systems can be
improved in the future."
7245,"Conclusions & further research
In the context of a more human-centric Industry 4.0, the Industrial Internet pyramid proposed in
this study argues that an enterprise's transformation from an Automated Factory into a Smart
Factory will occur when there will be no more information asymmetry within and among
technology, process and people, thus achieving a fully (or quasi-fully) coupled human-machine
interaction.","@

 Op1   0,05 0,02      0,09       0   0         0,01  0,09 0,02      0,07 0
 Op2
 Op3   0,06       0   0,04 0,03      0,02 0,03       0,06 0,01      0,03 0,02
 Op4
 Op5   0,04       0   0,06 0,07      0,06 0,02       0,07       0   0,06 0
 Op6
 Op7   0,04       0   0,06 0,03      0,1 0,01        0,11       0   0                    0
 Op8
 Op9   0,05 0,04      0,1 0,02       0,08 0,02       0,04 0,02      0,03 0,01
Op10
Media  0,06 0,01      0,06 0,02      0,07 0,02       0,04 0,02      0,08 0,01
 LSD
       0,08       0   0,09 0,05      0,07 0,02       0,05 0,03      0,07 0,02
   >
       0,04       0   0,09       0   0,05       0    0,09 0,01      0,05 0,01

       0,05 0,01      0,06 0,06      0,08 0,04       0,07 0,02      0,12 0,03

       0,04 0,01      0,06 0,04      0,04 0,01       0,06 0,04      0,07 0,01

       0,051 0,009    0,071 0,032    0,057 0,018     0,068 0,017    0,058 0,011

       0,0199         0,0335            0,0353       0,0286            0,0376

           0,042          0,039          0,039           0,051          0,047

5.","The complexity of this transformation resides not only in the lack of clear
implementation guidelines in literature and of structured information but also in enabling and
convincing enterprises and operators (more familiar with legacy systems and traditional
procedures) to easily harness this knowledge.",2022-05-30 16:48:51+00:00,Ubiquitous knowledge empowers the Smart Factory: The impacts of a Service-oriented Digital Twin on enterprises' performance,cs.CY,['cs.CY'],"[arxiv.Result.Author('Francesco Longo'), arxiv.Result.Author('Letizia Nicoletti'), arxiv.Result.Author('Antonio Padovano')]","While the Industry 4.0 is idolizing the potential of an artificial
intelligence embedded into ""things"", it is neglecting the role of the human
component, which is still indispensable in different manufacturing activities,
such as a machine setup or maintenance operations. The present research study
first proposes an Industrial Internet pyramid as emergent human-centric
manufacturing paradigm within Industry 4.0 in which central is the role of a
Ubiquitous Knowledge about the manufacturing system intuitively accessed and
used by the manufacturing employees. Second, the prototype of a
Service-oriented Digital Twin, which leverage on a flexible ontology-oriented
knowledge structure and on augmented reality combined to a vocal interaction
system for an intuitive knowledge retrieval and fruition, has been designed and
developed to deliver this manufacturing knowledge. Two test-beds, complimentary
for the problems in practice (the former on the maintenance-production
interface in a large enterprise, the latter majorly focused in production and
setups in a small and medium enterprise), show the significant benefits in
terms of time, costs and process quality, thus validating the approach
proposed. This research shows that a human-centric and knowledge-driven
approach can drive the performance of Industry 4.0 initiatives and lead a Smart
Factory towards its full potential."
7248,"Avenues for further research, particularly
          in information behavior and practices, are suggested.","This suggests a moral
          opportunity for information professionals and scholars to work toward connecting people with
          information for hope, particularly in difficult times.","Topic areas: History and philosophy of information, Information behavior and practices
          Keywords: information ethics, hope, information sources

         Cease to lament for that thou canst not help,
         And study help for that which thou lament’st…
         Hope is a lover’s staff; walk hence with that
         And manage it against despairing thoughts.",2022-06-06 16:46:16+00:00,"Theorizing Information Sources for Hope: Belief, Desire, Imagination, and Metacognition",cs.CY,"['cs.CY', 'cs.HC', 'cs.IR']",[arxiv.Result.Author('Tim Gorichanaz')],"Introduction. Hope is a positive attitude oriented toward a possible (yet
uncertain), desired outcome. Though hope is a virtue, hopelessness is
widespread and seems related not only to current events but also to information
about current events. This paper examines how hope can be sparked through
information. Method. This study uses the philosophical methods of conceptual
analysis and design to advance a theoretical argument. Analysis. First, a
conceptualization of hope is offered, drawing on work primarily in virtue
ethics. Then, four types of information sources for hope are theorized,
building on and synthesizing work from philosophy and psychology. Results. Four
categories of information source conducive to hopefulness are identified:
information for forming beliefs about the past or future; information for
engaging the moral imagination regarding possibilities for the future;
information for sparking desire for particular moral outcomes; and information
for metacognition, or about how we become informed with respect to hope.
Conclusions. Hope is, in many cases, responsive to information. This suggests a
moral opportunity for information professionals and scholars to work toward
connecting people with information for hope, particularly in difficult times.
Avenues for further research, particularly in information behavior and
practices, are suggested."
7249,"In this paper, we will explore this notion in more depth, with an eye toward delineating the
categories of information sources that can contribute to hope and providing grounding for
further research.","In her words, “If you
don’t sit down and talk to people, how can you expect they’re going to change?” (Tippett,
2020).","Information sources can be defined as the entities in which information is
instantiated and thus able to inform people; examples include books, articles, podcasts and
other people.",2022-06-06 16:46:16+00:00,"Theorizing Information Sources for Hope: Belief, Desire, Imagination, and Metacognition",cs.CY,"['cs.CY', 'cs.HC', 'cs.IR']",[arxiv.Result.Author('Tim Gorichanaz')],"Introduction. Hope is a positive attitude oriented toward a possible (yet
uncertain), desired outcome. Though hope is a virtue, hopelessness is
widespread and seems related not only to current events but also to information
about current events. This paper examines how hope can be sparked through
information. Method. This study uses the philosophical methods of conceptual
analysis and design to advance a theoretical argument. Analysis. First, a
conceptualization of hope is offered, drawing on work primarily in virtue
ethics. Then, four types of information sources for hope are theorized,
building on and synthesizing work from philosophy and psychology. Results. Four
categories of information source conducive to hopefulness are identified:
information for forming beliefs about the past or future; information for
engaging the moral imagination regarding possibilities for the future;
information for sparking desire for particular moral outcomes; and information
for metacognition, or about how we become informed with respect to hope.
Conclusions. Hope is, in many cases, responsive to information. This suggests a
moral opportunity for information professionals and scholars to work toward
connecting people with information for hope, particularly in difficult times.
Avenues for further research, particularly in information behavior and
practices, are suggested."
7250,"This framework provides the
conceptual grounding for further research on hope and information, for example in the field of
information behavior and practices, with specific suggestions for further work outlined in the
conclusion.","Next, I will suggest that there are four types of
information that can spark hope: information contributing to our understanding, to our
imagination, to our desires, and to our metacognition.","Defining hope: from belief to desire

Hope is a positive attitude oriented toward a possible (yet uncertain), desired outcome.",2022-06-06 16:46:16+00:00,"Theorizing Information Sources for Hope: Belief, Desire, Imagination, and Metacognition",cs.CY,"['cs.CY', 'cs.HC', 'cs.IR']",[arxiv.Result.Author('Tim Gorichanaz')],"Introduction. Hope is a positive attitude oriented toward a possible (yet
uncertain), desired outcome. Though hope is a virtue, hopelessness is
widespread and seems related not only to current events but also to information
about current events. This paper examines how hope can be sparked through
information. Method. This study uses the philosophical methods of conceptual
analysis and design to advance a theoretical argument. Analysis. First, a
conceptualization of hope is offered, drawing on work primarily in virtue
ethics. Then, four types of information sources for hope are theorized,
building on and synthesizing work from philosophy and psychology. Results. Four
categories of information source conducive to hopefulness are identified:
information for forming beliefs about the past or future; information for
engaging the moral imagination regarding possibilities for the future;
information for sparking desire for particular moral outcomes; and information
for metacognition, or about how we become informed with respect to hope.
Conclusions. Hope is, in many cases, responsive to information. This suggests a
moral opportunity for information professionals and scholars to work toward
connecting people with information for hope, particularly in difficult times.
Avenues for further research, particularly in information behavior and
practices, are suggested."
7251,"Avenues for further research, particularly
          in information behavior and practices, are suggested.","This suggests a moral
          opportunity for information professionals and scholars to work toward connecting people with
          information for hope, particularly in difficult times.","Topic areas: History and philosophy of information, Information behavior and practices
          Keywords: information ethics, hope, information sources

         Cease to lament for that thou canst not help,
         And study help for that which thou lament’st…
         Hope is a lover’s staff; walk hence with that
         And manage it against despairing thoughts.",2022-06-06 16:46:16+00:00,"Theorizing Information Sources for Hope: Belief, Desire, Imagination, and Metacognition",cs.CY,"['cs.CY', 'cs.HC', 'cs.IR']",[arxiv.Result.Author('Tim Gorichanaz')],"Introduction. Hope is a positive attitude oriented toward a possible (yet
uncertain), desired outcome. Though hope is a virtue, hopelessness is
widespread and seems related not only to current events but also to information
about current events. This paper examines how hope can be sparked through
information. Method. This study uses the philosophical methods of conceptual
analysis and design to advance a theoretical argument. Analysis. First, a
conceptualization of hope is offered, drawing on work primarily in virtue
ethics. Then, four types of information sources for hope are theorized,
building on and synthesizing work from philosophy and psychology. Results. Four
categories of information source conducive to hopefulness are identified:
information for forming beliefs about the past or future; information for
engaging the moral imagination regarding possibilities for the future;
information for sparking desire for particular moral outcomes; and information
for metacognition, or about how we become informed with respect to hope.
Conclusions. Hope is, in many cases, responsive to information. This suggests a
moral opportunity for information professionals and scholars to work toward
connecting people with information for hope, particularly in difficult times.
Avenues for further research, particularly in information behavior and
practices, are suggested."
7252,"In this paper, we will explore this notion in more depth, with an eye toward delineating the
categories of information sources that can contribute to hope and providing grounding for
further research.","In her words, “If you
don’t sit down and talk to people, how can you expect they’re going to change?” (Tippett,
2020).","Information sources can be defined as the entities in which information is
instantiated and thus able to inform people; examples include books, articles, podcasts and
other people.",2022-06-06 16:46:16+00:00,"Theorizing Information Sources for Hope: Belief, Desire, Imagination, and Metacognition",cs.CY,"['cs.CY', 'cs.HC', 'cs.IR']",[arxiv.Result.Author('Tim Gorichanaz')],"Introduction. Hope is a positive attitude oriented toward a possible (yet
uncertain), desired outcome. Though hope is a virtue, hopelessness is
widespread and seems related not only to current events but also to information
about current events. This paper examines how hope can be sparked through
information. Method. This study uses the philosophical methods of conceptual
analysis and design to advance a theoretical argument. Analysis. First, a
conceptualization of hope is offered, drawing on work primarily in virtue
ethics. Then, four types of information sources for hope are theorized,
building on and synthesizing work from philosophy and psychology. Results. Four
categories of information source conducive to hopefulness are identified:
information for forming beliefs about the past or future; information for
engaging the moral imagination regarding possibilities for the future;
information for sparking desire for particular moral outcomes; and information
for metacognition, or about how we become informed with respect to hope.
Conclusions. Hope is, in many cases, responsive to information. This suggests a
moral opportunity for information professionals and scholars to work toward
connecting people with information for hope, particularly in difficult times.
Avenues for further research, particularly in information behavior and
practices, are suggested."
7253,"This framework provides the
conceptual grounding for further research on hope and information, for example in the field of
information behavior and practices, with specific suggestions for further work outlined in the
conclusion.","Next, I will suggest that there are four types of
information that can spark hope: information contributing to our understanding, to our
imagination, to our desires, and to our metacognition.","Defining hope: from belief to desire

Hope is a positive attitude oriented toward a possible (yet uncertain), desired outcome.",2022-06-06 16:46:16+00:00,"Theorizing Information Sources for Hope: Belief, Desire, Imagination, and Metacognition",cs.CY,"['cs.CY', 'cs.HC', 'cs.IR']",[arxiv.Result.Author('Tim Gorichanaz')],"Introduction. Hope is a positive attitude oriented toward a possible (yet
uncertain), desired outcome. Though hope is a virtue, hopelessness is
widespread and seems related not only to current events but also to information
about current events. This paper examines how hope can be sparked through
information. Method. This study uses the philosophical methods of conceptual
analysis and design to advance a theoretical argument. Analysis. First, a
conceptualization of hope is offered, drawing on work primarily in virtue
ethics. Then, four types of information sources for hope are theorized,
building on and synthesizing work from philosophy and psychology. Results. Four
categories of information source conducive to hopefulness are identified:
information for forming beliefs about the past or future; information for
engaging the moral imagination regarding possibilities for the future;
information for sparking desire for particular moral outcomes; and information
for metacognition, or about how we become informed with respect to hope.
Conclusions. Hope is, in many cases, responsive to information. This suggests a
moral opportunity for information professionals and scholars to work toward
connecting people with information for hope, particularly in difficult times.
Avenues for further research, particularly in information behavior and
practices, are suggested."
7544,"Ultimately, we aim to encourage further research into this topic.","In this paper, we discuss concerns and opportunities raised by AI-driven hiring in relation to disability
                                        discrimination.","Hence, we establish some starting points and design
                                        a roadmap for ethicists, lawmakers, advocates as well as AI practitioners alike.",2022-06-13 13:32:37+00:00,"Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, Legal and Technical Analysis",cs.CY,['cs.CY'],"[arxiv.Result.Author('Maarten Buyl'), arxiv.Result.Author('Christina Cociancig'), arxiv.Result.Author('Cristina Frattone'), arxiv.Result.Author('Nele Roekens')]","Tackling algorithmic discrimination against persons with disabilities (PWDs)
demands a distinctive approach that is fundamentally different to that applied
to other protected characteristics, due to particular ethical, legal, and
technical challenges. We address these challenges specifically in the context
of artificial intelligence (AI) systems used in hiring processes (or automated
hiring systems, AHSs), in which automated assessment procedures are subject to
unique ethical and legal considerations and have an undeniable adverse impact
on PWDs. In this paper, we discuss concerns and opportunities raised by
AI-driven hiring in relation to disability discrimination. Ultimately, we aim
to encourage further research into this topic. Hence, we establish some
starting points and design a roadmap for ethicists, lawmakers, advocates as
well as AI practitioners alike."
7545,"With the aim of inspiring further research into this area, we provide an analysis of
the ethical, legal and technical challenges and opportunities for promoting social justice for job candidates with a
disability.","Even though PWDs ﬁnd no mention
in studies like this, it has been recognized that they face unique forms of discrimination in their everyday life, including
when they apply for a job [75].","First in Section 2, we argue that non-discrimination and inclusiveness should be regarded as moral obligations
to a distinguishable vulnerable group.",2022-06-13 13:32:37+00:00,"Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, Legal and Technical Analysis",cs.CY,['cs.CY'],"[arxiv.Result.Author('Maarten Buyl'), arxiv.Result.Author('Christina Cociancig'), arxiv.Result.Author('Cristina Frattone'), arxiv.Result.Author('Nele Roekens')]","Tackling algorithmic discrimination against persons with disabilities (PWDs)
demands a distinctive approach that is fundamentally different to that applied
to other protected characteristics, due to particular ethical, legal, and
technical challenges. We address these challenges specifically in the context
of artificial intelligence (AI) systems used in hiring processes (or automated
hiring systems, AHSs), in which automated assessment procedures are subject to
unique ethical and legal considerations and have an undeniable adverse impact
on PWDs. In this paper, we discuss concerns and opportunities raised by
AI-driven hiring in relation to disability discrimination. Ultimately, we aim
to encourage further research into this topic. Hence, we establish some
starting points and design a roadmap for ethicists, lawmakers, advocates as
well as AI practitioners alike."
7546,"Though we hope for further research into ways to model disabilities and provide reasonable accommodation, we
also point out two ways in which AI systems can already improve the experience of PWDs in the job market.","However, some of the accommodations we deem ethically and legally necessary may not yet be
possible to automate with present technology, due to the heterogeneity of disability that is so incongruent with the
current paradigm of machine learning that is consistently data-driven.","First,
we can leverage data-driven approaches to recommend reasonable accommodations to job seekers, employees and
employers.",2022-06-13 13:32:37+00:00,"Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, Legal and Technical Analysis",cs.CY,['cs.CY'],"[arxiv.Result.Author('Maarten Buyl'), arxiv.Result.Author('Christina Cociancig'), arxiv.Result.Author('Cristina Frattone'), arxiv.Result.Author('Nele Roekens')]","Tackling algorithmic discrimination against persons with disabilities (PWDs)
demands a distinctive approach that is fundamentally different to that applied
to other protected characteristics, due to particular ethical, legal, and
technical challenges. We address these challenges specifically in the context
of artificial intelligence (AI) systems used in hiring processes (or automated
hiring systems, AHSs), in which automated assessment procedures are subject to
unique ethical and legal considerations and have an undeniable adverse impact
on PWDs. In this paper, we discuss concerns and opportunities raised by
AI-driven hiring in relation to disability discrimination. Ultimately, we aim
to encourage further research into this topic. Hence, we establish some
starting points and design a roadmap for ethicists, lawmakers, advocates as
well as AI practitioners alike."
7547,"Yet even with this understanding, the technical adjustments needed
to provide accommodation are varied and challenging, presenting obvious risks for PWDs and therefore a demand for

                                                                                           15
FAccT ’22, June 21–24, 2022, Seoul, Republic of Korea                    Maarten Buyl, Christina Cociancig, Cristina Fra one, and Nele Roekens

further research and testing in the long term.","To some extent, this heterogeneity can be tackled
by employing AI to better understand disabilities.","In the short term, AI can oﬀer opportunities for PWDs by acting as a
source of information during the hiring process, either by assisting in providing reasonable accommodation in hiring
decisions that are not automated, or by presenting proof of the lack of accommodation in hiring decisions that are
automated.",2022-06-13 13:32:37+00:00,"Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, Legal and Technical Analysis",cs.CY,['cs.CY'],"[arxiv.Result.Author('Maarten Buyl'), arxiv.Result.Author('Christina Cociancig'), arxiv.Result.Author('Cristina Frattone'), arxiv.Result.Author('Nele Roekens')]","Tackling algorithmic discrimination against persons with disabilities (PWDs)
demands a distinctive approach that is fundamentally different to that applied
to other protected characteristics, due to particular ethical, legal, and
technical challenges. We address these challenges specifically in the context
of artificial intelligence (AI) systems used in hiring processes (or automated
hiring systems, AHSs), in which automated assessment procedures are subject to
unique ethical and legal considerations and have an undeniable adverse impact
on PWDs. In this paper, we discuss concerns and opportunities raised by
AI-driven hiring in relation to disability discrimination. Ultimately, we aim
to encourage further research into this topic. Hence, we establish some
starting points and design a roadmap for ethicists, lawmakers, advocates as
well as AI practitioners alike."
7578,"This notwithstanding, CSS researchers should prioritise the publication of well-
archived, high quality, and accessible datasets that enable the replication of results and the advancement of
further research (Hollingshead et al., 2021).","While transparent research
conduct can facilitate reproducibility and replicability, concerns about the privacy and anonymity of
research subjects should also factor into how training data, models, and results are made available to the
scientific community.","They should also pursue research design, analysis, and reporting
in an interpretability-aware manner that prioritises process transparency, the understandability of models,
and the accessibility and explainability of the rationale behind their results.",2022-06-12 09:51:19+00:00,"Don't ""research fast and break things"": On the ethics of Computational Social Science",cs.CY,"['cs.CY', 'cs.CL', 'cs.GT', 'cs.LG', 'cs.SI']",[arxiv.Result.Author('David Leslie')],"This article is concerned with setting up practical guardrails within the
research activities and environments of CSS. It aims to provide CSS scholars,
as well as policymakers and other stakeholders who apply CSS methods, with the
critical and constructive means needed to ensure that their practices are
ethical, trustworthy, and responsible. It begins by providing a taxonomy of the
ethical challenges faced by researchers in the field of CSS. These are
challenges related to (1) the treatment of research subjects, (2) the impacts
of CSS research on affected individuals and communities, (3) the quality of CSS
research and to its epistemological status, (4) research integrity, and (5)
research equity. Taking these challenges as a motivation for cultural
transformation, it then argues for the end-to-end incorporation of habits of
responsible research and innovation (RRI) into CSS practices, focusing on the
role that contextual considerations, anticipatory reflection, impact
assessment, public engagement, and justifiable and well-documented action
should play across the research lifecycle. In proposing the inclusion of habits
of RRI in CSS practices, the chapter lays out several practical steps needed
for ethical, trustworthy, and responsible CSS research activities. These
include stakeholder engagement processes, research impact assessments, data
lifecycle documentation, bias self-assessments, and transparent research
reporting protocols."
7686,"However, it is not clear why we ob-
serve these interaction patterns only for songs at the extreme ends of the novelty
score ranges, and these ﬁndings highlight an avenue for further research into how
O’Toole and Horv´at                                                                                Page 14 of 21

the attributes of cultural artifacts impact their likelihood of inﬂuencing the larger
cultural ecosystem.","A possible explanation is that these combinations of high and
low novelty scores impact how memorable a song is, even if they are more likely
to hurt the songs initial success probability.","Figure 8 Controlling for initial novelty, we see that diﬀerent combinations of high and low MIR
  and lyric novelty scores have diﬀerent impacts on the inﬂuence probability.",2022-06-15 18:25:39+00:00,Novelty and Cultural Evolution in Modern Popular Music,cs.CY,['cs.CY'],"[arxiv.Result.Author(""Katherine O'Toole""), arxiv.Result.Author('Emőke-Ágnes Horvát')]","The ubiquity of digital music consumption has made it possible to extract
information about modern music that allows us to perform large scale analysis
of stylistic change over time. In order to uncover underlying patterns in
cultural evolution, we examine the relationship between the established
characteristics of different genres and styles, and the introduction of novel
ideas that fuel this ongoing creative evolution. To understand how this dynamic
plays out and shapes the cultural ecosystem, we compare musical artifacts to
their contemporaries to identify novel artifacts, study the relationship
between novelty and commercial success, and connect this to the changes in
musical content that we can observe over time. Using Music Information
Retrieval (MIR) data and lyrics from Billboard Hot 100 songs between 1974-2013,
we calculate a novelty score for each song's aural attributes and lyrics.
Comparing both scores to the popularity of the song following its release, we
uncover key patterns in the relationship between novelty and audience
reception. Additionally, we look at the link between novelty and the likelihood
that a song was influential given where its MIR and lyrical features fit within
the larger trends we observed."
7687,"However, it is not clear why we
observe these interaction patterns only for songs at the extreme ends of the novelty
score ranges, and these ﬁndings highlight an avenue for further research into how
the attributes of cultural artifacts impact their likelihood of inﬂuencing the larger
cultural ecosystem.",likely to hurt the songs initial success probability.,"Figure 8 Controlling for initial novelty, we see that diﬀerent combinations of high and low MIR
  and lyric novelty scores have diﬀerent associations with changes in inﬂuence probability.",2022-06-15 18:25:39+00:00,Novelty and Cultural Evolution in Modern Popular Music,cs.CY,['cs.CY'],"[arxiv.Result.Author(""Katherine O'Toole""), arxiv.Result.Author('Emőke-Ágnes Horvát')]","The ubiquity of digital music consumption has made it possible to extract
information about modern music that allows us to perform large scale analysis
of stylistic change over time. In order to uncover underlying patterns in
cultural evolution, we examine the relationship between the established
characteristics of different genres and styles, and the introduction of novel
ideas that fuel this ongoing creative evolution. To understand how this dynamic
plays out and shapes the cultural ecosystem, we compare musical artifacts to
their contemporaries to identify novel artifacts, study the relationship
between novelty and commercial success, and connect this to the changes in
musical content that we can observe over time. Using Music Information
Retrieval (MIR) data and lyrics from Billboard Hot 100 songs between 1974-2013,
we calculate a novelty score for each song's aural attributes and lyrics.
Comparing both scores to the popularity of the song following its release, we
uncover key patterns in the relationship between novelty and audience
reception. Additionally, we look at the link between novelty and the likelihood
that a song was influential given where its MIR and lyrical features fit within
the larger trends we observed."
7948,"That is, we may
    We surveyed papers on the societal impacts of AI broadly,                           manage to train AI systems which can (perhaps fully)
identiﬁed potential impacts in the four above categories,                               automate tasks involved in the scientific process, such as
clustered them into areas, and did further research on each area.","persistent changes which affect how good the world is at
    every point in the far future, such as eliminating all disease).4               • AI could make it possible to automate an increased
                                                                                        proportion of the scientific process.",generating new ideas and running experiments.,2022-06-22 13:42:28+00:00,A Survey of the Potential Long-term Impacts of AI,cs.CY,['cs.CY'],"[arxiv.Result.Author('Sam Clarke'), arxiv.Result.Author('Jess Whittlestone')]","It is increasingly recognised that advances in artificial intelligence could
have large and long-lasting impacts on society. However, what form those
impacts will take, just how large and long-lasting they will be, and whether
they will ultimately be positive or negative for humanity, is far from clear.
Based on surveying literature on the societal impacts of AI, we identify and
discuss five potential long-term impacts of AI: how AI could lead to long-term
changes in science, cooperation, power, epistemics, and values. We review the
state of existing research in each of these areas and highlight priority
questions for future research."
7999,"To motivate further research on violence detection using multimodel
       approaches in real-time using wearable and portable technologies that
       can assess the violence level and send an alert.",3.,"Our data fusion approach developed at diﬀerent levels as follows:

   1.",2022-06-23 16:45:50+00:00,DeepSafety:Multi-level Audio-Text Feature Extraction and Fusion Approach for Violence Detection in Conversations,cs.CY,['cs.CY'],"[arxiv.Result.Author('Amna Anwar'), arxiv.Result.Author('Eiman Kanjo'), arxiv.Result.Author('Dario Ortega Anderez')]","Natural Language Processing has recently made understanding human interaction
easier, leading to improved sentimental analysis and behaviour prediction.
However, the choice of words and vocal cues in conversations presents an
underexplored rich source of natural language data for personal safety and
crime prevention. When accompanied by audio analysis, it makes it possible to
understand the context of a conversation, including the level of tension or
rift between people. Building on existing work, we introduce a new information
fusion approach that extracts and fuses multi-level features including verbal,
vocal, and text as heterogeneous sources of information to detect the extent of
violent behaviours in conversations. Our multilevel multimodel fusion framework
integrates four types of information from raw audio signals including
embeddings generated from both BERT and Bi-long short-term memory (LSTM) models
along with the output of 2D CNN applied to Mel-frequency Cepstrum (MFCC) as
well as the output of audio Time-Domain dense layer. The embeddings are then
passed to three-layer FC networks, which serve as a concatenated step. Our
experimental setup revealed that the combination of the multi-level features
from different modalities achieves better performance than using a single one
with F1 Score=0.85. We expect that the findings derived from our method
provides new approaches for violence detection in conversations."
8278,"Such false impressions can be counterproductive if
                                        they serve to discourage further research in this area, since, as                      e
                                        we discuss, eliminating computing’s, and more generally soci-
                                        ety’s, carbon emissions is far from a solved problem.","successes, which has the potential to inadvertently convey the
                                        false impression that this is now, or will soon be, a solved                       E=  d                                                       (1)
                                        problem.","To better                       Likewise, the growth rate rE in computing’s energy con-
                                        understand the problem’s scope, this paper distills the funda-                     sumption is simply a function of the growth rate in its demand
                                        mental trends that determine computing’s carbon footprint                          (rd) versus its energy-efﬁciency (re): if demand increases
                                        and their implications for achieving sustainable computing.",2022-06-30 19:48:33+00:00,Sustainable Computing -- Without the Hot Air,cs.CY,"['cs.CY', 'cs.DC', 'cs.LG']","[arxiv.Result.Author('Noman Bashir'), arxiv.Result.Author('David Irwin'), arxiv.Result.Author('Prashant Shenoy'), arxiv.Result.Author('Abel Souza')]","The demand for computing is continuing to grow exponentially. This growth
will translate to exponential growth in computing's energy consumption unless
improvements in its energy-efficiency can outpace increases in its demand. Yet,
after decades of research, further improving energy-efficiency is becoming
increasingly challenging, as it is already highly optimized. As a result, at
some point, increases in computing demand are likely to outpace increases in
its energy-efficiency, potentially by a wide margin. Such exponential growth,
if left unchecked, will position computing as a substantial contributor to
global carbon emissions. While prominent technology companies have recognized
the problem and sought to reduce their carbon emissions, they understandably
focus on their successes, which has the potential to inadvertently convey the
false impression that this is now, or will soon be, a solved problem. Such
false impressions can be counterproductive if they serve to discourage further
research in this area, since, as we discuss, eliminating computing's, and more
generally society's, carbon emissions is far from a solved problem. To better
understand the problem's scope, this paper distills the fundamental trends that
determine computing's carbon footprint and their implications for achieving
sustainable computing."
8279,"Unfortunately, such false impressions can be counter-
print is simply a function of the growth rate in its aggregate                productive if they unintentionally discourage further research,
energy consumption (rE ) versus its energy’s carbon-efﬁciency                 since, as we discuss, eliminating computing’s, and more gen-
(rc): if consumption increases faster than carbon-efﬁciency,                  erally society’s, real carbon emissions is far from a solved
i.e., rE > rc, then it will grow exponentially, and otherwise, it             problem.","For example, many technology compa-
Ed                                                                            nies have eliminated their net carbon emissions [3, 23, 37, 42],
C= =   (2)                                                                    which they often refer to as running on “100% renewable
c c×e                                                                         energy.” However, eliminating net carbon emissions is both
                                                                              different and much easier than eliminating direct carbon emis-
   Likewise, the growth rate rC in computing’s carbon foot-                   sions.","To better understand the problem’s scope, we exam-
will shrink.",2022-06-30 19:48:33+00:00,Sustainable Computing -- Without the Hot Air,cs.CY,"['cs.CY', 'cs.DC', 'cs.LG']","[arxiv.Result.Author('Noman Bashir'), arxiv.Result.Author('David Irwin'), arxiv.Result.Author('Prashant Shenoy'), arxiv.Result.Author('Abel Souza')]","The demand for computing is continuing to grow exponentially. This growth
will translate to exponential growth in computing's energy consumption unless
improvements in its energy-efficiency can outpace increases in its demand. Yet,
after decades of research, further improving energy-efficiency is becoming
increasingly challenging, as it is already highly optimized. As a result, at
some point, increases in computing demand are likely to outpace increases in
its energy-efficiency, potentially by a wide margin. Such exponential growth,
if left unchecked, will position computing as a substantial contributor to
global carbon emissions. While prominent technology companies have recognized
the problem and sought to reduce their carbon emissions, they understandably
focus on their successes, which has the potential to inadvertently convey the
false impression that this is now, or will soon be, a solved problem. Such
false impressions can be counterproductive if they serve to discourage further
research in this area, since, as we discuss, eliminating computing's, and more
generally society's, carbon emissions is far from a solved problem. To better
understand the problem's scope, this paper distills the fundamental trends that
determine computing's carbon footprint and their implications for achieving
sustainable computing."
8280,"ing, or even discourage further research altogether.","Such messaging is often pejoratively               employees), and as a hedge against future changes in the en-
referred to as “greenwashing.” False impressions of com-                  ergy system, such as energy constraints due to geopolitical
puting’s carbon footprint are a signiﬁcant issue, as they can             events, stricter carbon regulations imposed by governments,
diminish the perception of progress in decarbonizing comput-              or further signiﬁcant drops in renewable or battery prices.","Another reason for the lack of research may also be that
   In the end, as we discuss, the various forms of carbon                 optimizing carbon-efﬁciency requires deeper visibility into
accounting and offsets are temporary measures that, by deﬁ-               energy’s carbon emissions, which has historically not been
nition, will not be applicable at zero-carbon.",2022-06-30 19:48:33+00:00,Sustainable Computing -- Without the Hot Air,cs.CY,"['cs.CY', 'cs.DC', 'cs.LG']","[arxiv.Result.Author('Noman Bashir'), arxiv.Result.Author('David Irwin'), arxiv.Result.Author('Prashant Shenoy'), arxiv.Result.Author('Abel Souza')]","The demand for computing is continuing to grow exponentially. This growth
will translate to exponential growth in computing's energy consumption unless
improvements in its energy-efficiency can outpace increases in its demand. Yet,
after decades of research, further improving energy-efficiency is becoming
increasingly challenging, as it is already highly optimized. As a result, at
some point, increases in computing demand are likely to outpace increases in
its energy-efficiency, potentially by a wide margin. Such exponential growth,
if left unchecked, will position computing as a substantial contributor to
global carbon emissions. While prominent technology companies have recognized
the problem and sought to reduce their carbon emissions, they understandably
focus on their successes, which has the potential to inadvertently convey the
false impression that this is now, or will soon be, a solved problem. Such
false impressions can be counterproductive if they serve to discourage further
research in this area, since, as we discuss, eliminating computing's, and more
generally society's, carbon emissions is far from a solved problem. To better
understand the problem's scope, this paper distills the fundamental trends that
determine computing's carbon footprint and their implications for achieving
sustainable computing."
8401,"All students planned on
further study after completing secondary school.","Two students
liked to tell stories, and three students had immediate experience writing short stories.",Table 4.,2022-06-04 09:11:38+00:00,Secondary School Student-AI Creative Writing: Strategies from Text Generator Interactions,cs.CY,"['cs.CY', 'cs.CL']",[arxiv.Result.Author('David James Woo')],"Text generation is a function of artificial intelligence natural language
processing. Youths can learn to apply text generation in mainstream education.
To explore how students apply text generation to creative writing, we designed
and implemented the 1st Human-AI Creative Writing Contest in a Hong Kong
secondary school. In this contest, a student wrote a short story of up to 500
words using the student's own words and words from any of four text generators
designed for the contest and built on open-source language models.
Additionally, using design-based research, we developed seven workshops where
students wrote with text generators and answered reflection questions. In
analyzing four students' short stories, their reflections and adjudicators'
scores for the stories, we found different strategies in terms of the number
and the type of text generator words that students used. Some strategies
appeared more sophisticated than others. We also found differences in
sophistication when students described text generator input and output.
Besides, students showed preferences for text generators and they expressed a
range of feelings when writing with text generators. The findings provide
design implications not only for text generators in formal schooling but also
for AI curriculum."
8402,"All students
planned on further study after completing secondary school.","Two students liked to
tell stories, and three students had immediate experience writing short stories.",Table 4.,2022-06-04 09:11:38+00:00,Student-AI Creative Writing: Pedagogical Strategies for Applying Natural Language Generation in Schools,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('David James Woo'), arxiv.Result.Author('Yanzhi Wang'), arxiv.Result.Author('Hengky Susanto')]","AI natural language generation (NLG) is a process where computer systems
generate human-comprehensible language texts from information. It can become an
integral part of a human's creative writing process. Importantly, youths can
learn to apply NLG in mainstream education and become better prepared for
AI-enhanced writing jobs and other writing endeavors. To explore how students
apply NLG to creative writing, we designed and implemented the 1st Human-AI
Creative Writing Contest in a Hong Kong secondary school. In this contest, each
student participant wrote a short story of up to 500-words using the student's
own words and words generated by a computer and built on open-source language
models. We designed four text generators for the contest as the computer's text
entry. Additionally, using design-based research, we developed seven workshops
where students learned to write with the four text generators and answered
reflection questions. In analyzing four students' short stories and
adjudicators' scores for the stories, we found different strategies in terms of
the number and the type of text generator words that students used. Some
strategies appeared more sophisticated than others. In analyzing students'
reflections, we found students could describe text generator input and output
as units of thought. Besides, students showed preferences for text generators;
and they expressed a range of feelings when writing with text generators. The
findings provide design implications not only for NLG applications in formal
schooling but also suggest pedagogical strategies for AI curriculum."
8403,"Both datasets were made publicly available, with the aim to
promote further research on (synthetic) depth- and thermal-data-based vision tasks5.","[III.66] present their
own dataset comprising 8k image pairs.","The authors of [III.65] were among the first to highlight the potential of combining synthetic depth data
and machine learning, by example of human pose estimation.",2022-06-26 14:27:33+00:00,State of the Art of Audio- and Video-Based Solutions for AA,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC', 'cs.SD', 'eess.AS']","[arxiv.Result.Author('Slavisa Aleksic'), arxiv.Result.Author('Michael Atanasov'), arxiv.Result.Author('Jean Calleja Agius'), arxiv.Result.Author('Kenneth Camilleri'), arxiv.Result.Author('Anto Cartolovni'), arxiv.Result.Author('Pau Climent-Peerez'), arxiv.Result.Author('Sara Colantonio'), arxiv.Result.Author('Stefania Cristina'), arxiv.Result.Author('Vladimir Despotovic'), arxiv.Result.Author('Hazim Kemal Ekenel'), arxiv.Result.Author('Ekrem Erakin'), arxiv.Result.Author('Francisco Florez-Revuelta'), arxiv.Result.Author('Danila Germanese'), arxiv.Result.Author('Nicole Grech'), arxiv.Result.Author('Steinunn Gróa Sigurðardóttir'), arxiv.Result.Author('Murat Emirzeoglu'), arxiv.Result.Author('Ivo Iliev'), arxiv.Result.Author('Mladjan Jovanovic'), arxiv.Result.Author('Martin Kampel'), arxiv.Result.Author('William Kearns'), arxiv.Result.Author('Andrzej Klimczuk'), arxiv.Result.Author('Lambros Lambrinos'), arxiv.Result.Author('Jennifer Lumetzberger'), arxiv.Result.Author('Wiktor Mucha'), arxiv.Result.Author('Sophie Noiret'), arxiv.Result.Author('Zada Pajalic'), arxiv.Result.Author('Rodrigo Rodriguez Peerez'), arxiv.Result.Author('Galidiya Petrova'), arxiv.Result.Author('Sintija Petrovica'), arxiv.Result.Author('Peter Pocta'), arxiv.Result.Author('Angelica Poli'), arxiv.Result.Author('Mara Pudane'), arxiv.Result.Author('Susanna Spinsante'), arxiv.Result.Author('Albert Ali Salah'), arxiv.Result.Author('Maria Jose Santofimia'), arxiv.Result.Author('Anna Sigridur Islind'), arxiv.Result.Author('Lacramioara Stoicu-Tivadar'), arxiv.Result.Author('Hilda Tellioglu'), arxiv.Result.Author('Andrej Zgank')]","The report illustrates the state of the art of the most successful AAL
applications and functions based on audio and video data, namely (i)
lifelogging and self-monitoring, (ii) remote monitoring of vital signs, (iii)
emotional state recognition, (iv) food intake monitoring, activity and
behaviour recognition, (v) activity and personal assistance, (vi) gesture
recognition, (vii) fall detection and prevention, (viii) mobility assessment
and frailty recognition, and (ix) cognitive and motor rehabilitation. For these
application scenarios, the report illustrates the state of play in terms of
scientific advances, available products and research project. The open
challenges are also highlighted."
8404,"A
framework for which further research can be performed is presented.","Yet as technologies advance, the laws must stay abreast of such progress.","It concludes that AAL technologies
require a legal system that both promotes their development while at the same time safeguards against
risks posed by the technology.",2022-06-26 14:27:33+00:00,State of the Art of Audio- and Video-Based Solutions for AA,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC', 'cs.SD', 'eess.AS']","[arxiv.Result.Author('Slavisa Aleksic'), arxiv.Result.Author('Michael Atanasov'), arxiv.Result.Author('Jean Calleja Agius'), arxiv.Result.Author('Kenneth Camilleri'), arxiv.Result.Author('Anto Cartolovni'), arxiv.Result.Author('Pau Climent-Peerez'), arxiv.Result.Author('Sara Colantonio'), arxiv.Result.Author('Stefania Cristina'), arxiv.Result.Author('Vladimir Despotovic'), arxiv.Result.Author('Hazim Kemal Ekenel'), arxiv.Result.Author('Ekrem Erakin'), arxiv.Result.Author('Francisco Florez-Revuelta'), arxiv.Result.Author('Danila Germanese'), arxiv.Result.Author('Nicole Grech'), arxiv.Result.Author('Steinunn Gróa Sigurðardóttir'), arxiv.Result.Author('Murat Emirzeoglu'), arxiv.Result.Author('Ivo Iliev'), arxiv.Result.Author('Mladjan Jovanovic'), arxiv.Result.Author('Martin Kampel'), arxiv.Result.Author('William Kearns'), arxiv.Result.Author('Andrzej Klimczuk'), arxiv.Result.Author('Lambros Lambrinos'), arxiv.Result.Author('Jennifer Lumetzberger'), arxiv.Result.Author('Wiktor Mucha'), arxiv.Result.Author('Sophie Noiret'), arxiv.Result.Author('Zada Pajalic'), arxiv.Result.Author('Rodrigo Rodriguez Peerez'), arxiv.Result.Author('Galidiya Petrova'), arxiv.Result.Author('Sintija Petrovica'), arxiv.Result.Author('Peter Pocta'), arxiv.Result.Author('Angelica Poli'), arxiv.Result.Author('Mara Pudane'), arxiv.Result.Author('Susanna Spinsante'), arxiv.Result.Author('Albert Ali Salah'), arxiv.Result.Author('Maria Jose Santofimia'), arxiv.Result.Author('Anna Sigridur Islind'), arxiv.Result.Author('Lacramioara Stoicu-Tivadar'), arxiv.Result.Author('Hilda Tellioglu'), arxiv.Result.Author('Andrej Zgank')]","The report illustrates the state of the art of the most successful AAL
applications and functions based on audio and video data, namely (i)
lifelogging and self-monitoring, (ii) remote monitoring of vital signs, (iii)
emotional state recognition, (iv) food intake monitoring, activity and
behaviour recognition, (v) activity and personal assistance, (vi) gesture
recognition, (vii) fall detection and prevention, (viii) mobility assessment
and frailty recognition, and (ix) cognitive and motor rehabilitation. For these
application scenarios, the report illustrates the state of play in terms of
scientific advances, available products and research project. The open
challenges are also highlighted."
8405,"Both datasets were made publicly available, with the aim to
promote further research on (synthetic) depth- and thermal-data-based vision tasks5.","[III.66] present their
own dataset comprising 8k image pairs.","The authors of [III.65] were among the first to highlight the potential of combining synthetic depth data
and machine learning, by example of human pose estimation.",2022-06-26 14:27:33+00:00,State of the Art of Audio- and Video-Based Solutions for AAL,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC', 'cs.SD', 'eess.AS', 'I.2']","[arxiv.Result.Author('Slavisa Aleksic'), arxiv.Result.Author('Michael Atanasov'), arxiv.Result.Author('Jean Calleja Agius'), arxiv.Result.Author('Kenneth Camilleri'), arxiv.Result.Author('Anto Cartolovni'), arxiv.Result.Author('Pau Climent-Peerez'), arxiv.Result.Author('Sara Colantonio'), arxiv.Result.Author('Stefania Cristina'), arxiv.Result.Author('Vladimir Despotovic'), arxiv.Result.Author('Hazim Kemal Ekenel'), arxiv.Result.Author('Ekrem Erakin'), arxiv.Result.Author('Francisco Florez-Revuelta'), arxiv.Result.Author('Danila Germanese'), arxiv.Result.Author('Nicole Grech'), arxiv.Result.Author('Steinunn Gróa Sigurðardóttir'), arxiv.Result.Author('Murat Emirzeoglu'), arxiv.Result.Author('Ivo Iliev'), arxiv.Result.Author('Mladjan Jovanovic'), arxiv.Result.Author('Martin Kampel'), arxiv.Result.Author('William Kearns'), arxiv.Result.Author('Andrzej Klimczuk'), arxiv.Result.Author('Lambros Lambrinos'), arxiv.Result.Author('Jennifer Lumetzberger'), arxiv.Result.Author('Wiktor Mucha'), arxiv.Result.Author('Sophie Noiret'), arxiv.Result.Author('Zada Pajalic'), arxiv.Result.Author('Rodrigo Rodriguez Peerez'), arxiv.Result.Author('Galidiya Petrova'), arxiv.Result.Author('Sintija Petrovica'), arxiv.Result.Author('Peter Pocta'), arxiv.Result.Author('Angelica Poli'), arxiv.Result.Author('Mara Pudane'), arxiv.Result.Author('Susanna Spinsante'), arxiv.Result.Author('Albert Ali Salah'), arxiv.Result.Author('Maria Jose Santofimia'), arxiv.Result.Author('Anna Sigridur Islind'), arxiv.Result.Author('Lacramioara Stoicu-Tivadar'), arxiv.Result.Author('Hilda Tellioglu'), arxiv.Result.Author('Andrej Zgank')]","The report illustrates the state of the art of the most successful AAL
applications and functions based on audio and video data, namely (i)
lifelogging and self-monitoring, (ii) remote monitoring of vital signs, (iii)
emotional state recognition, (iv) food intake monitoring, activity and
behaviour recognition, (v) activity and personal assistance, (vi) gesture
recognition, (vii) fall detection and prevention, (viii) mobility assessment
and frailty recognition, and (ix) cognitive and motor rehabilitation. For these
application scenarios, the report illustrates the state of play in terms of
scientific advances, available products and research project. The open
challenges are also highlighted."
8406,"A
framework for which further research can be performed is presented.","Yet as technologies advance, the laws must stay abreast of such progress.","It concludes that AAL technologies
require a legal system that both promotes their development while at the same time safeguards against
risks posed by the technology.",2022-06-26 14:27:33+00:00,State of the Art of Audio- and Video-Based Solutions for AAL,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC', 'cs.SD', 'eess.AS', 'I.2']","[arxiv.Result.Author('Slavisa Aleksic'), arxiv.Result.Author('Michael Atanasov'), arxiv.Result.Author('Jean Calleja Agius'), arxiv.Result.Author('Kenneth Camilleri'), arxiv.Result.Author('Anto Cartolovni'), arxiv.Result.Author('Pau Climent-Peerez'), arxiv.Result.Author('Sara Colantonio'), arxiv.Result.Author('Stefania Cristina'), arxiv.Result.Author('Vladimir Despotovic'), arxiv.Result.Author('Hazim Kemal Ekenel'), arxiv.Result.Author('Ekrem Erakin'), arxiv.Result.Author('Francisco Florez-Revuelta'), arxiv.Result.Author('Danila Germanese'), arxiv.Result.Author('Nicole Grech'), arxiv.Result.Author('Steinunn Gróa Sigurðardóttir'), arxiv.Result.Author('Murat Emirzeoglu'), arxiv.Result.Author('Ivo Iliev'), arxiv.Result.Author('Mladjan Jovanovic'), arxiv.Result.Author('Martin Kampel'), arxiv.Result.Author('William Kearns'), arxiv.Result.Author('Andrzej Klimczuk'), arxiv.Result.Author('Lambros Lambrinos'), arxiv.Result.Author('Jennifer Lumetzberger'), arxiv.Result.Author('Wiktor Mucha'), arxiv.Result.Author('Sophie Noiret'), arxiv.Result.Author('Zada Pajalic'), arxiv.Result.Author('Rodrigo Rodriguez Peerez'), arxiv.Result.Author('Galidiya Petrova'), arxiv.Result.Author('Sintija Petrovica'), arxiv.Result.Author('Peter Pocta'), arxiv.Result.Author('Angelica Poli'), arxiv.Result.Author('Mara Pudane'), arxiv.Result.Author('Susanna Spinsante'), arxiv.Result.Author('Albert Ali Salah'), arxiv.Result.Author('Maria Jose Santofimia'), arxiv.Result.Author('Anna Sigridur Islind'), arxiv.Result.Author('Lacramioara Stoicu-Tivadar'), arxiv.Result.Author('Hilda Tellioglu'), arxiv.Result.Author('Andrej Zgank')]","The report illustrates the state of the art of the most successful AAL
applications and functions based on audio and video data, namely (i)
lifelogging and self-monitoring, (ii) remote monitoring of vital signs, (iii)
emotional state recognition, (iv) food intake monitoring, activity and
behaviour recognition, (v) activity and personal assistance, (vi) gesture
recognition, (vii) fall detection and prevention, (viii) mobility assessment
and frailty recognition, and (ix) cognitive and motor rehabilitation. For these
application scenarios, the report illustrates the state of play in terms of
scientific advances, available products and research project. The open
challenges are also highlighted."
8407,"Moreover,
the catalogue is a starting point for further research on AI ethics.","The given catalogue (see Figure 2) of principles and challenging factors
could be used as a guideline for deﬁning ethics in the AI domain.","It is
essential to mention that the identiﬁed principles and challenging factors
only reﬂect the perceptions of 99 practitioners and lawmakers in 20 countries.",2022-06-30 17:24:29+00:00,AI Ethics: Software Practitioners and Lawmakers Points of View,cs.CY,['cs.CY'],"[arxiv.Result.Author('Arif Ali Khan'), arxiv.Result.Author('Muhammad Azeem Akbar'), arxiv.Result.Author('Muhammad Waseem'), arxiv.Result.Author('Mahdi Fahmideh'), arxiv.Result.Author('Aakash Ahmad'), arxiv.Result.Author('Peng Liang'), arxiv.Result.Author('Mahmood Niazi'), arxiv.Result.Author('Pekka Abrahamsson')]","Despite their commonly accepted usefulness, AI technologies are concerned
with ethical unreliability. Various guidelines, principles, and regulatory
frameworks are designed to ensure that AI technologies bring ethical
well-being. However, the implications of AI ethics principles and guidelines
are still being debated. To further explore the significance of AI ethics
principles and relevant challenges, we conducted an empirical survey of 99 AI
practitioners and lawmakers from twenty countries across five continents. Study
findings confirm that transparency, accountability, and privacy are the most
critical AI ethics principles. On the other hand, lack of ethical knowledge, no
legal frameworks, and lacking monitoring bodies are found the most common AI
ethics challenges. The impact analysis of the challenges across AI ethics
principles reveals that conflict in practice is a highly severe challenge. Our
findings stimulate further research, epically empowering existing capability
maturity models to support the quality assessment of ethics-aware AI systems."
8408,"stimulate further research, especially empowering existing capa-
                                        bility maturity models to support the development and quality          Extensively, the ethically aligned AI system should meet the
                                        assessment of ethics-aware AI systems.","Our ﬁndings   practitioners, policy, and lawmakers [4] [5].","following three components through the entire life cycle [2]:
                                                                                                            1) compliance with all the applicable laws and regulations, 2)
                                           Index Terms—Artiﬁcial Intelligence, AI Ethics, Machine           adherence to ethical principles and values, and 3) technical
                                        Ethics, Accountable AI, AI Ethics Principles, Challenges.",2022-06-30 17:24:29+00:00,AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,cs.CY,['cs.CY'],"[arxiv.Result.Author('Arif Ali Khan'), arxiv.Result.Author('Muhammad Azeem Akbar'), arxiv.Result.Author('Mahdi Fahmideh'), arxiv.Result.Author('Peng Liang'), arxiv.Result.Author('Muhammad Waseem'), arxiv.Result.Author('Aakash Ahmad'), arxiv.Result.Author('Mahmood Niazi'), arxiv.Result.Author('Pekka Abrahamsson')]","Artificial Intelligence (AI) solutions and technologies are being
increasingly adopted in smart systems context, however, such technologies are
continuously concerned with ethical uncertainties. Various guidelines,
principles, and regulatory frameworks are designed to ensure that AI
technologies bring ethical well-being. However, the implications of AI ethics
principles and guidelines are still being debated. To further explore the
significance of AI ethics principles and relevant challenges, we conducted a
survey of 99 representative AI practitioners and lawmakers (e.g., AI engineers,
lawyers) from twenty countries across five continents. To the best of our
knowledge, this is the first empirical study that encapsulates the perceptions
of two different types of population (AI practitioners and lawmakers) and the
study findings confirm that transparency, accountability, and privacy are the
most critical AI ethics principles. On the other hand, lack of ethical
knowledge, no legal frameworks, and lacking monitoring bodies are found the
most common AI ethics challenges. The impact analysis of the challenges across
AI ethics principles reveals that conflict in practice is a highly severe
challenge. Moreover, the perceptions of practitioners and lawmakers are
statistically correlated with significant differences for particular principles
(e.g. fairness, freedom) and challenges (e.g. lacking monitoring bodies,
machine distortion). Our findings stimulate further research, especially
empowering existing capability maturity models to support the development and
quality assessment of ethics-aware AI systems."
8409,"The identiﬁed challenges are core focus areas that
[32] argue that thorough exploration is required to encounter             need further research to explore the root causes and best
and articulate the conﬂict and tensions across the AI ethics              practices to mitigate them.",ers.,principles.,2022-06-30 17:24:29+00:00,AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,cs.CY,['cs.CY'],"[arxiv.Result.Author('Arif Ali Khan'), arxiv.Result.Author('Muhammad Azeem Akbar'), arxiv.Result.Author('Mahdi Fahmideh'), arxiv.Result.Author('Peng Liang'), arxiv.Result.Author('Muhammad Waseem'), arxiv.Result.Author('Aakash Ahmad'), arxiv.Result.Author('Mahmood Niazi'), arxiv.Result.Author('Pekka Abrahamsson')]","Artificial Intelligence (AI) solutions and technologies are being
increasingly adopted in smart systems context, however, such technologies are
continuously concerned with ethical uncertainties. Various guidelines,
principles, and regulatory frameworks are designed to ensure that AI
technologies bring ethical well-being. However, the implications of AI ethics
principles and guidelines are still being debated. To further explore the
significance of AI ethics principles and relevant challenges, we conducted a
survey of 99 representative AI practitioners and lawmakers (e.g., AI engineers,
lawyers) from twenty countries across five continents. To the best of our
knowledge, this is the first empirical study that encapsulates the perceptions
of two different types of population (AI practitioners and lawmakers) and the
study findings confirm that transparency, accountability, and privacy are the
most critical AI ethics principles. On the other hand, lack of ethical
knowledge, no legal frameworks, and lacking monitoring bodies are found the
most common AI ethics challenges. The impact analysis of the challenges across
AI ethics principles reveals that conflict in practice is a highly severe
challenge. Moreover, the perceptions of practitioners and lawmakers are
statistically correlated with significant differences for particular principles
(e.g. fairness, freedom) and challenges (e.g. lacking monitoring bodies,
machine distortion). Our findings stimulate further research, especially
empowering existing capability maturity models to support the development and
quality assessment of ethics-aware AI systems."
8410,"Moreover, the catalogue
explicitly analyzed and discussed the principles based on the        is a starting point for further research on AI ethics.","To complement empiricism           principles and challenging factors can be used as a guideline
in exploring AI ethics principles and challenges, this study         for deﬁning ethics in the AI domain.","It is
perceptions of two different types of populations (practitioners     essential to mention that the identiﬁed principles and chal-
and lawmakers).",2022-06-30 17:24:29+00:00,AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers,cs.CY,['cs.CY'],"[arxiv.Result.Author('Arif Ali Khan'), arxiv.Result.Author('Muhammad Azeem Akbar'), arxiv.Result.Author('Mahdi Fahmideh'), arxiv.Result.Author('Peng Liang'), arxiv.Result.Author('Muhammad Waseem'), arxiv.Result.Author('Aakash Ahmad'), arxiv.Result.Author('Mahmood Niazi'), arxiv.Result.Author('Pekka Abrahamsson')]","Artificial Intelligence (AI) solutions and technologies are being
increasingly adopted in smart systems context, however, such technologies are
continuously concerned with ethical uncertainties. Various guidelines,
principles, and regulatory frameworks are designed to ensure that AI
technologies bring ethical well-being. However, the implications of AI ethics
principles and guidelines are still being debated. To further explore the
significance of AI ethics principles and relevant challenges, we conducted a
survey of 99 representative AI practitioners and lawmakers (e.g., AI engineers,
lawyers) from twenty countries across five continents. To the best of our
knowledge, this is the first empirical study that encapsulates the perceptions
of two different types of population (AI practitioners and lawmakers) and the
study findings confirm that transparency, accountability, and privacy are the
most critical AI ethics principles. On the other hand, lack of ethical
knowledge, no legal frameworks, and lacking monitoring bodies are found the
most common AI ethics challenges. The impact analysis of the challenges across
AI ethics principles reveals that conflict in practice is a highly severe
challenge. Moreover, the perceptions of practitioners and lawmakers are
statistically correlated with significant differences for particular principles
(e.g. fairness, freedom) and challenges (e.g. lacking monitoring bodies,
machine distortion). Our findings stimulate further research, especially
empowering existing capability maturity models to support the development and
quality assessment of ethics-aware AI systems."
8928,"Sanchez & Langer [96] informed that the games used in their study were
   entertainment games, and further research could be oriented to validate their results with games designed for
   assessment purposes.","Validation
   is intended to ensure that the proposed methods and the accomplished results were proved satisfactory by
   conducting empirical experiments.","40

           30

           20

Frequency  10

           0

                        llenges            itations               allenge          allenge             llenges           allenge  NA

Methodolo      gical cha  Data sample lim            Validation ch   ame d esign ch  Tech   nical cha  Integ    ration ch

                                                                    G

                          Figure 12: Number of papers based on their limitations and challenges.",2022-07-15 09:34:27+00:00,A Systematic Literature Review of Digital Game-based Assessment Empirical Studies: Current Trends and Open Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies, based on 66 research papers that used digital
GBAs to determine: (1) the context where the study has been applied, (2) the
primary purpose, (3) the knowledge domain of the game used, (4) game/tool
availability, (5) the size of the data sample, (6) the data science techniques
and algorithms applied, (7) the targeted stakeholders of the study, and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in formal education and for assessment purposes, and most GBAs
focus on assessing STEM content and cognitive skills. Furthermore, the current
limitations indicate that future GBA research would benefit from the use of
bigger data samples and more specialized algorithms. Based on our results, we
discuss the status of the field with the current trends and the open challenges
(including replication and validation problems) providing recommendations for
the future research agenda of the GBA field."
8929,"This is a relatively new trend due to certain limitations, such as the cross-domain generalizability of
behaviors between game and workplace contexts, which need further research [31].","Concerning the professional environment, companies have begun to include assessment games for employee recruitment
and selection.","In medical environments, the use of
GBAs can also be helpful for multiple purposes.",2022-07-15 09:34:27+00:00,A Systematic Literature Review of Digital Game-based Assessment Empirical Studies: Current Trends and Open Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies, based on 66 research papers that used digital
GBAs to determine: (1) the context where the study has been applied, (2) the
primary purpose, (3) the knowledge domain of the game used, (4) game/tool
availability, (5) the size of the data sample, (6) the data science techniques
and algorithms applied, (7) the targeted stakeholders of the study, and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in formal education and for assessment purposes, and most GBAs
focus on assessing STEM content and cognitive skills. Furthermore, the current
limitations indicate that future GBA research would benefit from the use of
bigger data samples and more specialized algorithms. Based on our results, we
discuss the status of the field with the current trends and the open challenges
(including replication and validation problems) providing recommendations for
the future research agenda of the GBA field."
8930,"Therefore, further research is needed to overcome current limitations and to continue exploring the possibilities of game
as assessment tools in other contexts and environments.","Considering this lack of theoretical papers focused on describing GBA foundations, we believe that future work
should address publications with additional content on the theoretical side.","Finally, we encourage authors to document their research in a
reproducible and veriﬁable way, using beneﬁcial open science practices by pre-registering their study, sharing data and
code for replication purposes, and if possible open sourcing the GBA tools with clear descriptions so that they can be
used by interested stakeholders and researchers.",2022-07-15 09:34:27+00:00,A Systematic Literature Review of Digital Game-based Assessment Empirical Studies: Current Trends and Open Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies, based on 66 research papers that used digital
GBAs to determine: (1) the context where the study has been applied, (2) the
primary purpose, (3) the knowledge domain of the game used, (4) game/tool
availability, (5) the size of the data sample, (6) the data science techniques
and algorithms applied, (7) the targeted stakeholders of the study, and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in formal education and for assessment purposes, and most GBAs
focus on assessing STEM content and cognitive skills. Furthermore, the current
limitations indicate that future GBA research would benefit from the use of
bigger data samples and more specialized algorithms. Based on our results, we
discuss the status of the field with the current trends and the open challenges
(including replication and validation problems) providing recommendations for
the future research agenda of the GBA field."
8931,"Sanchez & Langer [105] suggested that the games used in their study were entertain-
           ment games, and further research could be oriented to validate their results with games designed for assessment
           purposes.","Validation is
           intended to ensure that the proposed methods and the accomplished results proved satisfactory by conducting
           empirical experiments.",Figure 12: Number of papers based on their limitations and challenges.,2022-07-15 09:34:27+00:00,A Systematic Literature Review of Game-based Assessment Studies: Trends and Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies. It is based on 65 research papers that used
digital GBAs to determine: (1) the context where the study has been applied;
(2) the primary purpose; (3) the domain of the game used; (4) game/tool
availability; (5) the size of the data sample; (6) the computational methods
and algorithms applied; (7) the targeted stakeholders of the study; and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in K-16 education and for assessment purposes, and that most GBAs
focus on assessing STEM content, and cognitive and soft skills. Furthermore,
the current limitations indicate that future GBA research would benefit from
the use of bigger data samples and more specialized algorithms. Based on our
results, we discuss current trends in the field and open challenges (including
replication and validation problems), providing recommendations for the future
research agenda of the GBA field."
8932,"This is a relatively new trend due to certain limitations, such as the cross-domain
generalizability of behaviors between game and workforce contexts, which needs further research [40].","Concerning the professional environment, companies have begun to include assessment games for the recruitment
of staff and the selection process.","In medical
environments, the use of GBAs can also be helpful for multiple purposes.",2022-07-15 09:34:27+00:00,A Systematic Literature Review of Game-based Assessment Studies: Trends and Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies. It is based on 65 research papers that used
digital GBAs to determine: (1) the context where the study has been applied;
(2) the primary purpose; (3) the domain of the game used; (4) game/tool
availability; (5) the size of the data sample; (6) the computational methods
and algorithms applied; (7) the targeted stakeholders of the study; and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in K-16 education and for assessment purposes, and that most GBAs
focus on assessing STEM content, and cognitive and soft skills. Furthermore,
the current limitations indicate that future GBA research would benefit from
the use of bigger data samples and more specialized algorithms. Based on our
results, we discuss current trends in the field and open challenges (including
replication and validation problems), providing recommendations for the future
research agenda of the GBA field."
8933,"Due to the above, we ﬁrmly believe that the future of games for assessment
is promising; however, further research is needed to overcome the existing problems, and increase the still limited
application of games in real-life environments, in order to start building the classrooms of the future.","Some examples are the possibility to recreate
a virtual environment with daily life activities, allowing a precise and complete cognitive evaluation, which can be
useful to treat certain diseases such as Alzheimer’s [71] or using games to rehabilitate children with cerebral visual
impairment using an eye-tracker [94].","5 Conclusions

Technology is changing and improving every day, and this is also making a signiﬁcant impact on educational areas.",2022-07-15 09:34:27+00:00,A Systematic Literature Review of Game-based Assessment Studies: Trends and Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies. It is based on 65 research papers that used
digital GBAs to determine: (1) the context where the study has been applied;
(2) the primary purpose; (3) the domain of the game used; (4) game/tool
availability; (5) the size of the data sample; (6) the computational methods
and algorithms applied; (7) the targeted stakeholders of the study; and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in K-16 education and for assessment purposes, and that most GBAs
focus on assessing STEM content, and cognitive and soft skills. Furthermore,
the current limitations indicate that future GBA research would benefit from
the use of bigger data samples and more specialized algorithms. Based on our
results, we discuss current trends in the field and open challenges (including
replication and validation problems), providing recommendations for the future
research agenda of the GBA field."
8934,"Therefore, further research is needed to overcome current limitations and to continue exploring the possibilities of
games as assessment tools in other contexts and environments.","Considering this lack of theoretical
papers focused on describing GBA foundations, we believe that future work should address publications with additional
content on the theoretical side.","Finally, we encourage authors to document their research
in a reproducible and veriﬁable way, using beneﬁcial open science practices by pre-registering their study, sharing data

                                                                     19
A Systematic Literature Review of Digital GBA Empirical Studies

and code for replication purposes, and if possible open sourcing the GBA tools with clear descriptions so that they can
be used by interested stakeholders and researchers.",2022-07-15 09:34:27+00:00,A Systematic Literature Review of Game-based Assessment Studies: Trends and Challenges,cs.CY,['cs.CY'],"[arxiv.Result.Author('Manuel J. Gomez'), arxiv.Result.Author('José A. Ruipérez-Valiente'), arxiv.Result.Author('Félix J. García Clemente')]","Technology has become an essential part of our everyday life, and its use in
educational environments keeps growing. In addition, games are one of the most
popular activities across cultures and ages, and there is ample evidence that
supports the benefits of using games for assessment. This field is commonly
known as game-based assessment (GBA), which refers to the use of games to
assess learners' competencies, skills, or knowledge. This paper analyzes the
current status of the GBA field by performing the first systematic literature
review on empirical GBA studies. It is based on 65 research papers that used
digital GBAs to determine: (1) the context where the study has been applied;
(2) the primary purpose; (3) the domain of the game used; (4) game/tool
availability; (5) the size of the data sample; (6) the computational methods
and algorithms applied; (7) the targeted stakeholders of the study; and (8)
what limitations and challenges are reported by authors. Based on the
categories established and our analysis, the findings suggest that GBAs are
mainly used in K-16 education and for assessment purposes, and that most GBAs
focus on assessing STEM content, and cognitive and soft skills. Furthermore,
the current limitations indicate that future GBA research would benefit from
the use of bigger data samples and more specialized algorithms. Based on our
results, we discuss current trends in the field and open challenges (including
replication and validation problems), providing recommendations for the future
research agenda of the GBA field."
8975,"A possible solution
might be the use of super-resolution, but a further study should be performed
to determine its eﬀectiveness.","The resolution of a poster
is also a limitation, especially when there is a small face.","Another limitation is that no data specify how
many posters were produced for each movie and how many posters were printed
from each variation which may portray a diﬀerent picture.",2022-07-17 13:13:02+00:00,Ethnic Representation Analysis of Commercial Movie Posters,cs.CY,['cs.CY'],"[arxiv.Result.Author('Dima Kagan'), arxiv.Result.Author('Mor Levy'), arxiv.Result.Author('Michael Fire'), arxiv.Result.Author('Galit Fuhrmann Alpert')]","In the last decades, global awareness towards the importance of diverse
representation has been increasing. Lack of diversity and discrimination toward
minorities did not skip the film industry. Here, we examine ethnic bias in the
film industry through commercial posters, the industry's primary advertisement
medium for decades. Movie posters are designed to establish the viewer's
initial impression. We developed a novel approach for evaluating ethnic bias in
the film industry by analyzing nearly 125,000 posters using state-of-the-art
deep learning models. Our analysis shows that while ethnic biases still exist,
there is a trend of reduction of bias, as seen by several parameters.
Particularly in English-speaking movies, the ethnic distribution of characters
on posters from the last couple of years is reaching numbers that are
approaching the actual ethnic composition of US population. An automatic
approach to monitor ethnic diversity in the film industry, potentially
integrated with financial value, may be of significant use for producers and
policymakers."
9058,"However, we make our code
for collecting ads publicly available which might help further research in other countries and
populations.",(3) Our study is limited to U.S. users and mostly U.S. advertisers.,(4) Ad explanations from the “Why am I seeing this ad?” might have limitations.,2022-07-19 14:16:54+00:00,"Exploring the Online Micro-targeting Practices of Small, Medium, and Large Businesses",cs.CY,['cs.CY'],"[arxiv.Result.Author('Salim Chouaki'), arxiv.Result.Author('Islem Bouzenia'), arxiv.Result.Author('Oana Goga'), arxiv.Result.Author('Beatrice Roussillon')]","Facebook and other advertising platforms exploit users data for marketing
purposes by allowing advertisers to select specific users and target them (the
practice is being called micro-targeting). However, advertisers such as
Cambridge Analytica have maliciously used these targeting features to
manipulate users in the context of elections. The European Commission plans to
restrict or ban some targeting functionalities in the new European Democracy
Action Plan act to protect users from such harms. The difficulty is that we do
not know the economic impact of these restrictions on regular advertisers. In
this paper, to inform the debate, we take a first step by understanding who is
advertising on Facebook and how they use the targeting functionalities. For
this, we asked 890 U.S. users to install a monitoring tool on their browsers to
collect the ads they receive on Facebook and information about how these ads
were targeted. By matching advertisers on Facebook with their LinkedIn
profiles, we could see that 71% of advertisers are small and medium-sized
businesses with 200 employees or less, and they are responsible for 61% of ads
and 57% of ad impressions. Regarding micro-targeting, we found that only 32% of
small and medium-sized businesses and 30% of large-sized businesses
micro-target at least one of their ads. These results should not be interpreted
as micro-targeting not being useful as a marketing strategy, but rather that
advertisers prefer to outsource the micro-targeting task to ad platforms.
Indeed, Facebook is employing optimization algorithms that exploit user data to
decide which users should see what ads; which means ad platforms are performing
an algorithmic-driven micro-targeting. Hence, when setting restrictions,
legislators should take into account both the traditional advertiser-driven
micro-targeting as well as algorithmic-driven micro-targeting performed by ad
platforms."
9771,"In this paper we give an examples of approaches that have broadened
representation in data science efforts, and advocate for further research into paradigms that will
improve the diversity of the current public health workforce, both domestically and around the
world.","Finally, as the value of diversity is recognized as integral to efforts in public health practice, our
fourth recommendation is that diversity must be considered paramount in public health education
efforts as well.","The widespread training of individuals in true data acumen – core data science skills
complemented by an openness to multidisciplinary perspectives – stands to grow the conceptual
depth and interventional capacity of research and practice in public health as a field.",2022-08-06 08:09:42+00:00,Data science in public health: building next generation capacity,cs.CY,"['cs.CY', 'stat.AP']","[arxiv.Result.Author('Nicholas Mirin'), arxiv.Result.Author('Heather Mattie'), arxiv.Result.Author('Latifa Jackson'), arxiv.Result.Author('Zainab Samad'), arxiv.Result.Author('Rumi Chunara')]","Rapidly evolving technology, data and analytic landscapes are permeating many
fields and professions. In public health, the need for data science skills
including data literacy is particularly prominent given both the potential of
novel data types and analysis methods to fill gaps in existing public health
research and intervention practices, as well as the potential of such data or
methods to perpetuate or augment health disparities. Through a review of public
health courses and programs at the top 10 U.S. and globally ranked schools of
public health, this article summarizes existing educational efforts in public
health data science. These existing practices serve to inform efforts for
broadening such curricula to further schools and populations. Data science
ethics course offerings are also examined in context of assessing how
population health principles can be blended into training across levels of data
involvement to augment the traditional core of public health curricula.
Parallel findings from domestic and international 'outside the classroom'
training programs are also synthesized to advance approaches for increasing
diversity in public health data science. Based on these program reviews and
their synthesis, a four-point formula is distilled for furthering public health
data science education efforts, toward development of a critical and inclusive
mass of practitioners with fluency to leverage data to advance goals of public
health and improve quality of life in the digital age."
9875,"A further research review on the
prospects of Virtual Diagnostic Solutions (VDS) and foreseeable challenges was also
highlighted.","This research further explores notable developments in Deep
Learning model optimizations for Virtual Diagnostic Solutions.","Conclusively, this research gives a general overview of Artificial Intelligence in
Telemedicine with a central focus on Deep Learning-based approaches to Virtual Diagnostic
Solutions.",2022-07-31 09:01:25+00:00,AI in Telemedicine: An Appraisal on Deep Learning-Based Approaches to Virtual Diagnostic Solutions (VDS),cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Ozioma Collins Oguine'), arxiv.Result.Author('Kanyifeechukwu Jane Oguine')]","Advancements in Telemedicine as an approach to healthcare delivery have
heralded a new dawn in modern Medicine. Its fast-paced development in our
contemporary society is credence to the advances in Artificial Intelligence and
Information Technology. This paper carries out a descriptive study to broadly
explore AI's implementations in healthcare delivery with a more holistic view
of the usability of various Telemedical Innovations in enhancing Virtual
Diagnostic Solutions (VDS). This research further explores notable developments
in Deep Learning model optimizations for Virtual Diagnostic Solutions. A
further research review on the prospects of Virtual Diagnostic Solutions (VDS)
and foreseeable challenges was also highlighted. Conclusively, this research
gives a general overview of Artificial Intelligence in Telemedicine with a
central focus on Deep Learning-based approaches to Virtual Diagnostic
Solutions."
9876,"It is essential to
connections between learning resources for further research.","Therefore, we    show extreme unevenness and long-tail distribution and that plenty
also take the course structures from MOOCCubeX to provide             of videos are involved in limited interactions.","conduct a learning style analysis on students’ behaviors to mine
                                                                      critical learning components and alleviate such severe sparsity.",2022-07-18 13:18:39+00:00,Towards a General Pre-training Framework for Adaptive Learning in MOOCs,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Qingyang Zhong'), arxiv.Result.Author('Jifan Yu'), arxiv.Result.Author('Zheyuan Zhang'), arxiv.Result.Author('Yiming Mao'), arxiv.Result.Author('Yuquan Wang'), arxiv.Result.Author('Yankai Lin'), arxiv.Result.Author('Lei Hou'), arxiv.Result.Author('Juanzi Li'), arxiv.Result.Author('Jie Tang')]","Adaptive learning aims to stimulate and meet the needs of individual
learners, which requires sophisticated system-level coordination of diverse
tasks, including modeling learning resources, estimating student states, and
making personalized recommendations. Existing deep learning methods have
achieved great success over statistical models; however, they still lack
generalization for diverse tasks and suffer from insufficient capacity since
they are composed of highly-coupled task-specific architectures and rely on
small-scale, coarse-grained recommendation scenarios. To realize the idea of
general adaptive systems proposed in pedagogical theory, with the emerging
pre-training techniques in NLP, we try to conduct a practical exploration on
applying pre-training to adaptive learning, to propose a unified framework
based on data observation and learning style analysis, properly leveraging
heterogeneous learning elements. Through a series of downstream tasks of
Learning Recommendation, Learning Resource Evaluation, Knowledge Tracing, and
Dropout Prediction, we find that course structures, text, and knowledge are
helpful for modeling and inherently coherent to student non-sequential learning
behaviors and that indirectly relevant information included in the pre-training
foundation can be shared across downstream tasks to facilitate effectiveness.
We finally build a simplified systematic application of adaptive learning and
reflect on the insights brought back to pedagogy. The source code and dataset
will be released."
9877,"This report
seeks to contextualize and connect the relevant streams of research in order to encourage further study.","1
Figure 1: Cumulative total of academic publications on the moral consideration of artificial entities, by
date of publication (Harris & Anthis, 2021)

Researchers approach the topic with different motivations, influences, and methodologies, often
seemingly unaware of the work of other academics whose interests overlap with their own.","This is especially important because granting sentient AI moral consideration, such as protection in
society’s laws or social norms, may be important for preventing large-scale suffering or other serious
wrongs in the future (Anthis & Paez, 2021), and academic field-building is a tractable stepping stone
towards this form of moral circle expansion (Harris, 2021).",2022-07-06 17:52:27+00:00,The History of AI Rights Research,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']",[arxiv.Result.Author('Jamie Harris')],"This report documents the history of research on AI rights and other moral
consideration of artificial entities. It highlights key intellectual influences
on this literature as well as research and academic discussion addressing the
topic more directly. We find that researchers addressing AI rights have often
seemed to be unaware of the work of colleagues whose interests overlap with
their own. Academic interest in this topic has grown substantially in recent
years; this reflects wider trends in academic research, but it seems that
certain influential publications, the gradual, accumulating ubiquity of AI and
robotic technology, and relevant news events may all have encouraged increased
academic interest in this specific topic. We suggest four levers that, if
pulled on in the future, might increase interest further: the adoption of
publication strategies similar to those of the most successful previous
contributors; increased engagement with adjacent academic fields and debates;
the creation of specialized journals, conferences, and research institutions;
and more exploration of legal rights for artificial entities."
9878,"Potential items for further study

What is the history of AI rights research that is written in languages other than English?","Putnam, Freitas, Lehman-Wilzig), then the searches might
underrepresent the number of citations of them.","This report
predominantly only included publications written in English, so relevant research in other languages may
have been accidentally excluded.",2022-07-06 17:52:27+00:00,The History of AI Rights Research,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']",[arxiv.Result.Author('Jamie Harris')],"This report documents the history of research on AI rights and other moral
consideration of artificial entities. It highlights key intellectual influences
on this literature as well as research and academic discussion addressing the
topic more directly. We find that researchers addressing AI rights have often
seemed to be unaware of the work of colleagues whose interests overlap with
their own. Academic interest in this topic has grown substantially in recent
years; this reflects wider trends in academic research, but it seems that
certain influential publications, the gradual, accumulating ubiquity of AI and
robotic technology, and relevant news events may all have encouraged increased
academic interest in this specific topic. We suggest four levers that, if
pulled on in the future, might increase interest further: the adoption of
publication strategies similar to those of the most successful previous
contributors; increased engagement with adjacent academic fields and debates;
the creation of specialized journals, conferences, and research institutions;
and more exploration of legal rights for artificial entities."
9879,"This report
seeks to contextualize and connect the relevant streams of research in order to encourage further study.","1
Figure 1: Cumulative total of academic publications on the moral consideration of artificial entities, by
date of publication (Harris & Anthis, 2021)

Researchers approach the topic with different motivations, influences, and methodologies, often
seemingly unaware of the work of other academics whose interests overlap with their own.","This is especially important because granting sentient AI moral consideration, such as protection in
society’s laws or social norms, may be important for preventing large-scale suffering or other serious
wrongs in the future (Anthis & Paez, 2021), and academic field-building is a tractable stepping stone
towards this form of moral circle expansion (Harris, 2021).",2022-07-06 17:52:27+00:00,The History of AI Rights Research,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']",[arxiv.Result.Author('Jamie Harris')],"This report documents the history of research on AI rights and other moral
consideration of artificial entities. It highlights key intellectual influences
on this literature as well as research and academic discussion addressing the
topic more directly. We find that researchers addressing AI rights have often
seemed to be unaware of the work of colleagues whose interests overlap with
their own. Academic interest in this topic has grown substantially in recent
years; this reflects wider trends in academic research, but it seems that
certain influential publications, the gradual, accumulating ubiquity of AI and
robotic technology, and relevant news events may all have encouraged increased
academic interest in this specific topic. We suggest four levers that, if
pulled on in the future, might increase interest further: the adoption of
publication strategies similar to those of the most successful previous
contributors; increased engagement with adjacent academic fields and debates;
the creation of specialized journals, conferences, and research institutions;
and more exploration of legal rights for artificial entities."
9880,"Potential items for further study

What is the history of AI rights research that is written in languages other than English?","Putnam, Freitas, Lehman-Wilzig), then the searches might
underrepresent the number of citations of them.","This report
predominantly only included publications written in English, so relevant research in other languages may
have been accidentally excluded.",2022-07-06 17:52:27+00:00,The History of AI Rights Research,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']",[arxiv.Result.Author('Jamie Harris')],"This report documents the history of research on AI rights and other moral
consideration of artificial entities. It highlights key intellectual influences
on this literature as well as research and academic discussion addressing the
topic more directly. We find that researchers addressing AI rights have often
seemed to be unaware of the work of colleagues whose interests overlap with
their own. Academic interest in this topic has grown substantially in recent
years; this reflects wider trends in academic research, but it seems that
certain influential publications, the gradual, accumulating ubiquity of AI and
robotic technology, and relevant news events may all have encouraged increased
academic interest in this specific topic. We suggest four levers that, if
pulled on in the future, might increase interest further: the adoption of
publication strategies similar to those of the most successful previous
contributors; increased engagement with adjacent academic fields and debates;
the creation of specialized journals, conferences, and research institutions;
and more exploration of legal rights for artificial entities."
10450,"For further research, one area is to improve the consistency of the

                                                           9
PRP violation reduction, as we observed the largest standard error in reducing this metric.","Our work reinforces this claim but also adds on that trade-offs between fairness
deﬁnitions can be negligible as well.","This could
be due to us using random forests for all experiments, which is known to be an uncalibrated model
[6].",2022-08-24 22:04:51+00:00,Pushing the limits of fairness impossibility: Who's the fairest of them all?,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG', 'stat.AP']","[arxiv.Result.Author('Brian Hsu'), arxiv.Result.Author('Rahul Mazumder'), arxiv.Result.Author('Preetam Nandy'), arxiv.Result.Author('Kinjal Basu')]","The impossibility theorem of fairness is a foundational result in the
algorithmic fairness literature. It states that outside of special cases, one
cannot exactly and simultaneously satisfy all three common and intuitive
definitions of fairness - demographic parity, equalized odds, and predictive
rate parity. This result has driven most works to focus on solutions for one or
two of the metrics. Rather than follow suit, in this paper we present a
framework that pushes the limits of the impossibility theorem in order to
satisfy all three metrics to the best extent possible. We develop an
integer-programming based approach that can yield a certifiably optimal
post-processing method for simultaneously satisfying multiple fairness criteria
under small violations. We show experiments demonstrating that our
post-processor can improve fairness across the different definitions
simultaneously with minimal model performance reduction. We also discuss
applications of our framework for model selection and fairness explainability,
thereby attempting to answer the question: who's the fairest of them all?"
10451,"(2021) also advocate for further research according to this approach,
applying multi-theory models where machines can interchangeably apply diﬀerent theories
depending on the type of situation.",Tolmeijer et al.,"They argue that human morality is complex and cannot
be captured by one single classical ethical theory.",2022-08-12 08:48:16+00:00,Principles for Macro Ethics of Sociotechnical Systems: Taxonomy and Future Directions,cs.CY,"['cs.CY', 'cs.MA']","[arxiv.Result.Author('Jessica Woodgate'), arxiv.Result.Author('Nirav Ajmeri')]","The rapid adoption of artificial intelligence (AI) necessitates careful
analysis of its ethical implications. In addressing ethics and fairness
implications, it is important to examine the whole range of ethically relevant
features rather than looking at individual agents alone. This can be
accomplished by shifting perspective to the systems in which agents are
embedded, which is encapsulated in the macro ethics of sociotechnical systems
(STS). Through the lens of macro ethics, the governance of systems - which is
where participants try to promote outcomes and norms which reflect their values
- is key. However, multiple-user social dilemmas arise in an STS when
stakeholders of the STS have different value preferences or when norms in the
STS conflict. To develop equitable governance which meets the needs of
different stakeholders, and resolve these dilemmas in satisfactory ways with a
higher goal of fairness, we need to integrate a variety of normative ethical
principles in reasoning. Normative ethical principles are understood as
operationalizable rules inferred from philosophical theories. A taxonomy of
ethical principles is thus beneficial to enable practitioners to utilise them
in reasoning.
  This work develops a taxonomy of normative ethical principles which can be
operationalized in the governance of STS. We identify an array of ethical
principles, with 25 nodes on the taxonomy tree. We describe the ways in which
each principle has previously been operationalized, and suggest how the
operationalization of principles may be applied to the macro ethics of STS. We
further explain potential difficulties that may arise with each principle. We
envision this taxonomy will facilitate the development of methodologies to
incorporate ethical principles in reasoning capacities for governing equitable
STS."
10452,"Opportunities in this area lie in further researching bottom-up approaches,
   as well as formal ways of discerning the circumstances in which each of the diﬀerent
   architectures is appropriate.",• Direction.,"28
Figure 3: Key Takeaways and Future Research to Operationalize Ethical Principles in STS

Deﬁning Welfare.",2022-08-12 08:48:16+00:00,Principles for Macro Ethics of Sociotechnical Systems: Taxonomy and Future Directions,cs.CY,"['cs.CY', 'cs.MA']","[arxiv.Result.Author('Jessica Woodgate'), arxiv.Result.Author('Nirav Ajmeri')]","The rapid adoption of artificial intelligence (AI) necessitates careful
analysis of its ethical implications. In addressing ethics and fairness
implications, it is important to examine the whole range of ethically relevant
features rather than looking at individual agents alone. This can be
accomplished by shifting perspective to the systems in which agents are
embedded, which is encapsulated in the macro ethics of sociotechnical systems
(STS). Through the lens of macro ethics, the governance of systems - which is
where participants try to promote outcomes and norms which reflect their values
- is key. However, multiple-user social dilemmas arise in an STS when
stakeholders of the STS have different value preferences or when norms in the
STS conflict. To develop equitable governance which meets the needs of
different stakeholders, and resolve these dilemmas in satisfactory ways with a
higher goal of fairness, we need to integrate a variety of normative ethical
principles in reasoning. Normative ethical principles are understood as
operationalizable rules inferred from philosophical theories. A taxonomy of
ethical principles is thus beneficial to enable practitioners to utilise them
in reasoning.
  This work develops a taxonomy of normative ethical principles which can be
operationalized in the governance of STS. We identify an array of ethical
principles, with 25 nodes on the taxonomy tree. We describe the ways in which
each principle has previously been operationalized, and suggest how the
operationalization of principles may be applied to the macro ethics of STS. We
further explain potential difficulties that may arise with each principle. We
envision this taxonomy will facilitate the development of methodologies to
incorporate ethical principles in reasoning capacities for governing equitable
STS."
10453,"Looking forward, the encoding of principles in either rules, consequences, or
   virtues will require a great deal of further research to develop systematic methods in the
   context of governing STS.",• Direction.,Principle Dependent Inputs.,2022-08-12 08:48:16+00:00,Principles for Macro Ethics of Sociotechnical Systems: Taxonomy and Future Directions,cs.CY,"['cs.CY', 'cs.MA']","[arxiv.Result.Author('Jessica Woodgate'), arxiv.Result.Author('Nirav Ajmeri')]","The rapid adoption of artificial intelligence (AI) necessitates careful
analysis of its ethical implications. In addressing ethics and fairness
implications, it is important to examine the whole range of ethically relevant
features rather than looking at individual agents alone. This can be
accomplished by shifting perspective to the systems in which agents are
embedded, which is encapsulated in the macro ethics of sociotechnical systems
(STS). Through the lens of macro ethics, the governance of systems - which is
where participants try to promote outcomes and norms which reflect their values
- is key. However, multiple-user social dilemmas arise in an STS when
stakeholders of the STS have different value preferences or when norms in the
STS conflict. To develop equitable governance which meets the needs of
different stakeholders, and resolve these dilemmas in satisfactory ways with a
higher goal of fairness, we need to integrate a variety of normative ethical
principles in reasoning. Normative ethical principles are understood as
operationalizable rules inferred from philosophical theories. A taxonomy of
ethical principles is thus beneficial to enable practitioners to utilise them
in reasoning.
  This work develops a taxonomy of normative ethical principles which can be
operationalized in the governance of STS. We identify an array of ethical
principles, with 25 nodes on the taxonomy tree. We describe the ways in which
each principle has previously been operationalized, and suggest how the
operationalization of principles may be applied to the macro ethics of STS. We
further explain potential difficulties that may arise with each principle. We
envision this taxonomy will facilitate the development of methodologies to
incorporate ethical principles in reasoning capacities for governing equitable
STS."
10454,"On the other hand, this limitation could lead to further research in this area by applying
our methodology to the analysis of more studies than those identiﬁed here.",This helps to eﬀectively identify relevant research.,"The ﬁfth issue of researcher bias also threatens the internal validity as it can sway the
results in a particular direction rather than being objective.",2022-08-12 08:48:16+00:00,Principles for Macro Ethics of Sociotechnical Systems: Taxonomy and Future Directions,cs.CY,"['cs.CY', 'cs.MA']","[arxiv.Result.Author('Jessica Woodgate'), arxiv.Result.Author('Nirav Ajmeri')]","The rapid adoption of artificial intelligence (AI) necessitates careful
analysis of its ethical implications. In addressing ethics and fairness
implications, it is important to examine the whole range of ethically relevant
features rather than looking at individual agents alone. This can be
accomplished by shifting perspective to the systems in which agents are
embedded, which is encapsulated in the macro ethics of sociotechnical systems
(STS). Through the lens of macro ethics, the governance of systems - which is
where participants try to promote outcomes and norms which reflect their values
- is key. However, multiple-user social dilemmas arise in an STS when
stakeholders of the STS have different value preferences or when norms in the
STS conflict. To develop equitable governance which meets the needs of
different stakeholders, and resolve these dilemmas in satisfactory ways with a
higher goal of fairness, we need to integrate a variety of normative ethical
principles in reasoning. Normative ethical principles are understood as
operationalizable rules inferred from philosophical theories. A taxonomy of
ethical principles is thus beneficial to enable practitioners to utilise them
in reasoning.
  This work develops a taxonomy of normative ethical principles which can be
operationalized in the governance of STS. We identify an array of ethical
principles, with 25 nodes on the taxonomy tree. We describe the ways in which
each principle has previously been operationalized, and suggest how the
operationalization of principles may be applied to the macro ethics of STS. We
further explain potential difficulties that may arise with each principle. We
envision this taxonomy will facilitate the development of methodologies to
incorporate ethical principles in reasoning capacities for governing equitable
STS."
10607,"Discussion

This is an early proposal in a direction that we hope to attract much further research and policy
implementation effort.",6.,"Let us now briefly set it in the context of the wider AI specification

                                                         23
                                                 BAJGAR & HORENOVSKY

problem, outline a few limitations and potential risks that this proposal carries and, relatedly,
areas in which we would consider future work to be especially fruitful.",2022-08-31 11:57:13+00:00,Negative Human Rights as a Basis for Long-term AI Safety and Regulation,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Ondrej Bajgar'), arxiv.Result.Author('Jan Horenovsky')]","If future AI systems are to be reliably safe in novel situations, they will
need to incorporate general principles guiding them to robustly recognize which
outcomes and behaviours would be harmful. Such principles may need to be
supported by a binding system of regulation, which would need the underlying
principles to be widely accepted. They should also be specific enough for
technical implementation. Drawing inspiration from law, this article explains
how negative human rights could fulfil the role of such principles and serve as
a foundation both for an international regulatory system and for building
technical safety constraints for future AI systems."
10710,"Finally, we would like to acknowledge that the pri-
mary focus of our paper is on ideal speech for the English language.11 We do not discuss
how our arguments can carry over to other languages or different modes of communica-
tion such as oral, rather than written, linguistic traditions.12 We believe it is an important
open question – and one for further research – whether and in what way other languages,
language varieties, and cultural traditions, may generate different interpretations of the
normative ideals that inform speech and communication.","We demon-

                                                          4
strate the need for research into appropriate norms of conversation that govern interac-
tion between conversational agents and human interlocutors, and we provide illustra-
tions of what this might look like.","2 Evaluating human-conversational agent interactions

At its core, linguistic communication between people can be understood as a cooperative
endeavour structured by various norms that help to ensure its success.",2022-09-01 21:16:47+00:00,In conversation with Artificial Intelligence: aligning language models with human values,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Atoosa Kasirzadeh'), arxiv.Result.Author('Iason Gabriel')]","Large-scale language technologies are increasingly used in various forms of
communication with humans across different contexts. One particular use case
for these technologies is conversational agents, which output natural language
text in response to prompts and queries. This mode of engagement raises a
number of social and ethical questions. For example, what does it mean to align
conversational agents with human norms or values? Which norms or values should
they be aligned with? And how can this be accomplished? In this paper, we
propose a number of steps that help answer these questions. We start by
developing a philosophical analysis of the building blocks of linguistic
communication between conversational agents and human interlocutors. We then
use this analysis to identify and formulate ideal norms of conversation that
can govern successful linguistic communication between humans and
conversational agents. Furthermore, we explore how these norms can be used to
align conversational agents with human values across a range of different
discursive domains. We conclude by discussing the practical implications of our
proposal for the design of conversational agents that are aligned with these
norms and values."
10711,"With further research, it may be

42See, for example, Binns [14], Lee et al.","Finally, we think that our analysis could be used to help evaluate the quality of actual
interactions between conversational agents and users.","[64], Gabriel [37], and Bondi et al.",2022-09-01 21:16:47+00:00,In conversation with Artificial Intelligence: aligning language models with human values,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Atoosa Kasirzadeh'), arxiv.Result.Author('Iason Gabriel')]","Large-scale language technologies are increasingly used in various forms of
communication with humans across different contexts. One particular use case
for these technologies is conversational agents, which output natural language
text in response to prompts and queries. This mode of engagement raises a
number of social and ethical questions. For example, what does it mean to align
conversational agents with human norms or values? Which norms or values should
they be aligned with? And how can this be accomplished? In this paper, we
propose a number of steps that help answer these questions. We start by
developing a philosophical analysis of the building blocks of linguistic
communication between conversational agents and human interlocutors. We then
use this analysis to identify and formulate ideal norms of conversation that
can govern successful linguistic communication between humans and
conversational agents. Furthermore, we explore how these norms can be used to
align conversational agents with human values across a range of different
discursive domains. We conclude by discussing the practical implications of our
proposal for the design of conversational agents that are aligned with these
norms and values."
10712,"Second,
we would like to acknowledge that the primary focus of our paper is on ideal speech for
the English language.10 We do not discuss how our arguments carry over to other lan-
guages or different modes of communication such as oral, rather than written, linguistic
traditions.11 We believe it is an important open question – and one for further research
– whether and in what way other languages, language varieties, and cultural traditions,
may generate different interpretations of the normative ideals that inform speech and
communication.","Due to limitations of space, we do not engage with
these views directly, and acknowledge that they might offer a different interpretation of
the norms governing conversation between humans and language technologies.","2 Evaluating human-conversational agent interactions

At its core, linguistic communication between people can be understood as a cooperative
endeavour structured by various norms that help to ensure its success.",2022-09-01 21:16:47+00:00,In conversation with Artificial Intelligence: aligning language models with human values,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Atoosa Kasirzadeh'), arxiv.Result.Author('Iason Gabriel')]","Large-scale language technologies are increasingly used in various forms of
communication with humans across different contexts. One particular use case
for these technologies is conversational agents, which output natural language
text in response to prompts and queries. This mode of engagement raises a
number of social and ethical questions. For example, what does it mean to align
conversational agents with human norms or values? Which norms or values should
they be aligned with? And how can this be accomplished? In this paper, we
propose a number of steps that help answer these questions. We start by
developing a philosophical analysis of the building blocks of linguistic
communication between conversational agents and human interlocutors. We then
use this analysis to identify and formulate ideal norms of conversation that
can govern successful linguistic communication between humans and
conversational agents. Furthermore, we explore how these norms can be used to
align conversational agents with human values across a range of different
discursive domains. We conclude by discussing the practical implications of our
proposal for the design of conversational agents that are aligned with these
norms and values."
10713,"With further research, it may be
possible to use our framework to reﬁne both human and automatic evaluation of the
performance of conversational agents.","Finally, we think that our analysis could be used to help evaluate the quality of actual
interactions between conversational agents and users.","6 Conclusion

This paper addresses the alignment of large-scale conversational agents with human val-
ues.",2022-09-01 21:16:47+00:00,In conversation with Artificial Intelligence: aligning language models with human values,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Atoosa Kasirzadeh'), arxiv.Result.Author('Iason Gabriel')]","Large-scale language technologies are increasingly used in various forms of
communication with humans across different contexts. One particular use case
for these technologies is conversational agents, which output natural language
text in response to prompts and queries. This mode of engagement raises a
number of social and ethical questions. For example, what does it mean to align
conversational agents with human norms or values? Which norms or values should
they be aligned with? And how can this be accomplished? In this paper, we
propose a number of steps that help answer these questions. We start by
developing a philosophical analysis of the building blocks of linguistic
communication between conversational agents and human interlocutors. We then
use this analysis to identify and formulate ideal norms of conversation that
can govern successful linguistic communication between humans and
conversational agents. Furthermore, we explore how these norms can be used to
align conversational agents with human values across a range of different
discursive domains. We conclude by discussing the practical implications of our
proposal for the design of conversational agents that are aligned with these
norms and values."
10714,"In addition to deeper investigation of the norms proposed herein, a complemen-
tary exploration of the norms that structure other languages and linguistic traditions is
another important task that remains to be explored in further research.","It could be enriched further through analysis of
other sociological and philosophical traditions such as Luhmann’s (1995) system theory,
Latour’s (2007) actor-network theory, or Cameron’s (1992) feminist analysis of linguistic
theory.","Acknowledgement

We would like to thank Courtney Biles, Martin Chadwick, Julia Haas, Po-Sen Huang,
Lisa Anne Hendricks, Geoffrey Irving, Sean Legassick, Donald Martin Jr, Jaylen Pittman,
Laura Rimmel, Christopher Summerﬁeld, Laura Weidinger and Johannes Welbl for con-
tributions and feedback on this paper.",2022-09-01 21:16:47+00:00,In conversation with Artificial Intelligence: aligning language models with human values,cs.CY,"['cs.CY', 'cs.CL']","[arxiv.Result.Author('Atoosa Kasirzadeh'), arxiv.Result.Author('Iason Gabriel')]","Large-scale language technologies are increasingly used in various forms of
communication with humans across different contexts. One particular use case
for these technologies is conversational agents, which output natural language
text in response to prompts and queries. This mode of engagement raises a
number of social and ethical questions. For example, what does it mean to align
conversational agents with human norms or values? Which norms or values should
they be aligned with? And how can this be accomplished? In this paper, we
propose a number of steps that help answer these questions. We start by
developing a philosophical analysis of the building blocks of linguistic
communication between conversational agents and human interlocutors. We then
use this analysis to identify and formulate ideal norms of conversation that
can govern successful linguistic communication between humans and
conversational agents. Furthermore, we explore how these norms can be used to
align conversational agents with human values across a range of different
discursive domains. We conclude by discussing the practical implications of our
proposal for the design of conversational agents that are aligned with these
norms and values."
10891,"We have opensourced our codebase encouraging further research2

2 Related work

Gender classiﬁcation: Hu et al (2021) [8] inferred gender from user ﬁrst names
(US data) using character based models.","We also analyze the Indian social media ‘Koo’ to understand the degree of
     representation a weaker section of the Indian society has on the web and its
     improvement over time.","They further conclude that using com-
plete names results in better prediction results compared to only ﬁrst names.",2022-09-07 11:54:49+00:00,Decoding Demographic un-fairness from Indian Names,cs.CY,"['cs.CY', 'cs.CL', 'cs.DL', 'cs.LG', 'cs.SI', 'J.4; K.4.1']","[arxiv.Result.Author('Medidoddi Vahini'), arxiv.Result.Author('Jalend Bantupalli'), arxiv.Result.Author('Souvic Chakraborty'), arxiv.Result.Author('Animesh Mukherjee')]","Demographic classification is essential in fairness assessment in recommender
systems or in measuring unintended bias in online networks and voting systems.
Important fields like education and politics, which often lay a foundation for
the future of equality in society, need scrutiny to design policies that can
better foster equality in resource distribution constrained by the unbalanced
demographic distribution of people in the country.
  We collect three publicly available datasets to train state-of-the-art
classifiers in the domain of gender and caste classification. We train the
models in the Indian context, where the same name can have different styling
conventions (Jolly Abraham/Kumar Abhishikta in one state may be written as
Abraham Jolly/Abishikta Kumar in the other). Finally, we also perform
cross-testing (training and testing on different datasets) to understand the
efficacy of the above models.
  We also perform an error analysis of the prediction models. Finally, we
attempt to assess the bias in the existing Indian system as case studies and
find some intriguing patterns manifesting in the complex demographic layout of
the sub-continent across the dimensions of gender and caste."
10892,We have also opensourced our codebase for further research and contribution.,"Through a series of
rigorous case studies we have shown the gender and caste based biases that exist
in basic and higher education as well as in the representation in social media.","In future, we will like to consider more caste varieties and data from all states
for a nuanced evaluation.",2022-09-07 11:54:49+00:00,Decoding Demographic un-fairness from Indian Names,cs.CY,"['cs.CY', 'cs.CL', 'cs.DL', 'cs.LG', 'cs.SI', 'J.4; K.4.1']","[arxiv.Result.Author('Medidoddi Vahini'), arxiv.Result.Author('Jalend Bantupalli'), arxiv.Result.Author('Souvic Chakraborty'), arxiv.Result.Author('Animesh Mukherjee')]","Demographic classification is essential in fairness assessment in recommender
systems or in measuring unintended bias in online networks and voting systems.
Important fields like education and politics, which often lay a foundation for
the future of equality in society, need scrutiny to design policies that can
better foster equality in resource distribution constrained by the unbalanced
demographic distribution of people in the country.
  We collect three publicly available datasets to train state-of-the-art
classifiers in the domain of gender and caste classification. We train the
models in the Indian context, where the same name can have different styling
conventions (Jolly Abraham/Kumar Abhishikta in one state may be written as
Abraham Jolly/Abishikta Kumar in the other). Finally, we also perform
cross-testing (training and testing on different datasets) to understand the
efficacy of the above models.
  We also perform an error analysis of the prediction models. Finally, we
attempt to assess the bias in the existing Indian system as case studies and
find some intriguing patterns manifesting in the complex demographic layout of
the sub-continent across the dimensions of gender and caste."
10915,"ACM,

design and evaluation of ToxicBuddy constitute the first step to                                                                        2021.
investigating the potential mitigation strategies and pave the way                                                                [10] Mohit Chandra, Manvith Reddy, Shradha Sehgal, Saurabh Gupta, Arun Balaji
for further research.","In ACM Conference on Web Science (WebSci), pages 148–157.","Buduru, and Ponnurangam Kumaraguru.",2022-09-07 20:45:41+00:00,Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots,cs.CY,"['cs.CY', 'cs.AI', 'cs.CR', 'cs.SI']","[arxiv.Result.Author('Wai Man Si'), arxiv.Result.Author('Michael Backes'), arxiv.Result.Author('Jeremy Blackburn'), arxiv.Result.Author('Emiliano De Cristofaro'), arxiv.Result.Author('Gianluca Stringhini'), arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Yand Zhang')]","Chatbots are used in many applications, e.g., automated agents, smart home
assistants, interactive characters in online games, etc. Therefore, it is
crucial to ensure they do not behave in undesired manners, providing offensive
or toxic responses to users. This is not a trivial task as state-of-the-art
chatbot models are trained on large, public datasets openly collected from the
Internet. This paper presents a first-of-its-kind, large-scale measurement of
toxicity in chatbots. We show that publicly available chatbots are prone to
providing toxic responses when fed toxic queries. Even more worryingly, some
non-toxic queries can trigger toxic responses too. We then set out to design
and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to
generate non-toxic queries that make chatbots respond in a toxic manner. Our
extensive experimental evaluation demonstrates that our attack is effective
against public chatbot models and outperforms manually-crafted malicious
queries proposed by previous work. We also evaluate three defense mechanisms
against ToxicBuddy, showing that they either reduce the attack performance at
the cost of affecting the chatbot's utility or are only effective at mitigating
a portion of the attack. This highlights the need for more research from the
computer security and online safety communities to ensure that chatbot models
do not hurt their users. Overall, we are confident that ToxicBuddy can be used
as an auditing tool and that our work will pave the way toward designing more
effective defenses for chatbot safety."
10916,"ACM,

design and evaluation of ToxicBuddy constitute the first step to                                                                        2021.
investigating the potential mitigation strategies and pave the way                                                                [10] Mohit Chandra, Manvith Reddy, Shradha Sehgal, Saurabh Gupta, Arun Balaji
for further research.","In ACM Conference on Web Science (WebSci), pages 148–157.","Buduru, and Ponnurangam Kumaraguru.",2022-09-07 20:45:41+00:00,Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots,cs.CY,"['cs.CY', 'cs.AI', 'cs.CR', 'cs.SI']","[arxiv.Result.Author('Wai Man Si'), arxiv.Result.Author('Michael Backes'), arxiv.Result.Author('Jeremy Blackburn'), arxiv.Result.Author('Emiliano De Cristofaro'), arxiv.Result.Author('Gianluca Stringhini'), arxiv.Result.Author('Savvas Zannettou'), arxiv.Result.Author('Yang Zhang')]","Chatbots are used in many applications, e.g., automated agents, smart home
assistants, interactive characters in online games, etc. Therefore, it is
crucial to ensure they do not behave in undesired manners, providing offensive
or toxic responses to users. This is not a trivial task as state-of-the-art
chatbot models are trained on large, public datasets openly collected from the
Internet. This paper presents a first-of-its-kind, large-scale measurement of
toxicity in chatbots. We show that publicly available chatbots are prone to
providing toxic responses when fed toxic queries. Even more worryingly, some
non-toxic queries can trigger toxic responses too. We then set out to design
and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to
generate non-toxic queries that make chatbots respond in a toxic manner. Our
extensive experimental evaluation demonstrates that our attack is effective
against public chatbot models and outperforms manually-crafted malicious
queries proposed by previous work. We also evaluate three defense mechanisms
against ToxicBuddy, showing that they either reduce the attack performance at
the cost of affecting the chatbot's utility or are only effective at mitigating
a portion of the attack. This highlights the need for more research from the
computer security and online safety communities to ensure that chatbot models
do not hurt their users. Overall, we are confident that ToxicBuddy can be used
as an auditing tool and that our work will pave the way toward designing more
effective defenses for chatbot safety."
10951,"People’s receptiveness to advice was also
conducting further research varying the degree of human-         shown to be correlated with the inferred quality and accu-
machine similarity beyond the three degrees we studied.","These differences may be less         trust in automation (Hoff and Bashir 2015; Madhavan and
severe for real-world decision aids, and it is hence worth       Wiegmann 2007).",racy of an advisor’s advice (Bonaccio and Dalal 2006).,2022-09-08 13:50:35+00:00,Taking Advice from (Dis)Similar Machines: The Impact of Human-Machine Similarity on Machine-Assisted Decision-Making,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Author('Nina Grgić-Hlača'), arxiv.Result.Author('Claude Castelluccia'), arxiv.Result.Author('Krishna P. Gummadi')]","Machine learning algorithms are increasingly used to assist human
decision-making. When the goal of machine assistance is to improve the accuracy
of human decisions, it might seem appealing to design ML algorithms that
complement human knowledge. While neither the algorithm nor the human are
perfectly accurate, one could expect that their complementary expertise might
lead to improved outcomes. In this study, we demonstrate that in practice
decision aids that are not complementary, but make errors similar to human ones
may have their own benefits.
  In a series of human-subject experiments with a total of 901 participants, we
study how the similarity of human and machine errors influences human
perceptions of and interactions with algorithmic decision aids. We find that
(i) people perceive more similar decision aids as more useful, accurate, and
predictable, and that (ii) people are more likely to take opposing advice from
more similar decision aids, while (iii) decision aids that are less similar to
humans have more opportunities to provide opposing advice, resulting in a
higher influence on people's decisions overall."
11039,"Exploring several limitations of this study may produce
noteworthy references for further study.","It is the initial research work on behavioral modelling of Web3 and delivers the resourceful
viewpoint for forthcoming research.","Firstly, we compiled a small set of data based on the
snowball sampling, which could not provide a broad measure of respondents’ Behavioral Intention.",2022-09-11 16:37:46+00:00,Web 3.0 Adoption Behavior: PLS-SEM and Sentiment Analysis,cs.CY,"['cs.CY', 'cs.HC']","[arxiv.Result.Author('Sheikh M. Hizam'), arxiv.Result.Author('Waqas Ahmed'), arxiv.Result.Author('Habiba Akter'), arxiv.Result.Author('Ilham Sentosa'), arxiv.Result.Author('Mohamad N. Masrek')]","Web 3.0 is considered as future of Internet where decentralization, user
personalization and privacy protection would be the main aspects of Internet.
Aim of this research work is to elucidate the adoption behavior of Web
3.0through a multi-analytical approach based on Partial Least Squares
Structural Equation Modelling (PLS-SEM) and Twitter sentiment analysis. A
theoretical framework centered on Performance Expectancy (PE), Electronic
Word-of-Mouth (eWOM) and Digital Dexterity (DD), was hypothesized towards
Behavioral Intention (INT) of the Web 3.0 adoption. Surveyed data were
collected through online questionnaires and 167 responses were analyzed through
PLS-SEM. While 3,989 tweets of Web3 were analyzed by VADER sentiment analysis
tool in RapidMiner. PLS-SEM results showed that DD and eWOM had significant
impact while PE had no effect on INT. Moreover, these results were also
validated by PLS-Predict method. While sentiment analysis explored that 56%
tweets on Web 3.0 were positive in sense and 7% depicted negative sentiment
while remaining were neutral. Such inferences are novel in nature and an
innovative addition to web informatics and could support the stakeholders
towards web technology integration"
11072,"Why we need further study
In some regards, the medical and health industry has set the standard for various practices that prioritize protecting patients’
personal information.","For our purposes, we explore whether the mHealth domain has been adequately assessed
for the impact of unwanted bias and to what extent our current guardrails (e.g., regulation) address disparate or discriminatory
outcomes.","In the U.S., the Health Insurance Portability and Accountability Act (1996) (""HIPAA"") regulates personal
health information collected and used by covered entities and business associates.",2022-08-29 00:15:45+00:00,"Bias Impact Analysis of AI in Consumer Mobile Health Technologies: Legal, Technical, and Policy",cs.CY,['cs.CY'],"[arxiv.Result.Author('Kristine Gloria'), arxiv.Result.Author('Nidhi Rastogi'), arxiv.Result.Author('Stevie DeGroff')]","Today's large-scale algorithmic and automated deployment of decision-making
systems threatens to exclude marginalized communities. Thus, the emergent
danger comes from the effectiveness and the propensity of such systems to
replicate, reinforce, or amplify harmful existing discriminatory acts.
Algorithmic bias exposes a deeply entrenched encoding of a range of unwanted
biases that can have profound real-world effects that manifest in domains from
employment, to housing, to healthcare. The last decade of research and examples
on these effects further underscores the need to examine any claim of a
value-neutral technology. This work examines the intersection of algorithmic
bias in consumer mobile health technologies (mHealth). We include mHealth, a
term used to describe mobile technology and associated sensors to provide
healthcare solutions through patient journeys. We also include mental and
behavioral health (mental and physiological) as part of our study. Furthermore,
we explore to what extent current mechanisms - legal, technical, and or
normative - help mitigate potential risks associated with unwanted bias in
intelligent systems that make up the mHealth domain. We provide additional
guidance on the role and responsibilities technologists and policymakers have
to ensure that such systems empower patients equitably."
11073,"One point of further study is the economic feasibility of implementing such a complex assessment
program.","To address
the entire product life cycle, combining these pre-development questions with a post-dev auditing mechanism would ensure a
thorough examination of bias.","Policy and regulatory strategies
Another critical prong for mitigating unwanted biases is through public policymaking and regulation.",2022-08-29 00:15:45+00:00,"Bias Impact Analysis of AI in Consumer Mobile Health Technologies: Legal, Technical, and Policy",cs.CY,['cs.CY'],"[arxiv.Result.Author('Kristine Gloria'), arxiv.Result.Author('Nidhi Rastogi'), arxiv.Result.Author('Stevie DeGroff')]","Today's large-scale algorithmic and automated deployment of decision-making
systems threatens to exclude marginalized communities. Thus, the emergent
danger comes from the effectiveness and the propensity of such systems to
replicate, reinforce, or amplify harmful existing discriminatory acts.
Algorithmic bias exposes a deeply entrenched encoding of a range of unwanted
biases that can have profound real-world effects that manifest in domains from
employment, to housing, to healthcare. The last decade of research and examples
on these effects further underscores the need to examine any claim of a
value-neutral technology. This work examines the intersection of algorithmic
bias in consumer mobile health technologies (mHealth). We include mHealth, a
term used to describe mobile technology and associated sensors to provide
healthcare solutions through patient journeys. We also include mental and
behavioral health (mental and physiological) as part of our study. Furthermore,
we explore to what extent current mechanisms - legal, technical, and or
normative - help mitigate potential risks associated with unwanted bias in
intelligent systems that make up the mHealth domain. We provide additional
guidance on the role and responsibilities technologists and policymakers have
to ensure that such systems empower patients equitably."
11074,"6 For further study

The mobile health market is booming, and the potential of mHealth apps to improve access to real-time monitoring and health
care resources for changing health-related behaviors is well established49.","Instead, there is a signiﬁcant and dire need for
actionable interventions that may include third-party oversight and accountability.","Nevertheless, mHealth apps also pose problems
concerning data privacy and potentially exacerbate unwanted bias, which can disproportionately impact speciﬁc populations.",2022-08-29 00:15:45+00:00,"Bias Impact Analysis of AI in Consumer Mobile Health Technologies: Legal, Technical, and Policy",cs.CY,['cs.CY'],"[arxiv.Result.Author('Kristine Gloria'), arxiv.Result.Author('Nidhi Rastogi'), arxiv.Result.Author('Stevie DeGroff')]","Today's large-scale algorithmic and automated deployment of decision-making
systems threatens to exclude marginalized communities. Thus, the emergent
danger comes from the effectiveness and the propensity of such systems to
replicate, reinforce, or amplify harmful existing discriminatory acts.
Algorithmic bias exposes a deeply entrenched encoding of a range of unwanted
biases that can have profound real-world effects that manifest in domains from
employment, to housing, to healthcare. The last decade of research and examples
on these effects further underscores the need to examine any claim of a
value-neutral technology. This work examines the intersection of algorithmic
bias in consumer mobile health technologies (mHealth). We include mHealth, a
term used to describe mobile technology and associated sensors to provide
healthcare solutions through patient journeys. We also include mental and
behavioral health (mental and physiological) as part of our study. Furthermore,
we explore to what extent current mechanisms - legal, technical, and or
normative - help mitigate potential risks associated with unwanted bias in
intelligent systems that make up the mHealth domain. We provide additional
guidance on the role and responsibilities technologists and policymakers have
to ensure that such systems empower patients equitably."
11077,"Since some philosophical theories such as longtermism say that exis-
       tential risk reduction has extremely high value, further research would be
       valuable.","Although previous work and this
       report arrive at some useful conclusions, there is still substantial uncer-

                                                  16
       tainty about existential risk and which actions would be useful to reduce
       it.","Also, until relatively recently research on existential risk and
       AI strategy has been neglected.",2022-08-30 15:49:11+00:00,How Do AI Timelines Affect Existential Risk?,cs.CY,['cs.CY'],[arxiv.Result.Author('Stephen McAleese')],"Superhuman artificial general intelligence could be created this century and
would likely be a significant source of existential risk. Delaying the creation
of superintelligent AI (ASI) could decrease total existential risk by
increasing the amount of time humanity has to work on the AI alignment problem.
  However, since ASI could reduce most risks, delaying the creation of ASI
could also increase other existential risks, especially from advanced future
technologies such as synthetic biology and molecular nanotechnology.
  If AI existential risk is high relative to the sum of other existential risk,
delaying the creation of ASI will tend to decrease total existential risk and
vice-versa.
  Other factors such as war and a hardware overhang could increase AI risk and
cognitive enhancement could decrease AI risk. To reduce total existential risk,
humanity should take robustly positive actions such as working on existential
risk analysis, AI governance and safety, and reducing all sources of
existential risk by promoting differential technological development."
11078,"Beyond the prevalent assess-
ment that existing legislations are not appropriate for the wide range of AI applications, the
results show a partly fragmented, heterogeneous or unspecified field of ideas, and uncovers
uncertainty and ambiguities which should serve as a focal point both for further research and
political negotiations.","It provides an overarching regulatory picture by synthesizing the proposals and
assessments stemming from literature across different disciplines.","Our review did not aim to develop an ideal regulatory model including
responsible actors, processes, and instruments.",2022-09-07 11:29:30+00:00,"Tackling problems, harvesting benefits -- A systematic review of the regulatory debate around AI",cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Anja Folberth'), arxiv.Result.Author('Jutta Jahnel'), arxiv.Result.Author('Jascha Bareis'), arxiv.Result.Author('Carsten Orwat'), arxiv.Result.Author('Christian Wadephul')]","How to integrate an emerging and all-pervasive technology such as AI into the
structures and operations of our society is a question of contemporary
politics, science and public debate. It has produced a considerable amount of
international academic literature from different disciplines. This article
analyzes the academic debate around the regulation of artificial intelligence
(AI). The systematic review comprises a sample of 73 peer-reviewed journal
articles published between January 1st, 2016, and December 31st, 2020. The
analysis concentrates on societal risks and harms, questions of regulatory
responsibility, and possible adequate policy frameworks, including risk-based
and principle-based approaches. The main interests are proposed regulatory
approaches and instruments. Various forms of interventions such as bans,
approvals, standard-setting, and disclosure are presented. The assessments of
the included papers indicate the complexity of the field, which shows its
prematurity and the remaining lack of clarity. By presenting a structured
analysis of the academic debate, we contribute both empirically and
conceptually to a better understanding of the nexus of AI and regulation and
the underlying normative decisions. A comparison of the scientific proposals
with the proposed European AI regulation illustrates the specific approach of
the regulation, its strengths and weaknesses."
11079,"This stock of knowledge is a viable basis for further research and public discussions that
are necessary in many respects, in particular for the evaluation of the emerging regulatory
frameworks with respect to effectivity, legitimacy or coherence.","Instead, we have shown that there is already a
rich source of scientific knowledge which can be transferred and adopted for regulatory pur-
poses.","Furthermore, the emergence
of new AI applications with specific risks requires continuous adaptations of the regulatory
frameworks.",2022-09-07 11:29:30+00:00,"Tackling problems, harvesting benefits -- A systematic review of the regulatory debate around AI",cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Anja Folberth'), arxiv.Result.Author('Jutta Jahnel'), arxiv.Result.Author('Jascha Bareis'), arxiv.Result.Author('Carsten Orwat'), arxiv.Result.Author('Christian Wadephul')]","How to integrate an emerging and all-pervasive technology such as AI into the
structures and operations of our society is a question of contemporary
politics, science and public debate. It has produced a considerable amount of
international academic literature from different disciplines. This article
analyzes the academic debate around the regulation of artificial intelligence
(AI). The systematic review comprises a sample of 73 peer-reviewed journal
articles published between January 1st, 2016, and December 31st, 2020. The
analysis concentrates on societal risks and harms, questions of regulatory
responsibility, and possible adequate policy frameworks, including risk-based
and principle-based approaches. The main interests are proposed regulatory
approaches and instruments. Various forms of interventions such as bans,
approvals, standard-setting, and disclosure are presented. The assessments of
the included papers indicate the complexity of the field, which shows its
prematurity and the remaining lack of clarity. By presenting a structured
analysis of the academic debate, we contribute both empirically and
conceptually to a better understanding of the nexus of AI and regulation and
the underlying normative decisions. A comparison of the scientific proposals
with the proposed European AI regulation illustrates the specific approach of
the regulation, its strengths and weaknesses."
11080,"To stimulate
further research, the data and code are available publicly at:      [6] Yanjie Fu, Hui Xiong, Yong Ge, Zijun Yao, Yu Zheng, and Zhi-Hua
https://github.com/IndigoPurple/PATE.","Journal of Property
prediction accuracy and also enhance performance by de-                  Valuation and Investment, 1998.
signing complex variants of existing models.",While we aim to use                Zhou.,2022-08-29 12:31:10+00:00,"PATE: Property, Amenities, Traffic and Emotions Coming Together for Real Estate Price Prediction",cs.CY,['cs.CY'],"[arxiv.Result.Author('Yaping Zhao'), arxiv.Result.Author('Ramgopal Ravi'), arxiv.Result.Author('Shuhui Shi'), arxiv.Result.Author('Zhongrui Wang'), arxiv.Result.Author('Edmund Y. Lam'), arxiv.Result.Author('Jichang Zhao')]","Real estate prices have a significant impact on individuals, families,
businesses, and governments. The general objective of real estate price
prediction is to identify and exploit socioeconomic patterns arising from real
estate transactions over multiple aspects, ranging from the property itself to
other contributing factors. However, price prediction is a challenging
multidimensional problem that involves estimating many characteristics beyond
the property itself. In this paper, we use multiple sources of data to evaluate
the economic contribution of different socioeconomic characteristics such as
surrounding amenities, traffic conditions and social emotions. Our experiments
were conducted on 28,550 houses in Beijing, China and we rank each
characteristic by its importance. Since the use of multi-source information
improves the accuracy of predictions, the aforementioned characteristics can be
an invaluable resource to assess the economic and social value of real estate.
Code and data are available at: https://github.com/IndigoPurple/PATE"
11081,"To stimulate
further research, the data and code are available publicly at:      [6] Yanjie Fu, Hui Xiong, Yong Ge, Zijun Yao, Yu Zheng, and Zhi-Hua
https://github.com/IndigoPurple/PATE.","Journal of Property
prediction accuracy and also enhance performance by de-                  Valuation and Investment, 1998.
signing complex variants of existing models.",While we aim to use                Zhou.,2022-08-29 12:31:10+00:00,"PATE: Property, Amenities, Traffic and Emotions Coming Together for Real Estate Price Prediction",cs.CY,['cs.CY'],"[arxiv.Result.Author('Yaping Zhao'), arxiv.Result.Author('Ramgopal Ravi'), arxiv.Result.Author('Shuhui Shi'), arxiv.Result.Author('Zhongrui Wang'), arxiv.Result.Author('Edmund Y. Lam'), arxiv.Result.Author('Jichang Zhao')]","Real estate prices have a significant impact on individuals, families,
businesses, and governments. The general objective of real estate price
prediction is to identify and exploit socioeconomic patterns arising from real
estate transactions over multiple aspects, ranging from the property itself to
other contributing factors. However, price prediction is a challenging
multidimensional problem that involves estimating many characteristics beyond
the property itself. In this paper, we use multiple sources of data to evaluate
the economic contribution of different socioeconomic characteristics such as
surrounding amenities, traffic conditions and social emotions. Our experiments
were conducted on 28,550 houses in Beijing, China and we rank each
characteristic by its importance. Since the use of multi-source information
improves the accuracy of predictions, the aforementioned characteristics can be
an invaluable resource to assess the economic and social value of real estate.
Code and data are available at: https://github.com/IndigoPurple/PATE"
11270,"The problem of measurement of impact and a general monitoring, evaluation and learning
(MEL) framework is generally diﬃcult, so also points to areas for further research to eﬀectively make participatory
methods part of regular practice [35].","Investing in such types of participation may appear
wasteful when outcomes are measured using blunt instruments such as cost-beneﬁt analysis, and it could instead be
the limitations of the metrics we use to evaluate participatory approaches that are an obstacle to the eﬀective use of
participatory approaches.",Expertise and Incentives.,2022-09-15 19:20:13+00:00,Power to the People? Opportunities and Challenges for Participatory AI,cs.CY,['cs.CY'],"[arxiv.Result.Author('Abeba Birhane'), arxiv.Result.Author('William Isaac'), arxiv.Result.Author('Vinodkumar Prabhakaran'), arxiv.Result.Author('Mark Díaz'), arxiv.Result.Author('Madeleine Clare Elish'), arxiv.Result.Author('Iason Gabriel'), arxiv.Result.Author('Shakir Mohamed')]","Participatory approaches to artificial intelligence (AI) and machine learning
(ML) are gaining momentum: the increased attention comes partly with the view
that participation opens the gateway to an inclusive, equitable, robust,
responsible and trustworthy AI.Among other benefits, participatory approaches
are essential to understanding and adequately representing the needs, desires
and perspectives of historically marginalized communities. However, there
currently exists lack of clarity on what meaningful participation entails and
what it is expected to do. In this paper we first review participatory
approaches as situated in historical contexts as well as participatory methods
and practices within the AI and ML pipeline. We then introduce three case
studies in participatory AI.Participation holds the potential for beneficial,
emancipatory and empowering technology design, development and deployment while
also being at risk for concerns such as cooptation and conflation with other
activities. We lay out these limitations and concerns and argue that as
participatory AI/ML becomes in vogue, a contextual and nuanced understanding of
the term as well as consideration of who the primary beneficiaries of
participatory activities ought to be constitute crucial factors to realizing
the benefits and opportunities that participation brings."
11508,"This is an exciting development
in the industry and one that warrants further research in due course.","Applying the same
approach to venture capital firms as they do to startups, Founder Institute are now “working
to launch 1,000 new venture capital firms over the next five years to support innovative
companies worldwide that are working to make an impact”.","References

Agnew, H. (2022, April 13).",2022-09-13 01:17:39+00:00,Sustainable Venture Capital,cs.CY,"['cs.CY', 'econ.GN', 'q-fin.EC', 'K.1; K.4.1; K.5.2']",[arxiv.Result.Author('Sam Johnston')],"Sustainability initiatives are set to benefit greatly from the growing
involvement of venture capital, in the same way that other technological
endeavours have been enabled and accelerated in the post-war period. With the
spoils increasingly being shared between shareholders and other stakeholders,
this requires a more nuanced view than the finance-first methodologies deployed
to date. Indeed, it is possible for a venture-backed sustainability startup to
deliver outstanding results to society in general without returning a cent to
investors, though the most promising outcomes deliver profit with purpose,
satisfying all stakeholders in ways that make existing 'extractive' venture
capital seem hollow.
  To explore this nascent area, a review of related research was conducted and
social entrepreneurs & investors interviewed to construct a questionnaire
assessing the interests and intentions of current & future ecosystem
participants. Analysis of 114 responses received via several sampling methods
revealed statistically significant relationships between investing preferences
and genders, generations, sophistication, and other variables, all the way down
to the level of individual UN Sustainable Development Goals (SDGs)."
11509,"Appendix B Data

The survey data analysed is provided for validation and further research.","* 3.54x (vs 7.54x) median moic at sustainability acquisition

EXAMINE VARIABLES=moic_acq
 /PLOT BOXPLOT STEMLEAF
 /COMPARE GROUPS
 /STATISTICS DESCRIPTIVES
 /CINTERVAL 95
 /MISSING LISTWISE
 /NOTOTAL
 /ID moic_acq.","country,d_generation_older,d_holding_period_long,d_investor_type_pro,d_risk_appetite_high,d_sustainability_preferred,gender,generat
ion,holding_period,hurdle_rate,investor_type,motivation_ranking_1,motivation_ranking_2,motivation_ranking_3,motivation_ranking_4,
motivation_ranking_5,nps,nps_detractor,nps_passive,nps_promoter,nps_type,risk_appetite,sdg1,sdg2,sdg3,sdg4,sdg5,sdg6,sdg7,sdg8,sdg
9,sdg10,sdg11,sdg12,sdg13,sdg14,sdg15,sdg16,sdg17,sustainability_preference,sustainability_returns,rank_environment,rank_resilience,r
ank_performance,rank_legacy,rank_empowerment
6,1,0,1,1,1,2,3,1, ,5,1,3,4,2,5,7,0,1,0,0,4,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,4,3,5,2,4,3,1
1,1,0,1,1,1,2,3,2, ,4,4,1,2,5,3,10,0,0,1,1,4,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,5,3,4,3,1,5,2
8,1,0,0,1,1,2,3,2,10,2,1,3,2,5,4,9,0,0,1,1,4,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,5,3,5,3,4,1,2
16,0,1,1,1,0,2,4,4, ,3,2,5,1,3,4,1,1,0,0,-1,5,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,2,2,3,5,2,1,4
13,0,0,0,0,1,1,4,2,15,2,4,1,2,3,5,6,1,0,0,-1,3,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,4,4,4,3,2,5,1
13,0,0,1,1,1,1,4,2, ,3,5,1,2,3,4,10,0,0,1,1,4,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,5,3,4,3,2,1,5
13,1,1,1,1,0,1,3,3,6,4,1,2,5,3,4,7,0,1,0,0,4,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,3,3,5,4,2,1,3
13,1,0,1,1,1,2,3,2,10,3,1,3,4,2,5,9,0,0,1,1,5,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,5,3,5,2,4,3,1
1, ,1,1,0,1,1, ,3,40,3,1,2,4,5,3,10,0,0,1,1,2,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,5,3,5,4,1,3,2
1,1,1,1,1,1,1,2,4,10,3,1,4,2,3,5,10,0,0,1,1,4,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,5,3,5,3,2,4,1
16,0,1,0,1,1,2,4,3,7,1,4,1,5,2,3,8,0,1,0,0,4,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,4,3,4,2,1,5,3
13,0,0,0,0,0,1,4,2,10,2,1,4,5,2,3,7,0,1,0,0,3,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,3,3,5,2,1,4,3
1,0,0,0,1,0,1,4,1, ,2,3,2,5,1,4,4,1,0,0,-1,4,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,2,3,2,4,5,1,3
20,0,0,0,1,1,1,4,2,5,2,1,4,2,3,5,7,0,1,0,0,4,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4,3,5,3,2,4,1
2,1,0,0,0,1,2,3,2,8,2,3,2,5,1,4,8,0,1,0,0,3,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,4,2,2,4,5,1,3
16,0,1,0,0,1,2,4,3, ,2,1,4,2,3,5,9,0,0,1,1,3,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,0,0,5,4,5,3,2,4,1
20,0,1,0,1,1,2,4,3,15,2,3,2,1,4,5,5,1,0,0,-1,4,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,4,5,3,4,5,2,1
16,0,1,0,1,0,2,4,4,8,2,1,4,5,2,3,0,1,0,0,-1,5,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,2,1,5,2,1,4,3
20,1,0,0,0,1,2,2,2,0,2,4,1,5,2,3,9,0,0,1,1,3,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,4,2,4,2,1,5,3
16,0,0,0,1,1,2,4,2,12,2,4,1,2,3,5,5,1,0,0,-1,4,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,5,4,4,3,2,5,1
1,1,0,1,1,1,2,3,2,12,5,3,4,1,2,5,5,1,0,0,-1,4,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,4,3,3,2,5,4,1
1,1,1,0,1,1,2,3,3, ,1,1,4,3,2,5,10,0,0,1,1,5,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,4,3,5,2,3,4,1
15,1,1,0,0,1,2,3,3,4,1,1,3,2,4,5,7,0,1,0,0,2,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,4,4,5,3,4,2,1
5,1,1,0,0,1,2,3,3, ,2,4,1,5,3,2,9,0,0,1,1,3,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,4,3,4,1,2,5,3
6,0,1,0,0,1,2,4,3,4,2,1,4,2,3,5,9,0,0,1,1,3,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,5,4,5,3,2,4,1
8,0,0,0,0,1,2,4,2,8,2,4,3,2,5,1,7,0,1,0,0,3,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,4,4,1,3,4,5,2
13,1,0,0,1,1,2,3,2,25,2,4,1,2,3,5,8,0,1,0,0,4,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,4,3,4,3,2,5,1
13,0,0,0,1,0,2,4,2,15,2,1,3,4,2,5,5,1,0,0,-1,4,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,3,4,5,2,4,3,1
12,1,0,0,1,0,2,3,1,10,2,4,2,3,1,5,5,1,0,0,-1,4,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,3,2,2,4,3,5,1
9,1,0,0,1,0,2,3,2,50,2, , , , , ,2,1,0,0,-1,4,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,0,0,3,2, , , , ,
8,0,1,0,1,0,1,5,4,12,2,2,3,1,4,5,8,0,1,0,0,4,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,3,4,3,5,4,2,1
13,0,0,0,1,1,2,4,1,10,2,4,1,3,2,5,5,1,0,0,-1,5,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,4,4,4,2,3,5,1
13,0,0,0,0,0,1,4,1,10,2,5,4,1,3,2,5,1,0,0,-1,2,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,3,3,3,1,2,4,5
8,0,0,0,0,0,2,4,2,8,2,2,1,4,3,5,7,0,1,0,0,3,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,3,2,4,5,2,3,1
20,1,0,0,1,1,2,3,2,7,2,1,3,2,4,5,9,0,0,1,1,4,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,4,3,5,3,4,2,1
9,0,0,0,0,1,2,4,2,5,2,1,5,4,2,3,7,0,1,0,0,3,0,0,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,4,3,5,2,1,3,4
20,1,1,0,1,1,2,2,4,7,1,4,1,2,3,5,8,0,1,0,0,4,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,3,4,3,2,5,1
9,1,1,1,0,0, ,3,3,8,3,2,3,4,1,5,4,1,0,0,-1,3,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,3,3,2,5,4,3,1
13,1,1,1,0,0,1,3,3, ,4,3,2,1,5,4,6,1,0,0,-1,3,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,3,4,3,4,5,1,2
9,1,1,0,0,1,1,3,4,10,0,1,5,4,2,3,5,1,0,0,-1,2,0,0,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,4,2,5,2,1,3,4
18,0,0,0,1,0,2,4,2,20,2,3,2,1,4,5,7,0,1,0,0,4,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,3,3,3,4,5,2,1
1,0,0,0,0,1,1,4,2, ,0,1,2,4,3,5,10,0,0,1,1,2,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,5,2,5,4,2,3,1
11,0,1,0,0,1,1,4,3, ,2,4,5,2,1,3,9,0,0,1,1,3,0,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,4,3,2,3,1,5,4
13,1,1,0,0,1,2,3,3,7,2,1,4,2,3,5,8,0,1,0,0,3,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,5,3,5,3,2,4,1
5,0,0,0,1,1,2,4,1, ,0, , , , , ,8,0,1,0,0,5,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,1,5,3, , , , ,
1,1,0,1,1,0,2,3,2,9,3,3,2,5,1,4,5,1,0,0,-1,4,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,3,3,2,4,5,1,3
5,1,0,0,0,1,2,2,2,5,2,2,3,4,1,5,7,0,1,0,0,3,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,4,4,2,5,4,3,1
1,0,1,0,0,1,2,4,3, ,2,3,2,1,5,4,8,0,1,0,0,3,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,5,4,3,4,5,1,2
6,0,0,0,1,0,2,4,2,8,2,3,1,2,4,5,0,1,0,0,-1,4,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0,3,2,4,3,5,2,1
1,1,1,1,1,0,2,3,3,15,3,1,4,2,3,5,5,1,0,0,-1,5,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,3,2,5,3,2,4,1
13,0,0,0,1,0,2,4,2,10,2,1,5,4,2,3,5,1,0,0,-1,4,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2,2,5,2,1,3,4
17,0,0,0,1,0,2,4,2,10,2,3,1,2,4,5,5,1,0,0,-1,4,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,3,3,4,3,5,2,1
13,0,0,0,0,0,2,4,2,10,2,5,2,1,4,3,6,1,0,0,-1,3,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,3,3,3,4,1,2,5
1,1,1,1,1,1,2,3,3,8,5,1,2,4,3,5,8,0,1,0,0,4,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,5,3,5,4,2,3,1
1,1,0,0,1,1,2,3,2, ,2,1,5,4,3,2,9,0,0,1,1,4,0,0,0,0,0,1,1,0,0,0,0,1,0,0,0,0,0,5,3,5,1,2,3,4
10,1,1,0,0,0,2,3,4, ,2,2,3,1,4,5,5,1,0,0,-1,3,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,4,3,5,4,2,1
13,0,1,1,0,0,2,4,4,3,3,3,2,5,1,4,0,1,0,0,-1,3,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,3,3,2,4,5,1,3
13,0,1,1,0,0,1,4,3,15,3,3,1,2,4,5,8,0,1,0,0,3,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,3,3,4,3,5,2,1
1,1,1,0,0,1,1,3,4, ,2,1,4,3,5,2,9,0,0,1,1,2,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,5,3,5,1,3,4,2
3,0,0,0,1,0,2,4,1,25,2,2,3,4,1,5,3,1,0,0,-1,5,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,2,3,2,5,4,3,1
13,1,1,0,0,1,2,3,3,6,2,4,2,3,1,5,7,0,1,0,0,3,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,4,3,2,4,3,5,1
20,1,1,1,1,1,1,3,4,10,5,1,4,2,3,5,7,0,1,0,0,4,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,5,4,5,3,2,4,1
7,1,0,1,1,0,2,3,2,7,3,2,3,1,4,5,7,0,1,0,0,4,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,3,3,3,5,4,2,1
16,0,1,0,1,1,1,4,3,3,1,1,2,4,3,5,9,0,0,1,1,4,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,4,3,5,4,2,3,1
13,0,0,0,1,1,2,4,2, ,2,1,5,3,4,2,3,1,0,0,-1,4,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,4,3,5,1,3,2,4
4,0,0,0,1,1,2,4,2, ,2,1,4,5,2,3,4,1,0,0,-1,4,0,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,4,2,5,2,1,4,3
21,0,0,0,0,0,2,4,2, ,1,2,1,4,5,3,3,1,0,0,-1,2,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,3,2,4,5,1,3,2
13,0,0,1,1,1,2,4,2,7,3,3,2,1,4,5,9,0,0,1,1,4,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,4,3,3,4,5,2,1
21,0,1,0,1,1,2,4,3,5,2,3,1,2,4,5,6,1,0,0,-1,4,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,4,3,4,3,5,2,1
1,0,0,0,0,1,2,4,2,5,0,4,5,1,2,3,5,1,0,0,-1,3,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,4,4,3,2,1,5,4
13,0,0,0,0,0,2,4,2,7,2,1,4,3,2,5,8,0,1,0,0,3,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,3,3,5,2,3,4,1
6,1,1,0,0,1,1,2,4,3,2,1,4,5,2,3,8,0,1,0,0,2,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,5,2,5,2,1,4,3
1,0,0,1,1,1,2,4,2, ,3,1,3,2,4,5,9,0,0,1,1,4,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,4,3,5,3,4,2,1
13,1,0,0,1,1,2,3,2,20,2,1,2,3,4,5,9,0,0,1,1,4,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,4,3,5,4,3,2,1
13,0,1,0,1,1,2,4,3,8,2,4,1,5,2,3,10,0,0,1,1,4,0,0,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,5,3,4,2,1,5,3
8,1,0,0,1,0,2,3,2,35,2, , , , , ,5,1,0,0,-1,4,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,3,4, , , , ,
1,0,1,0,0,1,2,4,3,5,1,3,1,2,4,5,2,1,0,0,-1,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,4,3,4,3,5,2,1
1,0,1,0,0,1,2,4,3,10,2,1,4,2,3,5,5,1,0,0,-1,2,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,4,3,5,3,2,4,1
1,0,1,0,1,1,1,4,4,15,1,3,2,4,1,5,8,0,1,0,0,4,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,5,2,2,4,5,3,1
13,1,1,1,0,1,2,3,3,25,3,5,1,2,3,4,10,0,0,1,1,3,0,0,1,0,0,0,0,0,1,0,1,0,0,0,0,0,0,4,3,4,3,2,1,5
13,0,1,0,1,0,2,4,4,10,2,3,2,1,4,5,4,1,0,0,-1,4,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,3,3,3,4,5,2,1
1,1,1,1,1,1,2,3,3,8,5,1,4,3,2,5,9,0,0,1,1,4,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,5,3,5,2,3,4,1
13,1,0,0,0,1,2,3,2,15,2,3,2,5,1,4,10,0,0,1,1,2,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,5,4,2,4,5,1,3
1,0,0,0,0,1,2,4,2,8,2,2,3,1,4,5,5,1,0,0,-1,1,1,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,4,2,3,5,4,2,1
20,1,0,1,1,1,2,3,2,5,3,1,3,2,5,4,10,0,0,1,1,4,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,4,3,5,3,4,1,2
8,0,0,0,0,1,2,4,1,12,2,3,2,1,4,5,10,0,0,1,1,3,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5,3,3,4,5,2,1
14,0,1,0,0,1,1,4,4, ,1,1,4,3,2,5,9,0,0,1,1,3,1,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,5,3,5,2,3,4,1
16,0,1,0,1,0,2,4,3,7,2,3,2,1,5,4,5,1,0,0,-1,4,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,3,3,3,4,5,1,2
8,0,1,0,0,0,2,4,4,10,1,3,4,2,1,5,7,0,1,0,0,2,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,3,3,2,3,5,4,1
16,0,0,0,1,1,1,4,2,8,2,3,1,2,4,5,9,0,0,1,1,5,0,0,0,0,0,0,1,0,0,1,0,1,0,0,0,0,0,4,4,4,3,5,2,1
8,0,0,0,1,1,2,4,2,10,2,3,2,4,1,5,10,0,0,1,1,4,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,0,0,5,4,2,4,5,3,1
8,0,0,0,1,1,1,4,1,35,2,1,5,2,3,4,7,0,1,0,0,4,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,4,4,5,3,2,1,4
19,1,0,0,1,1,2,3,2,25,1,2,3,1,5,4,10,0,0,1,1,4,0,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,5,3,3,5,4,1,2
20,0,0,0,1,0,2,4,2,5,2,2,1,3,4,5,6,1,0,0,-1,4,0,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,3,3,4,5,3,2,1
8,0,1,0,1,1,2,4,3,16,2, , , , , ,9,0,0,1,1,4,0,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,5,4, , , , ,
16,0,1,0,0,1,1,4,3, ,1,1,2,3,4,5,10,0,0,1,1,3,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,5,3,5,4,3,2,1
8,0,1,0,1,0,2,4,4,30,2,2,4,1,3,5,6,1,0,0,-1,4,0,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,3,3,3,5,2,4,1
20,0,0,0,0,1, ,4,2,5,1,1,3,2,5,4,0,1,0,0,-1,3,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,4,3,5,3,4,1,2
19,0,0,0,1,1,1,4,2,0,2,1,5,4,3,2,8,0,1,0,0,5,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,4,4,5,1,2,3,4
8,0,0,0,1,1,2,4,1,20,2,2,4,5,3,1,8,0,1,0,0,5,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,4,2,1,5,2,4,3
8,0,0,0,0,1,2,4,2,20,2,1,2,5,3,4,5,1,0,0,-1,2,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4,4,5,4,2,1,3
20,1,0,1,0,1,2,2,2,8,5,1,5,4,2,3,7,0,1,0,0,3,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,4,2,5,2,1,3,4
13,0,0,0,0,1,2,4,2,6,2,2,1,4,3,5,7,0,1,0,0,3,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,4,2,4,5,2,3,1
8,0,0,0,0,1,2,4,2,11,0,1,4,5,2,3,10,0,0,1,1,3,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,5,4,5,2,1,4,3
19,1,1,0,0,1,1,3,3,0,2,1,5,4,3,2,7,0,1,0,0,2,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,4,3,5,1,2,3,4
13,0,0,0,1,1,2,4,2,20,2,1,3,2,5,4,10,0,0,1,1,4,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,4,4,5,3,4,1,2
13,0,0,0,0,0,2,4,2,10,0,1,4,2,3,5,8,0,1,0,0,2,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,3,3,5,3,2,4,1
13,0,0,0,0,0,2,4,2,1,2,1,4,2,3,5,5,1,0,0,-1,3,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,5,3,2,4,1
13,0,0,0,1,0,2,4,2,8,2,3,2,1,5,4,6,1,0,0,-1,4,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,3,3,3,4,5,1,2
13,0,0,0,1,0,2,4,2,30,2,2,3,1,4,5,5,1,0,0,-1,5,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,3,3,3,5,4,2,1
13,0,1,0,0,1,1,4,3,4,2,1,2,5,4,3,7,0,1,0,0,3,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,4,2,5,4,1,2,3
21,0,0,0,1,0,1,4,2, ,2,3,1,5,2,4,5,1,0,0,-1,5,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,3,3,4,2,5,1,3
13,0,1,0,0,1,1,4,4,4,1,1,2,4,5,3,10,0,0,1,1,3,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,5,4,5,4,1,3,2
13,1,0,1,1,1,2,3,2,10,3,4,1,2,3,5,9,0,0,1,1,5,0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,0,0,4,3,4,3,2,5,1
Appendix C License

Sustainable Venture Capital © 2022 by Samuel James Johnston <samj@samj.net>
Sustainable Venture Capital is licensed under a
Creative Commons Attribution-ShareAlike 4.0 International License.",2022-09-13 01:17:39+00:00,Sustainable Venture Capital,cs.CY,"['cs.CY', 'econ.GN', 'q-fin.EC', 'K.1; K.4.1; K.5.2']",[arxiv.Result.Author('Sam Johnston')],"Sustainability initiatives are set to benefit greatly from the growing
involvement of venture capital, in the same way that other technological
endeavours have been enabled and accelerated in the post-war period. With the
spoils increasingly being shared between shareholders and other stakeholders,
this requires a more nuanced view than the finance-first methodologies deployed
to date. Indeed, it is possible for a venture-backed sustainability startup to
deliver outstanding results to society in general without returning a cent to
investors, though the most promising outcomes deliver profit with purpose,
satisfying all stakeholders in ways that make existing 'extractive' venture
capital seem hollow.
  To explore this nascent area, a review of related research was conducted and
social entrepreneurs & investors interviewed to construct a questionnaire
assessing the interests and intentions of current & future ecosystem
participants. Analysis of 114 responses received via several sampling methods
revealed statistically significant relationships between investing preferences
and genders, generations, sophistication, and other variables, all the way down
to the level of individual UN Sustainable Development Goals (SDGs)."
11617,We leave these reﬁnements for further study.,"Conversely, people deleting contacts
from their contact list may not want the deleted contact to be actively notiﬁed
about this.","In this paper we study privacy friendly protocols for mutual contact discov-
ery.",2022-09-24 13:08:32+00:00,Mutual Contact Discovery,cs.CY,['cs.CY'],[arxiv.Result.Author('Jaap-Henk Hoepman')],"Messaging services allow new users to find existing contacts that already use
that service through a process called contact discovery. Existing users are
similarly informed of new users that are already on their contact list. This
creates a privacy issue: when you join and enable contact discovery, anyone
already on the service that has your number on their contact list gets notified
that you joined. Even if you don't know that person, or if it is an ex or
former colleague that you long parted with and whose contact details you
deleted long ago. To solve this, we propose a \emph{mutual} contact discovery
protocol, that only allow users to discover each other when both are (still) in
each other's contact list. Mutual contact discovery has the additional
advantage that it can be implemented in a more privacy friendly fashion (\eg
protecting the social graph from the server) than traditional, one-sided
contact discovery, without even relying on trusted hardware."
11618,We leave these reﬁnements for further study.,"Conversely, people deleting contacts
from their contact list may not want the deleted contact to be actively notiﬁed
about this.","In this paper we study privacy friendly protocols for mutual contact discov-
ery.",2022-09-24 13:08:32+00:00,Mutual Contact Discovery,cs.CY,['cs.CY'],[arxiv.Result.Author('Jaap-Henk Hoepman')],"Messaging services allow new users to find existing contacts that already use
that service through a process called contact discovery. Existing users are
similarly informed of new users that are already on their contact list. This
creates a privacy issue: when you join and enable contact discovery, anyone
already on the service that has your number on their contact list gets notified
that you joined. Even if you don't know that person, or if it is an ex or
former colleague that you long parted with and whose contact details you
deleted long ago. To solve this, we propose a \emph{mutual} contact discovery
protocol, that only allow users to discover each other when both are (still) in
each other's contact list. Mutual contact discovery has the additional
advantage that it can be implemented in a more privacy friendly fashion (e.g.
protecting the social graph from the server) than traditional, one-sided
contact discovery, without even relying on trusted hardware."
11644,"Indeed, TSMC
                                                                 relied that year on hundreds of water trucks to maintain its
   To further study the long-term sustainability of the Tai-     water supply while several restrictions where being taken at
wanese electronics industry, we now analyze the territorial      the national level [38].","If ECMs were already facing stress in the water-
B. Territorial Constraints of Taiwan for Electricity and         intensive production chain, this drought seriously ampliﬁed
Water Supply                                                     the crisis in this key sector of the island.","In this sense, Taiwanese ECMs share
constraints of Taiwan regarding renewable electricity gen-       a liability regarding water supply due to the increasing and
eration and water supply.",2022-09-26 08:59:45+00:00,From Silicon Shield to Carbon Lock-in ? The Environmental Footprint of Electronic Components Manufacturing in Taiwan (2015-2020),cs.CY,['cs.CY'],"[arxiv.Result.Author('Gauthier Roussilhe'), arxiv.Result.Author('Thibault Pirson'), arxiv.Result.Author('Mathieu Xhonneux'), arxiv.Result.Author('David Bol')]","Taiwan plans to rapidly increase its industrial production capacity of
electronic components while concurrently setting policies for its ecological
transition. Given that the island is responsible for the manufacturing of a
significant part of worldwide electronics components, the sustainability of the
Taiwanese electronics industry is therefore of critical interest. In this
paper, we survey the environmental footprint of 16 Taiwanese electronic
components manufacturers (ECM) using corporate sustainability responsibility
reports (CSR). Based on data from 2015 to 2020, this study finds out that our
sample of 16 manufacturers increased its greenhouse gases (GHG) emissions by
7.5\% per year, its final energy and electricity consumption by 8.8\% and
8.9\%, and the water usage by 6.1\%. We show that the volume of manufactured
electronic components and the environmental footprints compiled in this study
are strongly correlated, which suggests that relative efficiency gains are not
sufficient to curb the environmental footprint at the national scale. Given the
critical nature of electronics industry for Taiwan's geopolitics and economics,
the observed increase of energy consumption and the slow renewable energy
roll-out, these industrial activities could create a carbon lock-in, blocking
the Taiwanese government from achieving its carbon reduction goals and its
sustainability policies. Besides, the European Union, the USA or even China aim
at developing an industrial ecosystem targeting sub-10nm CMOS technology nodes
similar to Taiwan. This study thus provides important insights regarding the
environmental implications associated with such a technology roadmap. All data
and calculation models used in this study are provided as supplementary
material."
11684,"We conclude,
in Part V, with where further research could be most fruitful, given the possibilities raised.","Although public law is a reflection of the path-dependent structure
of political power within a society and not a perfect aggregation of human values, it is likely the
most authoritative encapsulation of the attitudes, norms and values of the governed.",II.,2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law is a computational engine that converts
opaque human values into legible and enforceable directives. Law Informs Code
is the research agenda attempting to capture that complex computational process
of human law, and embed it in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how the data generated by legal processes and the theoretical
constructs and practices of law (methods of law-making, statutory
interpretation, contract drafting, applications of standards, legal reasoning,
etc.) can facilitate the robust specification of inherently vague human goals
for AI. This helps with human-AI alignment and the local usefulness of AI.
Toward society-AI alignment, we present a framework for understanding law as
the applied philosophy of multi-agent alignment. Although law is partly a
reflection of historically contingent political power - and thus not a perfect
aggregation of citizen preferences - if properly parsed, its distillation
offers a legitimate computational comprehension of societal values."
11685,"We
conclude, in Part V, with drawbacks of our approach and with where further research could be
most fruitful.","Second, public law as data helps AI
parse what it should generally not do, providing an up-to-date distillation of democratically
deliberated means of reducing externalities and pursuing societal coordination (Part IV).","57 Or they should demonstrate correspondingly advanced legal comprehension and legal reasoning abilities of
specialized Legal Informatics AI systems that are directly available for guiding the knowledge and actions of the
primary AI.",2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda embedding legal knowledge and
reasoning in AI. Similar to how parties to a legal contract cannot foresee
every potential contingency of their future relationship, and legislators
cannot predict all the circumstances under which their proposed bills will be
applied, we cannot ex ante specify rules that provably direct good AI behavior.
Legal theory and practice have developed arrays of tools to address these
specification problems. For instance, legal standards allow humans to develop
shared understandings and adapt them to novel situations. In contrast to more
prosaic uses of the law (e.g., as a deterrent of bad behavior through the
threat of sanction), leveraged as an expression of how humans communicate their
goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
11686,"We conclude, in Part V, with
where further research could be most fruitful, given the possibilities raised.","Although public law is a reflection of the path-dependent structure of political power
within a society and not a perfect aggregation of human values, it is likely the most authoritative
encapsulation of the attitudes, norms and values of the governed.",II.,2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of standards, legal
reasoning, etc.) can facilitate the robust specification of inherently vague
human goals. This increases human-AI alignment and the local usefulness of AI.
Toward society-AI alignment, we present a framework for understanding law as
the applied philosophy of multi-agent alignment. Although law is partly a
reflection of historically contingent political power - and thus not a perfect
aggregation of citizen preferences - if properly parsed, its distillation
offers the most legitimate computational comprehension of societal values
available. If law eventually informs powerful AI, engaging in the deliberative
political process to improve law takes on even more meaning."
11687,"We conclude, in Part V, with
where further research could be most fruitful, given the possibilities raised.","Although public law is a reflection of the path-dependent structure of political power within a
society and not a perfect aggregation of human values, it is likely the most authoritative
encapsulation of the attitudes, norms and values of the governed.",II.,2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of standards, legal
reasoning, etc.) can facilitate the robust specification of inherently vague
human goals. This increases human-AI alignment and the local usefulness of AI.
Toward society-AI alignment, we present a framework for understanding law as
the applied philosophy of multi-agent alignment. Although law is partly a
reflection of historically contingent political power - and thus not a perfect
aggregation of citizen preferences - if properly parsed, its distillation
offers the most legitimate computational comprehension of societal values
available. If law eventually informs powerful AI, engaging in the deliberative
political process to improve law takes on even more meaning."
11688,"We conclude, in Part V, with
where further research could be most fruitful, given the possibilities raised.","Although public law is a reflection of the path-dependent structure of political power within a
society and not a perfect aggregation of human values, it is likely the most authoritative
encapsulation of the attitudes, norms and values of the governed.",II.,2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
11689,"We conclude, in Part V, with where further research
could be most fruitful, given the possibilities raised.","Although public
law is a reflection of the path-dependent structure of political power within a society and not a
perfect aggregation of human values, it is likely the most authoritative encapsulation of the
attitudes, norms and values of the governed.","56 See, e.g., Or Sharir, Barak Peleg & Yoav Shoham, The Cost of Training NLP Models: A Concise Overview (2020).",2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
11690,"We conclude, in Part V, with drawbacks of this approach and
with where further research could be most fruitful, given the possibilities raised.","Although public law is a
reflection of the path-dependent structure of political power within a society and not a perfect
aggregation of human values, it is the most authoritative democratic encapsulation of the attitudes,
norms and values of the governed.",II.,2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
11691,"We conclude, in Part V, with drawbacks of this approach and
with where further research could be most fruitful, given the possibilities raised.","Although public law is a
reflection of the path-dependent structure of political power within a society and not a perfect
aggregation of human values, it is the most authoritative democratic encapsulation of the attitudes,
norms and values of the governed.",II.,2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
11692,"We
conclude, in Part V, with drawbacks of our approach and with where further research could be
most fruitful.","Second, public law as data helps AI
parse what it should generally not do, providing an up-to-date distillation of democratically
deliberated means of reducing externalities and pursuing societal coordination (Part IV).","57 Or they should demonstrate correspondingly advanced legal comprehension and legal reasoning abilities of
specialized Legal Informatics AI systems that are directly available for guiding the knowledge and actions of the
primary AI.",2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
11693,"We
conclude, in Part V, with drawbacks of our approach and with where further research could be
most fruitful.","Second, public law as data helps AI
parse what it should generally not do, providing an up-to-date distillation of democratically
deliberated means of reducing externalities and pursuing societal coordination (Part IV).","57 Or they should demonstrate correspondingly advanced legal comprehension and legal reasoning abilities of
specialized Legal Informatics AI systems that are directly available for guiding the knowledge and actions of the
primary AI.",2022-09-14 00:49:09+00:00,Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('John J. Nay')],"We are currently unable to specify human goals and societal values in a way
that reliably directs AI behavior. Law-making and legal interpretation form a
computational engine that converts opaque human values into legible directives.
""Law Informs Code"" is the research agenda capturing complex computational legal
processes, and embedding them in AI. Similar to how parties to a legal contract
cannot foresee every potential contingency of their future relationship, and
legislators cannot predict all the circumstances under which their proposed
bills will be applied, we cannot ex ante specify rules that provably direct
good AI behavior. Legal theory and practice have developed arrays of tools to
address these specification problems. For instance, legal standards allow
humans to develop shared understandings and adapt them to novel situations. In
contrast to more prosaic uses of the law (e.g., as a deterrent of bad behavior
through the threat of sanction), leveraged as an expression of how humans
communicate their goals, and what society values, Law Informs Code.
  We describe how data generated by legal processes (methods of law-making,
statutory interpretation, contract drafting, applications of legal standards,
legal reasoning, etc.) can facilitate the robust specification of inherently
vague human goals. This increases human-AI alignment and the local usefulness
of AI. Toward society-AI alignment, we present a framework for understanding
law as the applied philosophy of multi-agent alignment. Although law is partly
a reflection of historically contingent political power - and thus not a
perfect aggregation of citizen preferences - if properly parsed, its
distillation offers the most legitimate computational comprehension of societal
values available. If law eventually informs powerful AI, engaging in the
deliberative political process to improve law takes on even more meaning."
12148,"On the way to SAE Level 4 driverless operation On-Road Automated Driving (ORAD)
Committee (2021), repeated accidents of autonomous vehicles show that further research is needed
to increase the safety, reliability and robustness of the automated driving systems Daily et al.","In the last ten years, many projects from industrial and academic organisms have further advanced the
state of the art.",(2017).,2022-10-08 14:49:35+00:00,Reliability of fault-tolerant system architectures for automated driving systems,cs.CY,['cs.CY'],"[arxiv.Result.Author('Tim Maurice Julitz'), arxiv.Result.Author('Antoine Tordeux'), arxiv.Result.Author('Manuel Löwer')]","Automated driving functions at high levels of autonomy operate without driver
supervision. The system itself must provide suitable responses in case of
hardware element failures. This requires fault-tolerant approaches using domain
ECUs and multicore processors operating in lockstep mode. The selection of a
suitable architecture for fault-tolerant vehicle systems is currently
challenging. Lockstep CPUs enable the implementation of majority redundancy or
M-out-of-N ($M$oo$N$) architectures. In addition to structural redundancy,
diversity redundancy in the ECU architecture is also relevant to fault
tolerance. Two fault-tolerant ECU architecture groups exist: architectures with
one ECU (system on a chip) and architectures consisting of multiple
communicating ECUs. The single-ECU systems achieve higher reliability, whereas
the multi-ECU systems are more robust against dependent failures, such as
common-cause or cascading failures, due to their increased potential for
diversity redundancy. Yet, it remains not fully understood how different types
of architectures influence the system reliability. The work aims to design
architectures with respect to CPU and sensor number, $M$oo$N$ expression, and
hardware element reliability. The results enable a direct comparison of
different architecture types. We calculate their reliability and quantify the
effort to achieve high safety requirements. Markov processes allow comparing
sensor and CPU architectures by varying the number of components and failure
rates. The objective is to evaluate systems' survival probability and fault
tolerance and design suitable sensor-CPU architectures. The results show that
the system architecture strongly influences the reliability. However, a
suitable system architecture must have a trade-off between reliability and
self-diagnostics that parallel systems without majority redundancies do not
provide."
12576,"Also, [9] has
investigated the relationship between the factors and mentioned for further study to
explore the effects of the ease of use on the intention to use social commerce.","While our study will fill this gap of different age range
with different education level not limited to university students.","[10]
examined only two factors from the TAM model and in the Dhofar region where our
research will examine more factors and in the different governorate.",2022-09-22 19:44:55+00:00,Determinants Influencing Intention to Use Social Commerce for Shopping in developing countries: A Case Study of Oman,cs.CY,['cs.CY'],"[arxiv.Result.Author('Shamma Al Harizi'), arxiv.Result.Author('Maryam Al Areimi'), arxiv.Result.Author('Abdul. Khalique Shaikh')]","Social media has had a significant impact on our individual lives, including
our behavior regarding the purchasing of daily products. This study
investigates the factors influencing Omani nationals' intentions to obtain
products via social commerce. The researcher surveyed 202 participants and
utilized the Technology Acceptance Model to develop the theoretical framework.
The data collection was analyzed statistically using an appropriate testing
mechanism. Statistical methods, including Cronbach's alpha and multiple linear
regression, were utilized for reliability and hypotheses testing. After
analyzing the collected data and testing the hypotheses, the findings indicated
that perceived usefulness, enjoyment, and ease of use of social commerce affect
positively on Omani nationals' intentions to utilize social commerce for
shopping. The independent variables had a statistically significant impact on
the intention to use social commerce shopping for products; these explain 69.9%
of the variation on customers intention to utilize social commerce for
shopping."
12577,"The findings suggest the need for further research in which these
variables can be explored and tested in different settings.","While this study is expected for further discussion in which can be tested and developed
in different settings.","In the practical aspect, the
implications provide several recommendations for businesses and sellers.",2022-09-22 19:44:55+00:00,Determinants Influencing Intention to Use Social Commerce for Shopping in developing countries: A Case Study of Oman,cs.CY,['cs.CY'],"[arxiv.Result.Author('Shamma Al Harizi'), arxiv.Result.Author('Maryam Al Areimi'), arxiv.Result.Author('Abdul. Khalique Shaikh')]","Social media has had a significant impact on our individual lives, including
our behavior regarding the purchasing of daily products. This study
investigates the factors influencing Omani nationals' intentions to obtain
products via social commerce. The researcher surveyed 202 participants and
utilized the Technology Acceptance Model to develop the theoretical framework.
The data collection was analyzed statistically using an appropriate testing
mechanism. Statistical methods, including Cronbach's alpha and multiple linear
regression, were utilized for reliability and hypotheses testing. After
analyzing the collected data and testing the hypotheses, the findings indicated
that perceived usefulness, enjoyment, and ease of use of social commerce affect
positively on Omani nationals' intentions to utilize social commerce for
shopping. The independent variables had a statistically significant impact on
the intention to use social commerce shopping for products; these explain 69.9%
of the variation on customers intention to utilize social commerce for
shopping."
12578,"Second, further study is
needed to examine the relations between perceived ease of use, usefulness, enjoyment,
and intentions to use social commerce for shopping.","Expanding the research to other
areas of Oman would add considerably to understanding consumer intentions when
utilizing social commerce for shopping to buy or sell products.","Third, an additional examination is
required to investigate other factors (e.g., perceived value and perceived risks) that
impact goods purchasing via social commerce.",2022-09-22 19:44:55+00:00,Determinants Influencing Intention to Use Social Commerce for Shopping in developing countries: A Case Study of Oman,cs.CY,['cs.CY'],"[arxiv.Result.Author('Shamma Al Harizi'), arxiv.Result.Author('Maryam Al Areimi'), arxiv.Result.Author('Abdul. Khalique Shaikh')]","Social media has had a significant impact on our individual lives, including
our behavior regarding the purchasing of daily products. This study
investigates the factors influencing Omani nationals' intentions to obtain
products via social commerce. The researcher surveyed 202 participants and
utilized the Technology Acceptance Model to develop the theoretical framework.
The data collection was analyzed statistically using an appropriate testing
mechanism. Statistical methods, including Cronbach's alpha and multiple linear
regression, were utilized for reliability and hypotheses testing. After
analyzing the collected data and testing the hypotheses, the findings indicated
that perceived usefulness, enjoyment, and ease of use of social commerce affect
positively on Omani nationals' intentions to utilize social commerce for
shopping. The independent variables had a statistically significant impact on
the intention to use social commerce shopping for products; these explain 69.9%
of the variation on customers intention to utilize social commerce for
shopping."
12579,Sustainable supply chain management: framework and further research directions.,"Dubey, Rameshwar, Gunasekaran, A., Papadopoulos, T., Childe, S. J., Shibin, K. T., & Wamba, S. F.
      (2017).","Journal
      of Cleaner Production, 142, 1119–1130.",2022-09-21 06:52:39+00:00,Artificial Intelligence and Innovation to Reduce the Impact of Extreme Weather Events on Sustainable Production,cs.CY,"['cs.CY', 'cs.AI']","[arxiv.Result.Author('Derrick Effah'), arxiv.Result.Author('Chunguang Bai'), arxiv.Result.Author('Matthew Quayson')]","Frequent occurrences of extreme weather events substantially impact the lives
of the less privileged in our societies, particularly in agriculture-inclined
economies. The unpredictability of extreme fires, floods, drought, cyclones,
and others endangers sustainable production and life on land (SDG goal 15),
which translates into food insecurity and poorer populations. Fortunately,
modern technologies such as Artificial Intelligent (AI), the Internet of Things
(IoT), blockchain, 3D printing, and virtual and augmented reality (VR and AR)
are promising to reduce the risk and impact of extreme weather in our
societies. However, research directions on how these technologies could help
reduce the impact of extreme weather are unclear. This makes it challenging to
emploring digital technologies within the spheres of extreme weather. In this
paper, we employed the Delphi Best Worst method and Machine learning approaches
to identify and assess the push factors of technology. The BWM evaluation
revealed that predictive nature was AI's most important criterion and role,
while the mass-market potential was the less important criterion. Based on this
outcome, we tested the predictive ability of machine elarning on a publilcly
available dataset to affrm the predictive rols of AI. We presented the
managerial and methodological implications of the study, which are crucial for
research and practice. The methodology utilized in this study could aid
decision-makers in devising strategies and interventions to safeguard
sustainable production. This will also facilitate allocating scarce resources
and investment in improving AI techniques to reduce the adverse impacts of
extreme events. Correspondingly, we put forward the limitations of this, which
necessitate future research."
12580,"To overcome       Vienna, Austria, 3San Raffaele Roma Open University, Rome, Italy,
                                        this and allow research participants to agree to participate    4IRCCS San Raffaele Roma, San Raffaele Roma Open University,
                                        in further research projects, a dynamic consent approach has    5University of Rome Tor Vergata, Rome, Italy
                                        been broadly discussed in the scientiﬁc community.","Hence, these data
                                        cannot be easily shared and gathered in larger datasets, which         1Guglielmo Marconi University, Rome, Italy, 2University of Vienna,
                                        may make the difference for machine learning.","7,14,20,25
                                                                                                        Corresponding author:
                                           In this paper, we present the Active Informed Consent        Fabio Massimo Zanzotto, University of Rome Tor Vergata, Viale del
                                        (AIC) as a novel hybrid legal-technological tool to foster the  Politecnico, 1, 00133, Rome, Italy.",2022-09-27 10:24:08+00:00,Active Informed Consent to Boost the Application of Machine Learning in Medicine,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG', 'J.3']","[arxiv.Result.Author('Marco Gerardi'), arxiv.Result.Author('Katarzyna Barud'), arxiv.Result.Author('Marie-Catherine Wagner'), arxiv.Result.Author('Nikolaus Forgo'), arxiv.Result.Author('Francesca Fallucchi'), arxiv.Result.Author('Noemi Scarpato'), arxiv.Result.Author('Fiorella Guadagni'), arxiv.Result.Author('Fabio Massimo Zanzotto')]","Machine Learning may push research in precision medicine to unprecedented
heights. To succeed, machine learning needs a large amount of data, often
including personal data. Therefore, machine learning applied to precision
medicine is on a cliff edge: if it does not learn to fly, it will deeply fall
down. In this paper, we present Active Informed Consent (AIC) as a novel hybrid
legal-technological tool to foster the gathering of a large amount of data for
machine learning. We carefully analyzed the compliance of this technological
tool to the legal intricacies protecting the privacy of European Citizens."
12583,"Despite this, we support a reflexive turn in data science and recommend
much needed further research in this direction.","There
remain a great deal of practical challenges with attaining the intended virtues of reflexivity
in organisational spaces fraught with multiple, conflicting logics such as universities
[author date].","At the very least, a reflexive and
transparent approach seeks to avoid shifting the blame to the data and external sources,
acknowledge partiality (as opposed to deceptive efforts to debias) and the distribution of
collective responsibility within the actors and institutions involved in constructing and
deploying a model.",2022-10-05 17:34:51+00:00,Addressing contingency in algorithmic misinformation detection: Toward a responsible innovation agenda,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG', 'cs.SI']","[arxiv.Result.Author('Andrés Domínguez Hernández'), arxiv.Result.Author('Richard Owen'), arxiv.Result.Author('Dan Saattrup Nielsen'), arxiv.Result.Author('Ryan McConville')]","Machine learning (ML) enabled classification models are becoming increasingly
popular for tackling the sheer volume and speed of online misinformation. In
building these models, data scientists need to take a stance on the legitimacy,
authoritativeness and objectivity of the sources of `truth' used for model
training and testing. This has political, ethical and epistemic implications
which are rarely addressed in technical papers. Despite (and due to) their
reported high performance, ML-driven moderation systems have the potential to
shape online public debate and create downstream negative impacts such as undue
censorship and reinforcing false beliefs. This article reports on a responsible
innovation (RI) inflected collaboration at the intersection of social studies
of science and data science. We identify a series of algorithmic
contingencies--key moments during model development which could lead to
different future outcomes, uncertainty and harmful effects. We conclude by
offering an agenda of reflexivity and responsible development of ML tools for
combating misinformation."
12591,"The authors have provided succinct definitions
based on their experience with the subject and present them here     System and/or Model Errors and Failures
as the basis for further research and discussion.",ambiguous.,"In machine learning (ML), model errors are one of the main
                                                                     impediments to improved accuracy and reliability as errors can
                          II.",2022-10-14 16:54:20+00:00,Artificial Intelligence Nomenclature Identified From Delphi Study on Key Issues Related to Trust and Barriers to Adoption for Autonomous Systems,cs.CY,"['cs.CY', 'cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Thomas E. Doyle'), arxiv.Result.Author('Victoria Tucci'), arxiv.Result.Author('Calvin Zhu'), arxiv.Result.Author('Yifei Zhang'), arxiv.Result.Author('Basem Yassa'), arxiv.Result.Author('Sajjad Rashidiani'), arxiv.Result.Author('Md Asif Khan'), arxiv.Result.Author('Reza Samavi'), arxiv.Result.Author('Michael Noseworthy'), arxiv.Result.Author('Steven Yule')]","The rapid integration of artificial intelligence across traditional research
domains has generated an amalgamation of nomenclature. As cross-discipline
teams work together on complex machine learning challenges, finding a consensus
of basic definitions in the literature is a more fundamental problem. As a step
in the Delphi process to define issues with trust and barriers to the adoption
of autonomous systems, our study first collected and ranked the top concerns
from a panel of international experts from the fields of engineering, computer
science, medicine, aerospace, and defence, with experience working with
artificial intelligence. This document presents a summary of the literature
definitions for nomenclature derived from expert feedback."
12683,"This motivates further research, for instance,
exploring whether there may be subcomponents of experience–such as feelings
of guilt, regret, and remorse–that contribute to moral reasoning in ways similar
to perceived agency.","But at the same time, this effect could
simply reflect the fact that all of the scenarios presented involved machines
and humans performing actions.",But what do these results mean for AI researchers?,2022-10-18 18:20:42+00:00,Why do people judge humans differently from machines? The role of agency and experience,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']","[arxiv.Result.Author('Jingling Zhang'), arxiv.Result.Author('Jane Conway'), arxiv.Result.Author('César A. Hidalgo')]","People are known to judge artificial intelligence using a utilitarian moral
philosophy and humans using a moral philosophy emphasizing perceived
intentions. But why do people judge humans and machines differently? Psychology
suggests that people may have different mind perception models for humans and
machines, and thus, will treat human-like robots more similarly to the way they
treat humans. Here we present a randomized experiment where we manipulated
people's perception of machines to explore whether people judge more human-like
machines more similarly to the way they judge humans. We find that people's
judgments of machines become more similar to that of humans when they perceive
machines as having more agency (e.g. ability to plan, act), but not more
experience (e.g. ability to feel). Our findings indicate that people's use of
different moral philosophies to judge humans and machines can be explained by a
progression of mind perception models where the perception of agency plays a
prominent role. These findings add to the body of evidence suggesting that
people's judgment of machines becomes more similar to that of humans motivating
further work on differences in the judgment of human and machine actions."
12684,"We hope
these findings help stimulate further research on the moral philosophy of humans
judging machines.","This has significant implications for the design
of machines, as it indicates that modifying a person’s perception of a machine’s
agency can affect how that person judges the machine’s mistakes.","11
Figure 1: A. Schematic Illustration of mind perception models of humans and
machines.",2022-10-18 18:20:42+00:00,Why do people judge humans differently from machines? The role of agency and experience,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']","[arxiv.Result.Author('Jingling Zhang'), arxiv.Result.Author('Jane Conway'), arxiv.Result.Author('César A. Hidalgo')]","People are known to judge artificial intelligence using a utilitarian moral
philosophy and humans using a moral philosophy emphasizing perceived
intentions. But why do people judge humans and machines differently? Psychology
suggests that people may have different mind perception models for humans and
machines, and thus, will treat human-like robots more similarly to the way they
treat humans. Here we present a randomized experiment where we manipulated
people's perception of machines to explore whether people judge more human-like
machines more similarly to the way they judge humans. We find that people's
judgments of machines become more similar to that of humans when they perceive
machines as having more agency (e.g. ability to plan, act), but not more
experience (e.g. ability to feel). Our findings indicate that people's use of
different moral philosophies to judge humans and machines can be explained by a
progression of mind perception models where the perception of agency plays a
prominent role. These findings add to the body of evidence suggesting that
people's judgment of machines becomes more similar to that of humans motivating
further work on differences in the judgment of human and machine actions."
12780,"For further research in this study, we recommend studying the
teacher professional development (TPD) based on ICT skills, evaluate teachers' technological
pedagogical and content knowledge (TPACK).","Thus, the teachers
can be able to use the ICT technology anywhere and anytime for their students' benefit in the
presence of all the aids of practice.","References

Alazam, A.-O., Bakar, A. R., Hamzah, R., & Asmiran, S. (2012).",2022-10-14 10:31:05+00:00,A Study of Teacher Educators Skill and ICT Integration in Online Teaching during the Pandemic Situation in India,cs.CY,['cs.CY'],"[arxiv.Result.Author('Subaveerapandiyan A'), arxiv.Result.Author('R Nandhakumar')]","Information and communication technology prompted the sharing of information
over the world. For its impact on education the government and the authorities
like the University Grants Commission in India have energized the higher
education institutions in India to implement online education during the
pandemic situation. This paper attempts to know the teaching faculties ICT
skills and related online class skills in higher educational institutions in
India. In India like developing countries quick as the lightning change in
traditional to fully online classes are like a rumble of thunder because
faculties are adopting this situation but students are challenging to adopt."
12821,These claims have since been debunked through further research and empirical data [3].,"With some early reports suggesting that all computers could consume up to 50% of U.S. electricity
in 2010 [2].","This pattern of
inaccurate or misleading predictions and measurements regarding the energy consumption of a fast-growing information
technology is considered problematic as it may inﬂuence policymakers [4] and may feed misinformation to the general
public when picked up by popular media.",2022-10-21 01:24:19+00:00,Promoting Rigour in Blockchains Energy & Environmental Footprint Research: A Systematic Literature Review,cs.CY,"['cs.CY', 'cs.DC']","[arxiv.Result.Author('Ashish Rajendra Sai'), arxiv.Result.Author('Harald Vranken')]","There is a growing interest in understanding the energy and environmental
footprint of digital currencies, specifically in cryptocurrencies such as
Bitcoin and Ethereum. These cryptocurrencies are operated by a geographically
distributed network of computing nodes, making it hard to accurately estimate
their energy consumption.
  Existing studies, both in academia and industry, attempt to model the
cryptocurrencies energy consumption often based on a number of assumptions for
instance about the hardware in use or geographic distribution of the computing
nodes. A number of these studies has already been widely criticized for their
design choices and subsequent over or under-estimation of the energy use.
  In this study, we evaluate the reliability of prior models and estimates by
leveraging existing scientific literature from fields cognizant of blockchain
such as social energy sciences and information systems. We first design a
quality assessment framework based on existing research, we then conduct a
systematic literature review examining scientific and non-academic literature
demonstrating common issues and potential avenues of addressing these issues.
  Our goal with this article is to to advance the field by promoting scientific
rigor in studies focusing on Blockchain's energy footprint. To that end, we
provide a novel set of codes of conduct for the five most widely used research
methodologies: quantitative energy modeling, literature reviews, data analysis
\& statistics, case studies, and experiments. We envision that these codes of
conduct would assist in standardizing the design and assessment of studies
focusing on blockchain-based systems' energy and environmental footprint."
13226,"However, those
discrepancies between pediatric and adult patients also indicate an area of potential opportunity
of expansion and further study.","The wide variation in size and metabolic function
makes it challenging to code simulation models, with additional attributes that must be tracked
and programmed to account for the difference in patient populations.","Of the nine pediatric HCSO simulations, four were focused on emergency department
operational changes.",2022-10-20 15:23:20+00:00,Discrete-Event Simulation in Healthcare Settings: a Review,cs.CY,"['cs.CY', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('John J. Forbus'), arxiv.Result.Author('Daniel Berleant')]","We review and define the current state of the art as relating to discrete
event simulation in healthcare-related systems. A review of published
literature over the past five years (2017 - 2021) was conducted, building upon
previously published work. PubMed and EBSCOhost were searched for journal
articles on discrete event simulation in healthcare resulting in identification
of 933 unique articles. Of these about half were excluded at the title/abstract
level and 154 at the full text level, leaving 311 papers to analyze. These were
categorized, then analyzed by category and collectively to identify publication
volume over time, disease focus, activity levels by coun-try, software systems
used, and sizes of healthcare unit under study. A total of 1196 articles were
initially identified. This list was narrowed down to 311 for systematic review.
Following the schema from prior systematic reviews, the articles fell into four
broad categories: health care sys-tems operations (HCSO), disease progression
modeling (DPM), screening modeling (SM), and health behavior modeling (HBM). We
found that discrete event simulation in healthcare has con-tinued to increase
year-over-year, as well as expand into diverse areas of the healthcare system.
In addition, this study adds extra bibliometric dimensions to gain more insight
into the details and nuances of how and where simulation is being used in
healthcare."
13227,The following recommendations are for further study.,"Frequent Upgrade of the application is required in other to ensure security against
         latest web application vulnerabilities since new threats surface daily.",i.,2022-10-25 16:46:34+00:00,Secure Web-Based Student Information Management System,cs.CY,"['cs.CY', 'cs.CR', 'cs.IR']",[arxiv.Result.Author('Oluwatosin Samuel Falebita')],"The reliability and success of any organization such as academic institution
rely on its ability to provide secure, accurate and timely data about its
operations. Erstwhile managing student information in academic institution was
done through paper-based information system, where academic records are
documented in several files that are kept in shelves. Several problems are
associated with paper-based information system. Managing information through
the manual approach require physical exertion to retrieve, alter, and re-file
the paper records. These are nonvalue added services results in data
inconsistency and redundancy, currently institutions have migrated to web-based
student information management system without considering the security
architecture of the web portal. This project seeks to ameliorates and secure
how information is being managed in Nigeria Police Academy through the
development of a secured web-based student information management system, which
has a friendly user interface that provides an easy and secure way to manage
academic information such as students information, staff information, course
registration, course materials and results. This project was developed using
Laravel 5.5 PHP Framework to provide a robust secure web-based student
information system that is not vulnerable to 2018 OWASP TOP 10 web
vulnerabilities."
13228,"As the pandemic forced and fostered
the use of ICT for educational and labor purposes, further research is needed to
analyze these effects.","These variables are, for
instance, ICT use, skills, and appropriation.","Finally, studies should be carried out on the effect that
public policies implemented by CFE Telecomunicaciones e Internet para Todos
can have on disadvantaged areas in the coming years.",2022-10-28 14:12:14+00:00,Digital divide among the States of Mexico: a comparison 2010-2020,cs.CY,"['cs.CY', 'J.4']","[arxiv.Result.Author('Sergio R. Coria'), arxiv.Result.Author('Luz M. Garcia-Garcia')]","Digital divide is one of the challenges that open government must face in
mid- and low-income countries. In these contexts, inhabitants are left out of
the benefits of information and communication technology (ICT), such as online
government services. The present scenario that has emerged from the COVID-19
pandemic offers opportunities and challenges in ICT access and use to current
and potential users all over the world. Therefore, it is important to know the
advancement in digital inclusion in the recent years, particularly regarding
the consumption and use of ICT goods and services. Thus, this article analyzes
the Mexican case by comparing the availability of ICT in households of the
states between the years 2010 and 2020. Open data from the Mexican Censuses of
these two years are used to produce these analyses. The results suggest that
inequalities prevail between South and Southeast states compared to Center and
North states, and that cell telephone availability has increased, fostering
Internet access."
13602,"From the responses, the developed     benchmark ideas to the conduct of further research projects.","Key   extended thru publication, online open access journals, and
features that aids in the ease of use, access to, and management of  online libraries serves as important references and
the research resource emerged.","application evidently suggests its usability and compliance to       As instruction is always based from outputs or generated
standards from the participants.",2022-11-06 13:24:48+00:00,Development and Evaluation of the Institutionally Farmed Research On-line Repository and Management System (InFORMs) towards Knowledge-Sharing and Utilization,cs.CY,"['cs.CY', 'cs.DB', 'cs.IR', '68P20', 'H.4.3; H.3.5; J.1']","[arxiv.Result.Author('Billy S. Javier'), arxiv.Result.Author('Leo P. Paliuanan'), arxiv.Result.Author('Corazon T. Talamayan'), arxiv.Result.Author('James Karl A. Agpalza'), arxiv.Result.Author('Jesty S. Agoto')]","This paper presents the usability, acceptability and extent of compliance to
ISO 25010:2011 of the developed project InFORMS. Key features that aid in the
ease of use, access to, and management of the research resource emerged. From
the responses, the developed application evidently suggests its usability and
compliance to standards from the participants. The application was limited to
showcasing all research resources produced in the University, in the last 10
years, after having gone through approval of the research review committee
prior inclusion in the database. Maximizing the web application for
knowledge-sharing and utilization is commended, advancing instruction and
knowledge economy."
13649,"In addition, the published dataset that was used in this
research may serve as a tool to be expanded and used for further research and discussion.","Moreover, the designed system represents a major step for Sharia in coping
with digital financial development and advanced models based on Artificial Intelligence
(AI) and Machine Learning.","This research will contribute by:
1.",2022-11-04 17:34:09+00:00,CryptoHalal: An Intelligent Decision-System for Identifying Halal and Haram Cryptocurrencies,cs.CY,"['cs.CY', 'cs.HC']",[arxiv.Result.Author('Shahad Al-Khalifa')],"In this research, we discussed a rising issue for Muslims in today world that
involves a financial and technical innovation, namely: cryptocurrencies. We
found out through a questionnaire that many Muslims are having a hard time
finding the jurisprudence rulings on certain cryptocurrencies. Therefore, the
objective of this research is to investigate and identify features that play a
part in determining the jurisprudence rulings on cryptocurrencies. We have
collected a dataset containing 106 cryptocurrencies classified into 56 Halal
and 50 Haram cryptocurrencies, and used 20 handcrafted features. Moreover,
based on these identified features, we designed an intelligent system that
contains a Machine Learning model for classifying cryptocurrencies into Halal
and Haram."
13650,"The last view states that the matter of cryptocurrency is still not
transparent to Islamic scholars and needs further study and investigation.","The second
view states that cryptocurrencies are speculative, similar to gambling, and thus are
forbidden in Islam.","Next, we will
present the views of the proponent, opponent, and neutral sources.",2022-11-04 17:34:09+00:00,CryptoHalal: An Intelligent Decision-System for Identifying Halal and Haram Cryptocurrencies,cs.CY,"['cs.CY', 'cs.HC']",[arxiv.Result.Author('Shahad Al-Khalifa')],"In this research, we discussed a rising issue for Muslims in today world that
involves a financial and technical innovation, namely: cryptocurrencies. We
found out through a questionnaire that many Muslims are having a hard time
finding the jurisprudence rulings on certain cryptocurrencies. Therefore, the
objective of this research is to investigate and identify features that play a
part in determining the jurisprudence rulings on cryptocurrencies. We have
collected a dataset containing 106 cryptocurrencies classified into 56 Halal
and 50 Haram cryptocurrencies, and used 20 handcrafted features. Moreover,
based on these identified features, we designed an intelligent system that
contains a Machine Learning model for classifying cryptocurrencies into Halal
and Haram."
13651,"The findings of this study indicate that there is no conclusive answer to the ruling
on cryptocurrency in Sharia, therefore the matter is suspended for further research in all
its aspects.","Moreover, Abdeldayem et al., (2020) conducted research to investigate
cryptocurrency in Islamic finance, particularly in the Gulf Cooperation Council (GCC),
and addressed important questions about the Islamic finance view on cryptocurrency and
whether cryptocurrency can be considered legal money and a medium of exchange in
Sharia.","Furthermore, the authors concluded that cryptocurrencies should be subject to
financial and Sharia compliance and oversight so that Muslims worldwide can adopt
them, especially in the Gulf countries.",2022-11-04 17:34:09+00:00,CryptoHalal: An Intelligent Decision-System for Identifying Halal and Haram Cryptocurrencies,cs.CY,"['cs.CY', 'cs.HC']",[arxiv.Result.Author('Shahad Al-Khalifa')],"In this research, we discussed a rising issue for Muslims in today world that
involves a financial and technical innovation, namely: cryptocurrencies. We
found out through a questionnaire that many Muslims are having a hard time
finding the jurisprudence rulings on certain cryptocurrencies. Therefore, the
objective of this research is to investigate and identify features that play a
part in determining the jurisprudence rulings on cryptocurrencies. We have
collected a dataset containing 106 cryptocurrencies classified into 56 Halal
and 50 Haram cryptocurrencies, and used 20 handcrafted features. Moreover,
based on these identified features, we designed an intelligent system that
contains a Machine Learning model for classifying cryptocurrencies into Halal
and Haram."
13652,(2021)     scientific literature on                          suspended for further research.,"scams
                                                           • The results indicate no conclusive answer to the
Bartoletti et  Perform an extensive review of                    ruling on cryptocurrency, and the matter is
al.","cryptocurrency scams
                                                           • Cryptocurrencies should be subject to financial
                                                                 and Sharia compliance so that Muslims around the
                                                                 world can adopt them.",2022-11-04 17:34:09+00:00,CryptoHalal: An Intelligent Decision-System for Identifying Halal and Haram Cryptocurrencies,cs.CY,"['cs.CY', 'cs.HC']",[arxiv.Result.Author('Shahad Al-Khalifa')],"In this research, we discussed a rising issue for Muslims in today world that
involves a financial and technical innovation, namely: cryptocurrencies. We
found out through a questionnaire that many Muslims are having a hard time
finding the jurisprudence rulings on certain cryptocurrencies. Therefore, the
objective of this research is to investigate and identify features that play a
part in determining the jurisprudence rulings on cryptocurrencies. We have
collected a dataset containing 106 cryptocurrencies classified into 56 Halal
and 50 Haram cryptocurrencies, and used 20 handcrafted features. Moreover,
based on these identified features, we designed an intelligent system that
contains a Machine Learning model for classifying cryptocurrencies into Halal
and Haram."
13742,"In addition, we asked our participants in case they want to learn
about security which can help us to plan further research.","To further understand the participants’ reaction about these security threats, we included an option to
report the security issues that they may notice.","This study is approved by the Human Research Ethics
Committee at the University of Adelaide (H-2021-106).",2022-11-14 18:10:34+00:00,An Empirical Study on Secure Usage of Mobile Health Apps: The Attack Simulation Approach,cs.CY,"['cs.CY', 'cs.SE']","[arxiv.Result.Author('Bakheet Aljedaani'), arxiv.Result.Author('Aakash Ahmad'), arxiv.Result.Author('Mansooreh Zahedi'), arxiv.Result.Author('M. Ali Babar')]","Mobile applications, mobile apps for short, have proven their usefulness in
enhancing service provisioning across a multitude of domains that range from
smart healthcare, to mobile commerce, and areas of context sensitive computing.
In recent years, a number of empirically grounded, survey-based studies have
been conducted to investigate secure development and usage of mHealth apps.
However, such studies rely on self reported behaviors documented via interviews
or survey questions that lack a practical, i.e. action based approach to
monitor and synthesise users actions and behaviors in security critical
scenarios. We conducted an empirical study, engaging participants with attack
simulation scenarios and analyse their actions, for investigating the security
awareness of mHealth app users via action-based research. We simulated some
common security attack scenarios in mHealth context and engaged a total of 105
app users to monitor their actions and analyse their behavior. We analysed
users data with statistical analysis including reliability and correlations
tests, descriptive analysis, and qualitative data analysis. Our results
indicate that whilst the minority of our participants perceived access
permissions positively, the majority had negative views by indicating that such
an app could violate or cost them to lose privacy. Users provide their consent,
granting permissions, without a careful review of privacy policies that leads
to undesired or malicious access to health critical data. The results also
indicated that 73.3% of our participants had denied at least one access
permission, and 36% of our participants preferred no authentication method. The
study complements existing research on secure usage of mHealth apps, simulates
security threats to monitor users actions, and provides empirically grounded
guidelines for secure development and usage of mobile health systems."
13747,"It is, however, used as a secondary informa-
tion resource, which individuals use to further research and contribute towards topics they have
encountered through other news media.",Wikipedia is of course not a news website.,"13% of readers visit the site directly because of current
events, and a further 30% visit due to wider media coverage1)[12].",2022-11-14 18:36:21+00:00,Between News and History: Identifying Networked Topics of Collective Attention on Wikipedia,cs.CY,"['cs.CY', 'cs.SI', 'physics.soc-ph']","[arxiv.Result.Author('Patrick Gildersleve'), arxiv.Result.Author('Renaud Lambiotte'), arxiv.Result.Author('Taha Yasseri')]","The digital information landscape has introduced a new dimension to
understanding how we collectively react to new information and preserve it at
the societal level. This, together with the emergence of platforms such as
Wikipedia, has challenged traditional views on the relationship between current
events and historical accounts of events, with an ever-shrinking divide between
""news"" and ""history"". Wikipedia's place as the Internet's primary reference
work thus poses the question of how it represents both traditional
encyclopaedic knowledge and evolving important news stories. In other words,
how is information on and attention towards current events integrated into the
existing topical structures of Wikipedia? To address this we develop a temporal
community detection approach towards topic detection that takes into account
both short term dynamics of attention as well as long term article network
structures. We apply this method to a dataset of one year of current events on
Wikipedia to identify clusters distinct from those that would be found solely
from page view time series correlations or static network structure. We are
able to resolve the topics that more strongly reflect unfolding current events
vs more established knowledge by the relative importance of collective
attention dynamics vs link structures. We also offer important developments by
identifying and describing the emergent topics on Wikipedia. This work provides
a means of distinguishing how these information and attention clusters are
related to Wikipedia's twin faces of encyclopaedic knowledge and current events
-- crucial to understanding the production and consumption of knowledge in the
digital age."
14014,"V discusses the grand challenges for IoT that remain open
                                                                    for further research and deemed to decelerate its wide scale
   Although IoT promises to support intelligence decision           adoption.","Section
that lead into smart decisions (IoT actuation).","Lastly, Section VI offers concluding remarks.",2022-11-14 16:43:02+00:00,"Revisiting the Internet of Things: New Trends, Opportunities and Grand Challenges",cs.CY,"['cs.CY', 'cs.DC', 'cs.NI']","[arxiv.Result.Author('Khalid Elgazzar'), arxiv.Result.Author('Haytham Khalil'), arxiv.Result.Author('Taghreed Alghamdi'), arxiv.Result.Author('Ahmed Badr'), arxiv.Result.Author('Ghadeer Abdelkader'), arxiv.Result.Author('Abdelrahman Elewah'), arxiv.Result.Author('Rajkumar Buyya')]","The Internet of Things (IoT) has brought the dream of ubiquitous data access
from physical environments into reality. IoT embeds sensors and actuators in
physical objects so that they can communicate and exchange data between
themselves to improve efficiency along with enabling real-time intelligent
services and offering better quality of life to people. The number of deployed
IoT devices has rapidly grown in the past five years in a way that makes IoT
the most disruptive technology in recent history. In this paper, we reevaluate
the position of IoT in our life and provide deep insights on its enabling
technologies, applications, rising trends and grand challenges. The paper also
highlights the role of artificial intelligence to make IoT the top
transformative technology that has been ever developed in human history."
14113,"Although our study gives an idea about public sentiment
an Accuracy of 69%, Recall of 68%, Precision of 67%, and            in North American regions, further study is needed to detect
F1 score of 68%.","Using a Logistic regression classiﬁer, we get        favor.","Using an XGBOOST classiﬁer, we get an              conspiracy and the user group for the other part of the world
Accuracy of 66%, Recall of 65%, Precision of 67%, and F1            to get a more realistic picture of COVID-19 Vaccines.",2022-11-20 04:59:33+00:00,Detecting Conspiracy Theory Against COVID-19 Vaccines,cs.CY,"['cs.CY', 'cs.CL', 'cs.LG', 'cs.SI']","[arxiv.Result.Author('Md Hasibul Amin'), arxiv.Result.Author('Harika Madanu'), arxiv.Result.Author('Sahithi Lavu'), arxiv.Result.Author('Hadi Mansourifar'), arxiv.Result.Author('Dana Alsagheer'), arxiv.Result.Author('Weidong Shi')]","Since the beginning of the vaccination trial, social media has been flooded
with anti-vaccination comments and conspiracy beliefs. As the day passes, the
number of COVID- 19 cases increases, and online platforms and a few news
portals entertain sharing different conspiracy theories. The most popular
conspiracy belief was the link between the 5G network spreading COVID-19 and
the Chinese government spreading the virus as a bioweapon, which initially
created racial hatred. Although some disbelief has less impact on society,
others create massive destruction. For example, the 5G conspiracy led to the
burn of the 5G Tower, and belief in the Chinese bioweapon story promoted an
attack on the Asian-Americans. Another popular conspiracy belief was that Bill
Gates spread this Coronavirus disease (COVID-19) by launching a mass
vaccination program to track everyone. This Conspiracy belief creates distrust
issues among laypeople and creates vaccine hesitancy. This study aims to
discover the conspiracy theory against the vaccine on social platforms. We
performed a sentiment analysis on the 598 unique sample comments related to
COVID-19 vaccines. We used two different models, BERT and Perspective API, to
find out the sentiment and toxicity of the sentence toward the COVID-19
vaccine."
14189,"Lastly, further research about the effectiveness of the web-based system may be
conducted for further enhancements of the system.","Moreover,
completion of the software development methodology may be done to complete the
cycle.","Research Implications – Services of the Commission may be enhanced upon the
implementation of the developed web-based management information system of filed
cases.",2022-11-23 06:30:01+00:00,Web-based Management Information System of Cases Filed with the National Labor Relations Commission,cs.CY,['cs.CY'],[arxiv.Result.Author('Aaron Paul M. Dela Rosa')],"This study was developed to describe the daily operations and encountered
problems of the National Labor Relations Commission Regional Arbitration Branch
No. IV (NLRC RAB IV) through conducted observations and interviews. These
problems were addressed and analyzed to be the features of the developed
web-based management information system (MIS) for cases. The research
methodology utilized in this project was the descriptive developmental
approach. The Agile Software Development methodology was followed to develop
the system. It was used to quickly produce the desired output while allowing
the user to go back through phases without finishing the whole cycle. The
system covered managing filed complaints, Single-Entry Approach (SEnA), labor
cases, and report generation. The findings, through the interview, of handling
records were inconsistent and inaccurate. This study also focused on ensuring
the Data Privacy Act of 2012, protecting the database's information using the
XOR Cipher Algorithm. This study was evaluated using standard web evaluation
criteria. Using the criteria, the study's overall mean was 4.27 and 4.43, with
the descriptive meaning of Very Good, which showed that the system was accepted
as perceived by experts and end-users, respectively. Management of filed cases
is a vital process for the Commission. With that said, developing a web-based
management information system could ease the internal operations of handling
and managing filed labor cases. Moreover, respondents and complainants can
easily determine their filed cases' status using the case status tracking
system. For further improvements to the system, additional printable documents
may be added that could be found needed by the Commission. Lastly, further
research about the effectiveness of the web-based system may be conducted for
further enhancements of the system."
14190,"Recommendations for future development of the study are to (1) provide
additional printable documents that include documents such as the mailing to both
complainants and respondents; (2) complete the Agile software development
methodology phases, continuing up to the release, tracking, and monitoring phase to
finish the cycle; and (3) develop a further study that would identify the impact of using a
web-based management system in a government agency.","They can be used by future researchers in the fields of
information technology or information systems who want to develop the same kind of
study.","IMPLICATIONS

    After the development of the web-based management information system for cases
filed with NLRC RAB IV, the agency may improve its services to the public upon its
implementation.",2022-11-23 06:30:01+00:00,Web-based Management Information System of Cases Filed with the National Labor Relations Commission,cs.CY,['cs.CY'],[arxiv.Result.Author('Aaron Paul M. Dela Rosa')],"This study was developed to describe the daily operations and encountered
problems of the National Labor Relations Commission Regional Arbitration Branch
No. IV (NLRC RAB IV) through conducted observations and interviews. These
problems were addressed and analyzed to be the features of the developed
web-based management information system (MIS) for cases. The research
methodology utilized in this project was the descriptive developmental
approach. The Agile Software Development methodology was followed to develop
the system. It was used to quickly produce the desired output while allowing
the user to go back through phases without finishing the whole cycle. The
system covered managing filed complaints, Single-Entry Approach (SEnA), labor
cases, and report generation. The findings, through the interview, of handling
records were inconsistent and inaccurate. This study also focused on ensuring
the Data Privacy Act of 2012, protecting the database's information using the
XOR Cipher Algorithm. This study was evaluated using standard web evaluation
criteria. Using the criteria, the study's overall mean was 4.27 and 4.43, with
the descriptive meaning of Very Good, which showed that the system was accepted
as perceived by experts and end-users, respectively. Management of filed cases
is a vital process for the Commission. With that said, developing a web-based
management information system could ease the internal operations of handling
and managing filed labor cases. Moreover, respondents and complainants can
easily determine their filed cases' status using the case status tracking
system. For further improvements to the system, additional printable documents
may be added that could be found needed by the Commission. Lastly, further
research about the effectiveness of the web-based system may be conducted for
further enhancements of the system."
14198,"and solar panel are tested for their functionality, although
From the values of latitude and longitude shown in Figure 13,              further research is needed to verify the effectiveness of white
it indicates that the baby is located around Klang, Malaysia.","Moreover, the white noise machine
obtained from the GPS unit and displays them on the website.",noise on the sleeping baby.,2022-11-26 12:42:27+00:00,A Remote Baby Surveillance System with RFID and GPS Tracking,cs.CY,"['cs.CY', 'cs.HC', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Ruven A/L Sundarajoo'), arxiv.Result.Author('Gwo Chin Chung'), arxiv.Result.Author('Wai Leong Pang'), arxiv.Result.Author('Soo Fun Tan')]","In the 21st century, sending babies or children to daycare centres has become
more and more common among young guardians. The balance between full-time work
and child care is increasingly challenging nowadays. In Malaysia, thousands of
child abuse cases have been reported from babysitting centres every year, which
indeed triggers the anxiety and stress of the guardians. Hence, this paper
proposes to construct a remote baby surveillance system with radio-frequency
identification (RFID) and global positioning system (GPS) tracking. With the
incorporation of the Internet of Things (IoT), a sensor-based microcontroller
is used to detect the conditions of the baby as well as the surrounding
environment and then display the real-time data as well as notifications to
alert the guardians via a mobile application. These conditions include the
crying and waking of the baby, as well as temperature, the mattress's wetness,
and moving objects around the baby. In addition, RFID and GPS location tracking
are implemented to ensure the safety of the baby, while white noise is used to
increase the comfort of the baby. In the end, a prototype has been successfully
developed for functionality and reliability testing. Several experiments have
been conducted to measure the efficiency of the mattress's wetness detection,
the RFID transmission range, the frequency spectrum of white noise, and also
the output power of the solar panel. The proposed system is expected to assist
guardians in ensuring the safety and comfort of their babies remotely, as well
as prevent any occurrence of child abuse."
14236,"In                 2021.
addition, it is worth noting that this article also draws attention  [11] K. MacCallum and D. Parsons, “Teacher perspectives on mobile aug-
to the fact that new moral problems need further study.","102 970–102 988,
governance mechanisms, and study-level testing methods.","How                mented reality: The potential of metaverse for learning,” in The World
has the relationship between parents and educational insti-                Conference on Mobile and Contextual Learning, 2019, pp.",2022-11-27 22:03:16+00:00,"Metaverse in Education: Vision, Opportunities, and Challenges",cs.CY,"['cs.CY', 'cs.DB']","[arxiv.Result.Author('Hong Lin'), arxiv.Result.Author('Shicheng Wan'), arxiv.Result.Author('Wensheng Gan'), arxiv.Result.Author('Jiahui Chen'), arxiv.Result.Author('Han-Chieh Chao')]","Traditional education has been updated with the development of information
technology in human history. Within big data and cyber-physical systems, the
Metaverse has generated strong interest in various applications (e.g.,
entertainment, business, and cultural travel) over the last decade. As a novel
social work idea, the Metaverse consists of many kinds of technologies, e.g.,
big data, interaction, artificial intelligence, game design, Internet
computing, Internet of Things, and blockchain. It is foreseeable that the usage
of Metaverse will contribute to educational development. However, the
architectures of the Metaverse in education are not yet mature enough. There
are many questions we should address for the Metaverse in education. To this
end, this paper aims to provide a systematic literature review of Metaverse in
education. This paper is a comprehensive survey of the Metaverse in education,
with a focus on current technologies, challenges, opportunities, and future
directions. First, we present a brief overview of the Metaverse in education,
as well as the motivation behind its integration. Then, we survey some
important characteristics for the Metaverse in education, including the
personal teaching environment and the personal learning environment. Next, we
envisage what variations of this combination will bring to education in the
future and discuss their strengths and weaknesses. We also review the
state-of-the-art case studies (including technical companies and educational
institutions) for Metaverse in education. Finally, we point out several
challenges and issues in this promising area."
14296,"Additionally, to allow further research, we make our raw data
available for exploration here: https://dooleys.github.io/robustness/.1

By benchmarking both commercial and academic models, we can understand two important insights:
(1) audit the use-case of a company which takes open-source models to build in-house facial recog-
nition models, and (2) adjudicate corporation’s claims of caring about demographic biases in their
products by measuring the extent to which their models are less biased than academic models which
have no fairness considerations.","Across these more than 5,000,000 noisy images
from four commonly used academic datasets: Adience [20], Casual Conversations Dataset [34],
MIAP [65], and UTKFace [82].","As such, we endeavor to answer three research questions:

(RQ1): How robust are commercial and academic face detection models to natural types of noise?",2022-11-29 05:22:47+00:00,Robustness Disparities in Face Detection,cs.CY,"['cs.CY', 'cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Samuel Dooley'), arxiv.Result.Author('George Z. Wei'), arxiv.Result.Author('Tom Goldstein'), arxiv.Result.Author('John P. Dickerson')]","Facial analysis systems have been deployed by large companies and critiqued
by scholars and activists for the past decade. Many existing algorithmic audits
examine the performance of these systems on later stage elements of facial
analysis systems like facial recognition and age, emotion, or perceived gender
prediction; however, a core component to these systems has been vastly
understudied from a fairness perspective: face detection, sometimes called face
localization. Since face detection is a pre-requisite step in facial analysis
systems, the bias we observe in face detection will flow downstream to the
other components like facial recognition and emotion prediction. Additionally,
no prior work has focused on the robustness of these systems under various
perturbations and corruptions, which leaves open the question of how various
people are impacted by these phenomena. We present the first of its kind
detailed benchmark of face detection systems, specifically examining the
robustness to noise of commercial and academic models. We use both standard and
recently released academic facial datasets to quantitatively analyze trends in
face detection robustness. Across all the datasets and systems, we generally
find that photos of individuals who are $\textit{masculine presenting}$,
$\textit{older}$, of $\textit{darker skin type}$, or have $\textit{dim
lighting}$ are more susceptible to errors than their counterparts in other
identities."
14622,"Studying how organisations can develop data-driven insights through data
management practices such as “data democratization” is another potential area for further study.","This could be a good area for future studies as it links with the
competitive advantage.","Data
democratization is a growing research area that helps organisations for empowering employees to use
data to drive decision-making and foster innovation.",2022-12-04 22:17:23+00:00,Data-driven Innovation: Understanding the Direction for Future Research,cs.CY,"['cs.CY', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sasari Samarasinghe'), arxiv.Result.Author('Sachithra Lokuge')]","In the contemporary age of information, organisations have realised the
importance of data to innovate and thereby attain a competitive advantage. As a
result, firms are more focused on understanding the potential to achieve
data-driven innovation (DDI). Researchers too have focused on examining this
novel phenomenon in a broader scope. In this study, we conducted a systematic
and comprehensive review of the literature to understand the DDI phenomenon.
The findings of this study benefit scholars in determining the gaps in the
current body of knowledge as well as for practitioners to improve their data
strategy to enhance and develop innovation capabilities."
14663,"Nevertheless, interesting statements are arising
which can serve as a basis for further research in the context of the application of AI in
GRC.","Due to the small number of interviews
and because people were addressed with the aid of relevant associations, the result
cannot be considered representative.","Specifically, the study should provide answers to the following questions

    • What is the current status of using AI in GRC?",2022-12-07 12:36:10+00:00,"Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)",cs.CY,['cs.CY'],"[arxiv.Result.Author('Eva Ponick'), arxiv.Result.Author('Gabriele Wieczorek')]","The digital transformation leads to fundamental change in organizational
structures. To be able to apply new technologies not only selectively,
processes in companies must be revised and functional units must be viewed
holistically, especially with regard to interfaces. Target-oriented management
decisions are made, among other things, on the basis of risk management and
compliance in combination with the internal control system as governance
functions. The effectiveness and efficiency of these functions is decisive to
follow guidelines and regulatory requirements as well as for the evaluation of
alternative options for acting with regard to activities of companies. GRC
(Governance, Risk and Compliance) means an integrated governance-approach, in
which the mentioned governance functions are interlinked and not separated from
each other. Methods of artificial intelligence represents an important
technology of digital transformation. This technology, which offers a broad
range of methods such as machine learning, artificial neural networks, natural
language processing or deep learning, offers a lot of possible applications in
many business areas from purchasing to production or customer service.
Artificial intelligence is also being used in GRC, for example for processing
and analysis of unstructured data sets. This study contains the results of a
survey conducted in 2021 to identify and analyze the potential applications of
artificial intelligence in GRC."
14664,"The obtained data from the survey serve as basis for additional, more
complex analysis and further research.","The questions asked in the study as well as the survey results
are listed below.",Chapter 2 lists the questions of the study and the results in the order used.,2022-12-07 12:36:10+00:00,"Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)",cs.CY,['cs.CY'],"[arxiv.Result.Author('Eva Ponick'), arxiv.Result.Author('Gabriele Wieczorek')]","The digital transformation leads to fundamental change in organizational
structures. To be able to apply new technologies not only selectively,
processes in companies must be revised and functional units must be viewed
holistically, especially with regard to interfaces. Target-oriented management
decisions are made, among other things, on the basis of risk management and
compliance in combination with the internal control system as governance
functions. The effectiveness and efficiency of these functions is decisive to
follow guidelines and regulatory requirements as well as for the evaluation of
alternative options for acting with regard to activities of companies. GRC
(Governance, Risk and Compliance) means an integrated governance-approach, in
which the mentioned governance functions are interlinked and not separated from
each other. Methods of artificial intelligence represents an important
technology of digital transformation. This technology, which offers a broad
range of methods such as machine learning, artificial neural networks, natural
language processing or deep learning, offers a lot of possible applications in
many business areas from purchasing to production or customer service.
Artificial intelligence is also being used in GRC, for example for processing
and analysis of unstructured data sets. This study contains the results of a
survey conducted in 2021 to identify and analyze the potential applications of
artificial intelligence in GRC."
14665,"The study serves as a basis for more
and complex analysis of the data obtained as well as deriving further research topics and
discussions.","The results for every
single question were presented and discussed.","Even though the presented study is not representative, it does show some interesting
approaches for further research.",2022-12-07 12:36:10+00:00,"Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)",cs.CY,['cs.CY'],"[arxiv.Result.Author('Eva Ponick'), arxiv.Result.Author('Gabriele Wieczorek')]","The digital transformation leads to fundamental change in organizational
structures. To be able to apply new technologies not only selectively,
processes in companies must be revised and functional units must be viewed
holistically, especially with regard to interfaces. Target-oriented management
decisions are made, among other things, on the basis of risk management and
compliance in combination with the internal control system as governance
functions. The effectiveness and efficiency of these functions is decisive to
follow guidelines and regulatory requirements as well as for the evaluation of
alternative options for acting with regard to activities of companies. GRC
(Governance, Risk and Compliance) means an integrated governance-approach, in
which the mentioned governance functions are interlinked and not separated from
each other. Methods of artificial intelligence represents an important
technology of digital transformation. This technology, which offers a broad
range of methods such as machine learning, artificial neural networks, natural
language processing or deep learning, offers a lot of possible applications in
many business areas from purchasing to production or customer service.
Artificial intelligence is also being used in GRC, for example for processing
and analysis of unstructured data sets. This study contains the results of a
survey conducted in 2021 to identify and analyze the potential applications of
artificial intelligence in GRC."
14666,"Even though the presented study is not representative, it does show some interesting
approaches for further research.","The study serves as a basis for more
and complex analysis of the data obtained as well as deriving further research topics and
discussions.","How exactly does the integration of the GRC business
segments affect data exchange?",2022-12-07 12:36:10+00:00,"Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)",cs.CY,['cs.CY'],"[arxiv.Result.Author('Eva Ponick'), arxiv.Result.Author('Gabriele Wieczorek')]","The digital transformation leads to fundamental change in organizational
structures. To be able to apply new technologies not only selectively,
processes in companies must be revised and functional units must be viewed
holistically, especially with regard to interfaces. Target-oriented management
decisions are made, among other things, on the basis of risk management and
compliance in combination with the internal control system as governance
functions. The effectiveness and efficiency of these functions is decisive to
follow guidelines and regulatory requirements as well as for the evaluation of
alternative options for acting with regard to activities of companies. GRC
(Governance, Risk and Compliance) means an integrated governance-approach, in
which the mentioned governance functions are interlinked and not separated from
each other. Methods of artificial intelligence represents an important
technology of digital transformation. This technology, which offers a broad
range of methods such as machine learning, artificial neural networks, natural
language processing or deep learning, offers a lot of possible applications in
many business areas from purchasing to production or customer service.
Artificial intelligence is also being used in GRC, for example for processing
and analysis of unstructured data sets. This study contains the results of a
survey conducted in 2021 to identify and analyze the potential applications of
artificial intelligence in GRC."
14707,"Additionally, we found that these disparities are even more correlated with certain
“fixable problems,” which provides a potential pathway for further research to investigate how
the disparities present in the healthcare system today can be addressed.","Khanna, Lu, Warrier - 6

Our results show that socioeconomic factors, specifically income and level of educational
attainment, correlate with certain health outcomes through visual analysis and robust predictive
modeling.",9.,2022-12-01 00:00:40+00:00,The Impact of Socioeconomic Factors on Health Disparities,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG', '68U99', 'I.2.6; J.4']","[arxiv.Result.Author('Krish Khanna'), arxiv.Result.Author('Jeffrey Lu'), arxiv.Result.Author('Jay Warrier'), arxiv.Result.Author('Phillip Lo'), arxiv.Result.Author('Adela DePavia'), arxiv.Result.Author('Ray Fregly')]","High-quality healthcare in the US can be cost-prohibitive for certain
socioeconomic groups. In this paper, we examined data from the US Census and
the CDC to determine the degree to which specific socioeconomic factors
correlate with both specific and general health metrics. We employed visual
analysis to find broad trends and predictive modeling to identify more complex
relationships between variables. Our results indicate that certain
socioeconomic factors, like income and educational attainment, are highly
correlated with aggregate measures of health."
14708,"Additionally, we found that these disparities are even more correlated with certain
“fixable problems,” which provides a potential pathway for further research to investigate how
the disparities present in the healthcare system today can be addressed.","Khanna, Lu, Warrier - 6

Our results show that socioeconomic factors, specifically income and level of educational
attainment, correlate with certain health outcomes through visual analysis and robust predictive
modeling.",9.,2022-12-01 00:00:40+00:00,The Impact of Socioeconomic Factors on Health Disparities,cs.CY,"['cs.CY', 'cs.AI', 'cs.LG', '68U99', 'I.2.6; J.4']","[arxiv.Result.Author('Krish Khanna'), arxiv.Result.Author('Jeffrey Lu'), arxiv.Result.Author('Jay Warrier'), arxiv.Result.Author('Phillip Lo'), arxiv.Result.Author('Adela DePavia'), arxiv.Result.Author('Ray Fregly')]","High-quality healthcare in the US can be cost-prohibitive for certain
socioeconomic groups. In this paper, we examined data from the US Census and
the CDC to determine the degree to which specific socioeconomic factors
correlate with both specific and general health metrics. We employed visual
analysis to find broad trends and predictive modeling to identify more complex
relationships between variables. Our results indicate that certain
socioeconomic factors, like income and educational attainment, are highly
correlated with aggregate measures of health."
14840,A further study conducted by Bu¨chi et al.,"Moreover, the study was based on English
Wikipedia, to which the evidence of chilling eﬀects may not be applicable in
other Wikipedia languages.","(2019)
has suggested that a subtle and long-term chilling eﬀect may exist from organi-
sations proﬁling our information.",2022-12-12 11:03:10+00:00,Wikipedia's Balancing Act: A Tool for Collective Intelligence or Mass Surveillance?,cs.CY,['cs.CY'],[arxiv.Result.Author('Simon Liu')],"Wikipedia has evolved beyond its original function as an online encyclopedia
in an increasingly complex data-driven society. The social platform is met with
a balancing act between collective intelligence and mass surveillance;
processes need to be developed to protect individuals and the community from
government mass surveillance without sacrificing the important contributions
made through prohibited anonymous communication software. Case studies are
provided from NSA government surveillance practices, the anti-SOPA legislation
movement, and research that covers Wikipedia's involvement with participatory
journalism, disinformation, self-censorship, and the use of Tor. This paper
proposes that a common ground can be developed between individuals, public and
private institutions through future research in socio-cultural anthropology and
policy frameworks around data retention and government accountability.
Wikipedia is used as an example within the US intelligence community as a
complex organisation that can adapt to changes through its iterative nature,
which draws insight into how policy frameworks can be future-proofed. Finally,
this paper is a wake-up call to individuals, private institutions, and
governments to remain vigilant about the storage and use of personal
information as a result of contributing to online communities."
15034,"Section 5 con-
cludes and suggests questions for further research.","Sec-
tion 4 discusses how the model could help reduce risks from AI.","2 The 3LoD model

In this section, I give an overview of the basic structure (Section 2.1) and his-
tory of the 3LoD model (Section 2.2).",2022-12-16 09:33:00+00:00,Three lines of defense against risks from AI,cs.CY,['cs.CY'],[arxiv.Result.Author('Jonas Schuett')],"Organizations that develop and deploy artificial intelligence (AI) systems
need to manage the associated risks - for economic, legal, and ethical reasons.
However, it is not always clear who is responsible for AI risk management. The
Three Lines of Defense (3LoD) model, which is considered best practice in many
industries, might offer a solution. It is a risk management framework that
helps organizations to assign and coordinate risk management roles and
responsibilities. In this article, I suggest ways in which AI companies could
implement the model. I also discuss how the model could help reduce risks from
AI: it could identify and close gaps in risk coverage, increase the
effectiveness of risk management practices, and enable the board of directors
to oversee management more effectively. The article is intended to inform
decision-makers at leading AI companies, regulators, and standard-setting
bodies."
15035,"Based on the findings of this article, I suggest the following questions for
further research.","It
concluded that, while there are some limitations and the effects should not be
overstated, the model can plausibly contribute to a reduction of risks from AI.","First, the article has highlighted the importance of internal
audit in AI risk management.",2022-12-16 09:33:00+00:00,Three lines of defense against risks from AI,cs.CY,['cs.CY'],[arxiv.Result.Author('Jonas Schuett')],"Organizations that develop and deploy artificial intelligence (AI) systems
need to manage the associated risks - for economic, legal, and ethical reasons.
However, it is not always clear who is responsible for AI risk management. The
Three Lines of Defense (3LoD) model, which is considered best practice in many
industries, might offer a solution. It is a risk management framework that
helps organizations to assign and coordinate risk management roles and
responsibilities. In this article, I suggest ways in which AI companies could
implement the model. I also discuss how the model could help reduce risks from
AI: it could identify and close gaps in risk coverage, increase the
effectiveness of risk management practices, and enable the board of directors
to oversee management more effectively. The article is intended to inform
decision-makers at leading AI companies, regulators, and standard-setting
bodies."
15230,"However, we need
to do further research on the topic as such dynamic architecture might not be good
for a small application as it requires much more effort to build it successfully.","This
architecture helps us isolate each layer dependency more easily.",6.,2022-12-21 14:49:48+00:00,CNN waste classification project report,cs.CY,['cs.CY'],"[arxiv.Result.Author('Fei Wu'), arxiv.Result.Author('LiQin Zhang'), arxiv.Result.Author('An Tran')]","This report is about waste management project. We used CNN as classifier to
classify waste image captured from mobile phone. Our model can identify 6 waste
classes with highly accurate and our model is successfully transferred into IOS
platform as application by swift. In addition, this report also introduced some
basic project management from planning project to landing project, for instance
using agile development to develop this waste app."
