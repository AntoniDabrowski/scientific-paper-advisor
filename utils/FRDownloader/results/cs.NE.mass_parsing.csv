,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract
740,"And it paves the way for
further research on solving Reinforcement Learning problems
with directly-trained SNNs.",games with the directly-trained SNN.,"JOURNAL OF X, VOL.",2021-12-13 09:46:17+00:00,Human-Level Control through Directly-Trained Deep Spiking Q-Networks,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Guisong Liu'), arxiv.Result.Author('Wenjie Deng'), arxiv.Result.Author('Xiurui Xie'), arxiv.Result.Author('Li Huang'), arxiv.Result.Author('Huajin Tang')]","As the third-generation neural networks, Spiking Neural Networks (SNNs) have
great potential on neuromorphic hardware because of their high
energy-efficiency. However, Deep Spiking Reinforcement Learning (DSRL), i.e.,
the Reinforcement Learning (RL) based on SNNs, is still in its preliminary
stage due to the binary output and the non-differentiable property of the
spiking function. To address these issues, we propose a Deep Spiking Q-Network
(DSQN) in this paper. Specifically, we propose a directly-trained deep spiking
reinforcement learning architecture based on the Leaky Integrate-and-Fire (LIF)
neurons and Deep Q-Network (DQN). Then, we adapt a direct spiking learning
algorithm for the Deep Spiking Q-Network. We further demonstrate the advantages
of using LIF neurons in DSQN theoretically. Comprehensive experiments have been
conducted on 17 top-performing Atari games to compare our method with the
state-of-the-art conversion method. The experimental results demonstrate the
superiority of our method in terms of performance, stability, robustness and
energy-efficiency. To the best of our knowledge, our work is the first one to
achieve state-of-the-art performance on multiple Atari games with the
directly-trained SNN."
741,"And it paves the
way for further research on solving Reinforcement Learning                                      III.",Atari games with the directly-trained SNN.,"METHODS
problems with directly-trained SNNs.",2021-12-13 09:46:17+00:00,Human-Level Control through Directly-Trained Deep Spiking Q-Networks,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Guisong Liu'), arxiv.Result.Author('Wenjie Deng'), arxiv.Result.Author('Xiurui Xie'), arxiv.Result.Author('Li Huang'), arxiv.Result.Author('Huajin Tang')]","As the third-generation neural networks, Spiking Neural Networks (SNNs) have
great potential on neuromorphic hardware because of their high
energy-efficiency. However, Deep Spiking Reinforcement Learning (DSRL), i.e.,
the Reinforcement Learning (RL) based on SNNs, is still in its preliminary
stage due to the binary output and the non-differentiable property of the
spiking function. To address these issues, we propose a Deep Spiking Q-Network
(DSQN) in this paper. Specifically, we propose a directly-trained deep spiking
reinforcement learning architecture based on the Leaky Integrate-and-Fire (LIF)
neurons and Deep Q-Network (DQN). Then, we adapt a direct spiking learning
algorithm for the Deep Spiking Q-Network. We further demonstrate the advantages
of using LIF neurons in DSQN theoretically. Comprehensive experiments have been
conducted on 17 top-performing Atari games to compare our method with the
state-of-the-art conversion method. The experimental results demonstrate the
superiority of our method in terms of performance, stability, robustness and
energy-efficiency. To the best of our knowledge, our work is the first one to
achieve state-of-the-art performance on multiple Atari games with the
directly-trained SNN."
742,"such as Distributional RL, our work needs further study.","For other Deep Reinforcement Learning algorithms,
and the CDQN and CDSQN are trained on 10M timesteps.","The
The hyperparameters of the Double DQN and CDQN follow               theoretical analysis of LIF neuron‚Äôs nature is not particularly
their references [44] and [45] respectively.",2021-12-13 09:46:17+00:00,Human-Level Control through Directly-Trained Deep Spiking Q-Networks,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Guisong Liu'), arxiv.Result.Author('Wenjie Deng'), arxiv.Result.Author('Xiurui Xie'), arxiv.Result.Author('Li Huang'), arxiv.Result.Author('Huajin Tang')]","As the third-generation neural networks, Spiking Neural Networks (SNNs) have
great potential on neuromorphic hardware because of their high
energy-efficiency. However, Deep Spiking Reinforcement Learning (DSRL), i.e.,
the Reinforcement Learning (RL) based on SNNs, is still in its preliminary
stage due to the binary output and the non-differentiable property of the
spiking function. To address these issues, we propose a Deep Spiking Q-Network
(DSQN) in this paper. Specifically, we propose a directly-trained deep spiking
reinforcement learning architecture based on the Leaky Integrate-and-Fire (LIF)
neurons and Deep Q-Network (DQN). Then, we adapt a direct spiking learning
algorithm for the Deep Spiking Q-Network. We further demonstrate the advantages
of using LIF neurons in DSQN theoretically. Comprehensive experiments have been
conducted on 17 top-performing Atari games to compare our method with the
state-of-the-art conversion method. The experimental results demonstrate the
superiority of our method in terms of performance, stability, robustness and
energy-efficiency. To the best of our knowledge, our work is the first one to
achieve state-of-the-art performance on multiple Atari games with the
directly-trained SNN."
1222,"We anticipate that this study will inspire further research
into automatic design of energy-efÔ¨Åcient SNN architectures.","ternational Joint Conference on Neural Networks, 2015.","Ding, M., Lian, X., Yang, L., Wang, P., Jin, X., Lu, Z.,
                                                                  and Luo, P. Hr-nas: Searching efÔ¨Åcient high-resolution
References                                                        neural architectures with lightweight transformers.",2022-01-30 06:12:59+00:00,AutoSNN: Towards Energy-Efficient Spiking Neural Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Byunggook Na'), arxiv.Result.Author('Jisoo Mok'), arxiv.Result.Author('Seongsik Park'), arxiv.Result.Author('Dongjin Lee'), arxiv.Result.Author('Hyeokjun Choe'), arxiv.Result.Author('Sungroh Yoon')]","Spiking neural networks (SNNs) that mimic information transmission in the
brain can energy-efficiently process spatio-temporal information through
discrete and sparse spikes, thereby receiving considerable attention. To
improve accuracy and energy efficiency of SNNs, most previous studies have
focused solely on training methods, and the effect of architecture has rarely
been studied. We investigate the design choices used in the previous studies in
terms of the accuracy and number of spikes and figure out that they are not
best-suited for SNNs. To further improve the accuracy and reduce the spikes
generated by SNNs, we propose a spike-aware neural architecture search
framework called AutoSNN. We define a search space consisting of architectures
without undesirable design choices. To enable the spike-aware architecture
search, we introduce a fitness that considers both the accuracy and number of
spikes. AutoSNN successfully searches for SNN architectures that outperform
hand-crafted SNNs in accuracy and energy efficiency. We thoroughly demonstrate
the effectiveness of AutoSNN on various datasets including neuromorphic
datasets."
1223,"We anticipate that this
have eight TBD blocks as described in TABLE VI; both of            study will inspire further research into automatic design of
them include 390,625 architectures (58).","Our results highlighted the importance of architectural
We construct two search spaces, where the macro architectures      conÔ¨Ågurations in the SNN domain.",One is the SNN 3-         energy-efÔ¨Åcient SNN architectures.,2022-01-30 06:12:59+00:00,AutoSNN: Towards Energy-Efficient Spiking Neural Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Byunggook Na'), arxiv.Result.Author('Jisoo Mok'), arxiv.Result.Author('Seongsik Park'), arxiv.Result.Author('Dongjin Lee'), arxiv.Result.Author('Hyeokjun Choe'), arxiv.Result.Author('Sungroh Yoon')]","Spiking neural networks (SNNs) that mimic information transmission in the
brain can energy-efficiently process spatio-temporal information through
discrete and sparse spikes, thereby receiving considerable attention. To
improve accuracy and energy efficiency of SNNs, most previous studies have
focused solely on training methods, and the effect of architecture has rarely
been studied. We investigate the design choices used in the previous studies in
terms of the accuracy and number of spikes and figure out that they are not
best-suited for SNNs. To further improve the accuracy and reduce the spikes
generated by SNNs, we propose a spike-aware neural architecture search
framework called AutoSNN. We define a search space consisting of architectures
without undesirable design choices. To enable the spike-aware architecture
search, we introduce a fitness that considers both the accuracy and number of
spikes. AutoSNN successfully searches for SNN architectures that outperform
hand-crafted SNNs in accuracy and energy efficiency. We thoroughly demonstrate
the effectiveness of AutoSNN on various datasets including neuromorphic
datasets."
1224,"We               Guerra, G. A. F., Joshi, P., Plank, P., and Risbud, S. R.
anticipate that this study will inspire further research into      Advancing neuromorphic computing with loihi: A survey
automatic design of energy-efÔ¨Åcient SNN architectures.","Our results highlighted the importance     Davies, M., Wild, A., Orchard, G., Sandamirskaya, Y.,
of architectural conÔ¨Ågurations in the SNN domain.",of results and outlook.,2022-01-30 06:12:59+00:00,AutoSNN: Towards Energy-Efficient Spiking Neural Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Byunggook Na'), arxiv.Result.Author('Jisoo Mok'), arxiv.Result.Author('Seongsik Park'), arxiv.Result.Author('Dongjin Lee'), arxiv.Result.Author('Hyeokjun Choe'), arxiv.Result.Author('Sungroh Yoon')]","Spiking neural networks (SNNs) that mimic information transmission in the
brain can energy-efficiently process spatio-temporal information through
discrete and sparse spikes, thereby receiving considerable attention. To
improve accuracy and energy efficiency of SNNs, most previous studies have
focused solely on training methods, and the effect of architecture has rarely
been studied. We investigate the design choices used in the previous studies in
terms of the accuracy and number of spikes and figure out that they are not
best-suited for SNNs. To further improve the accuracy and reduce the spikes
generated by SNNs, we propose a spike-aware neural architecture search
framework called AutoSNN. We define a search space consisting of architectures
without undesirable design choices. To enable the spike-aware architecture
search, we introduce a fitness that considers both the accuracy and number of
spikes. AutoSNN successfully searches for SNN architectures that outperform
hand-crafted SNNs in accuracy and energy efficiency. We thoroughly demonstrate
the effectiveness of AutoSNN on various datasets including neuromorphic
datasets."
1526,"Secondly, our results are limited to a single system and further research is
needed to apply QD-search methods to a wider variety of creative systems.","However, such simple measures would be unlikely to generalise
to other systems, so further work is needed to Ô¨Ånd high quality aesthetic Ô¨Åtness
measures that work across diÔ¨Äerent visual forms and styles.","The
fundamental challenge is in devising suitable computable measures of both qual-
ity and diversity that work for a speciÔ¨Åc generative system.",2022-02-04 04:11:21+00:00,Quality-diversity for aesthetic evolution,cs.NE,"['cs.NE', 'cs.HC', 'F.2.3; J.5; I.3.3']","[arxiv.Result.Author('Jon McCormack'), arxiv.Result.Author('Camilo Cruz Gambardella')]","Many creative generative design spaces contain multiple regions with
individuals of high aesthetic value. Yet traditional evolutionary computing
methods typically focus on optimisation, searching for the fittest individual
in a population. In this paper we apply quality-diversity search methods to
explore a creative generative system (an agent-based line drawing model). We
perform a random sampling of genotype space and use individual artist-assigned
evaluations of aesthetic quality to formulate a computable fitness measure
specific to the artist and this system. To compute diversity we use a
convolutional neural network to discriminate features that are dimensionally
reduced into two dimensions. We show that the quality-diversity search is able
to find multiple phenotypes of high aesthetic value. These phenotypes show
greater diversity and quality than those the artist was able to find using
manual search methods."
1535,"However,
such that the area under the KDE curve is 1.                                                                                      we believe that further studying noise in network performance eval-
                                                                                                                                  uation with more advanced NAS techniques, including approaches
Table 1.",The y-axis is normalized                                                                      using partial training can only aggravate this problem.,"Comparison of the best found architectures to al-                                                                        based on supernetworks, is an interesting topic for further research.",2022-02-04 11:20:46+00:00,Heed the Noise in Performance Evaluations in Neural Architecture Search,cs.NE,"['cs.NE', 'cs.CV', 'eess.IV']","[arxiv.Result.Author('Arkadiy Dushatskiy'), arxiv.Result.Author('Tanja Alderliesten'), arxiv.Result.Author('Peter A. N. Bosman')]","Neural Architecture Search (NAS) has recently become a topic of great
interest. However, there is a potentially impactful issue within NAS that
remains largely unrecognized: noise. Due to stochastic factors in neural
network initialization, training, and the chosen train/validation dataset
split, the performance evaluation of a neural network architecture, which is
often based on a single learning run, is also stochastic. This may have a
particularly large impact if a dataset is small. We therefore propose to reduce
the noise by having architecture evaluations comprise averaging of scores over
multiple network training runs using different random seeds and
cross-validation. We perform experiments for a combinatorial optimization
formulation of NAS in which we vary noise reduction levels. We use the same
computational budget for each noise level in terms of network training runs,
i.e., we allow less architecture evaluations when averaging over more training
runs. Multiple search algorithms are considered, including evolutionary
algorithms which generally perform well for NAS. We use two publicly available
datasets from the medical image segmentation domain where datasets are often
limited and variability among samples is often high. Our results show that
reducing noise in architecture evaluations enables finding better architectures
by all considered search algorithms."
1536,"Comparison of the best found architectures to al-                                                                        based on supernetworks, is an interesting topic for further research.","However,
such that the area under the KDE curve is 1.                                                                                      we believe that further studying noise in network performance eval-
                                                                                                                                  uation with more advanced NAS techniques, including approaches
Table 1.",ternative Unet-like architectures.,2022-02-04 11:20:46+00:00,Heed the Noise in Performance Evaluations in Neural Architecture Search,cs.NE,"['cs.NE', 'cs.CV', 'eess.IV']","[arxiv.Result.Author('Arkadiy Dushatskiy'), arxiv.Result.Author('Tanja Alderliesten'), arxiv.Result.Author('Peter A. N. Bosman')]","Neural Architecture Search (NAS) has recently become a topic of great
interest. However, there is a potentially impactful issue within NAS that
remains largely unrecognized: noise. Due to stochastic factors in neural
network initialization, training, and the chosen train/validation dataset
split, the performance evaluation of a neural network architecture, which is
often based on a single learning run, is also stochastic. This may have a
particularly large impact if a dataset is small. We therefore propose to reduce
the noise by having architecture evaluations comprise averaging of scores over
multiple network training runs using different random seeds and
cross-validation. We perform experiments for a combinatorial optimization
formulation of NAS in which we vary noise reduction levels. We use the same
computational budget for each noise level in terms of network training runs,
i.e., we allow less architecture evaluations when averaging over more training
runs. Multiple search algorithms are considered, including evolutionary
algorithms which generally perform well for NAS. We use two publicly available
datasets from the medical image segmentation domain where datasets are often
limited and variability among samples is often high. Our results show that
reducing noise in architecture evaluations enables finding better architectures
by all considered search algorithms."
1537,"However,
EfficientNet-b7-Unet           0.707          0.895                                                                               we believe that further studying noise in network performance eval-
nnUnet                         0.699          0.897                                                                               uation with more advanced NAS techniques, including approaches
Ours, Setup-1Fold (best)       0.723          0.894                                                                               based on supernetworks, is an interesting topic for further research.","Further-
Architecture              Prostate, Dice  ACDC, Dice                                                                              more, we observe that even without partial training (for a fewer
ResNet-18-Unet                 0.690          0.893                                                                               number of epochs) network performance scores are quite noisy, and
EfficientNet-b0-Unet           0.703          0.885                                                                               using partial training can only aggravate this problem.","Ours, Setup-CV (best)          0.723          0.896
Ours, Setup-3CV (best)         0.726          0.897                                                                               7 CONCLUSION

find better networks than the alternatives.",2022-02-04 11:20:46+00:00,Heed the Noise in Performance Evaluations in Neural Architecture Search,cs.NE,"['cs.NE', 'cs.CV', 'eess.IV']","[arxiv.Result.Author('Arkadiy Dushatskiy'), arxiv.Result.Author('Tanja Alderliesten'), arxiv.Result.Author('Peter A. N. Bosman')]","Neural Architecture Search (NAS) has recently become a topic of great
interest. However, there is a potentially impactful issue within NAS that
remains largely unrecognized: noise. Due to stochastic factors in neural
network initialization, training, and the chosen train/validation dataset
split, the performance evaluation of a neural network architecture, which is
often based on a single learning run, is also stochastic. This may have a
particularly large impact if a dataset is small. We therefore propose to reduce
this noise by evaluating architectures based on average performance over
multiple network training runs using different random seeds and
cross-validation. We perform experiments for a combinatorial optimization
formulation of NAS in which we vary noise reduction levels. We use the same
computational budget for each noise level in terms of network training runs,
i.e., we allow less architecture evaluations when averaging over more training
runs. Multiple search algorithms are considered, including evolutionary
algorithms which generally perform well for NAS. We use two publicly available
datasets from the medical image segmentation domain where datasets are often
limited and variability among samples is often high. Our results show that
reducing noise in architecture evaluations enables finding better architectures
by all considered search algorithms."
2209,"We believe
                                                                          expressivity provides a productive perspective for further research
   To highlight the mechanisms that make expressive encodings             on many aspects of evolutionary computation.",adaptation and make intractable problems tractable.,"powerful, the test domains were idealized to contain two comple-
mentary targets.",2022-02-19 20:54:37+00:00,Simple Genetic Operators are Universal Approximators of Probability Distributions (and other Advantages of Expressive Encodings),cs.NE,['cs.NE'],"[arxiv.Result.Author('Elliot Meyerson'), arxiv.Result.Author('Xin Qiu'), arxiv.Result.Author('Risto Miikkulainen')]","This paper characterizes the inherent power of evolutionary algorithms. This
power depends on the computational properties of the genetic encoding. With
some encodings, two parents recombined with a simple crossover operator can
sample from an arbitrary distribution of child phenotypes. Such encodings are
termed \emph{expressive encodings} in this paper. Universal function
approximators, including popular evolutionary substrates of genetic programming
and neural networks, can be used to construct expressive encodings. Remarkably,
this approach need not be applied only to domains where the phenotype is a
function: Expressivity can be achieved even when optimizing static structures,
such as binary vectors. Such simpler settings make it possible to characterize
expressive encodings theoretically: Across a variety of test problems,
expressive encodings are shown to achieve up to super-exponential convergence
speed-ups over the standard direct encoding. The conclusion is that, across
evolutionary computation areas as diverse as genetic programming,
neuroevolution, genetic algorithms, and theory, expressive encodings can be a
key to understanding and realizing the full power of evolution."
2210,"2019.
expressivity provides a productive perspective for further research
                                                                                                 Evolvability ES: scalable and direct optimization of evolvability.","[28] Alexander Gajewski, Jeff Clune, Kenneth O Stanley, and Joel Lehman.","In Proceedings of
on many aspects of evolutionary computation.",2022-02-19 20:54:37+00:00,Simple Genetic Operators are Universal Approximators of Probability Distributions (and other Advantages of Expressive Encodings),cs.NE,['cs.NE'],"[arxiv.Result.Author('Elliot Meyerson'), arxiv.Result.Author('Xin Qiu'), arxiv.Result.Author('Risto Miikkulainen')]","This paper characterizes the inherent power of evolutionary algorithms. This
power depends on the computational properties of the genetic encoding. With
some encodings, two parents recombined with a simple crossover operator can
sample from an arbitrary distribution of child phenotypes. Such encodings are
termed \emph{expressive encodings} in this paper. Universal function
approximators, including popular evolutionary substrates of genetic programming
and neural networks, can be used to construct expressive encodings. Remarkably,
this approach need not be applied only to domains where the phenotype is a
function: Expressivity can be achieved even when optimizing static structures,
such as binary vectors. Such simpler settings make it possible to characterize
expressive encodings theoretically: Across a variety of test problems,
expressive encodings are shown to achieve up to super-exponential convergence
speed-ups over the standard direct encoding. The conclusion is that, across
evolutionary computation areas as diverse as genetic programming,
neuroevolution, genetic algorithms, and theory, expressive encodings can be a
key to understanding and realizing the full power of evolution."
2211,expressivity provides a productive perspective for further research                        [25] Chelsea Finn and Sergey Levine.,We believe                                   (2017).,2017.,2022-02-19 20:54:37+00:00,Simple Genetic Operators are Universal Approximators of Probability Distributions (and other Advantages of Expressive Encodings),cs.NE,['cs.NE'],"[arxiv.Result.Author('Elliot Meyerson'), arxiv.Result.Author('Xin Qiu'), arxiv.Result.Author('Risto Miikkulainen')]","This paper characterizes the inherent power of evolutionary algorithms. This
power depends on the computational properties of the genetic encoding. With
some encodings, two parents recombined with a simple crossover operator can
sample from an arbitrary distribution of child phenotypes. Such encodings are
termed \emph{expressive encodings} in this paper. Universal function
approximators, including popular evolutionary substrates of genetic programming
and neural networks, can be used to construct expressive encodings. Remarkably,
this approach need not be applied only to domains where the phenotype is a
function: Expressivity can be achieved even when optimizing static structures,
such as binary vectors. Such simpler settings make it possible to characterize
expressive encodings theoretically: Across a variety of test problems,
expressive encodings are shown to achieve up to super-exponential convergence
speed-ups over the standard direct encoding. The conclusion is that, across
evolutionary computation areas as diverse as genetic programming,
neuroevolution, genetic algorithms, and theory, expressive encodings can be a
key to understanding and realizing the full power of evolution."
2212,expressivity provides a productive perspective for further research                        [25] Chelsea Finn and Sergey Levine.,We believe                                   (2017).,2017.,2022-02-19 20:54:37+00:00,Simple Genetic Operators are Universal Approximators of Probability Distributions (and other Advantages of Expressive Encodings),cs.NE,['cs.NE'],"[arxiv.Result.Author('Elliot Meyerson'), arxiv.Result.Author('Xin Qiu'), arxiv.Result.Author('Risto Miikkulainen')]","This paper characterizes the inherent power of evolutionary algorithms. This
power depends on the computational properties of the genetic encoding. With
some encodings, two parents recombined with a simple crossover operator can
sample from an arbitrary distribution of child phenotypes. Such encodings are
termed \emph{expressive encodings} in this paper. Universal function
approximators, including popular evolutionary substrates of genetic programming
and neural networks, can be used to construct expressive encodings. Remarkably,
this approach need not be applied only to domains where the phenotype is a
function: Expressivity can be achieved even when optimizing static structures,
such as binary vectors. Such simpler settings make it possible to characterize
expressive encodings theoretically: Across a variety of test problems,
expressive encodings are shown to achieve up to super-exponential convergence
speed-ups over the standard direct encoding. The conclusion is that, across
evolutionary computation areas as diverse as genetic programming,
neuroevolution, genetic algorithms, and theory, expressive encodings can be a
key to understanding and realizing the full power of evolution."
2456,"We
see this as a motivation for designing ad hoc neuromorphic chips that are highly specialized in performing the FT. We
hope that this work encourages further research on the design of novel hardware architectures that leverage the potential
of neuromorphic hardware to create signal processing solutions faster and more efÔ¨Åcient than current state-of-the-art
solutions.","However, the computational
performance of the proposed work is behind FT accelerators in terms of energy consumption and execution time.","We believe that replacing the general-purpose board used for the experiments with a chip that implements a
neuron model and a connection grid tailored for the proposed algorithm would signiÔ¨Åcantly improve the computational
performance of the algorithm and would outperform the traditional solutions used today to implement the FT.",2022-02-25 12:15:46+00:00,Time-coded Spiking Fourier Transform in Neuromorphic Hardware,cs.NE,"['cs.NE', 'eess.SP']","[arxiv.Result.Author('Javier L√≥pez-Randulfe'), arxiv.Result.Author('Nico Reeb'), arxiv.Result.Author('Negin Karimi'), arxiv.Result.Author('Chen Liu'), arxiv.Result.Author('Hector A. Gonzalez'), arxiv.Result.Author('Robin Dietrich'), arxiv.Result.Author('Bernhard Vogginger'), arxiv.Result.Author('Christian Mayr'), arxiv.Result.Author('Alois Knoll')]","After several decades of continuously optimizing computing systems, the
Moore's law is reaching itsend. However, there is an increasing demand for fast
and efficient processing systems that can handlelarge streams of data while
decreasing system footprints. Neuromorphic computing answers thisneed by
creating decentralized architectures that communicate with binary events over
time. Despiteits rapid growth in the last few years, novel algorithms are
needed that can leverage the potential ofthis emerging computing paradigm and
can stimulate the design of advanced neuromorphic chips.In this work, we
propose a time-based spiking neural network that is mathematically equivalent
tothe Fourier transform. We implemented the network in the neuromorphic chip
Loihi and conductedexperiments on five different real scenarios with an
automotive frequency modulated continuouswave radar. Experimental results
validate the algorithm, and we hope they prompt the design of adhoc
neuromorphic chips that can improve the efficiency of state-of-the-art digital
signal processorsand encourage research on neuromorphic computing for signal
processing."
2457,"By means of this paper we aim to stimulate further research on the application of time-based SNNs for signal process-
ing.","Moreover,
the implementation of the proposed model and other SNNs is restrained by the contemporary absence of commercial
neuromorphic chips.","The S-FT can serve as the initial stage for larger processing pipelines, providing input for higher-level operations
performed by other time-based SNNs, such as object detection, tracking, or classiÔ¨Åcation.",2022-02-25 12:15:46+00:00,Time-coded Spiking Fourier Transform in Neuromorphic Hardware,cs.NE,"['cs.NE', 'eess.SP']","[arxiv.Result.Author('Javier L√≥pez-Randulfe'), arxiv.Result.Author('Nico Reeb'), arxiv.Result.Author('Negin Karimi'), arxiv.Result.Author('Chen Liu'), arxiv.Result.Author('Hector A. Gonzalez'), arxiv.Result.Author('Robin Dietrich'), arxiv.Result.Author('Bernhard Vogginger'), arxiv.Result.Author('Christian Mayr'), arxiv.Result.Author('Alois Knoll')]","After several decades of continuously optimizing computing systems, the
Moore's law is reaching itsend. However, there is an increasing demand for fast
and efficient processing systems that can handlelarge streams of data while
decreasing system footprints. Neuromorphic computing answers thisneed by
creating decentralized architectures that communicate with binary events over
time. Despiteits rapid growth in the last few years, novel algorithms are
needed that can leverage the potential ofthis emerging computing paradigm and
can stimulate the design of advanced neuromorphic chips.In this work, we
propose a time-based spiking neural network that is mathematically equivalent
tothe Fourier transform. We implemented the network in the neuromorphic chip
Loihi and conductedexperiments on five different real scenarios with an
automotive frequency modulated continuouswave radar. Experimental results
validate the algorithm, and we hope they prompt the design of adhoc
neuromorphic chips that can improve the efficiency of state-of-the-art digital
signal processorsand encourage research on neuromorphic computing for signal
processing."
2458,"We
see this as a motivation for designing ad hoc neuromorphic chips that are highly specialized in performing the FT. We
hope that this work encourages further research on the design of novel hardware architectures that leverage the potential
of neuromorphic hardware to create signal processing solutions faster and more efÔ¨Åcient than current state-of-the-art
solutions.","However, the computational
performance of the proposed work is behind FT accelerators in terms of energy consumption and execution time.","We believe that replacing the general-purpose board used for the experiments with a chip that implements a
neuron model and a connection grid tailored for the proposed algorithm would signiÔ¨Åcantly improve the computational
performance of the algorithm and would outperform the traditional solutions used today to implement the FT.",2022-02-25 12:15:46+00:00,Time-coded Spiking Fourier Transform in Neuromorphic Hardware,cs.NE,"['cs.NE', 'eess.SP']","[arxiv.Result.Author('Javier L√≥pez-Randulfe'), arxiv.Result.Author('Nico Reeb'), arxiv.Result.Author('Negin Karimi'), arxiv.Result.Author('Chen Liu'), arxiv.Result.Author('Hector A. Gonzalez'), arxiv.Result.Author('Robin Dietrich'), arxiv.Result.Author('Bernhard Vogginger'), arxiv.Result.Author('Christian Mayr'), arxiv.Result.Author('Alois Knoll')]","After several decades of continuously optimizing computing systems, the
Moore's law is reaching itsend. However, there is an increasing demand for fast
and efficient processing systems that can handlelarge streams of data while
decreasing system footprints. Neuromorphic computing answers thisneed by
creating decentralized architectures that communicate with binary events over
time. Despiteits rapid growth in the last few years, novel algorithms are
needed that can leverage the potential ofthis emerging computing paradigm and
can stimulate the design of advanced neuromorphic chips.In this work, we
propose a time-based spiking neural network that is mathematically equivalent
tothe Fourier transform. We implemented the network in the neuromorphic chip
Loihi and conductedexperiments on five different real scenarios with an
automotive frequency modulated continuouswave radar. Experimental results
validate the algorithm, and we hope they prompt the design of adhoc
neuromorphic chips that can improve the efficiency of state-of-the-art digital
signal processorsand encourage research on neuromorphic computing for signal
processing."
2459,"By means of this paper we aim to stimulate further research on the application of time-based SNNs for signal process-
ing.","Moreover,
the implementation of the proposed model and other SNNs is restrained by the contemporary absence of commercial
neuromorphic chips.","The S-FT can serve as the initial stage for larger processing pipelines, providing input for higher-level operations
performed by other time-based SNNs, such as object detection, tracking, or classiÔ¨Åcation.",2022-02-25 12:15:46+00:00,Time-coded Spiking Fourier Transform in Neuromorphic Hardware,cs.NE,"['cs.NE', 'eess.SP']","[arxiv.Result.Author('Javier L√≥pez-Randulfe'), arxiv.Result.Author('Nico Reeb'), arxiv.Result.Author('Negin Karimi'), arxiv.Result.Author('Chen Liu'), arxiv.Result.Author('Hector A. Gonzalez'), arxiv.Result.Author('Robin Dietrich'), arxiv.Result.Author('Bernhard Vogginger'), arxiv.Result.Author('Christian Mayr'), arxiv.Result.Author('Alois Knoll')]","After several decades of continuously optimizing computing systems, the
Moore's law is reaching itsend. However, there is an increasing demand for fast
and efficient processing systems that can handlelarge streams of data while
decreasing system footprints. Neuromorphic computing answers thisneed by
creating decentralized architectures that communicate with binary events over
time. Despiteits rapid growth in the last few years, novel algorithms are
needed that can leverage the potential ofthis emerging computing paradigm and
can stimulate the design of advanced neuromorphic chips.In this work, we
propose a time-based spiking neural network that is mathematically equivalent
tothe Fourier transform. We implemented the network in the neuromorphic chip
Loihi and conductedexperiments on five different real scenarios with an
automotive frequency modulated continuouswave radar. Experimental results
validate the algorithm, and we hope they prompt the design of adhoc
neuromorphic chips that can improve the efficiency of state-of-the-art digital
signal processorsand encourage research on neuromorphic computing for signal
processing."
3452,"proof of concept motivates further study into usage of diversity in
                                                                                                              ùúÉ ‚ààŒò ùúã ‚ààŒ†

algorithm configuration, for example by changing the AC problem‚Äôs              The parameter space can be continuous, integer, categorical, and
objective from finding a ‚Äúsingle‚Äù optimum to selecting a diverse set        mixed-integer.","This           a configuration ùúÉ ‚àó ‚àà arg min ùëê (ùúÉ, ùúã).","In addition, some parameters can be conditional and
of well-performing configurations.",2022-03-17 10:34:30+00:00,Non-Elitist Selection among Survivor Configurations can Improve the Performance of Irace,cs.NE,['cs.NE'],"[arxiv.Result.Author('Furong Ye'), arxiv.Result.Author('Diederick L. Vermetten'), arxiv.Result.Author('Carola Doerr'), arxiv.Result.Author('Thomas B√§ck')]","Modern optimization strategies such as evolutionary algorithms, ant colony
algorithms, Bayesian optimization techniques, etc.~come with several parameters
that steer their behavior during the optimization process. To obtain
high-performing algorithm instances, automated algorithm configuration
techniques have been developed. One of the most popular tools is irace, which
evaluates configurations in sequential races, at the end of which a statistical
test is used to determine the set of survivor configurations. It then selects
up to five elite configurations from this set, via greedy truncation selection.
  We demonstrate that an alternative selection of the elites can improve the
performance of irace. Our strategy keeps the best survivor and selects the
remaining configurations uniformly at random from the set of survivors. We
apply this alternative selection method to tune ant colony optimization
algorithms for traveling salesperson problems and to configure an exact tree
search solver for satisfiability problems.
  We also experiment with two non-elitist selection criteria, based on entropy
and Gower's distance, respectively. Both methods provide more diverse
configurations than irace, making them an interesting approach for exploring a
wide range of solutions and understanding algorithms' performance. Moreover,
the entropy-based selection performs better on our benchmarks than the default
selection of irace."
3453,"configurations than the elitist selection, there seems to be a lot of
room for further study.","In the context of algo-

   Since we have shown that even a completely random selection                   rithm selection, such approaches are studied under the notion of
procedure can potentially lead to irace returning better performing              algorithm portfolio selection [24].","While the two non-elitist selection methods              REFERENCES
present improvement in the performance of irace via exploring
diverse configurations, we did not modify the procedure of sampling               [1] Anonym, N. Data Sets for the study ""Non-Elitist Selection among Survivor
new configurations.",2022-03-17 10:34:30+00:00,Non-Elitist Selection among Survivor Configurations can Improve the Performance of Irace,cs.NE,['cs.NE'],"[arxiv.Result.Author('Furong Ye'), arxiv.Result.Author('Diederick L. Vermetten'), arxiv.Result.Author('Carola Doerr'), arxiv.Result.Author('Thomas B√§ck')]","Modern optimization strategies such as evolutionary algorithms, ant colony
algorithms, Bayesian optimization techniques, etc.~come with several parameters
that steer their behavior during the optimization process. To obtain
high-performing algorithm instances, automated algorithm configuration
techniques have been developed. One of the most popular tools is irace, which
evaluates configurations in sequential races, at the end of which a statistical
test is used to determine the set of survivor configurations. It then selects
up to five elite configurations from this set, via greedy truncation selection.
  We demonstrate that an alternative selection of the elites can improve the
performance of irace. Our strategy keeps the best survivor and selects the
remaining configurations uniformly at random from the set of survivors. We
apply this alternative selection method to tune ant colony optimization
algorithms for traveling salesperson problems and to configure an exact tree
search solver for satisfiability problems.
  We also experiment with two non-elitist selection criteria, based on entropy
and Gower's distance, respectively. Both methods provide more diverse
configurations than irace, making them an interesting approach for exploring a
wide range of solutions and understanding algorithms' performance. Moreover,
the entropy-based selection performs better on our benchmarks than the default
selection of irace."
3454,"Therefore, there is still room
for further study of incorporating diversity into the selection operators.","While the irace-entropy presents improvement in the performance of irace
via exploring diverse conÔ¨Ågurations in all the tested scenarios, irace-rand obtain
better conÔ¨Ågurations for speciÔ¨Åc SPEAR instances.","Also, we
did not modify the procedure of sampling new conÔ¨Ågurations.",2022-03-17 10:34:30+00:00,Non-Elitist Selection among Survivor Configurations can Improve the Performance of Irace,cs.NE,['cs.NE'],"[arxiv.Result.Author('Furong Ye'), arxiv.Result.Author('Diederick L. Vermetten'), arxiv.Result.Author('Carola Doerr'), arxiv.Result.Author('Thomas B√§ck')]","Modern optimization strategies such as evolutionary algorithms, ant colony
algorithms, Bayesian optimization techniques, etc.~come with several parameters
that steer their behavior during the optimization process. To obtain
high-performing algorithm instances, automated algorithm configuration
techniques have been developed. One of the most popular tools is irace, which
evaluates configurations in sequential races, making use of iterated
statistical tests to discard poorly performing configurations. At the end of
the race, a set of elite configurations are selected from those survivor
configurations which were not discarded, using greedy truncation selection.
  We study two alternative selection methods: one keeps the best survivor and
selects the remaining configurations uniformly at random from the set of
survivors while the other applies entropy to maximize the diversity of the
elites. These methods are tested for tuning ant colony optimization algorithms
for traveling salesperson problems and the quadratic assignment problem and
tuning an exact tree search solver for satisfiability problems. The
experimental results show improvement on the tested benchmarks compared to the
default selection of irace. In addition, the obtained results indicate that
non-elitist can obtain diverse algorithm configurations, which encourages us to
explore a wider range of solutions to understand the behavior of algorithms."
3455,"Therefore, there is still room
for further study of incorporating diversity into the selection operators.","While the irace-entropy presents improvement in the performance of irace
via exploring diverse conÔ¨Ågurations in all the tested scenarios, irace-rand obtain
better conÔ¨Ågurations for speciÔ¨Åc SPEAR instances.","More in-
depth analysis on a wider set of algorithm conÔ¨Åguration problems can help us
better understand the beneÔ¨Åts of considering diversity in selection.",2022-03-17 10:34:30+00:00,Non-Elitist Selection Can Improve the Performance of Irace,cs.NE,['cs.NE'],"[arxiv.Result.Author('Furong Ye'), arxiv.Result.Author('Diederick L. Vermetten'), arxiv.Result.Author('Carola Doerr'), arxiv.Result.Author('Thomas B√§ck')]","Modern optimization strategies such as evolutionary algorithms, ant colony
algorithms, Bayesian optimization techniques, etc. come with several parameters
that steer their behavior during the optimization process. To obtain
high-performing algorithm instances, automated algorithm configuration
techniques have been developed. One of the most popular tools is irace, which
evaluates configurations in sequential races, making use of iterated
statistical tests to discard poorly performing configurations. At the end of
the race, a set of elite configurations are selected from those survivor
configurations that were not discarded, using greedy truncation selection. We
study two alternative selection methods: one keeps the best survivor and
selects the remaining configurations uniformly at random from the set of
survivors, while the other applies entropy to maximize the diversity of the
elites. These methods are tested for tuning ant colony optimization algorithms
for traveling salesperson problems and the quadratic assignment problem and
tuning an exact tree search solver for satisfiability problems. The
experimental results show improvement on the tested benchmarks compared to the
default selection of irace. In addition, the obtained results indicate that
non-elitist can obtain diverse algorithm configurations, which encourages us to
explore a wider range of solutions to understand the behavior of algorithms."
3652,"Afterwards, we investigate the properties of landscape
features in the context of the training set selection methods and select the most convenient
features for further research.","Then, we present our set of new landscape features
based on the CMA-ES state variables.","Finally, we analyse relationships between the selected features
and measured errors of the surrogate models with various settings.",2022-02-11 21:06:56+00:00,Landscape Analysis for Surrogate Models in the Evolutionary Black-Box Context,cs.NE,"['cs.NE', 'cs.LG', 'math.OC']","[arxiv.Result.Author('Zbynƒõk Pitra'), arxiv.Result.Author('Jan Koza'), arxiv.Result.Author('Ji≈ô√≠ Tumpach'), arxiv.Result.Author('Martin Hole≈àa')]","Surrogate modeling has become a valuable technique for black-box optimization
tasks with expensive evaluation of the objective function. In this paper, we
investigate the relationship between the predictive accuracy of surrogate
models and features of the black-box function landscape. We also study
properties of features for landscape analysis in the context of different
transformations and ways of selecting the input data. We perform the landscape
analysis of a large set of data generated using runs of a surrogate-assisted
version of the Covariance Matrix Adaptation Evolution Strategy on the noiseless
part of the Comparing Continuous Optimisers benchmark function testbed."
3653,"Afterwards, we investigate the
properties of landscape features in the context of the training set selection methods and
select the most convenient features for further research.","Then, we present our set of new land-
scape features based on the CMA-ES state variables.","Finally, we analyse relation-
ships between the selected features and measured errors of the surrogate models with
various settings.",2022-02-11 21:06:56+00:00,Landscape Analysis for Surrogate Models in the Evolutionary Black-Box Context,cs.NE,"['cs.NE', 'cs.LG', 'math.OC']","[arxiv.Result.Author('Zbynƒõk Pitra'), arxiv.Result.Author('Jan Koza'), arxiv.Result.Author('Ji≈ô√≠ Tumpach'), arxiv.Result.Author('Martin Hole≈àa')]","Surrogate modeling has become a valuable technique for black-box optimization
tasks with expensive evaluation of the objective function. In this paper, we
investigate the relationship between the predictive accuracy of surrogate
models and features of the black-box function landscape. We also study
properties of features for landscape analysis in the context of different
transformations and ways of selecting the input data. We perform the landscape
analysis of a large set of data generated using runs of a surrogate-assisted
version of the Covariance Matrix Adaptation Evolution Strategy on the noiseless
part of the Comparing Continuous Optimisers benchmark function testbed."
3775,"Although safe optimization was
                                        ceptable guidelines on how to benchmark different algorithms for         first considered by the EC community in 2009 [10] and 2011 [1], we
                                        SafeOPs, an area where the EC community has significant expe-            are not aware of any further research on this topic.","Moreover, there is a lack of ac-         safe GP algorithm, respectively).","In comparison,
                                        rience in.",2022-03-24 17:11:36+00:00,Are Evolutionary Algorithms Safe Optimizers?,cs.NE,"['cs.NE', 'cs.LG', 'cs.SY', 'eess.SY', 'I.2.8']","[arxiv.Result.Author('Youngmin Kim'), arxiv.Result.Author('Richard Allmendinger'), arxiv.Result.Author('Manuel L√≥pez-Ib√°√±ez')]","We consider a type of constrained optimization problem, where the violation
of a constraint leads to an irrevocable loss, such as breakage of a valuable
experimental resource/platform or loss of human life. Such problems are
referred to as safe optimization problems (SafeOPs). While SafeOPs have
received attention in the machine learning community in recent years, there was
little interest in the evolutionary computation (EC) community despite some
early attempts between 2009 and 2011. Moreover, there is a lack of acceptable
guidelines on how to benchmark different algorithms for SafeOPs, an area where
the EC community has significant experience in. Driven by the need for more
efficient algorithms and benchmark guidelines for SafeOPs, the objective of
this paper is to reignite the interest of this problem class in the EC
community. To achieve this we (i) provide a formal definition of SafeOPs and
contrast it to other types of optimization problems that the EC community is
familiar with, (ii) investigate the impact of key SafeOP parameters on the
performance of selected safe optimization algorithms, (iii) benchmark EC
against state-of-the-art safe optimization algorithms from the machine learning
community, and (iv) provide an open-source Python framework to replicate and
extend our work."
3776,"Driven by the need for more efficient algorithms and                     and 2011 [1, 2], we are not aware of any further research on this
                                       benchmark guidelines for SafeOPs, the objective of this paper is                    topic.","Although safe opti-
                                       SafeOPs, an area where the EC community has significant expe-                       mization was first considered by the EC community in 2009 [13]
                                       rience in.","In comparison, the machine learning community has actively
                                       to reignite the interest of the EC community in this problem class.",2022-03-24 17:11:36+00:00,Are Evolutionary Algorithms Safe Optimizers?,cs.NE,"['cs.NE', 'cs.LG', 'cs.SY', 'eess.SY', 'I.2.8']","[arxiv.Result.Author('Youngmin Kim'), arxiv.Result.Author('Richard Allmendinger'), arxiv.Result.Author('Manuel L√≥pez-Ib√°√±ez')]","We consider a type of constrained optimization problem, where the violation
of a constraint leads to an irrevocable loss, such as breakage of a valuable
experimental resource/platform or loss of human life. Such problems are
referred to as safe optimization problems (SafeOPs). While SafeOPs have
received attention in the machine learning community in recent years, there was
little interest in the evolutionary computation (EC) community despite some
early attempts between 2009 and 2011. Moreover, there is a lack of acceptable
guidelines on how to benchmark different algorithms for SafeOPs, an area where
the EC community has significant experience in. Driven by the need for more
efficient algorithms and benchmark guidelines for SafeOPs, the objective of
this paper is to reignite the interest of this problem class in the EC
community. To achieve this we (i) provide a formal definition of SafeOPs and
contrast it to other types of optimization problems that the EC community is
familiar with, (ii) investigate the impact of key SafeOP parameters on the
performance of selected safe optimization algorithms, (iii) benchmark EC
against state-of-the-art safe optimization algorithms from the machine learning
community, and (iv) provide an open-source Python framework to replicate and
extend our work."
4498,"[11] K. Rahimkhani, A. Aleahmad, M. Rahgozar, and A. Moeini, ‚ÄúA fast
   Because of the broad application of IM, the following topics             algorithm for finding most influential people based on the linear threshold
deserve further research.",obtain a high-quality seed set with a lower computational cost.,"Firstly, it is still worthwhile to explore        model,‚Äù Expert Systems with Applications, vol.",2022-04-07 08:53:42+00:00,A Multi-Transformation Evolutionary Framework for Influence Maximization in Social Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.SI']","[arxiv.Result.Author('Chao Wang'), arxiv.Result.Author('Jiaxuan Zhao'), arxiv.Result.Author('Lingling Li'), arxiv.Result.Author('Licheng Jiao'), arxiv.Result.Author('Jing Liu'), arxiv.Result.Author('Kai Wu')]","Influence maximization is a key issue for mining the deep information of
social networks, which aims to select a seed set from the network to maximize
the number of influenced nodes. To evaluate the influence spread of a seed set
efficiently, existing works have proposed some proxy models (transformations)
with lower computational costs to replace the expensive Monte Carlo simulation
process. These alternate transformations based on network prior knowledge
induce different search behaviors with similar characteristics from various
perspectives. For a specific case, it is difficult for users to determine a
suitable transformation a priori. Keeping those in mind, we propose a
multi-transformation evolutionary framework for influence maximization (MTEFIM)
to exploit the potential similarities and unique advantages of alternate
transformations and avoid users to determine the most suitable one manually. In
MTEFIM, multiple transformations are optimized simultaneously as multiple
tasks. Each transformation is assigned an evolutionary solver. Three major
components of MTEFIM are conducted: 1) estimating the potential relationship
across transformations based on the degree of overlap across individuals (seed
sets) of different populations, 2) transferring individuals across populations
adaptively according to the inter-transformation relationship, 3) selecting the
final output seed set containing all the proxy model knowledge. The
effectiveness of MTEFIM is validated on four real-world social networks.
Experimental results show that MTEFIM can efficiently utilize the potentially
transferable knowledge across multiple transformations to achieve highly
competitive performance compared to several popular IM-specific methods. The
implementation of MTEFIM can be accessed at
https://github.com/xiaofangxd/MTEFIM."
4499,"(2), we have,

   Because of the broad application of IM, the following topics                                                    ÔÉ¶ 1‚àí r2 * (t ) ÔÉ∂t
deserve further research.",(1) and Eq.,"Firstly, it is still worthwhile to                    ps (x,t) ÔÇ≥ ps (x, 0) ÔÉß                               s, j                ÔÉ∑    ,ÔÄ¢x : ÔÅ≥ s              (  x  )     ÔÄæ     ÔÅ≥  '  .",2022-04-07 08:53:42+00:00,A Multi-Transformation Evolutionary Framework for Influence Maximization in Social Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.SI']","[arxiv.Result.Author('Chao Wang'), arxiv.Result.Author('Jiaxuan Zhao'), arxiv.Result.Author('Lingling Li'), arxiv.Result.Author('Licheng Jiao'), arxiv.Result.Author('Jing Liu'), arxiv.Result.Author('Kai Wu')]","Influence maximization is a crucial issue for mining the deep information of
social networks, which aims to select a seed set from the network to maximize
the number of influenced nodes. To evaluate the influence spread of a seed set
efficiently, existing efforts have proposed proxy models (transformations) with
lower computational costs to replace the expensive Monte Carlo simulation
process. These alternate transformations based on network prior knowledge
induce different search behaviors with similar characteristics from various
perspectives. For a specific case, it is difficult for users to determine a
suitable transformation a priori. In this paper, we propose a
multi-transformation evolutionary framework for influence maximization (MTEFIM)
with convergence guarantees to exploit the potential similarities and unique
advantages of alternate transformations and avoid users manually determining
the most suitable one. In MTEFIM, multiple transformations are optimized
simultaneously as multiple tasks. Each transformation is assigned an
evolutionary solver. Three major components of MTEFIM are conducted: 1)
estimating the potential relationship across transformations based on the
degree of overlap across individuals (seed sets) of different populations, 2)
transferring individuals across populations adaptively according to the
inter-transformation relationship, 3) selecting the final output seed set
containing all the proxy model knowledge. The effectiveness of MTEFIM is
validated on both benchmarks and real-world social networks. Experimental
results show that MTEFIM can efficiently utilize the potentially transferable
knowledge across multiple transformations to achieve highly competitive
performance compared to several popular IM-specific methods. The implementation
of MTEFIM can be accessed at https://github.com/xiaofangxd/MTEFIM."
4500,"(2), we have,

   Because of the broad application potential of IM, the                                                                                                   ÔÉ¶ 1‚àí r2 * (t ) ÔÉ∂t
following topics deserve further research.",(1) and Eq.,"First, it is still                                                           ps (x, t) ÔÇ≥ ps (x, 0) ÔÉß                          s, j               ÔÉ∑     ,  ÔÄ¢x          :  ÔÅ≥        (  x  )  ÔÄæ  ÔÅ≥  '  .",2022-04-07 08:53:42+00:00,A Multi-Transformation Evolutionary Framework for Influence Maximization in Social Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.SI']","[arxiv.Result.Author('Chao Wang'), arxiv.Result.Author('Jiaxuan Zhao'), arxiv.Result.Author('Lingling Li'), arxiv.Result.Author('Licheng Jiao'), arxiv.Result.Author('Jing Liu'), arxiv.Result.Author('Kai Wu')]","Influence maximization is a crucial issue for mining the deep information of
social networks, which aims to select a seed set from the network to maximize
the number of influenced nodes. To evaluate the influence spread of a seed set
efficiently, existing studies have proposed transformations with lower
computational costs to replace the expensive Monte Carlo simulation process.
These alternate transformations, based on network prior knowledge, induce
different search behaviors with similar characteristics to various
perspectives. Specifically, it is difficult for users to determine a suitable
transformation a priori. This article proposes a multi-transformation
evolutionary framework for influence maximization (MTEFIM) with convergence
guarantees to exploit the potential similarities and unique advantages of
alternate transformations and to avoid users manually determining the most
suitable one. In MTEFIM, multiple transformations are optimized simultaneously
as multiple tasks. Each transformation is assigned an evolutionary solver.
Three major components of MTEFIM are conducted via: 1) estimating the potential
relationship across transformations based on the degree of overlap across
individuals of different populations, 2) transferring individuals across
populations adaptively according to the inter-transformation relationship, and
3) selecting the final output seed set containing all the transformation's
knowledge. The effectiveness of MTEFIM is validated on both benchmarks and
real-world social networks. The experimental results show that MTEFIM can
efficiently utilize the potentially transferable knowledge across multiple
transformations to achieve highly competitive performance compared to several
popular IM-specific methods. The implementation of MTEFIM can be accessed at
https://github.com/xiaofangxd/MTEFIM."
4544,"We believe that further research is needed
                                                              to better quantify this type of complexity.",optimum.,Fig.,2022-04-06 13:19:41+00:00,Automatic inference of fault tree models via multi-objective evolutionary algorithms,cs.NE,['cs.NE'],"[arxiv.Result.Author('Lisandro A. Jimenez-Roa'), arxiv.Result.Author('Tom Heskes'), arxiv.Result.Author('Tiedo Tinga'), arxiv.Result.Author('Marielle Stoelinga')]","Fault tree analysis is a well-known technique in reliability engineering and
risk assessment, which supports decision-making processes and the management of
complex systems. Traditionally, fault tree (FT) models are built manually
together with domain experts, considered a time-consuming process prone to
human errors. With Industry 4.0, there is an increasing availability of
inspection and monitoring data, making techniques that enable knowledge
extraction from large data sets relevant. Thus, our goal with this work is to
propose a data-driven approach to infer efficient FT structures that achieve a
complete representation of the failure mechanisms contained in the failure data
set without human intervention. Our algorithm, the FT-MOEA, based on
multi-objective evolutionary algorithms, enables the simultaneous optimization
of different relevant metrics such as the FT size, the error computed based on
the failure data set and the Minimal Cut Sets. Our results show that, for six
case studies from the literature, our approach successfully achieved automatic,
efficient, and consistent inference of the associated FT models. We also
present the results of a parametric analysis that tests our algorithm for
different relevant conditions that influence its performance, as well as an
overview of the data-driven methods used to automatically infer FT models."
4596,"It should
be confirmed in further research works.","Since the SNN proposed has no features explicitly depending on the RL task solved, it is reasonable
to hope that the approach developed in this study will be applicable to wide range of RL tasks.","Particularly, the next stages of this research project should
include:

    ÔÇ∑ application of the approach described to the standard RL benchmarks ‚Äì to compare it with the
         state-of-the-art methods;

    ÔÇ∑ extension of my approach to the RL tasks where memory should be a necessary element.",2022-04-09 09:08:10+00:00,A Spiking Neural Network Structure Implementing Reinforcement Learning,cs.NE,['cs.NE'],[arxiv.Result.Author('Mikhail Kiselev')],"At present, implementation of learning mechanisms in spiking neural networks
(SNN) cannot be considered as a solved scientific problem despite plenty of SNN
learning algorithms proposed. It is also true for SNN implementation of
reinforcement learning (RL), while RL is especially important for SNNs because
of its close relationship to the domains most promising from the viewpoint of
SNN application such as robotics. In the present paper, I describe an SNN
structure which, seemingly, can be used in wide range of RL tasks. The
distinctive feature of my approach is usage of only the spike forms of all
signals involved - sensory input streams, output signals sent to actuators and
reward/punishment signals. Besides that, selecting the neuron/plasticity
models, I was guided by the requirement that they should be easily implemented
on modern neurochips. The SNN structure considered in the paper includes
spiking neurons described by a generalization of the LIFAT (leaky
integrate-and-fire neuron with adaptive threshold) model and a simple spike
timing dependent synaptic plasticity model (a generalization of
dopamine-modulated plasticity). My concept is based on very general assumptions
about RL task characteristics and has no visible limitations on its
applicability. To test it, I selected a simple but non-trivial task of training
the network to keep a chaotically moving light spot in the view field of an
emulated DVS camera. Successful solution of this RL problem by the SNN
described can be considered as evidence in favor of efficiency of my approach."
5275,"The code is written in Python 3.8                Hyperparameters         10       Hyperparameters         100
and will be made open access later for the convenience of                                                                       60
experimental reproduction and further research.","EXPERIMENTAL SETUP                                             TABLE II
                                                                      HYPERPARAMETER CONFIGURATIONS
   All experiments are conducted on a PC with an AMD 8-
Core R7-5800H CPU @3.2 GHz, 16 GB of RAM and a                                        DRL   Value                     EA      Value
single RTX 3060 GPU.","Additionally,            No.",2022-04-25 11:45:31+00:00,Deep Reinforcement Learning for Orienteering Problems Based on Decomposition,cs.NE,['cs.NE'],"[arxiv.Result.Author('Wei Liu'), arxiv.Result.Author('Tao Zhang'), arxiv.Result.Author('Rui Wang'), arxiv.Result.Author('Kaiwen Li'), arxiv.Result.Author('Wenhua Li'), arxiv.Result.Author('Kang Yang')]","This paper presents a new method for solving an orienteering problem (OP) by
breaking it down into two parts: a knapsack problem (KP) and a traveling
salesman problem (TSP). A KP solver is responsible for picking nodes, while a
TSP solver is responsible for designing the proper path and assisting the KP
solver in judging constraint violations. To address constraints, we propose a
dual-population coevolutionary algorithm (DPCA) as the KP solver, which
simultaneously maintains both feasible and infeasible populations. A dynamic
pointer network (DYPN) is introduced as the TSP solver, which takes city
locations as inputs and immediately outputs a permutation of nodes. The model,
which is trained by reinforcement learning, can capture both the structural and
dynamic patterns of the given problem. The model can generalize to other
instances with different scales and distributions. Experimental results show
that the proposed algorithm can outperform conventional approaches in terms of
training, inference, and generalization ability."
5596,"This fact hurts the energy efficiency of SNNs when
with low latency, we further study the representation error         using the conversion method.",To effectively train SNNs       tion.,"Furthermore, the conversion
due to the SNN-to-mapping approximation, and propose to             method is not suitable for neuromorphic data.",2022-05-01 12:44:49+00:00,Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Qingyan Meng'), arxiv.Result.Author('Mingqing Xiao'), arxiv.Result.Author('Shen Yan'), arxiv.Result.Author('Yisen Wang'), arxiv.Result.Author('Zhouchen Lin'), arxiv.Result.Author('Zhi-Quan Luo')]","Spiking Neural Network (SNN) is a promising energy-efficient AI model when
implemented on neuromorphic hardware. However, it is a challenge to efficiently
train SNNs due to their non-differentiability. Most existing methods either
suffer from high latency (i.e., long simulation time steps), or cannot achieve
as high performance as Artificial Neural Networks (ANNs). In this paper, we
propose the Differentiation on Spike Representation (DSR) method, which could
achieve high performance that is competitive to ANNs yet with low latency.
First, we encode the spike trains into spike representation using (weighted)
firing rate coding. Based on the spike representation, we systematically derive
that the spiking dynamics with common neural models can be represented as some
sub-differentiable mapping. With this viewpoint, our proposed DSR method trains
SNNs through gradients of the mapping and avoids the common
non-differentiability problem in SNN training. Then we analyze the error when
representing the specific mapping with the forward computation of the SNN. To
reduce such error, we propose to train the spike threshold in each layer, and
to introduce a new hyperparameter for the neural models. With these components,
the DSR method can achieve state-of-the-art SNN performance with low latency on
both static and neuromorphic datasets, including CIFAR-10, CIFAR-100, ImageNet,
and DVS-CIFAR10."
5998,"Limited by the sample sizes, this paper does not involve further study on
other important factors.","The results also enlighten us to focus more on the initialization
methods to get better accuracy when using machine learning models in practice.","For example, deeper neural networks are expected to
perform better than the 3-layer conÔ¨Åguration given more training samples.",2022-05-10 10:36:31+00:00,Neural Networks with Different Initialization Methods for Depression Detection,cs.NE,['cs.NE'],[arxiv.Result.Author('Tianle Yang')],"As a common mental disorder, depression is a leading cause of various
diseases worldwide. Early detection and treatment of depression can
dramatically promote remission and prevent relapse. However, conventional ways
of depression diagnosis require considerable human effort and cause economic
burden, while still being prone to misdiagnosis. On the other hand, recent
studies report that physical characteristics are major contributors to the
diagnosis of depression, which inspires us to mine the internal relationship by
neural networks instead of relying on clinical experiences. In this paper,
neural networks are constructed to predict depression from physical
characteristics. Two initialization methods are examined - Xaiver and Kaiming
initialization. Experimental results show that a 3-layers neural network with
Kaiming initialization achieves $83\%$ accuracy."
6237,"Thus we hope that in the future, this work will serve as inspiration for further research
and novel ideas in the direction of feature exploration, feature and prediction interpretability,
and channel selection.","This approach can be adapted to ChannelAppend
and be used in an analogous way for channel comparison, channel selection, and potentially
seizure localization.","More speciÔ¨Åcally, for epileptic seizure detection, seizure localization
and more detailed feature quality assessment for diÔ¨Äerent seizure-type classiÔ¨Åcations could
be research venues.",2022-05-16 13:18:37+00:00,Hyperdimensional computing encoding for feature selection on the use case of epileptic seizure detection,cs.NE,"['cs.NE', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Una Pale'), arxiv.Result.Author('Tomas Teijeiro'), arxiv.Result.Author('David Atienza')]","The healthcare landscape is moving from the reactive interventions focused on
symptoms treatment to a more proactive prevention, from one-size-fits-all to
personalized medicine, and from centralized to distributed paradigms. Wearable
IoT devices and novel algorithms for continuous monitoring are essential
components of this transition. Hyperdimensional (HD) computing is an emerging
ML paradigm inspired by neuroscience research with various aspects interesting
for IoT devices and biomedical applications. Here we explore the not yet
addressed topic of optimal encoding of spatio-temporal data, such as
electroencephalogram (EEG) signals, and all information it entails to the HD
vectors. Further, we demonstrate how the HD computing framework can be used to
perform feature selection by choosing an adequate encoding. To the best of our
knowledge, this is the first approach to performing feature selection using HD
computing in the literature. As a result, we believe it can support the ML
community to further foster the research in multiple directions related to
feature and channel selection, as well as model interpretability."
6238,"Overall, we expect that this work can
serve as inspiration for further research and novel ideas in the direction of feature exploration,
feature and prediction interpretability, and channel selection.","Three approaches were tested
and led to a signiÔ¨Åcant reduction of features, while keeping or even signiÔ¨Åcantly improving
the performance compared to using all the features.","References

Fatemeh Asgarinejad, Anthony Thomas, and Tajana Rosing.",2022-05-16 13:18:37+00:00,Hyperdimensional computing encoding for feature selection on the use case of epileptic seizure detection,cs.NE,"['cs.NE', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Una Pale'), arxiv.Result.Author('Tomas Teijeiro'), arxiv.Result.Author('David Atienza')]","The healthcare landscape is moving from the reactive interventions focused on
symptoms treatment to a more proactive prevention, from one-size-fits-all to
personalized medicine, and from centralized to distributed paradigms. Wearable
IoT devices and novel algorithms for continuous monitoring are essential
components of this transition. Hyperdimensional (HD) computing is an emerging
ML paradigm inspired by neuroscience research with various aspects interesting
for IoT devices and biomedical applications. Here we explore the not yet
addressed topic of optimal encoding of spatio-temporal data, such as
electroencephalogram (EEG) signals, and all information it entails to the HD
vectors. Further, we demonstrate how the HD computing framework can be used to
perform feature selection by choosing an adequate encoding. To the best of our
knowledge, this is the first approach to performing feature selection using HD
computing in the literature. As a result, we believe it can support the ML
community to further foster the research in multiple directions related to
feature and channel selection, as well as model interpretability."
6477,"We share our code online for       database has annotations for heartbeat class information verified
further research and experimentation.","The
this work is included in Section 4.",1                                by independent experts.,2022-05-12 17:27:38+00:00,Evolving SimGANs to Improve Abnormal Electrocardiogram Classification,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG', 'I.2']","[arxiv.Result.Author('Gabriel Wang'), arxiv.Result.Author('Anish Thite'), arxiv.Result.Author('Rodd Talebi'), arxiv.Result.Author(""Anthony D'Achille""), arxiv.Result.Author('Alex Mussa'), arxiv.Result.Author('Jason Zutty')]","Machine Learning models are used in a wide variety of domains. However,
machine learning methods often require a large amount of data in order to be
successful. This is especially troublesome in domains where collecting
real-world data is difficult and/or expensive. Data simulators do exist for
many of these domains, but they do not sufficiently reflect the real world data
due to factors such as a lack of real-world noise. Recently generative
adversarial networks (GANs) have been modified to refine simulated image data
into data that better fits the real world distribution, using the SimGAN
method. While evolutionary computing has been used for GAN evolution, there are
currently no frameworks that can evolve a SimGAN. In this paper we (1) extend
the SimGAN method to refine one-dimensional data, (2) modify Easy Cartesian
Genetic Programming (ezCGP), an evolutionary computing framework, to create
SimGANs that more accurately refine simulated data, and (3) create new
feature-based quantitative metrics to evaluate refined data. We also use our
framework to augment an electrocardiogram (ECG) dataset, a domain that suffers
from the issues previously mentioned. In particular, while healthy ECGs can be
simulated there are no current simulators of abnormal ECGs. We show that by
using an evolved SimGAN to refine simulated healthy ECG data to mimic
real-world abnormal ECGs, we can improve the accuracy of abnormal ECG
classifiers."
6766,"Now it is not clear how small this number should be and would require
further study as it depends on the efÔ¨Åciency of the recurrent network to recover the prime attractor given noisy input.","That is, P (kaS > 1) is close to one
and 1‚àíc2c2 P (kaT > 1) is less than one if we want the number of neurons to Ô¨Åre not part of the output prime attractor to

                                           28
                                                    The Neuro-Symbolic Brain

be less than the number of neurons part of it.","As  an  example  assume  that  c1  =  c2  =    30   and   that  the  number    of  connections    per  neuron  serving   the  connection  is
                                             10000
                                                                       1
3000 which   means   that  Œ∏  =  9.",2022-05-13 00:39:19+00:00,The Neuro-Symbolic Brain,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG', 'I.2.0; I.2.6']",[arxiv.Result.Author('Robert Liz√©e')],"Neural networks promote a distributed representation with no clear place for
symbols. Despite this, we propose that symbols are manufactured simply by
training a sparse random noise as a self-sustaining attractor in a feedback
spiking neural network. This way, we can generate many of what we shall call
prime attractors, and the networks that support them are like registers holding
a symbolic value, and we call them registers. Like symbols, prime attractors
are atomic and devoid of any internal structure. Moreover, the winner-take-all
mechanism naturally implemented by spiking neurons enables registers to recover
a prime attractor within a noisy signal. Using this faculty, when considering
two connected registers, an input one and an output one, it is possible to bind
in one shot using a Hebbian rule the attractor active on the output to the
attractor active on the input. Thus, whenever an attractor is active on the
input, it induces its bound attractor on the output; even though the signal
gets blurrier with more bindings, the winner-take-all filtering faculty can
recover the bound prime attractor. However, the capacity is still limited. It
is also possible to unbind in one shot, restoring the capacity taken by that
binding. This mechanism serves as a basis for working memory, turning prime
attractors into variables. Also, we use a random second-order network to
amalgamate the prime attractors held by two registers to bind the prime
attractor held by a third register to them in one shot, de facto implementing a
hash table. Furthermore, we introduce the register switch box composed of
registers to move the content of one register to another. Then, we use spiking
neurons to build a toy symbolic computer based on the above. The technics used
suggest ways to design extrapolating, reusable, sample-efficient deep learning
networks at the cost of structural priors."
6926,"Binary encodings                                               The effect of mechanism-dependent mutation rates may be
                                                                    investigated by further research.",2.1.,"To computationally simulate JaTAM, one needs to somehow
encode its rule sets in binary strings such that realistic bio-     A simple way to characterise the parametrisation of a given
logical operators may be deÔ¨Åned.",2022-05-28 22:47:33+00:00,Biological Evolution and Genetic Algorithms: Exploring the Space of Abstract Tile Self-Assembly,cs.NE,"['cs.NE', 'physics.bio-ph']",[arxiv.Result.Author('Christian Schroeder de Witt')],"A physically-motivated genetic algorithm (GA) and full enumeration for a
tile-based model of self-assembly (JaTAM) is implemented using a graphics
processing unit (GPU). We observe performance gains with respect to
state-of-the-art implementations on CPU of factor 7.7 for the GA and 2.9 for
JaTAM. The correctness of our GA implementation is demonstrated using a
test-bed fitness function, and our JaTAM implementation is verified by
classifying a well-known search space $S_{2,8}$ based on two tile types. The
performance gains achieved allow for the classification of a larger search
space $S^{32}_{3,8}$ based on three tile types. The prevalence of structures
based on two tile types demonstrates that simple organisms emerge preferrably
even in complex ecosystems. The modularity of the largest structures found
motivates the assumption that to first order, $S_{2,8}$ forms the building
blocks of $S_{3,8}$. We conclude that GPUs may play an important role in future
studies of evolutionary dynamics."
6927,"Whether it is possible to deÔ¨Åne a
gene-interpretation for Johnston‚Äôs model that allows for strong correlations between genotypes and phenotypes is a key
question for further research.","The observation of genetic drift, however, strongly
depends on the correlation between a particular gene and its phenototypic expression.","Kolmogorov complexity K(sb) is deÔ¨Åned as the shortest program size written in a language
L which can output a bitstring sb.",2022-05-28 22:47:33+00:00,Biological Evolution and Genetic Algorithms: Exploring the Space of Abstract Tile Self-Assembly,cs.NE,"['cs.NE', 'physics.bio-ph']",[arxiv.Result.Author('Christian Schroeder de Witt')],"A physically-motivated genetic algorithm (GA) and full enumeration for a
tile-based model of self-assembly (JaTAM) is implemented using a graphics
processing unit (GPU). We observe performance gains with respect to
state-of-the-art implementations on CPU of factor 7.7 for the GA and 2.9 for
JaTAM. The correctness of our GA implementation is demonstrated using a
test-bed fitness function, and our JaTAM implementation is verified by
classifying a well-known search space $S_{2,8}$ based on two tile types. The
performance gains achieved allow for the classification of a larger search
space $S^{32}_{3,8}$ based on three tile types. The prevalence of structures
based on two tile types demonstrates that simple organisms emerge preferrably
even in complex ecosystems. The modularity of the largest structures found
motivates the assumption that to first order, $S_{2,8}$ forms the building
blocks of $S_{3,8}$. We conclude that GPUs may play an important role in future
studies of evolutionary dynamics."
6985,"However, it may still be desirable to
further study the optimization properties of IL with mini-batches to improve performance on machine
learning tasks where mini-batches are typically used.","Additionally,
when Adam optimizers are used IL still performs similarly to BP.","7 Discussion

IL was originally used to train predictive coding models of cortical circuits [37].",2022-06-01 00:38:55+00:00,A Theoretical Framework for Inference Learning,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Nick Alonso'), arxiv.Result.Author('Beren Millidge'), arxiv.Result.Author('Jeff Krichmar'), arxiv.Result.Author('Emre Neftci')]","Backpropagation (BP) is the most successful and widely used algorithm in deep
learning. However, the computations required by BP are challenging to reconcile
with known neurobiology. This difficulty has stimulated interest in more
biologically plausible alternatives to BP. One such algorithm is the inference
learning algorithm (IL). IL has close connections to neurobiological models of
cortical function and has achieved equal performance to BP on supervised
learning and auto-associative tasks. In contrast to BP, however, the
mathematical foundations of IL are not well-understood. Here, we develop a
novel theoretical framework for IL. Our main result is that IL closely
approximates an optimization method known as implicit stochastic gradient
descent (implicit SGD), which is distinct from the explicit SGD implemented by
BP. Our results further show how the standard implementation of IL can be
altered to better approximate implicit SGD. Our novel implementation
considerably improves the stability of IL across learning rates, which is
consistent with our theory, as a key property of implicit SGD is its stability.
We provide extensive simulation results that further support our theoretical
interpretations and also demonstrate IL achieves quicker convergence when
trained with small mini-batches while matching the performance of BP for large
mini-batches."
7033,"However, it is important to note that this strategy does not correct the problem; the
gap still exists compared to BPTT, suggesting room for further research.","Bottom panels show this leads to a slight improvement in generalization gap (vertical lines
denote distribution mean).","Plotting conventions follow that of the
previous Ô¨Ågures.",2022-06-02 01:39:08+00:00,Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules,cs.NE,"['cs.NE', 'cs.AI', 'q-bio.NC']","[arxiv.Result.Author('Yuhan Helena Liu'), arxiv.Result.Author('Arna Ghosh'), arxiv.Result.Author('Blake A. Richards'), arxiv.Result.Author('Eric Shea-Brown'), arxiv.Result.Author('Guillaume Lajoie')]","To unveil how the brain learns, ongoing work seeks biologically-plausible
approximations of gradient descent algorithms for training recurrent neural
networks (RNNs). Yet, beyond task accuracy, it is unclear if such learning
rules converge to solutions that exhibit different levels of generalization
than their nonbiologically-plausible counterparts. Leveraging results from deep
learning theory based on loss landscape curvature, we ask: how do
biologically-plausible gradient approximations affect generalization? We first
demonstrate that state-of-the-art biologically-plausible learning rules for
training RNNs exhibit worse and more variable generalization performance
compared to their machine learning counterparts that follow the true gradient
more closely. Next, we verify that such generalization performance is
correlated significantly with loss landscape curvature, and we show that
biologically-plausible learning rules tend to approach high-curvature regions
in synaptic weight space. Using tools from dynamical systems, we derive
theoretical arguments and present a theorem explaining this phenomenon. This
predicts our numerical results, and explains why biologically-plausible rules
lead to worse and more variable generalization properties. Finally, we suggest
potential remedies that could be used by the brain to mitigate this effect. To
our knowledge, our analysis is the first to identify the reason for this
generalization gap between artificial and biologically-plausible learning
rules, which can help guide future investigations into how the brain learns
solutions that generalize."
7034,"However, it is important to note that this strategy does not
correct the problem; the gap still exists compared to BPTT, suggesting room for further research.","This
result also connects with the Ô¨Ånding that sensory depletion during critical periods in training deep
networks, which can be related to a small learning rate early in training, can impair learning and
yield convergence to sharp minima [192].","A  Pattern generation  B  Sequential MNIST  C  Delayed match-to-sample

Figure 5: Learning rate modulation as a possible remedy of the problem.",2022-06-02 01:39:08+00:00,Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules,cs.NE,"['cs.NE', 'cs.AI', 'q-bio.NC']","[arxiv.Result.Author('Yuhan Helena Liu'), arxiv.Result.Author('Arna Ghosh'), arxiv.Result.Author('Blake A. Richards'), arxiv.Result.Author('Eric Shea-Brown'), arxiv.Result.Author('Guillaume Lajoie')]","To unveil how the brain learns, ongoing work seeks biologically-plausible
approximations of gradient descent algorithms for training recurrent neural
networks (RNNs). Yet, beyond task accuracy, it is unclear if such learning
rules converge to solutions that exhibit different levels of generalization
than their nonbiologically-plausible counterparts. Leveraging results from deep
learning theory based on loss landscape curvature, we ask: how do
biologically-plausible gradient approximations affect generalization? We first
demonstrate that state-of-the-art biologically-plausible learning rules for
training RNNs exhibit worse and more variable generalization performance
compared to their machine learning counterparts that follow the true gradient
more closely. Next, we verify that such generalization performance is
correlated significantly with loss landscape curvature, and we show that
biologically-plausible learning rules tend to approach high-curvature regions
in synaptic weight space. Using tools from dynamical systems, we derive
theoretical arguments and present a theorem explaining this phenomenon. This
predicts our numerical results, and explains why biologically-plausible rules
lead to worse and more variable generalization properties. Finally, we suggest
potential remedies that could be used by the brain to mitigate this effect. To
our knowledge, our analysis is the first to identify the reason for this
generalization gap between artificial and biologically-plausible learning
rules, which can help guide future investigations into how the brain learns
solutions that generalize."
7035,"However, it is
important to note that this strategy does not correct the problem; the gap still exists compared to
BPTT, suggesting room for further research.","Bottom panels show this leads to a
slight improvement in generalization gap (vertical lines denote distribution mean).",Plotting conventions follow that of the previous Ô¨Ågures.,2022-06-02 01:39:08+00:00,Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules,cs.NE,"['cs.NE', 'cs.AI', 'q-bio.NC']","[arxiv.Result.Author('Yuhan Helena Liu'), arxiv.Result.Author('Arna Ghosh'), arxiv.Result.Author('Blake A. Richards'), arxiv.Result.Author('Eric Shea-Brown'), arxiv.Result.Author('Guillaume Lajoie')]","To unveil how the brain learns, ongoing work seeks biologically-plausible
approximations of gradient descent algorithms for training recurrent neural
networks (RNNs). Yet, beyond task accuracy, it is unclear if such learning
rules converge to solutions that exhibit different levels of generalization
than their nonbiologically-plausible counterparts. Leveraging results from deep
learning theory based on loss landscape curvature, we ask: how do
biologically-plausible gradient approximations affect generalization? We first
demonstrate that state-of-the-art biologically-plausible learning rules for
training RNNs exhibit worse and more variable generalization performance
compared to their machine learning counterparts that follow the true gradient
more closely. Next, we verify that such generalization performance is
correlated significantly with loss landscape curvature, and we show that
biologically-plausible learning rules tend to approach high-curvature regions
in synaptic weight space. Using tools from dynamical systems, we derive
theoretical arguments and present a theorem explaining this phenomenon. This
predicts our numerical results, and explains why biologically-plausible rules
lead to worse and more variable generalization properties. Finally, we suggest
potential remedies that could be used by the brain to mitigate this effect. To
our knowledge, our analysis is the first to identify the reason for this
generalization gap between artificial and biologically-plausible learning
rules, which can help guide future investigations into how the brain learns
solutions that generalize."
7300,"13
Accepted at 1st Conference on Lifelong Learning Agents, 2022

D CHARACTERISTICS ANALYSIS

To further study the characteristics of the model, we compare the task probabilities and calibration of the models
trained on different datasets with varying memory budgets.","We believe that SC can further improve the performance of CLS-ER and provides an interesting research avenue for
employing SC in a multiple semantic memories setup.","D.1 MODEL CALIBRATION

Figures S2 and S3 provides the reliability plots and ECE of the different models trained on S-CIFAR-10 and S-
TinyImageNet respectively with varying memory buffer sizes.",2022-06-08 17:08:56+00:00,SYNERgy between SYNaptic consolidation and Experience Replay for general continual learning,cs.NE,"['cs.NE', 'cs.AI', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Fahad Sarfraz'), arxiv.Result.Author('Elahe Arani'), arxiv.Result.Author('Bahram Zonooz')]","Continual learning (CL) in the brain is facilitated by a complex set of
mechanisms. This includes the interplay of multiple memory systems for
consolidating information as posited by the complementary learning systems
(CLS) theory and synaptic consolidation for protecting the acquired knowledge
from erasure. Thus, we propose a general CL method that creates a synergy
between SYNaptic consolidation and dual memory Experience Replay (SYNERgy). Our
method maintains a semantic memory that accumulates and consolidates
information across the tasks and interacts with the episodic memory for
effective replay. It further employs synaptic consolidation by tracking the
importance of parameters during the training trajectory and anchoring them to
the consolidated parameters in the semantic memory. To the best of our
knowledge, our study is the first to employ dual memory experience replay in
conjunction with synaptic consolidation that is suitable for general CL whereby
the network does not utilize task boundaries or task labels during training or
inference. Our evaluation on various challenging CL scenarios and
characteristics analyses demonstrate the efficacy of incorporating both
synaptic consolidation and CLS theory in enabling effective CL in DNNs."
7511,"How to make reinforcement learning
perform the same or better eÔ¨Äect with fewer evaluations is worth further research.","From the perspective of problem scale, the QGA algorithm has a good performance
on large-scale problems, but its time advantage is not obvious in small-scale problems due
to its Q-value evaluation and selection mechanism.","Overall,
the RL-EA algorithm proposed in this paper can solve the EDSSP problem very well and
has a good application prospect.",2022-06-12 08:53:56+00:00,RL-EA: A Reinforcement Learning-Based Evolutionary Algorithm Framework for Electromagnetic Detection Satellite Scheduling Problem,cs.NE,"['cs.NE', 'cs.AI', 'math.OC']","[arxiv.Result.Author('Yanjie Song'), arxiv.Result.Author('Luona Wei'), arxiv.Result.Author('Qing Yang'), arxiv.Result.Author('Jian Wu'), arxiv.Result.Author('Lining Xing'), arxiv.Result.Author('Yingwu Chen')]","The study of electromagnetic detection satellite scheduling problem (EDSSP)
has attracted attention due to the detection requirements for a large number of
targets. This paper proposes a mixed-integer programming model for the EDSSP
problem and an evolutionary algorithm framework based on reinforcement learning
(RL-EA). Numerous factors that affect electromagnetic detection are considered
in the model, such as detection mode, bandwidth, and other factors. The
evolutionary algorithm framework based on reinforcement learning uses the
Q-learning framework, and each individual in the population is regarded as an
agent. Based on the proposed framework, a Q-learning-based genetic
algorithm(QGA) is designed. Q-learning is used to guide the population search
process by choosing variation operators. In the algorithm, we design a reward
function to update the Q value. According to the problem characteristics, a new
combination of <state, action> is proposed. The QGA also uses an elite
individual retention strategy to improve search performance. After that, a task
time window selection algorithm is proposed To evaluate the performance of
population evolution. Various scales experiments are used to examine the
planning effect of the proposed algorithm. Through the experimental
verification of multiple instances, it can be seen that the QGA can solve the
EDSSP problem effectively. Compared with the state-of-the-art algorithms, the
QGA algorithm performs better in several aspects."
7633,"and have been demonstrated to balance swarm exploration while promoting conver-
gence, therefore, these quantities do not require further study if the optimization
problem resides in the standard Euclidean geometry.","For S = 10 particles (a) illustration of the global communication topology used in Basic PSO, and
(b) illustration of the random local communication topology with 2 links per particle used in SPSO2007.","These values guarantee that the
swarm will eventually settle down to a consensus point for the solution to the opti-
mization.",2022-06-14 16:00:22+00:00,Generating Exact Optimal Designs via Particle Swarm Optimization: Assessing Efficacy and Efficiency via Case Study,cs.NE,"['cs.NE', 'stat.ME']","[arxiv.Result.Author('Stephen J. Walsh'), arxiv.Result.Author('John J. Borkowski')]","In this study we address existing deficiencies in the literature on
applications of Particle Swarm Optimization to generate optimal designs. We
present the results of a large computer study in which we bench-mark both
efficiency and efficacy of PSO to generate high quality candidate designs for
small-exact response surface scenarios commonly encountered by industrial
practitioners. A preferred version of PSO is demonstrated and recommended.
Further, in contrast to popular local optimizers such as the coordinate
exchange, PSO is demonstrated to, even in a single run, generate highly
efficient designs with large probability at small computing cost. Therefore, it
appears beneficial for more practitioners to adopt and use PSO as tool for
generating candidate experimental designs."
7767,"Understanding this
issue may be important for further research.","The conclusion is that QD score does not entirely capture what
enables generalization and adaptation to novel terrains.","Possible ideas for biasing seeds towards producing generalizable inventions
include disallowing precise setting of joint position and oscillatory parameters,
introducing stochasticity to prevent overÔ¨Åtting to initial conditions, and incre-
mentally adjusting the seed.",2022-06-17 17:07:04+00:00,Evolution through Large Models,cs.NE,['cs.NE'],"[arxiv.Result.Author('Joel Lehman'), arxiv.Result.Author('Jonathan Gordon'), arxiv.Result.Author('Shawn Jain'), arxiv.Result.Author('Kamal Ndousse'), arxiv.Result.Author('Cathy Yeh'), arxiv.Result.Author('Kenneth O. Stanley')]","This paper pursues the insight that large language models (LLMs) trained to
generate code can vastly improve the effectiveness of mutation operators
applied to programs in genetic programming (GP). Because such LLMs benefit from
training data that includes sequential changes and modifications, they can
approximate likely changes that humans would make. To highlight the breadth of
implications of such evolution through large models (ELM), in the main
experiment ELM combined with MAP-Elites generates hundreds of thousands of
functional examples of Python programs that output working ambulating robots in
the Sodarace domain, which the original LLM had never seen in pre-training.
These examples then help to bootstrap training a new conditional language model
that can output the right walker for a particular terrain. The ability to
bootstrap new models that can output appropriate artifacts for a given context
in a domain where zero training data was previously available carries
implications for open-endedness, deep learning, and reinforcement learning.
These implications are explored here in depth in the hope of inspiring new
directions of research now opened up by ELM."
7907,"The code is written in Python 3.8 and will be open
   3) Training Method: In this study, the REINFORCE al-            access once the paper was accepted for the convenience of
gorithm [33] is used as a RL method to train the DYPN              experimental reproduction and further research.","All experiments in this study are conducted on a single RTX
                                                                   3060 GPU.","All competitor
model.",2022-06-21 15:20:42+00:00,Hybridization of evolutionary algorithm and deep reinforcement learning for multi-objective orienteering optimization,cs.NE,['cs.NE'],"[arxiv.Result.Author('Wei Liu'), arxiv.Result.Author('Rui Wang'), arxiv.Result.Author('Tao Zhang'), arxiv.Result.Author('Kaiwen Li'), arxiv.Result.Author('Wenhua Li'), arxiv.Result.Author('Hisao Ishibuchi')]","Multi-objective orienteering problems (MO-OPs) are classical multi-objective
routing problems and have received a lot of attention in the past decades. This
study seeks to solve MO-OPs through a problem-decomposition framework, that is,
a MO-OP is decomposed into a multi-objective knapsack problem (MOKP) and a
travelling salesman problem (TSP). The MOKP and TSP are then solved by a
multi-objective evolutionary algorithm (MOEA) and a deep reinforcement learning
(DRL) method, respectively. While the MOEA module is for selecting cities, the
DRL module is for planning a Hamiltonian path for these cities. An iterative
use of these two modules drives the population towards the Pareto front of
MO-OPs. The effectiveness of the proposed method is compared against NSGA-II
and NSGA-III on various types of MO-OP instances. Experimental results show
that our method exhibits the best performance on almost all the test instances,
and has shown strong generalization ability."
7938,"Finally, Section 5 concludes the paper
by summarizing the main Ô¨Åndings and pointing out directions for further research on
the topic.","Section 4 presents the experimental evaluation of our approach, discussing the experi-
mental settings adopted and the obtained results.","2 Background

In this section, we Ô¨Årst describe the three balanced crossover operators introduced

in [6], which we will use in our investigation.",2022-06-22 10:59:26+00:00,The Influence of Local Search over Genetic Algorithms with Balanced Representations,cs.NE,['cs.NE'],"[arxiv.Result.Author('Luca Manzoni'), arxiv.Result.Author('Luca Mariot'), arxiv.Result.Author('Eva Tuba')]","We continue the study of Genetic Algorithms (GA) on combinatorial
optimization problems where the candidate solutions need to satisfy a
balancedness constraint. It has been observed that the reduction of the search
space size granted by ad-hoc crossover and mutation operators does not usually
translate to a substantial improvement of the GA performances. There is still
no clear explanation of this phenomenon, although it is suspected that a
balanced representation might yield a more irregular fitness landscape, where
it could be more difficult for GA to converge to a global optimum. In this
paper, we investigate this issue by adding a local search step to a GA with
balanced operators, and use it to evolve highly nonlinear balanced Boolean
functions. In particular, we organize our experiments around two research
questions, namely if local search (1) improves the convergence speed of GA, and
(2) decreases the population diversity. Surprisingly, while our results answer
affirmatively the first question, they also show that adding local search
actually \emph{increases} the diversity among the individuals in the
population. We link these findings to some recent results on fitness landscape
analysis for problems on Boolean functions."
8175,We propose mining this model to capture        point for further research in this area for real-world problems.,"This  where the simple problem definition means that the explanations
cheaper model, surrogate [10, 22, 23, 40], also represents an explicit  can be compared against known expectations, and gives a starting
model of the population.","The
the sensitivity of the fitness function to the problem variables.",2022-05-31 09:16:18+00:00,Towards Explainable Metaheuristic: Mining Surrogate Fitness Models for Importance of Variables,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Manjinder Singh'), arxiv.Result.Author('Alexander E. I. Brownlee'), arxiv.Result.Author('David Cairns')]","Metaheuristic search algorithms look for solutions that either maximise or
minimise a set of objectives, such as cost or performance. However most
real-world optimisation problems consist of nonlinear problems with complex
constraints and conflicting objectives. The process by which a GA arrives at a
solution remains largely unexplained to the end-user. A poorly understood
solution will dent the confidence a user has in the arrived at solution. We
propose that investigation of the variables that strongly influence solution
quality and their relationship would be a step toward providing an explanation
of the near-optimal solution presented by a metaheuristic. Through the use of
four benchmark problems we use the population data generated by a Genetic
Algorithm (GA) to train a surrogate model, and investigate the learning of the
search space by the surrogate model. We compare what the surrogate has learned
after being trained on population data generated after the first generation and
contrast this with a surrogate model trained on the population data from all
generations. We show that the surrogate model picks out key characteristics of
the problem as it is trained on population data from each generation. Through
mining the surrogate model we can build a picture of the learning process of a
GA, and thus an explanation of the solution presented by the GA. The aim being
to build trust and confidence in the end-user about the solution presented by
the GA, and encourage adoption of the model."
8687,"Furthermore, since diÔ¨Äerent hyperparameters sampling methods showed
varied ranking, this work can further study the inÔ¨Çuence of the sampling method or sensitivity

                                                             29
Morris LHS  1.0        GD                   IGD                  HV
            0.8
            0.6     Morris LHS           Morris LHS           Morris LHS
            0.4       Morris
Morris      0.2         0.5
            0.0       Sobol Si
                                         Morris               Morris
            1.0
Sobol STi   0.8
            0.6
            0.4                 1.0 0.0    0.5       1.0 0.0    0.5       1.0
            0.2                   XDI    Sobol Si      PMDI   Sobol Si
            0.0                          P[PM]                                    N
                                                                Mode
            1.0
            0.8
            0.6
            0.4
            0.2
            0.0

               0.0

                    P[X]

Fig.","This framework can
further analyze the sensitivity and inÔ¨Çuence of adaptive and dynamically tuneable hyperparam-
eters for future work.",9: MOEA/D hyperparameters sensitivity analysis.,2022-07-11 12:39:39+00:00,Assessing Ranking and Effectiveness of Evolutionary Algorithm Hyperparameters Using Global Sensitivity Analysis Methodologies,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Varun Ojha'), arxiv.Result.Author('Jon Timmis'), arxiv.Result.Author('Giuseppe Nicosia')]","We present a comprehensive global sensitivity analysis of two
single-objective and two multi-objective state-of-the-art global optimization
evolutionary algorithms as an algorithm configuration problem. That is, we
investigate the quality of influence hyperparameters have on the performance of
algorithms in terms of their direct effect and interaction effect with other
hyperparameters. Using three sensitivity analysis methods, Morris LHS, Morris,
and Sobol, to systematically analyze tunable hyperparameters of covariance
matrix adaptation evolutionary strategy, differential evolution, non-dominated
sorting genetic algorithm III, and multi-objective evolutionary algorithm based
on decomposition, the framework reveals the behaviors of hyperparameters to
sampling methods and performance metrics. That is, it answers questions like
what hyperparameters influence patterns, how they interact, how much they
interact, and how much their direct influence is. Consequently, the ranking of
hyperparameters suggests their order of tuning, and the pattern of influence
reveals the stability of the algorithms."
8700,"Furthermore, it highlights that
further research aimed at unveiling the role of the dynamics of neuron models in deep hierarchical learning would be
highly beneÔ¨Åcial to close the gap between conventional DL approaches and SNNs.","Collectively, our results show that accurately selecting the neuron model employed
in an NM pipeline improves its performance, and that this selection should be driven by considering the complexity
of the spatio-temporal features that the layer in the network will have to understand.","Other future studies could consist
of analysing further relationships between the neuron models and other components of the learning pipeline, such as
the neural network architecture, and the learning rule.",2022-06-28 10:01:51+00:00,Simple and complex spiking neurons: perspectives and analysis in a simple STDP scenario,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Davide Liberato Manna'), arxiv.Result.Author('Alex Vicente Sola'), arxiv.Result.Author('Paul Kirkland'), arxiv.Result.Author('Trevor Bihl'), arxiv.Result.Author('Gaetano Di Caterina')]","Spiking neural networks (SNNs) are largely inspired by biology and
neuroscience and leverage ideas and theories to create fast and efficient
learning systems. Spiking neuron models are adopted as core processing units in
neuromorphic systems because they enable event-based processing. The
integrate-and-fire (I&F) models are often adopted, with the simple Leaky I&F
(LIF) being the most used. The reason for adopting such models is their
efficiency and/or biological plausibility. Nevertheless, rigorous justification
for adopting LIF over other neuron models for use in artificial learning
systems has not yet been studied. This work considers various neuron models in
the literature and then selects computational neuron models that are
single-variable, efficient, and display different types of complexities. From
this selection, we make a comparative study of three simple I&F neuron models,
namely the LIF, the Quadratic I&F (QIF) and the Exponential I&F (EIF), to
understand whether the use of more complex models increases the performance of
the system and whether the choice of a neuron model can be directed by the task
to be completed. Neuron models are tested within an SNN trained with
Spike-Timing Dependent Plasticity (STDP) on a classification task on the
N-MNIST and DVS Gestures datasets. Experimental results reveal that more
complex neurons manifest the same ability as simpler ones to achieve high
levels of accuracy on a simple dataset (N-MNIST), albeit requiring comparably
more hyper-parameter tuning. However, when the data possess richer
Spatio-temporal features, the QIF and EIF neuron models steadily achieve better
results. This suggests that accurately selecting the model based on the
richness of the feature spectrum of the data could improve the whole system's
performance. Finally, the code implementing the spiking neurons in the
SpykeTorch framework is made publicly available."
9525,"After further study,
tion, batch-normalization(BN)(Ioffe and Szegedy 2015) is                                we Ô¨Ånd ALBSNN does not always select the Ô¨Årst and sixth
applied.","The Ô¨Årst convolutional layer acts as an                                  There is an interesting phenomenon that FLNBSNN and
encoding layer and network structures for Fashion-MNIST,                                ALBSNN both select the Ô¨Årst and sixth layer as non-
CIFAR-10, and CIFAR-100 datasets are shown in Table 1.                                  binarized layers for the CIFAR-10 and CIFAR-100 datasets,
Between the convolution calculation and the activation func-                            but ALBSNN obtains a better accuracy.",All convolution operations used in the experiment                              layers as non-binarized layers.,2022-07-31 09:03:57+00:00,Ultra-low Latency Adaptive Local Binary Spiking Neural Network with Accuracy Loss Estimator,cs.NE,['cs.NE'],"[arxiv.Result.Author('Changqing Xu'), arxiv.Result.Author('Yijian Pei'), arxiv.Result.Author('Zili Wu'), arxiv.Result.Author('Yi Liu'), arxiv.Result.Author('Yintang Yang')]","Spiking neural network (SNN) is a brain-inspired model which has more
spatio-temporal information processing capacity and computational energy
efficiency. However, with the increasing depth of SNNs, the memory problem
caused by the weights of SNNs has gradually attracted attention. Inspired by
Artificial Neural Networks (ANNs) quantization technology, binarized SNN (BSNN)
is introduced to solve the memory problem. Due to the lack of suitable learning
algorithms, BSNN is usually obtained by ANN-to-SNN conversion, whose accuracy
will be limited by the trained ANNs. In this paper, we propose an ultra-low
latency adaptive local binary spiking neural network (ALBSNN) with accuracy
loss estimators, which dynamically selects the network layers to be binarized
to ensure the accuracy of the network by evaluating the error caused by the
binarized weights during the network learning process. Experimental results
show that this method can reduce storage space by more than 20 % without losing
network accuracy. At the same time, in order to accelerate the training speed
of the network, the global average pooling(GAP) layer is introduced to replace
the fully connected layers by the combination of convolution and pooling, so
that SNNs can use a small number of time steps to obtain better recognition
accuracy. In the extreme case of using only one time step, we still can achieve
92.92 %, 91.63 % ,and 63.54 % testing accuracy on three different datasets,
FashionMNIST, CIFAR-10, and CIFAR-100, respectively."
9615,"In future work, we will further study the eÔ¨Äectiveness of our top-down learning
framework on neural network with diÔ¨Äerent structures and dynamics.","Our Ô¨Åndings also suggest that
the biological plausible top-down learning framework is a potential mechanism
underlying how the brain learns.","We can also
apply the top-down framework to more diÔ¨Äerent scenarios, and to help extremely
large, or unconventional networks achieve good performance.",2022-08-01 07:14:37+00:00,Replacing Backpropagation with Biological Plausible Top-down Credit Assignment in Deep Neural Networks Training,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Jian-Hui Chen'), arxiv.Result.Author('Zuoren Wang'), arxiv.Result.Author('Cheng-Lin Liu')]","Top-down connections in the biological brain has been shown to be important
in high cognitive functions. However, the function of this mechanism in machine
learning has not been defined clearly. In this study, we propose to lay out a
framework constituted by a bottom-up and a top-down network. Here, we use a
Top-down Credit Assignment Network (TDCA-network) to replace the loss function
and back propagation (BP) which serve as the feedback mechanism in traditional
bottom-up network training paradigm. Our results show that the credit given by
well-trained TDCA-network outperforms the gradient from backpropagation in
classification task under different settings on multiple datasets. In addition,
we successfully use a credit diffusing trick, which can keep training and
testing performance remain unchanged, to reduce parameter complexity of the
TDCA-network. More importantly, by comparing their trajectories in the
parameter landscape, we find that TDCA-network directly achieved a global
optimum, in contrast to that backpropagation only can gain a localized optimum.
Thus, our results demonstrate that TDCA-network not only provide a biological
plausible learning mechanism, but also has the potential to directly achieve
global optimum, indicating that top-down credit assignment can substitute
backpropagation, and provide a better learning framework for Deep Neural
Networks."
10174,"As a second direction for further research, we note that we did not prove
any lower bounds, so we have not estimate on how far our runtime guarantees
are from the truth.","As our experiments have shown,
such solutions often contribute to successful crossovers.","Clearly, proving lower bounds for a crossover-based algo-
rithm is challenging as it requires a detailed understanding of the population
dynamics and of the typical diversity observed in the population.",2022-08-18 10:41:44+00:00,The First Mathematical Proof That Crossover Gives Super-Constant Performance Gains For the NSGA-II,cs.NE,"['cs.NE', 'cs.AI', 'cs.DS']","[arxiv.Result.Author('Benjamin Doerr'), arxiv.Result.Author('Zhongdi Qu')]","Very recently, the first mathematical runtime analyses for the NSGA-II, the
most common multi-objective evolutionary algorithm, have been conducted (Zheng,
Liu, Doerr (AAAI 2022)). Continuing this research direction, we prove that the
NSGA-II optimizes the OneJumpZeroJump benchmark asymptotically faster when
crossover is employed. This is the first time such an advantage of crossover is
proven for the NSGA-II. Our arguments can be transferred to single-objective
optimization. They then prove that crossover can speed-up the $(\mu+1)$ genetic
algorithm in a different way and more pronounced than known before. Our
experiments confirm the added value of crossover and show that the observed
speed-ups are even larger than what our proofs can guarantee."
10510,"Meanwhile,                                  16 end

our further research notice that this linkage measurement                                  17 Ft ‚Üê Evaluate(Ptn, S)
                                                                                           18 E ‚Üê bestIndividual(Ptn, E)
function often contains multiple optima especially in separable

functions and partially separable function.","Eq (15) is the original link-                             15  return E

age measurement function of our proposal [37].","Therefore, we can                              19  (Optimization)

attach a reasonable penalty to lead the direction of optimiza-                             20 while not stop criterion do

tion.",2022-08-29 08:18:15+00:00,Cooperative coevolutionary hybrid NSGA-II with Linkage Measurement Minimization for Large-scale Multi-objective optimization,cs.NE,['cs.NE'],"[arxiv.Result.Author('Rui Zhong'), arxiv.Result.Author('Masaharu Munetomo')]","In this paper, we propose a variable grouping method based on cooperative
coevolution for large-scale multi-objective problems (LSMOPs), named Linkage
Measurement Minimization (LMM). And for the sub-problem optimization stage, a
hybrid NSGA-II with a Gaussian sampling operator based on an estimated
convergence point is proposed. In the variable grouping stage, according to our
previous research, we treat the variable grouping problem as a combinatorial
optimization problem, and the linkage measurement function is designed based on
linkage identification by the nonlinearity check on real code (LINC-R). We
extend this variable grouping method to LSMOPs. In the sub-problem optimization
stage, we hypothesize that there is a higher probability of existing better
solutions around the Pareto Front (PF). Based on this hypothesis, we estimate a
convergence point at every generation of optimization and perform Gaussian
sampling around the convergence point. The samples with good objective value
will participate in the optimization as elites. Numerical experiments show that
our variable grouping method is better than some popular variable grouping
methods, and hybrid NSGA-II has broad prospects for multi-objective problem
optimization."
10854,"209‚Äì220,
foreground/background seed and hope to instigate new                    2011.
direction for further research integrating neuromorphics,
image processing and non-volatile memory devices.","2, pp.","Apart           [8] N. M. Zaitoun and M. J. Aqel, ‚ÄúSurvey on Image Segmentation
from the realization of the aforementioned tasks, the                   Techniques,‚Äù in Procedia Computer Science, 2015, vol.",2022-08-07 05:01:57+00:00,A neuromorphic approach to image processing and machine vision,cs.NE,"['cs.NE', 'cs.AI', 'cs.CV']",[arxiv.Result.Author('Arvind Subramaniam')],"Neuromorphic engineering is essentially the development of artificial
systems, such as electronic analog circuits that employ information
representations found in biological nervous systems. Despite being faster and
more accurate than the human brain, computers lag behind in recognition
capability. However, it is envisioned that the advancement in neuromorphics,
pertaining to the fields of computer vision and image processing will provide a
considerable improvement in the way computers can interpret and analyze
information. In this paper, we explore the implementation of visual tasks such
as image segmentation, visual attention and object recognition. Moreover, the
concept of anisotropic diffusion has been examined followed by a novel approach
employing memristors to execute image segmentation. Additionally, we have
discussed the role of neuromorphic vision sensors in artificial visual systems
and the protocol involved in order to enable asynchronous transmission of
signals. Moreover, two widely accepted algorithms that are used to emulate the
process of object recognition and visual attention have also been discussed.
Throughout the span of this paper, we have emphasized on the employment of
non-volatile memory devices such as memristors to realize artificial visual
systems. Finally, we discuss about hardware accelerators and wish to represent
a case in point for arguing that progress in computer vision may benefit
directly from progress in non-volatile memory technology."
11603,"To further study that impact, we varied the Ô¨Årst layer‚Äôs width and kept the width
factor Ô¨Åxed to 4 (which scales all layers).","Width (number of neurons) The width of the layers is rather impactful, as indicated
by varying the width factor of deep layers while keeping the Ô¨Årst layer‚Äôs width constant
(Figure 4).",The results are presented in Figure B.6.,2022-09-23 23:12:59+00:00,Hebbian Deep Learning Without Feedback,cs.NE,"['cs.NE', 'cs.LG', 'q-bio.NC']","[arxiv.Result.Author('Adrien Journ√©'), arxiv.Result.Author('Hector Garcia Rodriguez'), arxiv.Result.Author('Qinghai Guo'), arxiv.Result.Author('Timoleon Moraitis')]","Recent approximations to backpropagation (BP) have mitigated many of BP's
computational inefficiencies and incompatibilities with biology, but important
limitations still remain. Moreover, the approximations significantly decrease
accuracy in benchmarks, suggesting that an entirely different approach may be
more fruitful. Here, grounded on recent theory for Hebbian learning in soft
winner-take-all networks, we present multilayer SoftHebb, i.e. an algorithm
that trains deep neural networks, without any feedback, target, or error
signals. As a result, it achieves efficiency by avoiding weight transport,
non-local plasticity, time-locking of layer updates, iterative equilibria, and
(self-) supervisory or other feedback signals -- which were necessary in other
approaches. Its increased efficiency and biological compatibility do not trade
off accuracy compared to state-of-the-art bio-plausible learning, but rather
improve it. With up to five hidden layers and an added linear classifier,
accuracies on MNIST, CIFAR-10, STL-10, and ImageNet, respectively reach 99.4%,
80.3%, 76.2%, and 27.3%. In conclusion, SoftHebb shows with a radically
different approach from BP that Deep Learning over few layers may be plausible
in the brain and increases the accuracy of bio-plausible machine learning."
11738,"Deriving some propagation-style methods for
inference that achieve near globally-optimal performances is worth further study.","The Ô¨Årst problem arises when the number of categories is large, and in
this case the brute-force searching method is not efÔ¨Åcient any more.","For the second key problem, it is expected that a network can be trained by giving any subset of the input
units at each training step.",2022-09-26 10:43:29+00:00,Activation Learning by Local Competitions,cs.NE,"['cs.NE', 'cs.AI', 'cs.CV', 'cs.LG']",[arxiv.Result.Author('Hongchao Zhou')],"The backpropagation that drives the success of deep learning is most likely
different from the learning mechanism of the brain. In this paper, we develop a
biology-inspired learning rule that discovers features by local competitions
among neurons, following the idea of Hebb's famous proposal. It is demonstrated
that the unsupervised features learned by this local learning rule can serve as
a pre-training model to improve the performance of some supervised learning
tasks. More importantly, this local learning rule enables us to build a new
learning paradigm very different from the backpropagation, named activation
learning, where the output activation of the neural network roughly measures
how probable the input patterns are. The activation learning is capable of
learning plentiful local features from few shots of input patterns, and
demonstrates significantly better performances than the backpropagation
algorithm when the number of training samples is relatively small. This
learning paradigm unifies unsupervised learning, supervised learning and
generative models, and is also more secure against adversarial attack, paving a
road to some possibilities of creating general-task neural networks."
11800,"We hope this software will
help further research at the intersection of connectomics and machine learning, particularly for ex-
ploring the connectome of the Drosophila melanogaster, which includes a visual processing system
(Takemura (2015)) that may lead to new and powerful architectural discoveries for visual learning
problems.","This includes a
process of Ô¨Ånding a good set of initial shared weights for the excitatory and inhibitory connections,
as well as tuning the neuron parameters for arbitrary learning problems.","We believe that connectomes may provide structure that promotes stable bounds for models of
synaptic plasticity, which have seen a recent resurgence for use in deep learning applications (Mi-
coni et al.",2022-09-28 20:25:26+00:00,Biological connectomes as a representation for the architecture of artificial neural networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG', 'q-bio.NC']","[arxiv.Result.Author('Samuel Schmidgall'), arxiv.Result.Author('Catherine Schuman'), arxiv.Result.Author('Maryam Parsa')]","Grand efforts in neuroscience are working toward mapping the connectomes of
many new species, including the near completion of the Drosophila melanogaster.
It is important to ask whether these models could benefit artificial
intelligence. In this work we ask two fundamental questions: (1) where and when
biological connectomes can provide use in machine learning, (2) which design
principles are necessary for extracting a good representation of the
connectome. Toward this end, we translate the motor circuit of the C. Elegans
nematode into artificial neural networks at varying levels of biophysical
realism and evaluate the outcome of training these networks on motor and
non-motor behavioral tasks. We demonstrate that biophysical realism need not be
upheld to attain the advantages of using biological circuits. We also establish
that, even if the exact wiring diagram is not retained, the architectural
statistics provide a valuable prior. Finally, we show that while the C. Elegans
locomotion circuit provides a powerful inductive bias on locomotion problems,
its structure may hinder performance on tasks unrelated to locomotion such as
visual classification problems."
11801,"We hope this software will
help further research at the intersection of connectomics and machine learning, particularly for ex-
ploring the connectome of the Drosophila melanogaster, which includes a visual processing system
(Takemura (2015)) that may lead to new and powerful architectural discoveries for visual learning
problems.","This includes a
process of Ô¨Ånding a good set of initial shared weights for the excitatory and inhibitory connections,
as well as tuning the neuron parameters for arbitrary learning problems.","We believe that connectomes may provide structure that promotes stable bounds for models of
synaptic plasticity, which have seen a recent resurgence for use in deep learning applications (Mi-
coni et al.",2022-09-28 20:25:26+00:00,Biological connectomes as a representation for the architecture of artificial neural networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG', 'q-bio.NC']","[arxiv.Result.Author('Samuel Schmidgall'), arxiv.Result.Author('Catherine Schuman'), arxiv.Result.Author('Maryam Parsa')]","Grand efforts in neuroscience are working toward mapping the connectomes of
many new species, including the near completion of the Drosophila melanogaster.
It is important to ask whether these models could benefit artificial
intelligence. In this work we ask two fundamental questions: (1) where and when
biological connectomes can provide use in machine learning, (2) which design
principles are necessary for extracting a good representation of the
connectome. Toward this end, we translate the motor circuit of the C. Elegans
nematode into artificial neural networks at varying levels of biophysical
realism and evaluate the outcome of training these networks on motor and
non-motor behavioral tasks. We demonstrate that biophysical realism need not be
upheld to attain the advantages of using biological circuits. We also establish
that, even if the exact wiring diagram is not retained, the architectural
statistics provide a valuable prior. Finally, we show that while the C. Elegans
locomotion circuit provides a powerful inductive bias on locomotion problems,
its structure may hinder performance on tasks unrelated to locomotion such as
visual classification problems."
11882,"We hope our investigations pave the way for further research on
transformer-based SNNs models.","With directly training from scratch, Spiking Transformer outperforms
the state-of-the-art SNNs models.","10
FOR REVIEW

REPRODUCIBILITY STATEMENT

Our codes are based on SpikingJelly(Fang et al., 2020), an open-source SNN framework, and
Pytorch image models library (Timm)(Wightman, 2019).",2022-09-29 14:16:49+00:00,Spikformer: When Spiking Neural Network Meets Transformer,cs.NE,"['cs.NE', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Zhaokun Zhou'), arxiv.Result.Author('Yuesheng Zhu'), arxiv.Result.Author('Chao He'), arxiv.Result.Author('Yaowei Wang'), arxiv.Result.Author('Shuicheng Yan'), arxiv.Result.Author('Yonghong Tian'), arxiv.Result.Author('Li Yuan')]","We consider two biologically plausible structures, the Spiking Neural Network
(SNN) and the self-attention mechanism. The former offers an energy-efficient
and event-driven paradigm for deep learning, while the latter has the ability
to capture feature dependencies, enabling Transformer to achieve good
performance. It is intuitively promising to explore the marriage between them.
In this paper, we consider leveraging both self-attention capability and
biological properties of SNNs, and propose a novel Spiking Self Attention (SSA)
as well as a powerful framework, named Spiking Transformer (Spikformer). The
SSA mechanism in Spikformer models the sparse visual feature by using
spike-form Query, Key, and Value without softmax. Since its computation is
sparse and avoids multiplication, SSA is efficient and has low computational
energy consumption. It is shown that Spikformer with SSA can outperform the
state-of-the-art SNNs-like frameworks in image classification on both
neuromorphic and static datasets. Spikformer (66.3M parameters) with comparable
size to SEW-ResNet-152 (60.2M,69.26%) can achieve 74.81% top1 accuracy on
ImageNet using 4 time steps, which is the state-of-the-art in directly trained
SNNs models."
11883,"We hope our investigations pave the way for further research on
transformer-based SNNs models.","With directly training from scratch, Spiking Transformer outperforms
the state-of-the-art SNNs models.","10
FOR REVIEW

REPRODUCIBILITY STATEMENT

Our codes are based on SpikingJelly(Fang et al., 2020), an open-source SNN framework, and
Pytorch image models library (Timm)(Wightman, 2019).",2022-09-29 14:16:49+00:00,Spikformer: When Spiking Neural Network Meets Transformer,cs.NE,"['cs.NE', 'cs.CV', 'cs.LG']","[arxiv.Result.Author('Zhaokun Zhou'), arxiv.Result.Author('Yuesheng Zhu'), arxiv.Result.Author('Chao He'), arxiv.Result.Author('Yaowei Wang'), arxiv.Result.Author('Shuicheng Yan'), arxiv.Result.Author('Yonghong Tian'), arxiv.Result.Author('Li Yuan')]","We consider two biologically plausible structures, the Spiking Neural Network
(SNN) and the self-attention mechanism. The former offers an energy-efficient
and event-driven paradigm for deep learning, while the latter has the ability
to capture feature dependencies, enabling Transformer to achieve good
performance. It is intuitively promising to explore the marriage between them.
In this paper, we consider leveraging both self-attention capability and
biological properties of SNNs, and propose a novel Spiking Self Attention (SSA)
as well as a powerful framework, named Spiking Transformer (Spikformer). The
SSA mechanism in Spikformer models the sparse visual feature by using
spike-form Query, Key, and Value without softmax. Since its computation is
sparse and avoids multiplication, SSA is efficient and has low computational
energy consumption. It is shown that Spikformer with SSA can outperform the
state-of-the-art SNNs-like frameworks in image classification on both
neuromorphic and static datasets. Spikformer (66.3M parameters) with comparable
size to SEW-ResNet-152 (60.2M,69.26%) can achieve 74.81% top1 accuracy on
ImageNet using 4 time steps, which is the state-of-the-art in directly trained
SNNs models."
12105,"It would be of interest to further study
the conditions under which networks display sign stability.","Within the context of our nonlinear model we have now
showed that stable states can be fully determined by the conÔ¨Åguration of the connections, no
matter what the strength of these connections are.","This might be an underexplored
mechanism that real neural networks employ, i.e.",2022-10-06 22:54:17+00:00,A Step Towards Uncovering The Structure of Multistable Neural Networks,cs.NE,"['cs.NE', 'cond-mat.dis-nn', 'math.DS', 'q-bio.NC']","[arxiv.Result.Author('Magnus Tournoy'), arxiv.Result.Author('Brent Doiron')]","We study the structure of multistable recurrent neural networks. The
activation function is simplified by a nonsmooth Heaviside step function. This
nonlinearity partitions the phase space into regions with different, yet linear
dynamics. We derive how multistability is encoded within the network
architecture. Stable states are identified by their semipositivity constraints
on the synaptic weight matrix. The restrictions can be separated by their
effects on the signs or the strengths of the connections. Exact results on
network topology, sign stability, weight matrix factorization, pattern
completion and pattern coupling are derived and proven. These may lay the
foundation of more complex recurrent neural networks and neurocomputing."
12121,"As no single method is found to
                                                  provide near-optimal performance across all environments, there is a rich scope for
                                                  further research which we support by proposing future directions and providing
                                                  optimized open-source implementations.","Through an extensive empirical evaluation comparing
                                                  eight state-of-the-art methods on the basis of (i) metrics directly evaluating the
                                                  skills‚Äô diversity, (ii) the skills‚Äô performance on adaptation tasks, and (iii) the skills‚Äô
                                                  performance when used as primitives for hierarchical planning; QD methods are
                                                  found to provide equal, and sometimes improved, performance whilst being less
                                                  sensitive to hyperparameters and more scalable.","1 INTRODUCTION

                                       In the past decade, Reinforcement Learning (RL) has shown great promise at tackling sequential
                                       decision making problems in a generic fashion, leading to breakthroughs in many Ô¨Åelds such as games
                                       Silver et al.",2022-10-06 11:06:39+00:00,Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Felix Chalumeau'), arxiv.Result.Author('Raphael Boige'), arxiv.Result.Author('Bryan Lim'), arxiv.Result.Author('Valentin Mac√©'), arxiv.Result.Author('Maxime Allard'), arxiv.Result.Author('Arthur Flajolet'), arxiv.Result.Author('Antoine Cully'), arxiv.Result.Author('Thomas Pierrot')]","Deep Reinforcement Learning (RL) has emerged as a powerful paradigm for
training neural policies to solve complex control tasks. However, these
policies tend to be overfit to the exact specifications of the task and
environment they were trained on, and thus do not perform well when conditions
deviate slightly or when composed hierarchically to solve even more complex
tasks. Recent work has shown that training a mixture of policies, as opposed to
a single one, that are driven to explore different regions of the state-action
space can address this shortcoming by generating a diverse set of behaviors,
referred to as skills, that can be collectively used to great effect in
adaptation tasks or for hierarchical planning. This is typically realized by
including a diversity term - often derived from information theory - in the
objective function optimized by RL. However these approaches often require
careful hyperparameter tuning to be effective. In this work, we demonstrate
that less widely-used neuroevolution methods, specifically Quality Diversity
(QD), are a competitive alternative to information-theory-augmented RL for
skill discovery. Through an extensive empirical evaluation comparing eight
state-of-the-art methods on the basis of (i) metrics directly evaluating the
skills' diversity, (ii) the skills' performance on adaptation tasks, and (iii)
the skills' performance when used as primitives for hierarchical planning; QD
methods are found to provide equal, and sometimes improved, performance whilst
being less sensitive to hyperparameters and more scalable. As no single method
is found to provide near-optimal performance across all environments, there is
a rich scope for further research which we support by proposing future
directions and providing optimized open-source implementations."
12171,"5.4 Effectiveness for Training with Batch Size 1

To further study the online training, i.e.","The
architectures with feedback connections can be further improved with neural architecture search [63].","not only online in time but also one sample per training,
which is consistent with biological learning and learning on neuromorphic hardware, we verify the
effectiveness for training with batch size 1.",2022-10-09 07:47:56+00:00,Online Training Through Time for Spiking Neural Networks,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Mingqing Xiao'), arxiv.Result.Author('Qingyan Meng'), arxiv.Result.Author('Zongpeng Zhang'), arxiv.Result.Author('Di He'), arxiv.Result.Author('Zhouchen Lin')]","Spiking neural networks (SNNs) are promising brain-inspired energy-efficient
models. Recent progress in training methods has enabled successful deep SNNs on
large-scale tasks with low latency. Particularly, backpropagation through time
(BPTT) with surrogate gradients (SG) is popularly used to achieve high
performance in a very small number of time steps. However, it is at the cost of
large memory consumption for training, lack of theoretical clarity for
optimization, and inconsistency with the online property of biological learning
and rules on neuromorphic hardware. Other works connect spike representations
of SNNs with equivalent artificial neural network formulation and train SNNs by
gradients from equivalent mappings to ensure descent directions. But they fail
to achieve low latency and are also not online. In this work, we propose online
training through time (OTTT) for SNNs, which is derived from BPTT to enable
forward-in-time learning by tracking presynaptic activities and leveraging
instantaneous loss and gradients. Meanwhile, we theoretically analyze and prove
that gradients of OTTT can provide a similar descent direction for optimization
as gradients based on spike representations under both feedforward and
recurrent conditions. OTTT only requires constant training memory costs
agnostic to time steps, avoiding the significant memory costs of BPTT for GPU
training. Furthermore, the update rule of OTTT is in the form of three-factor
Hebbian learning, which could pave a path for online on-chip learning. With
OTTT, it is the first time that two mainstream supervised SNN training methods,
BPTT with SG and spike representation-based training, are connected, and
meanwhile in a biologically plausible form. Experiments on CIFAR-10, CIFAR-100,
ImageNet, and CIFAR10-DVS demonstrate the superior performance of our method on
large-scale static and neuromorphic datasets in small time steps."
12288,"Since each solution randomly Ô¨Çips one
further studying evolution operators.","These Ô¨Åndings      mutation, the Hamming distance of new individual y differs
are applicable to analyze the other EC scenarios using the
combination encoding mechanisms and provide insights for            from itself by one.","bit which is either the same as or different from the optimal
   Generally, each generation of ENAS consists of two steps:
generating new individuals by evolution operation and select-       individual, the distance of x may be reduced or increased by
ing the individuals surviving into the next generation.",2022-10-11 12:16:06+00:00,Analysis of Expected Hitting Time for Designing Evolutionary Neural Architecture Search Algorithms,cs.NE,['cs.NE'],"[arxiv.Result.Author('Zeqiong Lv'), arxiv.Result.Author('Chao Qian'), arxiv.Result.Author('Gary G. Yen'), arxiv.Result.Author('Yanan Sun')]","Evolutionary computation-based neural architecture search (ENAS) is a popular
technique for automating architecture design of deep neural networks. In recent
years, various ENAS algorithms have been proposed and shown promising
performance on diverse real-world applications. In contrast to these
groundbreaking applications, there is no theoretical guideline for assigning a
reasonable running time (mainly affected by the generation number, population
size, and evolution operator) given both the anticipated performance and
acceptable computation budget on ENAS problems. The expected hitting time
(EHT), which refers to the average generations, is considered to analyze the
running time of ENAS algorithms. This paper proposes a general framework for
estimating the EHT of ENAS algorithms, which includes common configuration,
search space partition, transition probability estimation, and hitting time
analysis. By exploiting the proposed framework, we consider the so-called
($\lambda$+$\lambda$)-ENAS algorithms with different mutation operators and
manage to estimate the lower bounds of the EHT {which are critical for the
algorithm to find the global optimum}. Furthermore, we study the theoretical
results on the NAS-Bench-101 architecture searching problem, and the results
show that the one-bit mutation with ""bit-based fair mutation"" strategy needs
less time than the ""offspring-based fair mutation"" strategy, and the bitwise
mutation operator needs less time than the $q$-bit mutation operator. To the
best of our knowledge, this is the first work focusing on the theory of ENAS,
and the above observation will be substantially helpful in designing efficient
ENAS algorithms."
12369,"Spiking DS-ResNet can efÔ¨Åciently per-           tion (tdBN) method proposed by [Zheng et al., 2021] can ad-
form identity mapping of discrete spikes as well as reduce      just the Ô¨Åring rate and avoid gradient vanishing or explosion
the probability of dormant unit generation, making it more      to some extent, which is helpful for our further research on
suitable for gradient propagation.","It is
propose spiking dormant-suppressed residual network (spik-      worth noting that the threshold-dependent batch normaliza-
ing DS-ResNet).",To demonstrate the ef-       gradient vanishing.,2022-10-12 16:39:46+00:00,Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Lang Feng'), arxiv.Result.Author('Qianhui Liu'), arxiv.Result.Author('Huajin Tang'), arxiv.Result.Author('De Ma'), arxiv.Result.Author('Gang Pan')]","Spiking neural networks (SNNs) are bio-inspired neural networks with
asynchronous discrete and sparse characteristics, which have increasingly
manifested their superiority in low energy consumption. Recent research is
devoted to utilizing spatio-temporal information to directly train SNNs by
backpropagation. However, the binary and non-differentiable properties of spike
activities force directly trained SNNs to suffer from serious gradient
vanishing and network degradation, which greatly limits the performance of
directly trained SNNs and prevents them from going deeper. In this paper, we
propose a multi-level firing (MLF) method based on the existing spatio-temporal
back propagation (STBP) method, and spiking dormant-suppressed residual network
(spiking DS-ResNet). MLF enables more efficient gradient propagation and the
incremental expression ability of the neurons. Spiking DS-ResNet can
efficiently perform identity mapping of discrete spikes, as well as provide a
more suitable connection for gradient propagation in deep SNNs. With the
proposed method, our model achieves superior performances on a non-neuromorphic
dataset and two neuromorphic datasets with much fewer trainable parameters and
demonstrates the great ability to combat the gradient vanishing and degradation
problem in deep SNNs."
12770,"We also present
                                                concepts that could serve as a basis for the realization of this framework,
                                                and identify directions for further research required to enable large-scale
                                                system integration of neuromorphic devices.","Based on this
                                                analysis, we propose a microservice-based framework for neuromorphic
                                                systems integration, consisting of a neuromorphic-system proxy, which
                                                provides virtualization and communication capabilities required in dis-
                                                tributed systems of systems, in combination with a declarative program-
                                                ming approach oÔ¨Äering engineering-process abstraction.","1 Introduction

                                        The accelerating developments of digital computing technology and deep learning‚Äì
                                        based AI are leading towards technological, environmental, and economic im-
                                        passes (Thompson et al., 2021; Mehonic and Kenyon, 2022).",2022-10-20 12:09:29+00:00,Integration of Neuromorphic AI in Event-Driven Distributed Digitized Systems: Concepts and Research Directions,cs.NE,"['cs.NE', 'cs.DC', 'cs.ET']","[arxiv.Result.Author('Mattias Nilsson'), arxiv.Result.Author('Olov Schel√©n'), arxiv.Result.Author('Anders Lindgren'), arxiv.Result.Author('Ulf Bodin'), arxiv.Result.Author('Cristina Paniagua'), arxiv.Result.Author('Jerker Delsing'), arxiv.Result.Author('Fredrik Sandin')]","Increasing complexity and data-generation rates in cyber-physical systems and
the industrial Internet of things are calling for a corresponding increase in
AI capabilities at the resource-constrained edges of the Internet. Meanwhile,
the resource requirements of digital computing and deep learning are growing
exponentially, in an unsustainable manner. One possible way to bridge this gap
is the adoption of resource-efficient brain-inspired ""neuromorphic"" processing
and sensing devices, which use event-driven, asynchronous, dynamic
neurosynaptic elements with colocated memory for distributed processing and
machine learning. However, since neuromorphic systems are fundamentally
different from conventional von Neumann computers and clock-driven sensor
systems, several challenges are posed to large-scale adoption and integration
of neuromorphic devices into the existing distributed digital-computational
infrastructure. Here, we describe the current landscape of neuromorphic
computing, focusing on characteristics that pose integration challenges. Based
on this analysis, we propose a microservice-based framework for neuromorphic
systems integration, consisting of a neuromorphic-system proxy, which provides
virtualization and communication capabilities required in distributed systems
of systems, in combination with a declarative programming approach offering
engineering-process abstraction. We also present concepts that could serve as a
basis for the realization of this framework, and identify directions for
further research required to enable large-scale system integration of
neuromorphic devices."
12771,"We present established con-
cepts for programming, representation, and communication in distributed sys-
tems that could serve as a basis for the realization of this framework, and identify
directions for further research required to enable such integration.","The framework consists of a neuromorphic-
system proxy, which provides virtualization and communication capabilities re-
quired in a distributed setting, in combination with a declarative programming
approach oÔ¨Äering engineering-process abstraction.","2 Neuromorphic Systems

The Ô¨Åeld of neuromorphic engineering dates back to the late 1980s (Mead, 1990,
2020), and originally dealt with the creation and use of sensing and processing
systems that imitate the brain at the level of structure and device physics.",2022-10-20 12:09:29+00:00,Integration of Neuromorphic AI in Event-Driven Distributed Digitized Systems: Concepts and Research Directions,cs.NE,"['cs.NE', 'cs.DC', 'cs.ET']","[arxiv.Result.Author('Mattias Nilsson'), arxiv.Result.Author('Olov Schel√©n'), arxiv.Result.Author('Anders Lindgren'), arxiv.Result.Author('Ulf Bodin'), arxiv.Result.Author('Cristina Paniagua'), arxiv.Result.Author('Jerker Delsing'), arxiv.Result.Author('Fredrik Sandin')]","Increasing complexity and data-generation rates in cyber-physical systems and
the industrial Internet of things are calling for a corresponding increase in
AI capabilities at the resource-constrained edges of the Internet. Meanwhile,
the resource requirements of digital computing and deep learning are growing
exponentially, in an unsustainable manner. One possible way to bridge this gap
is the adoption of resource-efficient brain-inspired ""neuromorphic"" processing
and sensing devices, which use event-driven, asynchronous, dynamic
neurosynaptic elements with colocated memory for distributed processing and
machine learning. However, since neuromorphic systems are fundamentally
different from conventional von Neumann computers and clock-driven sensor
systems, several challenges are posed to large-scale adoption and integration
of neuromorphic devices into the existing distributed digital-computational
infrastructure. Here, we describe the current landscape of neuromorphic
computing, focusing on characteristics that pose integration challenges. Based
on this analysis, we propose a microservice-based framework for neuromorphic
systems integration, consisting of a neuromorphic-system proxy, which provides
virtualization and communication capabilities required in distributed systems
of systems, in combination with a declarative programming approach offering
engineering-process abstraction. We also present concepts that could serve as a
basis for the realization of this framework, and identify directions for
further research required to enable large-scale system integration of
neuromorphic devices."
12772,All connections indicated in this table are subjects for further research.,"The symbol
    ‚Äú‚äó‚Äù indicates that a concept has been connected to neuromorphic systems in the literature discussed in this article, while ‚Äú√ó‚Äù indicates that the
    connection is introduced here.","The relations between these concepts and
    conventional digital computing are described in Section 3, but are not illustrated here.",2022-10-20 12:09:29+00:00,Integration of Neuromorphic AI in Event-Driven Distributed Digitized Systems: Concepts and Research Directions,cs.NE,"['cs.NE', 'cs.DC', 'cs.ET']","[arxiv.Result.Author('Mattias Nilsson'), arxiv.Result.Author('Olov Schel√©n'), arxiv.Result.Author('Anders Lindgren'), arxiv.Result.Author('Ulf Bodin'), arxiv.Result.Author('Cristina Paniagua'), arxiv.Result.Author('Jerker Delsing'), arxiv.Result.Author('Fredrik Sandin')]","Increasing complexity and data-generation rates in cyber-physical systems and
the industrial Internet of things are calling for a corresponding increase in
AI capabilities at the resource-constrained edges of the Internet. Meanwhile,
the resource requirements of digital computing and deep learning are growing
exponentially, in an unsustainable manner. One possible way to bridge this gap
is the adoption of resource-efficient brain-inspired ""neuromorphic"" processing
and sensing devices, which use event-driven, asynchronous, dynamic
neurosynaptic elements with colocated memory for distributed processing and
machine learning. However, since neuromorphic systems are fundamentally
different from conventional von Neumann computers and clock-driven sensor
systems, several challenges are posed to large-scale adoption and integration
of neuromorphic devices into the existing distributed digital-computational
infrastructure. Here, we describe the current landscape of neuromorphic
computing, focusing on characteristics that pose integration challenges. Based
on this analysis, we propose a microservice-based framework for neuromorphic
systems integration, consisting of a neuromorphic-system proxy, which provides
virtualization and communication capabilities required in distributed systems
of systems, in combination with a declarative programming approach offering
engineering-process abstraction. We also present concepts that could serve as a
basis for the realization of this framework, and identify directions for
further research required to enable large-scale system integration of
neuromorphic devices."
12773,"Research directions                Neuromorphic systems integration challenges
    and concepts
23                                     Communication  Virtualization  Programming  Testing and
    Neuromorphic-system proxy                                                √ó      validation
       Neuromorphic-system simulation           √ó             √ó
       Microservices                                          ‚äó              √ó           √ó
                                                √ó             √ó              ‚äó           ‚äó
    Communication and data models               √ó             √ó              ‚äó
       Semantic technologies                    ‚äó                            ‚äó           ‚äó
       Embeddings                               ‚äó             √ó                          ‚äó
       Soft state                               √ó                                        ‚äó
       PubSub messaging                         √ó             √ó
       Graph data and querying                  √ó

    Declarative programming
       Process calculus
       Machine learning
       Statistical evaluation
    In conclusion, there is a need for further research on interparadigmatic NC‚Äì
DC communication models and virtualization to establish the transparency,
reliability, and security that is typically required by large-scale distributed com-
puting applications in cyber-physical systems and the industrial Internet.","The relations between these concepts and
    conventional digital computing are described in Section 3, but are not illustrated here.","Fur-
thermore, research on NC programming abstractions and related protocols for
training, validation, and testing are required to eÔ¨Éciently develop, integrate,
and maintain hybrid neuromorphic‚Äìdigital AI solutions in such large-scale dis-
tributed computing systems of systems.",2022-10-20 12:09:29+00:00,Integration of Neuromorphic AI in Event-Driven Distributed Digitized Systems: Concepts and Research Directions,cs.NE,"['cs.NE', 'cs.DC', 'cs.ET']","[arxiv.Result.Author('Mattias Nilsson'), arxiv.Result.Author('Olov Schel√©n'), arxiv.Result.Author('Anders Lindgren'), arxiv.Result.Author('Ulf Bodin'), arxiv.Result.Author('Cristina Paniagua'), arxiv.Result.Author('Jerker Delsing'), arxiv.Result.Author('Fredrik Sandin')]","Increasing complexity and data-generation rates in cyber-physical systems and
the industrial Internet of things are calling for a corresponding increase in
AI capabilities at the resource-constrained edges of the Internet. Meanwhile,
the resource requirements of digital computing and deep learning are growing
exponentially, in an unsustainable manner. One possible way to bridge this gap
is the adoption of resource-efficient brain-inspired ""neuromorphic"" processing
and sensing devices, which use event-driven, asynchronous, dynamic
neurosynaptic elements with colocated memory for distributed processing and
machine learning. However, since neuromorphic systems are fundamentally
different from conventional von Neumann computers and clock-driven sensor
systems, several challenges are posed to large-scale adoption and integration
of neuromorphic devices into the existing distributed digital-computational
infrastructure. Here, we describe the current landscape of neuromorphic
computing, focusing on characteristics that pose integration challenges. Based
on this analysis, we propose a microservice-based framework for neuromorphic
systems integration, consisting of a neuromorphic-system proxy, which provides
virtualization and communication capabilities required in distributed systems
of systems, in combination with a declarative programming approach offering
engineering-process abstraction. We also present concepts that could serve as a
basis for the realization of this framework, and identify directions for
further research required to enable large-scale system integration of
neuromorphic devices."
12902,"The separated caste algorithm is the worst, perhaps
7 0.0015 0.02371 ‚àí0.01692                                       the learning relations should be further researched.","Comparing the socio-cognitive versions,
6 0.0012 0.02645 ‚àí0.01465                                       the Bode plots of the caste-based algorithm seems to be the
                                                                best Ô¨Åt.",8 0.0018 0.02087 ‚àí0.01857                                          In Fig.,2022-10-23 22:21:10+00:00,Socio-cognitive Optimization of Time-delay Control Problems using Evolutionary Metaheuristics,cs.NE,"['cs.NE', 'cs.AI', 'I.2.11; I.2.8']","[arxiv.Result.Author('Piotr Kipinski'), arxiv.Result.Author('Hubert Guzowski'), arxiv.Result.Author('Aleksandra Urbanczyk'), arxiv.Result.Author('Maciej Smolka'), arxiv.Result.Author('Marek Kisiel-Dorohinicki'), arxiv.Result.Author('Aleksander Byrski'), arxiv.Result.Author('Zuzana Kominkova Oplatkova'), arxiv.Result.Author('Roman Senkerik'), arxiv.Result.Author('Libor Pekar'), arxiv.Result.Author('Radek Matusu'), arxiv.Result.Author('Frantisek Gazdos')]","Metaheuristics are universal optimization algorithms which should be used for
solving difficult problems, unsolvable by classic approaches. In this paper we
aim at constructing novel socio-cognitive metaheuristic based on castes, and
apply several versions of this algorithm to optimization of time-delay system
model. Besides giving the background and the details of the proposed algorithms
we apply them to optimization of selected variants of the problem and discuss
the results."
12984,"It thus allows taking full advantage
of evolution in NAS and similar problems, and serves as a theoretical and experimental foundation
for further research on improving evolutionary search.","Empirical results on three SOTA NAS benchmarks further verify the theoretical
analysis, demonstrating the effectiveness of the SEP crossover.","2 RELATED WORK

The permutation problem has been discussed in the Neuroevolution community for many years.",2022-10-25 13:39:55+00:00,Shortest Edit Path Crossover: A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Xin Qiu'), arxiv.Result.Author('Risto Miikkulainen')]","Evolutionary algorithms (EAs) have gained attention recently due to their
success in neural architecture search (NAS). However, whereas traditional EAs
draw much power from crossover operations, most evolutionary NAS methods deploy
only mutation operators. The main reason is the permutation problem: The
mapping between genotype and phenotype in traditional graph representations is
many-to-one, leading to a disruptive effect of standard crossover. This work
conducts the first theoretical analysis of the behaviors of crossover and
mutation in the NAS context, and proposes a new crossover operator based on the
shortest edit path (SEP) in graph space. The SEP crossover is shown to overcome
the permutation problem, and as a result, offspring generated by the SEP
crossover is theoretically proved to have a better expected improvement in
terms of graph edit distance to global optimum, compared to mutation and
standard crossover. Experiments further show that the SEP crossover
significantly outperforms mutation and standard crossover on three
state-of-the-art NAS benchmarks. The SEP crossover therefore allows taking full
advantage of evolution in NAS, and potentially other similar design problems as
well."
12985,"It thus allows taking full advantage
of evolution in NAS and similar problems, and serves as a theoretical and experimental foundation
for further research on improving evolutionary search.","Empirical results on three SOTA NAS benchmarks further verify the theoretical
analysis, demonstrating the effectiveness of the SEP crossover.","2 RELATED WORK

The permutation problem has been discussed in the Neuroevolution community for many years.",2022-10-25 13:39:55+00:00,Shortest Edit Path Crossover: A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Xin Qiu'), arxiv.Result.Author('Risto Miikkulainen')]","Evolutionary algorithms (EAs) have gained attention recently due to their
success in neural architecture search (NAS). However, whereas traditional EAs
draw much power from crossover operations, most evolutionary NAS methods deploy
only mutation operators. The main reason is the permutation problem: The
mapping between genotype and phenotype in traditional graph representations is
many-to-one, leading to a disruptive effect of standard crossover. This work
conducts the first theoretical analysis of the behaviors of crossover and
mutation in the NAS context, and proposes a new crossover operator based on the
shortest edit path (SEP) in graph space. The SEP crossover is shown to overcome
the permutation problem, and as a result, offspring generated by the SEP
crossover is theoretically proved to have a better expected improvement in
terms of graph edit distance to global optimum, compared to mutation and
standard crossover. Experiments further show that the SEP crossover
significantly outperforms mutation and standard crossover on three
state-of-the-art NAS benchmarks. The SEP crossover therefore allows taking full
advantage of evolution in NAS, and potentially other similar design problems as
well."
13095,the conclusion and further research directions are presented.,?,"2 Related work

To our knowledge, no other study has been previously done on FDA perfor-
mance for low-dimensional continuous optimization problems.",2022-10-16 16:50:35+00:00,Study of the Fractal decomposition based metaheuristic on low-dimensional Black-Box optimization problems,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Arcadi Llanza'), arxiv.Result.Author('Nadiya Shvai'), arxiv.Result.Author('Amir Nakib')]","This paper analyzes the performance of the Fractal Decomposition Algorithm
(FDA) metaheuristic applied to low-dimensional continuous optimization
problems. This algorithm was originally developed specifically to deal
efficiently with high-dimensional continuous optimization problems by building
a fractal-based search tree with a branching factor linearly proportional to
the number of dimensions. Here, we aim to answer the question of whether FDA
could be equally effective for low-dimensional problems. For this purpose, we
evaluate the performance of FDA on the Black Box Optimization Benchmark (BBOB)
for dimensions 2, 3, 5, 10, 20, and 40. The experimental results show that
overall the FDA in its current form does not perform well enough. Among
different function groups, FDA shows its best performance on Misc. moderate and
Weak structure functions."
13147,"Resulting power planes for a 5-net design problem            6.6 H-GOMLP: results on solving non-trivial multi-
                                                                                 layer problems
it is part of our future work to further study the evolutionary
patterns of the handles.",FIGURE 13.,"For design C,D,E and F in Fig.",2022-10-28 03:58:52+00:00,Hierarchical Automatic Power Plane Generation with Genetic Optimization and Multilayer Perceptron,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Haiguang Liao'), arxiv.Result.Author('Vinay Patil'), arxiv.Result.Author('Xuliang Dong'), arxiv.Result.Author('Devika Shanbhag'), arxiv.Result.Author('Elias Fallon'), arxiv.Result.Author('Taylor Hogan'), arxiv.Result.Author('Mirko Spasojevic'), arxiv.Result.Author('Levent Burak Kara')]","We present an automatic multilayer power plane generation method to
accelerate the design of printed circuit boards (PCB). In PCB design, while
automatic solvers have been developed to predict important indicators such as
the IR-drop, power integrity, and signal integrity, the generation of the power
plane itself still largely relies on laborious manual methods. Our automatic
power plane generation approach is based on genetic optimization combined with
a multilayer perceptron and is able to automatically generate power planes
across a diverse set of problems with varying levels of difficulty. Our method
GOMLP consists of an outer loop genetic optimizer (GO) and an inner loop
multi-layer perceptron (MLP) that generate power planes automatically. The
critical elements of our approach include contour detection, feature expansion,
and a distance measure to enable island-minimizing complex power plane
generation. We compare our approach to a baseline solution based on A*. The A*
method consisting of a sequential island generation and merging process which
can produce less than ideal solutions. Our experimental results show that on
single layer power plane problems, our method outperforms A* in 71% of the
problems with varying levels of board layout difficulty. We further describe
H-GOMLP, which extends GOMLP to multilayer power plane problems using
hierarchical clustering and net similarities based on the Hausdorff distance."
13206,"Exp 8: To further study the effect of the state representation on the population, we record the added
undiscounted return after optimizing the shared state representation.","16 show that RL agent in ERL-Re2 (TD3) is selected as elites with a larger probability and as
discarders with a smaller probability than RL agent in ERL(TD3) and PDERL(TD3), which indicates
that both EA and RL in ERL-Re2 (TD3) have more competitive effects on population evolution than
in ERL(TD3) and PDERL(TD3).","SpeciÔ¨Åcally, we record the
change in average return, maximum return, and minimum return of the population before and after
the optimization of the shared state representation.",2022-10-26 10:34:48+00:00,ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Pengyi Li'), arxiv.Result.Author('Hongyao Tang'), arxiv.Result.Author('Jianye Hao'), arxiv.Result.Author('Yan Zheng'), arxiv.Result.Author('Xian Fu'), arxiv.Result.Author('Zhaopeng Meng')]","Deep Reinforcement Learning (Deep RL) and Evolutionary Algorithm (EA) are two
major paradigms of policy optimization with distinct learning principles, i.e.,
gradient-based v.s. gradient free. An appealing research direction is
integrating Deep RL and EA to devise new methods by fusing their complementary
advantages. However, existing works on combining Deep RL and EA have two common
drawbacks: 1) the RL agent and EA agents learn their policies individually,
neglecting efficient sharing of useful common knowledge; 2) parameter-level
policy optimization guarantees no semantic level of behavior evolution for the
EA side. In this paper, we propose Evolutionary Reinforcement Learning with
Two-scale State Representation and Policy Representation (ERL-Re2), a novel
solution to the aforementioned two drawbacks. The key idea of ERL-Re2 is
two-scale representation: all EA and RL policies share the same nonlinear state
representation while maintaining individual linear policy representations. The
state representation conveys expressive common features of the environment
learned by all the agents collectively; the linear policy representation
provides a favorable space for efficient policy optimization, where novel
behavior-level crossover and mutation operations can be performed. Moreover,
the linear policy representation allows convenient generalization of policy
fitness with the help of Policy-extended Value Function Approximator (PeVFA),
further improving the sample efficiency of fitness estimation. The experiments
on a range of continuous control tasks show that ERL-Re2 consistently
outperforms strong baselines and achieves significant improvement over both its
Deep RL and EA components."
13207,"MI loss brings certain performance improvements in Ant, which is worth further research in the
future.","As shown in Table 1, ERL-Re2 incurs some additional time consumption compared to

                                                            19
Accepted by Deep Reinforcement Learning Workshop, NeurIPS 2022

      Ant                                                             Walker

6000                                                            5000
Undiscounted Return
                                           Undiscounted Return50004000

4000                                                            3000

3000                                                            2000

2000  ERL-Re2(TD3)                                              1000

1000  ERL-Re2(TD3) w/ MI loss                                   0

      0.2 Tim0.e4 Steps (01.6e6) 0.8   1.0                       0.0  0.2 Tim0.e4 Steps (01.6e6) 0.8   1.0
                                      1e6                                                             1e6

Figure 18: Comparisons of ERL-Re2 (TD3) and ERL-Re2 (TD3) with MI loss (i.e., Self-supervised
loss).",other methods.,2022-10-26 10:34:48+00:00,ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Pengyi Li'), arxiv.Result.Author('Hongyao Tang'), arxiv.Result.Author('Jianye Hao'), arxiv.Result.Author('Yan Zheng'), arxiv.Result.Author('Xian Fu'), arxiv.Result.Author('Zhaopeng Meng')]","Deep Reinforcement Learning (Deep RL) and Evolutionary Algorithm (EA) are two
major paradigms of policy optimization with distinct learning principles, i.e.,
gradient-based v.s. gradient free. An appealing research direction is
integrating Deep RL and EA to devise new methods by fusing their complementary
advantages. However, existing works on combining Deep RL and EA have two common
drawbacks: 1) the RL agent and EA agents learn their policies individually,
neglecting efficient sharing of useful common knowledge; 2) parameter-level
policy optimization guarantees no semantic level of behavior evolution for the
EA side. In this paper, we propose Evolutionary Reinforcement Learning with
Two-scale State Representation and Policy Representation (ERL-Re2), a novel
solution to the aforementioned two drawbacks. The key idea of ERL-Re2 is
two-scale representation: all EA and RL policies share the same nonlinear state
representation while maintaining individual linear policy representations. The
state representation conveys expressive common features of the environment
learned by all the agents collectively; the linear policy representation
provides a favorable space for efficient policy optimization, where novel
behavior-level crossover and mutation operations can be performed. Moreover,
the linear policy representation allows convenient generalization of policy
fitness with the help of Policy-extended Value Function Approximator (PeVFA),
further improving the sample efficiency of fitness estimation. The experiments
on a range of continuous control tasks show that ERL-Re2 consistently
outperforms strong baselines and achieves significant improvement over both its
Deep RL and EA components."
13748,"In this paper, we further research the assistance  membrane potential V (t) reaches the Ô¨Åring threshold Vth.","a shorter conference version of this paper appeared in an
previous conference paper (ICASSP 2022) [23] that discussed        Third, the postsynaptic neuron will generate a spike once its
the function of motif distributions in SNN of spatial and
temporal tasks.","At
of Motifs for better simulating the cognitive phenomenon           the same time, the membrane potential V will be reset as the
including the McGurk effect and cocktail party effect.",2022-11-12 08:23:55+00:00,Motif-topology improved Spiking Neural Network for the Cocktail Party Effect and McGurk Effect,cs.NE,"['cs.NE', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Shuncheng Jia'), arxiv.Result.Author('Tielin Zhang'), arxiv.Result.Author('Ruichen Zuo'), arxiv.Result.Author('Bo Xu')]","Network architectures and learning principles are playing key in forming
complex functions in artificial neural networks (ANNs) and spiking neural
networks (SNNs). SNNs are considered the new-generation artificial networks by
incorporating more biological features than ANNs, including dynamic spiking
neurons, functionally specified architectures, and efficient learning
paradigms. Network architectures are also considered embodying the function of
the network. Here, we propose a Motif-topology improved SNN (M-SNN) for the
efficient multi-sensory integration and cognitive phenomenon simulations. The
cognitive phenomenon simulation we simulated includes the cocktail party effect
and McGurk effect, which are discussed by many researchers. Our M-SNN
constituted by the meta operator called network motifs. The source of 3-node
network motifs topology from artificial one pre-learned from the spatial or
temporal dataset. In the single-sensory classification task, the results showed
the accuracy of M-SNN using network motif topologies was higher than the pure
feedforward network topology without using them. In the multi-sensory
integration task, the performance of M-SNN using artificial network motif was
better than the state-of-the-art SNN using BRP (biologically-plausible reward
propagation). Furthermore, the M-SNN could better simulate the cocktail party
effect and McGurk effect with lower computational cost. We think the artificial
network motifs could be considered as some prior knowledge that would
contribute to the multi-sensory integration of SNNs and provide more benefits
for simulating the cognitive phenomenon."
13916,"HiveNAS was designed with a
modular and reusable pattern to encourage further research; from the dataset to the evaluation strat-
egy, every component in the pipeline can be trivially substituted if they support particular endpoints
(delineated thoroughly in the framework‚Äôs documentation1).","Although each NAS component has a distinct role, some operations (sampling and evaluating candi-
dates, for instance) overlap due to shared implementation properties.","Although HiveNAS was developed strictly as a NAS framework, a few numerical benchmarks are
provided to test the integrity of ABC (independent of the NAS components) and to empirically
deduce the optimal conÔ¨Åguration parameters for the optimization algorithm.",2022-11-18 14:11:47+00:00,HiveNAS: Neural Architecture Search using Artificial Bee Colony Optimization,cs.NE,"['cs.NE', 'cs.AI', 'cs.LG', 'I.2.0; G.1.6; I.2.2; G.3; I.2.11']","[arxiv.Result.Author('Mohamed Shahawy'), arxiv.Result.Author('Elhadj Benkhelifa')]","The traditional Neural Network-development process requires substantial
expert knowledge and relies heavily on intuition and trial-and-error. Neural
Architecture Search (NAS) frameworks were introduced to robustly search for
network topologies, as well as facilitate the automated development of Neural
Networks. While some optimization approaches -- such as Genetic Algorithms --
have been extensively explored in the NAS context, other Metaheuristic
Optimization algorithms have not yet been evaluated. In this paper, we propose
HiveNAS, the first Artificial Bee Colony-based NAS framework."
14094,A further research is now directed to:                                    Fleury G. (1993).,approach is verified by computing robust solutions.,"M√©thodes stochastiques et
ÔÇß obtain mathematical formulation of the problem.",2022-11-23 06:39:17+00:00,Stochastic Capacitated Arc Routing Problem,cs.NE,['cs.NE'],"[arxiv.Result.Author('Fleury G√©rard'), arxiv.Result.Author('Lacomme Philippe'), arxiv.Result.Author('Christian Prins')]","This paper deals with the Stochastic Capacitated Arc Routing Problem (SCARP),
obtained by randomizing quantities on the arcs in the CARP. Optimization
problems for the SCARP are characterized by decisions that are made without
knowing their full consequences. For real-life problems, it is important to
create solutions insensitive to variations of the quantities to collect because
of the randomness of these quantities. Efficient robust solutions are required
to avoid unprofitable costly moves of vehicles to the depot node. Different
criteria are proposed to model the SCARP and advanced concepts of a genetic
algorithm optimizing both cost and robustness are provided. The method is
benchmarked on the well-known instances proposed by DeArmon, Eglese and
Belenguer. The results prove it is possible to obtain robust solutions without
any significant enlargement of the solution cost. This allows treating more
realistic problems including industrial goals and constraints linked to
variations in the quantities to be collected."
14095,"with the SCARPs and further researches are required
providing tractable formulations for medium scale instances.","PhD Thesis,
Conventional formulations may be inappropriate in dealing         The University Blaise Pascal of Clermont-Ferrand, France.","_________, Lacomme P., Prins C., (2004).",2022-11-23 06:39:17+00:00,Stochastic Capacitated Arc Routing Problem,cs.NE,['cs.NE'],"[arxiv.Result.Author('Fleury G√©rard'), arxiv.Result.Author('Lacomme Philippe'), arxiv.Result.Author('Christian Prins')]","This paper deals with the Stochastic Capacitated Arc Routing Problem (SCARP),
obtained by randomizing quantities on the arcs in the CARP. Optimization
problems for the SCARP are characterized by decisions that are made without
knowing their full consequences. For real-life problems, it is important to
create solutions insensitive to variations of the quantities to collect because
of the randomness of these quantities. Efficient robust solutions are required
to avoid unprofitable costly moves of vehicles to the depot node. Different
criteria are proposed to model the SCARP and advanced concepts of a genetic
algorithm optimizing both cost and robustness are provided. The method is
benchmarked on the well-known instances proposed by DeArmon, Eglese and
Belenguer. The results prove it is possible to obtain robust solutions without
any significant enlargement of the solution cost. This allows treating more
realistic problems including industrial goals and constraints linked to
variations in the quantities to be collected."
14247,"It is a goal to further study these matrix representations not only of SN P
systems but also other variants of P systems.","Theorem 5 gives a version of reachability of conÔ¨Ågurations of SN P system
with delay.","Already in the 2011, [8] suggested
matrix representation for ECPe systems.",2022-11-28 09:09:07+00:00,Matrix representations of spiking neural P systems: Revisited,cs.NE,['cs.NE'],[arxiv.Result.Author('Henry N. Adorna')],"In the 2010, matrix representation of SN P system without delay was presented
while in the case of SN P systems with delay, matrix representation was
suggested in the 2017. These representations brought about series of simulation
of SN P systems using computer software and hardware technology. In this work,
we revisit these representation and provide some observations on the behavior
of the computations of SN P systems. The concept of reachability of
configuration is considered in both SN P systems with and without delays. A
better computation of next configuration is proposed in the case of SN P system
with delay."
14343,"In summary, learning generalizable counting behavior is still an open
                                                   problem and we discuss potential approaches for further research.","In particular, we observe
                                                   that the saturation of activation functions in LSTMs and the correct weight setting
                                                   for ReLUs to generalize counting behavior are not achieved in standard training
                                                   regimens.","1 Introduction

                                        Recurrent Neural Networks (RNNs) have been the go-to neural model for sequential tasks since the
                                        1980s and have been popular in recent years for a variety of applications, (see e.g., Karpathy, 2015),
                                        including Natural Language Processing (NLP).",2022-11-29 17:58:42+00:00,Exploring the Long-Term Generalization of Counting Behavior in RNNs,cs.NE,"['cs.NE', 'cs.FL', 'cs.LG']","[arxiv.Result.Author('Nadine El-Naggar'), arxiv.Result.Author('Pranava Madhyastha'), arxiv.Result.Author('Tillman Weyde')]","In this study, we investigate the generalization of LSTM, ReLU and GRU models
on counting tasks over long sequences. Previous theoretical work has
established that RNNs with ReLU activation and LSTMs have the capacity for
counting with suitable configuration, while GRUs have limitations that prevent
correct counting over longer sequences. Despite this and some positive
empirical results for LSTMs on Dyck-1 languages, our experimental results show
that LSTMs fail to learn correct counting behavior for sequences that are
significantly longer than in the training data. ReLUs show much larger variance
in behavior and in most cases worse generalization. The long sequence
generalization is empirically related to validation loss, but reliable long
sequence generalization seems not practically achievable through
backpropagation with current techniques. We demonstrate different failure modes
for LSTMs, GRUs and ReLUs. In particular, we observe that the saturation of
activation functions in LSTMs and the correct weight setting for ReLUs to
generalize counting behavior are not achieved in standard training regimens. In
summary, learning generalizable counting behavior is still an open problem and
we discuss potential approaches for further research."
14382,"Given that genetic algorithms go even further by not training one
network, but 100 at a time, and considering our limited time, we had to halt further research.","By contrast, the deepest ResNet uses more than 1000
dimensioniona in its lowest layers.","39
7 Further enhancements

7.1 Optimisation

The single biggest challenge we faced was performance.",2022-10-20 18:41:57+00:00,Combining Neuro-Evolution of Augmenting Topologies with Convolutional Neural Networks,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Jan Hohenheim'), arxiv.Result.Author('Mathias Fischler'), arxiv.Result.Author('Sara Zarubica'), arxiv.Result.Author('Jeremy Stucki')]","Current deep convolutional networks are fixed in their topology. We explore
the possibilites of making the convolutional topology a parameter itself by
combining NeuroEvolution of Augmenting Topologies (NEAT) with Convolutional
Neural Networks (CNNs) and propose such a system using blocks of Residual
Networks (ResNets). We then explain how our suggested system can only be built
once additional optimizations have been made, as genetic algorithms are way
more demanding than training per backpropagation. On the way there we explain
most of those buzzwords and offer a gentle and brief introduction to the most
important modern areas of machine learning"
14580,"However, the performance of the proposed algorithm does not reach state-of-the-art performance
and further researches are required to increase the convergence rate and to reduce the computational
times.","To the best of our knowledge the proposed ACO
is the first one proposed for the CARP providing high quality results for large scale instances.","References

1.",2022-11-19 10:31:27+00:00,First Competitive Ant Colony Scheme for the CARP,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Lacomme Philippe'), arxiv.Result.Author('Prins Christian'), arxiv.Result.Author('Tanguy Alain')]","This paper addresses the Capacitated Arc Routing Problem (CARP) using an Ant
Colony Optimization scheme. Ant Colony schemes can compute solutions for medium
scale instances of VRP. The proposed Ant Colony is dedicated to large-scale
instances of CARP with more than 140 nodes and 190 arcs to service. The Ant
Colony scheme is coupled with a local search procedure and provides high
quality solutions. The benchmarks we carried out prove possible to obtain
solutions as profitable as CARPET ones can be obtained using such scheme when a
sufficient number of iterations is devoted to the ants. It competes with the
Genetic Algorithm of Lacomme et al. regarding solution quality but it is more
time consuming on large scale instances. The method has been intensively
benchmarked on the well-known instances of Eglese, DeArmon and the last ones of
Belenguer and Benavent. This research report is a step forward CARP resolution
by Ant Colony proving ant schemes can compete with Taboo search methods and
Genetic Algorithms"
14581,"The
Algorithm Name             Total Time   Accuracy                           authors hope that this work will open new doors of
                           Taken (sec)     (%)                             opportunities for the researchers who are working with similar
                                                                           topics and through further research, they will be able to take
Proposed Hybrid Algorithm  1671         92.99                              this idea to a more advanced level where the management will
                                                                           be simpler and easier.","COMPARISON WITH BASE LEVEL ALGORITHMS                 solve other departmental tasks such as Teaching Assistant
                                                                           appointment and Lab Change procedure of the students.","Genetic Algorithm          4579         89.89
                                                                                                    ACKNOWLEDGMENT

                                                                               The authors would like to thank the Almighty for keeping
                                                                           us healthy in these tough times.",2022-11-15 09:43:02+00:00,A Hybrid Evolutionary Approach to Solve University Course Allocation Problem,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Dibyo Fabian Dofadar'), arxiv.Result.Author('Riyo Hayat Khan'), arxiv.Result.Author('Shafqat Hasan'), arxiv.Result.Author('Towshik Anam Taj'), arxiv.Result.Author('Arif Shakil'), arxiv.Result.Author('Mahbub Majumdar')]","This paper discusses various types of constraints, difficulties and solutions
to overcome the challenges regarding university course allocation problem. A
hybrid evolutionary algorithm has been defined combining Local Repair Algorithm
and Modified Genetic Algorithm to generate the best course assignment. After
analyzing the collected dataset, all the necessary constraints were formulated.
These constraints manage to cover the aspects needed to be kept in mind while
preparing clash free and efficient class schedules for every faculty member.
The goal is to generate an optimized solution which will fulfill those
constraints while maintaining time efficiency and also reduce the workload of
handling this task manually. The proposed algorithm was compared with some base
level optimization algorithms to show the better efficiency in terms of
accuracy and time."
14671,"The values from other sensors remained almost                 5 Discussion, Conclusions and
    constantly, while the variances of their values                  further research
    could be ascribed to the measurement accuracy of
    the particular sensor.",the night due to value 0 measured by light sensor.,"The following conclusions can be obtained, accord-
                                                                  ing to the results of the Ô¨Årst test: In general, the
        Due to the big number of features obtained                conducted test showed that the system is reliable
    as a result of preprocessing, the illustration of             due to the continuous operating over 14 days.",2022-12-07 14:35:23+00:00,Time series numerical association rule mining variants in smart agriculture,cs.NE,['cs.NE'],"[arxiv.Result.Author('Iztok Fister Jr.'), arxiv.Result.Author('Du≈°an Fister'), arxiv.Result.Author('Iztok Fister'), arxiv.Result.Author('Vili Podgorelec'), arxiv.Result.Author('Sancho Salcedo-Sanz')]","Numerical association rule mining offers a very efficient way of mining
association rules, where algorithms can operate directly with categorical and
numerical attributes. These methods are suitable for mining different
transaction databases, where data are entered sequentially. However, little
attention has been paid to the time series numerical association rule mining,
which offers a new technique for extracting association rules from time series
data. This paper presents a new algorithmic method for time series numerical
association rule mining and its application in smart agriculture. We offer a
concept of a hardware environment for monitoring plant parameters and a novel
data mining method with practical experiments. The practical experiments showed
the method's potential and opened the door for further extension."
14800,"We hope that this chapter will
stimulate further research pursuing a neuromorphic approach to spacecraft
onboard computation and sensing.","ducted by the ACT on evaluating the feasibility of a neuromorphic approach
for onboard AI applications (Section 5).","2 Spiking neural networks

Arguably, the feature which is found most often in modern neuromorphic

algorithms is spike-based communication.",2022-12-10 07:46:29+00:00,Neuromorphic Computing and Sensing in Space,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Dario Izzo'), arxiv.Result.Author('Alexander Hadjiivanov'), arxiv.Result.Author('Domink Dold'), arxiv.Result.Author('Gabriele Meoni'), arxiv.Result.Author('Emmanuel Blazquez')]","The term ``neuromorphic'' refers to systems that are closely resembling the
architecture and/or the dynamics of biological neural networks. Typical
examples are novel computer chips designed to mimic the architecture of a
biological brain, or sensors that get inspiration from, e.g., the visual or
olfactory systems in insects and mammals to acquire information about the
environment. This approach is not without ambition as it promises to enable
engineered devices able to reproduce the level of performance observed in
biological organisms -- the main immediate advantage being the efficient use of
scarce resources, which translates into low power requirements. The emphasis on
low power and energy efficiency of neuromorphic devices is a perfect match for
space applications. Spacecraft -- especially miniaturized ones -- have strict
energy constraints as they need to operate in an environment which is scarce
with resources and extremely hostile. In this work we present an overview of
early attempts made to study a neuromorphic approach in a space context at the
European Space Agency's (ESA) Advanced Concepts Team (ACT)."
14801,"We hope that this chapter will
stimulate further research pursuing a neuromorphic approach to spacecraft
onboard computation and sensing.","ducted by the ACT on evaluating the feasibility of a neuromorphic approach
for onboard AI applications (Section 5).","2 Spiking neural networks

Arguably, the feature which is found most often in modern neuromorphic

algorithms is spike-based communication.",2022-12-10 07:46:29+00:00,Neuromorphic Computing and Sensing in Space,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Dario Izzo'), arxiv.Result.Author('Alexander Hadjiivanov'), arxiv.Result.Author('Dominik Dold'), arxiv.Result.Author('Gabriele Meoni'), arxiv.Result.Author('Emmanuel Blazquez')]","The term ``neuromorphic'' refers to systems that are closely resembling the
architecture and/or the dynamics of biological neural networks. Typical
examples are novel computer chips designed to mimic the architecture of a
biological brain, or sensors that get inspiration from, e.g., the visual or
olfactory systems in insects and mammals to acquire information about the
environment. This approach is not without ambition as it promises to enable
engineered devices able to reproduce the level of performance observed in
biological organisms -- the main immediate advantage being the efficient use of
scarce resources, which translates into low power requirements. The emphasis on
low power and energy efficiency of neuromorphic devices is a perfect match for
space applications. Spacecraft -- especially miniaturized ones -- have strict
energy constraints as they need to operate in an environment which is scarce
with resources and extremely hostile. In this work we present an overview of
early attempts made to study a neuromorphic approach in a space context at the
European Space Agency's (ESA) Advanced Concepts Team (ACT)."
14942,This will be the subject of our further research.,"Similar studies could be made for comparing deterministic and nature-inspired methods on problems with general
or hidden constraints.","Acknowledgements

    This work was supported by the Grant Agency of the Czech Republic project no.",2022-12-13 19:44:24+00:00,Are metaheuristics worth it? A computational comparison between nature-inspired and deterministic techniques on black-box optimization problems,cs.NE,"['cs.NE', 'cs.AI', 'math.OC']",[arxiv.Result.Author('Jakub Kudela')],"In the field of derivative-free optimization, both of its main branches, the
deterministic and nature-inspired techniques, experienced in recent years
substantial advancement. In this paper, we provide an extensive computational
comparison of selected methods from each of these branches. The chosen
representatives were either standard and well-utilized methods, or the
best-performing methods from recent numerical comparisons. The computational
comparison was performed on five different benchmark sets and the results were
analyzed in terms of performance, time complexity, and convergence properties
of the selected methods. The results showed that, when dealing with situations
where the objective function evaluations are relatively cheap, the
nature-inspired methods have a significantly better performance than their
deterministic counterparts. However, in situations when the function
evaluations are costly or otherwise prohibited, the deterministic methods might
provide more consistent and overall better results."
15071,"Therefore, the mul-
tiple task generation and optimization methods used in these        where X indicates a solution with N features, and xi ÔÄΩ 1 means
existing EMT-based FS methods deserve further study.","X ÔÄΩ (x1, x2 ,..., xN )                                                   (1)
PSO variants are employed to perform knowledge transfer and
show limitations in convergence speed and search capability as                                         xi ÔÉé{0,1},i ÔÄΩ 1, 2,3..., N
the feature dimensionality increases [22].","that the corresponding i-th feature will be selected; otherwise,

   Based on the above analysis, this paper devises a more ef-       xi ÔÄΩ 0 means that it will not be selected.",2022-12-17 12:06:46+00:00,An Evolutionary Multitasking Algorithm with Multiple Filtering for High-Dimensional Feature Selection,cs.NE,['cs.NE'],"[arxiv.Result.Author('Lingjie Li'), arxiv.Result.Author('Manlin Xuan'), arxiv.Result.Author('Qiuzhen Lin'), arxiv.Result.Author('Min Jiang'), arxiv.Result.Author('Zhong Ming'), arxiv.Result.Author('Kay Chen Tan')]","Recently, evolutionary multitasking (EMT) has been successfully used in the
field of high-dimensional classification. However, the generation of multiple
tasks in the existing EMT-based feature selection (FS) methods is relatively
simple, using only the Relief-F method to collect related features with similar
importance into one task, which cannot provide more diversified tasks for
knowledge transfer. Thus, this paper devises a new EMT algorithm for FS in
high-dimensional classification, which first adopts different filtering methods
to produce multiple tasks and then modifies a competitive swarm optimizer to
efficiently solve these related tasks via knowledge transfer. First, a
diversified multiple task generation method is designed based on multiple
filtering methods, which generates several relevant low-dimensional FS tasks by
eliminating irrelevant features. In this way, useful knowledge for solving
simple and relevant tasks can be transferred to simplify and speed up the
solution of the original high-dimensional FS task. Then, a competitive swarm
optimizer is modified to simultaneously solve these relevant FS tasks by
transferring useful knowledge among them. Numerous empirical results
demonstrate that the proposed EMT-based FS method can obtain a better feature
subset than several state-of-the-art FS methods on eighteen high-dimensional
datasets."
15072,"To verify the experimental results and to facilitate further study
                                                                   by other researchers, we publish the source codes of our method
                                                                   and two reproduction methods (i.e., PSO-EMT and MTPSO)
                                                                   on GitHub1.","Moreover,          All the source codes of the compared algorithms, except
to verify the effectiveness of these FS methods, the classifica-   PSO-EMT and MTPSO, are provided by the original references.","B. Datasets
                                                                      In our experiments, eighteen unbalanced high-dimensional
                                                                   genetic datasets with more than 2000 features are adopted to
                                                                   validate the effectiveness of the proposed MF-CSO, which are

                                                                   1 https://github.com/gelin123/MF_CSO_Materials
                                                                                                                                   8

also available in1.",2022-12-17 12:06:46+00:00,An Evolutionary Multitasking Algorithm with Multiple Filtering for High-Dimensional Feature Selection,cs.NE,['cs.NE'],"[arxiv.Result.Author('Lingjie Li'), arxiv.Result.Author('Manlin Xuan'), arxiv.Result.Author('Qiuzhen Lin'), arxiv.Result.Author('Min Jiang'), arxiv.Result.Author('Zhong Ming'), arxiv.Result.Author('Kay Chen Tan')]","Recently, evolutionary multitasking (EMT) has been successfully used in the
field of high-dimensional classification. However, the generation of multiple
tasks in the existing EMT-based feature selection (FS) methods is relatively
simple, using only the Relief-F method to collect related features with similar
importance into one task, which cannot provide more diversified tasks for
knowledge transfer. Thus, this paper devises a new EMT algorithm for FS in
high-dimensional classification, which first adopts different filtering methods
to produce multiple tasks and then modifies a competitive swarm optimizer to
efficiently solve these related tasks via knowledge transfer. First, a
diversified multiple task generation method is designed based on multiple
filtering methods, which generates several relevant low-dimensional FS tasks by
eliminating irrelevant features. In this way, useful knowledge for solving
simple and relevant tasks can be transferred to simplify and speed up the
solution of the original high-dimensional FS task. Then, a competitive swarm
optimizer is modified to simultaneously solve these relevant FS tasks by
transferring useful knowledge among them. Numerous empirical results
demonstrate that the proposed EMT-based FS method can obtain a better feature
subset than several state-of-the-art FS methods on eighteen high-dimensional
datasets."
15120,"However, which parameters or strategies influence this property requires further study.",(3) We investigated some metaheuristics on whether their search is biased toward the origin.,"Overall, we hope that our study provides useful insight to guide future designs of more practicable
metaheuristics that are capable of handling complex, high-dimensional and large-scale real-world prob-
lems.",2022-12-19 14:13:10+00:00,Performance assessment and exhaustive listing of 500+ nature inspired metaheuristic algorithms,cs.NE,"['cs.NE', 'cs.AI']","[arxiv.Result.Author('Zhongqiang Ma'), arxiv.Result.Author('Guohua Wu'), arxiv.Result.Author('Ponnuthurai N. Suganthan'), arxiv.Result.Author('Aijuan Song'), arxiv.Result.Author('Qizhang Luo')]","Metaheuristics are popularly used in various fields, and they have attracted
much attention in the scientific and industrial communities. In recent years,
the number of new metaheuristic names has been continuously growing. Generally,
the inventors attribute the novelties of these new algorithms to inspirations
from either biology, human behaviors, physics, or other phenomena. In addition,
these new algorithms, compared against basic versions of other metaheuristics
using classical benchmark problems without shift/rotation, show competitive
performances. In this study, we exhaustively tabulate more than 500
metaheuristics. To comparatively evaluate the performance of the recent
competitive variants and newly proposed metaheuristics, 11 newly proposed
metaheuristics and 4 variants of established metaheuristics are comprehensively
compared on the CEC2017 benchmark suite. In addition, whether these algorithms
have a search bias to the center of the search space is investigated. The
results show that the performance of the newly proposed EBCM (effective
butterfly optimizer with covariance matrix adaptation) algorithm performs
comparably to the 4 well performing variants of the established metaheuristics
and possesses similar properties and behaviors, such as convergence, diversity,
exploration and exploitation trade-offs, in many aspects. The performance of
all 15 of the algorithms is likely to deteriorate due to certain
transformations, while the 4 state-of-the-art metaheuristics are less affected
by transformations such as the shifting of the global optimal point away from
the center of the search space. It should be noted that, except EBCM, the other
10 new algorithms proposed mostly during 2019-2020 are inferior to the well
performing 2017 variants of differential evolution and evolution strategy in
terms of convergence speed and global search ability on CEC 2017 functions."
15153,"Other            [13] J. Hurtado, A. Raymond, and A. Soto, ‚ÄúOptimizing reusable knowledge
directions for further research are a more in-depth examination           for continual learning via metalearning,‚Äù Advances in Neural Informa-
of the viability of different data-sets on the training ability           tion Processing Systems, vol.","29, 2016.
regime, there is a lot of methodology from the well-established
Ô¨Åeld of ‚Äòdeep learning‚Äô that we did not touch yet.","34, pp.",2022-12-20 08:33:57+00:00,Constructing Organism Networks from Collaborative Self-Replicators,cs.NE,"['cs.NE', 'cs.LG']","[arxiv.Result.Author('Steffen Illium'), arxiv.Result.Author('Maximilian Zorn'), arxiv.Result.Author('Cristian Lenta'), arxiv.Result.Author('Michael K√∂lle'), arxiv.Result.Author('Claudia Linnhoff-Popien'), arxiv.Result.Author('Thomas Gabor')]","We introduce organism networks, which function like a single neural network
but are composed of several neural particle networks; while each particle
network fulfils the role of a single weight application within the organism
network, it is also trained to self-replicate its own weights. As organism
networks feature vastly more parameters than simpler architectures, we perform
our initial experiments on an arithmetic task as well as on simplified
MNIST-dataset classification as a collective. We observe that individual
particle networks tend to specialise in either of the tasks and that the ones
fully specialised in the secondary task may be dropped from the network without
hindering the computational accuracy of the primary task. This leads to the
discovery of a novel pruning-strategy for sparse neural networks"
15312,"These encouraging

                                                                                           1
results revealed the need for further research regarding speciÔ¨Åc aspects of the
model, especially its capacity.","The DGNG approximation showed more eÔ¨Écient computational prop-
                                        erties while largely maintaining the desired performance.","In this context, capacity is understood as the
model‚Äôs ability of mapping input signals injectivly on a set of output.",2022-12-23 13:19:48+00:00,Capacity Studies for a Differential Growing Neural Gas,cs.NE,['cs.NE'],"[arxiv.Result.Author('P. Levi'), arxiv.Result.Author('P. Gelhausen'), arxiv.Result.Author('G. Peters')]","In 2019 Kerdels and Peters proposed a grid cell model (GCM) based on a
Differential Growing Neural Gas (DGNG) network architecture as a
computationally efficient way to model an Autoassociative Memory Cell (AMC)
\cite{Kerdels_Peters_2019}. An important feature of the DGNG architecture with
respect to possible applications in the field of computational neuroscience is
its \textit{capacity} refering to its capability to process and uniquely
distinguish input signals and therefore obtain a valid representation of the
input space. This study evaluates the capacity of a two layered DGNG grid cell
model on the Fashion-MNIST dataset. The focus on the study lies on the
variation of layer sizes to improve the understanding of capacity properties in
relation to network parameters as well as its scaling properties. Additionally,
parameter discussions and a plausability check with a pixel/segment variation
method are provided. It is concluded, that the DGNG model is able to obtain a
meaningful and plausible representation of the input space and to cope with the
complexity of the Fashion-MNIST dataset even at moderate layer sizes."
