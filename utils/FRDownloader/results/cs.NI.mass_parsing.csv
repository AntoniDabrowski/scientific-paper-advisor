,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract
393,"on Enterprise Distributed Object Computing Conference
of equal importance for further study.","IEEE
other business-relevant issues including service pricing are           16th Int’l Conf.","(EDOC), Sep. 2012.",2022-01-05 09:25:57+00:00,CDN Slicing over a Multi-Domain Edge Cloud,cs.NI,['cs.NI'],"[arxiv.Result.Author('T. Taleb'), arxiv.Result.Author('P. A. Frangoudis'), arxiv.Result.Author('I. Benkacem'), arxiv.Result.Author('A. Ksentini')]","We present an architecture for the provision of video Content Delivery
Network (CDN) functionality as a service over a multi-domain cloud. We
introduce the concept of a CDN slice, that is, a CDN service instance which is
created upon a content provider's request, is autonomously managed, and spans
multiple potentially heterogeneous edge cloud infrastructures. Our design is
tailored to a 5G mobile network context, building on its inherent
programmability, management flexibility, and the availability of cloud
resources at the mobile edge level, thus close to end users. We exploit Network
Functions Virtualization (NFV) and Multi-access Edge Computing (MEC)
technologies, proposing a system which is aligned with the recent NFV and MEC
standards. To deliver a Quality-of-Experience (QoE) optimized video service, we
derive empirical models of video QoE as a function of service workload, which,
coupled with multi-level service monitoring, drive our slice resource
allocation and elastic management mechanisms. These management schemes feature
autonomic compute resource scaling, and on-the-fly transcoding to adapt video
bit-rate to the current network conditions. Their effectiveness is demonstrated
via testbed experiments."
573,"While the management layer is not less           such, QoS and QoE requirements can be con-
important, further research is motivated in deploy-      tradictory.","As
levels.","Indeed, respecting QoS does not
ing management applications for SFC.",2022-01-05 12:21:46+00:00,Service Function Chaining in 5G & Beyond Networks: Challenges and Open Research Issues,cs.NI,['cs.NI'],"[arxiv.Result.Author('H. Hantouti'), arxiv.Result.Author('N. Benamar'), arxiv.Result.Author('T. Taleb')]","Service Function Chaining (SFC) is a trending paradigm, which has helped to
introduce unseen flexibility in telecom networks. Network service providers, as
well as big network infrastructure providers, are competing to offer
personalized services for their customers. Hence, added value services require
the invocation of various elementary functions called Service Functions (SFs).
The SFC concept composes and imposes the order in which SFs are invoked for a
particular service. Emerging technologies such as Software Defined Networking
and Network Function Virtualization support the dynamic creation and management
of SFC. Even though SFC is an active technical area where several aspects were
already standardized and many SFC architecture flavors are currently deployed,
yet some challenges and open issues are still to be solved. In this paper, we
present different research problems related to SFC and investigate several key
challenges that should be addressed to realize more reliable SFC operations."
712,"On this basis, we further study the selective   message is shown in Figure 1, which includes RPL InstanceID,
forwarding attacks and defense scheme in this work.","The format of a DIO
at the root node.","Unlike        Rank value, DODAG ID, Destination Advertisement Trigger
the blackhole attack model, which blindly drops all packets,      Sequence Number (DTSN), etc.",2022-01-18 12:59:09+00:00,Secure IoT Routing: Selective Forwarding Attacks and Trust-based Defenses in RPL Network,cs.NI,['cs.NI'],"[arxiv.Result.Author('Jun Jiang'), arxiv.Result.Author('Yuhong Liu')]","IPv6 Routing Protocol for Low Power and Lossy Networks (RPL) is an essential
routing protocol to enable communications for IoT networks with low power
devices. RPL uses an objective function and routing constraints to find an
optimized routing path for each node in the network. However, recent research
has shown that topological attacks, such as selective forwarding attacks, pose
great challenges to the secure routing of IoT networks. Many conventional
secure routing solutions, on the other hand, are computationally heavy to be
directly applied in resource-constrained IoT networks. There is an urgent need
to develop lightweight secure routing solutions for IoT networks. In this
paper, we first design and implement a series of advanced selective forwarding
attacks from the attack perspective, which can flexibly select the type and
percentage of forwarding packets in an energy efficient way, and even bad-mouth
other innocent nodes in the network. Experiment results show that the proposed
attacks can maximize the attack consequences (i.e. number of dropped packets)
while maintaining undetected. Moreover, we propose a lightweight trust-based
defense solution to detect and eliminate malicious selective forwarding nodes
from the network. The results show that the proposed defense solution can
achieve high detection accuracy with very limited extra energy usage (i.e.
3.4%)."
715,"The insights offered by this article motivate
sion techniques (such as pruning) have been optimized only          further research that can address the open questions and
for DNN accuracy and without considering device energy              challenges in intelligent 6G-MNs.",Standalone compres-         these issues.,consumption.,2022-01-18 13:15:26+00:00,AI-Aided Integrated Terrestrial and Non-Terrestrial 6G Solutions for Sustainable Maritime Networking,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Salwa Saafi'), arxiv.Result.Author('Olga Vikhrova'), arxiv.Result.Author('Gábor Fodor'), arxiv.Result.Author('Jiri Hosek'), arxiv.Result.Author('Sergey Andreev')]","The maritime industry is experiencing a technological revolution that affects
shipbuilding, operation of both seagoing and inland vessels, cargo management,
and working practices in harbors. This ongoing transformation is driven by the
ambition to make the ecosystem more sustainable and cost-efficient.
Digitalization and automation help achieve these goals by transforming shipping
and cruising into a much more cost- and energy-efficient, and decarbonized
industry segment. The key enablers in these processes are always-available
connectivity and content delivery services, which can not only aid shipping
companies in improving their operational efficiency and reducing carbon
emissions but also contribute to enhanced crew welfare and passenger
experience. Due to recent advancements in integrating high-capacity and
ultra-reliable terrestrial and non-terrestrial networking technologies,
ubiquitous maritime connectivity is becoming a reality. To cope with the
increased complexity of managing these integrated systems, this article
advocates the use of artificial intelligence and machine learning-based
approaches to meet the service requirements and energy efficiency targets in
various maritime communications scenarios."
716,"The insights offered by this article motivate
sion techniques (such as pruning) have been optimized only          further research that can address the open questions and
for DNN accuracy and without considering device energy              challenges in intelligent 6G-MNs.",Standalone compres-         these issues.,consumption.,2022-01-18 13:15:26+00:00,AI-Aided Integrated Terrestrial and Non-Terrestrial 6G Solutions for Sustainable Maritime Networking,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Salwa Saafi'), arxiv.Result.Author('Olga Vikhrova'), arxiv.Result.Author('Gábor Fodor'), arxiv.Result.Author('Jiri Hosek'), arxiv.Result.Author('Sergey Andreev')]","The maritime industry is experiencing a technological revolution that affects
shipbuilding, operation of both seagoing and inland vessels, cargo management,
and working practices in harbors. This ongoing transformation is driven by the
ambition to make the ecosystem more sustainable and cost-efficient.
Digitalization and automation help achieve these goals by transforming shipping
and cruising into a much more cost- and energy-efficient, and decarbonized
industry segment. The key enablers in these processes are always-available
connectivity and content delivery services, which can not only aid shipping
companies in improving their operational efficiency and reducing carbon
emissions but also contribute to enhanced crew welfare and passenger
experience. Due to recent advancements in integrating high-capacity and
ultra-reliable terrestrial and non-terrestrial networking technologies,
ubiquitous maritime connectivity is becoming a reality. To cope with the
increased complexity of managing these integrated systems, this article
advocates the use of artificial intelligence and machine learning-based
approaches to meet the service requirements and energy efficiency targets in
various maritime communications scenarios."
768,"In this     cially in the 5 GHz and 6 GHz bands, as a result of favorable
context, we set for further study the adoption of a dynamic       radio propagation conditions.","However, the non-adaptive implementation of the      feature may be complemented by the fact that nodes’ spatial
proposed mechanisms may not be efﬁcient for long-lasting          distribution may create different contention-free links, spe-
ﬂows, as links may change its occupancy very rapidly.","Therefore, trafﬁc with higher
strategy that not only takes into account the instantaneous       QoS requirements can be exclusively exchanged through those
channel occupancy of each interface when a ﬂow becomes            contention-free links, as long as they exist.",2022-01-19 09:49:53+00:00,Multi-link Operation in IEEE 802.11be WLANs,cs.NI,['cs.NI'],"[arxiv.Result.Author('Álvaro López-Raventós'), arxiv.Result.Author('Boris Bellalta')]","The multi-link operation (MLO) is a new feature proposed to be part of the
IEEE 802.11be Extremely High Throughput (EHT) amendment. Such feature
represents a paradigm shift towards multi-link communications, as nodes will be
allowed to transmit and receive data over multiple radio interfaces
concurrently. To make it possible, the 802.11be Task Group has proposed
different modifications in regards to nodes' architecture, transmission
operation, and management functionalities. This article reviews such changes
and tackles the question of how traffic should be distributed over multiple
links, as it is still unresolved. To that end, we evaluate different load
balancing strategies over the active links. Results show that in high load,
dense and complex scenarios, implementing congestion-aware load balancing
policies to significantly enhance next-generation WLAN performance using MLO is
a must."
769,"Percentile                          In this context, we point out some open issues that require
                                                                           further research:
Avg.","10
                                                                                          V. OPEN ISSUES AND CHALLENGES
                            0
                                                                              Although the MLO represents a promising functionality to
                                25th   50th  75th                    95th  be implemented in next generation WLANs, the concurrent
                                                                           use of multiple interfaces brings new challenges to face off.","throughput losses [%]                               Data flows
                            80                                                • non-STR and legacy blindness.",2022-01-19 09:49:53+00:00,Multi-link Operation in IEEE 802.11be WLANs,cs.NI,['cs.NI'],"[arxiv.Result.Author('Álvaro López-Raventós'), arxiv.Result.Author('Boris Bellalta')]","The multi-link operation (MLO) is a new feature proposed to be part of the
IEEE 802.11be Extremely High Throughput (EHT) amendment. Such feature
represents a paradigm shift towards multi-link communications, as nodes will be
allowed to transmit and receive data over multiple radio interfaces
concurrently. To make it possible, the 802.11be Task Group has proposed
different modifications in regards to nodes' architecture, transmission
operation, and management functionalities. This article reviews such changes
and tackles the question of how traffic should be distributed over multiple
links, as it is still unresolved. To that end, we evaluate different load
balancing strategies over the active links. Results show that in high load,
dense and complex scenarios, implementing congestion-aware load balancing
policies to significantly enhance next-generation WLAN performance using MLO is
a must."
770,"Although this has been the main topic of                 [7] Sharan Naribole, Wook Bong Lee, Srinivas Kandala, and Ashok Ran-
      this paper, further research is required to fully understand
      which is the best strategy to balance the trafﬁc in MLO                 ganath.","7

   • Load balancing.","Simultaneous Transmit-Receive Multi-Channel Operation in
      WLANs.",2022-01-19 09:49:53+00:00,Multi-link Operation in IEEE 802.11be WLANs,cs.NI,['cs.NI'],"[arxiv.Result.Author('Álvaro López-Raventós'), arxiv.Result.Author('Boris Bellalta')]","The multi-link operation (MLO) is a new feature proposed to be part of the
IEEE 802.11be Extremely High Throughput (EHT) amendment. Such feature
represents a paradigm shift towards multi-link communications, as nodes will be
allowed to transmit and receive data over multiple radio interfaces
concurrently. To make it possible, the 802.11be Task Group has proposed
different modifications in regards to nodes' architecture, transmission
operation, and management functionalities. This article reviews such changes
and tackles the question of how traffic should be distributed over multiple
links, as it is still unresolved. To that end, we evaluate different load
balancing strategies over the active links. Results show that in high load,
dense and complex scenarios, implementing congestion-aware load balancing
policies to significantly enhance next-generation WLAN performance using MLO is
a must."
771,"However,
further research need to be done to fully understand all new                  Duncan Ho.","framework will allow next generation of APs and stations to
perform concurrent transmissions by using their multiple wire-                IEEE, 2019.
less interfaces in a coordinated way, and therefore, opening the
door to both improve the network performance and achieve                      [9] Abhishek Patil, George Cherian, Alfred Asterjadhi, and
a more efﬁcient use of the spectrum resources.",Multi-Link Operation: Design Discussion.,2022-01-19 09:49:53+00:00,Multi-link Operation in IEEE 802.11be WLANs,cs.NI,['cs.NI'],"[arxiv.Result.Author('Álvaro López-Raventós'), arxiv.Result.Author('Boris Bellalta')]","The multi-link operation (MLO) is a new feature proposed to be part of the
IEEE 802.11be Extremely High Throughput (EHT) amendment. Such feature
represents a paradigm shift towards multi-link communications, as nodes will be
allowed to transmit and receive data over multiple radio interfaces
concurrently. To make it possible, the 802.11be Task Group has proposed
different modifications in regards to nodes' architecture, transmission
operation, and management functionalities. This article reviews such changes
and tackles the question of how traffic should be distributed over multiple
links, as it is still unresolved. To that end, we evaluate different load
balancing strategies over the active links. Results show that in high load,
dense and complex scenarios, implementing congestion-aware load balancing
policies to significantly enhance next-generation WLAN performance using MLO is
a must."
871,"The contribution of latency variation due
to this phenomena (on serializer receivers and SFP modules) needs further study.","Limiting ampliﬁer amplitude to phase modulation eﬀects should be taken into account for
high accuracy absolute calibrated PTP-WR links.","Unfortunately the large oﬀsets µ for all measured combinations ‘A’ to ‘G’ could not yet
be explained satisfactorily and are still an open question for which the authors do not have
a clear answer yet.",2022-01-21 11:02:04+00:00,First electrical White Rabbit absolute calibration inter-comparison,cs.NI,"['cs.NI', 'cs.SY', 'eess.SY', 'physics.ins-det', 'C.2.2; C.2.4']","[arxiv.Result.Author('P. P. M. Jansweijer'), arxiv.Result.Author('N. A. D. Boukadida'), arxiv.Result.Author('K. Hanhijärvi'), arxiv.Result.Author('A. Wallin'), arxiv.Result.Author('B. Eglin'), arxiv.Result.Author('E. Laier English')]","A time transfer link consisting of PTP White Rabbit (PTP-WR) devices can
transfer time with sub-nanosecond accuracy. Originally White Rabbit devices
were calibrated as a set of two devices. Progress in calibration makes
individual absolute calibrated PTP-WR devices possible. This enables exchange
of PTP-WR devices without the need for expensive in-situ end-to-end
calibrations.
  Electrical absolute calibration is the basis of absolute calibration. It
calibrates the time relationship between the internal timestamp and the
external electrical time reference plane. In this paper we examine the
electrical time transfer accuracy when a link is setup using electrical
absolute calibrated PTP-WR devices calibrated by different laboratories."
872,"The authors encourage further study to ﬁnd an answer
for this unsolved puzzle.","Combinations of diﬀerent types of PTP-WR devices showed signiﬁcant PPS residual oﬀsets
that are not yet fully understood.","Funding Information

This project 17IND14 WRITE has received funding from the EMPIR programme co-ﬁnanced
by the Participating States and from the European Union’s Horizon 2020 research and
innovation programme.",2022-01-21 11:02:04+00:00,First electrical White Rabbit absolute calibration inter-comparison,cs.NI,"['cs.NI', 'cs.SY', 'eess.SY', 'physics.ins-det', 'C.2.2; C.2.4']","[arxiv.Result.Author('P. P. M. Jansweijer'), arxiv.Result.Author('N. A. D. Boukadida'), arxiv.Result.Author('K. Hanhijärvi'), arxiv.Result.Author('A. Wallin'), arxiv.Result.Author('B. Eglin'), arxiv.Result.Author('E. Laier English')]","A time transfer link consisting of PTP White Rabbit (PTP-WR) devices can
transfer time with sub-nanosecond accuracy. Originally White Rabbit devices
were calibrated as a set of two devices. Progress in calibration makes
individual absolute calibrated PTP-WR devices possible. This enables exchange
of PTP-WR devices without the need for expensive in-situ end-to-end
calibrations.
  Electrical absolute calibration is the basis of absolute calibration. It
calibrates the time relationship between the internal timestamp and the
external electrical time reference plane. In this paper we examine the
electrical time transfer accuracy when a link is setup using electrical
absolute calibrated PTP-WR devices calibrated by different laboratories."
1032,"Additionally, also other elements (OXC, ampliﬁers, etc) of optical network
     can be included in the analysis to further research.","• The model for shaping trafﬁc in order to improve resource allocation and reduce energy consumption
     considers physical-layer interactions to minimizes the amount of total time-averaged transponder
                                                                                                                                                                                                53

     power consumption in [22].","• Besides the RSA solution for allocating resources with a model of trafﬁc variation which is area-
     aware based on mobile network trafﬁc [19], there is space to expand the solution to include RMLSA
     algorithms and explore other AI-based trafﬁc forecasting methods.",2022-01-26 02:17:42+00:00,Metropolitan Optical Networks: A Survey on New Architectures and Future Trends,cs.NI,"['cs.NI', 'C.2.1']","[arxiv.Result.Author('Léia Sousa de Sousa'), arxiv.Result.Author('André Costa Drummond')]","Metropolitan optical networks are undergoing major transformations to
continue being able to provide services that meet the requirements of the
applications of the future. The arrival of the $5G$ will expand the
possibilities for offering IoT applications, autonomous vehicles, and smart
cities services while imposing strong pressure on the physical infrastructure
currently implemented, as well as on static traffic engineering techniques that
do not respond in an agile way to the dynamic and heterogeneous nature of the
upcoming traffic patterns. In order to guarantee the strictest quality of
service and quality of experience requirements for users, as well as meeting
the providers' objectives of maintaining an acceptable trade-off between cost
and performance, new architectures for metropolitan optical networks have been
proposed in the literature, with a growing interest starting from $2017$.
However, due to the proliferation of a dozen of new architectures in recent
years, many questions need to be investigated regarding the planning,
implementation, and management of these architectures, before they could be
considered for practical application. This work presents a comprehensive survey
of the new proposed architectures for metropolitan optical networks. Firstly,
the main data transmission systems, equipment involved, and the structural
organization of the new metro ecosystems are discussed. The already established
and the novel architectures are presented, highlighting its characteristics and
application, and comparative analysis among these architectures is carried out
identifying the future technological trends. Finally, outstanding research
questions are drawn to help direct future research on the field."
1033,"Additionally, also other elements (OXC, ampliﬁers, etc) of optical network
     can be included in the analysis to further research.","• The model for shaping trafﬁc in order to improve resource allocation and reduce energy consumption
     considers physical-layer interactions to minimizes the amount of total time-averaged transponder
                                                                                                                                                                                                53

     power consumption in [21].","• Besides the RSA solution for allocating resources with a model of trafﬁc variation which is area-
     aware based on mobile network trafﬁc [18], there is space to expand the solution to include RMLSA
     algorithms and explore other AI-based trafﬁc forecasting methods.",2022-01-26 02:17:42+00:00,Metropolitan Optical Networks: A Survey on New Architectures and Future Trends,cs.NI,"['cs.NI', 'C.2.1']","[arxiv.Result.Author('Léia Sousa de Sousa'), arxiv.Result.Author('André Costa Drummond')]","Metropolitan optical networks are undergoing major transformations to
continue being able to provide services that meet the requirements of the
applications of the future. The arrival of the $5G$ will expand the
possibilities for offering IoT applications, autonomous vehicles, and smart
cities services while imposing strong pressure on the physical infrastructure
currently implemented, as well as on static traffic engineering techniques that
do not respond in an agile way to the dynamic and heterogeneous nature of the
upcoming traffic patterns. In order to guarantee the strictest quality of
service and quality of experience requirements for users, as well as meeting
the providers' objectives of maintaining an acceptable trade-off between cost
and performance, new architectures for metropolitan optical networks have been
proposed in the literature, with a growing interest starting from $2017$.
However, due to the proliferation of a dozen of new architectures in recent
years, many questions need to be investigated regarding the planning,
implementation, and management of these architectures, before they could be
considered for practical application. This work presents a comprehensive survey
of the new proposed architectures for metropolitan optical networks. Firstly,
the main data transmission systems, equipment involved, and the structural
organization of the new metro ecosystems are discussed. The already established
and the novel architectures are presented, highlighting its characteristics and
application, and comparative analysis among these architectures is carried out
identifying the future technological trends. Finally, outstanding research
questions are drawn to help direct future research on the field."
1115,"Therefore, in addition to the optimization ideas mentioned at each of the above INT stages, there
are opportunities for further research to develop solutions for other types of networks, such as
adapting or expanding the in-band telemetry system in a wireless sensor network (WSN) and
Internet of Things (IoT) data network.","The efficiency of these solutions
should be determined by performance evaluation.","For example, IoT packets are too small, making it difficult
to identify abnormal behaviour of packet [26].",2021-11-29 19:16:01+00:00,Survey on some optimization possibilities for data plane applications,cs.NI,['cs.NI'],"[arxiv.Result.Author('Gereltsetseg Altangerel'), arxiv.Result.Author('Tejfel Máté')]","By programming both the data plane and the control plane, network operators
can customize their networks based on their needs, regardless of the hardware
manufacturer. Control plane programming, a major component of the SDN (Software
Defined Network) concept, has been developed for more than 10 years and
successfully implemented in real networks. Efforts to develop reconfigurable
data planes and high-level network programming languages make it truly possible
to program data planes. Therefore, the programmable data planes and SDNs offer
great flexibility in network customization, allowing many innovations to be
introduced on the network. The general focus of research on the data plane is
data-plane abstractions, languages and compilers, data plane algorithms, and
applications. This paper outlines some emerging applications on the data plane
and offers opportunities for further improvement and optimization."
1327,"As previously seen in cloud                     UE, addressing device control under this general lack of data
                                        computing, this rapid advance of software has encouraged a                   requires further research.","network with the ability to be virtualized and made dynamic                  With signiﬁcantly less environmental context available at the
                                        in 5G and beyond deployment.","This paper investigates an enhance-
                                        decoupling of hardware from software to the extent that slower               ment of existing mobile-controlled handoff capabilities by
                                        moving hardware generations are made general purpose and                     doing all learning on-device” using the existing mechanic of
                                        are able to accommodate increasing heterogeneity of software                 measuring RSSI (Received Signal Strength Indicator).",2022-01-31 22:42:05+00:00,Using Transition Learning to Enhance Mobile-Controlled Handoff In Decentralized Future Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Steven Platt'), arxiv.Result.Author('Berkay Demirel'), arxiv.Result.Author('Miquel Oliver')]","Traditionally, resource management and capacity allocation has been
controlled network-side in cellular deployment. As autonomicity has been added
to network design, machine learning technologies have largely followed this
paradigm, benefiting from the higher compute capacity and informational context
available at the network core. However, when these network services are
disaggregated or decentralized, models that rely on assumed levels of network
or information availability may no longer function reliably. This paper
presents an inverted view of the resource management paradigm; one in which the
client device executes a learning algorithm and manages its own mobility under
a scenario where the networks and their corresponding data underneath are not
being centrally managed."
1425,"2
Control and learning objective Scale            Input data                Timescale                             Architecture                                   Challenges and limitations
                                                                                                                                                               Orchestration of large scale
     Policies, models, slicing        > 1000     Infrastructure-level     Non-real-time                          Non-real-time RIC                             deployments with multiple     Supported by O-RAN For further study
                                      devices            KPMs                   > 1 s                                                                     O1
  User Session Management                                                                                                                                       near-RT RICs, RAN nodes
  e.g., load balancing, handover       > 100        CU-level KPMs         Near-real-time     A1 gNB
                                      devices        e.g., number of       10-1000 ms                                                                              Process streams from
Medium Access Management                         sessions, PDCP traffic                       Near-rReIaCl-time E2 CU                                           multiple CUs and sessions
e.g., scheduling policy, RAN slicing   > 100                              Near-real-time                                                    F1
                                      devices     MAC-level KPMs           10-1000 ms                                                                         Operate at small time scales,
       Radio Management                           e.g., PRB utilization,                     Mobile devices  DU                                                 make decisions involving
      e.g., resource scheduling,        ~10                                  Real-time                          Open FH                                              several DUs/UEs
                                      devices            buffering            < 10 ms
             beamforming                                                                                     RU                                               Deployment of AI/ML models
  Device DL/UL Management             1 device  MAC/PHY-level KPMs           Real-time                                                                         at the DU is not supported
   e.g., modulation, interference,                e.g., PRB utilization,       < 1 ms
                                                  channel estimation                                                                                             Require device- and/or
          blockage detection                                                                                                                                     RU-level standardization
                                                     I/Q samples

Fig.","2: Evolution of the traditional black-box base station architecture toward a virtualized gNB with a functional split, including the PHY split based on
3GPP 7.2x split.","3: Closed-loop control enabled by the O-RAN architecture, and possible extensions, adapted from [18].",2022-02-02 13:56:04+00:00,"Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Michele Polese'), arxiv.Result.Author('Leonardo Bonati'), arxiv.Result.Author(""Salvatore D'Oro""), arxiv.Result.Author('Stefano Basagni'), arxiv.Result.Author('Tommaso Melodia')]","Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance
specifications have the potential to truly transform the telecom ecosystem.
O-RAN promotes virtualized and disaggregated RANs, where disaggregated
components are connected via open interfaces and optimized by intelligent
controllers. The result is a new paradigm for the RAN design, deployment, and
operations: O-RAN networks can be built with multi-vendor, interoperable
components, and can be programmatically optimized through a centralized
abstraction layer and data-driven closed-loop control. Therefore, understanding
O-RAN, its architecture, its interfaces, and workflows is key for researchers
and practitioners in the wireless community. In this article, we present the
first detailed tutorial on O-RAN. We also discuss the main research challenges
and review early results. We provide a deep dive on the O-RAN specifications,
describing its architecture, design principles, and the O-RAN interfaces. We
then describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to
effectively control and manage 3GPP-defined RANs. Based on this, we discuss
innovations and challenges that relate to O-RAN networks, including the
Artificial Intelligence (AI) and Machine Learning (ML) workflows that the
architecture and interfaces enable, and security and standardization issues.
Finally, we review experimental research platforms that can be used to design
and test O-RAN networks, along with recent research results, and we outline
future directions for O-RAN development."
1426,"This also fosters
not part of the current O-RAN architecture, but are mentioned         market competitiveness, innovation, faster update/upgrade cy-
in some speciﬁcations [24] as for further study.","These loops, which            another vendor, or again enabling the interoperability of CUs,
have a limited scale in terms of devices being optimized, are         DUs and RUs from different manufacturers.","cles, and eases the design and introduction of new softwarized
                                                                      components in the RAN ecosystem [18].",2022-02-02 13:56:04+00:00,"Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Michele Polese'), arxiv.Result.Author('Leonardo Bonati'), arxiv.Result.Author(""Salvatore D'Oro""), arxiv.Result.Author('Stefano Basagni'), arxiv.Result.Author('Tommaso Melodia')]","Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance
specifications have the potential to truly transform the telecom ecosystem.
O-RAN promotes virtualized and disaggregated RANs, where disaggregated
components are connected via open interfaces and optimized by intelligent
controllers. The result is a new paradigm for the RAN design, deployment, and
operations: O-RAN networks can be built with multi-vendor, interoperable
components, and can be programmatically optimized through a centralized
abstraction layer and data-driven closed-loop control. Therefore, understanding
O-RAN, its architecture, its interfaces, and workflows is key for researchers
and practitioners in the wireless community. In this article, we present the
first detailed tutorial on O-RAN. We also discuss the main research challenges
and review early results. We provide a deep dive on the O-RAN specifications,
describing its architecture, design principles, and the O-RAN interfaces. We
then describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to
effectively control and manage 3GPP-defined RANs. Based on this, we discuss
innovations and challenges that relate to O-RAN networks, including the
Artificial Intelligence (AI) and Machine Learning (ML) workflows that the
architecture and interfaces enable, and security and standardization issues.
Finally, we review experimental research platforms that can be used to design
and test O-RAN networks, along with recent research results, and we outline
future directions for O-RAN development."
1427,"ﬁcations for a non-real-time RIC, which integrates with the
                                                                                           network orchestrator and operates on a time scale longer than
   The O-RAN Alliance has evaluated the different RU/DU                                    1 s, and a near-real-time RIC, which drives control loops with
split options proposed by the 3GPP, with speciﬁc interest in                               RAN nodes with a time scale between 10 ms and 1 s. Figure 3
alternatives for physical layer split across the RU and the

Control and learning objective Scale (devices)  Input data                Timescale                        Architecture                          Challenges and limitations

Policies, models, slicing             > 1000    Infrastructure KPMs     Non-real-time          Non-real-time RIC                                 Orchestration of large-scale  Supported by O-RAN For further study
                                                                              > 1 s                                                                      deployments
                                                                                                                                             O1
                                                                        Near-real-time                                                              Process streams from
  User Session Management                             CU KPMs            10-1000 ms        A1                            gNB                      multiple CUs and sessions
  e.g., load balancing, handover                   e.g., number of
                                      > 100     sessions, PDCP traffic  Near-real-time     Near-rReIaCl-time E2 CU                                Small time scales, control
Medium Access Management              > 100                              10-1000 ms                                                      F1             many DUs/UEs
e.g., scheduling policy, RAN slicing   ~10          MAC KPMs
                                                e.g., PRB utilization,     Real-time       Mobile devices                DU                      Custom real-time loops not
      Radio Management                  1                                   < 10 ms                                         Open FH                        supported
  e.g., scheduling, beamforming                        buffering
                                                                           Real-time                                     RU                          Device- and RU-level
 Device DL/UL Management                         MAC/PHY KPMs                < 1 ms                                                                     standardization
          e.g., modulation                      e.g., PRB utilization,
                                                 channel estimation

                                                    I/Q samples

Fig.","The O-RAN Alliance has drafted speci-
boards and deployed close to RF antennas.","3: Closed-loop control enabled by the O-RAN architecture, and possible extensions, adapted from [19].",2022-02-02 13:56:04+00:00,"Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Michele Polese'), arxiv.Result.Author('Leonardo Bonati'), arxiv.Result.Author(""Salvatore D'Oro""), arxiv.Result.Author('Stefano Basagni'), arxiv.Result.Author('Tommaso Melodia')]","The Open Radio Access Network (RAN) and its embodiment through the O-RAN
Alliance specifications are poised to revolutionize the telecom ecosystem.
O-RAN promotes virtualized RANs where disaggregated components are connected
via open interfaces and optimized by intelligent controllers. The result is a
new paradigm for the RAN design, deployment, and operations: O-RAN networks can
be built with multi-vendor, interoperable components, and can be
programmatically optimized through a centralized abstraction layer and
data-driven closed-loop control. Therefore, understanding O-RAN, its
architecture, its interfaces, and workflows is key for researchers and
practitioners in the wireless community. In this article, we present the first
detailed tutorial on O-RAN. We also discuss the main research challenges and
review early research results. We provide a deep dive of the O-RAN
specifications, describing its architecture, design principles, and the O-RAN
interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs)
can be used to effectively control and manage 3GPP-defined RANs. Based on this,
we discuss innovations and challenges of O-RAN networks, including the
Artificial Intelligence (AI) and Machine Learning (ML) workflows that the
architecture and interfaces enable, security and standardization issues.
Finally, we review experimental research platforms that can be used to design
and test O-RAN networks, along with recent research results, and we outline
future directions for O-RAN development."
1428,"3
provides an overview of the closed-loop control that the RICs        in some speciﬁcations [21] as for further study.","The control loops are represented by the dashed
arrows over the architectural diagram.","enable throughout the disaggregated O-RAN infrastructure,
together with real-time extensions that are considered for           C. Virtualization
future work.",2022-02-02 13:56:04+00:00,"Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Michele Polese'), arxiv.Result.Author('Leonardo Bonati'), arxiv.Result.Author(""Salvatore D'Oro""), arxiv.Result.Author('Stefano Basagni'), arxiv.Result.Author('Tommaso Melodia')]","The Open Radio Access Network (RAN) and its embodiment through the O-RAN
Alliance specifications are poised to revolutionize the telecom ecosystem.
O-RAN promotes virtualized RANs where disaggregated components are connected
via open interfaces and optimized by intelligent controllers. The result is a
new paradigm for the RAN design, deployment, and operations: O-RAN networks can
be built with multi-vendor, interoperable components, and can be
programmatically optimized through a centralized abstraction layer and
data-driven closed-loop control. Therefore, understanding O-RAN, its
architecture, its interfaces, and workflows is key for researchers and
practitioners in the wireless community. In this article, we present the first
detailed tutorial on O-RAN. We also discuss the main research challenges and
review early research results. We provide a deep dive of the O-RAN
specifications, describing its architecture, design principles, and the O-RAN
interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs)
can be used to effectively control and manage 3GPP-defined RANs. Based on this,
we discuss innovations and challenges of O-RAN networks, including the
Artificial Intelligence (AI) and Machine Learning (ML) workflows that the
architecture and interfaces enable, security and standardization issues.
Finally, we review experimental research platforms that can be used to design
and test O-RAN networks, along with recent research results, and we outline
future directions for O-RAN development."
1429,"In addition, further research can help
   designing further extensions of the O-RAN architecture,             • Energy efﬁciency with Open RAN.",and RIC elements.,"As discussed in Sec-
   which, for example, enable real-time control in the RAN                tion II, virtualization and closed-loop control provide use-
   nodes through what we deﬁne as dApps in [197].",2022-02-02 13:56:04+00:00,"Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Michele Polese'), arxiv.Result.Author('Leonardo Bonati'), arxiv.Result.Author(""Salvatore D'Oro""), arxiv.Result.Author('Stefano Basagni'), arxiv.Result.Author('Tommaso Melodia')]","The Open Radio Access Network (RAN) and its embodiment through the O-RAN
Alliance specifications are poised to revolutionize the telecom ecosystem.
O-RAN promotes virtualized RANs where disaggregated components are connected
via open interfaces and optimized by intelligent controllers. The result is a
new paradigm for the RAN design, deployment, and operations: O-RAN networks can
be built with multi-vendor, interoperable components, and can be
programmatically optimized through a centralized abstraction layer and
data-driven closed-loop control. Therefore, understanding O-RAN, its
architecture, its interfaces, and workflows is key for researchers and
practitioners in the wireless community. In this article, we present the first
detailed tutorial on O-RAN. We also discuss the main research challenges and
review early research results. We provide a deep dive of the O-RAN
specifications, describing its architecture, design principles, and the O-RAN
interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs)
can be used to effectively control and manage 3GPP-defined RANs. Based on this,
we discuss innovations and challenges of O-RAN networks, including the
Artificial Intelligence (AI) and Machine Learning (ML) workflows that the
architecture and interfaces enable, security and standardization issues.
Finally, we review experimental research platforms that can be used to design
and test O-RAN networks, along with recent research results, and we outline
future directions for O-RAN development."
1440,"we selected for further study, and we take care to report on
actual users in groups only, and as generically as possible by      OpenINTEL      Start date   End date   Total # responses    # unique PTRs
picking a very common given name to search for.","To further mitigate this concern, we     Table 1: Statistics for the data sets that we obtained from
do not disclose the names of organisation’s whose networks          OpenINTEL and Rapid7.","Rapid7 Sonar
                                                                                  2020-02-17   2021-12-01               396 G          1,356 M
   Second, we sought express permission for our supplemen-                        2019-10-01   2021-01-01                 77 G         1,381 M
tary measurement, as this further aggravates the privacy risk
by obtaining more timely information about the presence             4.2 Identifying Exposing Networks
of devices and users on targeted networks.",2022-02-02 17:39:19+00:00,Saving Brian's Privacy: the Perils of Privacy Exposure through Reverse DNS,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Olivier van der Toorn'), arxiv.Result.Author('Raffaele Sommese'), arxiv.Result.Author('Anna Sperotto'), arxiv.Result.Author('Roland van Rijswijk-Deij'), arxiv.Result.Author('Mattijs Jonker')]","Given the importance of privacy, many Internet protocols are nowadays
designed with privacy in mind (e.g., using TLS for confidentiality). Foreseeing
all privacy issues at the time of protocol design, however, is challenging and
may become near impossible when interaction out of protocol bounds occurs. One
demonstrably not well understood interaction occurs when DHCP exchanges are
accompanied by automated changes to the global DNS, for example to dynamically
add hostnames for allocated IP addresses. As we will substantiate in this
paper, this is a privacy risk: the presence of specific clients and network
dynamics may be learned from virtually anywhere on the Internet, even if other
mechanisms to limit tracking by outsiders (e.g., blocking pings) are in place.
We present a first of its kind study into this risk. We identify networks that
expose client identifiers in reverse DNS records and study the relation between
the presence of clients and said records. Our results show a strong link: in 9
out of 10 cases, records linger for at most an hour, for a selection of
academic, enterprise and ISP networks alike. We also demonstrate how client
patterns and network dynamics can be learned, by tracking devices owned by
persons named Brian over time, revealing shifts in work patterns caused by
COVID-19 related work-from-home measures, and by determining a good time to
stage a heist."
1441,"We leave further study of external visibility of such
record the maximum number of daily IP addresses per /24 over the            network segmentation as future work.","For the prefixes for which we do, we also              Section 4.1).","Finally, we note that the
three-month period.",2022-02-02 17:39:19+00:00,Saving Brian's Privacy: the Perils of Privacy Exposure through Reverse DNS,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Olivier van der Toorn'), arxiv.Result.Author('Raffaele Sommese'), arxiv.Result.Author('Anna Sperotto'), arxiv.Result.Author('Roland van Rijswijk-Deij'), arxiv.Result.Author('Mattijs Jonker')]","Given the importance of privacy, many Internet protocols are nowadays
designed with privacy in mind (e.g., using TLS for confidentiality). Foreseeing
all privacy issues at the time of protocol design is, however, challenging and
may become near impossible when interaction out of protocol bounds occurs. One
demonstrably not well understood interaction occurs when DHCP exchanges are
accompanied by automated changes to the global DNS (e.g., to dynamically add
hostnames for allocated IP addresses). As we will substantiate, this is a
privacy risk: one may be able to infer device presence and network dynamics
from virtually anywhere on the Internet -- and even identify and track
individuals -- even if other mechanisms to limit tracking by outsiders (e.g.,
blocking pings) are in place.
  We present a first of its kind study into this risk. We identify networks
that expose client identifiers in reverse DNS records and study the relation
between the presence of clients and said records. Our results show a strong
link: in 9 out of 10 cases, records linger for at most an hour, for a selection
of academic, enterprise and ISP networks alike. We also demonstrate how client
patterns and network dynamics can be learned, by tracking devices owned by
persons named Brian over time, revealing shifts in work patterns caused by
COVID-19 related work-from-home measures, and by determining a good time to
stage a heist."
1442,"The DHCP Host        for further study, and we take care to report on users in aggregate
Name option is commonly used for identification and to update the       only.","To further mitigate this concern, we do not
we know that for Bluetooth and Wi-Fi Direct pairing, sharing such       disclose the names of organisations whose networks we selected
information helps identify the device in question.","Finally, when zooming in on individual given names, we
address of the host in local name services (see Section 2.1).",2022-02-02 17:39:19+00:00,Saving Brian's Privacy: the Perils of Privacy Exposure through Reverse DNS,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Olivier van der Toorn'), arxiv.Result.Author('Raffaele Sommese'), arxiv.Result.Author('Anna Sperotto'), arxiv.Result.Author('Roland van Rijswijk-Deij'), arxiv.Result.Author('Mattijs Jonker')]","Given the importance of privacy, many Internet protocols are nowadays
designed with privacy in mind (e.g., using TLS for confidentiality). Foreseeing
all privacy issues at the time of protocol design is, however, challenging and
may become near impossible when interaction out of protocol bounds occurs. One
demonstrably not well understood interaction occurs when DHCP exchanges are
accompanied by automated changes to the global DNS (e.g., to dynamically add
hostnames for allocated IP addresses). As we will substantiate, this is a
privacy risk: one may be able to infer device presence and network dynamics
from virtually anywhere on the Internet -- and even identify and track
individuals -- even if other mechanisms to limit tracking by outsiders (e.g.,
blocking pings) are in place.
  We present a first of its kind study into this risk. We identify networks
that expose client identifiers in reverse DNS records and study the relation
between the presence of clients and said records. Our results show a strong
link: in 9 out of 10 cases, records linger for at most an hour, for a selection
of academic, enterprise and ISP networks alike. We also demonstrate how client
patterns and network dynamics can be learned, by tracking devices owned by
persons named Brian over time, revealing shifts in work patterns caused by
COVID-19 related work-from-home measures, and by determining a good time to
stage a heist."
1471,"A meticulous analysis of energy consumption for deploying
RASCs with neutral grasping capabilities will also form part                    [15] Y. Yan, Q. Hu, and D. M. Blough, “Feasibility of multipath construction
of further research.","6627, 2015.","in mmwave backhaul,” in 2021 IEEE 22nd International Symposium on a
                                                                                      World of Wireless, Mobile and Multimedia Networks (WoWMoM).",2022-02-03 12:35:06+00:00,Robotic Aerial 6G Small Cells with Grasping End Effectors for mmWave Relay Backhauling,cs.NI,"['cs.NI', 'cs.RO']","[arxiv.Result.Author('Jongyul Lee'), arxiv.Result.Author('Vasilis Friderikos')]","Deployment of small cells in dense urban areas dedicated to the heterogeneous
network (HetNet) and associated relay nodes for improving backhauling is
expected to be an important structural element in the design of beyond 5G (B5G)
and 6G wireless access networks. A key operational aspect in HetNets is how to
optimally implement the wireless backhaul links to efficiently support the
traffic demand. In this work, we utilize the recently proposed Robotic Aerial
Small Cells (RASCs) that are able to grasp at different tall urban landforms as
wireless relay nodes for backhauling. This can be considered as an alternative
to fixed small cells (FSCs) which lack flexibility since once installed their
position cannot be altered. More specifically, on-demand deployment of RASCs is
considered for constructing a millimeter-wave (mmWave) backhaul network to
optimize available network capacity using a network flow-based mixed integer
linear programming (MILP) formulation. Numerical investigations reveal that for
the same required achievable throughput, the number of RASCs required are 25\%
to 65\% less than the number of required FSCs. This result can have significant
implications in reducing required wireless network equipment (capex) to provide
a given network capacity and allows for an efficient and flexible network
densification."
1563,"The further research in this direction will focus on a detailed studying the VCSEL-based optical
transmission with real-time monitoring function for ongoing 5G and beyond access networks of
millimeter-wave band.","The feasibility and efficiency of the
proposed solution are confirmed by a proof-of-concept experiment when optically transmitting a
high-speed digital signal with 64-position quadrature amplitude modulation of a 5-GHz radio-
frequency carrier, which is widely exploited in access networks of fifth-generation cellular
communication systems based on Radio-over-Fiber technology and small cell architecture
scenario.","The fundamental feasibility of this path due to optical injection locking
has already been considered in a number of scientific publications, for example, in [21] and
confirmed experimentally [22] using the same VCSEL chip as in this study.",2022-01-31 12:43:38+00:00,Advanced service data provisioning in ROF-based mobile backhauls/fronthauls,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Mikhail E. Belkin'), arxiv.Result.Author('Leonid Zhukov'), arxiv.Result.Author('Alexander S. Sigov')]","A new cost-efficient concept to realize a real-time monitoring of
quality-of-service metrics and other service data in 5G and beyond access
network using a separate return channel based on a vertical cavity surface
emitting laser in the optical injection locked mode that simultaneously
operates as an optical transmitter and as a resonant cavity enhanced
photodetector, is proposed and discussed. The feasibility and efficiency of the
proposed approach are confirmed by a proof-of-concept experiment when optically
transceiving high-speed digital signal with multi-position quadrature amplitude
modulation of a radio-frequency carrier."
1682,"Lastly, as a scope of further research, authors have identified the following issues:
scheduling, random access, packetization, and operation at higher levels.","Overall, authors have concluded that semantic networks require a combination of concepts and tools
which are developed separately.","The authors in [30], have implemented
semantics for solving the issues of spectrum and energy by proposing a framework for transmission under high
semantic fidelity.",2022-02-08 07:58:29+00:00,A Survey on Sematic Communications for Intelligent Wireless Networks,cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Khaled Rabie'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Wali Ullah Khan'), arxiv.Result.Author('Zubair Fadlullah')]","With deployment of 6G technology, it is envisioned that competitive edge of
wireless networks will be sustained and next decade's communication
requirements will be stratified. Also 6G will aim to aid development of a human
society which is ubiquitous and mobile, simultaneously providing solutions to
key challenges such as, coverage, capacity, etc. In addition, 6G will focus on
providing intelligent use-cases and applications using higher data-rates over
mill-meter waves and Tera-Hertz frequency. However, at higher frequencies
multiple non-desired phenomena such as atmospheric absorption, blocking, etc.,
occur which create a bottleneck owing to resource (spectrum and energy)
scarcity. Hence, following same trend of making efforts towards reproducing at
receiver, exact information which was sent by transmitter, will result in a
never ending need for higher bandwidth. A possible solution to such a challenge
lies in semantic communications which focuses on meaning (context) of received
data as opposed to only reproducing correct transmitted data. This in turn will
require less bandwidth, and will reduce bottleneck due to various undesired
phenomenon. In this respect, current article presents a detailed survey on
recent technological trends in regard to semantic communications for
intelligent wireless networks. We focus on semantic communications architecture
including model, and source and channel coding. Next, we detail cross-layer
interaction, and various goal-oriented communication applications. We also
present overall semantic communications trends in detail, and identify
challenges which need timely solutions before practical implementation of
semantic communications within 6G wireless technology. Our survey article is an
attempt to significantly contribute towards initiating future research
directions in area of semantic communications for intelligent 6G wireless
networks."
1683,"Also, keeping the aims of semantic
       communications in mind, the following require further research (i) the role which feedback will play
       considering real time channel environment, (ii) the retransmissions over the link layer under real channel
       conditions, and (iii) the error rates which can be achieved considering lengths of the block which are non-
       asymptotic in nature.","In view of savings on miscellaneous operations over packet data, the optimization of packet structure i.e., a
       clear differentiation between data and miscellaneous data is required.",6.,2022-02-08 07:58:29+00:00,A Survey on Sematic Communications for Intelligent Wireless Networks,cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Khaled Rabie'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Wali Ullah Khan'), arxiv.Result.Author('Zubair Fadlullah')]","With deployment of 6G technology, it is envisioned that competitive edge of
wireless networks will be sustained and next decade's communication
requirements will be stratified. Also 6G will aim to aid development of a human
society which is ubiquitous and mobile, simultaneously providing solutions to
key challenges such as, coverage, capacity, etc. In addition, 6G will focus on
providing intelligent use-cases and applications using higher data-rates over
mill-meter waves and Tera-Hertz frequency. However, at higher frequencies
multiple non-desired phenomena such as atmospheric absorption, blocking, etc.,
occur which create a bottleneck owing to resource (spectrum and energy)
scarcity. Hence, following same trend of making efforts towards reproducing at
receiver, exact information which was sent by transmitter, will result in a
never ending need for higher bandwidth. A possible solution to such a challenge
lies in semantic communications which focuses on meaning (context) of received
data as opposed to only reproducing correct transmitted data. This in turn will
require less bandwidth, and will reduce bottleneck due to various undesired
phenomenon. In this respect, current article presents a detailed survey on
recent technological trends in regard to semantic communications for
intelligent wireless networks. We focus on semantic communications architecture
including model, and source and channel coding. Next, we detail cross-layer
interaction, and various goal-oriented communication applications. We also
present overall semantic communications trends in detail, and identify
challenges which need timely solutions before practical implementation of
semantic communications within 6G wireless technology. Our survey article is an
attempt to significantly contribute towards initiating future research
directions in area of semantic communications for intelligent 6G wireless
networks."
1684,"Lastly, we have also presented
future directions to the multiple existing challenges with a hope that this will spur further research on semantic
communications for next generation intelligent wireless networks.","Further, this will also enable a learning mechanism which, in addition to
learning through examples, will construct abstract models to guide further learning.","References

      1.",2022-02-08 07:58:29+00:00,A Survey on Sematic Communications for Intelligent Wireless Networks,cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Khaled Rabie'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Wali Ullah Khan'), arxiv.Result.Author('Zubair Fadlullah')]","With deployment of 6G technology, it is envisioned that competitive edge of
wireless networks will be sustained and next decade's communication
requirements will be stratified. Also 6G will aim to aid development of a human
society which is ubiquitous and mobile, simultaneously providing solutions to
key challenges such as, coverage, capacity, etc. In addition, 6G will focus on
providing intelligent use-cases and applications using higher data-rates over
mill-meter waves and Tera-Hertz frequency. However, at higher frequencies
multiple non-desired phenomena such as atmospheric absorption, blocking, etc.,
occur which create a bottleneck owing to resource (spectrum and energy)
scarcity. Hence, following same trend of making efforts towards reproducing at
receiver, exact information which was sent by transmitter, will result in a
never ending need for higher bandwidth. A possible solution to such a challenge
lies in semantic communications which focuses on meaning (context) of received
data as opposed to only reproducing correct transmitted data. This in turn will
require less bandwidth, and will reduce bottleneck due to various undesired
phenomenon. In this respect, current article presents a detailed survey on
recent technological trends in regard to semantic communications for
intelligent wireless networks. We focus on semantic communications architecture
including model, and source and channel coding. Next, we detail cross-layer
interaction, and various goal-oriented communication applications. We also
present overall semantic communications trends in detail, and identify
challenges which need timely solutions before practical implementation of
semantic communications within 6G wireless technology. Our survey article is an
attempt to significantly contribute towards initiating future research
directions in area of semantic communications for intelligent 6G wireless
networks."
1685,"Lastly, as a scope of further research, authors have identified the following issues:
scheduling, random access, packetization, and operation at higher levels.","Overall, authors have concluded that semantic networks require a combination of concepts and tools
which are developed separately.","The authors in [30], have implemented
semantics for solving the issues of spectrum and energy by proposing a framework for transmission under high
semantic fidelity.",2022-02-08 07:58:29+00:00,A Survey on Semantic Communications for Intelligent Wireless Networks,cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Khaled Rabie'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Wali Ullah Khan'), arxiv.Result.Author('Zubair Fadlullah')]","With deployment of 6G technology, it is envisioned that competitive edge of
wireless networks will be sustained and next decade's communication
requirements will be stratified. Also 6G will aim to aid development of a human
society which is ubiquitous and mobile, simultaneously providing solutions to
key challenges such as, coverage, capacity, etc. In addition, 6G will focus on
providing intelligent use-cases and applications using higher data-rates over
mill-meter waves and Tera-Hertz frequency. However, at higher frequencies
multiple non-desired phenomena such as atmospheric absorption, blocking, etc.,
occur which create a bottleneck owing to resource (spectrum and energy)
scarcity. Hence, following same trend of making efforts towards reproducing at
receiver, exact information which was sent by transmitter, will result in a
never ending need for higher bandwidth. A possible solution to such a challenge
lies in semantic communications which focuses on meaning (context) of received
data as opposed to only reproducing correct transmitted data. This in turn will
require less bandwidth, and will reduce bottleneck due to various undesired
phenomenon. In this respect, current article presents a detailed survey on
recent technological trends in regard to semantic communications for
intelligent wireless networks. We focus on semantic communications architecture
including model, and source and channel coding. Next, we detail cross-layer
interaction, and various goal-oriented communication applications. We also
present overall semantic communications trends in detail, and identify
challenges which need timely solutions before practical implementation of
semantic communications within 6G wireless technology. Our survey article is an
attempt to significantly contribute towards initiating future research
directions in area of semantic communications for intelligent 6G wireless
networks."
1686,"Also, keeping the aims of semantic
       communications in mind, the following require further research (i) the role which feedback will play
       considering real time channel environment, (ii) the retransmissions over the link layer under real channel
       conditions, and (iii) the error rates which can be achieved considering lengths of the block which are non-
       asymptotic in nature.","In view of savings on miscellaneous operations over packet data, the optimization of packet structure i.e., a
       clear differentiation between data and miscellaneous data is required.",6.,2022-02-08 07:58:29+00:00,A Survey on Semantic Communications for Intelligent Wireless Networks,cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Khaled Rabie'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Wali Ullah Khan'), arxiv.Result.Author('Zubair Fadlullah')]","With deployment of 6G technology, it is envisioned that competitive edge of
wireless networks will be sustained and next decade's communication
requirements will be stratified. Also 6G will aim to aid development of a human
society which is ubiquitous and mobile, simultaneously providing solutions to
key challenges such as, coverage, capacity, etc. In addition, 6G will focus on
providing intelligent use-cases and applications using higher data-rates over
mill-meter waves and Tera-Hertz frequency. However, at higher frequencies
multiple non-desired phenomena such as atmospheric absorption, blocking, etc.,
occur which create a bottleneck owing to resource (spectrum and energy)
scarcity. Hence, following same trend of making efforts towards reproducing at
receiver, exact information which was sent by transmitter, will result in a
never ending need for higher bandwidth. A possible solution to such a challenge
lies in semantic communications which focuses on meaning (context) of received
data as opposed to only reproducing correct transmitted data. This in turn will
require less bandwidth, and will reduce bottleneck due to various undesired
phenomenon. In this respect, current article presents a detailed survey on
recent technological trends in regard to semantic communications for
intelligent wireless networks. We focus on semantic communications architecture
including model, and source and channel coding. Next, we detail cross-layer
interaction, and various goal-oriented communication applications. We also
present overall semantic communications trends in detail, and identify
challenges which need timely solutions before practical implementation of
semantic communications within 6G wireless technology. Our survey article is an
attempt to significantly contribute towards initiating future research
directions in area of semantic communications for intelligent 6G wireless
networks."
1687,"Lastly, we have also presented
future directions to the multiple existing challenges with a hope that this will spur further research on semantic
communications for next generation intelligent wireless networks.","Further, this will also enable a learning mechanism which, in addition to
learning through examples, will construct abstract models to guide further learning.","Declarations

Funding
The authors declare that no funds, grants, or other support were received during the
preparation of this manuscript.",2022-02-08 07:58:29+00:00,A Survey on Semantic Communications for Intelligent Wireless Networks,cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Khaled Rabie'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Wali Ullah Khan'), arxiv.Result.Author('Zubair Fadlullah')]","With deployment of 6G technology, it is envisioned that competitive edge of
wireless networks will be sustained and next decade's communication
requirements will be stratified. Also 6G will aim to aid development of a human
society which is ubiquitous and mobile, simultaneously providing solutions to
key challenges such as, coverage, capacity, etc. In addition, 6G will focus on
providing intelligent use-cases and applications using higher data-rates over
mill-meter waves and Tera-Hertz frequency. However, at higher frequencies
multiple non-desired phenomena such as atmospheric absorption, blocking, etc.,
occur which create a bottleneck owing to resource (spectrum and energy)
scarcity. Hence, following same trend of making efforts towards reproducing at
receiver, exact information which was sent by transmitter, will result in a
never ending need for higher bandwidth. A possible solution to such a challenge
lies in semantic communications which focuses on meaning (context) of received
data as opposed to only reproducing correct transmitted data. This in turn will
require less bandwidth, and will reduce bottleneck due to various undesired
phenomenon. In this respect, current article presents a detailed survey on
recent technological trends in regard to semantic communications for
intelligent wireless networks. We focus on semantic communications architecture
including model, and source and channel coding. Next, we detail cross-layer
interaction, and various goal-oriented communication applications. We also
present overall semantic communications trends in detail, and identify
challenges which need timely solutions before practical implementation of
semantic communications within 6G wireless technology. Our survey article is an
attempt to significantly contribute towards initiating future research
directions in area of semantic communications for intelligent 6G wireless
networks."
1737,"These areas are also under development, which
need further research.","Besides the descriptions and
discussions presented in Section 4 and Section 5, there are many other interesting
areas of using 5G, e.g., D2D communications, virtual reality, augmented reality,
smart industry, and smart grid.",Appendix A.,2022-02-09 07:13:18+00:00,Using 5G in Smart Cities: A Systematic Mapping Study,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Chen Yang'), arxiv.Result.Author('Peng Liang'), arxiv.Result.Author('Liming Fu'), arxiv.Result.Author('Guorui Cui'), arxiv.Result.Author('Fei Huang'), arxiv.Result.Author('Feng Teng'), arxiv.Result.Author('Yawar Abbas Bangash')]","5G is the fifth generation wireless network, with a set of characteristics,
e.g., high bandwidth and data rates. The scenarios of using 5G include enhanced
Mobile Broadband (eMBB), massive Machine Type Communications (mMTC), and
ultra-Reliable and Low-Latency Communications (uRLLC). 5G is expected to
support a wide variety of applications. We conducted a systematic mapping study
that covers the literature published between Jan 2012 and Dec 2019 regarding
using 5G in smart cities. The scenarios, architecture, technologies,
challenges, and lessons learned of using 5G in smart cities are summarized and
further analyzed based on 32 selected studies, and the results are that: (1)
The studies are distributed over 27 publication venues. 17 studies report
results based on academic studies and 13 studies use demonstration or toy
examples. Only 2 studies report using 5G in smart cities based on industrial
studies. 16 studies include assumptions of 5G network design or smart city
scenarios. (2) The most discussed smart city scenario is transportation,
followed by public safety, healthcare, city tourism, entertainment, and
education. (3) 28 studies propose and/or discuss the architecture of 5G-enabled
smart cities, containing smart city architecture (treating 5G as a component),
5G network architecture in smart cities, and business architecture of using 5G
in smart cities. (4) The most mentioned 5G-related technologies are radio
access technologies, network slicing, and edge computing. (5) Challenges are
mainly about complex context, challenging requirements, and network development
of using 5G in smart cities. (6) Most of the lessons learned identified are
benefits regarding 5G itself or the proposed 5G-related methods in smart
cities. This work provides a reflection of the past eight years of the state of
the art on using 5G in smart cities, which can benefit both researchers and
practitioners."
1738,"These areas are also under development, which
need further research.","Besides the descriptions and
discussions presented in Section 4 and Section 5, there are many other interesting
areas of using 5G, e.g., D2D communications, virtual reality, augmented reality,
smart industry, and smart grid.",Appendix A.,2022-02-09 07:13:18+00:00,Using 5G in Smart Cities: A Systematic Mapping Study,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Chen Yang'), arxiv.Result.Author('Peng Liang'), arxiv.Result.Author('Liming Fu'), arxiv.Result.Author('Guorui Cui'), arxiv.Result.Author('Fei Huang'), arxiv.Result.Author('Feng Teng'), arxiv.Result.Author('Yawar Abbas Bangash')]","5G is the fifth generation wireless network, with a set of characteristics,
e.g., high bandwidth and data rates. The scenarios of using 5G include enhanced
Mobile Broadband (eMBB), massive Machine Type Communications (mMTC), and
ultra-Reliable and Low-Latency Communications (uRLLC). 5G is expected to
support a wide variety of applications. We conducted a systematic mapping study
that covers the literature published between Jan 2012 and Dec 2019 regarding
using 5G in smart cities. The scenarios, architecture, technologies,
challenges, and lessons learned of using 5G in smart cities are summarized and
further analyzed based on 32 selected studies, and the results are that: (1)
The studies are distributed over 27 publication venues. 17 studies report
results based on academic studies and 13 studies use demonstration or toy
examples. Only 2 studies report using 5G in smart cities based on industrial
studies. 16 studies include assumptions of 5G network design or smart city
scenarios. (2) The most discussed smart city scenario is transportation,
followed by public safety, healthcare, city tourism, entertainment, and
education. (3) 28 studies propose and/or discuss the architecture of 5G-enabled
smart cities, containing smart city architecture (treating 5G as a component),
5G network architecture in smart cities, and business architecture of using 5G
in smart cities. (4) The most mentioned 5G-related technologies are radio
access technologies, network slicing, and edge computing. (5) Challenges are
mainly about complex context, challenging requirements, and network development
of using 5G in smart cities. (6) Most of the lessons learned identified are
benefits regarding 5G itself or the proposed 5G-related methods in smart
cities. This work provides a reflection of the past eight years of the state of
the art on using 5G in smart cities, which can benefit both researchers and
practitioners."
1887,"Such trends are in accordance with for-
   We further study the impacts of computation capacity of               mula and (10) and (11).","energy consumption is increasing with the increment of UAV’s
                                                                         computation capacity.","Besides, note that HAP’s computation
UAVs and HAPs on the optimization performance in Fig.",2022-02-12 11:39:42+00:00,Hierarchical Aerial Computing for Internet of Things via Cooperation of HAPs and UAVs,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Ziye Jia'), arxiv.Result.Author('Qihui Wu'), arxiv.Result.Author('Chao Dong'), arxiv.Result.Author('Chau Yuen'), arxiv.Result.Author('Zhu Han')]","With the explosive increment of computation requirements, the multi-access
edge computing (MEC) paradigm appears as an effective mechanism. Besides, as
for the Internet of Things (IoT) in disasters or remote areas requiring MEC
services, unmanned aerial vehicles (UAVs) and high altitude platforms (HAPs)
are available to provide aerial computing services for these IoT devices. In
this paper, we develop the hierarchical aerial computing framework composed of
HAPs and UAVs, to provide MEC services for various IoT applications. In
particular, the problem is formulated to maximize the total IoT data computed
by the aerial MEC platforms, restricted by the delay requirement of IoT and
multiple resource constraints of UAVs and HAPs, which is an integer programming
problem and intractable to solve. Due to the prohibitive complexity of
exhaustive search, we handle the problem by presenting the matching game theory
based algorithm to deal with the offloading decisions from IoT devices to UAVs,
as well as a heuristic algorithm for the offloading decisions between UAVs and
HAPs. The external effect affected by interplay of different IoT devices in the
matching is tackled by the externality elimination mechanism. Besides, an
adjustment algorithm is also proposed to make the best of aerial resources. The
complexity of proposed algorithms is analyzed and extensive simulation results
verify the efficiency of the proposed algorithms, and the system performances
are also analyzed by the numerical results."
1907,"We provide a brief review of the published       ies [28, 40, 41, 49] develop access control and authorisation mecha-
literature in order to motivate further research on applications and    nisms for IPFS storage in combination with blockchain solutions.","Various stud-
tralised applications.",areas that have not been covered yet.,2022-02-13 13:54:49+00:00,"Towards Decentralised Cloud Storage with IPFS: Opportunities, Challenges, and Future Directions",cs.NI,['cs.NI'],"[arxiv.Result.Author('Trinh Viet Doan'), arxiv.Result.Author('Vaibhav Bajpai'), arxiv.Result.Author('Yiannis Psaras'), arxiv.Result.Author('Jörg Ott')]","Recent data ownership initiatives such as GAIA-X attempt to shift from
currently common centralised cloud storage solutions to decentralised
alternatives, which gives users more control over their data. The
InterPlanetary File System (IPFS) is a storage architecture which attempts to
provide decentralised cloud storage by building on founding principles of P2P
networking and content addressing. It combines approaches from previous
research, such as Kademlia-based Distributed Hash Tables (DHTs), git's
versioning model with cryptographic hashing, Merkle Trees, and content-based
addressing in order to compose a protocol stack that supports both forward and
backward compatibility of components. IPFS is used by more than 250k peers per
month and serves tens of millions of requests per day, which makes it an
interesting large-scale operational network to study. In this editorial, we
provide an overview of the IPFS design and its core features, along with the
opportunities that it opens as well as the challenges that it faces because of
its properties. IPFS provides persistence of names, censorship circumvention,
built-in file deduplication with integrity verification, and file delivery to
external users via an HTTP gateway, among other properties."
2023,"topic to CN deployments and design, it also leaves much room
for further research contributions from different perspectives,              [11] N. P. Lopes and A. Rybalchenko, “Fast BGP Simulation of Large Data-
such as data collection or generation models, ML method                            centers BT - Veriﬁcation, Model Checking, and Abstract Interpretation,”
enhancements, and evaluation on deployment variations.",Although this approach makes it an attractive                          1–5.,"C. Enea and R. Piskac, Eds.",2022-02-15 16:03:29+00:00,Closing the Management Gap for Satellite-Integrated Community Networks: A Hierarchical Approach to Self-Maintenance,cs.NI,"['cs.NI', 'cs.LG']",[arxiv.Result.Author('Peng Hu')],"Community networks (CNs) have become an important paradigm for providing
essential Internet connectivity in unserved and underserved areas across the
world. However, an indispensable part for CNs is network management, where
responsive and autonomous maintenance is much needed. With the technological
advancement in telecommunications networks, a classical satellite-dependent CN
is envisioned to be transformed into a satellite-integrated CN (SICN), which
will embrace significant autonomy, intelligence, and scalability in network
management. This article discusses the machine-learning (ML) based hierarchical
approach to enabling autonomous self-maintenance for SICNs. The approach is
split into the anomaly identification and anomaly mitigation phases, where the
related ML methods, data collection means, deployment options, and mitigation
schemes are presented. With the case study, we discuss a typical scenario using
satellite and fixed connections as backhaul options and show the effectiveness
\hl{and performance improvements} of the proposed approach \hl{with recurrent
neural network and ensemble methods"
2024,"topic to CN deployments and design, it also leaves much room
for further research contributions from different perspectives,              [11] N. P. Lopes and A. Rybalchenko, “Fast BGP Simulation of Large Data-
such as data collection or generation models, ML method                            centers BT - Veriﬁcation, Model Checking, and Abstract Interpretation,”
enhancements, and evaluation on deployment variations.",Although this approach makes it an attractive                          1–5.,"C. Enea and R. Piskac, Eds.",2022-02-15 16:03:29+00:00,Closing the Management Gap for Satellite-Integrated Community Networks: A Hierarchical Approach to Self-Maintenance,cs.NI,"['cs.NI', 'cs.LG']",[arxiv.Result.Author('Peng Hu')],"Community networks (CNs) have become an important paradigm for providing
essential Internet connectivity in unserved and underserved areas across the
world. However, an indispensable part for CNs is network management, where
responsive and autonomous maintenance is much needed. With the technological
advancement in telecommunications networks, a classical satellite-dependent CN
is envisioned to be transformed into a satellite-integrated CN (SICN), which
will embrace significant autonomy, intelligence, and scalability in network
management. This article discusses the machine-learning (ML) based hierarchical
approach to enabling autonomous self-maintenance for SICNs. The approach is
split into the anomaly identification and anomaly mitigation phases, where the
related ML methods, data collection means, deployment options, and mitigation
schemes are presented. With the case study, we discuss a typical scenario using
satellite and fixed connections as backhaul options and show the effectiveness
and performance improvements of the proposed approach with recurrent neural
network and ensemble methods"
2308,"Nevertheless, further research is needed, since Wehner’s
entangling nodes belonging to diﬀerent quantum networks           model depends on some speciﬁc assumptions, such as tai-
– through network devices called quantum routers.","Fi-    standardization organizations and industries as discussed in
nally, the highest layer, i.e., the network layer, is responsi-   Section 7.8 – through the abstraction provided by HAL sub-
ble for establishing inter-network entanglement – namely, of      layer.","In addi-        loring the diﬀerent layers for quantum teleportation, which
tion, each layer above the physical one has access to auxil-      constitutes only a speciﬁc type of quantum communication
iary protocols for entanglement distillation, for performing      protocol.",2022-02-22 13:46:42+00:00,Quantum Internet Protocol Stack: a Comprehensive Survey,cs.NI,"['cs.NI', 'quant-ph']","[arxiv.Result.Author('Jessica Illiano'), arxiv.Result.Author('Marcello Caleffi'), arxiv.Result.Author('Antonio Manzalini'), arxiv.Result.Author('Angela Sara Cacciapuoti')]","Classical Internet evolved exceptionally during the last five decades, from a
network comprising a few static nodes in the early days to a leviathan
interconnecting billions of devices. This has been possible by the separation
of concern principle, for which the network functionalities are organized as a
stack of layers, each providing some communication functionalities through
specific network protocols. In this survey, we aim at highlighting the
impossibility of adapting the classical Internet protocol stack to the Quantum
Internet, due to the marvels of quantum mechanics. Indeed, the design of the
Quantum Internet requires a major paradigm shift of the whole protocol stack
for harnessing the peculiarities of quantum entanglement and quantum
information. In this context, we first overview the relevant literature about
Quantum Internet protocol stack. Then, stemming from this, we sheds the light
on the open problems and required efforts toward the design of an effective and
complete Quantum Internet protocol stack. To the best of authors' knowledge, a
survey of this type is the first of its own. What emerges from this analysis is
that the Quantum Internet, though still in its infancy, is a disruptive
technology whose design requires an inter-disciplinary effort at the border
between quantum physics, computer and telecommunications engineering."
2309,"Clearly, further research is needed for properly analyzing the        Furthermore, for the comparison purpose, we consider
impact and the trade-oﬀs arising with the adoption of multi-      an additional classiﬁcation, which arises by considering whether
partite entanglement.",proposal is the ﬁrst explicitly conceived to achieve this goal.,"a layer provides intra-network or inter-network functional-
                                                                  ities, namely, whether a layer explicitly provides services
    Van Meter’s model exhibits the remarkable feature of          aiming at interconnecting diﬀerent, independently operated
recognizing that entanglement – as carefully discussed in         networks.",2022-02-22 13:46:42+00:00,Quantum Internet Protocol Stack: a Comprehensive Survey,cs.NI,"['cs.NI', 'quant-ph']","[arxiv.Result.Author('Jessica Illiano'), arxiv.Result.Author('Marcello Caleffi'), arxiv.Result.Author('Antonio Manzalini'), arxiv.Result.Author('Angela Sara Cacciapuoti')]","Classical Internet evolved exceptionally during the last five decades, from a
network comprising a few static nodes in the early days to a leviathan
interconnecting billions of devices. This has been possible by the separation
of concern principle, for which the network functionalities are organized as a
stack of layers, each providing some communication functionalities through
specific network protocols. In this survey, we aim at highlighting the
impossibility of adapting the classical Internet protocol stack to the Quantum
Internet, due to the marvels of quantum mechanics. Indeed, the design of the
Quantum Internet requires a major paradigm shift of the whole protocol stack
for harnessing the peculiarities of quantum entanglement and quantum
information. In this context, we first overview the relevant literature about
Quantum Internet protocol stack. Then, stemming from this, we sheds the light
on the open problems and required efforts toward the design of an effective and
complete Quantum Internet protocol stack. To the best of authors' knowledge, a
survey of this type is the first of its own. What emerges from this analysis is
that the Quantum Internet, though still in its infancy, is a disruptive
technology whose design requires an inter-disciplinary effort at the border
between quantum physics, computer and telecommunications engineering."
2310,"Nevertheless, we may extend the classiﬁca-
further research is needed, since Van Meter’s proposal some-      tion to Wehner’s model – although not explicitly mentioned
how depends on a speciﬁc architecture, namely, entangle-          within the proposal – by exploiting the concept of hardware
ment puriﬁcation based-quantum repeater networks.","Clearly,       glement only.","Indeed,         abstraction.",2022-02-22 13:46:42+00:00,Quantum Internet Protocol Stack: a Comprehensive Survey,cs.NI,"['cs.NI', 'quant-ph']","[arxiv.Result.Author('Jessica Illiano'), arxiv.Result.Author('Marcello Caleffi'), arxiv.Result.Author('Antonio Manzalini'), arxiv.Result.Author('Angela Sara Cacciapuoti')]","Classical Internet evolved exceptionally during the last five decades, from a
network comprising a few static nodes in the early days to a leviathan
interconnecting billions of devices. This has been possible by the separation
of concern principle, for which the network functionalities are organized as a
stack of layers, each providing some communication functionalities through
specific network protocols. In this survey, we aim at highlighting the
impossibility of adapting the classical Internet protocol stack to the Quantum
Internet, due to the marvels of quantum mechanics. Indeed, the design of the
Quantum Internet requires a major paradigm shift of the whole protocol stack
for harnessing the peculiarities of quantum entanglement and quantum
information. In this context, we first overview the relevant literature about
Quantum Internet protocol stack. Then, stemming from this, we sheds the light
on the open problems and required efforts toward the design of an effective and
complete Quantum Internet protocol stack. To the best of authors' knowledge, a
survey of this type is the first of its own. What emerges from this analysis is
that the Quantum Internet, though still in its infancy, is a disruptive
technology whose design requires an inter-disciplinary effort at the border
between quantum physics, computer and telecommunications engineering."
2311,"Nevertheless, further research is needed, since Wehner’s
Internet design [9, 86], it is important to underline that Dür’s  model depends on some speciﬁc assumptions, such as tai-
proposal is the ﬁrst explicitly conceived to achieve this goal.","recognized the need           Section 7.8 – through the abstraction provided by HAL sub-
of exploiting multipartite entangled states for the Quantum       layer.","loring the diﬀerent layers for quantum teleportation, which
Clearly, further research is needed for properly analyzing the    constitutes only a speciﬁc type of quantum communication
impact and the trade-oﬀs arising with the adoption of multi-      protocol.",2022-02-22 13:46:42+00:00,Quantum Internet Protocol Stack: a Comprehensive Survey,cs.NI,"['cs.NI', 'quant-ph']","[arxiv.Result.Author('Jessica Illiano'), arxiv.Result.Author('Marcello Caleffi'), arxiv.Result.Author('Antonio Manzalini'), arxiv.Result.Author('Angela Sara Cacciapuoti')]","Classical Internet evolved exceptionally during the last five decades, from a
network comprising a few static nodes in the early days to a leviathan
interconnecting billions of devices. This has been possible by the separation
of concern principle, for which the network functionalities are organized as a
stack of layers, each providing some communication functionalities through
specific network protocols. In this survey, we aim at highlighting the
impossibility of adapting the classical Internet protocol stack to the Quantum
Internet, due to the marvels of quantum mechanics. Indeed, the design of the
Quantum Internet requires a major paradigm shift of the whole protocol stack
for harnessing the peculiarities of quantum entanglement and quantum
information. In this context, we first overview the relevant literature about
Quantum Internet protocol stack. Then, stemming from this, we sheds the light
on the open problems and required efforts toward the design of an effective and
complete Quantum Internet protocol stack. To the best of authors' knowledge, a
survey of this type is the first of its own. What emerges from this analysis is
that the Quantum Internet, though still in its infancy, is a disruptive
technology whose design requires an inter-disciplinary effort at the border
between quantum physics, computer and telecommunications engineering."
2312,"loring the diﬀerent layers for quantum teleportation, which
Clearly, further research is needed for properly analyzing the    constitutes only a speciﬁc type of quantum communication
impact and the trade-oﬀs arising with the adoption of multi-      protocol.","Nevertheless, further research is needed, since Wehner’s
Internet design [9, 86], it is important to underline that Dür’s  model depends on some speciﬁc assumptions, such as tai-
proposal is the ﬁrst explicitly conceived to achieve this goal.",partite entanglement.,2022-02-22 13:46:42+00:00,Quantum Internet Protocol Stack: a Comprehensive Survey,cs.NI,"['cs.NI', 'quant-ph']","[arxiv.Result.Author('Jessica Illiano'), arxiv.Result.Author('Marcello Caleffi'), arxiv.Result.Author('Antonio Manzalini'), arxiv.Result.Author('Angela Sara Cacciapuoti')]","Classical Internet evolved exceptionally during the last five decades, from a
network comprising a few static nodes in the early days to a leviathan
interconnecting billions of devices. This has been possible by the separation
of concern principle, for which the network functionalities are organized as a
stack of layers, each providing some communication functionalities through
specific network protocols. In this survey, we aim at highlighting the
impossibility of adapting the classical Internet protocol stack to the Quantum
Internet, due to the marvels of quantum mechanics. Indeed, the design of the
Quantum Internet requires a major paradigm shift of the whole protocol stack
for harnessing the peculiarities of quantum entanglement and quantum
information. In this context, we first overview the relevant literature about
Quantum Internet protocol stack. Then, stemming from this, we sheds the light
on the open problems and required efforts toward the design of an effective and
complete Quantum Internet protocol stack. To the best of authors' knowledge, a
survey of this type is the first of its own. What emerges from this analysis is
that the Quantum Internet, though still in its infancy, is a disruptive
technology whose design requires an inter-disciplinary effort at the border
between quantum physics, computer and telecommunications engineering."
2313,"Clearly,       be precisely applied to the layers of the others two mod-
further research is needed, since Van Meter’s proposal some-      els, we can recognize that the lowest two layers of Wehner’s
how depends on a speciﬁc architecture, namely, entangle-          proposal aim at distributing entanglement on single hops,
ment puriﬁcation based-quantum repeater networks.","Although this classiﬁcation cannot
duced by entanglement within the network topology.","Indeed,         whereas the network layer seems providing functionalities
Van Meter’s model was among the ﬁrst proposals, at early          acting on both intermediate and end nodes.",2022-02-22 13:46:42+00:00,Quantum Internet Protocol Stack: a Comprehensive Survey,cs.NI,"['cs.NI', 'quant-ph']","[arxiv.Result.Author('Jessica Illiano'), arxiv.Result.Author('Marcello Caleffi'), arxiv.Result.Author('Antonio Manzalini'), arxiv.Result.Author('Angela Sara Cacciapuoti')]","Classical Internet evolved exceptionally during the last five decades, from a
network comprising a few static nodes in the early days to a leviathan
interconnecting billions of devices. This has been possible by the separation
of concern principle, for which the network functionalities are organized as a
stack of layers, each providing some communication functionalities through
specific network protocols. In this survey, we aim at highlighting the
impossibility of adapting the classical Internet protocol stack to the Quantum
Internet, due to the marvels of quantum mechanics. Indeed, the design of the
Quantum Internet requires a major paradigm shift of the whole protocol stack
for harnessing the peculiarities of quantum entanglement and quantum
information. In this context, we first overview the relevant literature about
Quantum Internet protocol stack. Then, stemming from this, we sheds the light
on the open problems and required efforts toward the design of an effective and
complete Quantum Internet protocol stack. To the best of authors' knowledge, a
survey of this type is the first of its own. What emerges from this analysis is
that the Quantum Internet, though still in its infancy, is a disruptive
technology whose design requires an inter-disciplinary effort at the border
between quantum physics, computer and telecommunications engineering."
2368,"In 5G, the main limitation of blockchain
          concerns the throughput [2]; however, with the use of consensus algorithms, novel architecture, and
          sharing methods, and an increase in the network block size, the limitations can be minimized in 6G
          communications, which paves the way to further research in this direction.","Having features such as, decentralized tamper-resistance and secrecy, makes blockchain an ideal
          candidate for multiple applications in 6G communications [70].","Hence, advanced frameworks
          and mechanisms for incorporating intelligence within spectrum sharing need to be developed.",2022-02-23 13:13:17+00:00,A Survey on Technological Trends to Enhance Spectrum Efficiency in 6G Communications,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Anita Patil'), arxiv.Result.Author('Shilpa Bhairanatti'), arxiv.Result.Author('Soumya Halagatti'), arxiv.Result.Author('Rahul Jashvantbhai Pandya')]","The research community has already identified that, by 2030, 5G networks will
reach the capacity limits, and hence, will be inadequate to support next
generation bandwidth-hungry, ubiquitous, intelligent services, and
applications. Therefore, in view of sustaining the competitive edge of wireless
technology and stratifying the next decade's communication requirements both,
industry and research community have already begun conceptualizing the 6G
technology. This article presents a detailed survey on the recent technological
trends which address the capacity issues and enhance the spectrum-efficiency in
6G Communications. We present these trends in detail and then identify the
challenges that need solutions before the practical deployment to realize 6G
communications. Our survey article attempts to significantly contribute to
initiating future research directions in the area of spectrum-efficiency in 6G
communications."
2388,"As this PPO approach targets different
                     𝛿𝜋𝑖,𝑙 = 2𝐷𝜋o𝑖f,f𝑙⁄𝑇𝑖pm𝑤𝑖 − 1, ∀𝜋𝑖,𝑙 ∈ 𝒩𝑖 (9)            application scenarios, it is worth conducting further research.","If           In such a case, if the first part of a user program is offloaded to
the workload 𝐷𝑛off and the transmission time 𝑇𝑖pm are known,                 an edge server, it is not necessary to send the final result from
                                                                             the server to the user in the downlink channel, thus saving the
𝛿𝜋𝑖,𝑙 can be given by [13]                                                   data transmission time.",By substituting eq.,2022-02-24 02:27:10+00:00,Joint Program Partitioning and Resource Allocation for Completion Time Minimization in Multi-MEC Systems,cs.NI,['cs.NI'],"[arxiv.Result.Author('Taizhou Yi'), arxiv.Result.Author('Guopeng Zhang'), arxiv.Result.Author('Kezhi Wang'), arxiv.Result.Author('Kun Yang')]","This paper considers a practical mobile edge computing (MEC) system, where
edge server does not pre-install the program required to perform user offloaded
computing tasks. A partial program offloading (PPO) scheme is proposed, which
can divide a user program into two parts, where the first part is executed by
the user itself and the second part is transferred to an edge server for remote
execution. However, the execution of the latter part requires the results of
the previous part (called intermediate result) as the input. We aim to minimize
the overall time consumption of a multi-server MEC system to complete all user
offloaded tasks. It is modeled as a mixed integer nonlinear programming (MINLP)
problem which considers user-and-server association, program partitioning, and
communication resource allocation in a joint manner. An effective algorithm is
developed to solve the problem by exploiting its structural features. First,
the task completion time of a single server is minimized given the computing
workload and available resource. Then, the working time of the edge servers are
balanced by updating user-and-server association and communication resource
allocation. Numerical results show that significant performance improvement can
be achieved by the proposed scheme."
2542,"The main contributions of this paper are sum-
least, the congestion control mechanism of the network also        marized as follows:
needs further research in terms of model stability, convergence
speed, and robustness.",Last but not       subsequently.,"The complexity and diversity of service      1) To the best of the authors’ knowledge, this is the ﬁrst
scenarios and ﬁner granularity of ﬂow demands have made                 comprehensive survey about the application of ML in
congestion control more complicated in data centers.",2022-02-28 05:27:22+00:00,Machine Learning Empowered Intelligent Data Center Networking: A Survey,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Bo Li'), arxiv.Result.Author('Ting Wang'), arxiv.Result.Author('Peng Yang'), arxiv.Result.Author('Mingsong Chen'), arxiv.Result.Author('Shui Yu'), arxiv.Result.Author('Mounir Hamdi')]","To support the needs of ever-growing cloud-based services, the number of
servers and network devices in data centers is increasing exponentially, which
in turn results in high complexities and difficulties in network optimization.
To address these challenges, both academia and industry turn to artificial
intelligence technology to realize network intelligence. To this end, a
considerable number of novel and creative machine learning-based (ML-based)
research works have been put forward in recent few years. Nevertheless, there
are still enormous challenges faced by the intelligent optimization of data
center networks (DCNs), especially in the scenario of online real-time dynamic
processing of massive heterogeneous services and traffic data. To best of our
knowledge, there is a lack of systematic and original comprehensively
investigations with in-depth analysis on intelligent DCN. To this end, in this
paper, we comprehensively investigate the application of machine learning to
data center networking, and provide a general overview and in-depth analysis of
the recent works, covering flow prediction, flow classification, load
balancing, resource management, routing optimization, and congestion control.
In order to provide a multi-dimensional and multi-perspective comparison of
various solutions, we design a quality assessment criteria called REBEL-3S to
impartially measure the strengths and weaknesses of these research works.
Moreover, we also present unique insights into the technology evolution of the
fusion of data center network and machine learning, together with some
challenges and potential future research opportunities."
2543,"The main contributions of this paper are sum-
least, the congestion control mechanism of the network also        marized as follows:
needs further research in terms of model stability, convergence
speed, and robustness.",Last but not       subsequently.,"The complexity and diversity of service      1) To the best of the authors’ knowledge, this is the ﬁrst
scenarios and ﬁner granularity of ﬂow demands have made                 comprehensive survey about the application of ML in
congestion control more complicated in data centers.",2022-02-28 05:27:22+00:00,Machine Learning Empowered Intelligent Data Center Networking: A Survey,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Bo Li'), arxiv.Result.Author('Ting Wang'), arxiv.Result.Author('Peng Yang'), arxiv.Result.Author('Mingsong Chen'), arxiv.Result.Author('Shui Yu'), arxiv.Result.Author('Mounir Hamdi')]","To support the needs of ever-growing cloud-based services, the number of
servers and network devices in data centers is increasing exponentially, which
in turn results in high complexities and difficulties in network optimization.
To address these challenges, both academia and industry turn to artificial
intelligence technology to realize network intelligence. To this end, a
considerable number of novel and creative machine learning-based (ML-based)
research works have been put forward in recent few years. Nevertheless, there
are still enormous challenges faced by the intelligent optimization of data
center networks (DCNs), especially in the scenario of online real-time dynamic
processing of massive heterogeneous services and traffic data. To best of our
knowledge, there is a lack of systematic and original comprehensively
investigations with in-depth analysis on intelligent DCN. To this end, in this
paper, we comprehensively investigate the application of machine learning to
data center networking, and provide a general overview and in-depth analysis of
the recent works, covering flow prediction, flow classification, load
balancing, resource management, routing optimization, and congestion control.
In order to provide a multi-dimensional and multi-perspective comparison of
various solutions, we design a quality assessment criteria called REBEL-3S to
impartially measure the strengths and weaknesses of these research works.
Moreover, we also present unique insights into the technology evolution of the
fusion of data center network and machine learning, together with some
challenges and potential future research opportunities."
2649,"𝜁                                                                            DNS amplification ICMP flood                          Other

 DNS amp    change 𝑎𝑓 𝑡𝑒𝑟 change 𝑎𝑓 𝑡𝑒𝑟                                               change 𝑎𝑓 𝑡𝑒𝑟                                                                          NTP amplification               SYN/SYN-ACK flood
 NTP amp       𝑏𝑒𝑓 𝑜𝑟𝑒                                                    𝑏𝑒𝑓 𝑜𝑟𝑒
ICMP flood                                                                                           𝑏𝑒𝑓 𝑜𝑟𝑒
S/SA flood
            ↑  131%                                               ↑       137%        ↓            56%                                  Duration (mins) Peak intensity  102
   Other
            ↑  255%                                               ↑       151%        ↑ 1163%

            ↑  N/A                                                ↑       N/A         ↑            N/A                                                                  101

            ↑  192%                                               ↓       54%         ↓            74%

            ↑  N/A                                                ↑       N/A         ↑            N/A                                                                  100

            Table 5: Changes of anomalies                                                                                                                               103
                                                                                                                                                                        102
6.1 Measurement of Anomalies                                                                                                                                            101
                                                                                                                                                                        100Feb 24Mar 1 Mar 8 Mar 15 Mar 22 Mar 29 Apr 5 Apr 12 Apr 19 Apr 26 May 3 May 10May 17
We further study the anomalies that happened from February
24 to May 21 to investigate whether the pandemic had any                                                                                                                                        Occurrence time
impact on network security or not.","Both before and after
the transition the highest volume of daily high-high traffic
is exchanged with a single local educational institution fo-
cused on scientific data production about weather, climate,
Measuring Changes in Regional Network Traffic Due to COVID-19 Stay-at-Home Measures                                                                                                                                                                                              ,

3000 Normal time COVID-19                                            100 Normal time     COVID-19                                                 Normal time                COVID-19                                 Normal time  COVID-19
2000                                                                                                                                    100                                                                  50
1000                                                                                                                                                                                                          0
                                                                                                                                          0
3000
2000
1000

    0:002:004:006:008:0010:0012:0014:0016:0018:0020:0022:0024:00
               Time of the day

  (a) https traffic volume
(GWBe/e5kmeinnds) (GWB/or5kmdianys)                                    0
                                                    (GWBe/e5kmeinnds) (GWB/or5kmdianys)100
                                                                                                         (GWBe/e5kmeinnds) (GWB/or5kmdianys)
                                                                                                                                                              (GWBe/e5kmeinnds) (GWB/or5kmdianys)
                                                                     0                                                                  100                                                                  50
                                                                      0:00 2:00 4:00 6:00 8:0010:0012:0014:0016:0018:0020:0022:0024:00    0                                                                   0
                                                                                                                                           0:00 2:00 4:00 6:00 8:0010:0012:0014:0016:0018:0020:0022:0024:00    0:00 2:00 4:00 6:00 8:0010:0012:0014:0016:0018:0020:0022:0024:00
                                                                                 Time of the day                                                      Time of the day
                                                                     (b) Zoom traffic volume                                                                                                                               Time of the day

                                                                                                                                        (c) VPN traffic volume                                               (d) Steam traffic volume

                                                                  Figure 14: Traffic changes within workdays and weekends

Anomaly     Frequency                                             Duration            Peak int.","Figure 15: Illustration of the detected anomalies, in-
   Figure 15 shows the anomaly detection results.",2022-03-01 20:54:44+00:00,Measuring Changes in Regional Network Traffic Due to COVID-19 Stay-at-Home Measures,cs.NI,"['cs.NI', 'cs.CY']","[arxiv.Result.Author('Jelena Mirkovic'), arxiv.Result.Author('Yebo Feng'), arxiv.Result.Author('Jun Li')]","During the 2020 pandemic caused by the COVID-19 virus, many countries
implemented stay-at-home measures, which led to many businesses and schools
moving from in-person to online mode of operation. We analyze sampled Netflow
records at a medium-sized US Regional Optical Network to quantify the changes
in the network traffic due to stay-at-home measures in that region. We find
that human-driven traffic in the network decreases to around 70%, and mostly
shifts to local ISPs, while VPN and online meeting traffic increases up to 5
times. We also find that networks adopt a variety of online meeting solutions
and favor one but continue using a few others. We find that educational and
government institutions experience large traffic changes, but aim to keep their
productivity via increased online meetings. Some scientific traffic also
reduces possibly leading to loss of research productivity. Businesses mostly
lose their traffic and few show VPN or online meeting activity. Most network
prefixes experience large loss of live addresses but a handful increase their
liveness. We also find increased incidence of network attacks. Our findings can
help plan network provisioning and management to prepare for future possible
infection outbreaks and natural disasters."
2800,"smartphones with smaller wearable devices enables numerous                  Meanwhile, further research in this direction requires a better
                                       novel attractive use cases in consumer, industrial, and medical             understanding of the main peculiarities when handling XR
                                       areas, as well as is a foundation for Metaverse revolution [1],             devices and services in real cellular networks.",The suggested replacement of large-scale handheld                   an important role in 5G-Advanced and later 6G systems.,"To facilitate this
                                       [2].",2022-03-04 11:17:34+00:00,"Extended Reality (XR) over 5G and 5G-Advanced New Radio: Standardization, Applications, and Trends",cs.NI,['cs.NI'],"[arxiv.Result.Author('Vitaly Petrov'), arxiv.Result.Author('Margarita Gapeyenko'), arxiv.Result.Author('Stefano Paris'), arxiv.Result.Author('Andrea Marcano'), arxiv.Result.Author('Klaus I. Pedersen')]","Extended Reality (XR) is one of the major innovations to be introduced in
5G/5G-Advanced communication systems. A combination of augmented reality,
virtual reality, and mixed reality, supplemented by cloud gaming, revisits the
way how humans interact with computers, networks, and each other. However,
efficient support of XR services imposes new challenges for existing and future
wireless networks. This article presents a tutorial on integrating support for
the XR into the 3GPP New Radio (NR), summarizing a range of activities handled
within various 3GPP Services and Systems Aspects (SA) and Radio Access Networks
(RAN) groups. The article also delivers a case study evaluating the performance
of different XR services in state-of-the-art NR Release 17. The paper concludes
with a vision of further enhancements to better support XR in future NR
releases and outlines open problems in this area."
2801,"Particularly,
                                                                                                                  RAN1 performed a Release 17 study on evaluating NR per-
                                          To better tailor further research on XR to standardized                 formance for the XR [3].","Network (RAN) WG1 (“Physical layer”, RAN1).","The normative work now continues
                                       solutions, this article complements prior tutorials on XR from             in both SA and RAN for Release 18 (ﬁrst 5G-Advanced
                                       mainly the research angle ( [1], [2], among others) by summa-              release, tentatively, until 2023), aiming to provide necessary
                                       rizing and explaining the main ﬁndings from heterogeneous                  enhancements to better support XR services over NR.",2022-03-04 11:17:34+00:00,Standardization of Extended Reality (XR) over 5G and 5G-Advanced 3GPP New Radio,cs.NI,['cs.NI'],"[arxiv.Result.Author('Vitaly Petrov'), arxiv.Result.Author('Margarita Gapeyenko'), arxiv.Result.Author('Stefano Paris'), arxiv.Result.Author('Andrea Marcano'), arxiv.Result.Author('Klaus I. Pedersen')]","Extended Reality (XR) is one of the major innovations to be introduced in
5G/5G-Advanced communication systems. A combination of augmented reality,
virtual reality, and mixed reality, supplemented by cloud gaming, revisits the
way how humans interact with computers, networks, and each other. However,
efficient support of XR services imposes new challenges for existing and future
wireless networks. This article presents a tutorial on integrating support for
the XR into the 3GPP New Radio (NR), summarizing a range of activities handled
within various 3GPP Service and Systems Aspects (SA) and Radio Access Networks
(RAN) groups. The article also delivers a case study evaluating the performance
of different XR services in state-of-the-art NR Release 17. The paper concludes
with a vision of further enhancements to better support XR in future NR
releases and outlines open problems in this area."
3064,"In the future work, based on the work proposed in this paper, we will further study how to
extend the theory of network wave to more general cases, such as the cases including two primary
paths (i.e.","Based on the conclusions obtained in this paper, we can further summarize the advantages of
volatility transmission method as follows: it can maximize the end-to-end asymptotic throughput
of a primary path while maintaining the orderly utilization of network resources as much as
possible.",pair of paths) and any multiple primary paths (i.e.,2022-03-10 08:57:18+00:00,Theory of Network Wave (On a Primary Path),cs.NI,['cs.NI'],"[arxiv.Result.Author('Bo Li'), arxiv.Result.Author('Mao Yang'), arxiv.Result.Author('Zhongjiang Yan')]","Aiming at the disorder problem (i.e. uncertainty problem) of the utilization
of network resources commonly existing in multi-hop transmission networks, the
paper proposes the idea and the corresponding supporting theory, i.e. theory of
network wave, by constructing volatility information transmission mechanism
between the sending nodes of a primary path, so as to improve the orderliness
of the utilization of network resources. It is proved that the maximum
asymptotic throughput of a primary path depends on its intrinsic period, which
in itself is equal to the intrinsic interference intensity of a primary path.
Based on the proposed theory of network wave, an algorithm for the transmission
of information blocks based on the intrinsic period of a primary path is
proposed, which can maximize the asymptotic throughput of the primary path. The
research results of the paper lay an ideological and theoretical foundation for
further exploring more general methods that can improve the orderly utilization
of network resources."
3065,"In the future work, based on the work proposed in this paper, we will further study how to
extend the theory of network wave to more general cases, such as the cases including two primary
paths (i.e.","Based on the conclusions obtained in this paper, we can further summarize the advantages of
volatility transmission method as follows: it can maximize the end-to-end asymptotic throughput
of a primary path while maintaining the orderly utilization of network resources as much as
possible.",pair of paths) and any multiple primary paths (i.e.,2022-03-10 08:57:18+00:00,Theory of Network Wave (On a Primary Path),cs.NI,['cs.NI'],"[arxiv.Result.Author('Bo Li'), arxiv.Result.Author('Mao Yang'), arxiv.Result.Author('Zhongjiang Yan')]","Aiming at the disorder problem (i.e. uncertainty problem) of the utilization
of network resources commonly existing in multi-hop transmission networks, the
paper proposes the idea and the corresponding supporting theory, i.e. theory of
network wave, by constructing volatility information transmission mechanism
between the sending nodes of a primary path, so as to improve the orderliness
of the utilization of network resources. It is proved that the maximum
asymptotic throughput of a primary path depends on its intrinsic period, which
in itself is equal to the intrinsic interference intensity of a primary path.
Based on the proposed theory of network wave, an algorithm for the transmission
of information blocks based on the intrinsic period of a primary path is
proposed, which can maximize the asymptotic throughput of the primary path. The
research results of the paper lay an ideological and theoretical foundation for
further exploring more general methods that can improve the orderly utilization
of network resources."
3066,"In the future work, based on the work proposed in this paper, we will further study how to
extend the theory of network wave to more general cases, such as the cases including two primary
paths (i.e.","Based on the conclusions obtained in this paper, we can further summarize the advantages of
volatility transmission method as: it can maximize the end-to-end asymptotic throughput of a
primary path while maintaining the orderly utilization of network resources as much as
possible.",pair of paths) and any multiple primary paths (i.e.,2022-03-10 08:57:18+00:00,Theory of Network Wave (On a Primary Path),cs.NI,['cs.NI'],"[arxiv.Result.Author('Bo Li'), arxiv.Result.Author('Mao Yang'), arxiv.Result.Author('Zhongjiang Yan')]","Aiming at the disorder problem (i.e. uncertainty problem) of the utilization
of network resources commonly existing in multi-hop transmission networks, the
paper proposes the idea and the corresponding supporting theory, i.e. theory of
network wave, by constructing volatility information transmission mechanism
between the sending nodes of a primary path, so as to improve the orderliness
of the utilization of network resources. It is proved that the maximum
asymptotic throughput of a primary path depends on its intrinsic period, which
in itself is equal to the intrinsic interference intensity of a primary path.
Based on the proposed theory of network wave, an algorithm for the transmission
of information blocks based on the intrinsic period of a primary path is
proposed, which can maximize the asymptotic throughput of the primary path. The
research results of the paper lay an ideological and theoretical foundation for
further exploring more general methods that can improve the orderly utilization
of network resources."
3309,The   6G requires further research.,"for UEs that frequently initiate access requests, TPSSs can        Although the internal security problems of communities can
set a validity period for the security assessment results by at-   be solved using existing methods, their integration with ZTA-
taching a digital signature to the UE’s identity certiﬁcate.","accessed community can verify the digital signature instead of
initiating a new security service request.",2022-03-15 08:13:29+00:00,Zero Trust Architecture for 6G Security,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Xu Chen'), arxiv.Result.Author('Wei Feng'), arxiv.Result.Author('Ning Ge'), arxiv.Result.Author('Yan Zhang')]","The upcoming sixth generation (6G) network is envisioned to be more open and
heterogeneous than earlier generations. This challenges conventional security
architectures, which typically rely on the construction of a security perimeter
at network boundaries. In this article, we propose a software-defined zero
trust architecture (ZTA) for 6G networks, which is promising for establishing
an elastic and scalable security regime. This architecture achieves secure
access control through adaptive collaborations among the involved control
domains, and can effectively prevent malicious access behaviors such as
distributed denial of service (DDoS) attacks, malware spread, and zero-day
exploits. We also introduce key design aspects of this architecture and show
the simulation results of a case study, which shows the effectiveness and
robustness of ZTA for 6G. Furthermore, we discuss open issues to further
promote this new architecture."
3374,"Lastly, we highlight the several research scope and challenges and
list the potential research needs and encourage further research within the thrust area of IoT enabled by 6G
networks.","Next, we present the relevant use cases detailing the discussion on the role of the 6G technology within
a broad spectrum of IoT potential applications.","Keywords: 6G, IoT, wireless communication, AI, ML.",2022-03-16 07:00:57+00:00,Survey on Internet of Things enabled by 6G Wireless Networks,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Rakhee Kallimani'), arxiv.Result.Author('Krishna Pai'), arxiv.Result.Author('Rajashri Khanai'), arxiv.Result.Author('Dattaprasad Torse'), arxiv.Result.Author('Swati Mavinkattimath')]","The 6G wireless technology is visualized to revolutionize multiple customer
services with the Internet of Things (IoT), thereby contributing to a
ubiquitous intelligent society comprising autonomous systems. In this chapter,
we conduct a detailed survey on the IoT networks with 6G wireless networks and
investigate the trending possibilities provided by the 6G technology within the
IoT networks and the related utilization; Firstly, we detail the breakthrough
IoT technologies and the technological drivers which are anticipated to
strengthen IoT networks in future. Next, we present the relevant use cases
detailing the discussion on the role of the 6G technology within a broad
spectrum of IoT potential applications. Lastly, we highlight the several
research scope and challenges and list the potential research needs and
encourage further research within the thrust area of IoT enabled by 6G
networks."
3599,"To foster further research in this area, we discussed the   degree in informatics from University of Ulm, Germany.","degree in informatics from
detailed overview of the 5G-enabled C-ITS security procedures,       Johannes Kepler University (JKU), Linz, Austria, and Ph.D.
to date.","She
drawbacks of existing pseudonyms management approaches and           worked on enhancing vehicle’s autonomy by designing drivers’
complication towards balancing vehicular network privacy-            behavioral predictive models.",2022-03-20 23:10:37+00:00,5G-Enabled Pseudonymity for Cooperative Intelligent Transportation System,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Nardine Basta'), arxiv.Result.Author('Ming Ding'), arxiv.Result.Author('Muhammad Ikram'), arxiv.Result.Author('Mohamed Ali Kaafar')]","Cooperative Intelligent Transportation Systems (C-ITS) enable communications
between vehicles, road-side infrastructures, and road-users to improve users'
safety and to efficiently manage traffic. Most, if not all, of the intelligent
vehicles-to-everything (V2X) applications, often rely on continuous collection
and sharing of sensitive information such as detailed location information
which raises privacy concerns. In this light, a common approach to concealing
the long-term identity of C-ITS vehicles is using multiple temporary
identifiers, called pseudonyms. However, the legacy pseudonyms management
approach is prone to linking attacks. The introduction of 5G network to V2X
offers enhanced location accuracy, better clock synchronisation, improved
modular service-based architecture, and enhanced security and privacy
preservation controls. Motivated by the above enhancements, we study 5G-enabled
pseudonyms for protecting vehicle identity privacy in C-ITS. We highlight the
gaps in the current standards of pseudonyms management. We further provide
recommendations regarding the pseudonyms management life-cycle."
3723,"Therefore, further research is required to ﬁnd out what can be the other
reasons that aﬀect the performance of a QUIC stream over in-the-wild Internet.","However, there are instances where QUIC-enabled
streams perform poorly, even in a high bandwidth scenario when there is no fall-
back.","Finally, we believe that an analysis over more than 2600 streaming hours

                                                  26
of video data can provide a reliable indication about the root cause of QUIC’s
poor performance, as reported in much of the previous literature.",2022-03-22 18:16:24+00:00,YouTube over Google's QUIC vs Internet Middleboxes: A Tug of War between Protocol Sustainability and Application QoE,cs.NI,"['cs.NI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Sapna Chaudhary'), arxiv.Result.Author('Prince Sachdeva'), arxiv.Result.Author('Abhijit Mondal'), arxiv.Result.Author('Sandip Chakraborty'), arxiv.Result.Author('Mukulika Maity')]","Middleboxes such as web proxies, firewalls, etc. are widely deployed in
today's network infrastructure. As a result, most protocols need to adapt their
behavior to co-exist. One of the most commonly used transport protocols, QUIC,
adapts to such middleboxes by falling back to TCP, where they block it. In this
paper, we argue that the blind fallback behavior of QUIC, i.e., not
distinguishing between failures caused by middleboxes and that caused by
network congestion, hugely impacts the performance of QUIC. For this, we focus
on YouTube video streaming and conduct a measurement study by utilizing
production endpoints of YouTube by enabling TCP and QUIC at a time. In total,
we collect over 2600 streaming hours of data over various bandwidth patterns,
from 5 different geographical locations and various video genres. To our
surprise, we observe that the legacy setup (TCP) either outperforms or performs
the same as the QUIC-enabled browser for more than 60% of cases. We see that
our observation is consistent across individual QoE parameters, bandwidth
patterns, locations, and videos. Next, we conduct a deep-dive analysis to
discover the root cause behind such behavior. We find a good correlation
(0.3-0.7) between fallback and QoE drop events, i.e., quality drop and
re-buffering or stalling. We further perform Granger causal analysis and find
that fallback Granger causes either quality drop or stalling for 70% of the
QUIC-enabled sessions. We believe our study will help designers revisit the
decision to enable fallback in QUIC and distinguish between the packet drops
caused by middleboxes and network congestion."
3754,"To further study the results of the proposed mechanism
In particular, a sigmoid function is employed in the ﬁrst part
of (5) to describe the inﬂuence of s on the server’s reward.","However, under the function of revelation principle, the
while an unﬁtted reward coefﬁcient can decrease the beneﬁt         incentive compatibility of the proposed mechanism r∗(s) will
of the server, we model it as:                                     enable the device to ﬁnd out that truthful report is exactly the
                                                                   optimal choice, which will be rigorously proved and analyzed
            R(r, s) =           σ    − ρ(r − r0)2,  (5)            in Section IV-D.

                       1 + e−(s−s0)

where σ, ρ > 0 are constant parameters; s0 and r0 are              C. Derivation of Optimal Strategies
respectively the expected values of the data size and reward
coefﬁcient according to the historical and global information.","To    design process, we reveal the optimal strategies of both sides.",2022-02-12 22:12:50+00:00,Solving the Federated Edge Learning Participation Dilemma: A Truthful and Correlated Perspective,cs.NI,['cs.NI'],"[arxiv.Result.Author('Qin Hu'), arxiv.Result.Author('Feng Li'), arxiv.Result.Author('Xukai Zou'), arxiv.Result.Author('Yinhao Xiao')]","An emerging computational paradigm, named federated edge learning (FEL),
enables intelligent computing at the network edge with the feature of
preserving data privacy for edge devices. Given their constrained resources, it
becomes a great challenge to achieve high execution performance for FEL. Most
of the state-of-the-arts concentrate on enhancing FEL from the perspective of
system operation procedures, taking few precautions during the composition step
of the FEL system. Though a few recent studies recognize the importance of FEL
formation and propose server-centric device selection schemes, the impact of
data sizes is largely overlooked. In this paper, we take advantage of game
theory to depict the decision dilemma among edge devices regarding whether to
participate in FEL or not given their heterogeneous sizes of local datasets.
For realizing both the individual and global optimization, the server is
employed to solve the participation dilemma, which requires accurate
information collection for devices' local datasets. Hence, we utilize mechanism
design to enable truthful information solicitation. With the help of correlated
equilibrium, we derive a decision making strategy for devices from the global
perspective, which can achieve the long-term stability and efficacy of FEL. For
scalability consideration, we optimize the computational complexity of the
basic solution to the polynomial level. Lastly, extensive experiments based on
both real and synthetic data are conducted to evaluate our proposed mechanisms,
with experimental results demonstrating the performance advantages."
3838,"2013 Regulations and standards                                     [20]

      Resilience, ad-hoc networks’ deployment, routing             [27]

2016

      LMR-LTE convergence, push-to-talk over LTE                   [21]

      Hybrid satellite-aerial-terrestrial networks                 [18]

2017

      Mobile social networks (MSNs), D2D, data dissemination       [15]

      MANETs, VANETs, DTN                                          [24]

      D2D, DWN                                                     [26]

2018 Network-in-a-box                                              [28]

      AI, big data analysis and processing                         [14]

      Wireless technologies for disaster recovery and healthcare   [33]

      Indoor and outdoor non-image-based people counting technologies [17]

2019

      LMR, LTE                                                     [22]

      Autonomous decision-making systems, NFV, SDNs                [23]

2020

      UAV-assisted VANETs, routing protocols                       [32]

      Wireless technologies for resilient networks                 [29]

      Mobility models, MANETs                                      [25]

      Fog computing, disaster evacuation                           [16]

2021

      UAV path planning, network security                          [19]

      IoT-enabled ﬂood SAR systems                                 [30]

      Data-plane recovery mechanisms for packet-switched networks  [31]

2022 Paradigms, physical and networking layers, challenges         This paper

   3) Given the numerous aspects deserving further researchers’ attention, we discuss inherent
       challenges and present what we believe are the most exciting directions for future works
       in the area of post-disaster wireless communications.","In particular, we extensively discuss
       the most relevant research efforts done over the last decade to design powerful wireless
       technologies for PDCs and try to solve recurrent physical and networking layer problems;

   2) We also present stochastic-geometry-based simulation results for two realistic post-disaster
       network setups, and consequently discuss how to achieve efﬁcient network planning in such
       scenarios;
                                                                               7

                                        TABLE I
                       RELEVANT SURVEYS AND REVIEWS

Year Main focus                                                    Ref.","We speciﬁcally discuss relevant
       topics such as modulation and coding, backhauling, placement, trajectory and scheduling
       of movable nodes, handover management, and content caching.",2022-03-25 12:41:53+00:00,"Post-Disaster Communications: Enabling Technologies, Architectures, and Open Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Maurilio Matracia'), arxiv.Result.Author('Nasir Saeed'), arxiv.Result.Author('Mustafa A. Kishk'), arxiv.Result.Author('Mohamed-Slim Alouini')]","The number of disasters has increased over the past decade where these
calamities significantly affect the functionality of communication networks. In
the context of 6G, airborne and spaceborne networks offer hope in disaster
recovery to serve the underserved and to be resilient in calamities. Therefore,
this paper surveys the state-of-the-art literature on post-disaster wireless
communication networks and provides insights for the future establishment of
such networks. In particular, we first give an overview of the works
investigating the general procedures and strategies for counteracting any
large-scale disasters. Then, we present the possible technological solutions
for post-disaster communications, such as the recovery of the terrestrial
infrastructure, installing aerial networks, and using spaceborne networks.
Afterward, we shed light on the technological aspects of post-disaster
networks, primarily the physical and networking issues. We present the
literature on channel modeling, coverage and capacity, radio resource
management, localization, and energy efficiency in the physical layer and
discuss the integrated space-air-ground architectures, routing,
delay-tolerant/software-defined networks, and edge computing in the networking
layer. This paper also presents interesting simulation results which can
provide practical guidelines about the deployment of ad hoc network
architectures in emergency scenarios. Finally, we present several promising
research directions, namely backhauling, placement optimization of aerial base
stations, and the mobility-related aspects that come into play when deploying
aerial networks, such as planning their trajectories and the consequent
handovers."
3839,"In particular, we extensively discuss
                                                                                                                                                                                9

       the most relevant research efforts done over the last decade to design powerful wireless
       technologies for PDCs and try to solve recurrent physical and networking layer problems;
   2) We present our stochastic-geometry-based simulation results for two realistic post-disaster
       network setups, and consequently discuss how to achieve efﬁcient network planning in
       such scenarios;
   3) Given the numerous aspects deserving further researchers’ attention, we discuss inherent
       challenges and present what we believe are the most promising directions for future
       research in the area of post-disaster wireless communications.","We can thus summarize our contributions as follows:

   1) We provide an up-to-date review of PDCs to project the reader in the perspective of the 5G
       and beyond generation of wireless communications.","In particular, our interest is
       focused on: modulation and coding, backhauling, placement, trajectory and scheduling of
       movable nodes, HO management, and content caching.",2022-03-25 12:41:53+00:00,"Post-Disaster Communications: Enabling Technologies, Architectures, and Open Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Maurilio Matracia'), arxiv.Result.Author('Nasir Saeed'), arxiv.Result.Author('Mustafa A. Kishk'), arxiv.Result.Author('Mohamed-Slim Alouini')]","The number of disasters has increased over the past decade where these
calamities significantly affect the functionality of communication networks. In
the context of 6G, airborne and spaceborne networks offer hope in disaster
recovery to serve the underserved and to be resilient in calamities. Therefore,
this paper surveys the state-of-the-art literature on post-disaster wireless
communication networks and provides insights for the future establishment of
such networks. In particular, we first give an overview of the works
investigating the general procedures and strategies for counteracting any
large-scale disasters. Then, we present the possible technological solutions
for post-disaster communications, such as the recovery of the terrestrial
infrastructure, installing aerial networks, and using spaceborne networks.
Afterward, we shed light on the technological aspects of post-disaster
networks, primarily the physical and networking issues. We present the
literature on channel modeling, coverage and capacity, radio resource
management, localization, and energy efficiency in the physical layer and
discuss the integrated space-air-ground architectures, routing,
delay-tolerant/software-defined networks, and edge computing in the networking
layer. This paper also presents interesting simulation results which can
provide practical guidelines about the deployment of ad hoc network
architectures in emergency scenarios. Finally, we present several promising
research directions, namely backhauling, placement optimization of aerial base
stations, and the mobility-related aspects that come into play when deploying
aerial networks, such as planning their trajectories and the consequent
handovers."
4241,"Of course, further research will be required
to make this a reality.”

    The second chapter indicates that ”Beyond merely breaking down a higher layer of abstraction
(intent) into a lower layer of abstraction (policies, device conﬁguration), Intent Translation functions
can be complemented with functions and algorithms that perform optimizations and that are able to
learn and improve over time in order to result in the best outcomes, speciﬁcally in cases where multiple
ways of achieving those outcomes are conceivable.”

    Looking at the way to answer to those two chapters, we study the way to apply Artiﬁcial Intelligence
to Intent-Based Networking.","Ideally, it will be the Intent-Based Systems that is increasingly be able to learn how to
understand the user as opposed to the other way round.","We will continue to develop the concepts described is this paper in
Python to ﬁnalize our Proof of Concept.",2022-04-02 08:12:08+00:00,Introduction to the Artificial Intelligence that can be applied to the Network Automation Journey,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Gilbert Moisio'), arxiv.Result.Author('Alexandre Gonzalvez'), arxiv.Result.Author('Noam Zeitoun')]","The computer network world is changing and the NetDevOps approach has brought
the dynamics of applications and systems into the field of communication
infrastructure. Businesses are changing and businesses are faced with
difficulties related to the diversity of hardware and software that make up
those infrastructures. The ""Intent-Based Networking - Concepts and Definitions""
document describes the different parts of the ecosystem that could be involved
in NetDevOps. The recognize, generate intent, translate and refine features
need a new way to implement algorithms. This is where artificial intelligence
comes in."
4350,"This has led to
a high entry barrier, hindering further research in this area.","Moreover, given how scattered the literature
is, it is difﬁcult to even identify all steps/functions necessary to
build a basic system for WiFi-based sensing.","There has been no effort to integrate these tools or to build
a general software framework that can serve as the basis for
further research, e.g., on using machine learning to interpret
the altered WiFi signals.",2022-04-04 20:31:16+00:00,WifiEye -- Seeing over WiFi Made Accessible,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Philipp H. Kindt'), arxiv.Result.Author('Cristian Turetta'), arxiv.Result.Author('Florenc Demrozi'), arxiv.Result.Author('Alejandro Masrur'), arxiv.Result.Author('Graziano Pravadelli'), arxiv.Result.Author('Samarjit Chakraborty')]","While commonly used for communication purposes, an increasing number of
recent studies consider WiFi for sensing. In particular, wireless signals are
altered (e.g., reflected and attenuated) by the human body and objects in the
environment. This can be perceived by an observer to infer information on human
activities or changes in the environment and, hence, to ""see"" over WiFi. Until
now, works on WiFi-based sensing have resulted in a set of custom software
tools -- each designed for a specific purpose. Moreover, given how scattered
the literature is, it is difficult to even identify all steps/functions
necessary to build a basic system for WiFi-based sensing. This has led to a
high entry barrier, hindering further research in this area. There has been no
effort to integrate these tools or to build a general software framework that
can serve as the basis for further research, e.g., on using machine learning to
interpret the altered WiFi signals. To address this issue, in this paper, we
propose WiFiEye -- a generic software framework that makes all necessary
steps/functions available ""out of the box"". This way, WiFiEye allows
researchers to easily bootstrap new WiFi-based sensing applications, thereby,
focusing on research rather than on implementation aspects. To illustrate
WiFiEye's workflow, we present a case study on WiFi-based human activity
recognition."
4351,"There has been no effort to integrate these tools or to build
a general software framework that can serve as the basis for
further research, e.g., on using machine learning to interpret
the altered WiFi signals.","This has led to
a high entry barrier, hindering further research in this area.","To address this issue, in this paper, we
propose WiFiEye – a generic software framework that makes all
necessary steps/functions available “out of the box”.",2022-04-04 20:31:16+00:00,WifiEye -- Seeing over WiFi Made Accessible,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Philipp H. Kindt'), arxiv.Result.Author('Cristian Turetta'), arxiv.Result.Author('Florenc Demrozi'), arxiv.Result.Author('Alejandro Masrur'), arxiv.Result.Author('Graziano Pravadelli'), arxiv.Result.Author('Samarjit Chakraborty')]","While commonly used for communication purposes, an increasing number of
recent studies consider WiFi for sensing. In particular, wireless signals are
altered (e.g., reflected and attenuated) by the human body and objects in the
environment. This can be perceived by an observer to infer information on human
activities or changes in the environment and, hence, to ""see"" over WiFi. Until
now, works on WiFi-based sensing have resulted in a set of custom software
tools -- each designed for a specific purpose. Moreover, given how scattered
the literature is, it is difficult to even identify all steps/functions
necessary to build a basic system for WiFi-based sensing. This has led to a
high entry barrier, hindering further research in this area. There has been no
effort to integrate these tools or to build a general software framework that
can serve as the basis for further research, e.g., on using machine learning to
interpret the altered WiFi signals. To address this issue, in this paper, we
propose WiFiEye -- a generic software framework that makes all necessary
steps/functions available ""out of the box"". This way, WiFiEye allows
researchers to easily bootstrap new WiFi-based sensing applications, thereby,
focusing on research rather than on implementation aspects. To illustrate
WiFiEye's workflow, we present a case study on WiFi-based human activity
recognition."
4352,"This has led to
a high entry barrier, hindering further research in this area.","Moreover, given how scattered the literature
is, it is difﬁcult to even identify all steps/functions necessary to
build a basic system for WiFi-based sensing.","There has been no effort to integrate these tools or to build
a general software framework that can serve as the basis for
further research, e.g., on using machine learning to interpret
the altered WiFi signals.",2022-04-04 20:31:16+00:00,WiFiEye -- Seeing over WiFi Made Accessible,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Philipp H. Kindt'), arxiv.Result.Author('Cristian Turetta'), arxiv.Result.Author('Florenc Demrozi'), arxiv.Result.Author('Alejandro Masrur'), arxiv.Result.Author('Graziano Pravadelli'), arxiv.Result.Author('Samarjit Chakraborty')]","While commonly used for communication purposes, an increasing number of
recent studies consider WiFi for sensing. In particular, wireless signals are
altered (e.g., reflected and attenuated) by the human body and objects in the
environment. This can be perceived by an observer to infer information on human
activities or changes in the environment and, hence, to ""see"" over WiFi. Until
now, works on WiFi-based sensing have resulted in a set of custom software
tools - each designed for a specific purpose. Moreover, given how scattered the
literature is, it is difficult to even identify all steps/functions necessary
to build a basic system for WiFi-based sensing. This has led to a high entry
barrier, hindering further research in this area. There has been no effort to
integrate these tools or to build a general software framework that can serve
as the basis for further research, e.g., on using machine learning to interpret
the altered WiFi signals. To address this issue, in this paper, we propose
WiFiEye - a generic software framework that makes all necessary steps/functions
available ""out of the box"". This way, WiFiEye allows researchers to easily
bootstrap new WiFi-based sensing applications, thereby, focusing on research
rather than on implementation aspects. To illustrate WiFiEye's workflow, we
present a case study on WiFi-based human activity recognition."
4353,"There has been no effort to integrate these tools or to build
a general software framework that can serve as the basis for
further research, e.g., on using machine learning to interpret
the altered WiFi signals.","This has led to
a high entry barrier, hindering further research in this area.","To address this issue, in this paper, we
propose WiFiEye – a generic software framework that makes all
necessary steps/functions available “out of the box”.",2022-04-04 20:31:16+00:00,WiFiEye -- Seeing over WiFi Made Accessible,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Philipp H. Kindt'), arxiv.Result.Author('Cristian Turetta'), arxiv.Result.Author('Florenc Demrozi'), arxiv.Result.Author('Alejandro Masrur'), arxiv.Result.Author('Graziano Pravadelli'), arxiv.Result.Author('Samarjit Chakraborty')]","While commonly used for communication purposes, an increasing number of
recent studies consider WiFi for sensing. In particular, wireless signals are
altered (e.g., reflected and attenuated) by the human body and objects in the
environment. This can be perceived by an observer to infer information on human
activities or changes in the environment and, hence, to ""see"" over WiFi. Until
now, works on WiFi-based sensing have resulted in a set of custom software
tools - each designed for a specific purpose. Moreover, given how scattered the
literature is, it is difficult to even identify all steps/functions necessary
to build a basic system for WiFi-based sensing. This has led to a high entry
barrier, hindering further research in this area. There has been no effort to
integrate these tools or to build a general software framework that can serve
as the basis for further research, e.g., on using machine learning to interpret
the altered WiFi signals. To address this issue, in this paper, we propose
WiFiEye - a generic software framework that makes all necessary steps/functions
available ""out of the box"". This way, WiFiEye allows researchers to easily
bootstrap new WiFi-based sensing applications, thereby, focusing on research
rather than on implementation aspects. To illustrate WiFiEye's workflow, we
present a case study on WiFi-based human activity recognition."
4375,"Adversaries may attack aerial communication chan-           stage and there are many unexplored issues, we believe that
nels and deploy data breaches in the ﬂying BSs on the               this paper has revealed certain important lessons and key ideas
HAC platform, as the management of lower altitude-based             that will drive further research and unlock the full potential of
servers is limited owing to the physical distance [165].","As
critical issues related to security, privacy, and trust must be     the development of aerial computing is still in a preliminary
solved.",AI         a comprehensive 6G computing infrastructure in the future.,2022-04-05 06:09:04+00:00,"Aerial Computing: A New Computing Paradigm, Applications, and Challenges",cs.NI,"['cs.NI', 'cs.DC']","[arxiv.Result.Author('Quoc-Viet Pham'), arxiv.Result.Author('Rukhsana Ruby'), arxiv.Result.Author('Fang Fang'), arxiv.Result.Author('Dinh C. Nguyen'), arxiv.Result.Author('Zhaohui Yang'), arxiv.Result.Author('Mai Le'), arxiv.Result.Author('Zhiguo Ding'), arxiv.Result.Author('Won-Joo Hwang')]","In existing computing systems, such as edge computing and cloud computing,
several emerging applications and practical scenarios are mostly unavailable or
only partially implemented. To overcome the limitations that restrict such
applications, the development of a comprehensive computing paradigm has
garnered attention in both academia and industry. However, a gap exists in the
literature owing to the scarce research, and a comprehensive computing paradigm
is yet to be systematically designed and reviewed. This study introduces a
novel concept, called aerial computing, via the amalgamation of aerial radio
access networks and edge computing, which attempts to bridge the gap.
Specifically, first, we propose a novel comprehensive computing architecture
that is composed of low-altitude computing, high-altitude computing, and
satellite computing platforms, along with conventional computing systems. We
determine that aerial computing offers several desirable attributes: global
computing service, better mobility, higher scalability and availability, and
simultaneity. Second, we comprehensively discuss key technologies that
facilitate aerial computing, including energy refilling, edge computing,
network softwarization, frequency spectrum, multi-access techniques, artificial
intelligence, and big data. In addition, we discuss vertical domain
applications (e.g., smart cities, smart vehicles, smart factories, and smart
grids) supported by aerial computing. Finally, we highlight several challenges
that need to be addressed and their possible solutions."
4435,"We further study the
buffer requirements (§3.3) and highlight that the topologies introduce a fundamental tradeoff
between throughput, delay and buffer.","Specifically, we analytically derive
the throughput of periodic RDCNs (§3.1) and its relation to delay (§3.2).","We then present remarks and practical implications of
our results (§3.4).",2022-04-06 00:32:58+00:00,Mars: Near-Optimal Throughput with Shallow Buffers in Reconfigurable Datacenter Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Vamsi Addanki'), arxiv.Result.Author('Chen Avin'), arxiv.Result.Author('Stefan Schmid')]","The performance of large-scale computing systems often critically depends on
high-performance communication networks. Dynamically reconfigurable topologies,
e.g., based on optical circuit switches, are emerging as an innovative new
technology to deal with the explosive growth of datacenter traffic.
Specifically, \emph{periodic} reconfigurable datacenter networks (RDCNs) such
as RotorNet (SIGCOMM 2017), Opera (NSDI 2020) and Sirius (SIGCOMM 2020) have
been shown to provide high throughput, by emulating a \emph{complete graph}
through fast periodic circuit switch scheduling.
  However, to achieve such a high throughput, existing reconfigurable network
designs pay a high price: in terms of potentially high delays, but also, as we
show as a first contribution in this paper, in terms of the high buffer
requirements. In particular, we show that under buffer constraints, emulating
the high-throughput complete graph is infeasible at scale, and we uncover a
spectrum of unvisited and attractive alternative RDCNs, which emulate regular
graphs, but with lower node degree than the complete graph.
  We present Mars, a periodic reconfigurable topology which emulates a
$d$-regular graph with near-optimal throughput. In particular, we
systematically analyze how the degree~$d$ can be optimized for throughput given
the available buffer and delay tolerance of the datacenter. We further show
empirically that Mars achieves higher throughput compared to existing systems
when buffer sizes are bounded."
4527,"Hopefully, this                This paper intends to provide a comprehensive picture
                                        work will inspire further research to evolve existing WiFi/4G/5G             of this emerging ﬁeld by presenting the CSI measurement
                                        networks into next-generation intelligent wireless network (i.e.,            mechanisms of WiFi/4G/5G wireless networks, identifying the
                                        6G).","that hinder real deployment of ISAC applications, and provide
                                        possible solutions to those critical challenges.","major practical and theoretical problems that hinder the real
                                                                                                                     deployment of ISAC applications, and providing the effective
                                           Index Terms—CSI-based Sensing, ISAC, WiFi/5G sensing                      or possible solutions to those critical challenges in the con-
                                                                                                                     text of WiFi/4G/5G wireless networks.",2022-03-18 02:22:54+00:00,Practical Issues and Challenges in CSI-based Integrated Sensing and Communication,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Daqing Zhang'), arxiv.Result.Author('Dan Wu'), arxiv.Result.Author('Kai Niu'), arxiv.Result.Author('Xuanzhi Wang'), arxiv.Result.Author('Fusang Zhang'), arxiv.Result.Author('Jian Yao'), arxiv.Result.Author('Dajie Jiang'), arxiv.Result.Author('Fei Qin')]","Next-generation mobile communication network (i.e., 6G) has been envisioned
to go beyond classical communication functionality and provide integrated
sensing and communication (ISAC) capability to enable more emerging
applications, such as smart cities, connected vehicles, AIoT and health
care/elder care. Among all the ISAC proposals, the most practical and promising
approach is to empower existing wireless network (e.g., WiFi, 4G/5G) with the
augmented ability to sense the surrounding human and environment, and evolve
wireless communication networks into intelligent communication and sensing
network (e.g., 6G). In this paper, based on our experience on CSI-based
wireless sensing with WiFi/4G/5G signals, we intend to identify ten major
practical and theoretical problems that hinder real deployment of ISAC
applications, and provide possible solutions to those critical challenges.
Hopefully, this work will inspire further research to evolve existing
WiFi/4G/5G networks into next-generation intelligent wireless network (i.e.,
6G)."
4528,"INTRODUCTION                                    will inspire further research to evolve existing WiFi/4G/5G
                                                                                                                     networks into intelligent communication and sensing net-
                                           Next-generation mobile communication network (i.e., 6G)                   works (e.g., B5G and 6G).","Hopefully, this work
                                                                  I.","has been envisioned to go beyond classical communication
                                        functionality and provide integrated sensing and communica-                                  II.",2022-03-18 02:22:54+00:00,Practical Issues and Challenges in CSI-based Integrated Sensing and Communication,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Daqing Zhang'), arxiv.Result.Author('Dan Wu'), arxiv.Result.Author('Kai Niu'), arxiv.Result.Author('Xuanzhi Wang'), arxiv.Result.Author('Fusang Zhang'), arxiv.Result.Author('Jian Yao'), arxiv.Result.Author('Dajie Jiang'), arxiv.Result.Author('Fei Qin')]","Next-generation mobile communication network (i.e., 6G) has been envisioned
to go beyond classical communication functionality and provide integrated
sensing and communication (ISAC) capability to enable more emerging
applications, such as smart cities, connected vehicles, AIoT and health
care/elder care. Among all the ISAC proposals, the most practical and promising
approach is to empower existing wireless network (e.g., WiFi, 4G/5G) with the
augmented ability to sense the surrounding human and environment, and evolve
wireless communication networks into intelligent communication and sensing
network (e.g., 6G). In this paper, based on our experience on CSI-based
wireless sensing with WiFi/4G/5G signals, we intend to identify ten major
practical and theoretical problems that hinder real deployment of ISAC
applications, and provide possible solutions to those critical challenges.
Hopefully, this work will inspire further research to evolve existing
WiFi/4G/5G networks into next-generation intelligent wireless network (i.e.,
6G)."
4529,"Together with the        further research to evolve existing WiFi/4G/5G networks into
dynamic vector change model [20], the Fresnel Zone model           next-generation wireless networks (e.g., B5G and 6G).","Hopefully, this work will inspire
respiration can be detected are clariﬁed.","REFERENCES                                           [19] K. Ali, A. X. Liu, W. Wang, and M. Shahzad, “Keystroke recognition
                                                                                        using WiFi signals,” in Proceedings of the 21st Annual International
 [1] F. Liu, Y. Cui, C. Masouros, J. Xu, T. X. Han, Y. C. Eldar, and S. Buzzi,          Conference on Mobile Computing and Networking, ser.",2022-03-18 02:22:54+00:00,Practical Issues and Challenges in CSI-based Integrated Sensing and Communication,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Daqing Zhang'), arxiv.Result.Author('Dan Wu'), arxiv.Result.Author('Kai Niu'), arxiv.Result.Author('Xuanzhi Wang'), arxiv.Result.Author('Fusang Zhang'), arxiv.Result.Author('Jian Yao'), arxiv.Result.Author('Dajie Jiang'), arxiv.Result.Author('Fei Qin')]","Next-generation mobile communication network (i.e., 6G) has been envisioned
to go beyond classical communication functionality and provide integrated
sensing and communication (ISAC) capability to enable more emerging
applications, such as smart cities, connected vehicles, AIoT and health
care/elder care. Among all the ISAC proposals, the most practical and promising
approach is to empower existing wireless network (e.g., WiFi, 4G/5G) with the
augmented ability to sense the surrounding human and environment, and evolve
wireless communication networks into intelligent communication and sensing
network (e.g., 6G). In this paper, based on our experience on CSI-based
wireless sensing with WiFi/4G/5G signals, we intend to identify ten major
practical and theoretical problems that hinder real deployment of ISAC
applications, and provide possible solutions to those critical challenges.
Hopefully, this work will inspire further research to evolve existing
WiFi/4G/5G networks into next-generation intelligent wireless network (i.e.,
6G)."
4542,"The dataset is made publicly available
discovered that the strongest RSS value measured from the                                      to encourage further research.","Most surprisingly, we                                     testing samples.",nearest beacon is the one that suffers the most variation.,2022-04-07 20:30:43+00:00,A Kernel Method to Nonlinear Location Estimation with RSS-based Fingerprint,cs.NI,"['cs.NI', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Pai Chet Ng'), arxiv.Result.Author('Petros Spachos'), arxiv.Result.Author('James She'), arxiv.Result.Author('Konstantinos N. Plataniotis')]","This paper presents a nonlinear location estimation to infer the position of
a user holding a smartphone. We consider a large location with $M$ number of
grid points, each grid point is labeled with a unique fingerprint consisting of
the received signal strength (RSS) values measured from $N$ number of Bluetooth
Low Energy (BLE) beacons. Given the fingerprint observed by the smartphone, the
user's current location can be estimated by finding the top-k similar
fingerprints from the list of fingerprints registered in the database. Besides
the environmental factors, the dynamicity in holding the smartphone is another
source to the variation in fingerprint measurements, yet there are not many
studies addressing the fingerprint variability due to dynamic smartphone
positions held by human hands during online detection. To this end, we propose
a nonlinear location estimation using the kernel method. Specifically, our
proposed method comprises of two steps: 1) a beacon selection strategy to
select a subset of beacons that is insensitive to the subtle change of holding
positions, and 2) a kernel method to compute the similarity between this subset
of observed signals and all the fingerprints registered in the database. The
experimental results based on large-scale data collected in a complex building
indicate a substantial performance gain of our proposed approach in comparison
to state-of-the-art methods. The dataset consisting of the signal information
collected from the beacons is available online."
4967,"Topics in Comput., to be published, doi:
in its infancy and demands further research.",on Emerg.,10.1109/TETC.2021.3090061.,2022-04-18 05:44:44+00:00,Actions at the Edge: Jointly Optimizing the Resources in Multi-access Edge Computing,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Yiqin Deng'), arxiv.Result.Author('Xianhao Chen'), arxiv.Result.Author('Guangyu Zhu'), arxiv.Result.Author('Yuguang Fang'), arxiv.Result.Author('Zhigang Chen'), arxiv.Result.Author('Xiaoheng Deng')]","Multi-access edge computing (MEC) is an emerging paradigm that pushes
resources for sensing, communications, computing, storage and intelligence
(SCCSI) to the premises closer to the end users, i.e., the edge, so that they
could leverage the nearby rich resources to improve their quality of experience
(QoE). Due to the growing emerging applications targeting at intelligentizing
life-sustaining cyber-physical systems, this paradigm has become a hot research
topic, particularly when MEC is utilized to provide edge intelligence and
real-time processing and control. This article is to elaborate the research
issues along this line, including basic concepts and performance metrics,
killer applications, architectural design, modeling approaches and solutions,
and future research directions. It is hoped that this article provides a quick
introduction to this fruitful research area particularly for beginning
researchers."
5382,"The importance     trivial but yet to further research, passive side channel, active
here is that in their experiments conducted in [64], the NDPS     side channel, compromise of the function, and end device
model has surpassed the DRL model in performance.","Among the security threats that are non-
tion learning inspired technique [162], [163].",vulnerabilities can be seen as prominent.,2022-04-27 10:26:24+00:00,"A Survey on XAI for Beyond 5G Security: Technical Aspects, Use Cases, Challenges and Research Directions",cs.NI,"['cs.NI', 'cs.AI', 'cs.CR']","[arxiv.Result.Author('Thulitha Senevirathna'), arxiv.Result.Author('Zujany Salazar'), arxiv.Result.Author('Vinh Hoa La'), arxiv.Result.Author('Samuel Marchal'), arxiv.Result.Author('Bartlomiej Siniarski'), arxiv.Result.Author('Madhusanka Liyanage'), arxiv.Result.Author('Shen Wang')]","With the advent of 5G commercialization, the need for more reliable, faster,
and intelligent telecommunication systems are envisaged for the next generation
beyond 5G (B5G) radio access technologies. Artificial Intelligence (AI) and
Machine Learning (ML) are not just immensely popular in the service layer
applications but also have been proposed as essential enablers in many aspects
of B5G networks, from IoT devices and edge computing to cloud-based
infrastructures. However, most of the existing surveys in B5G security focus on
the performance of AI/ML models and their accuracy, but they often overlook the
accountability and trustworthiness of the models' decisions. Explainable AI
(XAI) methods are promising techniques that would allow system developers to
identify the internal workings of AI/ML black-box models. The goal of using XAI
in the security domain of B5G is to allow the decision-making processes of the
security of systems to be transparent and comprehensible to stakeholders making
the systems accountable for automated actions. In every facet of the
forthcoming B5G era, including B5G technologies such as RAN, zero-touch network
management, E2E slicing, this survey emphasizes the role of XAI in them and the
use cases that the general users would ultimately enjoy. Furthermore, we
presented the lessons learned from recent efforts and future research
directions on top of the currently conducted projects involving XAI."
5383,"XAI methods must be further researched, and defenses must
                                                                         be developed to make XAI secure.","Attacks against
to compromise the whole ML-based system.","While the security of XAI
   2) Impact on B5G: This threat exists for every ML ap-                 has not reached sufﬁcient maturity, the explanation should only
plication to B5G where explanation weighs equally or more                be used as additional information rather than directly used in
than the prediction in the action it triggers.",2022-04-27 10:26:24+00:00,"A Survey on XAI for Beyond 5G Security: Technical Aspects, Use Cases, Challenges and Research Directions",cs.NI,"['cs.NI', 'cs.AI', 'cs.CR']","[arxiv.Result.Author('Thulitha Senevirathna'), arxiv.Result.Author('Zujany Salazar'), arxiv.Result.Author('Vinh Hoa La'), arxiv.Result.Author('Samuel Marchal'), arxiv.Result.Author('Bartlomiej Siniarski'), arxiv.Result.Author('Madhusanka Liyanage'), arxiv.Result.Author('Shen Wang')]","With the advent of 5G commercialization, the need for more reliable, faster,
and intelligent telecommunication systems are envisaged for the next generation
beyond 5G (B5G) radio access technologies. Artificial Intelligence (AI) and
Machine Learning (ML) are not just immensely popular in the service layer
applications but also have been proposed as essential enablers in many aspects
of B5G networks, from IoT devices and edge computing to cloud-based
infrastructures. However, most of the existing surveys in B5G security focus on
the performance of AI/ML models and their accuracy, but they often overlook the
accountability and trustworthiness of the models' decisions. Explainable AI
(XAI) methods are promising techniques that would allow system developers to
identify the internal workings of AI/ML black-box models. The goal of using XAI
in the security domain of B5G is to allow the decision-making processes of the
security of systems to be transparent and comprehensible to stakeholders making
the systems accountable for automated actions. In every facet of the
forthcoming B5G era, including B5G technologies such as RAN, zero-touch network
management, E2E slicing, this survey emphasizes the role of XAI in them and the
use cases that the general users would ultimately enjoy. Furthermore, we
presented the lessons learned from recent efforts and future research
directions on top of the currently conducted projects involving XAI."
5466,"Whether the algorithm is the most
eﬃcient in comparison with other algorithms, perhaps even optimal, deserves
further research.","The simulative results demonstrate that
the generic Dijkstra algorithm is eﬃcient.","10 Acknowledgment

We dedicate this work to Alexander Stepanov for his decades-long inspiration,
and his contributions to generic programming and C++.",2022-04-28 14:56:30+00:00,Generic Dijkstra: correctness and tractability,cs.NI,"['cs.NI', 'cs.DS']","[arxiv.Result.Author('Ireneusz Szcześniak'), arxiv.Result.Author('Bożena Woźna-Szcześniak')]","The recently-proposed generic Dijkstra algorithm finds shortest paths in
networks with continuous and contiguous resources. The algorithm was proposed
in the context of optical networks, but is applicable to networks with finite
and discrete resources. The algorithm was published without a proof of
correctness, and with a minor shortcoming. We provide that missing proof and
offer a correction to the shortcoming. To prove the algorithm correct, we
generalize the Bellman's principle of optimality to algebraic structures with a
partial ordering. We also argue the stated problem is tractable by analyzing
the size of the search space in the worst-case."
5624,"We further study the failure rates for
the differences between DoUDP and DoTCP are marginal for the            the largest 10 ASes (based on number of RA probes), i.e., we group
resolvers showing low DoTCP failure rates, with the differences         the samples by resolver and AS before calculating the failure rates.","Overall,       By Autonomous System.",being around zero percentage points.,2022-05-02 08:51:33+00:00,Measuring DNS over TCP in the Era of Increasing DNS Response Sizes: A View from the Edge,cs.NI,['cs.NI'],"[arxiv.Result.Author('Mike Kosek'), arxiv.Result.Author('Trinh Viet Doan'), arxiv.Result.Author('Simon Huber'), arxiv.Result.Author('Vaibhav Bajpai')]","The Domain Name System (DNS) is one of the most crucial parts of the
Internet. Although the original standard defined the usage of DNS over UDP
(DoUDP) as well as DNS over TCP (DoTCP), UDP has become the predominant
protocol used in the DNS. With the introduction of new Resource Records (RRs),
the sizes of DNS responses have increased considerably. Since this can lead to
truncation or IP fragmentation, the fallback to DoTCP as required by the
standard ensures successful DNS responses by overcoming the size limitations of
DoUDP. However, the effects of the usage of DoTCP by stub resolvers are not
extensively studied to this date. We close this gap by presenting a view at
DoTCP from the Edge, issuing 12.1M DNS requests from 2,500 probes toward Public
as well as Probe DNS recursive resolvers. In our measurement study, we observe
that DoTCP is generally slower than DoUDP, where the relative increase in
Response Time is less than 37% for most resolvers. While optimizations to DoTCP
can be leveraged to further reduce the response times, we show that support on
Public resolvers is still missing, hence leaving room for optimizations in the
future. Moreover, we also find that Public resolvers generally have comparable
reliability for DoTCP and DoUDP. However, Probe resolvers show a significantly
different behavior: DoTCP queries targeting Probe resolvers fail in 3 out of 4
cases, and, therefore, do not comply with the standard. This problem will only
aggravate in the future: As DNS response sizes will continue to grow, the need
for DoTCP will solidify."
5625,"We further study the failure rates for
the differences between DoUDP and DoTCP are marginal for the            the largest 10 ASes (based on number of RA probes), i.e., we group
resolvers showing low DoTCP failure rates, with the differences         the samples by resolver and AS before calculating the failure rates.","Overall,       By Autonomous System.",being around zero percentage points.,2022-05-02 08:51:33+00:00,Measuring DNS over TCP in the Era of Increasing DNS Response Sizes: A View from the Edge,cs.NI,['cs.NI'],"[arxiv.Result.Author('Mike Kosek'), arxiv.Result.Author('Trinh Viet Doan'), arxiv.Result.Author('Simon Huber'), arxiv.Result.Author('Vaibhav Bajpai')]","The Domain Name System (DNS) is one of the most crucial parts of the
Internet. Although the original standard defined the usage of DNS over UDP
(DoUDP) as well as DNS over TCP (DoTCP), UDP has become the predominant
protocol used in the DNS. With the introduction of new Resource Records (RRs),
the sizes of DNS responses have increased considerably. Since this can lead to
truncation or IP fragmentation, the fallback to DoTCP as required by the
standard ensures successful DNS responses by overcoming the size limitations of
DoUDP. However, the effects of the usage of DoTCP by stub resolvers are not
extensively studied to this date. We close this gap by presenting a view at
DoTCP from the Edge, issuing 12.1M DNS requests from 2,500 probes toward Public
as well as Probe DNS recursive resolvers. In our measurement study, we observe
that DoTCP is generally slower than DoUDP, where the relative increase in
Response Time is less than 37% for most resolvers. While optimizations to DoTCP
can be leveraged to further reduce the response times, we show that support on
Public resolvers is still missing, hence leaving room for optimizations in the
future. Moreover, we also find that Public resolvers generally have comparable
reliability for DoTCP and DoUDP. However, Probe resolvers show a significantly
different behavior: DoTCP queries targeting Probe resolvers fail in 3 out of 4
cases, and, therefore, do not comply with the standard. This problem will only
aggravate in the future: As DNS response sizes will continue to grow, the need
for DoTCP will solidify."
5847,"[25] proposed an algorithm to        sure optimal deployment resources and edge service rates,
save energy by reducing the QoS in the ofﬂoading process       and this requires further research and discussion.",Qing Li et al.,of edge computing in 2022.,2022-05-06 08:59:53+00:00,SD-AETO: Service Deployment Enabled Adaptive Edge Task Offloading in MEC,cs.NI,['cs.NI'],"[arxiv.Result.Author('Liangjun Song'), arxiv.Result.Author('Gang Sun'), arxiv.Result.Author('Hongfang Yu'), arxiv.Result.Author('Mohsen Guizani')]","In recent years, edge computing, as an important pillar for future networks,
has been developed rapidly. Task offloading is a key part of edge computing
that can provide computing resources for resource-constrained devices to run
computing-intensive applications, accelerate computing speed and save energy.
An efficient and feasible task offloading scheme can not only greatly improve
the quality of experience (QoE) but also provide strong support and assistance
for 5G/B5G networks, the industrial Internet of Things (IIoT), computing
networks and so on. To achieve these goals, this paper proposes an adaptive
edge task offloading scheme assisted by service deployment (SD-AETO) focusing
on the optimization of the energy utilization ratio (EUR) and the processing
latency. In the pre-implementation stage of the SD-AETO scheme, a service
deployment scheme is invoked to assist with task offloading considering each
service's popularity. The optimal service deployment scheme is obtained by
using the approximate deployment graph (AD-graph). Furthermore, a task
scheduling and queue offloading design procedure is proposed to complete the
SD-AETO scheme based on the task priority. The task priority is generated by
the corresponding service popularity and task offloading direction. Finally, we
analyze our SD-AETO scheme and compare it with related approaches, and the
results show that our scheme has a higher edge offloading rate and lower
resource consumption for massive task scenarios in the edge network."
5848,"To further research the performance of the EUR of the
                                                                        SD-AETO scheme, Figure 17 gives the simulation curve with
JOURNAL OF LATEX CLASS FILES, VOL.","This is because
                                                                        the proposed scheme can adapt to peak or low peak service
                                                                        periods simultaneously.","14, NO.",2022-05-06 08:59:53+00:00,SD-AETO: Service Deployment Enabled Adaptive Edge Task Offloading in MEC,cs.NI,['cs.NI'],"[arxiv.Result.Author('Liangjun Song'), arxiv.Result.Author('Gang Sun'), arxiv.Result.Author('Hongfang Yu'), arxiv.Result.Author('Mohsen Guizani')]","In recent years, edge computing, as an important pillar for future networks,
has been developed rapidly. Task offloading is a key part of edge computing
that can provide computing resources for resource-constrained devices to run
computing-intensive applications, accelerate computing speed and save energy.
An efficient and feasible task offloading scheme can not only greatly improve
the quality of experience (QoE) but also provide strong support and assistance
for 5G/B5G networks, the industrial Internet of Things (IIoT), computing
networks and so on. To achieve these goals, this paper proposes an adaptive
edge task offloading scheme assisted by service deployment (SD-AETO) focusing
on the optimization of the energy utilization ratio (EUR) and the processing
latency. In the pre-implementation stage of the SD-AETO scheme, a service
deployment scheme is invoked to assist with task offloading considering each
service's popularity. The optimal service deployment scheme is obtained by
using the approximate deployment graph (AD-graph). Furthermore, a task
scheduling and queue offloading design procedure is proposed to complete the
SD-AETO scheme based on the task priority. The task priority is generated by
the corresponding service popularity and task offloading direction. Finally, we
analyze our SD-AETO scheme and compare it with related approaches, and the
results show that our scheme has a higher edge offloading rate and lower
resource consumption for massive task scenarios in the edge network."
6034,"having wide deployment in their networks but rather making
                                        Therefore, at the end of this article, we provide a list of challenges         them handle “small” tasks that they are able to control in case
                                        and open issues that can guide further research in this important              of unexpected model behaviours.",Research on network automation is still in its infancy.,"This is contradictory to the
                                        area.",2022-05-11 11:14:36+00:00,Knowledge-powered Explainable Artificial Intelligence (XAI) for Network Automation Towards 6G,cs.NI,['cs.NI'],"[arxiv.Result.Author('Yulei Wu'), arxiv.Result.Author('Guozhi Lin'), arxiv.Result.Author('Jingguo Ge')]","Communication networks are becoming increasingly complex towards 6G. Manual
management is no longer an option for network operators. Network automation has
been widely discussed in the networking community, and it is a sensible means
to manage the complex communication network. Deep learning models developed to
enable network automation for given operation practices have the limitations of
1) lack of explainability and 2) inapplicable across different networks and/or
network settings. To tackle the above issues, in this article we propose a new
knowledge-powered framework that provides a human-understandable explainable
artificial intelligence (XAI) agent for network automation. A case study of
path selection is developed to demonstrate the feasibility of the proposed
framework. Research on network automation is still in its infancy. Therefore,
at the end of this article, we provide a list of challenges and open issues
that can guide further research in this important area."
6035,"In this section, we discuss some challenges and
the three constraints are inferred to be a linear relationship    open issues which can guide further research on this topic.","In this case study,    challenges.",from the high to low priority C1 → C2 → C3.,2022-05-11 11:14:36+00:00,Knowledge-powered Explainable Artificial Intelligence (XAI) for Network Automation Towards 6G,cs.NI,['cs.NI'],"[arxiv.Result.Author('Yulei Wu'), arxiv.Result.Author('Guozhi Lin'), arxiv.Result.Author('Jingguo Ge')]","Communication networks are becoming increasingly complex towards 6G. Manual
management is no longer an option for network operators. Network automation has
been widely discussed in the networking community, and it is a sensible means
to manage the complex communication network. Deep learning models developed to
enable network automation for given operation practices have the limitations of
1) lack of explainability and 2) inapplicable across different networks and/or
network settings. To tackle the above issues, in this article we propose a new
knowledge-powered framework that provides a human-understandable explainable
artificial intelligence (XAI) agent for network automation. A case study of
path selection is developed to demonstrate the feasibility of the proposed
framework. Research on network automation is still in its infancy. Therefore,
at the end of this article, we provide a list of challenges and open issues
that can guide further research in this important area."
6036,Some studies explained           for carrying out further research.,"At last, we provided a list of research
   output decisions, i.e., which features have more weights      challenges and open issues that can be useful to the community
   towards the decision-making.","how a decision was made, step-by-step, by searching a
   space.",2022-05-11 11:14:36+00:00,Knowledge-powered Explainable Artificial Intelligence (XAI) for Network Automation Towards 6G,cs.NI,['cs.NI'],"[arxiv.Result.Author('Yulei Wu'), arxiv.Result.Author('Guozhi Lin'), arxiv.Result.Author('Jingguo Ge')]","Communication networks are becoming increasingly complex towards 6G. Manual
management is no longer an option for network operators. Network automation has
been widely discussed in the networking community, and it is a sensible means
to manage the complex communication network. Deep learning models developed to
enable network automation for given operation practices have the limitations of
1) lack of explainability and 2) inapplicable across different networks and/or
network settings. To tackle the above issues, in this article we propose a new
knowledge-powered framework that provides a human-understandable explainable
artificial intelligence (XAI) agent for network automation. A case study of
path selection is developed to demonstrate the feasibility of the proposed
framework. Research on network automation is still in its infancy. Therefore,
at the end of this article, we provide a list of challenges and open issues
that can guide further research in this important area."
6048,"However, sensor data visualization should be considered
and further researched in cyber physical systems.","Most current research in cyber physical
systems focuses on optimizing operational energy cost or consumption [31] through the
development of the middle layer.","The middle layer is not easily interpreted
by FM users, and without a thoroughly developed top management layer there will be a loss
of agency for FM users as cyber physical system development progresses.",2022-05-11 14:09:35+00:00,Building Automation System Data Integration with BIM: Data Structure and Supporting Case Study,cs.NI,['cs.NI'],"[arxiv.Result.Author('Caroline Quinn'), arxiv.Result.Author('Ali Zargar Shabestari'), arxiv.Result.Author('Marin Litoiu'), arxiv.Result.Author('J. J. McArthur')]","Buildings Automation Systems (BAS) are ubiquitous in contemporary buildings,
both monitoring building conditions and managing the building system control
points. At present, these controls are prescriptive and pre-determined by the
design team, rather than responsive to actual building performance. These are
further limited by prescribed logic, possess only rudimentary visualizations,
and lack broader system integration capabilities. Advances in machine learning,
edge analytics, data management systems, and Facility Management-enabled
Building Information Models (FM-BIMs) permit a novel approach: cloud-hosted
building management. This paper presents an integration technique for mapping
the data from a building Internet of Things (IoT) sensor network to an FM-BIM.
The sensor data naming convention and timeseries analysis strategies integrated
into the data structure are discussed and presented, including the use of a 3D
nested list to permit timeseries data to be mapped to the FM-BIM and readily
visualized. The developed approach is presented through a case study of an
office living lab consisting of a local sensor network mimicking a BAS, which
streams to a cloud server via a virtual private network connection. The
resultant data structure and key visualizations are presented to demonstrate
the value of this approach, which permits the end-user to select the desired
timeframe for visualization and readily step through the spatio-temporal
building performance data."
6049,"However, sensor
data visualization should be considered and further researched in cyber physical systems.","Most current research
in cyber physical systems focuses on optimizing operational energy cost or consumption
(Schmidta and Åhlund 2018) through the development of the middle layer.","The
middle layer is not easily interpreted by FM users, and without a thoroughly developed top
management layer, there will be a loss of agency for FM users as cyber physical system

                                                       47
                                 © 2020.",2022-05-11 14:09:35+00:00,Building Automation System Data Integration with BIM: Data Structure and Supporting Case Study,cs.NI,"['cs.NI', '68M10 (Primary), 93B12 (Secondary)', 'C.3']","[arxiv.Result.Author('Caroline Quinn'), arxiv.Result.Author('Ali Zargar Shabestari'), arxiv.Result.Author('Marin Litoiu'), arxiv.Result.Author('J. J. McArthur')]","Buildings Automation Systems (BAS) are ubiquitous in contemporary buildings,
both monitoring building conditions and managing the building system control
points. At present, these controls are prescriptive and pre-determined by the
design team, rather than responsive to actual building performance. These are
further limited by prescribed logic, possess only rudimentary visualizations,
and lack broader system integration capabilities. Advances in machine learning,
edge analytics, data management systems, and Facility Management-enabled
Building Information Models (FM-BIMs) permit a novel approach: cloud-hosted
building management. This paper presents an integration technique for mapping
the data from a building Internet of Things (IoT) sensor network to an FM-BIM.
The sensor data naming convention and timeseries analysis strategies integrated
into the data structure are discussed and presented, including the use of a 3D
nested list to permit timeseries data to be mapped to the FM-BIM and readily
visualized. The developed approach is presented through a case study of an
office living lab consisting of a local sensor network mimicking a BAS, which
streams to a cloud server via a virtual private network connection. The
resultant data structure and key visualizations are presented to demonstrate
the value of this approach, which permits the end-user to select the desired
timeframe for visualization and readily step through the spatio-temporal
building performance data."
6318,"An interesting area for further research
handling methods, as a function of the type of served UEs (i.e.,         is to analyze joint strategies that optimize the functional
cell-edge, cell-middle, or cell-center).","However, the interaction between the split selec-
   Finally, the presented results have allowed interesting obser-        tion and the scheduling/resource allocation strategies has
vations regarding the behaviours of FH-scheduling and SRS-               been less studied.","A summary of main               split and the FH compression control for shared FH multi-
conclusions is shown in Table I.",2022-05-17 13:23:21+00:00,Fronthaul Compression Control for shared Fronthaul Access Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Sandra Lagén'), arxiv.Result.Author('Xavier Gelabert'), arxiv.Result.Author('Andreas Hansson'), arxiv.Result.Author('Manuel Requena'), arxiv.Result.Author('Lorenza Giupponi')]","There is a widely held belief that future Radio Access Network (RAN)
architectures will be characterized by increased levels of virtualization,
whereby base station functionalities, traditionally residing at a single
location, will be scattered across different logical entities while being
interfaced via high-speed fronthaul (FH) links. For the deployment of such FH
links, operators are faced with the challenge of maintaining acceptable radio
access performance while at the same time keeping deployment costs low. A
common practice is to exploit statistical multiplexing by allowing several
cells to utilize the same FH link. As a result, in order to cope with the
resulting aggregated traffic, different techniques can be used to reduce the
required FH data rates. Herein, we focus on FH compression control strategies
for multiple-cell/multiple-user scenarios sharing a common FH link. We propose
various methods for sounding reference signal (SRS) handling and analyze
different FH-aware modulation data compression and scheduling strategies.
Considering a full system setup, including the radio and FH access networks,
numerical evaluation is conducted using a 5G NR system-level simulator
implemented in ns-3. Simulation results show that, under stringent FH capacity
constraints, optimized modulation compression strategies provide significant
user-perceived throughput gains over baseline strategies (between 5.2x and
6.9x). On top of them, SRS handling methods achieve additional 2% to 41% gains."
6321,"Therefore,                    [7] R. Boutaba et al., “A comprehensive survey on machine learning
further research is needed to explicitly include in the NAS loop
more direct metrics, such as speed or energy consumption, to                        for networking: evolution, applications and research opportunities,”
perform an ecology of models design space (as well as making                        Journal of Internet Services and Applications, vol.","However, NAS is guided by an indirect                       Artiﬁcial Intelligence and Machine Learning, 2021.
measure of computation complexity (i.e., FLOPs).","9, no.",2022-04-26 16:51:00+00:00,Landing AI on Networks: An equipment vendor viewpoint on Autonomous Driving Networks,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Dario Rossi'), arxiv.Result.Author('Liang Zhang')]","The tremendous achievements of Artificial Intelligence (AI) in computer
vision, natural language processing, games and robotics, has extended the reach
of the AI hype to other fields: in telecommunication networks, the long term
vision is to let AI fully manage, and autonomously drive, all aspects of
network operation. In this industry vision paper, we discuss challenges and
opportunities of Autonomous Driving Network (ADN) driven by AI technologies. To
understand how AI can be successfully landed in current and future networks, we
start by outlining challenges that are specific to the networking domain,
putting them in perspective with advances that AI has achieved in other fields.
We then present a system view, clarifying how AI can be fitted in the network
architecture. We finally discuss current achievements as well as future
promises of AI in networks, mentioning a roadmap to avoid bumps in the road
that leads to true large-scale deployment of AI technologies in networks."
6337,Ba¨uml et                                       needs further study.,"[30]                                      The effect of opportunism on the fundamental entanglement
analyze the fundamental limits of repeaterless communications                                       distribution rate between two endpoints of a repeater chain
using local operations and classical communication.","Our analysis of the swapping and reserva-
al.",2022-05-17 16:44:10+00:00,Opportunistic Routing in Quantum Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Ali Farahbakhsh'), arxiv.Result.Author('Chen Feng')]","Unlike classical routing algorithms, quantum routing algorithms make use of
entangled states - a type of resources that have a limited lifetime and need to
be regenerated after consumption. In a nutshell, quantum routing algorithms
have to use these resources efficiently, while optimizing some objectives such
as the total waiting time. Current routing algorithms tend to keep a routing
request waiting until all of the resources on its path are available. In this
paper, we introduce a new way of managing entanglement resources in an
opportunistic fashion: a request can move forward along its path as soon as
possible (even if some resources on its path are not ready). We show that this
opportunistic approach is fundamentally better than conventional approaches. In
particular, our results indicate that this new approach achieves a 30-50%
improvement in the average total waiting time and average link waiting time
compared with several state-of-the-art routing algorithms. As a by-product of
this work, we develop a new simulator for quantum routing, which can be used to
evaluate various design choices under different scenarios."
6338,Ba¨uml et                                       needs further study.,"[17]                                      The effect of opportunism on the fundamental entanglement
analyze the fundamental limits of repeaterless communications                                       distribution rate between two endpoints of a repeater chain
using local operations and classical communication.","Our analysis of the swapping and reserva-
al.",2022-05-17 16:44:10+00:00,Opportunistic Routing in Quantum Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Ali Farahbakhsh'), arxiv.Result.Author('Chen Feng')]","Unlike classical routing algorithms, quantum routing algorithms make use of
entangled states - a type of resources that have a limited lifetime and need to
be regenerated after consumption. In a nutshell, quantum routing algorithms
have to use these resources efficiently, while optimizing some objectives such
as the total waiting time. Current routing algorithms tend to keep a routing
request waiting until all of the resources on its path are available. In this
paper, we introduce a new way of managing entanglement resources in an
opportunistic fashion: a request can move forward along its path as soon as
possible (even if some resources on its path are not ready). We show that this
opportunistic approach is fundamentally better than conventional approaches. In
particular, our results indicate that this new approach achieves a 30-50%
improvement in the average total waiting time and average link waiting time
compared with several state-of-the-art routing algorithms. As a by-product of
this work, we develop a new simulator for quantum routing, which can be used to
evaluate various design choices under different scenarios."
6339,needs further study.,"The effect of opportunism on the fundamental entanglement
distribution rate between two endpoints of a repeater chain         [12] H. Kaushal, V. Jain, and K. Subrat, Free Space Optical Communication.","Our analysis of the swapping and reserva-            Springer India, 2017.
tion gains does not include the ﬁnite lifetime and probabilistic
swapping regime, and extending the results to include these         [13] S. Shi and C. Qian, “Concurrent entanglement routing for quantum
assumptions would provide useful insight for designing new                networks: Model and designs,” Proceedings of the Annual Conference
algorithms.",2022-05-17 16:44:10+00:00,Opportunistic Routing in Quantum Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Ali Farahbakhsh'), arxiv.Result.Author('Chen Feng')]","Unlike classical routing algorithms, quantum routing algorithms make use of
entangled states - a type of resources that have a limited lifetime and need to
be regenerated after consumption. In a nutshell, quantum routing algorithms
have to use these resources efficiently, while optimizing some objectives such
as the total waiting time. Current routing algorithms tend to keep a routing
request waiting until all of the resources on its path are available. In this
paper, we introduce a new way of managing entanglement resources in an
opportunistic fashion: a request can move forward along its path as soon as
possible (even if some resources on its path are not ready). We show that this
opportunistic approach is fundamentally better than conventional approaches. In
particular, our results indicate that this new approach achieves a 30-50%
improvement in the average total waiting time and average link waiting time
compared with several state-of-the-art routing algorithms. As a by-product of
this work, we develop a new simulator for quantum routing, which can be used to
evaluate various design choices under different scenarios."
6373,"For instance, the participants in     which requires further study in the future.","Referring to the protocol design
distributed intelligence, intelligence sharing, etc., can only be  of the Internet of information, we can also conceive a “thin
carried out on the premise of understanding the distributed        waist” hourglass architecture for the Internet of intelligence,
information of intelligence.","the Internet of intelligence may not know which services
are available in the network they are connected to.",2022-05-18 15:00:29+00:00,"Internet of Intelligence: A Survey on the Enabling Technologies, Applications, and Challenges",cs.NI,['cs.NI'],"[arxiv.Result.Author('Qinqin Tang'), arxiv.Result.Author('F. Richard Yu'), arxiv.Result.Author('Renchao Xie'), arxiv.Result.Author('Azzedine Boukerche'), arxiv.Result.Author('Tao Huang'), arxiv.Result.Author('Yunjie Liu')]","The Internet of intelligence is conceived as an emerging networking paradigm,
which will make intelligence as easy to obtain as information. This paper
provides an overview of the Internet of intelligence, focusing on motivations,
architecture, enabling technologies, applications, and existing challenges.
This can provide a good foundation for those who are interested to gain
insights into the concept of the Internet of intelligence and the key enablers
of this emerging networking paradigm. Specifically, this paper starts by
investigating the evolution of networking paradigms and artificial intelligence
(AI), based on which we present the motivations of the Internet of intelligence
by demonstrating that networking needs intelligence and intelligence needs
networking. We then present the layered architecture to characterize the
Internet of intelligence systems and discuss the enabling technologies of each
layer. Moreover, we discuss the critical applications and their integration
with the Internet of intelligence paradigm. Finally, some technical challenges
and open issues are summarized to fully exploit the benefits of the Internet of
intelligence."
6710,"However, further research needs to
vulnerability, the ﬂexibility of the approach, Protection from
IP spooﬁng, and overall security achieved.",The comparison is based on DDoS              the speciﬁc requirements.,"be conducted to ﬁnd the best way to transmit the allocated port

   It can be observed that in the case of a DDoS Attack,                   knocking sequence to the host.",2022-05-25 14:43:51+00:00,P4Filter: A two level defensive mechanism against attacks in SDN using P4,cs.NI,['cs.NI'],"[arxiv.Result.Author('Ananya Saxena'), arxiv.Result.Author('Ritvik Muttreja'), arxiv.Result.Author('Shivam Upadhyay'), arxiv.Result.Author('K. Shiv Kumar'), arxiv.Result.Author('Dr Venkanna U')]","The advancements in networking technologies have led to a new paradigm of
controlling networks, with data plane programmability as a basis. This facility
opens up many advantages, such as flexibility in packet processing and better
network management, which leads to better security in the network. However, the
current literature lacks network security solutions concerning authentication
and preventing unauthorized access. In this work, our goal is to avoid attacks
in a two level defense mechanism (P4Filter). The first level is a dynamic
firewall logic, which blocks packets generated from an unauthorized source. The
second level is an authentication mechanism based on dynamic port knocking. The
two security levels were tested in a virtual environment with P4 based
switches. The packets arriving at the switch from unknown hosts are sent to the
controller. The controller maintains an ACL using which it assigns rules for
both the levels to allow or drop the packets. For port knocking a new random
sequence is generated for every new host. Hosts can only connect using the
correct sequence assigned to them.The tests conducted show this approach
performs better than the previous P4 based firewall approaches due to two
security levels. Moreover, it is successful in mitigating specific security
attacks by blocking unauthorized access to the network."
6711,"However, further research needs to
vulnerability, the ﬂexibility of the approach, Protection from
IP spooﬁng, and overall security achieved.",The comparison is based on DDoS              the speciﬁc requirements.,"be conducted to ﬁnd the best way to transmit the allocated port

   It can be observed that in the case of a DDoS Attack,                   knocking sequence to the host.",2022-05-25 14:43:51+00:00,P4Filter: A two level defensive mechanism against attacks in SDN using P4,cs.NI,['cs.NI'],"[arxiv.Result.Author('Ananya Saxena'), arxiv.Result.Author('Ritvik Muttreja'), arxiv.Result.Author('Shivam Upadhyay'), arxiv.Result.Author('K. Shiv Kumar'), arxiv.Result.Author('Venkanna U')]","The advancements in networking technologies have led to a new paradigm of
controlling networks, with data plane programmability as a basis. This facility
opens up many advantages, such as flexibility in packet processing and better
network management, which leads to better security in the network. However, the
current literature lacks network security solutions concerning authentication
and preventing unauthorized access. In this work, our goal is to avoid attacks
in a two level defense mechanism (P4Filter). The first level is a dynamic
firewall logic, which blocks packets generated from an unauthorized source. The
second level is an authentication mechanism based on dynamic port knocking. The
two security levels were tested in a virtual environment with P4 based
switches. The packets arriving at the switch from unknown hosts are sent to the
controller. The controller maintains an ACL using which it assigns rules for
both the levels to allow or drop the packets. For port knocking a new random
sequence is generated for every new host. Hosts can only connect using the
correct sequence assigned to them.The tests conducted show this approach
performs better than the previous P4 based firewall approaches due to two
security levels. Moreover, it is successful in mitigating specific security
attacks by blocking unauthorized access to the network."
7866,"In the future, we are in-
                                                                             terested in further study on the ψ-score in order to explore the
                                                                             possibility to get these other information potentially valuable
                                                                             for some applications.","But in some cases, one might
                                                                             need to use the inﬂuence of a user on a speciﬁc user, which
                                                                             is giver by the OSP model but skipped by the proposed
                                                                             Power-ψ to go faster to the point.","ACKNOWLEDGEMENTS                                           [15] P. R. Miller, P. S. Bobkowski, D. Maliniak, and R. B. Rapoport,
                                                                                        “Talking politics on facebook: Network centrality and political
   The work of N.A.",2022-06-20 18:42:45+00:00,A Fast Algorithm for Ranking Users by their Influence in Online Social Platforms,cs.NI,"['cs.NI', 'cs.SI']","[arxiv.Result.Author('Nouamane Arhachoui'), arxiv.Result.Author('Esteban Bautista'), arxiv.Result.Author('Maximilien Danisch'), arxiv.Result.Author('Anastasios Giovanidis')]","Measuring the influence of users in social networks is key for numerous
applications. A recently proposed influence metric, coined as $\psi$-score,
allows to go beyond traditional centrality metrics, which only assess
structural graph importance, by further incorporating the rich information
provided by the posting and re-posting activity of users. The $\psi$-score is
shown in fact to generalize PageRank for non-homogeneous node activity. Despite
its significance, it scales poorly to large datasets; for a network of $N$
users it requires to solve $N$ linear systems of equations of size $N$. To
address this problem, this work introduces a novel scalable algorithm for the
fast approximation of $\psi$-score, named Power-$\psi$. The proposed algorithm
is based on a novel equation indicating that it suffices to solve one system of
equations of size $N$ to compute the $\psi$-score. Then, our algorithm exploits
the fact that such system can be recursively and distributedly approximated to
any desired error. This permits the $\psi$-score, summarizing both structural
and behavioral information for the nodes, to run as fast as PageRank. We
validate the effectiveness of the proposed algorithm on several real-world
datasets."
7867,"In the future, we are in-
                                                                             terested in further study on the ψ-score in order to explore the
                                                                             possibility to get these other information potentially valuable
                                                                             for some applications.","But in some cases, one might
                                                                             need to use the inﬂuence of a user on a speciﬁc user, which
                                                                             is giver by the OSP model but skipped by the proposed
                                                                             Power-ψ to go faster to the point.","ACKNOWLEDGEMENTS                                           [15] P. R. Miller, P. S. Bobkowski, D. Maliniak, and R. B. Rapoport,
                                                                                        “Talking politics on facebook: Network centrality and political
   The work of N.A.",2022-06-20 18:42:45+00:00,A Fast Algorithm for Ranking Users by their Influence in Online Social Platforms,cs.NI,"['cs.NI', 'cs.SI']","[arxiv.Result.Author('Nouamane Arhachoui'), arxiv.Result.Author('Esteban Bautista'), arxiv.Result.Author('Maximilien Danisch'), arxiv.Result.Author('Anastasios Giovanidis')]","Measuring the influence of users in social networks is key for numerous
applications. A recently proposed influence metric, coined as $\psi$-score,
allows to go beyond traditional centrality metrics, which only assess
structural graph importance, by further incorporating the rich information
provided by the posting and re-posting activity of users. The $\psi$-score is
shown in fact to generalize PageRank for non-homogeneous node activity. Despite
its significance, it scales poorly to large datasets; for a network of $N$
users it requires to solve $N$ linear systems of equations of size $N$. To
address this problem, this work introduces a novel scalable algorithm for the
fast approximation of $\psi$-score, named Power-$\psi$. The proposed algorithm
is based on a novel equation indicating that it suffices to solve one system of
equations of size $N$ to compute the $\psi$-score. Then, our algorithm exploits
the fact that such system can be recursively and distributedly approximated to
any desired error. This permits the $\psi$-score, summarizing both structural
and behavioral information for the nodes, to run as fast as PageRank. We
validate the effectiveness of the proposed algorithm on several real-world
datasets."
7868,"Available:
terested in further study on the ψ-score in order to explore the                        https://doi.org/10.1080/15472450.2012.716663
possibility to get these other information potentially valuable
for some applications.",[Online].,"[13] A. Tizghadam and A. Leon-Garcia, “Betweenness centrality and resis-
                                                                                        tance distance in communication networks,” IEEE Network, vol.",2022-06-20 18:42:45+00:00,A Fast Algorithm for Ranking Users by their Influence in Online Social Platforms,cs.NI,"['cs.NI', 'cs.SI']","[arxiv.Result.Author('Nouamane Arhachoui'), arxiv.Result.Author('Esteban Bautista'), arxiv.Result.Author('Maximilien Danisch'), arxiv.Result.Author('Anastasios Giovanidis')]","Measuring the influence of users in social networks is key for numerous
applications. A recently proposed influence metric, coined as $\psi$-score,
allows to go beyond traditional centrality metrics, which only assess
structural graph importance, by further incorporating the rich information
provided by the posting and re-posting activity of users. The $\psi$-score is
shown in fact to generalize PageRank for non-homogeneous node activity. Despite
its significance, it scales poorly to large datasets; for a network of $N$
users, it requires to solve $N$ linear systems of equations of size $N$. To
address this problem, this work introduces a novel scalable algorithm for the
fast approximation of $\psi$-score, named \textit{Power}-$\psi$. The proposed
algorithm is based on a novel equation indicating that it suffices to solve one
system of equations of size $N$ to compute the $\psi$-score. Then, our
algorithm exploits the fact that such a system can be recursively and
distributedly approximated to any desired error. This permits the $\psi$-score,
summarizing both structural and behavioral information for the nodes, to run as
fast as PageRank. We validate the effectiveness of the proposed algorithm,
which we release as an open source Python library, on several real-world
datasets."
8183,"27
                                              Figure 13: Future Research in nine areas

7.3 Deep Learning

8 FUTURE RESEARCH DIRECTION(need major revision)

As indicated by the above foundation and technical survey, we have summarized 9-areas for further research and
development.",12.,"Even though SDN has proﬁts by the network security viewpoint, despite everything, a few detectable
feeble focuses have been located.",2022-06-28 18:34:39+00:00,A Survey on SDN \& SDCN Traffic Measurement: Existing Approaches and Research Challenge,cs.NI,['cs.NI'],"[arxiv.Result.Author('MD Samiul Islam'), arxiv.Result.Author('Mojammel Hossain'), arxiv.Result.Author('Mohammed AlMukhtar')]","Software Defined Network (SDN) is the next generation network that decouples
the control plane from the data plane of forwarding devices by utilizing the
OpenFlow protocol as a communication link between the data plane and the
control plane. However, there are some security issues might be in actions on
SDN that the attackers can take control over the SDN control plane. Thus,
traffic measurement is a fundamental technique of protecting SDN against the
high-security threats such as DDoS, heavy hitter, superspreader as well as live
video calling, QoS control, high bandwidth requirement, resource management are
also inevitable in SDN/Software Defined Cellular Network (SDCN). In such a
scenario, we survey SDN traffic measurement solutions, in order to assess how
these solutions can make a secured, efficient and robust SDN/SDCN architecture.
In this paper, various types of SDN traffic measurement solutions have been
categorized based on network applications behaviour. Furthermore, we find out
the challenges related to SDN/SDCN traffic measurement and future scope of
research, which will guide to design and develop more advanced traffic
measurement solutions for a scalable, heterogeneous, hierarchical and widely
deployed SDN/SDCN in future prospects. More in details, we list out kinds of
practical machine learning (ML) approaches to analyze how we can make
improvement in the traffic measurement performances. We conclude that using ML
in SDN traffic measurement solutions will give benefit to get secured SDN/SDCN
network in complementary ways."
8211,"In future work, we will address further research challenges.","Proof-of-concept
prototypes, including a Raspberry Pi system and a mobile app, were developed, and an evaluation
study of the machine learning model and the effects of crowdsourcing were presented in the article.","For instance, how to extend the
functionalities of a hybrid sensing system to the setting of heterogeneous sensors.",2022-06-29 08:45:58+00:00,Integrating IoT-Sensing and Crowdsensing with Privacy: Privacy-Preserving Hybrid Sensing for Smart Cities,cs.NI,['cs.NI'],"[arxiv.Result.Author('Hanwei Zhu'), arxiv.Result.Author('Sid Chi-Kin Chau'), arxiv.Result.Author('Gladhi Guarddin'), arxiv.Result.Author('Weifa Liang')]","Data sensing and gathering is an essential task for various
information-driven services in smart cities. On the one hand, Internet of
Things (IoT) sensors can be deployed at certain fixed locations to capture data
reliably but suffer from limited sensing coverage. On the other hand, data can
also be gathered dynamically through crowdsensing contributed by voluntary
users but suffer from its unreliability and the lack of incentives for users'
contributions. In this paper, we explore an integrated paradigm called ""hybrid
sensing"" that harnesses both IoT-sensing and crowdsensing in a complementary
manner. In hybrid sensing, users are incentivized to provide sensing data not
covered by IoT sensors and provide crowdsourced feedback to assist in
calibrating IoT-sensing. Their contributions will be rewarded with credits that
can be redeemed to retrieve synthesized information from the hybrid system. In
this paper, we develop a hybrid sensing system that supports explicit user
privacy -- IoT sensors are obscured physically to prevent capturing private
user data, and users interact with a crowdsensing server via a
privacy-preserving protocol to preserve their anonymity. A key application of
our system is smart parking, by which users can inquire and find the available
parking spaces in outdoor parking lots. We implemented our hybrid sensing
system for smart parking and conducted extensive empirical evaluations.
Finally, our hybrid sensing system can be potentially applied to other
information-driven services in smart cities."
8297,"Lastly, we overview
the expected design challenges which may occur during the implementation process, and identify the key research
challenges which require timely solutions and which are significant to spur further research in this challenging area.","In addition, we also investigate the expected applications of WIET in the 6G IoNT based devices and
discuss the WIET implementation challenges in 6G IoNT for the optimal use of the technology.","Overall, through this survey, we discuss the possibility to maximize the applications of WIET in 6G IoNT.",2022-07-01 10:34:32+00:00,Survey on Wireless Information Energy Transfer (WIET) and Related Applications in 6G Internet of NanoThings (IoNT),cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Pragati Sharma'), arxiv.Result.Author('Rahul Jashvantbhai Pandya'), arxiv.Result.Author('Sridhar Iyer'), arxiv.Result.Author('Anubhav Sharma')]","This article contains an overview of WIET and the related applications in 6G
IoNT. Specifically, to explore the following, we: (i) introduce the 6G network
along with the implementation challenges, possible techniques, THz
communication and related research challenges, (ii) focus on the WIET
architecture, and different energy carrying code words for efficient charging
through WIET, (iii) discuss IoNT with techniques proposed for communication of
nano-devices, and (iv) conduct a detailed literature review to explore the
implicational aspects of the WIET in the 6G nano-network. In addition, we also
investigate the expected applications of WIET in the 6G IoNT based devices and
discuss the WIET implementation challenges in 6G IoNT for the optimal use of
the technology. Lastly, we overview the expected design challenges which may
occur during the implementation process, and identify the key research
challenges which require timely solutions and which are significant to spur
further research in this challenging area. Overall, through this survey, we
discuss the possibility to maximize the applications of WIET in 6G IoNT."
8303,"To this end, mobility/session management
                                                                             and routing techniques require further research.",guarantee.,"3) Ubiquitous connectivity: The above new network ar-
chitectures pave the way to achieve a highly efﬁcient and                 – Uncertain delay and jitter, network topology, and fre-
ﬂexible network O&M via building an intelligent network of                   quent handovers of user links impose challenges to
intelligent things, and lay the foundation for the high-quality              the QoS guarantee.",2022-06-10 12:08:39+00:00,"Semantic Communications for 6G Future Internet: Fundamentals, Applications, and Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Wanting Yang'), arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Ziqin Liew'), arxiv.Result.Author('Wei Yang Bryan Lim'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Xuefen Chi'), arxiv.Result.Author('Xuemin Sherman Shen'), arxiv.Result.Author('Chunyan Miao')]","With the increasing demand for intelligent services, the sixth-generation
(6G) wireless networks will shift from a traditional architecture that focuses
solely on high transmission rate to a new architecture that is based on the
intelligent connection of everything. Semantic communication (SemCom), a
revolutionary architecture that integrates user as well as application
requirements and meaning of information into the data processing and
transmission, is predicted to become a new core paradigm in 6G. While SemCom is
expected to progress beyond the classical Shannon paradigm, several obstacles
need to be overcome on the way to a SemCom-enabled smart wireless Internet. In
this paper, we first highlight the motivations and compelling reasons of SemCom
in 6G. Then, we outline the major 6G visions and key enabler techniques which
lay the foundation of SemCom. Meanwhile, we highlight some benefits of
SemCom-empowered 6G and present a SemCom-native 6G network architecture. Next,
we show the evolution of SemCom from its introduction to classical SemCom
related theory and modern AI-enabled SemCom. Following that, focusing on modern
SemCom, we classify SemCom into three categories, i.e., semantic-oriented
communication, goal-oriented communication, and semantic-aware communication,
and introduce three types of semantic metrics. We then discuss the
applications, the challenges and technologies related to semantics and
communication. Finally, we introduce future research opportunities. In a
nutshell, this paper investigates the fundamentals of SemCom, its applications
in 6G networks, and the existing challenges and open issues for further
direction."
8304,require further study.,"New           bandwidth for more important transmitted content to ensure
design schemes that combine these mechanisms with SemCom           information quality.","2) Energy Resource: In addition to the allocation of band-
B.",2022-06-10 12:08:39+00:00,"Semantic Communications for 6G Future Internet: Fundamentals, Applications, and Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Wanting Yang'), arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Ziqin Liew'), arxiv.Result.Author('Wei Yang Bryan Lim'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Xuefen Chi'), arxiv.Result.Author('Xuemin Sherman Shen'), arxiv.Result.Author('Chunyan Miao')]","With the increasing demand for intelligent services, the sixth-generation
(6G) wireless networks will shift from a traditional architecture that focuses
solely on high transmission rate to a new architecture that is based on the
intelligent connection of everything. Semantic communication (SemCom), a
revolutionary architecture that integrates user as well as application
requirements and meaning of information into the data processing and
transmission, is predicted to become a new core paradigm in 6G. While SemCom is
expected to progress beyond the classical Shannon paradigm, several obstacles
need to be overcome on the way to a SemCom-enabled smart wireless Internet. In
this paper, we first highlight the motivations and compelling reasons of SemCom
in 6G. Then, we outline the major 6G visions and key enabler techniques which
lay the foundation of SemCom. Meanwhile, we highlight some benefits of
SemCom-empowered 6G and present a SemCom-native 6G network architecture. Next,
we show the evolution of SemCom from its introduction to classical SemCom
related theory and modern AI-enabled SemCom. Following that, focusing on modern
SemCom, we classify SemCom into three categories, i.e., semantic-oriented
communication, goal-oriented communication, and semantic-aware communication,
and introduce three types of semantic metrics. We then discuss the
applications, the challenges and technologies related to semantics and
communication. Finally, we introduce future research opportunities. In a
nutshell, this paper investigates the fundamentals of SemCom, its applications
in 6G networks, and the existing challenges and open issues for further
direction."
8305,The estimated SNR value is then     tion with SemCom require further study.,"In the proposed model, the SNR is estimated by a           combine correction mechanisms in conventional communica-
pilot signal at the receiver.","extended to an SNR map that has the same size as the channel
output feature map.",2022-06-10 12:08:39+00:00,"Semantic Communications for Future Internet: Fundamentals, Applications, and Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Wanting Yang'), arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Ziqin Liew'), arxiv.Result.Author('Wei Yang Bryan Lim'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Xuefen Chi'), arxiv.Result.Author('Xuemin Sherman Shen'), arxiv.Result.Author('Chunyan Miao')]","With the increasing demand for intelligent services, the sixth-generation
(6G) wireless networks will shift from a traditional architecture that focuses
solely on high transmission rate to a new architecture that is based on the
intelligent connection of everything. Semantic communication (SemCom), a
revolutionary architecture that integrates user as well as application
requirements and meaning of information into the data processing and
transmission, is predicted to become a new core paradigm in 6G. While SemCom is
expected to progress beyond the classical Shannon paradigm, several obstacles
need to be overcome on the way to a SemCom-enabled smart wireless Internet. In
this paper, we first highlight the motivations and compelling reasons of SemCom
in 6G. Then, we outline the major 6G visions and key enabler techniques which
lay the foundation of SemCom. Meanwhile, we highlight some benefits of
SemCom-empowered 6G and present a SemCom-native 6G network architecture. Next,
we show the evolution of SemCom from its introduction to classical SemCom
related theory and modern AI-enabled SemCom. Following that, focusing on modern
SemCom, we classify SemCom into three categories, i.e., semantic-oriented
communication, goal-oriented communication, and semantic-aware communication,
and introduce three types of semantic metrics. We then discuss the
applications, the challenges and technologies related to semantics and
communication. Finally, we introduce future research opportunities. In a
nutshell, this paper investigates the fundamentals of SemCom, its applications
in 6G networks, and the existing challenges and open issues for further
direction."
8306,shift still leaves much room for further research.,"As we discuss
BLER than the model with conventional training, when more           above, some literature has attempted to use semantic informa-
than one pilot frame is sent by the transmitter during the testing  tion to guide the resource allocation process, but this paradigm
phase.","3) Coding and decoding scheme: The coding and decoding              3) Lessons learned for heterogeneous network devices: The
scheme needs to be improved based on the various channel            heterogeneity of network devices in the network is mainly
conditions of different users in the SemCom network.",2022-06-10 12:08:39+00:00,"Semantic Communications for Future Internet: Fundamentals, Applications, and Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Wanting Yang'), arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Ziqin Liew'), arxiv.Result.Author('Wei Yang Bryan Lim'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Xuefen Chi'), arxiv.Result.Author('Xuemin Sherman Shen'), arxiv.Result.Author('Chunyan Miao')]","With the increasing demand for intelligent services, the sixth-generation
(6G) wireless networks will shift from a traditional architecture that focuses
solely on high transmission rate to a new architecture that is based on the
intelligent connection of everything. Semantic communication (SemCom), a
revolutionary architecture that integrates user as well as application
requirements and meaning of information into the data processing and
transmission, is predicted to become a new core paradigm in 6G. While SemCom is
expected to progress beyond the classical Shannon paradigm, several obstacles
need to be overcome on the way to a SemCom-enabled smart wireless Internet. In
this paper, we first highlight the motivations and compelling reasons of SemCom
in 6G. Then, we outline the major 6G visions and key enabler techniques which
lay the foundation of SemCom. Meanwhile, we highlight some benefits of
SemCom-empowered 6G and present a SemCom-native 6G network architecture. Next,
we show the evolution of SemCom from its introduction to classical SemCom
related theory and modern AI-enabled SemCom. Following that, focusing on modern
SemCom, we classify SemCom into three categories, i.e., semantic-oriented
communication, goal-oriented communication, and semantic-aware communication,
and introduce three types of semantic metrics. We then discuss the
applications, the challenges and technologies related to semantics and
communication. Finally, we introduce future research opportunities. In a
nutshell, this paper investigates the fundamentals of SemCom, its applications
in 6G networks, and the existing challenges and open issues for further
direction."
8310,There are many directions for further research.,"Our work extends the results in the literature
on unit disk graphs to hypergraph models.","Determining which structured
hypergraphs are realizable and determining the maximum possible interference degree
of realizable hypergraphs are problems for further research.",2022-07-01 15:59:41+00:00,Structured Hypergraphs in Cellular Mobile Communication Systems,cs.NI,"['cs.NI', 'cs.CC', 'cs.DM', 'cs.DS']",[arxiv.Result.Author('Ashwin Ganesan')],"An open problem is to extend the results in the literature on unit disk
graphs to hypergraph models. Motivated by recent results that the worst-case
performance of the distributed maximal scheduling algorithm is characterized by
the interference degree of the hypergraph, in the present work we investigate
properties of the interference degree of the hypergraph and the structure of
hypergraphs arising from physical constraints. We show that the problem of
computing the interference degree of a hypergraph is NP-hard and we prove some
properties and results concerning this hypergraph invariant. We then
investigate which hypergraphs are realizable, i.e. which hypergraphs arise in
practice, based on physical constraints, as the interference model of a
wireless network. In particular, given the results on the worst-case
performance of the maximal scheduling algorithm, a question that arises
naturally is: what is the maximal value of $r$ such that the hypergraph
$K_{1,r}$ is realizable? We show that this value is $r=4$."
8311,"Determining which structured
hypergraphs are realizable and determining the maximum possible interference degree
of realizable hypergraphs are problems for further research.",There are many directions for further research.,"References

 [1] C. Avin, Y. Emek, E. Kantor, Z. Lotker, D. Peleg, and L. Roditty.",2022-07-01 15:59:41+00:00,Structured Hypergraphs in Cellular Mobile Communication Systems,cs.NI,"['cs.NI', 'cs.CC', 'cs.DM', 'cs.DS']",[arxiv.Result.Author('Ashwin Ganesan')],"An open problem is to extend the results in the literature on unit disk
graphs to hypergraph models. Motivated by recent results that the worst-case
performance of the distributed maximal scheduling algorithm is characterized by
the interference degree of the hypergraph, in the present work we investigate
properties of the interference degree of the hypergraph and the structure of
hypergraphs arising from physical constraints. We show that the problem of
computing the interference degree of a hypergraph is NP-hard and we prove some
properties and results concerning this hypergraph invariant. We then
investigate which hypergraphs are realizable, i.e. which hypergraphs arise in
practice, based on physical constraints, as the interference model of a
wireless network. In particular, given the results on the worst-case
performance of the maximal scheduling algorithm, a question that arises
naturally is: what is the maximal value of $r$ such that the hypergraph
$K_{1,r}$ is realizable? We show that this value is $r=4$."
8398,"Although modifications are necessary to enhance the credibility of
our work as simulation examples of actual space-terrestrial communications, our
view could be a motive for further research.","Moreover, we observe and
determine the impact of specific parameters such as the number of ground stations,
satellites, planes & satellites per plane, and intersatelliteLinks on the reliability of the
communications.","The implementation of space
communication protocols, mechanisms for collision detection and avoidance, routing
optimization algorithms or buffer requirements of satellites are a few significant

                                                                                                               15
topics for discussion.",2022-07-04 14:24:55+00:00,Satellite assisted disrupted communications in OMNeT++: Experiments and IoT Case Study,cs.NI,['cs.NI'],"[arxiv.Result.Author('Georgios Koukis'), arxiv.Result.Author('Vassilis Tsaoussidis')]","In this work we discuss the utilization of micro-satellite constellations as
effective infrastructures for the communication among ground stations or even
among 'smart' devices in IoT scenarios. We design and implement a series of
experiments in OMNeT++ (with the OS3 framework) and evaluate their results in
different scenarios. Initially, we establish the necessary theoretical
background for space communications, including satellite and constellation
design features, with existing and novel satellite services in various areas of
interest. Furthermore, we detail the OMNeT++ and OS3 frameworks and introduce
the significant variables/parameters for our experiments. Our scenarios are
presented in three groups, departing from the straightforward one sender - one
receiver communication and proceeding with a topology of multiple neighboring
ground stations transmitting pings. We conclude with an IoT Case Study in which
we import real measurements from sensors of the SmartSantander test-bed.
Through our experiments we observe the effect of simulation parameters such as
the constellation design (e.g., the number of satellites and planes) and the
intersatelliteLinks regarding the produced RTT and ping loss, while we also
highlight their potential contribution on networking communications when
disruptions dominate."
8399,"Although modifications are necessary to enhance the credibility of
our work as simulation examples of actual space-terrestrial communications, our
view could be a motive for further research.","Moreover, we observe and
determine the impact of specific parameters such as the number of ground stations,
satellites, planes & satellites per plane, and intersatelliteLinks on the reliability of the
communications.","The implementation of space
communication protocols, mechanisms for collision detection and avoidance, routing
optimization algorithms or buffer requirements of satellites are a few significant

                                                                                                               15
topics for discussion.",2022-07-04 14:24:55+00:00,Satellite assisted disrupted communications in OMNeT++: Experiments and IoT Case Study,cs.NI,['cs.NI'],[arxiv.Result.Author('Georgios Koukis')],"In this work we discuss the utilization of micro-satellite constellations as
effective infrastructures for the communication among ground stations or even
among 'smart' devices in IoT scenarios. We design and implement a series of
experiments in OMNeT++ (with the OS3 framework) and evaluate their results in
different scenarios. Initially, we establish the necessary theoretical
background for space communications, including satellite and constellation
design features, with existing and novel satellite services in various areas of
interest. Furthermore, we detail the OMNeT++ and OS3 frameworks and introduce
the significant variables/parameters for our experiments. Our scenarios are
presented in three groups, departing from the straightforward one sender - one
receiver communication and proceeding with a topology of multiple neighboring
ground stations transmitting pings. We conclude with an IoT Case Study in which
we import real measurements from sensors of the SmartSantander test-bed.
Through our experiments we observe the effect of simulation parameters such as
the constellation design (e.g., the number of satellites and planes) and the
intersatelliteLinks regarding the produced RTT and ping loss, while we also
highlight their potential contribution on networking communications when
disruptions dominate."
8980,"When all conditions in Theorem 3            In future work, we will further research ultra-low latency
are satisfied, the schedule can be computed only by searching        communication and study the deterministic latency guarantee
for the optimal time-offset set.",multiple flows is analyzed.,"Otherwise, relaxation of jitters    techniques for IIoT.",2022-07-17 16:52:51+00:00,An Intelligent Deterministic Scheduling Method for Ultra-Low Latency Communication in Edge Enabled Industrial Internet of Things,cs.NI,"['cs.NI', 'cs.AI', 'cs.SI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Yinzhi Lu'), arxiv.Result.Author('Liu Yang'), arxiv.Result.Author('Simon X. Yang'), arxiv.Result.Author('Qiaozhi Hua'), arxiv.Result.Author('Arun Kumar Sangaiah'), arxiv.Result.Author('Tan Guo'), arxiv.Result.Author('Keping Yu')]","Edge enabled Industrial Internet of Things (IIoT) platform is of great
significance to accelerate the development of smart industry. However, with the
dramatic increase in real-time IIoT applications, it is a great challenge to
support fast response time, low latency, and efficient bandwidth utilization.
To address this issue, Time Sensitive Network (TSN) is recently researched to
realize low latency communication via deterministic scheduling. To the best of
our knowledge, the combinability of multiple flows, which can significantly
affect the scheduling performance, has never been systematically analyzed
before. In this article, we first analyze the combinability problem. Then a
non-collision theory based deterministic scheduling (NDS) method is proposed to
achieve ultra-low latency communication for the time-sensitive flows. Moreover,
to improve bandwidth utilization, a dynamic queue scheduling (DQS) method is
presented for the best-effort flows. Experiment results demonstrate that
NDS/DQS can well support deterministic ultra-low latency services and guarantee
efficient bandwidth utilization."
9035,"Next, we further study how C aﬀects the network
connectivity.","The large-scale constraints
      Maximum number of iterations                        limit their global search ability and make them fall into
                                                          local infeasible regions.",Fig.,2022-07-19 05:53:55+00:00,Balancing the trade-off between cost and reliability for wireless sensor networks: a multi-objective optimized deployment method,cs.NI,"['cs.NI', 'cs.NE', 'I.6.3']","[arxiv.Result.Author('Long Chen'), arxiv.Result.Author('Yingying Xu'), arxiv.Result.Author('Fangyi Xu'), arxiv.Result.Author('Qian Hu'), arxiv.Result.Author('Zhenzhou Tang')]","The deployment of the sensor nodes (SNs) always plays a decisive role in the
system performance of wireless sensor networks (WSNs). In this work, we propose
an optimal deployment method for practical heterogeneous WSNs which gives a
deep insight into the trade-off between the reliability and deployment cost.
Specifically, this work aims to provide the optimal deployment of SNs to
maximize the coverage degree and connection degree, and meanwhile minimize the
overall deployment cost. In addition, this work fully considers the
heterogeneity of SNs (i.e. differentiated sensing range and deployment cost)
and three-dimensional (3-D) deployment scenarios. This is a multi-objective
optimization problem, non-convex, multimodal and NP-hard. To solve it, we
develop a novel swarm-based multi-objective optimization algorithm, known as
the competitive multi-objective marine predators algorithm (CMOMPA) whose
performance is verified by comprehensive comparative experiments with ten other
stateof-the-art multi-objective optimization algorithms. The computational
results demonstrate that CMOMPA is superior to others in terms of convergence
and accuracy and shows excellent performance on multimodal multiobjective
optimization problems. Sufficient simulations are also conducted to evaluate
the effectiveness of the CMOMPA based optimal SNs deployment method. The
results show that the optimized deployment can balance the trade-off among
deployment cost, sensing reliability and network reliability. The source code
is available on https://github.com/iNet-WZU/CMOMPA."
9260,"The proposed paradigms would lay the foundation                   long distance entanglement over multiple hops of quantum
                                        for further research on the area of entanglement routing.","The objective of entanglement routing is to establish
                                        ﬂexibility.",repeaters through entanglement swapping [21].,2022-07-19 12:09:03+00:00,A Multiple-Entanglement Routing Framework for Quantum Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Tu N. Nguyen'), arxiv.Result.Author('Kashyab J. Ambarani'), arxiv.Result.Author('Linh Le'), arxiv.Result.Author('Ivan Djordjevic'), arxiv.Result.Author('Zhi-Li Zhang')]","Quantum networks are gaining momentum in finding applications in a wide range
of domains. However, little research has investigated the potential of a
quantum network framework to enable highly reliable communications. The goal of
this work is to investigate and design the multiple-entanglement routing
framework, namely k-entangled routing. In particular, the $k$-entangled routing
will enable k paths connecting all demands (source-destination pairs) in the
network. To design the $k$-entangled routing, we propose two algorithms that
are called Sequential Multi-path Scheduling Algorithm and Min-Cut-based
Multi-path Scheduling Algorithm. In addition, we evaluate the performance of
the proposed algorithms and models through a realistic quantum network
simulator, NetSquid, that models the stochastic processes underlying quantum
communications. The results show that the proposed algorithms (SMPSA and MCSA)
largely enhance the network's traffic flexibility. The proposed paradigms would
lay the foundation for further research on the area of entanglement routing."
9261,"9(c) demonstrates the resource utilization efﬁciency of                                          This work will the lay foundation for further research on
the proposed algorithms by evaluating the qubit depletion ratio                                       “trafﬁc ﬂexibility"" of quantum networks via the k-entangled
while varying the number of nodes (|N |) from 50 to 250.",Fig.,The                                          routing problem.,2022-07-19 12:09:03+00:00,A Multiple-Entanglement Routing Framework for Quantum Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Tu N. Nguyen'), arxiv.Result.Author('Kashyab J. Ambarani'), arxiv.Result.Author('Linh Le'), arxiv.Result.Author('Ivan Djordjevic'), arxiv.Result.Author('Zhi-Li Zhang')]","Quantum networks are gaining momentum in finding applications in a wide range
of domains. However, little research has investigated the potential of a
quantum network framework to enable highly reliable communications. The goal of
this work is to investigate and design the multiple-entanglement routing
framework, namely k-entangled routing. In particular, the $k$-entangled routing
will enable k paths connecting all demands (source-destination pairs) in the
network. To design the $k$-entangled routing, we propose two algorithms that
are called Sequential Multi-path Scheduling Algorithm and Min-Cut-based
Multi-path Scheduling Algorithm. In addition, we evaluate the performance of
the proposed algorithms and models through a realistic quantum network
simulator, NetSquid, that models the stochastic processes underlying quantum
communications. The results show that the proposed algorithms (SMPSA and MCSA)
largely enhance the network's traffic flexibility. The proposed paradigms would
lay the foundation for further research on the area of entanglement routing."
9519,"For
for further research on user attention.","We can observe that the eye movement data
collection technologies are continuously improving and the            3) Insights: From the above datasets, we can observe that
relevant datasets are increasing, which provides strong support    the user’s attention is dispersed to images or videos.","Considering that VR        example, in Fig.",2022-07-31 06:04:15+00:00,Exploring Attention-Aware Network Resource Allocation for Customized Metaverse Services,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Jiacheng Wang'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Jiawen Kang'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Xuemin'), arxiv.Result.Author('Shen'), arxiv.Result.Author('Dong In Kim')]","Emerging with the support of computing and communications technologies,
Metaverse is expected to bring users unprecedented service experiences.
However, the increase in the number of Metaverse users places a heavy demand on
network resources, especially for Metaverse services that are based on
graphical extended reality and require rendering a plethora of virtual objects.
To make efficient use of network resources and improve the
Quality-of-Experience (QoE), we design an attention-aware network resource
allocation scheme to achieve customized Metaverse services. The aim is to
allocate more network resources to virtual objects in which users are more
interested. We first discuss several key techniques related to Metaverse
services, including QoE analysis, eye-tracking, and remote rendering. We then
review existing datasets and propose the user-object-attention level (UOAL)
dataset that contains the ground truth attention of 30 users to 96 objects in
1,000 images. A tutorial on how to use UOAL is presented. With the help of
UOAL, we propose an attention-aware network resource allocation algorithm that
has two steps, i.e., attention prediction and QoE maximization. Specially, we
provide an overview of the designs of two types of attention prediction
methods, i.e., interest-aware and time-aware prediction. By using the predicted
user-object-attention values, network resources such as the rendering capacity
of edge devices can be allocated optimally to maximize the QoE. Finally, we
propose promising research directions related to Metaverse services."
9520,"How-    QoE can then be maximized by allocating network resources
ever, representation and quantiﬁcation of various relationship
features remain challenging and worthy of further study.","Speciﬁcally, the uniform rendering capacity
allocation scheme distributes uniformly the rendering capacity
8

be inferred according to those of his/her close friends.",optimally.,2022-07-31 06:04:15+00:00,Exploring Attention-Aware Network Resource Allocation for Customized Metaverse Services,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Jiacheng Wang'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Jiawen Kang'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Xuemin'), arxiv.Result.Author('Shen'), arxiv.Result.Author('Dong In Kim')]","Emerging with the support of computing and communications technologies,
Metaverse is expected to bring users unprecedented service experiences.
However, the increase in the number of Metaverse users places a heavy demand on
network resources, especially for Metaverse services that are based on
graphical extended reality and require rendering a plethora of virtual objects.
To make efficient use of network resources and improve the
Quality-of-Experience (QoE), we design an attention-aware network resource
allocation scheme to achieve customized Metaverse services. The aim is to
allocate more network resources to virtual objects in which users are more
interested. We first discuss several key techniques related to Metaverse
services, including QoE analysis, eye-tracking, and remote rendering. We then
review existing datasets and propose the user-object-attention level (UOAL)
dataset that contains the ground truth attention of 30 users to 96 objects in
1,000 images. A tutorial on how to use UOAL is presented. With the help of
UOAL, we propose an attention-aware network resource allocation algorithm that
has two steps, i.e., attention prediction and QoE maximization. Specially, we
provide an overview of the designs of two types of attention prediction
methods, i.e., interest-aware and time-aware prediction. By using the predicted
user-object-attention values, network resources such as the rendering capacity
of edge devices can be allocated optimally to maximize the QoE. Finally, we
propose promising research directions related to Metaverse services."
9521,"Furthermore, we discussed open issues that are

B. Semantic Communication in Metaverse Services                  worthy of further research.",optimally.,"It is hoped that this article will

   Metaverse increases the demand for massive data transmis-     provide guidance regarding the consideration of user attention
sion and storage.",2022-07-31 06:04:15+00:00,Exploring Attention-Aware Network Resource Allocation for Customized Metaverse Services,cs.NI,"['cs.NI', 'cs.AI']","[arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Jiacheng Wang'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Jiawen Kang'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Xuemin'), arxiv.Result.Author('Shen'), arxiv.Result.Author('Dong In Kim')]","Emerging with the support of computing and communications technologies,
Metaverse is expected to bring users unprecedented service experiences.
However, the increase in the number of Metaverse users places a heavy demand on
network resources, especially for Metaverse services that are based on
graphical extended reality and require rendering a plethora of virtual objects.
To make efficient use of network resources and improve the
Quality-of-Experience (QoE), we design an attention-aware network resource
allocation scheme to achieve customized Metaverse services. The aim is to
allocate more network resources to virtual objects in which users are more
interested. We first discuss several key techniques related to Metaverse
services, including QoE analysis, eye-tracking, and remote rendering. We then
review existing datasets and propose the user-object-attention level (UOAL)
dataset that contains the ground truth attention of 30 users to 96 objects in
1,000 images. A tutorial on how to use UOAL is presented. With the help of
UOAL, we propose an attention-aware network resource allocation algorithm that
has two steps, i.e., attention prediction and QoE maximization. Specially, we
provide an overview of the designs of two types of attention prediction
methods, i.e., interest-aware and time-aware prediction. By using the predicted
user-object-attention values, network resources such as the rendering capacity
of edge devices can be allocated optimally to maximize the QoE. Finally, we
propose promising research directions related to Metaverse services."
9522,This is worthy of further study.,"The MPCC problem is more complex but more valuable when considering heterogeneous APs

and TDs’ natural number requirements (not just 1).","In addition, this paper notes in

Experiment 4.3 that more APs can decrease the total energy of the system.",2022-07-31 06:31:36+00:00,A Local-Ratio-Based Power Control Approach for Capacitated Access Points in Mobile Edge Computing,cs.NI,"['cs.NI', 'cs.DC']","[arxiv.Result.Author('Qinghui Zhang'), arxiv.Result.Author('Weidong Li'), arxiv.Result.Author('Qian Su'), arxiv.Result.Author('Xuejie Zhang')]","Terminal devices (TDs) connect to networks through access points (APs)
integrated into the edge server. This provides a prerequisite for TDs to upload
tasks to cloud data centers or offload them to edge servers for execution. In
this process, signal coverage, data transmission, and task execution consume
energy, and the energy consumption of signal coverage increases sharply as the
radius increases. Lower power leads to less energy consumption in a given time
segment. Thus, power control for APs is essential for reducing energy
consumption. Our objective is to determine the power assignment for each AP
with same capacity constraints such that all TDs are covered, and the total
power is minimized. We define this problem as a \emph{minimum power capacitated
cover } (MPCC) problem and present a \emph{minimum local ratio} (MLR) power
control approach for this problem to obtain accurate results in polynomial
time. Power assignments are chosen in a sequence of rounds. In each round, we
choose the power assignment that minimizes the ratio of its power to the number
of currently uncovered TDs it contains. In the event of a tie, we pick an
arbitrary power assignment that achieves the minimum ratio. We continue
choosing power assignments until all TDs are covered. Finally, various
experiments verify that this method can outperform another greedy-based way."
9558,"in cloud systems, but has shown some potential also for edge
   Their formats and characteristics are heterogeneous because                 computing [17], even though further research may be needed.","Finally, in [16], the authors
                                                                               distribute the execution of functions following a Function as a
– The raw data are the AV streams generated by the sensors,                    Service (FaaS) approach, which is adopted in production only
   irrespective of whether they have been anonymized or not.","they depend on the physical devices installed (e.g., may use                The solutions mentioned can be gradually incorporated in the
   different codec or sample AV at different rates).",2022-08-01 11:57:58+00:00,Design Guidelines for Apache Kafka Driven Data Management and Distribution in Smart Cities,cs.NI,"['cs.NI', 'cs.ET']","[arxiv.Result.Author('Theofanis P. Raptis'), arxiv.Result.Author('Claudio Cicconetti'), arxiv.Result.Author('Manolis Falelakis'), arxiv.Result.Author('Tassos Kanellos'), arxiv.Result.Author('Tomás Pariente Lobo')]","Smart city management is going through a remarkable transition, in terms of
quality and diversity of services provided to the end-users. The stakeholders
that deliver pervasive applications are now able to address fundamental
challenges in the big data value chain, from data acquisition, data analysis
and processing, data storage and curation, and data visualisation in real
scenarios. Industry 4.0 is pushing this trend forward, demanding for
servitization of products and data, also for the smart cities sector where
humans, sensors and devices are operating in strict collaboration. The data
produced by the ubiquitous devices must be processed quickly to allow the
implementation of reactive services such as situational awareness, video
surveillance and geo-localization, while always ensuring the safety and privacy
of involved citizens. This paper proposes a modular architecture to (i)
leverage innovative technologies for data acquisition, management and
distribution (such as Apache Kafka and Apache NiFi), (ii) develop a multi-layer
engineering solution for revealing valuable and hidden societal knowledge in
smart cities environment, and (iii) tackle the main issues in tasks involving
complex data flows and provide general guidelines to solve them. We derived
some guidelines from an experimental setting performed together with leading
industrial technical departments to accomplish an efficient system for
monitoring and servitization of smart city assets, with a scalable platform
that confirms its usefulness in numerous smart city use cases with different
needs."
9591,"In the future, we will further study the multi-agent training problem for the adaptive

MCW in the network.","This may lead

to huge training diﬃculties.","References

[1] Q. Wu, H. X. Liu, C. Zhang, et al., “Trajectory Protection Schemes Based on a Gravity Mobility Model in IoT,” Electronics, vol.8,
     no.148, 2019.",2022-08-02 07:09:54+00:00,Towards V2I Age-aware Fairness Access: A DQN Based Intelligent Vehicular Node Training and Test Method,cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Qiong Wu'), arxiv.Result.Author('Shuai Shi'), arxiv.Result.Author('Ziyang Wan'), arxiv.Result.Author('Qiang Fan'), arxiv.Result.Author('Pingyi Fan'), arxiv.Result.Author('Cui Zhang')]","Vehicles on the road exchange data with base station (BS) frequently through
vehicle to infrastructure (V2I) communications to ensure the normal use of
vehicular applications, where the IEEE 802.11 distributed coordination function
(DCF) is employed to allocate a minimum contention window (MCW) for channel
access. Each vehicle may change its MCW to achieve more access opportunities at
the expense of others, which results in unfair communication performance.
Moreover, the key access parameters MCW is the privacy information and each
vehicle are not willing to share it with other vehicles. In this uncertain
setting, age of information (AoI) is an important communication metric to
measure the freshness of data, we design an intelligent vehicular node to learn
the dynamic environment and predict the optimal MCW which can make it achieve
age fairness. In order to allocate the optimal MCW for the vehicular node, we
employ a learning algorithm to make a desirable decision by learning from
replay history data. In particular, the algorithm is proposed by extending the
traditional DQN training and testing method. Finally, by comparing with other
methods, it is proved that the proposed DQN method can significantly improve
the age fairness of the intelligent node."
9671,"In fact, there is
room for further research eﬀort for the improvement of security and performance
of BC-SDN also in view of upcoming use cases and (sadly) possible threats.","Several domains and applications would beneﬁt from such an integration, and
both researchers and practitioners working in such domains should continue
exploring BC-SDN integration with the aim of providing advantages such as
management ﬂexibility, scalability and data ﬂow veriﬁcation.","Future avenues that should be investigated are the technical challenges un-
derlining the considered technologies when applied in scenarios having particular
constraints in terms of scalability and computational eﬃciency.",2022-08-03 16:02:51+00:00,"On the Integration of Blockchain and SDN: Overview, Applications, and Future Perspectives",cs.NI,"['cs.NI', 'cs.CR', 'C.2.3; C.2.4']","[arxiv.Result.Author('Anichur Rahman'), arxiv.Result.Author('Antonio Montieri'), arxiv.Result.Author('Dipanjali Kundu'), arxiv.Result.Author('Md. Razaul Karim'), arxiv.Result.Author('Md. Jahidul Islam'), arxiv.Result.Author('Sara Umme'), arxiv.Result.Author('Alfredo Nascita'), arxiv.Result.Author('Antonio Pescapè')]","Blockchain (BC) and Software-Defined Networking (SDN) are leading
technologies which have recently found applications in several network-related
scenarios and have consequently experienced a growing interest in the research
community. Indeed, current networks connect a massive number of objects over
the Internet and in this complex scenario, to ensure security, privacy,
confidentiality, and programmability, the utilization of BC and SDN have been
successfully proposed. In this work, we provide a comprehensive survey
regarding these two recent research trends and review the related
state-of-the-art literature. We first describe the main features of each
technology and discuss their most common and used variants. Furthermore, we
envision the integration of such technologies to jointly take advantage of
these latter efficiently. Indeed, we consider their group-wise utilization --
named BC-SDN -- based on the need for stronger security and privacy.
Additionally, we cover the application fields of these technologies both
individually and combined. Finally, we discuss the open issues of reviewed
research and describe potential directions for future avenues regarding the
integration of BC and SDN.
  To summarize, the contribution of the present survey spans from an overview
of the literature background on BC and SDN to the discussion of the benefits
and limitations of BC-SDN integration in different fields, which also raises
open challenges and possible future avenues examined herein. To the best of our
knowledge, compared to existing surveys, this is the first work that analyzes
the aforementioned aspects in light of a broad BC-SDN integration, with a
specific focus on security and privacy issues in actual utilization scenarios."
9884,"A few areas in which further research on NFTs in business and

management may spread could be product traceability in supply chain management, intellectual

property rights protection, and online trades in virtual worlds.","Applications
of NFTs could be innumerable and in any field where an immutable and traceable identification

                                                                                                                      P a g e 16 | 20
and ownership of assets is needed.","This last application could have

immense potential for NFTs to thrive and give ways of innumerable fields of research.",2022-08-09 15:20:29+00:00,Non-Fungible Tokens in Business and Management -- A Review,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Najam A. Anjum'), arxiv.Result.Author('Mubashir Husain Rehmani')]","Non-Fungible Tokens (NFTs) are a new development in blockchain technology.
News around NFTs is surrounded by skepticism because unrealistically high
prices are being paid online for these NFTs which are in the form of apparently
simple digital arts and photographs. It is not clear if this is a trend, a
hype, a bubble, or a legitimate novel way of holding and trading value. A
literature review of peer-reviewed scholarly studies, performed in the context
of business and management, is presented here. Moreover, we also discuss open
issues, and challenges, and present future research directions. Analysis of
these studies reveal that schools of thoughts are divided on the validity of
this form of digital tokens. On one hand, there is a lot of criticism but on
the other hand, we can find novel business models and applications of NFTs
especially the feature of smart contracts. It can, therefore, be concluded that
NFTs, even if not in their current form, are here to stay and may promise new
ways of protecting digital assets in an immutable and easily traceable form."
9964,"Finally, since the aim           2017.
is to provide a general and realistic reliability model for all
EEC systems, a further study that takes into account multiple         [6] W. Wu, L. He, W. Lin, and R. Mao, “Accelerating federated learning over
orchestrators with multiple tasks or services and the queuing              reliability-agnostic clients in mobile edge computing systems,” IEEE
analysis of the system is of utmost importance.","54–61,
types of tasks and services in the model.","Transactions on Parallel and Distributed Systems, vol.",2022-08-11 13:26:12+00:00,On the Modeling of Reliability in Extreme Edge Computing Systems,cs.NI,['cs.NI'],"[arxiv.Result.Author('Mhd Saria Allahham'), arxiv.Result.Author('Amr Mohamed'), arxiv.Result.Author('Aiman Erbad'), arxiv.Result.Author('Hossam Hassanein')]","Extreme edge computing (EEC) refers to the endmost part of edge computing
wherein computational tasks and edge services are deployed only on extreme edge
devices (EEDs). EEDs are consumer or user-owned devices that offer
computational resources, which may consist of wearable devices, personal mobile
devices, drones, etc. Such devices are opportunistically or naturally present
within the proximity of other user devices. Hence, utilizing EEDs to deploy
edge services or perform computational tasks fulfills the promise of edge
computing of bringing the services and computation as close as possible to the
end-users. However, the lack of knowledge and control over the EEDs
computational resources raises a red flag, since executing the computational
tasks successfully becomes doubtful. To this end, we aim to study the EEDs
randomness from the computational perspective, and how reliable is an EED in
terms of executing the tasks on time. Specifically, we provide a reliability
model for the EEDs that takes into account the probabilistic nature of the
availability of the EEDs' computational resources. Moreover, we study the
reliability of executing different types of computational tasks in EEC systems
that are distributed across the EEDs. Lastly, we carry out experimental results
to analyze the EEDs and the EEC systems' reliability behavior in different
scenarios."
9966,"We make our crawl data available for
   By embedding caching within the gateways, we further stream-           further research on IPFS with the CID:
line performance by aggregating user demand.","for peers to stay online if we observe them to have been online
                                                                          for an extended time period.","Each gateway server
runs two forms of content storage: (i) the default nginx web cache,              bafybeigkawbwjxa325rhul5vodzxb5uof73neszqe6477nilzziw5k5oj4
with a Least Recently Used replacement strategy; and (ii) The IPFS
node store, which holds content manually uploaded by the Web3             4.2 IPFS Gateway Usage Data
and NFT Storage Initiatives.1 These allow third parties to pin con-
tent in the IPFS store of the gateway to make it persistently available.",2022-08-11 15:27:01+00:00,Design and Evaluation of IPFS: A Storage Layer for the Decentralized Web,cs.NI,"['cs.NI', 'C.2.2; C.2.1']","[arxiv.Result.Author('Dennis Trautwein'), arxiv.Result.Author('Aravindh Raman'), arxiv.Result.Author('Gareth Tyson'), arxiv.Result.Author('Ignacio Castro'), arxiv.Result.Author('Will Scott'), arxiv.Result.Author('Moritz Schubotz'), arxiv.Result.Author('Bela Gipp'), arxiv.Result.Author('Yiannis Psaras')]","Recent years have witnessed growing consolidation of web operations. For
example, the majority of web traffic now originates from a few organizations,
and even micro-websites often choose to host on large pre-existing cloud
infrastructures. In response to this, the ""Decentralized Web"" attempts to
distribute ownership and operation of web services more evenly. This paper
describes the design and implementation of the largest and most widely used
Decentralized Web platform - the InterPlanetary File System (IPFS) - an
open-source, content-addressable peer-to-peer network that provides distributed
data storage and delivery. IPFS has millions of daily content retrievals and
already underpins dozens of third-party applications. This paper evaluates the
performance of IPFS by introducing a set of measurement methodologies that
allow us to uncover the characteristics of peers in the IPFS network. We reveal
presence in more than 2700 Autonomous Systems and 152 countries, the majority
of which operate outside large central cloud providers like Amazon or Azure. We
further evaluate IPFS performance, showing that both publication and retrieval
delays are acceptable for a wide range of use cases. Finally, we share our
datasets, experiences and lessons learned."
10017,"They must be cognisant of the            Motivated by the importance of wireless communications in
potential interoperability issues between various IoT options,      Industry 4.0 applications articulated in the previous section,
associated M2M communications standards and capabilities,           and to stimulate further research and innovation in the area of
and support a lifetime of speciﬁc technology choices, whether       wireless smart manufacturing, this paper aims to bridge the ex-
they are open or proprietary solutions.","Contributions
is a constant challenge for system designers trying to keep pace
with the rate of development.","As such, there is a         isting knowledge gap in the area by presenting an overview of
requirement to compile information on the range and capa-           the different wireless protocols that are currently, or soon to be,
bilities of wireless technologies for industrial environments to    available for industrial IoT applications.",2022-08-13 18:07:05+00:00,"Wireless Communications for Smart Manufacturing and Industrial IoT: Existing Technologies, 5G, and Beyond",cs.NI,['cs.NI'],"[arxiv.Result.Author('Md. Noor-A-Rahim'), arxiv.Result.Author('Jobish John'), arxiv.Result.Author('Fadhil Firyaguna'), arxiv.Result.Author('Dimitrios Zorbas'), arxiv.Result.Author('Hafiz Husnain Raza Sherazi'), arxiv.Result.Author('Sergii Kushch'), arxiv.Result.Author('Eoin O Connell'), arxiv.Result.Author('Dirk Pesch'), arxiv.Result.Author('Brendan O Flynn'), arxiv.Result.Author('Martin Hayes'), arxiv.Result.Author('Eddie Armstrong')]","Smart manufacturing is a vision and major driver for change in industrial
environments. The goal of smart manufacturing is to optimize manufacturing
processes through constantly monitoring and adapting processes towards more
efficient and personalised manufacturing. This requires and relies on
technologies for connected machines incorporating a variety of computation,
sensing, actuation, and machine to machine communications modalities. As such,
understanding the change towards smart manufacturing requires knowledge of the
enabling technologies, their applications in real world scenarios and the
communications protocols that they rely on. This paper presents an extensive
review of wireless machine to machine communication protocols currently applied
in manufacturing environments and provides a comprehensive review of the
associated use cases whilst defining their expected impact on the future of
smart manufacturing. Based on the review, we point out a number of open
challenges and directions for future research."
10076,"However, most nodes are reluc-               further research in scalability of blockchain-based TRM
      tant to join this sharing scheme, as 6G does not              in all aspects, which is a non-trivial task.","Massive scale of 6G network demands
      computing tasks.","While ad-
      guarantee the trustworthiness of the nodes in the             vancements in hardware and infrastructure would help
      network.",2022-08-16 06:53:46+00:00,Towards Blockchain-based Trust and Reputation Management for Trustworthy 6G Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Guntur Dharma Putra'), arxiv.Result.Author('Volkan Dedeoglu'), arxiv.Result.Author('Salil S Kanhere'), arxiv.Result.Author('Raja Jurdak')]","6G is envisioned to enable futuristic technologies, which exhibit more
complexities than the previous generations, as it aims to bring connectivity to
a large number of devices, many of which may not be trustworthy. Proper
authentication can protect the network from unauthorized adversaries. However,
it cannot guarantee in situ reliability and trustworthiness of authorized
network nodes, as they can be compromised post-authentication and impede the
reliability and resilience of the network. Trust and Reputation Management
(TRM) is an effective approach to continuously evaluate the trustworthiness of
each participant by collecting and processing evidence of their interactions
with other nodes and the infrastructure. In this article, we argue that
blockchain-based TRM is critical to build trustworthy 6G networks, where
blockchain acts as a decentralized platform for collaboratively managing and
processing interaction evidence with the end goal of quantifying trust. We
present a case study of resource management in 6G networks, where
blockchain-based TRM quantifies and maintains reputation scores by evaluating
fulfillment of resource owner's obligations and facilitating resource consumers
to provide feedback. We also discuss inherent challenges and future directions
for the development of blockchain-based TRM for next-generation 6G networks."
10199,"This importance of SLA assurance mechanism           Besides AI-enabled RAN use cases published in phase II,
can lead to further research.","By combining the AI and Ml models into SLA          RRM functions and radio resource requirements for different
assurance mechanisms through Near-RT and Non-RT RIC, O-           terminals to O-CU and O-DU
RAN Alliance can raise the possibility of SLA slice assurance
being fulﬁlled.",Network slicing process still       there is also virtual RAN use case.,2022-08-19 02:23:02+00:00,"A Survey on Open Radio Access Networks: Challenges, Research Directions, and Open Source Approaches",cs.NI,['cs.NI'],"[arxiv.Result.Author('Wilfrid Azariah'), arxiv.Result.Author('Fransiscus Asisi Bimo'), arxiv.Result.Author('Chih-Wei Lin'), arxiv.Result.Author('Ray-Guang Cheng'), arxiv.Result.Author('Rittwik Jana'), arxiv.Result.Author('Navid Nikaein')]","The open radio access network (RAN) aims to bring openness and intelligence
to the traditional closed and proprietary RAN technology and offer flexibility,
performance improvement, and cost-efficiency in the RAN deployment and
operation. This paper provides a comprehensive survey of the open RAN
development. We briefly summarized the RAN evolution history and the
state-of-the-art technologies applied in open RAN. The open RAN-related
projects, activities, and standardization is then discussed. We then summarize
the challenges and future research directions required to support the open RAN.
Finally, we discuss some solutions to tackle these issues from the open
source's perspective."
10200,"However, ZF implementation still needs
also suggested a dynamic functional split to solve the timing     several further research.",Another work     latency in the FHI.,"Even though ZF can really reduce
requirement of connecting an O-DU or O-RU with a DU               the channel interference and the low latency requirements can
or RU that does not follow O-RAN delay requirements [6].",2022-08-19 02:23:02+00:00,"A Survey on Open Radio Access Networks: Challenges, Research Directions, and Open Source Approaches",cs.NI,['cs.NI'],"[arxiv.Result.Author('Wilfrid Azariah'), arxiv.Result.Author('Fransiscus Asisi Bimo'), arxiv.Result.Author('Chih-Wei Lin'), arxiv.Result.Author('Ray-Guang Cheng'), arxiv.Result.Author('Rittwik Jana'), arxiv.Result.Author('Navid Nikaein')]","The open radio access network (RAN) aims to bring openness and intelligence
to the traditional closed and proprietary RAN technology and offer flexibility,
performance improvement, and cost-efficiency in the RAN deployment and
operation. This paper provides a comprehensive survey of the open RAN
development. We briefly summarized the RAN evolution history and the
state-of-the-art technologies applied in open RAN. The open RAN-related
projects, activities, and standardization is then discussed. We then summarize
the challenges and future research directions required to support the open RAN.
Finally, we discuss some solutions to tackle these issues from the open
source's perspective."
10201,"should be seen as a big challenge, and this challenge should
be discussed in further research.","Therefore, a secure open RAN       networks, and ML system threats.","Focusing on O-RAN system, there are a total of 35 threats
                                                                  [103].",2022-08-19 02:23:02+00:00,"A Survey on Open Radio Access Networks: Challenges, Research Directions, and Open Source Approaches",cs.NI,['cs.NI'],"[arxiv.Result.Author('Wilfrid Azariah'), arxiv.Result.Author('Fransiscus Asisi Bimo'), arxiv.Result.Author('Chih-Wei Lin'), arxiv.Result.Author('Ray-Guang Cheng'), arxiv.Result.Author('Rittwik Jana'), arxiv.Result.Author('Navid Nikaein')]","The open radio access network (RAN) aims to bring openness and intelligence
to the traditional closed and proprietary RAN technology and offer flexibility,
performance improvement, and cost-efficiency in the RAN deployment and
operation. This paper provides a comprehensive survey of the open RAN
development. We briefly summarized the RAN evolution history and the
state-of-the-art technologies applied in open RAN. The open RAN-related
projects, activities, and standardization is then discussed. We then summarize
the challenges and future research directions required to support the open RAN.
Finally, we discuss some solutions to tackle these issues from the open
source's perspective."
10258,"[29]  √       ×  √  √  ×  basic terminologies, solutions and

                          architectures used in UAV-MEC

                          networks for offloading

[21]  √       √  √  √  ×  UAV-enabled MEC solutions in

                          computation offloading

[30]  √       √  ×  ×  ×  edge AI on the UAV

                          technical aspects

This paper √  √  √  √  √  Intelligent computation offloading and

                          price strategies in UAV-MEC

   However, further study and debate are required before using UAV-MEC to assist cellular networks for computation offloading
using AI, and dynamic pricing strategies (using AI methods) for resource allocation.","Existing surveys on computation offloading in UAV-MEC

UAV     UAV      AI  Computation Offloading Price for Description
survey  enabled
[23]    MEC      solution offloading challenges in UAV-MEC
        √
[24]                    UAV-MEC offloading
[25]    √
[26]    √        √   ×  ×  ×                                understanding of UAV-aided networks
        √
[27]                                                        architecture, benefits, challenges, and
[28]    √
        √                                                   various game theoretical solutions

                 √   √  √  ×                                intelligent UAV computing offloading to

                                                            enable 6G networks

                 √   ×  ×  ×                                surveys game-theoretic and machine

                                                            learning algorithms in UAV networks

                 √   √  √  ×                                describe UAV-RAN architecture and

                                                            fundamental features for the development of

                                                            6G networks

                 ×   √  √  ×                                3GPP standardization and emphasizes socio-

                                                            economic concerns in UAV networks

                 √   √  √  ×                                UAV-MEC intelligent computing with

                                                            various optimization objectives.","This paper offers a comprehensive overview
of the current state of UAV-MEC-assisted cellular networks.",2022-08-22 06:14:20+00:00,A Survey on Intelligent Computation Offloading and Pricing Strategy in UAV-Enabled MEC Network: Challenges and Research Directions,cs.NI,"['cs.NI', 'cs.DC']","[arxiv.Result.Author('Asrar Ahmed Baktayan'), arxiv.Result.Author('Ibrahim Ahmed Al-Baltah')]","The Mobile Network Operator (MNO) must select how to delegate Mobile Device
(MD) queries to its Mobile Edge Computing (MEC) server in order to maximize the
overall benefit of admitted requests with varying latency needs. Unmanned
Aerial Vehicles (UAVs) and Artificial Intelligent (AI) can increase MNO
performance because of their flexibility in deployment, high mobility of UAV,
and efficiency of AI algorithms. There is a trade-off between the cost incurred
by the MD and the profit received by the MNO. Intelligent computing offloading
to UAV-enabled MEC, on the other hand, is a promising way to bridge the gap
between MDs' limited processing resources, as well as the intelligent
algorithms that are utilized for computation offloading in the UAV-MEC network
and the high computing demands of upcoming applications. This study looks at
some of the research on the benefits of computation offloading process in the
UAV-MEC network, as well as the intelligent models that are utilized for
computation offloading. In addition, this article examines several intelligent
pricing techniques in different structures in the UAV-MEC network. Finally,
this work highlights some important open research issues and future research
directions of Artificial Intelligent (AI) in computation offloading and
applying intelligent pricing strategies in the UAV-MEC network."
10259,"Although computation offloading in SDN linked
UAV-MEC is still in its early phases, further study is needed to address several outstanding challenges, particularly in offloading
for both centralized and distributed SDNs, taking into consideration new characteristics such as data timeliness and
authentication [215].","To
offload to SDN, the computational and control operations must be segregated.","Furthermore, several situations in the mmWave 5G setting would almost certainly include buildings as well
as wind perturbations.",2022-08-22 06:14:20+00:00,A Survey on Intelligent Computation Offloading and Pricing Strategy in UAV-Enabled MEC Network: Challenges and Research Directions,cs.NI,"['cs.NI', 'cs.DC']","[arxiv.Result.Author('Asrar Ahmed Baktayan'), arxiv.Result.Author('Ibrahim Ahmed Al-Baltah')]","The Mobile Network Operator (MNO) must select how to delegate Mobile Device
(MD) queries to its Mobile Edge Computing (MEC) server in order to maximize the
overall benefit of admitted requests with varying latency needs. Unmanned
Aerial Vehicles (UAVs) and Artificial Intelligent (AI) can increase MNO
performance because of their flexibility in deployment, high mobility of UAV,
and efficiency of AI algorithms. There is a trade-off between the cost incurred
by the MD and the profit received by the MNO. Intelligent computing offloading
to UAV-enabled MEC, on the other hand, is a promising way to bridge the gap
between MDs' limited processing resources, as well as the intelligent
algorithms that are utilized for computation offloading in the UAV-MEC network
and the high computing demands of upcoming applications. This study looks at
some of the research on the benefits of computation offloading process in the
UAV-MEC network, as well as the intelligent models that are utilized for
computation offloading. In addition, this article examines several intelligent
pricing techniques in different structures in the UAV-MEC network. Finally,
this work highlights some important open research issues and future research
directions of Artificial Intelligent (AI) in computation offloading and
applying intelligent pricing strategies in the UAV-MEC network."
10260,"The Complexity of dynamic pricing for the computation offloading process with multi-objective
functions in UAV-MEC is challenging and this issue still needs further study.","Even though there are
many MDs with more than two offloading optimization metrics and few works that are studied offloading with mobility of
both multi-UAV and MDs.","6 Conclusion

   In UAV-MEC networks, computation offloading plays a key role in cooperative and collaborative network operations.",2022-08-22 06:14:20+00:00,A Survey on Intelligent Computation Offloading and Pricing Strategy in UAV-Enabled MEC Network: Challenges and Research Directions,cs.NI,"['cs.NI', 'cs.DC']","[arxiv.Result.Author('Asrar Ahmed Baktayan'), arxiv.Result.Author('Ibrahim Ahmed Al-Baltah')]","The Mobile Network Operator (MNO) must select how to delegate Mobile Device
(MD) queries to its Mobile Edge Computing (MEC) server in order to maximize the
overall benefit of admitted requests with varying latency needs. Unmanned
Aerial Vehicles (UAVs) and Artificial Intelligent (AI) can increase MNO
performance because of their flexibility in deployment, high mobility of UAV,
and efficiency of AI algorithms. There is a trade-off between the cost incurred
by the MD and the profit received by the MNO. Intelligent computing offloading
to UAV-enabled MEC, on the other hand, is a promising way to bridge the gap
between MDs' limited processing resources, as well as the intelligent
algorithms that are utilized for computation offloading in the UAV-MEC network
and the high computing demands of upcoming applications. This study looks at
some of the research on the benefits of computation offloading process in the
UAV-MEC network, as well as the intelligent models that are utilized for
computation offloading. In addition, this article examines several intelligent
pricing techniques in different structures in the UAV-MEC network. Finally,
this work highlights some important open research issues and future research
directions of Artificial Intelligent (AI) in computation offloading and
applying intelligent pricing strategies in the UAV-MEC network."
10471,"To this end, we have made OSF publicly available as a                                                  [12] O. Landsiedel et al., “Chaos: Versatile and Efﬁcient all-to-all Data
platform for further research.","of the 10th IPSN Conf., 2011.","In support of this, we have                                                      Sharing and In-Network Processing at Scale,” in Proc.",2022-08-26 19:40:29+00:00,OSF: An Open-Source Framework for Synchronous Flooding over Multiple Physical Layers,cs.NI,['cs.NI'],"[arxiv.Result.Author('Michael Baddeley'), arxiv.Result.Author('Yevgen Gyl'), arxiv.Result.Author('Markus Schuss'), arxiv.Result.Author('Xiaoyuan Ma'), arxiv.Result.Author('Carlo Alberto Boano')]","Flooding protocols based on concurrent transmissions are regarded as the most
reliable way to collect or disseminate data across a multi-hop low-power
wireless mesh network. Recent works have shown that such protocols are
effective for narrowband communication not only over IEEE 802.15.4, but also
over the BLE 5 physical layers (PHYs). However, to date, existing literature
has only built synchronous flooding solutions on top of a single PHY, and there
has been no attempt to leverage different PHYs at runtime to increase
performance. This paper fills this gap and presents OSF, an open-source
framework that enables the design of multi-PHY synchronous flooding solutions
thanks to a novel radio driver and middle-ware architecture capable of
dynamically switching the underlying physical layer. This allows exploitation
of the specific benefits of each PHY (e.g., higher data-rate, increased
robustness) on-demand during each flood, increasing performance. We tailor OSF
to the off-the-shelf nRF52840 platform, and showcase its benefits by comparing
single-PHY and multi-PHY synchronous flooding solutions on a real-world
testbed."
10574,"Using the result of this survey to not only find
the similarities and differences between various elements of cloud computing but also to propose some
topics to look into for further research.","In
this paper, we managed a comparison of cloud service features and after the comparison, It's simple to
select a certain cloud service from the available features by comparison with three selective cloud
providers like Amazon, Microsoft Azure and Digital Ocean.","KEYWORDS

Cloud Computing, Trending Cloud Providers, cloud Service feature.",2022-08-30 18:17:07+00:00,A Comparative Study On Three Selective Cloud Providers,cs.NI,['cs.NI'],"[arxiv.Result.Author('Rehnuma Tasnim'), arxiv.Result.Author('Afrin Akter Mim'), arxiv.Result.Author('Salman Hasan Mim'), arxiv.Result.Author('Professor Dr. Md. Ismail Jabiullah')]","Cloud Computing means a place where we can store our valuable information of
data and access the computing and networking services following the
pay-as-you-go method without a physical environment. In the present day, cloud
computing offers us powerful computing and storage, high availability and
security, instant accessibility and adaptation, guaranteed scalability and
interoperability, and cost and time effectiveness. Cloud computing has three
platforms (IaaS, PaaS, SaaS) with exclusive features which assure to make easy
their work for a client, Organization or Trade to build up any kind of IT
business. In this paper, we managed a comparison of cloud service features and
after the comparison, It's simple to select a certain cloud service from the
available features by comparison with three selective cloud providers like
Amazon, Microsoft Azure and Digital Ocean. Using the result of this survey to
not only find the similarities and differences between various elements of
cloud computing but also to propose some topics to look into for further
research."
10750,several open problems for further research.,ronment and operate correctly on previously unseen inputs.,"In this direction, meta-learning, and the combination of DRL         Problem 1: The slow progress of V2X deployment and
and Generative Adversarial Network (GAN) are emerging
approaches, given their strength in learning from massive         the lack of uniﬁed standards for many V2X technologies
inputs and automatically optimizing the decisions in inter-       remain an issue.",2022-09-03 07:21:06+00:00,Towards the Age of Intelligent Vehicular Networks for Connected and Autonomous Vehicles in 6G,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Van-Linh Nguyen'), arxiv.Result.Author('Ren-Hung Hwang'), arxiv.Result.Author('Po-Ching Lin'), arxiv.Result.Author('Abhishek Vyas'), arxiv.Result.Author('Van-Tao Nguyen')]","Twenty-two years after the advent of the first-generation vehicular network,
i.e., dedicated short-range communications (DSRC) standard/IEEE 802.11p, the
vehicular technology market has become very competitive with a new player,
Cellular Vehicle-to-Everything (C-V2X). Currently, C-V2X technology likely
dominates the race because of the big advantages of comprehensive coverage and
high throughput/reliability. Meanwhile, DSRC-based technologies are struggling
to survive and rebound with many hopes betting on the success of the
second-generation standard, IEEE P802.11bd. While the standards battle to
attract automotive makers and dominate the commercial market landing, the
research community has started thinking about the shape of the next-generation
vehicular networks. This article details the state-of-the-art progress of
vehicular networks, particularly the cellular V2X-related technologies in
specific use cases, compared to the features of the current generation. Through
the typical examples, we also highlight why 5G is inadequate to provide the
best connectivity for vehicular applications, and then 6G technologies can fill
up the vacancy."
10751,"The adversarial     Meanwhile, optimizing 6G technologies for V2X, e.g., THz-
attack means an attacker intentionally contaminates the input    NOMA, aerial-assisted vehicular networks will be the top
collection (inject incorrectly labeled data), algorithm (using   promising techniques and important topics for further research.",the favorite targets of adversarial attacks.,"learning weights designed by attackers), or training models
(use an alternative model to replace the deployed model)                                      REFERENCES
to mislead vehicles’ AI systems.",2022-09-03 07:21:06+00:00,Towards the Age of Intelligent Vehicular Networks for Connected and Autonomous Vehicles in 6G,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Van-Linh Nguyen'), arxiv.Result.Author('Ren-Hung Hwang'), arxiv.Result.Author('Po-Ching Lin'), arxiv.Result.Author('Abhishek Vyas'), arxiv.Result.Author('Van-Tao Nguyen')]","Twenty-two years after the advent of the first-generation vehicular network,
i.e., dedicated short-range communications (DSRC) standard/IEEE 802.11p, the
vehicular technology market has become very competitive with a new player,
Cellular Vehicle-to-Everything (C-V2X). Currently, C-V2X technology likely
dominates the race because of the big advantages of comprehensive coverage and
high throughput/reliability. Meanwhile, DSRC-based technologies are struggling
to survive and rebound with many hopes betting on the success of the
second-generation standard, IEEE P802.11bd. While the standards battle to
attract automotive makers and dominate the commercial market landing, the
research community has started thinking about the shape of the next-generation
vehicular networks. This article details the state-of-the-art progress of
vehicular networks, particularly the cellular V2X-related technologies in
specific use cases, compared to the features of the current generation. Through
the typical examples, we also highlight why 5G is inadequate to provide the
best connectivity for vehicular applications, and then 6G technologies can fill
up the vacancy."
10776,open issues which can guide the further research on this topic.,"In this section, we discuss research challenges and         the new network state.",A.,2022-09-05 07:08:42+00:00,Towards Zero Touch Networks: From the Perspective of Hierarchical Language Systems,cs.NI,['cs.NI'],"[arxiv.Result.Author('Guozhi Lin'), arxiv.Result.Author('Jingguo Ge'), arxiv.Result.Author('Yulei Wu')]","With ever-increasing complexity and dynamicity of communication networks,
intelligent network operation and maintenance has become more important to
network operators. With the fast development of artificial intelligence,
concepts such as ""Zero Touch"", ""Intent-based"", ""Knowledge-defined"" and
""Self-driving"" networks have become well-known in networking community for a
great vision of making networks automatically manageable and responsive to user
demands. This article discusses how to achieve Zero Touch Networks from the
perspective of language-like systems. We propose a novel hierarchical
`language' framework dedicated for networks to enable the Zero Touch Network,
which covers from symbolizing network components, a unified framework for
understanding network systems, to the logical description with network
semantics. A case study based on the proposed language framework is provided.
Finally, we discuss the challenges and open issues of intelligence models for
zero touch networks."
10777,"In addition,       community for carrying out further research.","At last, we provided a list of
application, such as reducing the transmission delay of the
application, but it may not be able to meet the value pursuit      research challenges and open issues that can be useful to the
of the entire network at this time, such as requiring the
performance of all applications to be balanced.","the value theory embedded in the intelligent representation
model is the basis for ensuring that the behavior of zero touch                                 REFERENCES
networks is credible.",2022-09-05 07:08:42+00:00,Towards Zero Touch Networks: From the Perspective of Hierarchical Language Systems,cs.NI,['cs.NI'],"[arxiv.Result.Author('Guozhi Lin'), arxiv.Result.Author('Jingguo Ge'), arxiv.Result.Author('Yulei Wu')]","With ever-increasing complexity and dynamicity of communication networks,
intelligent network operation and maintenance has become more important to
network operators. With the fast development of artificial intelligence,
concepts such as ""Zero Touch"", ""Intent-based"", ""Knowledge-defined"" and
""Self-driving"" networks have become well-known in networking community for a
great vision of making networks automatically manageable and responsive to user
demands. This article discusses how to achieve Zero Touch Networks from the
perspective of language-like systems. We propose a novel hierarchical
`language' framework dedicated for networks to enable the Zero Touch Network,
which covers from symbolizing network components, a unified framework for
understanding network systems, to the logical description with network
semantics. A case study based on the proposed language framework is provided.
Finally, we discuss the challenges and open issues of intelligence models for
zero touch networks."
10784,"Furthermore, in a service chain of multiple VNFs          theory and practice and serve as a tool for further study of
Element Management System (EMS) orchestrate and manage             IEEE 802.11 p in both simulation-based and ﬁeld operational
VNFs life-cycle through the VNF manager.","This provides seamless switching between
and authorizes the NFVI resource requested from the VNF            experimentation and simulation that bridge the gap between
manager.",tests for novel physical layer solution.,2022-09-05 10:42:51+00:00,"A Survey on Open-Source-Defined Wireless Networks: Framework, Key Technology, and Implementation",cs.NI,['cs.NI'],"[arxiv.Result.Author('Liqiang Zhao'), arxiv.Result.Author('Muhammad Muhammad Bala'), arxiv.Result.Author('Wu Gang'), arxiv.Result.Author('Pan Chengkang'), arxiv.Result.Author('Yuan Yannan'), arxiv.Result.Author('Tian Zhigang'), arxiv.Result.Author('Yu-Chee Tseng'), arxiv.Result.Author('Chen Xiang'), arxiv.Result.Author('Bin Shen'), arxiv.Result.Author('Chih-Lin I')]","The realization of open-source-defined wireless networks in the
telecommunication domain is accomplished through the fifth-generation network
(5G). In contrast to its predecessors (3G and 4G), the 5G network can support a
wide variety of heterogeneous use cases with challenging requirements from both
the Internet and the Internet of Things (IoT). The future sixth-generation (6G)
network will not only extend 5G capabilities but also innovate new
functionalities to address emerging academic and engineering challenges. The
research community has identified these challenges could be overcome by
open-source-defined wireless networks, which is based on open-source software
and hardware. In this survey, we present an overview of different aspects of
open-source-defined wireless networks, comprising motivation, frameworks, key
technologies, and implementation. We start by introducing the motivation and
explore several frameworks with classification into three different categories:
black-box, grey-box, and white-box. We review research efforts related to
open-source-defined Core Network (CN), Radio Access Network (RAN), Multi-access
Edge Computing (MEC), the capabilities of security threats, open-source
hardware, and various implementations, including testbeds. The last but most
important in this survey, lessons learned, future research direction, open
research issues, pitfalls, and limitations of existing surveys on open-source
wireless networks are included to motivate and encourage future research."
10887,"This work sets the scene for further research activities
                                       than centralizing computation in a cloud platform, since this                  on the emerging topic of in-network computing at the edge
                                       keeps processing close to where data are actually used, which                  through serverless/FaaS, as discussed in Sec.",IV.,"V.
                                       can be also an additional beneﬁt in terms of privacy [4].",2022-09-07 08:07:49+00:00,In-Network Computing With Function as a Service at the Edge,cs.NI,['cs.NI'],"[arxiv.Result.Author('Claudio Cicconetti'), arxiv.Result.Author('Marco Conti'), arxiv.Result.Author('Andrea Passarella')]","Offloading computation from user devices to nodes with processing
capabilities at the edge of the network is a major trend in today's
network/service architectures. At the same time, serverless computing has
gained a huge traction among the cloud computing technologies and has, thus,
promoted the adoption of Function-as-a-Service (FaaS). The latter has some
characteristics that make it generally suitable to edge applications, except
for its cumbersome support of stateful applications. This work is set to
provide a broad view on the options available for supporting stateful FaaS,
which are distilled into four reference execution models that differ on where
the state resides. While further investigation is needed to advance our
understanding of the opportunities offered by in-network computing through
stateful FaaS, initial insights are provided by means of a qualitative analysis
of the four alternatives and their quantitative comparison in a simulator."
10888,"The four models have                                 [12] Mohammad S. Aslanpour, Adel N. Toosi, Claudio Cicconetti, Bahman
different implications on the architecture and protocols, and we                                  Javadi, Peter Sbarski, Davide Taibi, Marcos Assuncao, Sukhpal Singh
envisage that further research is required to determine which                                     Gill, Raj K Gaire, and Schahram Dustdar.","Communications of the ACM, 64(5):76–84, 2021.
container; and, in-client, where the client’s device is the
sole owner of the application’s state.","Serverless Edge Computing:
one is best for a given deployment or set of edge applications.",2022-09-07 08:07:49+00:00,In-Network Computing With Function as a Service at the Edge,cs.NI,['cs.NI'],"[arxiv.Result.Author('Claudio Cicconetti'), arxiv.Result.Author('Marco Conti'), arxiv.Result.Author('Andrea Passarella')]","Offloading computation from user devices to nodes with processing
capabilities at the edge of the network is a major trend in today's
network/service architectures. At the same time, serverless computing has
gained a huge traction among the cloud computing technologies and has, thus,
promoted the adoption of Function-as-a-Service (FaaS). The latter has some
characteristics that make it generally suitable to edge applications, except
for its cumbersome support of stateful applications. This work is set to
provide a broad view on the options available for supporting stateful FaaS,
which are distilled into four reference execution models that differ on where
the state resides. While further investigation is needed to advance our
understanding of the opportunities offered by in-network computing through
stateful FaaS, initial insights are provided by means of a qualitative analysis
of the four alternatives and their quantitative comparison in a simulator."
11042,"It also discusses            We summarize the functionality of each module while high-
key directions for further research and development for IOTA.",ables affecting the new consensus algorithm.,lighting its beneﬁts to the overall protocol and IoT networks.,2022-09-11 23:25:12+00:00,"IOTA Tangle 2.0: Toward a Scalable, Decentralized, Smart, and Autonomous IoT Ecosystem",cs.NI,['cs.NI'],"[arxiv.Result.Author('Nathan Sealey'), arxiv.Result.Author('Adnan Aijaz'), arxiv.Result.Author('Ben Holden')]","IOTA Tangle is a distributed ledger technology (DLT), primarily designed for
Internet-of-Things (IoT) networks and applications. IOTA Tangle utilizes a
direct acyclic graph (DAG) structure for the ledger, with its protocol offering
features attractive to the IoT domain, over most blockchain alternatives, such
as feeless transactions, higher achievable transactions per second (TPS), and
lower energy consumption. The original IOTA implementation relied on a
bootstrap centralized coordinator solution for consensus which limited its
degree of decentralization and scalability. This concern, alongside other
limitations to its adoption, such as lack of smart contracts, are being
addressed with the release of IOTA 2.0. This update brings with it significant
changes in order to remove the coordinator and achieve a scalable decentralized
solution. To this end, this paper provides a technical overview of the key
features of IOTA 2.0 while discussing their relevance and benefits for the
wider IoT ecosystem. The paper also provides performance insights and future
research directions for IOTA 2.0."
11055,"Speciﬁcally, each RL agent learns its own pol-
further research efforts, as all relevant works converged to      icy by observing actual trafﬁc ﬂuctuations and appropriately
clear conclusions regarding the advantages of predictive ser-     penalizing or rewarding SA actions targeting on striking a
vice provisioning in both proactive and adaptive networks.","Each agent, representing a pre-computed path
                                                                  between a source-destination (s−d) pair, independently learns
    The existing literature provides a stepping stone towards     a SA policy.",balance between over- and under-provisioning.,2022-09-12 08:29:45+00:00,Survey on Machine Learning for Traffic-Driven Service Provisioning in Optical Networks,cs.NI,['cs.NI'],"[arxiv.Result.Author('Tania Panayiotou'), arxiv.Result.Author('Maria Michalopoulou'), arxiv.Result.Author('Georgios Ellinas')]","The unprecedented growth of the global Internet traffic, coupled with the
large spatio-temporal fluctuations that create, to some extent, predictable
tidal traffic conditions, are motivating the evolution from reactive to
proactive and eventually towards adaptive optical networks. In these networks,
traffic-driven service provisioning can address the problem of network
over-provisioning and better adapt to traffic variations, while keeping the
quality-of-service at the required levels. Such an approach will reduce network
resource over-provisioning and thus reduce the total network cost. This survey
provides a comprehensive review of the state of the art on machine learning
(ML)-based techniques at the optical layer for traffic-driven service
provisioning. The evolution of service provisioning in optical networks is
initially presented, followed by an overview of the ML techniques utilized for
traffic-driven service provisioning. ML-aided service provisioning approaches
are presented in detail, including predictive and prescriptive service
provisioning frameworks in proactive and adaptive networks. For all techniques
outlined, a discussion on their limitations, research challenges, and potential
opportunities is also presented."
11111,"We can see that Co-AP              Now, we further study the scenarios with more sensors
has a much lower average AoI than single-AP, thanks to the          and the average AoI of the whole network in Fig.","9 (the SNR at AP2
is larger than that at AP1 by 1dB).",10(a).,2022-09-13 04:10:21+00:00,Improving Information Freshness via Backbone-Assisted Cooperative Access Points,cs.NI,['cs.NI'],"[arxiv.Result.Author('Haoyuan Pan'), arxiv.Result.Author('Yu Zhou'), arxiv.Result.Author('Tse-Tin Chan'), arxiv.Result.Author('Ming Tang'), arxiv.Result.Author('Jianqiang Li'), arxiv.Result.Author('Zhihua Du')]","Information freshness, characterized by age of information (AoI), is
important for sensor applications involving timely status updates. In many
cases, the wireless signals from one sensor can be received by multiple access
points (APs). This paper investigates the average AoI for cooperative APs, in
which they can share information through a wired backbone network. We first
study a basic backbone-assisted COoperative AP (Co-AP) system where APs share
only decoded packets. Experimental results on software-defined radios (SDR)
indicate that Co-AP significantly improves the average AoI performance over a
single-AP system. Next, we investigate an improved Co-AP system, called
Soft-Co-AP. In addition to sharing decoded packets, Soft-Co-AP shares and
collects soft information of packets that the APs fail to decode for further
joint decoding. A critical issue in Soft-Co-AP is determining the number of
quantization bits that represent the soft information (each soft bit) shared
over the backbone. While more quantization bits per soft bit improves the joint
decoding performance, it leads to higher backbone delay. We experimentally
study the average AoI of Soft-Co-AP by evaluating the tradeoff between the
backbone delay and the number of quantization bits. SDR experiments show that
when the number of sensors is large, Soft-Co-AP further reduces the average AoI
by 12% compared with Co-AP. Interestingly, good average AoI performance is
usually achieved when the number of quantization bits per soft bit is neither
too large nor too small."
11183,"provide ultra-low latency, reliable, and ubiquitous intelligent
services, further research to enhance current edge computing                                                       III.","In future edge computing, the cloud still exists
                                                                                             but will not play the dominant role in managing all the edge
   To better support emerging advanced new applications and                                  and end nodes.","EAAS FRAMEWORK
is needed.",2022-09-14 13:04:48+00:00,EaaS: A Service-Oriented Edge Computing Framework Towards Distributed Intelligence,cs.NI,['cs.NI'],"[arxiv.Result.Author('Mingjin Zhang'), arxiv.Result.Author('Jiannong Cao'), arxiv.Result.Author('Yuvraj Sahni'), arxiv.Result.Author('Qianyi Chen'), arxiv.Result.Author('Shan Jiang'), arxiv.Result.Author('Tao Wu')]","Edge computing has become a popular paradigm where services and applications
are deployed at the network edge closer to the data sources. It provides
applications with outstanding benefits, including reduced response latency and
enhanced privacy protection. For emerging advanced applications, such as
autonomous vehicles, industrial IoT, and metaverse, further research is needed.
This is because such applications demand ultra-low latency, hyper-connectivity,
and dynamic and reliable service provision, while existing approaches are
inadequate to address the new challenges. Hence, we envision that the future
edge computing is moving towards distributed intelligence, where heterogeneous
edge nodes collaborate to provide services in large-scale and geo-distributed
edge infrastructure. We thereby propose Edge-as-a-Service (EaaS) to enable
distributed intelligence. EaaS jointly manages large-scale cross-node edge
resources and facilitates edge autonomy, edge-to-edge collaboration, and
resource elasticity. These features enable flexible deployment of services and
ubiquitous computation and intelligence. We first give an overview of existing
edge computing studies and discuss their limitations to articulate the
motivation for proposing EaaS. Then, we describe the details of EaaS, including
the physical architecture, proposed software framework, and benefits of EaaS.
Various application scenarios, such as real-time video surveillance, smart
building, and metaverse, are presented to illustrate the significance and
potential of EaaS. Finally, we discuss several challenging issues of EaaS to
inspire more research towards this new edge computing framework."
11407,necessary to provide a high-quality service for further research.,"This
sponses contain for example incorrect status codes or referrals to        shows that frequent change is visible, and an up-to-date service is
localhost.","6
Rusty Clusters?",2022-09-19 19:29:34+00:00,Rusty Clusters? Dusting an IPv6 Research Foundation,cs.NI,['cs.NI'],"[arxiv.Result.Author('Johannes Zirngibl'), arxiv.Result.Author('Lion Steger'), arxiv.Result.Author('Patrick Sattler'), arxiv.Result.Author('Oliver Gasser'), arxiv.Result.Author('Georg Carle')]","The long-running IPv6 Hitlist service is an important foundation for IPv6
measurement studies. It helps to overcome infeasible, complete address space
scans by collecting valuable, unbiased IPv6 address candidates and regularly
testing their responsiveness. However, the Internet itself is a quickly
changing ecosystem that can affect longrunning services, potentially inducing
biases and obscurities into ongoing data collection means. Frequent analyses
but also updates are necessary to enable a valuable service to the community.
  In this paper, we show that the existing hitlist is highly impacted by the
Great Firewall of China, and we offer a cleaned view on the development of
responsive addresses. While the accumulated input shows an increasing bias
towards some networks, the cleaned set of responsive addresses is well
distributed and shows a steady increase.
  Although it is a best practice to remove aliased prefixes from IPv6 hitlists,
we show that this also removes major content delivery networks. More than 98%
of all IPv6 addresses announced by Fastly were labeled as aliased and
Cloudflare prefixes hosting more than 10M domains were excluded. Depending on
the hitlist usage, e.g., higher layer protocol scans, inclusion of addresses
from these providers can be valuable.
  Lastly, we evaluate different new address candidate sources, including target
generation algorithms to improve the coverage of the current IPv6 Hitlist. We
show that a combination of different methodologies is able to identify 5.6M
new, responsive addresses. This accounts for an increase by 174% and combined
with the current IPv6 Hitlist, we identify 8.8M responsive addresses."
11445,"Also, recent
[18], further research on developing ﬂexible and intelligent           advancements in UAV trajectory optimization for maritime
maritime networks is required.","have been industrial initiatives on both terrestrial and satellite  • The physical-layer, resource management, and cloud/edge
segments, with broadband satellite coverage and long-distance          UAV-aided algorithms for maritime communications are
shore-to-vessel communications using cellular standards [16]–          categorized based on their performance targets.","Towards this end, exploiting            applications are thoroughly discussed.",2022-09-20 10:33:37+00:00,"A Survey on UAV-Aided Maritime Communications: Deployment Considerations, Applications, and Future Challenges",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('Nikolaos Nomikos'), arxiv.Result.Author('Panagiotis K. Gkonis'), arxiv.Result.Author('Petros S. Bithas'), arxiv.Result.Author('Panagiotis Trakadas')]","Maritime activities represent a major domain of economic growth with several
emerging maritime Internet of Things use cases, such as smart ports, autonomous
navigation, and ocean monitoring systems. The major enabler for this exciting
ecosystem is the provision of broadband, low-delay, and reliable wireless
coverage to the ever-increasing number of vessels, buoys, platforms, sensors,
and actuators. Towards this end, the integration of unmanned aerial vehicles
(UAVs) in maritime communications introduces an aerial dimension to wireless
connectivity going above and beyond current deployments, which are mainly
relying on shore-based base stations with limited coverage and satellite links
with high latency. Considering the potential of UAV-aided wireless
communications, this survey presents the state-of-the-art in UAV-aided maritime
communications, which, in general, are based on both conventional optimization
and machine-learning-aided approaches. More specifically, relevant UAV-based
network architectures are discussed together with the role of their building
blocks. Then, physical-layer, resource management, and cloud/edge computing and
caching UAV-aided solutions in maritime environments are discussed and grouped
based on their performance targets. Moreover, as UAVs are characterized by
flexible deployment with high re-positioning capabilities, studies on UAV
trajectory optimization for maritime applications are thoroughly discussed. In
addition, aiming at shedding light on the current status of real-world
deployments, experimental studies on UAV-aided maritime communications are
presented and implementation details are given. Finally, several important open
issues in the area of UAV-aided maritime communications are given, related to
the integration of sixth generation (6G) advancements."
11739,"-6                                                                   As the A2C algorithm performs the best in each network
                  0 0.5 1 1.5 2 2.5 3 3.5 4                                       setting, we further study other metrics under the A2C frame-
                                                                                  work.","-log(|reward|)      DDQN PPO

                -4                                                                performs much better than vanilla DQN, as we can see that
                                                                                  it obtained a satisfactory reward in the end under the network
                -5                                                                setting with the smallest UE count.",Fig.,2022-09-27 14:28:04+00:00,Resource Allocation for Mobile Metaverse with the Internet of Vehicles over 6G Wireless Communications: A Deep Reinforcement Learning Approach,cs.NI,"['cs.NI', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Terence Jie Chua'), arxiv.Result.Author('Wenhan Yu'), arxiv.Result.Author('Jun Zhao')]","Improving the interactivity and interconnectivity between people is one of
the highlights of the Metaverse. The Metaverse relies on a core approach,
digital twinning, which is a means to replicate physical world objects, people,
actions and scenes onto the virtual world. Being able to access scenes and
information associated with the physical world, in the Metaverse in real-time
and under mobility, is essential in developing a highly accessible, interactive
and interconnective experience for all users. This development allows users
from other locations to access high-quality real-world and up-to-date
information about events happening in another location, and socialize with
others hyper-interactively. Nevertheless, receiving continual, smooth updates
generated by others from the Metaverse is a challenging task due to the large
data size of the virtual world graphics and the need for low latency
transmission. With the development of Mobile Augmented Reality (MAR), users can
interact via the Metaverse in a highly interactive manner, even under mobility.
Hence in our work, we considered an environment with users in moving Internet
of Vehicles (IoV), downloading real-time virtual world updates from Metaverse
Service Provider Cell Stations (MSPCSs) via wireless communications. We design
an environment with multiple cell stations, where there will be a handover of
users' virtual world graphic download tasks between cell stations. As
transmission latency is the primary concern in receiving virtual world updates
under mobility, our work aims to allocate system resources to minimize the
total time taken for users in vehicles to download their virtual world scenes
from the cell stations. We utilize deep reinforcement learning and evaluate the
performance of the algorithms under different environmental configurations. Our
work provides a use case of the Metaverse over AI-enabled 6G communications."
11747,"6 DISCUSSION AND FUTURE WORK                                                       TS4

The work we have presented in this paper suggests several avenues                  TS5
of further research, regarding improvements to the RL methodology,
extensions to the simulated scenarios, and considerations for real-                TS6      7.5 8.0 Us8e.r5expe9r.i0ence9s.c5ore 10.0 10.5 11.0
world deployment.","Note that in between the static test scenarios, there is no

corresponding Optuna solution, as the offline optimization would                   TS3

have had to be run on each intermediate setup of user locations.","7.0

   Richer scenarios and action spaces.",2022-09-08 12:58:09+00:00,FORLORN: A Framework for Comparing Offline Methods and Reinforcement Learning for Optimization of RAN Parameters,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Vegard Edvardsen'), arxiv.Result.Author('Gard Spreemann'), arxiv.Result.Author('Jeriek Van den Abeele')]","The growing complexity and capacity demands for mobile networks necessitate
innovative techniques for optimizing resource usage. Meanwhile, recent
breakthroughs have brought Reinforcement Learning (RL) into the domain of
continuous control of real-world systems. As a step towards RL-based network
control, this paper introduces a new framework for benchmarking the performance
of an RL agent in network environments simulated with ns-3. Within this
framework, we demonstrate that an RL agent without domain-specific knowledge
can learn how to efficiently adjust Radio Access Network (RAN) parameters to
match offline optimization in static scenarios, while also adapting on the fly
in dynamic scenarios, in order to improve the overall user experience. Our
proposed framework may serve as a foundation for further work in developing
workflows for designing RL-based RAN control algorithms."
11881,"We will further study performance improvement with
     larity of 1 ms.","Since the time jitter is caused by software delay that
     6.1.2 The Adjustment of Encoding Time Granularity                    is device-dependent, we can adjust the parameters of tempo-
        As stated above, we actually encode the digit at the granu-       ral modulation for different devices under different environ-
                                                                          ments.","If the time jitter is larger than 0.5 milliseconds,  the time granularity adjustment in the evaluation.",2022-09-30 12:08:08+00:00,Crocs: Cross-Technology Clock Synchronization for WiFi and ZigBee,cs.NI,['cs.NI'],"[arxiv.Result.Author('Zihao Yu'), arxiv.Result.Author('Chengkun Jiang'), arxiv.Result.Author('Yuan He'), arxiv.Result.Author('Xiaolong Zheng'), arxiv.Result.Author('Xiuzhen Guo')]","Clock synchronization is a key function in embedded wireless systems and
networks. This issue is equally important and more challenging in IoT systems
nowadays, which often include heterogeneous wireless devices that follow
different wireless standards. Conventional solutions to this problem employ
gateway-based indirect synchronization, which suffers low accuracy. This paper
for the first time studies the problem of cross-technology clock
synchronization. Our proposal called Crocs synchronizes WiFi and ZigBee devices
by direct cross-technology communication. Crocs decouples the synchronization
signal from the transmission of a timestamp. By incorporating a barker-code
based beacon for time alignment and cross-technology transmission of
timestamps, Crocs achieves robust and accurate synchronization among WiFi and
ZigBee devices, with the synchronization error lower than 1 millisecond. We
further make attempts to implement different cross-technology communication
methods in Crocs and provide insight findings with regard to the achievable
accuracy and expected overhead."
12056,"carried out in emerging application areas as well as
                                                        promoting further research, and development in the
Virtual reality is radically changing the interactions  successful deployment of OWC systems as a
between humans and the outside world by building        protuberant complementary to RF-based
a synthetic virtual environment to mimic the real       technologies in the 5&6G and beyond
world, which can be used for social sharing, video      heterogeneous wireless networks.","This will
communications and highly precise indoor                some of the features, issues, and research works
localization.","streaming, and 6 degree-of-freedom content
streaming, etc.",2022-07-18 20:43:23+00:00,"EU cost action on future generation optical wireless communication technologies -- newfocus ca19111, a white paper",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('M A Khalighi'), arxiv.Result.Author('Z Ghassemlooy'), arxiv.Result.Author('S Zvanovec'), arxiv.Result.Author('N Stevens'), arxiv.Result.Author('L N Alves'), arxiv.Result.Author('A Shrestha'), arxiv.Result.Author('M Uysal'), arxiv.Result.Author('A M Vegni'), arxiv.Result.Author('P D Diamantoulakis'), arxiv.Result.Author('V K Papanikolaou'), arxiv.Result.Author('G K Karagiannidis'), arxiv.Result.Author('B Ortega'), arxiv.Result.Author('V Almenar'), arxiv.Result.Author('O Bouchet'), arxiv.Result.Author('L Ladid')]","The EU COST Action NEWFOCUS is focused on investigating radical solutions
with the potential to impact the design of future wireless networks. It aims to
address some of the challenges in OWC and establish it as an efficient
technology that can satisfy the demanding requirements of backhaul and access
network levels in 5G networks. This also includes the use of hybrid links that
associate OWC with radiofrequency or wired/fiber-based technologies. The focus
of this White Paper is on the use of optical wireless communication (OWC) as
enabling technology in a range of areas outlined in HE's Pillar II including
Health, Manufacturing, Intelligent Transportation Systems (ITS), Unmanned
Aerial Vehicles and Network and Protocol."
12057,"In such a camera-     While recent experimental works have already
based VLC system, the received light from the           demonstrated the feasibility of the vehicular VLC,
imaging lens projected onto the image sensor is         further research efforts are required in several areas
converted to binary data by the readout circuit.","CHALLENGES AND FUTURE DIRECTIONS
lane detection, these built-in cameras can be also
potentially used for VLC systems.","The    of vehicular VLC before commercialization and
image sensor consists of multiple micron- sized         widespread adoption of this promising technology.",2022-07-18 20:43:23+00:00,"EU cost action on future generation optical wireless communication technologies -- newfocus ca19111, a white paper",cs.NI,"['cs.NI', 'eess.SP']","[arxiv.Result.Author('M A Khalighi'), arxiv.Result.Author('Z Ghassemlooy'), arxiv.Result.Author('S Zvanovec'), arxiv.Result.Author('N Stevens'), arxiv.Result.Author('L N Alves'), arxiv.Result.Author('A Shrestha'), arxiv.Result.Author('M Uysal'), arxiv.Result.Author('A M Vegni'), arxiv.Result.Author('P D Diamantoulakis'), arxiv.Result.Author('V K Papanikolaou'), arxiv.Result.Author('G K Karagiannidis'), arxiv.Result.Author('B Ortega'), arxiv.Result.Author('V Almenar'), arxiv.Result.Author('O Bouchet'), arxiv.Result.Author('L Ladid')]","The EU COST Action NEWFOCUS is focused on investigating radical solutions
with the potential to impact the design of future wireless networks. It aims to
address some of the challenges in OWC and establish it as an efficient
technology that can satisfy the demanding requirements of backhaul and access
network levels in 5G networks. This also includes the use of hybrid links that
associate OWC with radiofrequency or wired/fiber-based technologies. The focus
of this White Paper is on the use of optical wireless communication (OWC) as
enabling technology in a range of areas outlined in HE's Pillar II including
Health, Manufacturing, Intelligent Transportation Systems (ITS), Unmanned
Aerial Vehicles and Network and Protocol."
12194,"how to better integrate blockchain and the SIoT is also worthy
                                                                                                                  of further study.","Therefore,
semantic attack as a future research direction.",IV.,2022-10-10 08:02:09+00:00,Rethinking Wireless Communication Security in Semantic Internet of Things,cs.NI,['cs.NI'],"[arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Jiacheng Wang'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Jiawen Kang'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Mohsen Guizani'), arxiv.Result.Author('Dong In Kim')]","Semantic communication is an important participant in the next generation of
wireless communications. Enabled by this novel paradigm, the conventional
Internet-of-Things (IoT) is evolving toward the semantic IoT (SIoT) to achieve
significant system performance improvements. However, traditional wireless
communication security techniques for bit transmission cannot be applied
directly to the SIoT that focuses on semantic information transmission. One key
reason is the lack of new security performance indicators. Thus, we have to
rethink the wireless communication security in the SIoT. As such, in the paper,
we analyze and compare classical security techniques, i.e., physical layer
security, covert communications, and encryption, from the perspective of
semantic information security. We highlight the differences among these
security techniques when applied to the SIoT. Novel performance indicators such
as semantic secrecy outage probability (for physical layer security techniques)
and detection error expectation (for covert communication techniques) are
proposed. Considering that semantic communications can raise new security
issues, we then review attack and defense methods at the semantic level.
Finally, we present several promising directions for future secure SIoT
research."
12195,"how to better integrate blockchain and the SIoT is also worthy
                                                                                                                  of further study.","Therefore,
semantic attack as a future research direction.",IV.,2022-10-10 08:02:09+00:00,Rethinking Wireless Communication Security in Semantic Internet of Things,cs.NI,['cs.NI'],"[arxiv.Result.Author('Hongyang Du'), arxiv.Result.Author('Jiacheng Wang'), arxiv.Result.Author('Dusit Niyato'), arxiv.Result.Author('Jiawen Kang'), arxiv.Result.Author('Zehui Xiong'), arxiv.Result.Author('Mohsen Guizani'), arxiv.Result.Author('Dong In Kim')]","Semantic communication is an important participant in the next generation of
wireless communications. Enabled by this novel paradigm, the conventional
Internet-of-Things (IoT) is evolving toward the semantic IoT (SIoT) to achieve
significant system performance improvements. However, traditional wireless
communication security techniques for bit transmission cannot be applied
directly to the SIoT that focuses on semantic information transmission. One key
reason is the lack of new security performance indicators. Thus, we have to
rethink the wireless communication security in the SIoT. As such, in the paper,
we analyze and compare classical security techniques, i.e., physical layer
security, covert communications, and encryption, from the perspective of
semantic information security. We highlight the differences among these
security techniques when applied to the SIoT. Novel performance indicators such
as semantic secrecy outage probability (for physical layer security techniques)
and detection failure probability (for covert communication techniques) are
proposed. Considering that semantic communications can raise new security
issues, we then review attack and defense methods at the semantic level.
Finally, we present several promising directions for future secure SIoT
research."
12460,"In future work, we will further study the GAN-based trust
   The comparisons of number of attacks are given in Fig.",since the former is much smaller than the latter.,9.,2022-10-14 11:20:08+00:00,Generative Adversarial Learning for Trusted and Secure Clustering in Industrial Wireless Sensor Networks,cs.NI,"['cs.NI', 'cs.AI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Liu Yang'), arxiv.Result.Author('Simon X. Yang'), arxiv.Result.Author('Yun Li'), arxiv.Result.Author('Yinzhi Lu'), arxiv.Result.Author('Tan Guo')]","Traditional machine learning techniques have been widely used to establish
the trust management systems. However, the scale of training dataset can
significantly affect the security performances of the systems, while it is a
great challenge to detect malicious nodes due to the absence of labeled data
regarding novel attacks. To address this issue, this paper presents a
generative adversarial network (GAN) based trust management mechanism for
Industrial Wireless Sensor Networks (IWSNs). First, type-2 fuzzy logic is
adopted to evaluate the reputation of sensor nodes while alleviating the
uncertainty problem. Then, trust vectors are collected to train a GAN-based
codec structure, which is used for further malicious node detection. Moreover,
to avoid normal nodes being isolated from the network permanently due to error
detections, a GAN-based trust redemption model is constructed to enhance the
resilience of trust management. Based on the latest detection results, a trust
model update method is developed to adapt to the dynamic industrial
environment. The proposed trust management mechanism is finally applied to
secure clustering for reliable and real-time data transmission, and simulation
results show that it achieves a high detection rate up to 96%, as well as a low
false positive rate below 8%."
12919,"Machine M                                （RVP）        IP address X            We will further study on ICMP rate limiting and its side
                                                                                                      channels in the future.","In addition,
NETWORK                                                          NETWORK                              we measure the implementation of ICMP rate limiting, reveal
                                                                                                      the security and privacy risks of existing ICMP rate limiting
        Prober P          Hidden                                 Periphery    Unreachable             implementations, and provide possible mitigation measures.","Traditional        N ICMP Echo Requests
   Probe                 src=P, dst=X                                                                                  X.",2022-10-24 10:14:16+00:00,Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting Side Channels,cs.NI,['cs.NI'],"[arxiv.Result.Author('Long Pan'), arxiv.Result.Author('Jiahai Yang'), arxiv.Result.Author('Lin He'), arxiv.Result.Author('Zhiliang Wang'), arxiv.Result.Author('Leyao Nie'), arxiv.Result.Author('Guanglei Song'), arxiv.Result.Author('Yaozhong Liu')]","Active Internet measurements face challenges when some measurements require
many remote vantage points. In this paper, we propose a novel technique for
measuring remote IPv6 networks via side channels in ICMP rate limiting, a
required function for IPv6 nodes to limit the rate at which ICMP error messages
are generated. This technique, iVantage, can to some extent use 1.1M remote
routers distributed in 9.5k autonomous systems and 182 countries as our
""vantage points"". We apply iVantage to two different, but both challenging
measurement tasks: 1) measuring the deployment of inbound source address
validation (ISAV) and 2) measuring reachability between arbitrary Internet
nodes. We accomplish these two tasks from only one local vantage point without
controlling the targets or relying on other services within the target
networks. Our large-scale ISAV measurements cover ~50% of all IPv6 autonomous
systems and find ~79% of them are vulnerable to spoofing, which is the most
large-scale measurement study of IPv6 ISAV to date. Our method for reachability
measurements achieves over 80% precision and recall in our evaluation. Finally,
we perform an Internet-wide measurement of the ICMP rate limiting
implementations, present a detailed discussion on ICMP rate limiting,
particularly the potential security and privacy risks in the mechanism of ICMP
rate limiting, and provide possible mitigation measures. We make our code
available to the community."
12920,"Machine M                                （RVP）        IP address X            We will further study on ICMP rate limiting and its side
                                                                                                      channels in the future.","In addition,
NETWORK                                                          NETWORK                              we measure the implementation of ICMP rate limiting, reveal
                                                                                                      the security and privacy risks of existing ICMP rate limiting
        Prober P          Hidden                                 Periphery    Unreachable             implementations, and provide possible mitigation measures.","Traditional        N ICMP Echo Requests
   Probe                 src=P, dst=X                                                                                  X.",2022-10-24 10:14:16+00:00,Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting Side Channels,cs.NI,['cs.NI'],"[arxiv.Result.Author('Long Pan'), arxiv.Result.Author('Jiahai Yang'), arxiv.Result.Author('Lin He'), arxiv.Result.Author('Zhiliang Wang'), arxiv.Result.Author('Leyao Nie'), arxiv.Result.Author('Guanglei Song'), arxiv.Result.Author('Yaozhong Liu')]","Active Internet measurements face challenges when some measurements require
many remote vantage points. In this paper, we propose a novel technique for
measuring remote IPv6 networks via side channels in ICMP rate limiting, a
required function for IPv6 nodes to limit the rate at which ICMP error messages
are generated. This technique, iVantage, can to some extent use 1.1M remote
routers distributed in 9.5k autonomous systems and 182 countries as our
""vantage points"". We apply iVantage to two different, but both challenging
measurement tasks: 1) measuring the deployment of inbound source address
validation (ISAV) and 2) measuring reachability between arbitrary Internet
nodes. We accomplish these two tasks from only one local vantage point without
controlling the targets or relying on other services within the target
networks. Our large-scale ISAV measurements cover ~50% of all IPv6 autonomous
systems and find ~79% of them are vulnerable to spoofing, which is the most
large-scale measurement study of IPv6 ISAV to date. Our method for reachability
measurements achieves over 80% precision and recall in our evaluation. Finally,
we perform an Internet-wide measurement of the ICMP rate limiting
implementations, present a detailed discussion on ICMP rate limiting,
particularly the potential security and privacy risks in the mechanism of ICMP
rate limiting, and provide possible mitigation measures. We make our code
available to the community."
12956,"We further study an example (e.g., total bandwidth equal to
100 MHz) under scenario 2.","Total bandwidth under different
                                                                                                     scenarios.","In such a scenario, the initial UE’s       the characteristics are the same as part C. Fig.",2022-10-25 03:14:19+00:00,Latency Aware Multi-Path Data Transmission for URLLC Services,cs.NI,"['cs.NI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Liu Cao'), arxiv.Result.Author('Abbas Kiani'), arxiv.Result.Author('Amanda Xiang'), arxiv.Result.Author('Kaippallimalil John'), arxiv.Result.Author('Tony Saboorian')]","5th Generation Mobile Communication Technology (5G) utilizes Access Traffic
Steering, Switching, and Splitting (ATSSS) rule to enable multi-path data
transmission, which is currently being standardized. Recently, the 3rd
Generation Partnership Project (3GPP) SA1 and SA2 have been working on
multi-path solution for possible improvement from different perspectives.
However, the existing 3GPP multi-path solution has some limitations on URLLC
traffic in terms of reliability and latency requirements. In order to capture
the potential gains of multi-path architecture in the context of URLLC
services, this paper proposes a new traffic splitting technique which can more
efficiently enjoy the benefit of multi-path architecture in reducing users'
uplink (UL) End-to-End (E2E) latency. In particular, we formulate an
optimization framework which minimizes the UL E2E latency of users via
optimizing the ratio of traffic assigned to each path and corresponding
transmit power. The performance of the proposed scheme is evaluated via well
designed simulations."
12958,"Previ-
ous work on learning to engineer WAN trafﬁc attempted to                To aid further research and development, we will release
achieve similar performance as the TE optmization while              TEAL’s source code upon publication.",increasing scale of TE optimization in cloud WANs.,"We place TEAL in the
operating under demand uncertainty [55].",2022-10-25 04:46:30+00:00,Teal: Learning-Accelerated Optimization of Traffic Engineering,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Zhiying Xu'), arxiv.Result.Author('Francis Y. Yan'), arxiv.Result.Author('Rachee Singh'), arxiv.Result.Author('Justin T. Chiu'), arxiv.Result.Author('Alexander M. Rush'), arxiv.Result.Author('Minlan Yu')]","In the last decade, global cloud wide-area networks (WANs) have grown
10$\times$ in size due to the deployment of new network sites and datacenters,
making it challenging for commercial optimization engines to solve the network
traffic engineering (TE) problem within the temporal budget of a few minutes.
In this work, we show that carefully designed deep learning models are key to
accelerating the running time of intra-WAN TE systems for large deployments
since deep learning is both massively parallel and it benefits from the wealth
of historical traffic allocation data from production WANs. However,
off-the-shelf deep learning methods fail to perform well on the TE task since
they ignore the effects of network connectivity on flow allocations. They are
also faced with a tractability challenge posed by the large problem scale of TE
optimization. Moreover, neural networks do not have mechanisms to readily
enforce hard constraints on model outputs (e.g., link capacity constraints). We
tackle these challenges by designing a deep learning-based TE system -- Teal.
First, Teal leverages graph neural networks (GNN) to faithfully capture
connectivity and model network flows. Second, Teal devises a multi-agent
reinforcement learning (RL) algorithm to process individual demands
independently in parallel to lower the problem scale. Finally, Teal reduces
link capacity violations and improves solution quality using the alternating
direction method of multipliers (ADMM). We evaluate Teal on traffic matrices of
a global commercial cloud provider and find that Teal computes near-optimal
traffic allocations with a 59$\times$ speedup over state-of-the-art TE systems
on a WAN topology of over 1,500 nodes."
13026,"In this section, we further study the
collision probabilities and the transmission throughput with                                   𝑝𝑡 = 1 − 𝑒−𝜆·𝑡𝑠𝑙𝑜𝑡 .","However, a long slot length will lead to a low channel
utilization and severe intra-slot collisions due to the suppressed                             The transmission probability for each slot is then
backlogs in the long slot.","(6)
respect to the slot length, packet duration, packet arrival rate,
and the number of nodes.",2022-10-26 06:14:38+00:00,Impact and analysis of space-time coupling on slotted MAC in UANs,cs.NI,['cs.NI'],"[arxiv.Result.Author('Yan Wang'), arxiv.Result.Author('Quansheng Guan'), arxiv.Result.Author('Fei Ji'), arxiv.Result.Author('Weiqi Chen')]","The propagation delay is non-negligible in underwater acoustic networks
(UANs) since the propagation speed is five orders of magnitude smaller than the
speed of light. In this case, space and time factors are strongly coupled to
determine the collisions of packet transmissions. To this end, this paper
analyzes the impact of spatial-time coupling on slotted medium access control
(MAC). We find that both inter-slot and intra-slot collisions may exist, and
the inter-slot collision may span multiple slots. The sending slot dependent
interference regions could be an annulus inside the whole transmission range.
It is pointed out that there exist collision-free regions when a guard interval
larger than a packet duration is used in the slot setting. In this sense, the
long slot brings spatial reuse in a transmission range. However, we further
find that the successful transmission probabilities and throughput are the same
for the slot lengths of one packet duration and two packet durations.
Simulation results show that the maximum successful transmission probability
and throughput can be achieved by a guard interval less than a packet duration,
which is much shorter than the existing slot setting in typical Slotted-ALOHA.
Simulations also show that the spatial impact is greater for vertical
transmission than for horizontal transmissions due to the longer vertical
transmission range in three-dimensional UANs."
13315,"Thus, further research should focus          Paper, 2020.
on ﬁnding an efﬁcient way of provisioning the edge resources
so that the capital cost can be reduced while maintaining a        [2] P. J. Schildkraut, “AI regulation: What you need to know to stay ahead of
desirable system performance.","REFERENCES
Hence, while using the average conﬁguration during the rush
hours, efﬁcient measures need to be taken to avoid any unsafe      [1] T. Litman, “Autonomous vehicle implementation predictions: Implica-
situation by limiting the safe speed of the AVs to guarantee            tions for transport planning,” Victoria Transport Policy Institute – White
a required blind distance.","In addition, researchers should           the curve,” https://www.arnoldporter.com/en/perspectives/publications/
also consider how to modify the routing algorithms to take              2021/06/ai-regulation-what-you-need-to-know, 2021.
into account the amount of edge resource deployed in different
areas and their effect on the expected safe speed for safe and     [3] H. Wang, B. Kim, J. Xie, and Z. Han, “E-auto: A communication scheme
faster navigation of the AVs.",2022-09-23 21:54:53+00:00,Are Turn-by-Turn Navigation Systems of Regular Vehicles Ready for Edge-Assisted Autonomous Vehicles?,cs.NI,['cs.NI'],"[arxiv.Result.Author('Syeda Tanjila Atik'), arxiv.Result.Author('Marco Brocanelli'), arxiv.Result.Author('Daniel Grosu')]","Future private and public transportation will be dominated by Autonomous
Vehicles (AV), which are potentially safer than regular vehicles. However,
ensuring good performance for the autonomous features requires fast processing
of heavy computational tasks. Providing each AV with powerful enough computing
resources is certainly a practical solution but may result in increased AV cost
and decreased driving range. An alternative solution being explored in research
is to install low-power computing hardware on each AV and offload the heavy
tasks to powerful nearby edge servers. In this case, the AV's reaction time
depends on how quickly the navigation tasks are completed in the edge server.
To reduce task completion latency, the edge servers must be equipped with
enough network and computing resources to handle the vehicle demands. However,
this demand shows large spatio-temporal variations. Thus, deploying the same
amount of resources in different locations may lead to unnecessary resource
over-provisioning.
  Taking these challenges into consideration, in this paper, we discuss the
implications of deploying different amounts of resources in different city
areas based on real traffic data to sustain peak versus average demand. Because
deploying edge resources to handle the average demand leads to lower deployment
costs and better system utilization, we then investigate how peak-hour demand
affect the safe travel time of AVs and whether current turn-by-turn navigation
apps would still provide the fastest travel route. The insights and findings of
this paper will inspire new research that can considerably speed up the
deployment of edge-assisted AVs in our society."
13594,"The development of new
ten select attack nodes that result in a much larger   heuristic approaches also deserves further study.","At the same time, the heuristic algorithms of-    terdependent networks.",connected component.,2022-11-10 15:42:59+00:00,Finding Critical Nodes in Interdependent Networks with SAT and ILP Solvers,cs.NI,['cs.NI'],"[arxiv.Result.Author('Kyozo Hida'), arxiv.Result.Author('Tatsuhiro Tsuchiya')]","Infrastructure systems, such as power systems, often experience cascading
failures. Modeling an infrastructure system as a collection of interdependent
networks has recently received attention as a way to explain cascading
failures. In this study, we propose an approach to find the set of critical
nodes in an interdependent network. For an integer k, we say that a set of k
nodes is critical if the initial failures of these k nodes result in the most
severe cascading failure among all sets of k nodes. This approach adopts the
seminal model of interdependent networks proposed by Buldyrev et al., in which
new link failures occur in a network if the connectivity is lost in the paired
network. The problem of finding critical nodes is NP-hard; thus the aim of the
approach is to accurately solve the problem in feasible time for moderate-size
problem instances. The proposed approach consists of two phases. In the first
phase, the maximum number of failure propagation stages is computed by
repeatedly solving the Boolean satisfiability problem. This number is then used
in the second phase, where the set of critical nodes is computed using integer
linear programming. The results of applying this approach to a variety of
problem instances demonstrate that the approach is feasible for up to at least
30 nodes and can be used as the baseline to compare the performance of
heuristic solutions."
13869,"(iii) To ensure repro-
                                        ous reﬂecting elements with sub-wavelength spacing whose                      ducibility and support further research on DRL-based RIS
                                        impedances are adjusted to induce the desired phase shifts on                 systems, we provide our source code and results in the GitHub
                                        the incident wave before it is reﬂected, allowing a multipath                 repository1.",An RIS consists of numer-                     the agent assumes them to be ideal.,"interference of desired nature to be created at the receiver
                                        [2].",2022-10-10 09:37:53+00:00,Deep Reinforcement Learning Based Joint Downlink Beamforming and RIS Configuration in RIS-aided MU-MISO Systems Under Hardware Impairments and Imperfect CSI,cs.NI,"['cs.NI', 'cs.LG', 'eess.SP']","[arxiv.Result.Author('Baturay Saglam'), arxiv.Result.Author('Doga Gurgunoglu'), arxiv.Result.Author('Suleyman S. Kozat')]","We investigate the joint transmit beamforming and reconfigurable intelligent
surface (RIS) configuration problem to maximize the sum downlink rate of a
RIS-aided cellular multiuser multiple input single output (MU-MISO) system
under imperfect channel state information (CSI) and hardware impairments by
considering a practical phase-dependent RIS amplitude model. To this end, we
present a novel deep reinforcement learning (DRL) framework and compare its
performance against a vanilla DRL agent under two scenarios: the golden
standard where the base station (BS) knows the channel and the phase-dependent
RIS amplitude model perfectly, and the mismatch scenario where the BS has
imperfect CSI and assumes ideal RIS reflections. Our numerical results show
that the introduced framework substantially outperforms the vanilla DRL agent
under mismatch and approaches the golden standard."
13948,topic for further research.,"7 (e)–(f) reﬂect that the   those time-varying interference factors is another interesting
OU and RQ kernel functions lack of ability to ﬁt the tail data.","V. CONCLUSIONS                                                    ACKNOWLEDGMENT

   In this paper, we have proposed multidimensional ﬁnger-             This work was supported in part by Postgraduate Research
print data augmentation for indoor localization in a large-         Scholarship (under Grant PGRS1912001) and Key Program
scale building complex based on MOGP and systematically             Special Fund (under Grant KSF-E-25) of Xi’an Jiaotong-
investigated the impact of the various aspects of MOGP-based        Liverpool University.",2022-11-19 10:07:17+00:00,On the Multidimensional Augmentation of Fingerprint Data for Indoor Localization in A Large-Scale Building Complex Based on Multi-Output Gaussian Process,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Zhe Tang'), arxiv.Result.Author('Sihao Li'), arxiv.Result.Author('Kyeong Soo Kim'), arxiv.Result.Author('Jeremy Smith')]","Wi-Fi fingerprinting becomes a dominant solution for large-scale indoor
localization due to its major advantage of not requiring new infrastructure and
dedicated devices. The number and the distribution of Reference Points (RPs)
for the measurement of localization fingerprints like RSSI during the offline
phase, however, greatly affects the localization accuracy; for instance, the
UJIIndoorLoc is known to have the issue of uneven spatial distribution of RPs
over buildings and floors. Data augmentation has been proposed as a feasible
solution to not only improve the smaller number and the uneven distribution of
RPs in the existing fingerprint databases but also reduce the labor and time
costs of constructing new fingerprint databases. In this paper, we propose the
multidimensional augmentation of fingerprint data for indoor localization in a
large-scale building complex based on Multi-Output Gaussian Process (MOGP) and
systematically investigate the impact of augmentation ratio as well as MOGP
kernel functions and models with their hyperparameters on the performance of
indoor localization using the UJIIndoorLoc database and the state-of-the-art
neural network indoor localization model based on a hierarchical RNN. The
investigation based on experimental results suggests that we can generate
synthetic RSSI fingerprint data up to ten times the original data -- i.e., the
augmentation ratio of 10 -- through the proposed multidimensional MOGP-based
data augmentation without significantly affecting the indoor localization
performance compared to that of the original data alone, which extends the
spatial coverage of the combined RPs and thereby could improve the localization
performance at the locations that are not part of the test dataset."
14168,"We left as further study the optimization problem to                                                               for Computing Machinery, 2011.
assign ranks and puriﬁcation rounds of a REDiP tunnel, given
a set of user requirements and network conditions.","A preliminary performance                                                          [6] L. Aparicio, R. Van Meter, and H. Esaki, “Protocol design for quantum
evaluation of REDiP proved that its conﬁgurability is essential                                                            repeater networks,” in Proceedings of the 7th Asian Internet Engineering
to meet user requirements and mitigate the effect of quantum                                                               Conference, AINTEC ’11, (New York, NY, USA), p. 73–80, Association
errors.","[7] A. Dahlberg et al., “A link layer protocol for quantum networks,” in
                                                                                                                           Proceedings of the ACM Special Interest Group on Data Communica-
                            REFERENCES                                                                                     tion, SIGCOMM ’19, (New York, NY, USA), p. 159–173, Association
                                                                                                                           for Computing Machinery, 2019.",2022-11-25 12:01:48+00:00,A Configurable Protocol for Quantum Entanglement Distribution to End Nodes,cs.NI,['cs.NI'],"[arxiv.Result.Author('Leonardo Bacciottini'), arxiv.Result.Author('Luciano Lenzini'), arxiv.Result.Author('Enzo Mingozzi'), arxiv.Result.Author('Giuseppe Anastasi')]","The primary task of a quantum repeater network is to deliver entanglement
among end nodes. Most of existing entanglement distribution protocols do not
consider purification, which is thus delegated to an upper layer. This is a
major drawback since, once an end-to-end entangled connection (or a portion
thereof) is established it cannot be purified if its fidelity (F) does not fall
within an interval bounded by Fmin (greater than 0.5) and Fmax (less than 1).
In this paper, we propose the Ranked Entanglement Distribution Protocol
(REDiP), a connection-oriented protocol that overcomes the above drawback. This
result was achieved by including in our protocol two mechanisms for carrying
out jointly purification and entanglement swapping. We use simulations to
investigate the impact of these mechanisms on the performance of a repeater
network, in terms of throughput and fidelity. Moreover, we show how REDiP can
easily be configured to implement custom entanglement swapping and purification
strategies, including (but not restricted to) those adopted in two recent
works."
14218,"signals, multiple base stations and various sensor measure-                          26–32, 2020.
ments requires further research.","1, pp.","An important open research
question concerns the distribution of localization functional-                 [14] S. Kekki et al., ETSI White Paper No.",2022-11-27 10:24:33+00:00,"Architecture, Protocols, and Algorithms for Location-Aware Services in Beyond 5G Networks",cs.NI,"['cs.NI', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Peter Hammarberg'), arxiv.Result.Author('Julia Vinogradova'), arxiv.Result.Author('Gábor Fodor'), arxiv.Result.Author('Ritesh Shreevastav'), arxiv.Result.Author('Satyam Dwivedi'), arxiv.Result.Author('Fredrik Gunnarsson')]","The automotive and railway industries are rapidly transforming with a strong
drive towards automation and digitalization, with the goal of increased
convenience, safety, efficiency, and sustainability. Since assisted and fully
automated automotive and train transport services increasingly rely on
vehicle-to-everything communications, and high-accuracy real-time positioning,
it is necessary to continuously maintain high-accuracy localization, even in
occlusion scenes such as tunnels, urban canyons, or areas covered by dense
foliage. In this paper, we review the 5G positioning framework of the 3rd
Generation Partnership Project in terms of methods and architecture and propose
enhancements to meet the stringent requirements imposed by the transport
industry. In particular, we highlight the benefit of fusing cellular and sensor
measurements and discuss required architecture and protocol support for
achieving this at the network side. We also propose a positioning framework to
fuse cellular network measurements with measurements by onboard sensors. We
illustrate the viability of the proposed fusion-based positioning approach
using a numerical example."
14286,"Resource management (e.g.,            progress in both academia and industry, evoke growing atten-
resource provisioning, resource scheduling, and resource mon-          tion, stimulate wide discussions, and inspire further research
itoring) and across the hierarchy of “camera-edge-cloud” will          ideas on EVA.","We hope this survey can reﬂect the recent
requirements of large-scale LVA.",pose signiﬁcant challenges in such settings.,2022-11-28 20:11:37+00:00,Deep Learning-Driven Edge Video Analytics: A Survey,cs.NI,"['cs.NI', 'cs.CV', 'cs.LG', 'C.2.1; I.2.10']","[arxiv.Result.Author('Renjie Xu'), arxiv.Result.Author('Saiedeh Razavi'), arxiv.Result.Author('Rong Zheng')]","Video, as a key driver in the global explosion of digital information, can
create tremendous benefits for human society. Governments and enterprises are
deploying innumerable cameras for a variety of applications, e.g., law
enforcement, emergency management, traffic control, and security surveillance,
all facilitated by video analytics (VA). This trend is spurred by the rapid
advancement of deep learning (DL), which enables more precise models for object
classification, detection, and tracking. Meanwhile, with the proliferation of
Internet-connected devices, massive amounts of data are generated daily,
overwhelming the cloud. Edge computing, an emerging paradigm that moves
workloads and services from the network core to the network edge, has been
widely recognized as a promising solution. The resulting new intersection, edge
video analytics (EVA), begins to attract widespread attention. Nevertheless,
only a few loosely-related surveys exist on this topic. A dedicated venue for
collecting and summarizing the latest advances of EVA is highly desired by the
community. Besides, the basic concepts of EVA (e.g., definition, architectures,
etc.) are ambiguous and neglected by these surveys due to the rapid development
of this domain. A thorough clarification is needed to facilitate a consensus on
these concepts. To fill in these gaps, we conduct a comprehensive survey of the
recent efforts on EVA. In this paper, we first review the fundamentals of edge
computing, followed by an overview of VA. The EVA system and its enabling
techniques are discussed next. In addition, we introduce prevalent frameworks
and datasets to aid future researchers in the development of EVA systems.
Finally, we discuss existing challenges and foresee future research directions.
We believe this survey will help readers comprehend the relationship between VA
and edge computing, and spark new ideas on EVA."
14487,"The development of 6G
analytical (algebraic) formulation of the electric and magnetic  STAR-RISs while addressing practical hardware limitations
polarization densities as a function of macroscopic ﬁelds and    will be a challenge; therefore, further research is required.",The GSTC model provides an              formance optimization in practice.,dyadic surface susceptibilities.,2022-12-02 11:22:07+00:00,Simultaneous Transmitting and Reflecting-Reconfigurable Intelligent Surface in 6G: Design Guidelines and Future Perspectives,cs.NI,"['cs.NI', 'cs.ET', 'cs.IT', 'math.IT']","[arxiv.Result.Author('Waqas Khalid'), arxiv.Result.Author('Zeeshan Kaleem'), arxiv.Result.Author('Rehmat Ullah'), arxiv.Result.Author('Trinh Van Chien'), arxiv.Result.Author('Song Noh'), arxiv.Result.Author('Heejung Yu')]","Reconfigurable intelligent surfaces (RISs) have been considered as a
promising technology for the sixth-generation (6G) wireless networks that can
control wireless channels in a desirable way and significantly enhance the
network performance. Simultaneous transmitting and reflecting-RISs (STAR-RISs)
can overcome limitation of reflecting-only RISs by leveraging the higher design
flexibility and full-space coverage. Despite the benefits, the modeling and
analysis of STAR-RISs are complicated because of various control parameters for
both transmission and reflection links. In this article, a general framework to
facilitate the design and implementation of STAR-RISs in 6G scenarios and
network topologies is presented. We provide a systematic introduction to the
STAR-RIS operating protocols for different communication modes and discuss
recent efforts to identify the research progress and combination solutions.
Finally, we provide the design concepts, research challenges, potential
solutions, and future directions related to the channel modeling, channel
estimation, hardware implementations, modeling and limitations, and
optimization."
14569,further research.,"These
entiations in the environment of each region, the decisions               work provides a solid foundation for federated learning in
inferred by the global learning model may be misjudged.","Therefore, considering the differentiations between regions in
complex network environments, we propose a novel differ-                  B. Federated Reinforcement Learning
entiated federated reinforcement learning (DFRL) approach.",2022-12-05 07:40:29+00:00,Differentiated Federated Reinforcement Learning for Dynamic and Heterogeneous Network,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Fengxiao Tang'), arxiv.Result.Author('Yilin Yang'), arxiv.Result.Author('Xin Yao'), arxiv.Result.Author('Ming Zhao'), arxiv.Result.Author('Nei Kato')]","The modern dynamic and heterogeneous network brings differential environments
with respective state transition probability to agents, which leads to the
local strategy trap problem of traditional federated reinforcement learning
(FRL) based network optimization algorithm. To solve this problem, we propose a
novel Differentiated Federated Reinforcement Learning (DFRL), which evolves the
global policy model integration and local inference with the global policy
model in traditional FRL to a collaborative learning process with parallel
global trends learning and differential local policy model learning. In the
DFRL, the local policy learning model is adaptively updated with the global
trends model and local environment and achieves better differentiated
adaptation. We evaluate the outperformance of the proposal compared with the
state-of-the-art FRL in a classical CartPole game with heterogeneous
environments. Furthermore, we implement the proposal in the heterogeneous
Space-air-ground Integrated Network (SAGIN) for the classical traffic
offloading problem in network. The simulation result shows that the proposal
shows better global performance and fairness than baselines in terms of
throughput, delay, and packet drop rate."
14574,"This suggests that further research is warranted on the                            send the local parameters to the server (2); the server per-
                                       ways – often counter-intuitive – in which convergence bounds can                             forms a (weighted) averaging of the model (3) and sends the
                                       be exploited to improve the performance of real-world distributed                            global parameters back to the learning nodes (4).","More                                              4: global
                                       unexpectedly, we find that some of the quantities appearing in the                                              model
                                       bounds turn out to be very useful to identify the clients that are
                                       most likely to contribute to the learning process, without requiring                         Figure 1: Main steps of each iteration of the federated learn-
                                       the disclosure of any information about the quality or size of their                         ing paradigm: learning nodes train their local model (1) and
                                       datasets.",learning tasks.,2022-12-05 10:55:25+00:00,Unexpectedly Useful: Convergence Bounds And Real-World Distributed Learning,cs.NI,"['cs.NI', 'cs.LG']","[arxiv.Result.Author('Francesco Malandrino'), arxiv.Result.Author('Carla Fabiana Chiasserini')]","Convergence bounds are one of the main tools to obtain information on the
performance of a distributed machine learning task, before running the task
itself. In this work, we perform a set of experiments to assess to which
extent, and in which way, such bounds can predict and improve the performance
of real-world distributed (namely, federated) learning tasks. We find that, as
can be expected given the way they are obtained, bounds are quite loose and
their relative magnitude reflects the training rather than the testing loss.
More unexpectedly, we find that some of the quantities appearing in the bounds
turn out to be very useful to identify the clients that are most likely to
contribute to the learning process, without requiring the disclosure of any
information about the quality or size of their datasets. This suggests that
further research is warranted on the ways -- often counter-intuitive -- in
which convergence bounds can be exploited to improve the performance of
real-world distributed learning tasks."
14643,"This article is targeted toward         no means the only ones within the risk management theory
graduate students, early-stage researchers, and profession-        [74], and further research is needed to identify and link
als interested in getting a comprehensive overview of the          more risk-related metrics to the design/analysis of URLLC
statistical tools and methodologies relevant to URLLC, and         systems.","Finally, the risk metrics
further elaborated through concrete numerical examples             discussed in Section III-C, i.e., VaR (39) and CVar (40), are by
and selected applications.","will help foster more research in URLLC and its evolution
towards next-generation wireless systems.",2022-10-27 11:01:31+00:00,Statistical Tools and Methodologies for URLLC -- A Tutorial,cs.NI,"['cs.NI', 'cs.IT', 'math.IT', 'stat.AP']","[arxiv.Result.Author('Onel López'), arxiv.Result.Author('Nurul Mahmood'), arxiv.Result.Author('Mohammad Shehab'), arxiv.Result.Author('Hirley Alves'), arxiv.Result.Author('Osmel Rosabal'), arxiv.Result.Author('Leatile Marata'), arxiv.Result.Author('Matti Latva-aho')]","Ultra-reliable low-latency communication (URLLC) constitutes a key service
class of the fifth generation and beyond cellular networks. Notably, designing
and supporting URLLC poses a herculean task due to the fundamental need of
identifying and accurately characterizing the underlying statistical models in
which the system operates, e.g., interference statistics, channel conditions,
and the behavior of protocols. In general, multi-layer end-to-end approaches
considering all the potential delay and error sources and proper statistical
tools and methodologies are inevitably required for providing strong
reliability and latency guarantees. This paper contributes to the body of
knowledge in the latter aspect by providing a tutorial on several statistical
tools and methodologies that are useful for designing and analyzing URLLC
systems. Specifically, we overview the frameworks related to i) reliability
theory, ii) short packet communications, iii) inequalities, distribution
bounds, tail approximations, and risk-assessment tools, iv) rare events
simulation, v) large-scale tools such as stochastic geometry, clustering,
compressed sensing, and mean-field games, vi) queuing theory and information
freshness, and vii) machine learning. Throughout the paper, we briefly review
the state-of-the-art works using the addressed tools and methodologies, and
their link to URLLC systems. Moreover, we discuss novel application examples
focused on physical and medium access control layers. Finally, key research
challenges and directions are highlighted to elucidate how URLLC
analysis/design research may evolve in the coming years."
14644,"Therefore, further research is
interactions, where physical and software components are           needed to properly link efﬁcient sampling algorithms and
deeply intertwined [209].","This is specially evident for use cases related to          cient sampling to assess novel probabilistic metrics with a
emerging sophisticated cyber-physical systems, which rely          signiﬁcant number of samples from the probability space
on embedded, decentralized, real-time computations and             where the URLLC event exists.",The design and analysis of such          URLLC research.,2022-10-27 11:01:31+00:00,Statistical Tools and Methodologies for URLLC -- A Tutorial,cs.NI,"['cs.NI', 'cs.IT', 'math.IT', 'stat.AP']","[arxiv.Result.Author('Onel López'), arxiv.Result.Author('Nurul Mahmood'), arxiv.Result.Author('Mohammad Shehab'), arxiv.Result.Author('Hirley Alves'), arxiv.Result.Author('Osmel Rosabal'), arxiv.Result.Author('Leatile Marata'), arxiv.Result.Author('Matti Latva-aho')]","Ultra-reliable low-latency communication (URLLC) constitutes a key service
class of the fifth generation and beyond cellular networks. Notably, designing
and supporting URLLC poses a herculean task due to the fundamental need of
identifying and accurately characterizing the underlying statistical models in
which the system operates, e.g., interference statistics, channel conditions,
and the behavior of protocols. In general, multi-layer end-to-end approaches
considering all the potential delay and error sources and proper statistical
tools and methodologies are inevitably required for providing strong
reliability and latency guarantees. This paper contributes to the body of
knowledge in the latter aspect by providing a tutorial on several statistical
tools and methodologies that are useful for designing and analyzing URLLC
systems. Specifically, we overview the frameworks related to i) reliability
theory, ii) short packet communications, iii) inequalities, distribution
bounds, tail approximations, and risk-assessment tools, iv) rare events
simulation, v) large-scale tools such as stochastic geometry, clustering,
compressed sensing, and mean-field games, vi) queuing theory and information
freshness, and vii) machine learning. Throughout the paper, we briefly review
the state-of-the-art works using the addressed tools and methodologies, and
their link to URLLC systems. Moreover, we discuss novel application examples
focused on physical and medium access control layers. Finally, key research
challenges and directions are highlighted to elucidate how URLLC
analysis/design research may evolve in the coming years."
14697,"In this section, we also discuss the implications for further research on congestion
control using MPC.","In Section 5, we present our evaluation of PredicTor, focusing first on small scenarios
to demonstrate its functioning before we leverage larger-scale simulations of complex networks for
deeper insights.","We complete our work by presenting related work in Section 6 and summarizing
this contribution in Section 7.",2022-12-08 11:08:01+00:00,Optimization-Based Predictive Congestion Control for the Tor Network: Opportunities and Challenges,cs.NI,['cs.NI'],"[arxiv.Result.Author('Christoph Döpmann'), arxiv.Result.Author('Felix Fiedler'), arxiv.Result.Author('Sergio Lucia'), arxiv.Result.Author('Florian Tschorsch')]","Based on the principle of onion routing, the Tor network achieves anonymity
for its users by relaying user data over a series of intermediate relays. This
approach makes congestion control in the network a challenging task. As of
today, this results in higher latencies due to considerable backlog as well as
unfair data rate allocation. In this paper, we present a concept study of
PredicTor, a novel approach to congestion control that tackles clogged overlay
networks. Unlike traditional approaches, it is built upon the idea of
distributed model predictive control, a recent advancement from the area of
control theory. PredicTor is tailored to minimizing latency in the network and
achieving max-min fairness. We contribute a thorough evaluation of its behavior
in both toy scenarios to assess the optimizer and complex networks to assess
its potential. For this, we conduct large-scale simulation studies and compare
PredicTor to existing congestion control mechanisms in Tor. We show that
PredicTor is highly effective in reducing latency and realizing fair rate
allocations. In addition, we strive to bring the ideas of modern control theory
to the networking community, enabling the development of improved, future
congestion control. We therefore demonstrate benefits and issues alike with
this novel research direction."
14698,"On the other hand,
we investigate to what extent the underlying assumptions made in PredicTor collide with reality
and what implications this has for further research in the field.","On the one hand, we thus verify whether PredicTor’s claimed benefits do also exist
in scenarios that are not as easy to understand as the toy scenarios before.","Lastly, we evaluate how PredicTor
handles different traffic patterns (bulk and web traffic).",2022-12-08 11:08:01+00:00,Optimization-Based Predictive Congestion Control for the Tor Network: Opportunities and Challenges,cs.NI,['cs.NI'],"[arxiv.Result.Author('Christoph Döpmann'), arxiv.Result.Author('Felix Fiedler'), arxiv.Result.Author('Sergio Lucia'), arxiv.Result.Author('Florian Tschorsch')]","Based on the principle of onion routing, the Tor network achieves anonymity
for its users by relaying user data over a series of intermediate relays. This
approach makes congestion control in the network a challenging task. As of
today, this results in higher latencies due to considerable backlog as well as
unfair data rate allocation. In this paper, we present a concept study of
PredicTor, a novel approach to congestion control that tackles clogged overlay
networks. Unlike traditional approaches, it is built upon the idea of
distributed model predictive control, a recent advancement from the area of
control theory. PredicTor is tailored to minimizing latency in the network and
achieving max-min fairness. We contribute a thorough evaluation of its behavior
in both toy scenarios to assess the optimizer and complex networks to assess
its potential. For this, we conduct large-scale simulation studies and compare
PredicTor to existing congestion control mechanisms in Tor. We show that
PredicTor is highly effective in reducing latency and realizing fair rate
allocations. In addition, we strive to bring the ideas of modern control theory
to the networking community, enabling the development of improved, future
congestion control. We therefore demonstrate benefits and issues alike with
this novel research direction."
14831,"In addition it proposed ﬁxes
  different types of handovers in LEO satel-              and areas for further research.","For example, there are            and satellite orbit.","lite networks, such as intra-satellite handovers,     • Performance implications of link charac-
  inter-satellite handovers, and inter-access net-        teristics: It produced informational documents
                                                       37

     that discuss the capabilities and limitations of  These EOSCs expect to provide commercial broad-
     performance enhancing proxies (PEPs).",2022-12-12 02:54:57+00:00,Future Space Networks: Toward the Next Giant Leap for Humankind,cs.NI,['cs.NI'],"[arxiv.Result.Author('Mohammed Y. Abdelsadek'), arxiv.Result.Author('Aizaz U. Chaudhry'), arxiv.Result.Author('Tasneem Darwish'), arxiv.Result.Author('Eylem Erdogan'), arxiv.Result.Author('Gunes Karabulut-Kurt'), arxiv.Result.Author('Pablo G. Madoery'), arxiv.Result.Author('Olfa Ben Yahia'), arxiv.Result.Author('Halim Yanikomeroglu')]","Due to the unprecedented advances in satellite fabrication and deployment,
innovative communications and networking technologies, ambitious space projects
and programs, and the resurgence of interest in satellite networks, there is a
need to redefine space networks (SpaceNets) to incorporate all of these
evolutions. This paper introduces a vision for future SpaceNets that considers
advances in several related domains. First, we present a reference architecture
that captures the various network entities and terminals in a holistic manner.
Based on this, space, air, and ground use cases are studied. Then, the
architectures and technologies that enable the envisaged SpaceNets are
investigated. In so doing, we highlight the activities and projects of
different standardization bodies, satellite operators, and national
organizations towards the envisioned SpaceNets. Finally, the challenges,
potential solutions, and open issues from communications and networking
perspectives are discussed."
15006,"The mitigation of these phenomena requires substantial further research in 6G
underwater networks.","However, underwater communications rely on ultra-low frequencies, which are
affected by water ﬂow, the Doppler effect of ships, environmental noise, and vortex-induced
water vibration.","Aerial communications in 6G rely on drones or unmanned aerial vehicles (UAVs) and low/high
altitude platforms (LAPs/HAPs).",2022-11-07 14:03:48+00:00,Five Facets of 6G: Research Challenges and Opportunities,cs.NI,"['cs.NI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Li-Hsiang Shen'), arxiv.Result.Author('Kai-Ten Feng'), arxiv.Result.Author('Lajos Hanzo')]","Whilst the fifth-generation (5G) systems are being rolled out across the
globe, researchers have turned their attention to the exploration of radical
next-generation solutions. At this early evolutionary stage we survey five main
research facets of this field, namely {\em Facet~1: next-generation
architectures, spectrum and services, Facet~2: next-generation networking,
Facet~3: Internet of Things (IoT), Facet~4: wireless positioning and sensing,
as well as Facet~5: applications of deep learning in 6G networks.} In this
paper, we have provided a critical appraisal of the literature of promising
techniques ranging from the associated architectures, networking, applications
as well as designs. We have portrayed a plethora of heterogeneous architectures
relying on cooperative hybrid networks supported by diverse access and
transmission mechanisms. The vulnerabilities of these techniques are also
addressed and carefully considered for highlighting the most of promising
future research directions. Additionally, we have listed a rich suite of
learning-driven optimization techniques. We conclude by observing the
evolutionary paradigm-shift that has taken place from pure single-component
bandwidth-efficiency, power-efficiency or delay-optimization towards
multi-component designs, as exemplified by the twin-component ultra-reliable
low-latency mode of the 5G system. We advocate a further evolutionary step
towards multi-component Pareto optimization, which requires the exploration of
the entire Pareto front of all optiomal solutions, where none of the components
of the objective function may be improved without degrading at least one of the
other components."
15007,"However, achieving this ambitious design objective, while handling diverse
cell-sizes, ranging from small cells (SCs) to femtocells, picocells and the emerging nanocells [37],
requires substantial further research in the context of 6G networks.","The network determines its resource-allocation strictly based on the QoS
requirements [36].","To elaborate a little further,
a host of sophisticated interference management, dynamic channel allocation, high-mobility
handover, packet admission control, power control, and scheduling have to be investigated.",2022-11-07 14:03:48+00:00,Five Facets of 6G: Research Challenges and Opportunities,cs.NI,"['cs.NI', 'cs.SY', 'eess.SY']","[arxiv.Result.Author('Li-Hsiang Shen'), arxiv.Result.Author('Kai-Ten Feng'), arxiv.Result.Author('Lajos Hanzo')]","Whilst the fifth-generation (5G) systems are being rolled out across the
globe, researchers have turned their attention to the exploration of radical
next-generation solutions. At this early evolutionary stage we survey five main
research facets of this field, namely {\em Facet~1: next-generation
architectures, spectrum and services, Facet~2: next-generation networking,
Facet~3: Internet of Things (IoT), Facet~4: wireless positioning and sensing,
as well as Facet~5: applications of deep learning in 6G networks.} In this
paper, we have provided a critical appraisal of the literature of promising
techniques ranging from the associated architectures, networking, applications
as well as designs. We have portrayed a plethora of heterogeneous architectures
relying on cooperative hybrid networks supported by diverse access and
transmission mechanisms. The vulnerabilities of these techniques are also
addressed and carefully considered for highlighting the most of promising
future research directions. Additionally, we have listed a rich suite of
learning-driven optimization techniques. We conclude by observing the
evolutionary paradigm-shift that has taken place from pure single-component
bandwidth-efficiency, power-efficiency or delay-optimization towards
multi-component designs, as exemplified by the twin-component ultra-reliable
low-latency mode of the 5G system. We advocate a further evolutionary step
towards multi-component Pareto optimization, which requires the exploration of
the entire Pareto front of all optiomal solutions, where none of the components
of the objective function may be improved without degrading at least one of the
other components."
15169,wide-spread adoption and further research and development.,"The ATLAS framework                platforms and use-cases, such as smart homes, building, and
                                        is open-sourced at https://atlas-tuw.sourceforge.io to enable        environments.","Smart environments tend to offer a wide-range of
                                           Index Terms—IoT, Smart, Environment, Security, Privacy,           functionalities and services, which can be controlled or
                                        Anonymous, Tracing, BLE, Localization, Tracking, Bluetooth           operated using a single user device.",2022-12-20 14:33:34+00:00,ATLAS: An IoT Architecture and Secure Open-source Networking Stack for Anonymous Localization and Tracking Using Smartphones and Bluetooth Beacons,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Bharath Srinivas Prabakaran'), arxiv.Result.Author('Felix Fasching'), arxiv.Result.Author('Juri Schreib'), arxiv.Result.Author('Andreas Steininger'), arxiv.Result.Author('Muhammad Shafique')]","Bluetooth (BT) has revolutionized close-range communication enabling smart
capabilities in everyday devices through wireless technology. One of the most
important sub-domains of Internet-of-Things (IoT) specializes in the usage of
BT technologies to develop smart homes and environments, which include
hospitals, buildings, shopping facilities, etc. to offer a wide-range of
features, like instantaneous and remote access to ventilation, lighting,
security, localization, and tracking. However, the deployment of such features
in smart infrastructures are typically unaccompanied by appropriate security
measures that safeguard the data and protect its users. Towards this, we
propose the ATLAS framework, which is composed of our novel IoT architecture
and secure networking stack that can be used to anonymously localize and track
smartphones and wearables by deploying multiple Bluetooth Low Energy (BLE)
beacons across the environment. The proposed networking stack enables varying
levels of encryption across all layers of the communication stack to ensure an
easy-to-adopt, secure-by-design network architecture. We also deploy a novel
data transformation and fingerprinting-based localization algorithm, which is
highly effective in localizing user devices within a given area. The ATLAS
framework is open-sourced at https://atlas-tuw.sourceforge.io to enable
wide-spread adoption and further research and development."
15170,"We do this by        //atlas-tuw.sourceforge.io, which can be easily adopted for
establishing an initial communication via a quick response     similar IoT architectures to ensure wide-spread adoption and
(QR) code (generated by the system integrator; block 0 in      further research in this domain.","The proposed secure
typically active communicating with other wearables such       networking stack is open-source and available online at https:
as smart-watches and wireless headphones.","The initial pairing of the user
Fig.",2022-12-20 14:33:34+00:00,ATLAS: An IoT Architecture and Secure Open-source Networking Stack for Anonymous Localization and Tracking Using Smartphones and Bluetooth Beacons,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Bharath Srinivas Prabakaran'), arxiv.Result.Author('Felix Fasching'), arxiv.Result.Author('Juri Schreib'), arxiv.Result.Author('Andreas Steininger'), arxiv.Result.Author('Muhammad Shafique')]","Bluetooth (BT) has revolutionized close-range communication enabling smart
capabilities in everyday devices through wireless technology. One of the most
important sub-domains of Internet-of-Things (IoT) specializes in the usage of
BT technologies to develop smart homes and environments, which include
hospitals, buildings, shopping facilities, etc. to offer a wide-range of
features, like instantaneous and remote access to ventilation, lighting,
security, localization, and tracking. However, the deployment of such features
in smart infrastructures are typically unaccompanied by appropriate security
measures that safeguard the data and protect its users. Towards this, we
propose the ATLAS framework, which is composed of our novel IoT architecture
and secure networking stack that can be used to anonymously localize and track
smartphones and wearables by deploying multiple Bluetooth Low Energy (BLE)
beacons across the environment. The proposed networking stack enables varying
levels of encryption across all layers of the communication stack to ensure an
easy-to-adopt, secure-by-design network architecture. We also deploy a novel
data transformation and fingerprinting-based localization algorithm, which is
highly effective in localizing user devices within a given area. The ATLAS
framework is open-sourced at https://atlas-tuw.sourceforge.io to enable
wide-spread adoption and further research and development."
15171,"Our
framework is open-sourced at https://atlas-tuw.sourceforge.io
to enable wide-spread adoption and reproducibility, which can
further research and development in this ﬁeld.","The ATLAS framework
analyzes a combination of signal strength, hashed user IDs,
beacon UUIDs, and timestamps to effectively determine the
proximal location of each user in the environment, thereby
enabling privacy-preserving contact tracing capabilities.","In the next phase of our work, we propose to evaluate
the scalability of our ATLAS framework using a larger
number of bluetooth beacons and smartphones, followed by
the deployment of these beacons across multiple buildings
and/other city infrastructures.",2022-12-20 14:33:34+00:00,ATLAS: An IoT Architecture and Secure Open-source Networking Stack for Anonymous Localization and Tracking Using Smartphones and Bluetooth Beacons,cs.NI,"['cs.NI', 'cs.CR']","[arxiv.Result.Author('Bharath Srinivas Prabakaran'), arxiv.Result.Author('Felix Fasching'), arxiv.Result.Author('Juri Schreib'), arxiv.Result.Author('Andreas Steininger'), arxiv.Result.Author('Muhammad Shafique')]","Bluetooth (BT) has revolutionized close-range communication enabling smart
capabilities in everyday devices through wireless technology. One of the most
important sub-domains of Internet-of-Things (IoT) specializes in the usage of
BT technologies to develop smart homes and environments, which include
hospitals, buildings, shopping facilities, etc. to offer a wide-range of
features, like instantaneous and remote access to ventilation, lighting,
security, localization, and tracking. However, the deployment of such features
in smart infrastructures are typically unaccompanied by appropriate security
measures that safeguard the data and protect its users. Towards this, we
propose the ATLAS framework, which is composed of our novel IoT architecture
and secure networking stack that can be used to anonymously localize and track
smartphones and wearables by deploying multiple Bluetooth Low Energy (BLE)
beacons across the environment. The proposed networking stack enables varying
levels of encryption across all layers of the communication stack to ensure an
easy-to-adopt, secure-by-design network architecture. We also deploy a novel
data transformation and fingerprinting-based localization algorithm, which is
highly effective in localizing user devices within a given area. The ATLAS
framework is open-sourced at https://atlas-tuw.sourceforge.io to enable
wide-spread adoption and further research and development."
15256,"However, translation of these techniques
        into viable systems that could be used for long-term monitoring is one of the major
        considerations that is often overlooked, and requires further research and evaluation
        to assess their practicality and safety.","• Translation of novel architectures to viable systems: Myriads of new circuits,
        architectures and techniques have been proposed in the last decade for powering,
        sensing and communication in the bio-nodes.","Figure 1(c) also shows the traditional bio-sensing architecture, comprising of (a) a
bio-sensor node and (b) an on-body hub, with which the bio-sensor node communicates.",2022-12-21 21:18:39+00:00,Bioelectronic Sensor Nodes for Internet of Bodies,cs.NI,['cs.NI'],"[arxiv.Result.Author('Baibhab Chatterjee'), arxiv.Result.Author('Pedram Mohseni'), arxiv.Result.Author('Shreyas Sen')]","Energy-efficient sensing with Physically-secure communication for bio-sensors
on, around and within the Human Body is a major area of research today for
development of low-cost healthcare, enabling continuous monitoring and/or
secure, perpetual operation. These devices, when used as a network of nodes
form the Internet of Bodies (IoB), which poses certain challenges including
stringent resource constraints (power/area/computation/memory), simultaneous
sensing and communication, and security vulnerabilities as evidenced by the DHS
and FDA advisories. One other major challenge is to find an efficient on-body
energy harvesting method to support the sensing, communication, and security
sub-modules. Due to the limitations in the harvested amount of energy, we
require reduction of energy consumed per unit information, making the use of
in-sensor analytics/processing imperative. In this paper, we review the
challenges and opportunities in low-power sensing, processing and
communication, with possible powering modalities for future bio-sensor nodes.
Specifically, we analyze, compare and contrast (a) different sensing mechanisms
such as voltage/current domain vs time-domain, (b) low-power, secure
communication modalities including wireless techniques and human-body
communication, and (c) different powering techniques for both wearable devices
and implants."
15370,"communication for haptics and Tactile applications
will be supported by the two fundamental drivers for                                                          China Communications
6G, viz., IoE and mobile Internet, to realize compre-

28
6.1.1 The 4C Tradeoff                                     Hence, the wireless channel interference remains a key
                                                          challenge that requires further research investigations.",The holographic and high-precision         challenges pertaining to the i4C.,"In [46], it was proved that with an integrated system
harnessing synergistic combinations of different func-    6.1.4 Security Issues in 4C
tionalities/resources, the same types of services can
be realized.",2022-12-26 12:58:56+00:00,"Beyond 5G Networks: Integration of Communication, Computing, Caching, and Control",cs.NI,"['cs.NI', 'cs.DC', 'cs.LG', 'cs.SY', 'eess.SP', 'eess.SY']","[arxiv.Result.Author('Musbahu Mohammed Adam'), arxiv.Result.Author('Liqiang Zhao'), arxiv.Result.Author('Kezhi Wang'), arxiv.Result.Author('Zhu Han')]","In recent years, the exponential proliferation of smart devices with their
intelligent applications poses severe challenges on conventional cellular
networks. Such challenges can be potentially overcome by integrating
communication, computing, caching, and control (i4C) technologies. In this
survey, we first give a snapshot of different aspects of the i4C, comprising
background, motivation, leading technological enablers, potential applications,
and use cases. Next, we describe different models of communication, computing,
caching, and control (4C) to lay the foundation of the integration approach. We
review current state-of-the-art research efforts related to the i4C, focusing
on recent trends of both conventional and artificial intelligence (AI)-based
integration approaches. We also highlight the need for intelligence in
resources integration. Then, we discuss integration of sensing and
communication (ISAC) and classify the integration approaches into various
classes. Finally, we propose open challenges and present future research
directions for beyond 5G networks, such as 6G."
15371,"The classical information the-
                                                            oretical model (by which instantaneous rate regions
The recent emergence of edge intelligence will un-          is addressed) is not directly applicable to the con-
doubtedly trigger further research investigation.","the theoretical capacity of each individual functional-
                                                            ity of 4C remains a potential direction that quest for
6.2.2 Integration                                           further investigations.",The       verged system of these functionalities.,2022-12-26 12:58:56+00:00,"Beyond 5G Networks: Integration of Communication, Computing, Caching, and Control",cs.NI,"['cs.NI', 'cs.DC', 'cs.LG', 'cs.SY', 'eess.SP', 'eess.SY']","[arxiv.Result.Author('Musbahu Mohammed Adam'), arxiv.Result.Author('Liqiang Zhao'), arxiv.Result.Author('Kezhi Wang'), arxiv.Result.Author('Zhu Han')]","In recent years, the exponential proliferation of smart devices with their
intelligent applications poses severe challenges on conventional cellular
networks. Such challenges can be potentially overcome by integrating
communication, computing, caching, and control (i4C) technologies. In this
survey, we first give a snapshot of different aspects of the i4C, comprising
background, motivation, leading technological enablers, potential applications,
and use cases. Next, we describe different models of communication, computing,
caching, and control (4C) to lay the foundation of the integration approach. We
review current state-of-the-art research efforts related to the i4C, focusing
on recent trends of both conventional and artificial intelligence (AI)-based
integration approaches. We also highlight the need for intelligence in
resources integration. Then, we discuss integration of sensing and
communication (ISAC) and classify the integration approaches into various
classes. Finally, we propose open challenges and present future research
directions for beyond 5G networks, such as 6G."
15373,"We further study the reasons why these traditional probability distributions fail to model control
traffic by analyzing how well the Poisson distribution can model the burstiness of control-plane
traffic via variance-time plots [19, 26], and directly comparing the cumulative distributions of the
trace with the fitted Poisson distributions.","Our statistical test results show that surprisingly, the inter-arrival time of the control
events and the sojourn time in the four UE states of EMM and ECM (DEREGISTERED, REGISTERED,
CONNECTED, and IDLE) for the mobile network cannot be modeled as Poisson processes or other
traditional probability distributions, including Pareto [21], Weibull [39] and Tcplib [16, 17].","Our analysis reveals that the control-plane traffic of
the mobile network has much higher burstiness and longer tails, in their cumulative distributions,
compared to the traditional probability models.",2022-12-26 18:31:50+00:00,Characterizing and Modeling Control-Plane Traffic for Mobile Core Network,cs.NI,['cs.NI'],"[arxiv.Result.Author('Jiayi Meng'), arxiv.Result.Author('Jingqi Huang'), arxiv.Result.Author('Y. Charlie Hu'), arxiv.Result.Author('Yaron Koral'), arxiv.Result.Author('Xiaojun Lin'), arxiv.Result.Author('Muhammad Shahbaz'), arxiv.Result.Author('Abhigyan Sharma')]","In this paper, we first carry out to our knowledge the first in-depth
characterization of control-plane traffic, using a real-world control-plane
trace for 37,325 UEs sampled at a real-world LTE Mobile Core Network (MCN). Our
analysis shows that control events exhibit significant diversity in device
types and time-of-day among UEs. Second, we study whether traditional
probability distributions that have been widely adopted for modeling Internet
traffic can model the control-plane traffic originated from individual UEs. Our
analysis shows that the inter-arrival time of the control events as well as the
sojourn time in the UE states of EMM and ECM for the cellular network cannot be
modeled as Poisson processes or other traditional probability distributions. We
further show that the reasons that these models fail to capture the
control-plane traffic are due to its higher burstiness and longer tails in the
cumulative distribution than the traditional models. Third, we propose a
two-level hierarchical state-machine-based traffic model for UE clusters
derived from our adaptive clustering scheme based on the Semi-Markov Model to
capture key characteristics of mobile network control-plane traffic -- in
particular, the dependence among events generated by each UE, and the diversity
in device types and time-of-day among UEs. Finally, we show how our model can
be easily adjusted from LTE to 5G to support modeling 5G control-plane traffic,
when the sizable control-plane trace for 5G UEs becomes available to train the
adjusted model. The developed control-plane traffic generator for LTE/5G
networks is open-sourced to the research community to support high-performance
MCN architecture design R&D."
15414,"We demonstrated that         conducting further research on the impact of other parameters
a trigger line adjacent to the RSU outperforms trigger lines        of transactional protocols; the ﬁndings from this paper will
before or after the RSU.","We are currently
especially where a transaction occurs.",While this suggests the superiority        allow a smaller search space for optimal solutions.,2022-12-28 18:01:49+00:00,Performance Analysis of V2I Zone Activation and Scalability for C-V2X Transactional Services,cs.NI,['cs.NI'],"[arxiv.Result.Author('Mahdi Zaman'), arxiv.Result.Author('Md Saifuddin'), arxiv.Result.Author('Mahdi Razzaghpour'), arxiv.Result.Author('Yaser P. Fallah')]","Cellular-V2X (C-V2X) enables communication between vehicles and other
transportation entities over the 5.9GHz spectrum. C-V2X utilizes direct
communication mode for safety packet broadcasts (through the usage of periodic
basic safety messages) while leaving sufficient room in the resource pool for
advanced service applications. While many such ITS applications are under
development, it is crucial to identify and optimize the relevant network
parameters. In this paper, we envision an infrastructure-assisted transaction
procedure entirely carried out by C-V2X, and we optimize it in terms of the
service parameters. To achieve the service utility of a transaction class, two
C-V2X entities require a successive exchange of multiple messages. With this
notion, our proposed application prototype can be generalized for any vehicular
service to establish connections on-the-fly. We identify suitable activation
zones for vehicles and assess their impact on service efficiency. The results
show a variety of potential service and parameter settings that can be
appropriate for different use-cases, laying the foundation for subsequent
studies."
