,further research line,further research prefix,further research suffix,publication date,title,primary category,categories,authors,abstract
301,"Answers to the research
questions are summarised and we conclude with observations and proposals
for further study of polarised communities.","The revealed polarised communities are compared from behavioural and
content perspectives, as well as through bot analysis.","2 The Dataset and its Timeline

The primary dataset, ‘ArsonEmergency’, consists of 27,546 tweets contain-
ing this term posted by 12,872 unique accounts from 31 December 2019
to 17 January 2020.",2022-01-10 03:44:31+00:00,Promoting and countering misinformation during Australia's 2019-2020 bushfires: A case study of polarisation,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Author('Derek Weber'), arxiv.Result.Author('Lucia Falzon'), arxiv.Result.Author('Lewis Mitchell'), arxiv.Result.Author('Mehwish Nasim')]","During Australia's unprecedented bushfires in 2019-2020, misinformation
blaming arson resurfaced on Twitter using #ArsonEmergency. The extent to which
bots were responsible for disseminating and amplifying this misinformation has
received scrutiny in the media and academic research. Here we study Twitter
communities spreading this misinformation during the population-level event,
and investigate the role of online communities and bots. Our in-depth
investigation of the dynamics of the discussion uses a phased approach --
before and after reporting of bots promoting the hashtag was broadcast by the
mainstream media. Though we did not find many bots, the most bot-like accounts
were social bots, which present as genuine humans. Further, we distilled
meaningful quantitative differences between two polarised communities in the
Twitter discussion, resulting in the following insights. First, Supporters of
the arson narrative promoted misinformation by engaging others directly with
replies and mentions using hashtags and links to external sources. In response,
Opposers retweeted fact-based articles and official information. Second,
Supporters were embedded throughout their interaction networks, but Opposers
obtained high centrality more efficiently despite their peripheral positions.
By the last phase, Opposers and unaffiliated accounts appeared to coordinate,
potentially reaching a broader audience. Finally, unaffiliated accounts shared
the same URLs as Opposers over Supporters by a ratio of 9:1 in the last phase,
having shared mostly Supporter URLs in the first phase. This foiled Supporters'
efforts, highlighting the value of exposing misinformation campaigns. We
speculate that the communication strategies observed here could be discoverable
in other misinformation-related discussions and could inform
counter-strategies."
403,"We will further study the more refined division strategy
admit that simple modularity reconstruction cannot yet achieve                                                                                                                                                           for ground-truth networks on VGAER and the semi-supervised
the best NMI performance on some networks with ground truth,                                                                                                                                                             framework.",But we also                                                                                                                                                       and stable.,which leaves a lot of room for improvement in VGAER.,2022-01-08 02:19:47+00:00,VGAER: graph neural network reconstruction based community detection,cs.SI,"['cs.SI', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Chenyang Qiu'), arxiv.Result.Author('Zhaoci Huang'), arxiv.Result.Author('Wenzhe Xu'), arxiv.Result.Author('Huijia Li')]","Community detection is a fundamental and important issue in network science,
but there are only a few community detection algorithms based on graph neural
networks, among which unsupervised algorithms are almost blank. By fusing the
high-order modularity information with network features, this paper proposes a
Variational Graph AutoEncoder Reconstruction based community detection VGAER
for the first time, and gives its non-probabilistic version. They do not need
any prior information. We have carefully designed corresponding input features,
decoder, and downstream tasks based on the community detection task and these
designs are concise, natural, and perform well (NMI values under our design are
improved by 59.1% - 565.9%). Based on a series of experiments with wide range
of datasets and advanced methods, VGAER has achieved superior performance and
shows strong competitiveness and potential with a simpler design. Finally, we
report the results of algorithm convergence analysis and t-SNE visualization,
which clearly depicted the stable performance and powerful network modularity
ability of VGAER. Our codes are available at https://github.com/qcydm/VGAER."
404,"We will further study the more refined division strategy
mization theory, VGAER’s high Q values and powerful network
modularity ability (visualization) on the unknown-community net-
works are impressive; at the same time, the performance of VGAER 1
is also good and stable on networks with ground truth.","And the NMI and Q results
                                                                                                                          of VGAER and GAER on real world networks are impressively high
As a joint optimization method coming from modularity maxi-                                                               and stable.","But we also
DLG-AAAI ’22, Feb 28, 2022, Vancouver, BC                                                                                 Chenyang Qiu, Zhaoci Huang, Wenzhe Xu, and Huijia Li

for ground-truth networks on VGAER and the semi-supervised                               [25] Carl Eckart and Gale Young.",2022-01-08 02:19:47+00:00,VGAER: graph neural network reconstruction based community detection,cs.SI,"['cs.SI', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Chenyang Qiu'), arxiv.Result.Author('Zhaoci Huang'), arxiv.Result.Author('Wenzhe Xu'), arxiv.Result.Author('Huijia Li')]","Community detection is a fundamental and important issue in network science,
but there are only a few community detection algorithms based on graph neural
networks, among which unsupervised algorithms are almost blank. By fusing the
high-order modularity information with network features, this paper proposes a
Variational Graph AutoEncoder Reconstruction based community detection VGAER
for the first time, and gives its non-probabilistic version. They do not need
any prior information. We have carefully designed corresponding input features,
decoder, and downstream tasks based on the community detection task and these
designs are concise, natural, and perform well (NMI values under our design are
improved by 59.1% - 565.9%). Based on a series of experiments with wide range
of datasets and advanced methods, VGAER has achieved superior performance and
shows strong competitiveness and potential with a simpler design. Finally, we
report the results of algorithm convergence analysis and t-SNE visualization,
which clearly depicted the stable performance and powerful network modularity
ability of VGAER. Our codes are available at https://github.com/qcydm/VGAER."
405,We will further study the more reﬁned division      ral network.,"Unsupervised con-
and GAER on real world networks are impressively high           strained community detection via self-expressive graph neu-
and stable.","In Uncertainty in Artiﬁcial Intelligence, 1078–
strategy for ground-truth networks on VGAER and the semi-       1088.",2022-01-08 02:19:47+00:00,VGAER: graph neural network reconstruction based community detection,cs.SI,"['cs.SI', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Chenyang Qiu'), arxiv.Result.Author('Zhaoci Huang'), arxiv.Result.Author('Wenzhe Xu'), arxiv.Result.Author('Huijia Li')]","Community detection is a fundamental and important issue in network science,
but there are only a few community detection algorithms based on graph neural
networks, among which unsupervised algorithms are almost blank. By fusing the
high-order modularity information with network features, this paper proposes a
Variational Graph AutoEncoder Reconstruction based community detection VGAER
for the first time, and gives its non-probabilistic version. They do not need
any prior information. We have carefully designed corresponding input features,
decoder, and downstream tasks based on the community detection task and these
designs are concise, natural, and perform well (NMI values under our design are
improved by 59.1% - 565.9%). Based on a series of experiments with wide range
of datasets and advanced methods, VGAER has achieved superior performance and
shows strong competitiveness and potential with a simpler design. Finally, we
report the results of algorithm convergence analysis and t-SNE visualization,
which clearly depicted the stable performance and powerful network modularity
ability of VGAER. Our codes are available at https://github.com/qcydm/VGAER."
406,We will further study the more reﬁned division      ral network.,"Unsupervised con-
and GAER on real world networks are impressively high           strained community detection via self-expressive graph neu-
and stable.","In Uncertainty in Artiﬁcial Intelligence, 1078–
strategy for ground-truth networks on VGAER and the semi-       1088.",2022-01-08 02:19:47+00:00,VGAER: Graph Neural Network Reconstruction based Community Detection,cs.SI,"['cs.SI', 'cs.AI', 'cs.LG']","[arxiv.Result.Author('Chenyang Qiu'), arxiv.Result.Author('Zhaoci Huang'), arxiv.Result.Author('Wenzhe Xu'), arxiv.Result.Author('Huijia Li')]","Community detection is a fundamental and important issue in network science,
but there are only a few community detection algorithms based on graph neural
networks, among which unsupervised algorithms are almost blank. By fusing the
high-order modularity information with network features, this paper proposes a
Variational Graph AutoEncoder Reconstruction based community detection VGAER
for the first time, and gives its non-probabilistic version. They do not need
any prior information. We have carefully designed corresponding input features,
decoder, and downstream tasks based on the community detection task and these
designs are concise, natural, and perform well (NMI values under our design are
improved by 59.1% - 565.9%). Based on a series of experiments with wide range
of datasets and advanced methods, VGAER has achieved superior performance and
shows strong competitiveness and potential with a simpler design. Finally, we
report the results of algorithm convergence analysis and t-SNE visualization,
which clearly depicted the stable performance and powerful network modularity
ability of VGAER. Our codes are available at https://github.com/qcydm/VGAER."
581,"Subreddits that                Temporal & Content Analysis
are centered around game, such as r/PUBGMobile and
r/CallOfDutyMobile, have the largest proportions of nega-      To further study the content of the words of each comment
tive comments of the game industry topic, whereas subred-      and the changes of public opinion on Chinese technology
dits that are centered around smartphones, such as r/Xiaomi    companies over time, we study the context of each word by
and r/Android, have the largest proportions of negative com-   employing skip-gram algorithms in the word2vec (Mikolov
ments of phone complaints and criticism topic.","The topic distributions
correspond to the subreddit’s theme well.",More im-        et al.,2022-01-14 16:16:58+00:00,"""Ban the Chinese spyware!"": A Fine-Grained Analysis of Public Opinion toward Chinese Technology Companies on Reddit",cs.SI,['cs.SI'],"[arxiv.Result.Author('Enting Zhou'), arxiv.Result.Author('Yurong Liu'), arxiv.Result.Author('Hanjia Lyu'), arxiv.Result.Author('Jiebo Luo')]","In the face of the growing global influence and prevalence of Chinese
technology companies, governments worldwide have expressed concern and mistrust
toward these companies. There have been few studies that focus on large-scale
public reaction to this phenomenon. This study aims to fill in the gap of
understanding the public opinion toward Chinese technology companies using
Reddit data, a popular news-oriented social media platform. We employ the
state-of-the-art transformer model to build a reliable sentiment classifier. We
then use LDA to model the topics associated with positive and negative
comments. We also conduct content analysis by studying the changes in the
semantic meaning of the companies' names over time. Our main findings include
the following: 1) There are 68% more negative comments than positive comments
toward Chinese technology companies; 2) Positive comments are mostly associated
with the companies' consumer products, such as smartphones, laptops, and
wearable electronics. Negative comments have a more diverse topic distribution
(notable topics include criticism toward the platform, dissatisfaction with the
companies' smartphone products, companies' ties to the Chinese government, data
security concerns, 5G construction, and general politics discussions); and 3)
Characterization of each technology company is usually centered around a
particular predominant theme related to the company, while real-world political
events may trigger drastic changes in users' characterization."
616,"In the sections that fol-      stances in which Tweets are used as references in Wikipedia
low, we present and discuss research questions and studies        articles would allow to further study Twitter and Wikipedia’s
with respect to three areas: (1) Wikipedia’s and Twitter’s co-    co-dependency and give an even more holistic picture of
relationship (2) the use of Wikipedia links in Twitter con-       their relationship.","Finally, the de-
Due to it’s unique nature, we believe that TWikiL offers a        velopment of a complementary dataset, that collects all in-
wide range of scholarly use cases.","versations with a focus on fact-checking and ﬁghting misin-
formation and (3) digital humanities and the history of the       Wikipedia links in Twitter conversations
web.",2022-01-15 13:32:05+00:00,TWikiL -- The Twitter Wikipedia Link Dataset,cs.SI,['cs.SI'],[arxiv.Result.Author('Florian Meier')],"Recent research has shown how strongly Wikipedia and other web services or
platforms are connected. For example, search engines rely heavily on surfacing
Wikipedia links to satisfy their users' information needs and volunteer-created
Wikipedia content frequently gets re-used on other social media platforms like
Reddit. However, publicly accessible datasets that enable researchers to study
the interrelationship between Wikipedia and other platforms are sparse. In
addition to that, most studies only focus on certain points in time and don't
consider the historical perspective. To begin solving these problems we
developed TWikiL, the Twitter Wikipedia Link Dataset, which contains all
Wikipedia links posted on Twitter in the period 2006 to January 2021. We
extract Wikipedia links from Tweets and enrich the referenced articles with
their respective Wikidata identifiers and Wikipedia topic categories, which
will make this dataset immediately useful for a large range of scholarly use
cases. In this paper, we describe the data collection process, perform an
initial exploratory analysis and present a comprehensive overview of how this
dataset can be useful for the research community."
617,"Finally, the develop-                           Conclusion
ment of a complementary dataset, that collects all instances
in which Tweets are used as references in Wikipedia articles      As we see more and more evidence for web platforms being
would allow to further study Twitter and Wikipedia’s co-          tightly connected to each other, there is an increasing need
dependency and give an even more holistic picture of their        for not only studying them in isolation but paint a holistic
relationship.","attracts users with malicious intentions which can lead to an
increase in vandalism or even edit wars.","picture of their dependency and the value they contribute
                                                                  to each other.",2022-01-15 13:32:05+00:00,TWikiL -- The Twitter Wikipedia Link Dataset,cs.SI,['cs.SI'],[arxiv.Result.Author('Florian Meier')],"Recent research has shown how strongly Wikipedia and other web services or
platforms are connected. For example, search engines rely heavily on surfacing
Wikipedia links to satisfy their users' information needs and volunteer-created
Wikipedia content frequently gets re-used on other social media platforms like
Reddit. However, publicly accessible datasets that enable researchers to study
the interrelationship between Wikipedia and other platforms are sparse. In
addition to that, most studies only focus on certain points in time and don't
consider the historical perspective. To begin solving these problems we
developed TWikiL, the Twitter Wikipedia Link Dataset, which contains all
Wikipedia links posted on Twitter in the period 2006 to January 2021. We
extract Wikipedia links from Tweets and enrich the referenced articles with
their respective Wikidata identifiers and Wikipedia topic categories, which
will make this dataset immediately useful for a large range of scholarly use
cases. In this paper, we describe the data collection process, perform an
initial exploratory analysis and present a comprehensive overview of how this
dataset can be useful for the research community."
638,"Although further research is
underway to determine where this peak occurs.","As the dependency network is
the reverse projection of the contributor network we can conclude that the local efficiency will continue
to drop while the global efficiency will peak and then begin dropping.","Placing these results in the context of code
development and maintenance then provides insights into problem solving networks.",2022-01-16 13:02:19+00:00,Social Networks as a Collective Intelligence: An Examination of the Python Ecosystem,cs.SI,"['cs.SI', 'cs.PL']","[arxiv.Result.Author('Thomas Pike'), arxiv.Result.Author('Robert Colter'), arxiv.Result.Author('Mark Bailey'), arxiv.Result.Author('Jackie Kazil'), arxiv.Result.Author('John Speed Meyers')]","The Python ecosystem represents a global, data rich, technology-enabled
network. By analyzing Python's dependency network, its top 14 most imported
libraries and cPython (or core Python) libraries, this research finds clear
evidence the Python network can be considered a problem solving network.
Analysis of the contributor network of the top 14 libraries and cPython reveals
emergent specialization, where experts of specific libraries are isolated and
focused while other experts link these critical libraries together, optimizing
both local and global information exchange efficiency. As these networks are
expanded, the local efficiency drops while the density increases, representing
a possible transition point between exploitation (optimizing working solutions)
and exploration (finding new solutions). These results provide insight into the
optimal functioning of technology-enabled social networks and may have larger
implications for the effective functioning of modern organizations."
639,The opportunity for further research in this area is substantial.,"The one exception contributes to both cPython and six, which is a

                                 transition library between Python 2 and Python 3.","A first step is getting more
contributor data to expand this analysis to more of the ecosystem.",2022-01-16 13:02:19+00:00,Social Networks as a Collective Intelligence: An Examination of the Python Ecosystem,cs.SI,"['cs.SI', 'cs.PL']","[arxiv.Result.Author('Thomas Pike'), arxiv.Result.Author('Robert Colter'), arxiv.Result.Author('Mark Bailey'), arxiv.Result.Author('Jackie Kazil'), arxiv.Result.Author('John Speed Meyers')]","The Python ecosystem represents a global, data rich, technology-enabled
network. By analyzing Python's dependency network, its top 14 most imported
libraries and cPython (or core Python) libraries, this research finds clear
evidence the Python network can be considered a problem solving network.
Analysis of the contributor network of the top 14 libraries and cPython reveals
emergent specialization, where experts of specific libraries are isolated and
focused while other experts link these critical libraries together, optimizing
both local and global information exchange efficiency. As these networks are
expanded, the local efficiency drops while the density increases, representing
a possible transition point between exploitation (optimizing working solutions)
and exploration (finding new solutions). These results provide insight into the
optimal functioning of technology-enabled social networks and may have larger
implications for the effective functioning of modern organizations."
845,"Therefore, further research using other factors is needed to monitor the change of
public attitudes.","The survey was performed from May to June 2021, public attitudes may have changed
over this time.",6.,2022-01-20 18:07:14+00:00,Influences of social media usage on public attitudes and behavior towards COVID-19 vaccine in the Arab world,cs.SI,['cs.SI'],"[arxiv.Result.Author('Md. Rafiul Biswas'), arxiv.Result.Author('Hazrat Ali'), arxiv.Result.Author('Raian Ali'), arxiv.Result.Author('Zubair Shah')]","Background: Vaccination programs are effective only when a significant
percentage of people are vaccinated. However, vaccine acceptance varies among
communities around the world. Social media usage is arguably one of the factors
affecting public attitudes towards vaccines. Objective: This study aims to
identify if the social media usages factors can be used to predict attitudes
and behavior towards the COVID-19 vaccines among the people in the Arab world.
Methods: An online survey was conducted in the Arab countries and 217 Arab
people participated in this study. Logistic regression was applied to identify
what demographics and social media usage factors predict public attitudes and
behavior towards the COVID-19 vaccines. Results: Of the 217 participants,
56.22% of them were willing to accept the vaccine and 41.47% of them were
hesitant. This study shows that none of the social media usages factors were
significant enough to predict the actual vaccine acceptance behavior. Whereas
the analysis showed few of the social media usage factors can predict public
attitudes towards the COVID-19 vaccines. For example, frequent social media
users were 2.85 times more likely to agree that the risk of COVID-19 is being
exaggerated (OR=2.85, 95% CI=0.86-9.45, p=0.046) than infrequent social media
users. Whereas participants having more trust in vaccine information shared by
their contacts are less likely to agree that decision-makers have verified that
vaccines are safe (OR=0.528, 95% CI= 0.276-1.012, p=0.05). Conclusion: The use
of social media and information shared on it may affect public attitudes
towards COVID-19 vaccines. Therefore, disseminating correct and validated
information about COVID-19 and other vaccines on social media is important for
increasing public trust and countering the impact of incorrect and
misinformation."
846,"Therefore, further research
vaccine.","The
Many participants who believed in the information shared by            survey was performed from May to June 2021, and public
their contacts were concerned about the side effect of the             attitudes may have changed.","Participants who trusted information shared by their          using other factors is needed to monitor the change in public
contacts were more likely to believe that vaccines may increase        attitudes.",2022-01-20 18:07:14+00:00,Influences of social media usage on public attitudes and behavior towards COVID-19 vaccine in the Arab world,cs.SI,['cs.SI'],"[arxiv.Result.Author('Md. Rafiul Biswas'), arxiv.Result.Author('Hazrat Ali'), arxiv.Result.Author('Raian Ali'), arxiv.Result.Author('Zubair Shah')]","Background: Vaccination programs are effective only when a significant
percentage of people are vaccinated. However, vaccine acceptance varies among
communities around the world. Social media usage is arguably one of the factors
affecting public attitudes towards vaccines. Objective: This study aims to
identify if the social media usages factors can be used to predict attitudes
and behavior towards the COVID-19 vaccines among the people in the Arab world.
Methods: An online survey was conducted in the Arab countries and 217 Arab
people participated in this study. Logistic regression was applied to identify
what demographics and social media usage factors predict public attitudes and
behavior towards the COVID-19 vaccines. Results: Of the 217 participants,
56.22% of them were willing to accept the vaccine and 41.47% of them were
hesitant. This study shows that none of the social media usages factors were
significant enough to predict the actual vaccine acceptance behavior. Whereas
the analysis showed few of the social media usage factors can predict public
attitudes towards the COVID-19 vaccines. For example, frequent social media
users were 2.85 times more likely to agree that the risk of COVID-19 is being
exaggerated (OR=2.85, 95% CI=0.86-9.45, p=0.046) than infrequent social media
users. Whereas participants having more trust in vaccine information shared by
their contacts are less likely to agree that decision-makers have verified that
vaccines are safe (OR=0.528, 95% CI= 0.276-1.012, p=0.05). Conclusion: The use
of social media and information shared on it may affect public attitudes
towards COVID-19 vaccines. Therefore, disseminating correct and validated
information about COVID-19 and other vaccines on social media is important for
increasing public trust and countering the impact of incorrect and
misinformation."
1131,"Can the Wikipedia moderation model
the network mining community to spur further research in social                                 rescue the social marketplace of ideas?",2021.,arXiv preprint arXiv:2104.13754 (2021).,2022-01-27 17:22:49+00:00,Learning Stance Embeddings from Signed Social Graphs,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('John Pougué-Biyong'), arxiv.Result.Author('Akshay Gupta'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ahmed El-Kishky')]","A key challenge in social network analysis is understanding the position, or
stance, of people in the graph on a large set of topics. While past work has
modeled (dis)agreement in social networks using signed graphs, these approaches
have not modeled agreement patterns across a range of correlated topics. For
instance, disagreement on one topic may make disagreement(or agreement) more
likely for related topics. We propose the Stance Embeddings Model(SEM), which
jointly learns embeddings for each user and topic in signed social graphs with
distinct edge types for each topic. By jointly learning user and topic
embeddings, SEM is able to perform cold-start topic stance detection,
predicting the stance of a user on topics for which we have not observed their
engagement. We demonstrate the effectiveness of SEM using two large-scale
Twitter signed graph datasets we open-source. One dataset, TwitterSG, labels
(dis)agreements using engagements between users via tweets to derive
topic-informed, signed edges. The other, BirdwatchSG, leverages community
reports on misinformation and misleading content. On TwitterSG and BirdwatchSG,
SEM shows a 39% and 26% error reduction respectively against strong baselines."
1132,"We open-source these two datasets to the network
                                                           mining community to spur further research in social network anal-
                                                           ysis and stance detection.","Experimental results show
                                                           that SEM embeddings outperform state-of-the-art signed-graph em-
                                                           bedding techniques on two new Twitter datasets: TwitterSG and
                                                           BirdwatchSG.","Learning Stance Embeddings from Signed Social Graphs                                                               WSDM ’23, February 27-March 3, 2023, Singapore, Singapore

ACKNOWLEDGMENTS                                                                              In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021.",2022-01-27 17:22:49+00:00,Learning Stance Embeddings from Signed Social Graphs,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('John Pougué-Biyong'), arxiv.Result.Author('Akshay Gupta'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ahmed El-Kishky')]","A key challenge in social network analysis is understanding the position, or
stance, of people in the graph on a large set of topics. While past work has
modeled (dis)agreement in social networks using signed graphs, these approaches
have not modeled agreement patterns across a range of correlated topics. For
instance, disagreement on one topic may make disagreement(or agreement) more
likely for related topics. We propose the Stance Embeddings Model(SEM), which
jointly learns embeddings for each user and topic in signed social graphs with
distinct edge types for each topic. By jointly learning user and topic
embeddings, SEM is able to perform cold-start topic stance detection,
predicting the stance of a user on topics for which we have not observed their
engagement. We demonstrate the effectiveness of SEM using two large-scale
Twitter signed graph datasets we open-source. One dataset, TwitterSG, labels
(dis)agreements using engagements between users via tweets to derive
topic-informed, signed edges. The other, BirdwatchSG, leverages community
reports on misinformation and misleading content. On TwitterSG and BirdwatchSG,
SEM shows a 39% and 26% error reduction respectively against strong baselines."
1276,should be investigated through further research (see Sec-                                                                Health Ben.,"For example, our data suggests that DXM                                                        General
may be related to health problems and addiction, which                                                              Glowing Exp.",tion 7.2).,2022-01-31 08:40:17+00:00,Glowing Experience or Bad Trip? A Quantitative Analysis of User Reported Drug Experiences on Erowid.org,cs.SI,['cs.SI'],"[arxiv.Result.Author('Angelina Mooseder'), arxiv.Result.Author('Momin M. Malik'), arxiv.Result.Author('Hemank Lamba'), arxiv.Result.Author('Earth Erowid'), arxiv.Result.Author('Sylvia Thyssen'), arxiv.Result.Author('Juergen Pfeffer')]","Erowid.org is a website dedicated to documenting information about
psychoactive substances, with over 36,000 user-submitted drug Experience
Reports. We study the potential of these reports to provide information about
characteristic experiences with drugs. First, we assess different kinds of drug
experiences, such as 'addiction' or 'bad trips'. We quantitatively analyze how
such experiences are related to substances and user variables. Furthermore, we
classify positive and negative experiences as well as reported addiction using
information about the consumer, substance, context and location of the drug
experience. While variables based only on objective characteristics yield poor
predictive performance for subjective experiences, we find subjective user
reports can help to identify new patterns and impact factors on drug
experiences. In particular, we found a positive association between addiction
experiences and dextromethorphan, a substance with largely unknown withdrawal
effects. Our research can help to gain a deeper sociological understanding of
drug consumption and to identify relationships which may have clinical
relevance. Moreover, it can show how non-mainstream social media platforms can
be utilized to study characteristics of human behavior and how this can be done
in an ethical way in collaboration with the platform providers."
1277,"tematic exploration with and reﬂection on psychoactive sub-      This should allow further research to investigate whether
stances.",They are also likely more engaged in sys-        the motivation for and interpretation of drug consumption.,"In addition, there might be a selection bias in the     there are also demographic differences in the choices drug
data, e.g.",2022-01-31 08:40:17+00:00,Glowing Experience or Bad Trip? A Quantitative Analysis of User Reported Drug Experiences on Erowid.org,cs.SI,['cs.SI'],"[arxiv.Result.Author('Angelina Mooseder'), arxiv.Result.Author('Momin M. Malik'), arxiv.Result.Author('Hemank Lamba'), arxiv.Result.Author('Earth Erowid'), arxiv.Result.Author('Sylvia Thyssen'), arxiv.Result.Author('Juergen Pfeffer')]","Erowid.org is a website dedicated to documenting information about
psychoactive substances, with over 36,000 user-submitted drug Experience
Reports. We study the potential of these reports to provide information about
characteristic experiences with drugs. First, we assess different kinds of drug
experiences, such as 'addiction' or 'bad trips'. We quantitatively analyze how
such experiences are related to substances and user variables. Furthermore, we
classify positive and negative experiences as well as reported addiction using
information about the consumer, substance, context and location of the drug
experience. While variables based only on objective characteristics yield poor
predictive performance for subjective experiences, we find subjective user
reports can help to identify new patterns and impact factors on drug
experiences. In particular, we found a positive association between addiction
experiences and dextromethorphan, a substance with largely unknown withdrawal
effects. Our research can help to gain a deeper sociological understanding of
drug consumption and to identify relationships which may have clinical
relevance. Moreover, it can show how non-mainstream social media platforms can
be utilized to study characteristics of human behavior and how this can be done
in an ethical way in collaboration with the platform providers."
1278,"Standardizing drug dosages is a       scribed, such as ‘Families’ or ‘Mystical Experiences’, show
challenging task which requires extensive domain knowl-          a great potential for further research, as they can provide new
edge.","Many of the categories de-
pecially the drug dosages.","Even if users reported dosages in standardized ways, it    insights into how people experience drug consumption.",2022-01-31 08:40:17+00:00,Glowing Experience or Bad Trip? A Quantitative Analysis of User Reported Drug Experiences on Erowid.org,cs.SI,['cs.SI'],"[arxiv.Result.Author('Angelina Mooseder'), arxiv.Result.Author('Momin M. Malik'), arxiv.Result.Author('Hemank Lamba'), arxiv.Result.Author('Earth Erowid'), arxiv.Result.Author('Sylvia Thyssen'), arxiv.Result.Author('Juergen Pfeffer')]","Erowid.org is a website dedicated to documenting information about
psychoactive substances, with over 36,000 user-submitted drug Experience
Reports. We study the potential of these reports to provide information about
characteristic experiences with drugs. First, we assess different kinds of drug
experiences, such as 'addiction' or 'bad trips'. We quantitatively analyze how
such experiences are related to substances and user variables. Furthermore, we
classify positive and negative experiences as well as reported addiction using
information about the consumer, substance, context and location of the drug
experience. While variables based only on objective characteristics yield poor
predictive performance for subjective experiences, we find subjective user
reports can help to identify new patterns and impact factors on drug
experiences. In particular, we found a positive association between addiction
experiences and dextromethorphan, a substance with largely unknown withdrawal
effects. Our research can help to gain a deeper sociological understanding of
drug consumption and to identify relationships which may have clinical
relevance. Moreover, it can show how non-mainstream social media platforms can
be utilized to study characteristics of human behavior and how this can be done
in an ethical way in collaboration with the platform providers."
1279,"Although we tried a wide range of
models, further research may ﬁnd others which reveal better      Baggott, M.; Coyle, J.; Erowid, E.; Erowid, F.; and Robertson, L.
results and may show other factors, with which consumers         2011.","Frontiers in Neuroscience 14: 149.
ﬁers and parameters used.","Abnormal visual experiences in individuals with histories of
could control the outcome of their drug experience.",2022-01-31 08:40:17+00:00,Glowing Experience or Bad Trip? A Quantitative Analysis of User Reported Drug Experiences on Erowid.org,cs.SI,['cs.SI'],"[arxiv.Result.Author('Angelina Mooseder'), arxiv.Result.Author('Momin M. Malik'), arxiv.Result.Author('Hemank Lamba'), arxiv.Result.Author('Earth Erowid'), arxiv.Result.Author('Sylvia Thyssen'), arxiv.Result.Author('Juergen Pfeffer')]","Erowid.org is a website dedicated to documenting information about
psychoactive substances, with over 36,000 user-submitted drug Experience
Reports. We study the potential of these reports to provide information about
characteristic experiences with drugs. First, we assess different kinds of drug
experiences, such as 'addiction' or 'bad trips'. We quantitatively analyze how
such experiences are related to substances and user variables. Furthermore, we
classify positive and negative experiences as well as reported addiction using
information about the consumer, substance, context and location of the drug
experience. While variables based only on objective characteristics yield poor
predictive performance for subjective experiences, we find subjective user
reports can help to identify new patterns and impact factors on drug
experiences. In particular, we found a positive association between addiction
experiences and dextromethorphan, a substance with largely unknown withdrawal
effects. Our research can help to gain a deeper sociological understanding of
drug consumption and to identify relationships which may have clinical
relevance. Moreover, it can show how non-mainstream social media platforms can
be utilized to study characteristics of human behavior and how this can be done
in an ethical way in collaboration with the platform providers."
1325,"These findings motivate further study on the effect of the expertise and sensitisation of annotators on the quality of
their annotations.","The ratings by the amateurs were
also found to be closer to the W&H dataset’s annotations, corroborating the initially unregulated annotation process.",Al Kuwatly et al.,2022-01-26 10:38:36+00:00,Handling Bias in Toxic Speech Detection: A Survey,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Tanmay Garg'), arxiv.Result.Author('Sarah Masud'), arxiv.Result.Author('Tharun Suresh'), arxiv.Result.Author('Tanmoy Chakraborty')]","The massive growth of social media usage has witnessed a tsunami of online
toxicity in teams of hate speech, abusive posts, cyberbullying, etc. Detecting
online toxicity is challenging due to its inherent subjectivity. Factors such
as the context of the speech, geography, socio-political climate, and
background of the producers and consumers of the posts play a crucial role in
determining if the content can be flagged as toxic. Adoption of automated
toxicity detection models in production can lead to a sidelining of the various
demographic and psychographic groups they aim to help in the first place. It
has piqued researchers' interest in examining unintended biases and their
mitigation. Due to the nascent and multi-faceted nature of the work, complete
literature is chaotic in its terminologies, techniques, and findings. In this
paper, we put together a systematic study to discuss the limitations and
challenges of existing methods.
  We start by developing a taxonomy for categorising various unintended biases
and a suite of evaluation metrics proposed to quantify such biases. We take a
closer look at each proposed method for evaluating and mitigating bias in toxic
speech detection. To examine the limitations of existing methods, we also
conduct a case study to introduce the concept of bias shift due to
knowledge-based bias mitigation methods. The survey concludes with an overview
of the critical challenges, research gaps and future directions. While reducing
toxicity on online platforms continues to be an active area of research, a
systematic study of various biases and their mitigation strategies will help
the research community produce robust and fair models."
1326,"These findings motivate further study on the effect of the expertise and sensitisation of annotators on the quality of
their annotations.","The ratings by the amateurs were
also found to be closer to the W&H dataset’s annotations, corroborating the initially unregulated annotation process.",Al Kuwatly et al.,2022-01-26 10:38:36+00:00,Handling Bias in Toxic Speech Detection: A Survey,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Tanmay Garg'), arxiv.Result.Author('Sarah Masud'), arxiv.Result.Author('Tharun Suresh'), arxiv.Result.Author('Tanmoy Chakraborty')]","The massive growth of social media usage has witnessed a tsunami of online
toxicity in teams of hate speech, abusive posts, cyberbullying, etc. Detecting
online toxicity is challenging due to its inherent subjectivity. Factors such
as the context of the speech, geography, socio-political climate, and
background of the producers and consumers of the posts play a crucial role in
determining if the content can be flagged as toxic. Adoption of automated
toxicity detection models in production can lead to a sidelining of the various
demographic and psychographic groups they aim to help in the first place. It
has piqued researchers' interest in examining unintended biases and their
mitigation. Due to the nascent and multi-faceted nature of the work, complete
literature is chaotic in its terminologies, techniques, and findings. In this
paper, we put together a systematic study to discuss the limitations and
challenges of existing methods.
  We start by developing a taxonomy for categorising various unintended biases
and a suite of evaluation metrics proposed to quantify such biases. We take a
closer look at each proposed method for evaluating and mitigating bias in toxic
speech detection. To examine the limitations of existing methods, we also
conduct a case study to introduce the concept of bias shift due to
knowledge-based bias mitigation methods. The survey concludes with an overview
of the critical challenges, research gaps and future directions. While reducing
toxicity on online platforms continues to be an active area of research, a
systematic study of various biases and their mitigation strategies will help
the research community produce robust and fair models."
1814,"We further study how the sentiment of fear is present among
the public.","In our
work, we aim to explore the percentage of fake news being spread on Twitter as well as measure the
sentiment of the public at the same time.","In addition to that we compare the rate of spread of the virus per day with the rate of
spread of fake news on Twitter.",2022-02-10 16:39:29+00:00,Understanding Twitters behavior during the pandemic: Fake News and Fear,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Author('Guillermo Romera Rodriguez'), arxiv.Result.Author('Sanjana Gautam'), arxiv.Result.Author('Andrea Tapia')]","The outbreak of the SARS-CoV-2 novel coronavirus (COVID-19) has been
accompanied by a large amount of misleading and false information about the
virus, especially on social media. During the pandemic social media gained
special interest as it went on to become an important medium of communication.
This made the information being relayed on these platforms especially critical.
In our work, we aim to explore the percentage of fake news being spread on
Twitter as well as measure the sentiment of the public at the same time. We
further study how the sentiment of fear is present among the public. In
addition to that we compare the rate of spread of the virus per day with the
rate of spread of fake news on Twitter. Our study is useful in establishing the
role of Twitter, and social media, during a crisis, and more specifically
during crisis management."
1974,"Nevertheless, further research
is required to understand better the role of regulatory regimes, consumer practices,
and economic development factors on these differences (Okazaki et al., 2020).","Thus, this additional analysis provides
additional evidence to support that information privacy concerns are more related
to the region of residence than the spoken language.","As the
Spanish-English balance in tweets in our dataset is such that it does not lend itself
to intra-region comparison for Asia and North and Latin America, future work could
seek to explore if this pattern repeats in those regions as well

   As with any study, our research has limitations.",2022-02-14 22:35:19+00:00,Regional Differences in Information Privacy Concerns After the Facebook-Cambridge Analytica Data Scandal,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY', 'K.4; I.2']","[arxiv.Result.Author('Felipe González-Pizarro'), arxiv.Result.Author('Andrea Figueroa'), arxiv.Result.Author('Claudia López'), arxiv.Result.Author('Cecilia Aragon')]","While there is increasing global attention to data privacy, most of their
current theoretical understanding is based on research conducted in a few
countries. Prior work argues that people's cultural backgrounds might shape
their privacy concerns; thus, we could expect people from different world
regions to conceptualize them in diverse ways. We collected and analyzed a
large-scale dataset of tweets about the #CambridgeAnalytica scandal in Spanish
and English to start exploring this hypothesis. We employed word embeddings and
qualitative analysis to identify which information privacy concerns are present
and characterize language and regional differences in emphasis on these
concerns. Our results suggest that related concepts, such as regulations, can
be added to current information privacy frameworks. We also observe a greater
emphasis on data collection in English than in Spanish. Additionally, data from
North America exhibits a narrower focus on awareness compared to other regions
under study. Our results call for more diverse sources of data and nuanced
analysis of data privacy concerns around the globe."
1975,"Nevertheless, further research
is required to understand better the role of regulatory regimes, consumer practices,
and economic development factors on these differences (Okazaki et al., 2020).","Thus, this additional analysis provides
additional evidence to support that information privacy concerns are more related
to the region of residence than the spoken language.","As the
Spanish-English balance in tweets in our dataset is such that it does not lend itself
to intra-region comparison for Asia and North and Latin America, future work could
seek to explore if this pattern repeats in those regions as well

   As with any study, our research has limitations.",2022-02-14 22:35:19+00:00,Regional Differences in Information Privacy Concerns After the Facebook-Cambridge Analytica Data Scandal,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY', 'K.4; I.2']","[arxiv.Result.Author('Felipe González-Pizarro'), arxiv.Result.Author('Andrea Figueroa'), arxiv.Result.Author('Claudia López'), arxiv.Result.Author('Cecilia Aragon')]","While there is increasing global attention to data privacy, most of their
current theoretical understanding is based on research conducted in a few
countries. Prior work argues that people's cultural backgrounds might shape
their privacy concerns; thus, we could expect people from different world
regions to conceptualize them in diverse ways. We collected and analyzed a
large-scale dataset of tweets about the #CambridgeAnalytica scandal in Spanish
and English to start exploring this hypothesis. We employed word embeddings and
qualitative analysis to identify which information privacy concerns are present
and characterize language and regional differences in emphasis on these
concerns. Our results suggest that related concepts, such as regulations, can
be added to current information privacy frameworks. We also observe a greater
emphasis on data collection in English than in Spanish. Additionally, data from
North America exhibits a narrower focus on awareness compared to other regions
under study. Our results call for more diverse sources of data and nuanced
analysis of data privacy concerns around the globe."
2221,"We acknowl-
edge that this may cause some limitations in our approach, which should be the
topic of further research.","Although modularity is a
widely used measure, it suﬀers from resolution limit problems [21].","For every generated graph, we calculate the top ARI score for every mea-
sure [31].",2022-02-20 14:52:52+00:00,Dissecting graph measure performance for node clustering in LFR parameter space,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Author('Vladimir Ivashkin'), arxiv.Result.Author('Pavel Chebotarev')]","Graph measures that express closeness or distance between nodes can be
employed for graph nodes clustering using metric clustering algorithms. There
are numerous measures applicable to this task, and which one performs better is
an open question. We study the performance of 25 graph measures on generated
graphs with different parameters. While usually measure comparisons are limited
to general measure ranking on a particular dataset, we aim to explore the
performance of various measures depending on graph features. Using an LFR graph
generator, we create a dataset of 11780 graphs covering the whole LFR parameter
space. For each graph, we assess the quality of clustering with k-means
algorithm for each considered measure. Based on this, we determine the best
measure for each area of the parameter space. We find that the parameter space
consists of distinct zones where one particular measure is the best. We analyze
the geometry of the resulting zones and describe it with simple criteria. Given
particular graph parameters, this allows us to recommend a particular measure
to use for clustering."
2302,"This may be an
avenue for further research in the specific context of Singapore’s online public sphere.","We acknowledge that signaling functions such as “most
popular first” or “newest first” may affect how commenters and readers coordinate the flow
of information and therefore impact the salience of the issue discussed.","Similarly, we did not consider the effect of gatekeepers and how the journalistic or news site
articles’ content influenced the nature of the counter-publics that emerged in the thread below
the articles.",2022-02-22 11:44:35+00:00,"Co-opted marginality, a new type of anti-immigrant discourse on social media? Classifying social media messages about immigrants with BERT",cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Author('Claire Stravato Emes'), arxiv.Result.Author('Anfan Chen')]","The article analyzes public discourse about immigrants in comments sections
of 11 social media community platforms over six months in Singapore."
2419,"Researchers studying undirected or directed graphs with positive
weights can readily adopt our framework to reveal subgraphs that merit further study.","Our Flow Laplacian framework offers a strategy for clustering edges for the ﬁrst time, thus
providing unique and diverse insights into directed inﬂuence and concentrated ﬂows in graphs
via three different methods.","With the
weighted adjacency matrix and the desired number of clusters being the only inputs, the frame-
work produces subgraph clusters through modest complexity, only requiring one to compute the
K eigenvectors associated with the minimum eigenvalues of a M × M symmetric psd matrix,
followed by row normalization and k-means++ clustering.",2022-02-23 16:24:55+00:00,Clustering Edges in Directed Graphs,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Author('Manohar Murthi'), arxiv.Result.Author('Kamal Premaratne')]","How do vertices exert influence in graph data? We develop a framework for
edge clustering, a new method for exploratory data analysis that reveals how
both vertices and edges collaboratively accomplish directed influence in
graphs, especially for directed graphs. In contrast to the ubiquitous vertex
clustering which groups vertices, edge clustering groups edges. Edges sharing a
functional affinity are assigned to the same group and form an influence
subgraph cluster. With a complexity comparable to that of vertex clustering,
this framework presents three different methods for edge spectral clustering
that reveal important influence subgraphs in graph data, with each method
providing different insight into directed influence processes. We present
several diverse examples demonstrating the potential for widespread application
of edge clustering in scientific research."
2763,"This counter-intuitive findings incites further research
into the effects of democracy on international research collaboration.","(2021) also
showed a negative interaction effect between democracy and international collaboration
intensity, where the effect of democracy on scientific performance diminished for higher levels

                                                                                                                              9
of international collaboration intensity.",Democracy and Academic Freedom.,2022-02-27 22:14:30+00:00,Democratic Governance and International Research Collaboration: A Longitudinal Analysis of the Global Science Network,cs.SI,"['cs.SI', 'cs.DL', 'physics.soc-ph']",[arxiv.Result.Author('Travis A. Whetsell')],"The democracy-science relationship has traditionally been examined through
philosophical conjecture and single country case studies. There remains limited
global scale empirical research on the topic. This study explores country level
factors that affect dynamics of the global scientific research collaboration
network, focusing on structural effects of democratic governance on the
formation, persistence, and strength of international research collaboration
ties. This study combines longitudinal data between 2008 and 2017 from the
Varieties of Democracy Institute, World Bank Indicators, Scopus, and Web of
Science bibliometric data. Methods of analysis include temporal and weighted
exponential random graph models. The results suggest positive significant
effects of both democratic governance on international research collaboration
and homophily between countries with similar levels of democratic governance.
Finally, the results show the effects of exogenous economic, population, and
geo-political factors, as well as endogenous network effects including
preferential attachment and transitivity."
2764,"This counter-intuitive findings incites further research
into the effects of democracy on international research collaboration.","(2021) also
showed a negative interaction effect between democracy and international collaboration
intensity, where the effect of democracy on scientific performance diminished for higher levels

                                                                                                                               9
of international collaboration intensity.",Democracy and Academic Freedom.,2022-02-27 22:14:30+00:00,Democratic Governance and International Research Collaboration: A Longitudinal Analysis of the Global Science Network,cs.SI,"['cs.SI', 'cs.DL', 'physics.soc-ph']",[arxiv.Result.Author('Travis A. Whetsell')],"The democracy-science relationship has traditionally been examined through
philosophical conjecture and single country case studies. There remains limited
global scale empirical research on the topic. This study explores country level
factors related to the dynamics of the global scientific research collaboration
network, focusing on structural associations between democratic governance and
the formation, persistence, and strength of international research
collaboration ties. This study combines longitudinal data between 2008 and 2017
from the Varieties of Democracy Institute, World Bank Indicators, Scopus, and
Web of Science bibliometric data. Methods of analysis include temporal and
weighted exponential random graph models (ERGM). The results suggest positive
significant effects of both democratic governance on international research
collaboration and homophily between countries with similar levels of democratic
governance. The results also show the importance of exogenous economic,
population, and geo-political factors, as well as endogenous network factors
including preferential attachment and transitivity."
2770,How bottoms interact with the network is also an area where further research is needed.,"Further research focused on how traﬃckers are connected, both socially
and professionally, will allow for more accurate traﬃcker social networks to be produced.","While
their function in the network is known, little is known on how they are connected to other traﬃckers
and victims outside of their operation.",2022-03-03 18:17:06+00:00,Generating Synthetic but Realistic Human Trafficking Networks for Modeling Disruptions through Transdisciplinary and Community-Based Action Research,cs.SI,"['cs.SI', 'math.OC']","[arxiv.Result.Author('Daniel Kosmas'), arxiv.Result.Author('Christina Melander'), arxiv.Result.Author('Emily Singerhouse'), arxiv.Result.Author('Thomas C. Sharkey'), arxiv.Result.Author('Kayse Lee Maass'), arxiv.Result.Author('Kelle Barrick'), arxiv.Result.Author('Lauren Martin')]","One of the major challenges associated with applying operations research (OR)
models to disrupting human trafficking networks is a limited amount of reliable
data sources readily available for public use, since operations are
intentionally hidden to prevent detection, and data from known operations are
often incomplete. To help address this data gap, we propose a network generator
for domestic sex trafficking networks by integrating OR concepts and
qualitative research. Multiple sources have been triangulated to ensure that
networks produced by the generator are realistic, including law enforcement
case file analysis, interviews with domain experts, and a survivor-centered
advisory group with first-hand knowledge of sex trafficking. The output models
the relationships between traffickers, so-called ""bottoms"", and victims. This
generator allows operations researchers to access realistic sex trafficking
network structures in a responsible manner that does not disclose identifiable
details of the people involved. We demonstrate the use of output networks in
exploring policy recommendations from max flow network interdiction with
restructuring. To do so, we propose a novel conceptualization of flow as the
ability of a trafficker to control their victims. Our results show the
importance of understanding how sex traffickers react to disruptions,
especially in terms of recruiting new victims."
2771,"35
    How bottoms interact with the network is also an area where further research is needed.","Further research focused on how traﬃckers are connected, both socially
and professionally, will allow for more accurate traﬃcker social networks to be produced.","While
the role of bottoms in their own traﬃcking operation has been previously studied, little is known
on how they are connected to other traﬃckers and victims outside of their operation.",2022-03-03 18:17:06+00:00,Generating Synthetic but Realistic Domestic Sex Trafficking Networks for Modeling Disruptions through Transdisciplinary Research,cs.SI,"['cs.SI', 'math.OC']","[arxiv.Result.Author('Daniel Kosmas'), arxiv.Result.Author('Christina Melander'), arxiv.Result.Author('Emily Singerhouse'), arxiv.Result.Author('Thomas C. Sharkey'), arxiv.Result.Author('Kayse Lee Maass'), arxiv.Result.Author('Kelle Barrick'), arxiv.Result.Author('Lauren Martin')]","One of the major challenges associated with applying operations research (OR)
models to disrupting human trafficking networks is the limited amount of
reliable data sources readily available for public use, since operations are
intentionally hidden to prevent detection, and data from known operations are
often incomplete. To help address this data gap, we propose a network generator
for domestic sex trafficking networks by integrating OR concepts and
qualitative research. Multiple sources regarding sex trafficking in the upper
Midwest of the United States have been triangulated to ensure that networks
produced by the generator are realistic, including law enforcement case file
analysis, interviews with domain experts, and a survivor-centered advisory
group with first-hand knowledge of sex trafficking. The output models the
relationships between traffickers, so-called ""bottoms"", and victims. This
generator allows operations researchers to access realistic sex trafficking
network structures in a responsible manner that does not disclose identifiable
details of the people involved. We demonstrate the use of output networks in
exploring policy recommendations from max flow network interdiction with
restructuring. To do so, we propose a novel conceptualization of flow as the
ability of a trafficker to control their victims. Our results show the
importance of understanding how sex traffickers react to disruptions,
especially in terms of recruiting new victims."
3028,"In developing a new approach and expanding methods already in place to
distil this data and find clusters of similar-minded people we hope to distribute important infor-
mation about the structure of the Twitter ecosystem and hope that further research can be con-
ducted on top of our work.","We showed that there are in fact clusters
of users retweeting only themselves and using the same language regarding the debate on the
Covid-19 pandemic.","Computer Science & Information Technology (CS & IT)

Finding clusters in the retweet network heavily depends on the number of influencers and the
threshold chosen.",2022-03-06 21:41:35+00:00,Finding Clusters of Similar-minded People on Twitter Regarding the Covid-19 Pandemic,cs.SI,['cs.SI'],"[arxiv.Result.Author('Philipp Kappus'), arxiv.Result.Author('Paul Groß')]","Two clustering methods to determine users with similar opinions on the
Covid-19 pandemic and the related public debate in Germany will be presented in
this paper. We believe, they can help gaining an overview over similar-minded
groups and could support the prevention of fake-news distribution. The first
method uses a new approach to create a network based on retweet relationships
between users and the most retweeted users, the so-called influencers. The
second method extracts hashtags from users posts to create a ""user feature
vector"" which is then clustered, using a consensus matrix based on previous
work, to identify groups using the same language. With both approaches it was
possible to identify clusters that seem to fit groups of different public
opinions in Germany. However, we also found that clusters from one approach can
not be associated with clusters from the other due to filtering steps in the
two methods."
3154,"Evidence of
maximum ranges above 20 hops were also seen in the Devices                                                                 In a dynamical system, we have to be clear about the dis-
channel, but the computational expense or going beyond this                                                             tinction between infrastucture carriers and the virtual processes
prohibited further study.","SUMMARY
is shorter on the scale of ASes than for Devices.","It’s at least suggestive that the ﬁnite                                                       that multiply on top of it, over different semantic channels.",2022-02-23 11:33:13+00:00,On The Scale Dependence and Spacetime Dimension of the Internet with Causal Sets,cs.SI,"['cs.SI', 'cs.DC', 'gr-qc', '05C, 11K55', 'C.2.1; C.2.m; H.m; K.6.m']",[arxiv.Result.Author('Mark Burgess')],"A statistical measure of dimension is used to compute the effective average
space dimension for the Internet and other graphs, based on typed edges (links)
from an ensemble of starting points. The method is applied to CAIDA's ITDK data
for the Internet. The effective dimension at different scales is calibrated to
the conventional Euclidean dimension using low dimensional hypercubes. Internet
spacetime has a 'foamy' multi-scale containment hierarchy, with interleaving
semantic types. There is an emergent scale for approximate long range order in
the device node spectrum, but this is not evident at the AS level, where there
is finite distance containment. Statistical dimension is thus a locally varying
measure, which is scale-dependent, giving an visual analogy for the hidden
scale-dependent dimensions of Kaluza-Klein theories. The characteristic
exterior dimensions of the Internet lie between 1.66 +- 0.00 and 6.12 +- 0.00,
and maximal interior dimensions rise to 7.7."
3479,"In the future, we will                             erence formation for pro-environmental technology: The case of a U.K.
conduct further research on an eﬀective reinforcement learning-                           workplace electric-vehicle study, Ecological Economics 95 (2013) 96–
based framework for the incentive allocation problem in large-                            107.
scale networks.","Thus, it is impossible for GAC                     [14] J. Axsen, C. Orlebar, S. Skippon, Social inﬂuence and consumer pref-
to handle large-scale social networks.","[15] B. Wilder, N. Immorlica, E. Rice, M. Tambe, Maximizing Inﬂuence in an
References                                                                                Unknown Social Network, in: Proceedings of the Thirty-Second AAAI
                                                                                          Conference on Artiﬁcial Intelligence, 2018, pp.",2022-03-17 19:41:49+00:00,GAC: A Deep Reinforcement Learning Model Toward User Incentivization in Unknown Social Networks,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shiqing Wu'), arxiv.Result.Author('Weihua Li'), arxiv.Result.Author('Quan Bai')]","In recent years, many applications have deployed incentive mechanisms to
promote users' attention and engagement. Most incentive mechanisms determine
specific incentive values based on users' attributes (e.g., preferences), while
such information is unavailable in many real-world applications. Meanwhile, due
to budget restrictions, realizing successful incentivization for all users can
be challenging to complete. In this light, we consider leveraging social
influence to maximize the incentivization result. We can directly incentivize
influential users to affect more users, so the cost of incentivizing these
users can be decreased. However, identifying influential users in a social
network requires complete information about influence strength among users,
which is impractical to acquire in real-world situations. In this research, we
propose an end-to-end reinforcement learning-based framework, called Geometric
Actor-Critic (GAC), to tackle the abovementioned problem. The proposed approach
can realize effective incentive allocation without having prior knowledge about
users' attributes. Three real-world social network datasets have been adopted
in the experiments to evaluate the performance of GAC. The experimental results
indicate that GAC can learn and apply effective incentive allocation policies
in unknown social networks and outperform existing incentive allocation
approaches."
3490,"Finally, we present some promising directions             made within the virtual domain and restricts fromrepudiating
to drive further research innovations and developments towards                any committed action.","We also present some major             same legal authority in the metaverse as one’s legal rights in the
projects to showcase the role of blockchain in metaverse applica-             real world; this makes the avatar warranted for any transactions
tions and services.","The access can be gainedby any person
the use of blockchain in the metaverse in the future.",2022-03-18 04:35:19+00:00,Blockchain for the Metaverse: A Review,cs.SI,['cs.SI'],"[arxiv.Result.Author('Thippa Reddy Gadekallu'), arxiv.Result.Author('Thien Huynh-The'), arxiv.Result.Author('Weizheng Wang'), arxiv.Result.Author('Gokul Yenduri'), arxiv.Result.Author('Pasika Ranaweera'), arxiv.Result.Author('Quoc-Viet Pham'), arxiv.Result.Author('Daniel Benevides da Costa'), arxiv.Result.Author('Madhusanka Liyanage')]","Since Facebook officially changed its name to Metaverse in Oct. 2021, the
metaverse has become a new norm of social networks and three-dimensional (3D)
virtual worlds. The metaverse aims to bring 3D immersive and personalized
experiences to users by leveraging many pertinent technologies. Despite great
attention and benefits, a natural question in the metaverse is how to secure
its users' digital content and data. In this regard, blockchain is a promising
solution owing to its distinct features of decentralization, immutability, and
transparency. To better understand the role of blockchain in the metaverse, we
aim to provide an extensive survey on the applications of blockchain for the
metaverse. We first present a preliminary to blockchain and the metaverse and
highlight the motivations behind the use of blockchain for the metaverse. Next,
we extensively discuss blockchain-based methods for the metaverse from
technical perspectives, such as data acquisition, data storage, data sharing,
data interoperability, and data privacy preservation. For each perspective, we
first discuss the technical challenges of the metaverse and then highlight how
blockchain can help. Moreover, we investigate the impact of blockchain on
key-enabling technologies in the metaverse, including Internet-of-Things,
digital twins, multi-sensory and immersive applications, artificial
intelligence, and big data. We also present some major projects to showcase the
role of blockchain in metaverse applications and services. Finally, we present
some promising directions to drive further research innovations and
developments towards the use of blockchain in the metaverse in the future."
3491,"4) Summary: Despite the potential of blockchain in in-
                                                                     creasing the interoperability between virtual worlds in several
   4) Summary: The use of blockchain technology will im-             metaverses, further research is required.","Hence, it will benefit applications like Nmusik,
Ascribe, Tracr, UBS, and Applicature [67].","The main challenge
prove the flexibility and adaptability of the metaverse data.",2022-03-18 04:35:19+00:00,Blockchain for the Metaverse: A Review,cs.SI,['cs.SI'],"[arxiv.Result.Author('Thippa Reddy Gadekallu'), arxiv.Result.Author('Thien Huynh-The'), arxiv.Result.Author('Weizheng Wang'), arxiv.Result.Author('Gokul Yenduri'), arxiv.Result.Author('Pasika Ranaweera'), arxiv.Result.Author('Quoc-Viet Pham'), arxiv.Result.Author('Daniel Benevides da Costa'), arxiv.Result.Author('Madhusanka Liyanage')]","Since Facebook officially changed its name to Metaverse in Oct. 2021, the
metaverse has become a new norm of social networks and three-dimensional (3D)
virtual worlds. The metaverse aims to bring 3D immersive and personalized
experiences to users by leveraging many pertinent technologies. Despite great
attention and benefits, a natural question in the metaverse is how to secure
its users' digital content and data. In this regard, blockchain is a promising
solution owing to its distinct features of decentralization, immutability, and
transparency. To better understand the role of blockchain in the metaverse, we
aim to provide an extensive survey on the applications of blockchain for the
metaverse. We first present a preliminary to blockchain and the metaverse and
highlight the motivations behind the use of blockchain for the metaverse. Next,
we extensively discuss blockchain-based methods for the metaverse from
technical perspectives, such as data acquisition, data storage, data sharing,
data interoperability, and data privacy preservation. For each perspective, we
first discuss the technical challenges of the metaverse and then highlight how
blockchain can help. Moreover, we investigate the impact of blockchain on
key-enabling technologies in the metaverse, including Internet-of-Things,
digital twins, multi-sensory and immersive applications, artificial
intelligence, and big data. We also present some major projects to showcase the
role of blockchain in metaverse applications and services. Finally, we present
some promising directions to drive further research innovations and
developments towards the use of blockchain in the metaverse in the future."
3492,"Finally, we present some promising directions             transactions made within the virtual domain and restricts from
                                        to drive further research innovations and developments towards                repudiating any committed action.","We also present some major              the same legal authority in the metaverse as one’s legal rights
                                        projects to showcase the role of blockchain in metaverse applica-             in the real world; this makes the avatar warranted for any
                                        tions and services.","The access can be gained
                                        the use of blockchain in the metaverse in the future.",2022-03-18 04:35:19+00:00,Blockchain for the Metaverse: A Review,cs.SI,['cs.SI'],"[arxiv.Result.Author('Thippa Reddy Gadekallu'), arxiv.Result.Author('Thien Huynh-The'), arxiv.Result.Author('Weizheng Wang'), arxiv.Result.Author('Gokul Yenduri'), arxiv.Result.Author('Pasika Ranaweera'), arxiv.Result.Author('Quoc-Viet Pham'), arxiv.Result.Author('Daniel Benevides da Costa'), arxiv.Result.Author('Madhusanka Liyanage')]","Since Facebook officially changed its name to Metaverse in Oct. 2021, the
metaverse has become a new norm of social networks and three-dimensional (3D)
virtual worlds. The metaverse aims to bring 3D immersive and personalized
experiences to users by leveraging many pertinent technologies. Despite great
attention and benefits, a natural question in the metaverse is how to secure
its users' digital content and data. In this regard, blockchain is a promising
solution owing to its distinct features of decentralization, immutability, and
transparency. To better understand the role of blockchain in the metaverse, we
aim to provide an extensive survey on the applications of blockchain for the
metaverse. We first present a preliminary to blockchain and the metaverse and
highlight the motivations behind the use of blockchain for the metaverse. Next,
we extensively discuss blockchain-based methods for the metaverse from
technical perspectives, such as data acquisition, data storage, data sharing,
data interoperability, and data privacy preservation. For each perspective, we
first discuss the technical challenges of the metaverse and then highlight how
blockchain can help. Moreover, we investigate the impact of blockchain on
key-enabling technologies in the metaverse, including Internet-of-Things,
digital twins, multi-sensory and immersive applications, artificial
intelligence, and big data. We also present some major projects to showcase the
role of blockchain in metaverse applications and services. Finally, we present
some promising directions to drive further research innovations and
developments towards the use of blockchain in the metaverse in the future."
3493,"4) Summary: Despite the potential of blockchain in in-
                                                                 creasing the interoperability between virtual worlds in several
   4) Summary: The use of blockchain technology will im-         metaverses, further research is required.","Hence, it will beneﬁt applications like Nmusik,
Ascribe, Tracr, UBS, and Applicature [67].","The main challenge
prove the ﬂexibility and adaptability of the metaverse data.",2022-03-18 04:35:19+00:00,Blockchain for the Metaverse: A Review,cs.SI,['cs.SI'],"[arxiv.Result.Author('Thippa Reddy Gadekallu'), arxiv.Result.Author('Thien Huynh-The'), arxiv.Result.Author('Weizheng Wang'), arxiv.Result.Author('Gokul Yenduri'), arxiv.Result.Author('Pasika Ranaweera'), arxiv.Result.Author('Quoc-Viet Pham'), arxiv.Result.Author('Daniel Benevides da Costa'), arxiv.Result.Author('Madhusanka Liyanage')]","Since Facebook officially changed its name to Metaverse in Oct. 2021, the
metaverse has become a new norm of social networks and three-dimensional (3D)
virtual worlds. The metaverse aims to bring 3D immersive and personalized
experiences to users by leveraging many pertinent technologies. Despite great
attention and benefits, a natural question in the metaverse is how to secure
its users' digital content and data. In this regard, blockchain is a promising
solution owing to its distinct features of decentralization, immutability, and
transparency. To better understand the role of blockchain in the metaverse, we
aim to provide an extensive survey on the applications of blockchain for the
metaverse. We first present a preliminary to blockchain and the metaverse and
highlight the motivations behind the use of blockchain for the metaverse. Next,
we extensively discuss blockchain-based methods for the metaverse from
technical perspectives, such as data acquisition, data storage, data sharing,
data interoperability, and data privacy preservation. For each perspective, we
first discuss the technical challenges of the metaverse and then highlight how
blockchain can help. Moreover, we investigate the impact of blockchain on
key-enabling technologies in the metaverse, including Internet-of-Things,
digital twins, multi-sensory and immersive applications, artificial
intelligence, and big data. We also present some major projects to showcase the
role of blockchain in metaverse applications and services. Finally, we present
some promising directions to drive further research innovations and
developments towards the use of blockchain in the metaverse in the future."
3687,"Our primary aim here is to prove the existence of a meaningful
signal in the proposed measure and stimulate further research that could better isolate, ﬁlter, and
amplify this signal.","Yet, neither can we rely on
another composite measure such as the SEI as a ground-truth benchmark to measure our success
against: as we mentioned in the introduction, the sociological community has not coalesced to a
universal understanding of SES.","4.1 Validation of brand SES

We begin by qualitatively sense-checking the SES estimates for brands.",2022-03-22 11:44:30+00:00,A Method for Estimating Individual Socioeconomic Status of Twitter Users,cs.SI,"['cs.SI', 'cs.CY', 'K.6; J.4']","[arxiv.Result.Author('Yuanmo He'), arxiv.Result.Author('Milena Tsvetkova')]","The rise of social media and computational social science (CSS) has opened
countless opportunities to explore social science questions with new forms of
data and methods. However, CSS research on socioeconomic inequality, a
fundamental problem in sociology, has been constrained due to the lack of
individual-level socioeconomic status (SES) measures in digital trace data. We
propose a new approach to address this problem. Following Bourdieu, we argue
that the commercial and entertainment accounts that Twitter users follow
reflect their economic and cultural capital and hence, we can use these
followings to infer the users' SES. Inspired by political science approaches to
inferring social media users' political ideology, we develop a method that uses
correspondence analysis to project official Twitter accounts and their
followers onto a linear SES scale. Using this method, we estimate the SES of
3,482,657 Twitter users who follow the Twitter accounts of 339 supermarkets and
department stores, clothing and speciality retailers, chain restaurants,
newspapers and news channels, sports, and TV shows in the United States. We
validate our estimates with data on audience composition from the Facebook
Marketing API, self-reported job titles on users' Twitter profiles, and a small
survey sample. The results show reasonable correlations between our SES
estimates and the standard proxies for SES: education, occupational class, and
income at the aggregate level and weaker but still significant correlations at
the individual level. The proposed method opens new opportunities for
innovative social research on inequality on Twitter and similar online
platforms."
3868,"We suspect that further study  The data analyzed here is provided by Twitter under a li-
of all unlikes (not just unlikes of deleted tweets) could lead  cense that prohibits redistribution.","Second, we uncovered inauthentic behaviors consisting of     Ethics statement
accounts that coordinate to repeatedly like and unlike a tweet
before it is eventually deleted.","For this reason, as well
to the identiﬁcation of a signiﬁcantly higher number of abu-    as to honor user intent, we are not allowed to make it pub-
sive accounts.",2022-03-25 20:07:08+00:00,Manipulating Twitter Through Deletions,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Author('Christopher Torres-Lugo'), arxiv.Result.Author('Manita Pote'), arxiv.Result.Author('Alexander Nwala'), arxiv.Result.Author('Filippo Menczer')]","Research into influence campaigns on Twitter has mostly relied on identifying
malicious activities from tweets obtained via public APIs. These APIs provide
access to public tweets that have not been deleted. However, bad actors can
delete content strategically to manipulate the system. Unfortunately, estimates
based on publicly available Twitter data underestimate the true deletion
volume. Here, we provide the first exhaustive, large-scale analysis of
anomalous deletion patterns involving more than a billion deletions by over 11
million accounts. We find that a small fraction of accounts delete a large
number of tweets daily. We also uncover two abusive behaviors that exploit
deletions. First, limits on tweet volume are circumvented, allowing certain
accounts to flood the network with over 26 thousand daily tweets. Second,
coordinated networks of accounts engage in repetitive likes and unlikes of
content that is eventually deleted, which can manipulate ranking algorithms.
These kinds of abuse can be exploited to amplify content and inflate
popularity, while evading detection. Our study provides platforms and
researchers with new methods for identifying social media abuse."
3913,"patterns in missed tweets, so further research may be needed.","However, there are various       information, according to Twitter’s guidelines.","Acknowledgement                                Cheng, M.; Wang, S.; Yan, X.; Yang, T.; Wang, W.; Huang,
                                                                 Z.; Xiao, X.; Nazarian, S.; and Bogdan, P. 2021.",2022-03-27 08:25:57+00:00,"""This is Fake News"": Characterizing the Spontaneous Debunking from Twitter Users to COVID-19 False Information",cs.SI,['cs.SI'],"[arxiv.Result.Author('Kunihiro Miyazaki'), arxiv.Result.Author('Takayuki Uchiba'), arxiv.Result.Author('Kenji Tanaka'), arxiv.Result.Author('Jisun An'), arxiv.Result.Author('Haewoon Kwak'), arxiv.Result.Author('Kazutoshi Sasahara')]","False information spreads on social media, and fact-checking is a potential
countermeasure. However, there is a severe shortage of fact-checkers; an
efficient way to scale fact-checking is desperately needed, especially in
pandemics like COVID-19. In this study, we focus on spontaneous debunking by
social media users, which has been missed in existing research despite its
indicated usefulness for fact-checking and countering false information.
Specifically, we characterize the tweets with false information, or fake
tweets, that tend to be debunked and Twitter users who often debunk fake
tweets. For this analysis, we create a comprehensive dataset of responses to
fake tweets, annotate a subset of them, and build a classification model for
detecting debunking behaviors. We find that most fake tweets are left
undebunked, spontaneous debunking is slower than other forms of responses, and
spontaneous debunking exhibits partisanship in political topics. These results
provide actionable insights into utilizing spontaneous debunking to scale
conventional fact-checking, thereby supplementing existing research from a new
perspective."
3914,"However, there are various patterns in missed tweets,
accurate in debunking; thus, the debunking of partisan users      so further research may be needed.","(2021), politically balanced people are more      siﬁer.",has to be used with caution.,2022-03-27 08:25:57+00:00,"""This is Fake News"": Characterizing the Spontaneous Debunking from Twitter Users to COVID-19 False Information",cs.SI,['cs.SI'],"[arxiv.Result.Author('Kunihiro Miyazaki'), arxiv.Result.Author('Takayuki Uchiba'), arxiv.Result.Author('Kenji Tanaka'), arxiv.Result.Author('Jisun An'), arxiv.Result.Author('Haewoon Kwak'), arxiv.Result.Author('Kazutoshi Sasahara')]","False information spreads on social media, and fact-checking is a potential
countermeasure. However, there is a severe shortage of fact-checkers; an
efficient way to scale fact-checking is desperately needed, especially in
pandemics like COVID-19. In this study, we focus on spontaneous debunking by
social media users, which has been missed in existing research despite its
indicated usefulness for fact-checking and countering false information.
Specifically, we characterize the tweets with false information, or fake
tweets, that tend to be debunked and Twitter users who often debunk fake
tweets. For this analysis, we create a comprehensive dataset of responses to
fake tweets, annotate a subset of them, and build a classification model for
detecting debunking behaviors. We find that most fake tweets are left
undebunked, spontaneous debunking is slower than other forms of responses, and
spontaneous debunking exhibits partisanship in political topics. These results
provide actionable insights into utilizing spontaneous debunking to scale
conventional fact-checking, thereby supplementing existing research from a new
perspective."
3972,"To further study this relationship,  3.3 Importance of Dynamic Information
we also conduct observations on Taocode diffusion data
from graph level and node level respectively.","As stated in Section 1, user interest diffusion is naturally
related with item features."," 
                                                                        
    First, from the graph level, we observe whether diffusion    &RXQWV
graph statistics (such as diffusion scale) correlate with item                                                                                                                                                                                               
features (such as sales).",2022-03-28 14:45:24+00:00,Who is next: rising star prediction via diffusion of user interest in social networks,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Author('Xuan Yang'), arxiv.Result.Author('Yang Yang'), arxiv.Result.Author('Jintao Su'), arxiv.Result.Author('Yifei Sun'), arxiv.Result.Author('Shen Fan'), arxiv.Result.Author('Zhongyao Wang'), arxiv.Result.Author('Jun Zhang'), arxiv.Result.Author('Jingmin Chen')]","Finding items with potential to increase sales is of great importance in
online market. In this paper, we propose to study this novel and practical
problem: rising star prediction. We call these potential items Rising Star,
which implies their ability to rise from low-turnover items to best-sellers in
the future. Rising stars can be used to help with unfair recommendation in
e-commerce platform, balance supply and demand to benefit the retailers and
allocate marketing resources rationally. Although the study of rising star can
bring great benefits, it also poses challenges to us. The sales trend of rising
star fluctuates sharply in the short-term and exhibits more contingency caused
by some external events (e.g., COVID-19 caused increasing purchase of the face
mask) than other items, which cannot be solved by existing sales prediction
methods. To address above challenges, in this paper, we observe that the
presence of rising stars is closely correlated with the early diffusion of user
interest in social networks, which is validated in the case of Taocode (an
intermediary that diffuses user interest in Taobao). Thus, we propose a novel
framework, RiseNet, to incorporate the user interest diffusion process with the
item dynamic features to effectively predict rising stars. Specifically, we
adopt a coupled mechanism to capture the dynamic interplay between items and
user interest, and a special designed GNN based framework to quantify user
interest. Our experimental results on large-scale real-world datasets provided
by Taobao demonstrate the effectiveness of our proposed framework."
3973,"To further study this relationship,  3.3 Importance of Dynamic Information
we also conduct observations on Taocode diffusion data
from graph level and node level respectively.","As stated in Section 1, user interest diffusion is naturally
related with item features."," 
                                                                        
    First, from the graph level, we observe whether diffusion    &RXQWV
graph statistics (such as diffusion scale) correlate with item                                                                                                                                                                                               
features (such as sales).",2022-03-28 14:45:24+00:00,Who is next: rising star prediction via diffusion of user interest in social networks,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Author('Xuan Yang'), arxiv.Result.Author('Yang Yang'), arxiv.Result.Author('Jintao Su'), arxiv.Result.Author('Yifei Sun'), arxiv.Result.Author('Shen Fan'), arxiv.Result.Author('Zhongyao Wang'), arxiv.Result.Author('Jun Zhang'), arxiv.Result.Author('Jingmin Chen')]","Finding items with potential to increase sales is of great importance in
online market. In this paper, we propose to study this novel and practical
problem: rising star prediction. We call these potential items Rising Star,
which implies their ability to rise from low-turnover items to best-sellers in
the future. Rising stars can be used to help with unfair recommendation in
e-commerce platform, balance supply and demand to benefit the retailers and
allocate marketing resources rationally. Although the study of rising star can
bring great benefits, it also poses challenges to us. The sales trend of rising
star fluctuates sharply in the short-term and exhibits more contingency caused
by some external events (e.g., COVID-19 caused increasing purchase of the face
mask) than other items, which cannot be solved by existing sales prediction
methods. To address above challenges, in this paper, we observe that the
presence of rising stars is closely correlated with the early diffusion of user
interest in social networks, which is validated in the case of Taocode (an
intermediary that diffuses user interest in Taobao). Thus, we propose a novel
framework, RiseNet, to incorporate the user interest diffusion process with the
item dynamic features to effectively predict rising stars. Specifically, we
adopt a coupled mechanism to capture the dynamic interplay between items and
user interest, and a special designed GNN based framework to quantify user
interest. Our experimental results on large-scale real-world datasets provided
by Taobao demonstrate the effectiveness of our proposed framework."
3974,"In
particular, the current “bottleneck” and an area for further research is to design a faster, parallelized implementation
of the background graph.","Despite the fact that ABCDe is already very fast, there are some ways the generation process can be improved.","This would allow to make a better use of multiple threads in scenarios when the parameter
ξ is large and so most of the edges are present in the background graph.",2022-03-28 17:03:24+00:00,Properties and Performance of the ABCDe Random Graph Model with Community Structure,cs.SI,"['cs.SI', 'cs.LG', 'math.CO', 'I.6.5; G.4']","[arxiv.Result.Author('Bogumił Kamiński'), arxiv.Result.Author('Tomasz Olczak'), arxiv.Result.Author('Bartosz Pankratz'), arxiv.Result.Author('Paweł Prałat'), arxiv.Result.Author('François Théberge')]","In this paper, we investigate properties and performance of synthetic random
graph models with a built-in community structure. Such models are important for
evaluating and tuning community detection algorithms that are unsupervised by
nature. We propose a new implementation of the ABCD graph generator, ABCDe,
that uses multiple-threading. We discuss the implementation details of the
algorithm as well as compare it with both the previously available sequential
version of the ABCD model and with the parallel implementation of the standard
and extensively used LFR generator. We show that ABCDe is more than ten times
faster and scales better than the parallel implementation of LFR provided in
NetworKit. Moreover, the algorithm is not only faster but random graphs
generated by ABCD have similar properties to the ones generated by the original
LFR algorithm, while the parallelized NetworKit implementation of LFR produces
graphs that have noticeably different characteristics."
3975,"In
particular, the current “bottleneck” and an area for further research is to design a faster, parallelized implementation
of the background graph.","Despite the fact that ABCDe is already very fast, there are some ways the generation process can be improved.","This would allow to make a better use of multiple threads in scenarios when the parameter
ξ is large and so most of the edges are present in the background graph.",2022-03-28 17:03:24+00:00,Properties and Performance of the ABCDe Random Graph Model with Community Structure,cs.SI,"['cs.SI', 'cs.LG', 'math.CO', 'I.6.5; G.4']","[arxiv.Result.Author('Bogumił Kamiński'), arxiv.Result.Author('Tomasz Olczak'), arxiv.Result.Author('Bartosz Pankratz'), arxiv.Result.Author('Paweł Prałat'), arxiv.Result.Author('François Théberge')]","In this paper, we investigate properties and performance of synthetic random
graph models with a built-in community structure. Such models are important for
evaluating and tuning community detection algorithms that are unsupervised by
nature. We propose ABCDe, a multi-threaded implementation of the ABCD
(Artificial Benchmark for Community Detection) graph generator. We discuss the
implementation details of the algorithm and compare it with both the previously
available sequential version of the ABCD model and with the parallel
implementation of the standard and extensively used LFR
(Lancichinetti--Fortunato--Radicchi) generator. We show that ABCDe is more than
ten times faster and scales better than the parallel implementation of LFR
provided in NetworKit. Moreover, the algorithm is not only faster but random
graphs generated by ABCD have similar properties to the ones generated by the
original LFR algorithm, while the parallelized NetworKit implementation of LFR
produces graphs that have noticeably different characteristics."
4090,"In addition, we developed an algorithm that generates an overlapping
community-structured random network to empower further research in the ﬁeld.","Our approach is composed of graph theory notions and straightforward yet accurate machine-
learning-based link-prediction techniques.","We evaluated our method on 1,000 networks generated by us and on 1,000 networks sampled from Reddit’s comments
dataset, where each contained tens of thousands of vertices and edges.",2022-03-30 12:23:55+00:00,Co-Membership-based Generic Anomalous Communities Detection,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Author('Shay Lapid'), arxiv.Result.Author('Dima Kagan'), arxiv.Result.Author('Michael Fire')]","Nowadays, detecting anomalous communities in networks is an essential task in
research, as it helps discover insights into community-structured networks.
Most of the existing methods leverage either information regarding attributes
of vertices or the topological structure of communities. In this study, we
introduce the Co-Membership-based Generic Anomalous Communities Detection
Algorithm (referred as to CMMAC), a novel and generic method that utilizes the
information of vertices co-membership in multiple communities. CMMAC is
domain-free and almost unaffected by communities' sizes and densities.
Specifically, we train a classifier to predict the probability of each vertex
in a community being a member of the community. We then rank the communities by
the aggregated membership probabilities of each community's vertices. The
lowest-ranked communities are considered to be anomalous. Furthermore, we
present an algorithm for generating a community-structured random network
enabling the infusion of anomalous communities to facilitate research in the
field. We utilized it to generate two datasets, composed of thousands of
labeled anomaly-infused networks, and published them. We experimented
extensively on thousands of simulated, and real-world networks, infused with
artificial anomalies. CMMAC outperformed other existing methods in a range of
settings. Additionally, we demonstrated that CMMAC can identify abnormal
communities in real-world unlabeled networks in different domains, such as
Reddit and Wikipedia."
4092,"Tweets linking to YouTube videos            both mainstream platforms and alt-tech platforms, and we argue
promoting fraud claims also received more engagement than tweets          that the dynamics between these platforms warrants further study.","Hence, these
linked to approximately 28 times more than BitChute videos pro-           complications allowed for harmful content to live and spread on
moting election fraud claims.",linking to BitChute videos promoting fraud claims.,2022-03-30 13:10:40+00:00,Characterizing YouTube and BitChute Content and Mobilizers During U.S. Election Fraud Discussions on Twitter,cs.SI,['cs.SI'],"[arxiv.Result.Author('Matthew C. Childs'), arxiv.Result.Author('Cody Buntain'), arxiv.Result.Author('Milo Z. Trujillo'), arxiv.Result.Author('Benjamin D. Horne')]","In this study, we characterize the cross-platform mobilization of YouTube and
BitChute videos on Twitter during the 2020 U.S. Election fraud discussions.
Specifically, we extend the VoterFraud2020 dataset to describe the prevalence
of content supplied by both platforms, the mobilizers of that content, the
suppliers of that content, and the content itself. We find that while BitChute
videos promoting election fraud claims were linked to and engaged with in the
Twitter discussion, they played a relatively small role compared to YouTube
videos promoting fraud claims. This core finding points to the continued need
for proactive, consistent, and collaborative content moderation solutions
rather than the reactive and inconsistent solutions currently being used.
Additionally, we find that cross-platform disinformation spread from video
platforms was not prominently from bot accounts or political elites, but rather
average Twitter users. This finding supports past work arguing that research on
disinformation should move beyond a focus on bots and trolls to a focus on
participatory disinformation spread."
4267,"In sum, our observations paint a richer picture of at-        online behavioral signals, such as linguistic and narrative
tention patterns across the political spectrum, provide a ba-         characteristics, of two ideology groups in response to mass
sis for further studying political framing and group behav-           shooting events.","Lin and Chung (2020) distinguished
longer.",Garimella et al.,2022-04-03 04:49:28+00:00,Whose Advantage? Measuring Attention Dynamics across YouTube and Twitter on Controversial Topics,cs.SI,['cs.SI'],"[arxiv.Result.Author('JooYoung Lee'), arxiv.Result.Author('Siqi Wu'), arxiv.Result.Author('Ali Mert Ertugrul'), arxiv.Result.Author('Yu-Ru Lin'), arxiv.Result.Author('Lexing Xie')]","The ideological asymmetries have been recently observed in contested online
spaces, where conservative voices seem to be relatively more pronounced even
though liberals are known to have the population advantage on digital
platforms. Most prior research, however, focused on either one single platform
or one single political topic. Whether an ideological group garners more
attention across platforms and topics, and how the attention dynamics evolve
over time, have not been explored. In this work, we present a quantitative
study that links collective attention across two social media platforms --
YouTube and Twitter, centered on online activities surrounding videos of three
controversial political topics including Abortion, Gun control, and Black Lives
Matter over 16 months. We propose several video-centric metrics to characterize
how online attention is accumulated for different ideological groups. We find
that neither side is on a winning streak: left-leaning videos are overall more
viewed, more engaging, but less tweeted than right-leaning videos. The
attention time series unfold quicker for left-leaning videos, but span a longer
time for right-leaning videos. Network analysis on the early adopters and tweet
cascades show that the information diffusion for left-leaning videos tends to
involve centralized actors; while that for right-leaning videos starts earlier
in the attention lifecycle. In sum, our findings go beyond the static picture
of ideological asymmetries in digital spaces and provide a set of methods to
quantify attention dynamics across different social platforms."
4268,"In sum, our observations paint a richer picture of at-        online behavioral signals, such as linguistic and narrative
tention patterns across the political spectrum, provide a ba-         characteristics, of two ideology groups in response to mass
sis for further studying political framing and group behav-           shooting events.","Lin and Chung (2020) distinguished
longer.",Garimella et al.,2022-04-03 04:49:28+00:00,Whose Advantage? Measuring Attention Dynamics across YouTube and Twitter on Controversial Topics,cs.SI,['cs.SI'],"[arxiv.Result.Author('JooYoung Lee'), arxiv.Result.Author('Siqi Wu'), arxiv.Result.Author('Ali Mert Ertugrul'), arxiv.Result.Author('Yu-Ru Lin'), arxiv.Result.Author('Lexing Xie')]","The ideological asymmetries have been recently observed in contested online
spaces, where conservative voices seem to be relatively more pronounced even
though liberals are known to have the population advantage on digital
platforms. Most prior research, however, focused on either one single platform
or one single political topic. Whether an ideological group garners more
attention across platforms and topics, and how the attention dynamics evolve
over time, have not been explored. In this work, we present a quantitative
study that links collective attention across two social media platforms --
YouTube and Twitter, centered on online activities surrounding videos of three
controversial political topics including Abortion, Gun control, and Black Lives
Matter over 16 months. We propose several video-centric metrics to characterize
how online attention is accumulated for different ideological groups. We find
that neither side is on a winning streak: left-leaning videos are overall more
viewed, more engaging, but less tweeted than right-leaning videos. The
attention time series unfold quicker for left-leaning videos, but span a longer
time for right-leaning videos. Network analysis on the early adopters and tweet
cascades show that the information diffusion for left-leaning videos tends to
involve centralized actors; while that for right-leaning videos starts earlier
in the attention lifecycle. In sum, our findings go beyond the static picture
of ideological asymmetries in digital spaces and provide a set of methods to
quantify attention dynamics across different social platforms."
4269,"In sum, our observations paint a richer picture of at-        online behavioral signals, such as linguistic and narrative
tention patterns across the political spectrum, provide a ba-         characteristics, of two ideology groups in response to mass
sis for further studying political framing and group behav-           shooting events.","Lin and Chung (2020) distinguished
longer.",Garimella et al.,2022-04-03 04:49:28+00:00,Whose Advantage? Measuring Attention Dynamics across YouTube and Twitter on Controversial Topics,cs.SI,['cs.SI'],"[arxiv.Result.Author('JooYoung Lee'), arxiv.Result.Author('Siqi Wu'), arxiv.Result.Author('Ali Mert Ertugrul'), arxiv.Result.Author('Yu-Ru Lin'), arxiv.Result.Author('Lexing Xie')]","The ideological asymmetries have been recently observed in contested online
spaces, where conservative voices seem to be relatively more pronounced even
though liberals are known to have the population advantage on digital
platforms. Most prior research, however, focused on either one single platform
or one single political topic. Whether an ideological group garners more
attention across platforms and/or topics, and how the attention dynamics evolve
over time, have not been explored. In this work, we present a quantitative
study that links collective attention across two social platforms -- YouTube
and Twitter, centered on online activities surrounding popular videos of three
controversial political topics including Abortion, Gun control, and Black Lives
Matter over 16 months. We propose several sets of video-centric metrics to
characterize how online attention is accumulated for different ideological
groups. We find that neither side is on a winning streak: left-leaning videos
are overall more viewed, more engaging, but less tweeted than right-leaning
videos. The attention time series unfold quicker for left-leaning videos, but
span a longer time for right-leaning videos. Network analysis on the early
adopters and tweet cascades show that the information diffusion for
left-leaning videos tends to involve centralized actors; while that for
right-leaning videos starts earlier in the attention lifecycle. In sum, our
findings go beyond the static picture of ideological asymmetries in digital
spaces and provide a set of methods to quantify attention dynamics across
different social platforms."
4408,"Of course, there is a possibility that the endpoint v2 also delivers Tweets that should not be part
of the queried result, but most likely the endpoint v1.1 misses Tweets with certain properties due storage or search
characteristics—further research can look more closely into these differences.","At this point, we can only
hypothesize that the API endpoint V1.1 has a different approach for searching in Twitter’s archival data that leads
to different results.","At this point, we can report that the
Academic API delivers more Tweets in response to a historic search than the costly Premium API utilizing endpoint
v1.1.",2022-04-04 13:02:15+00:00,This Sample seems to be good enough! Assessing Coverage and Temporal Reliability of Twitter's Academic API,cs.SI,"['cs.SI', 'E.0; J.4; H.3.0']","[arxiv.Result.Author('Juergen Pfeffer'), arxiv.Result.Author('Angelina Mooseder'), arxiv.Result.Author('Luca Hammer'), arxiv.Result.Author('Oliver Stritzel'), arxiv.Result.Author('David Garcia')]","Because of its willingness to share data with academia and industry, Twitter
has been the primary social media platform for scientific research as well as
for the consulting of businesses and governments in the last decade. In recent
years, a series of publications have studied and criticized Twitter's APIs and
Twitter has partially adapted its existing data streams. The newest Twitter API
for Academic Research allows to ""access Twitter's real-time and historical
public data with additional features and functionality that support collecting
more precise, complete, and unbiased datasets."" The main new feature of this
API is the possibility of accessing the full archive of all historic Tweets. In
this article, we will take a closer look at the Academic API and will try to
answer two questions. First, are the datasets collected with the Academic API
complete? Secondly, since Twitter's Academic API delivers historic Tweets as
represented on Twitter at the time of data collection, we need to understand
how much data is lost over time due to Tweet and account removal from the
platform. Our work shows evidence that Twitter's Academic API can indeed create
(almost) complete samples of Twitter data based on a wide variety of search
terms. We also provide evidence that Twitter's data endpoint v2 delivers better
samples than the previously used endpoint v1.1. Furthermore, collecting Tweets
with the Academic API at the time of studying a phenomenon rather than creating
local archives of stored Tweets, allows for a straightforward way of following
Twitter's developer agreement. Finally, we will also discuss technical
artifacts and implications of the Academic API. We hope that our work can add
another layer of understanding of Twitter data collections leading to more
reliable studies of human behavior via social media data."
4587,"For example, outrage is regarded as especially important
   We further study four speciﬁc derived emotions:               emotion for online behavior but with severe negative risks
DISAPPROVAL, UNBELIEF, OUTRAGE, and GUILT.","and Pro¨llochs 2022; Pro¨llochs, Ba¨r, and Feuerriegel 2021b).",This                  (Crockett 2017).,2022-04-08 18:37:05+00:00,Online Emotions During the Storming of the U.S. Capitol: Evidence from the Social Media Network Parler,cs.SI,['cs.SI'],"[arxiv.Result.Author('Johannes Jakubik'), arxiv.Result.Author('Michael Vössing'), arxiv.Result.Author('Dominik Bär'), arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","The storming of the U.S. Capitol on January 6, 2021 has led to the killing of
5 people and is widely regarded as an attack on democracy. The storming was
largely coordinated through social media networks such as Twitter and ""Parler"".
Yet little is known regarding how users interacted on Parler during the
storming of the Capitol. In this work, we examine the emotion dynamics on
Parler during the storming with regard to heterogeneity across time and users.
For this, we segment the user base into different groups (e.g., Trump
supporters and QAnon supporters). We use affective computing to infer the
emotions in content, thereby allowing us to provide a comprehensive assessment
of online emotions. Our evaluation is based on a large-scale dataset from
Parler, comprising of 717,300 posts from 144,003 users. We find that the user
base responded to the storming of the Capitol with an overall negative
sentiment. Akin to this, Trump supporters also expressed a negative sentiment
and high levels of unbelief. In contrast to that, QAnon supporters did not
express a more negative sentiment during the storming. We further provide a
cross-platform analysis and compare the emotion dynamics on Parler and Twitter.
Our findings point at a comparatively less negative response to the incidents
on Parler compared to Twitter accompanied by higher levels of disapproval and
outrage. Our contribution to research is three-fold: (1) We identify online
emotions that were characteristic of the storming; (2) we assess emotion
dynamics across different user groups on Parler; (3) we compare the emotion
dynamics on Parler and Twitter. Thereby, our work offers important implications
for actively managing online emotions to prevent similar incidents in the
future."
4588,We further study                       2022).,"TRUST, DISGUST, JOY, SADNESS).",Psychological research (Lutz et al.,2022-04-08 18:37:05+00:00,Online Emotions During the Storming of the U.S. Capitol: Evidence from the Social Media Network Parler,cs.SI,['cs.SI'],"[arxiv.Result.Author('Johannes Jakubik'), arxiv.Result.Author('Michael Vössing'), arxiv.Result.Author('Dominik Bär'), arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","The storming of the U.S. Capitol on January 6, 2021 has led to the killing of
5 people and is widely regarded as an attack on democracy. The storming was
largely coordinated through social media networks such as Parler. Yet little is
known regarding how users interacted on Parler during the storming of the
Capitol. In this work, we examine the emotion dynamics on Parler during the
storming with regard to heterogeneity across time and users. For this, we
segment the user base into different groups (e.g., Trump supporters and QAnon
supporters). We use affective computing (Kratzwald et al. 2018) to infer the
emotions in the contents, thereby allowing us to provide a comprehensive
assessment of online emotions. Our evaluation is based on a large-scale dataset
from Parler, comprising of 717,300 posts from 144,003 users. We find that the
user base responded to the storming of the Capitol with an overall negative
sentiment. Akin to this, Trump supporters also expressed a negative sentiment
and high levels of unbelief. In contrast to that, QAnon supporters did not
express a more negative sentiment during the storming. We further provide a
cross-platform analysis and compare the emotion dynamics on Parler and Twitter.
Our findings point at a comparatively less negative response to the incidents
on Parler compared to Twitter accompanied by higher levels of disapproval and
outrage. Our contribution to research is three-fold: (1) We identify online
emotions that were characteristic of the storming; (2) we assess emotion
dynamics across different user groups on Parler; (3) we compare the emotion
dynamics on Parler and Twitter. Thereby, our work offers important implications
for actively managing online emotions to prevent similar incidents in the
future."
4589,We further study                       2022).,"TRUST, DISGUST, JOY, SADNESS).",Psychological research (Lutz et al.,2022-04-08 18:37:05+00:00,Online Emotions During the Storming of the U.S. Capitol: Evidence from the Social Media Network Parler,cs.SI,['cs.SI'],"[arxiv.Result.Author('Johannes Jakubik'), arxiv.Result.Author('Michael Vössing'), arxiv.Result.Author('Dominik Bär'), arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","The storming of the U.S. Capitol on January 6, 2021 has led to the killing of
5 people and is widely regarded as an attack on democracy. The storming was
largely coordinated through social media networks such as Parler. Yet little is
known regarding how users interacted on Parler during the storming of the
Capitol. In this work, we examine the emotion dynamics on Parler during the
storming with regard to heterogeneity across time and users. For this, we
segment the user base into different groups (e.g., Trump supporters and QAnon
supporters). We use affective computing (Kratzwald et al. 2018) to infer the
emotions in the contents, thereby allowing us to provide a comprehensive
assessment of online emotions. Our evaluation is based on a large-scale dataset
from Parler, comprising of 717,300 posts from 144,003 users. We find that the
user base responded to the storming of the Capitol with an overall negative
sentiment. Akin to this, Trump supporters also expressed a negative sentiment
and high levels of unbelief. In contrast to that, QAnon supporters did not
express a more negative sentiment during the storming. We further provide a
cross-platform analysis and compare the emotion dynamics on Parler and Twitter.
Our findings point at a comparatively less negative response to the incidents
on Parler compared to Twitter accompanied by higher levels of disapproval and
outrage. Our contribution to research is three-fold: (1) We identify online
emotions that were characteristic of the storming; (2) we assess emotion
dynamics across different user groups on Parler; (3) we compare the emotion
dynamics on Parler and Twitter. Thereby, our work offers important implications
for actively managing online emotions to prevent similar incidents in the
future."
4865,"From these engagements, we learned that there is interest by academic institutions to expand
their cyberinfrastructure deployments and further research initiatives on campuses.","BRICCs also engaged
with the Texas Association of Community College CIOs (TACC-CIO) to further community engagement and advertise
the BRICCs activities.","BRICCs discovered that there
are several groups working in this space and that connections need to be made.",2022-04-14 19:53:28+00:00,Expanding the Reach of Research Computing: A Landscape Study,cs.SI,['cs.SI'],"[arxiv.Result.Author('Dhruva K. Chakravorty'), arxiv.Result.Author('Sarah K. Janes'), arxiv.Result.Author('James V. Howell'), arxiv.Result.Author('Lisa M. Perez'), arxiv.Result.Author('Amy Schultz'), arxiv.Result.Author('Marie Goldie'), arxiv.Result.Author('Austin L. Gamble'), arxiv.Result.Author('Rajiv Malkan'), arxiv.Result.Author('Honggao Liu'), arxiv.Result.Author('Daniel Mireles'), arxiv.Result.Author('Yuanqi Jing'), arxiv.Result.Author('Zhenhua He'), arxiv.Result.Author('Tim Cockrill')]","Research-computing continues to play an ever increasing role in academia.
Access to computing resources, however, varies greatly between institutions.
Sustaining the growing need for computing skills and access to advanced
cyberinfrastructure requires that computing resources be available to students
at all levels of scholarship, including community colleges. The National
Science Foundation-funded Building Research Innovation in Community Colleges
(BRICCs) community set out to understand the challenges faced by
administrators, researchers and faculty in building a sustainable research
computing continuum that extends to smaller and two-year terminal degree
granting institutions. BRICCs purpose is to address the technology gaps, and
encourage the development of curriculum needed to grow a computationally
proficient research workforce. Toward addressing these goals, we performed a
landscape study that culminated with a community workshop. Here, we present our
key findings from workshop discussions and identify next steps to be taken by
BRICCs, funding agencies, and the broader cyberinfrastructure community."
4866,"From these engagements, we learned that there is interest by academic institutions to expand
their cyberinfrastructure deployments and further research initiatives on campuses.","BRICCs also engaged
with the Texas Association of Community College CIOs (TACC-CIO) to further community engagement and advertise
the BRICCs activities.","BRICCs discovered that there
are several groups working in this space and that connections need to be made.",2022-04-14 19:53:28+00:00,Expanding the Reach of Research Computing: A Landscape Study,cs.SI,['cs.SI'],"[arxiv.Result.Author('Dhruva K. Chakravorty'), arxiv.Result.Author('Sarah K. Janes'), arxiv.Result.Author('James V. Howell'), arxiv.Result.Author('Lisa M. Perez'), arxiv.Result.Author('Amy Schultz'), arxiv.Result.Author('Marie Goldie'), arxiv.Result.Author('Austin L. Gamble'), arxiv.Result.Author('Rajiv Malkan'), arxiv.Result.Author('Honggao Liu'), arxiv.Result.Author('Daniel Mireles'), arxiv.Result.Author('Yuanqi Jing'), arxiv.Result.Author('Zhenhua He'), arxiv.Result.Author('Tim Cockerill')]","Research-computing continues to play an ever increasing role in academia.
Access to computing resources, however, varies greatly between institutions.
Sustaining the growing need for computing skills and access to advanced
cyberinfrastructure requires that computing resources be available to students
at all levels of scholarship, including community colleges. The National
Science Foundation-funded Building Research Innovation in Community Colleges
(BRICCs) community set out to understand the challenges faced by
administrators, researchers and faculty in building a sustainable research
computing continuum that extends to smaller and two-year terminal degree
granting institutions. BRICCs purpose is to address the technology gaps, and
encourage the development of curriculum needed to grow a computationally
proficient research workforce. Toward addressing these goals, we performed a
landscape study that culminated with a community workshop. Here, we present our
key findings from workshop discussions and identify next steps to be taken by
BRICCs, funding agencies, and the broader cyberinfrastructure community."
4991,Our results motivate further study of layered network models.,"The Layered
Conﬁguration Model relies on a simple description of network structure based on the Onion Decomposition, classifying
nodes based on their degree and centrality layer, but requiring an intricate connection scheme to generate complex
random networks from that description.","Layered heterogeneous mean-ﬁeld approximations
might oﬀer a powerful way of capturing the impact of network centrality on dynamical processes.",2022-04-18 17:55:52+00:00,"Network Onion Divergence: Network representation and comparison using nested configuration models with fixed connectivity, correlation and centrality patterns",cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Author('Laurent Hébert-Dufresne'), arxiv.Result.Author('Jean-Gabriel Young'), arxiv.Result.Author('Alexander Daniels'), arxiv.Result.Author('Antoine Allard')]","Random networks, constrained to reproduce specific features of networks, are
often used to represent and analyze network data as well as their mathematical
descriptions. Chief among them, the configuration model constrains random
networks by their degree distribution and is foundational to many areas of
network science. However, these representations are often selected based on
intuition or mathematical and computational simplicity rather than on
statistical evidence. To evaluate the quality of a network representation we
need to consider both the amount of information required by a random network
model as well as the probability of recovering the original data when using the
model as a generative process. To this end, we calculate the approximate size
of network ensembles generated by the popular configuration model and its
generalizations that include degree-correlations and centrality layers based on
the onion decomposition. We then apply minimum description length as a model
selection criterion and also introduce the Network Onion Divergence: model
selection and network comparison over a nested family of configuration models
with differing level of structural details. Using over 100 empirical sets of
network data, we find that a simple Layered Configuration Model offers the most
compact representation of the majority of real networks. We hope that our
results will continue to motivate the development of intricate random network
models that help capture network structure beyond the simple degree
distribution."
5017,"a single high sender, we see many promising opportuni-
ties for further study of competition effects from other high     Subsection .","to keep the total receiving rates ﬁxed is by dropping mes-

   While this paper estimated the role of repetition from         sages sufﬁciently fast (homogeneously across sources), cf.","Here, we consider a situation where senders
senders.",2022-04-19 08:32:18+00:00,Influence of Repetition through Limited Recall,cs.SI,"['cs.SI', 'cs.HC', 'stat.AP']","[arxiv.Result.Author('Jad Sassine'), arxiv.Result.Author('M. Amin Rahimian'), arxiv.Result.Author('Dean Eckles')]","Decision makers who receive many signals are subject to imperfect recall.
This is especially important when learning from feeds that aggregate messages
from many senders on social media platforms. In this paper, we study a stylized
model of learning from feeds and highlight the inefficiencies that arise due to
imperfect recall. In our model, failure to recall a specific message comes from
the accumulation of messages which creates interference. We characterize the
influence of each sender according to the rate at which she sends messages and
to the strength of interference. Our analysis indicates that imperfect recall
not only leads to double-counting and extreme opinions in finite populations,
but also impedes the ability of the receiver to learn the true state as the
population of the senders increases. We estimate the strength of interference
in an online experiment where participants are exposed to (non-informative)
repeated messages and they need to estimate the opinion of others. Results show
that interference plays a significant role and is weaker among participants who
disagree with each other. Our work has implication for the diffusion of
information in networks, especially when it is false because it is shared and
repeated more than true information."
5018,"a single high sender, we see many promising opportuni-
ties for further study of competition effects from other high     Subsection .","to keep the total receiving rates ﬁxed is by dropping mes-

   While this paper estimated the role of repetition from         sages sufﬁciently fast (homogeneously across sources), cf.","Here, we consider a situation where senders
senders.",2022-04-19 08:32:18+00:00,Influence of Repetition through Limited Recall,cs.SI,"['cs.SI', 'cs.HC', 'stat.AP']","[arxiv.Result.Author('Jad Sassine'), arxiv.Result.Author('M. Amin Rahimian'), arxiv.Result.Author('Dean Eckles')]","Decision makers who receive many signals are subject to imperfect recall.
This is especially important when learning from feeds that aggregate messages
from many senders on social media platforms. In this paper, we study a stylized
model of learning from feeds and highlight the inefficiencies that arise due to
imperfect recall. In our model, failure to recall a specific message comes from
the accumulation of messages which creates interference. We characterize the
influence of each sender according to the rate at which she sends messages and
to the strength of interference. Our analysis indicates that imperfect recall
not only leads to double-counting and extreme opinions in finite populations,
but also impedes the ability of the receiver to learn the true state as the
population of the senders increases. We estimate the strength of interference
in an online experiment where participants are exposed to (non-informative)
repeated messages and they need to estimate the opinion of others. Results show
that interference plays a significant role and is weaker among participants who
disagree with each other. Our work has implication for the diffusion of
information in networks, especially when it is false because it is shared and
repeated more than true information."
5147,"The estimating of the parameter will be considered in
further researches.","Therefore, we focus on
testing the ﬂexibility of the proposed model to simulate various realistic situations by setting
the model’s parameters manually.","In this section, we consider three types of diseases with low, medium, and high pathogenic
and lethal thresholds.",2022-04-11 04:14:31+00:00,To Simulate the Spread of Infectious Diseases by the Random Matrix,cs.SI,['cs.SI'],"[arxiv.Result.Author('Ting Wang'), arxiv.Result.Author('Gui-Yun Li'), arxiv.Result.Author('Xin-Hui Li'), arxiv.Result.Author('Chi-Chun Zhou'), arxiv.Result.Author('Yuan-Yuan Wang'), arxiv.Result.Author('Li-Juan Li'), arxiv.Result.Author('Yan-Ting Yang')]","The main aim to build models capable of simulating the spreading of
infectious diseases is to control them. And along this way, the key to find the
optimal strategy for disease control is to obtain a large number of simulations
of disease transitions under different scenarios. Therefore, the models that
can simulate the spreading of diseases under scenarios closer to the reality
and are with high efficiency are preferred. In the realistic social networks,
the random contact, including contacts between people in the public places and
the public transits, becomes the important access for the spreading of
infectious diseases. In this paper, a model can efficiently simulate the
spreading of infectious diseases under random contacts is proposed. In this
approach, the random contact between people is characterized by the random
matrix with elements randomly generated and the spread of the diseases is
simulated by the Markov process. We report an interesting property of the
proposed model: the main indicators of the spreading of the diseases such as
the death rate are invariant of the size of the population. Therefore,
representative simulations can be conducted on models consist of small number
of populations. The main advantage of this model is that it can easily simulate
the spreading of diseases under more realistic scenarios and thus is able to
give a large number of simulations needed for the searching of the optimal
control strategy. Based on this work, the reinforcement learning will be
introduced to give the optimal control strategy in the following work."
5148,"Here we only report this
interesting property and further research on this phenomenon will be carried out in later
works.","In the following simulations, we consider 100 individuals.","–9–
3.3 A Simple Discussion on Whether the Infectious Disease Will Break Our
       or Not

In this section, we investigate the outbreak threshold of the epidemic spreading.",2022-04-11 04:14:31+00:00,To Simulate the Spread of Infectious Diseases by the Random Matrix,cs.SI,['cs.SI'],"[arxiv.Result.Author('Ting Wang'), arxiv.Result.Author('Gui-Yun Li'), arxiv.Result.Author('Xin-Hui Li'), arxiv.Result.Author('Chi-Chun Zhou'), arxiv.Result.Author('Yuan-Yuan Wang'), arxiv.Result.Author('Li-Juan Li'), arxiv.Result.Author('Yan-Ting Yang')]","The main aim to build models capable of simulating the spreading of
infectious diseases is to control them. And along this way, the key to find the
optimal strategy for disease control is to obtain a large number of simulations
of disease transitions under different scenarios. Therefore, the models that
can simulate the spreading of diseases under scenarios closer to the reality
and are with high efficiency are preferred. In the realistic social networks,
the random contact, including contacts between people in the public places and
the public transits, becomes the important access for the spreading of
infectious diseases. In this paper, a model can efficiently simulate the
spreading of infectious diseases under random contacts is proposed. In this
approach, the random contact between people is characterized by the random
matrix with elements randomly generated and the spread of the diseases is
simulated by the Markov process. We report an interesting property of the
proposed model: the main indicators of the spreading of the diseases such as
the death rate are invariant of the size of the population. Therefore,
representative simulations can be conducted on models consist of small number
of populations. The main advantage of this model is that it can easily simulate
the spreading of diseases under more realistic scenarios and thus is able to
give a large number of simulations needed for the searching of the optimal
control strategy. Based on this work, the reinforcement learning will be
introduced to give the optimal control strategy in the following work."
5225,"Fourth, our results
depend on channel-level classiﬁcations from scholars and subject matter experts; further research
should examine whether the patterns we observe are robust to alternate measures at the channel and
(if possible) video level.","Findings from 2020 may not mirror what would have been observed

                                                         23
in prior years—in particular, it is possible that YouTube algorithms recommended alternative and
extremist channel videos more frequently prior to the changes made in 2019.","Finally, our measures of views, referrals, and subscriptions contain some
degree of error due to technical and ethical limitations.",2022-04-22 20:22:06+00:00,Subscriptions and external links help drive resentful users to alternative and extremist YouTube videos,cs.SI,"['cs.SI', 'cs.CY', 'cs.HC', 'cs.IR']","[arxiv.Result.Author('Annie Y. Chen'), arxiv.Result.Author('Brendan Nyhan'), arxiv.Result.Author('Jason Reifler'), arxiv.Result.Author('Ronald E. Robertson'), arxiv.Result.Author('Christo Wilson')]","Do online platforms facilitate the consumption of potentially harmful
content? Despite widespread concerns that YouTube's algorithms send people down
""rabbit holes"" with recommendations to extremist videos, little systematic
evidence exists to support this conjecture. Using paired behavioral and survey
data provided by participants recruited from a representative sample (n=1,181),
we show that exposure to alternative and extremist channel videos on YouTube is
heavily concentrated among a small group of people with high prior levels of
gender and racial resentment. These viewers typically subscribe to these
channels (causing YouTube to recommend their videos more often) and often
follow external links to them. Contrary to the ""rabbit holes"" narrative,
non-subscribers are rarely recommended videos from alternative and extremist
channels and seldom follow such recommendations when offered."
5397,"ments increases, highlighting the need for further research.","approach successfully locates relevant documents in nearby       These solutions carry their own limitations, including security
nodes but accuracy sharply declines as the number of docu-       concerns and poor load balancing of trafﬁc.",B.,2022-04-27 13:13:46+00:00,A Graph Diffusion Scheme for Decentralized Content Search based on Personalized PageRank,cs.SI,['cs.SI'],"[arxiv.Result.Author('Nikolaos Giatsoglou'), arxiv.Result.Author('Emmanouil Krasanakis'), arxiv.Result.Author('Symeon Papadopoulos'), arxiv.Result.Author('Ioannis Kompatsiaris')]","Decentralization is emerging as a key feature of the future Internet.
However, effective algorithms for search are missing from state-of-the-art
decentralized technologies, such as distributed hash tables and blockchain.
This is surprising, since decentralized search has been studied extensively in
earlier peer-to-peer (P2P) literature. In this work, we adopt a fresh outlook
for decentralized search in P2P networks that is inspired by advancements in
dense information retrieval and graph signal processing. In particular, we
generate latent representations of P2P nodes based on their stored documents
and diffuse them to the rest of the network with graph filters, such as
personalized PageRank. We then use the diffused representations to guide search
queries towards relevant content. Our preliminary approach is successful in
locating relevant documents in nearby nodes but the accuracy declines sharply
with the number of stored documents, highlighting the need for more
sophisticated techniques."
5430,These limitations suggest avenues for further research.,"However, our results may not
                generalize to other natural disasters such as floods or forest fires which may have
                specific effects on public sentiment and community resilience.","Platforms such Facebook,
                Reddit, and Weibo can provide detailed real-time data on public sentiment that would
                allow generalization beyond specific social media platforms and their communities.",2022-04-27 21:58:44+00:00,Quantifying societal emotional resilience to natural disasters from geo-located social media content,cs.SI,"['cs.SI', 'J.4']","[arxiv.Result.Author('Krishna C. Bathina'), arxiv.Result.Author('Marijn ten Thij'), arxiv.Result.Author('Johan Bollen')]","Natural disasters can have devastating and long-lasting effects on a
community's emotional well-being. These effects may be distributed unequally,
affecting some communities more profoundly and possibly over longer time
periods than others. Here, we analyze the effects of four major US hurricanes,
namely, Irma, Harvey, Florence, and Dorian on the emotional well-being of the
affected communities and regions. We show that a community's emotional response
to a hurricane event can be measured from the content of social media that its
population posted before, during, and after the hurricane. For each hurricane
making landfall in the US, we observe a significant decrease in sentiment in
the affected areas before and during the hurricane followed by a rapid return
to pre-hurricane baseline, often within 1-2 weeks. However, some communities
exhibit markedly different rates of decline and return to previous equilibrium
levels. This points towards the possibility of measuring the emotional
resilience of communities from the dynamics of their online emotional response."
5845,"Our ﬁndings also point to issues for further research on false news in China and other countries: First, in addition to
political false news, we need more research in other domains, because some ﬁndings in Politics may not apply to others.","We
made suggestions on the pipeline design including suspicious news discovery, veracity prediction, and proper display.","Second, we advocate for more focus on users who have special roles, like starters and veriﬁed users.",2022-05-06 08:23:26+00:00,Characterizing Multi-Domain False News and Underlying User Effects on Chinese Weibo,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']","[arxiv.Result.Author('Qiang Sheng'), arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('H. Russell Bernard'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Jintao Li'), arxiv.Result.Author('Huan Liu')]","False news that spreads on social media has proliferated over the past years
and has led to multi-aspect threats in the real world. While there are studies
of false news on specific domains (like politics or health care), little work
is found comparing false news across domains. In this article, we investigate
false news across nine domains on Weibo, the largest Twitter-like social media
platform in China, from 2009 to 2019. The newly collected data comprise 44,728
posts in the nine domains, published by 40,215 users, and reposted over 3.4
million times. Based on the distributions and spreads of the multi-domain
dataset, we observe that false news in domains that are close to daily life
like health and medicine generated more posts but diffused less effectively
than those in other domains like politics, and that political false news had
the most effective capacity for diffusion. The widely diffused false news posts
on Weibo were associated strongly with certain types of users -- by gender,
age, etc. Further, these posts provoked strong emotions in the reposts and
diffused further with the active engagement of false-news starters. Our
findings have the potential to help design false news detection systems in
suspicious news discovery, veracity prediction, and display and explanation.
The comparison of the findings on Weibo with those of existing work
demonstrates nuanced patterns, suggesting the need for more research on data
from diverse platforms, countries, or languages to tackle the global issue of
false news. The code and new anonymized dataset are available at
https://github.com/ICTMCG/Characterizing-Weibo-Multi-Domain-False-News."
5846,"Our ﬁndings also point to issues for further research on false news in China and other countries: First, in addition to
political false news, we need more research in other domains, because some ﬁndings in Politics may not apply to others.","We
made suggestions on the pipeline design including suspicious news discovery, veracity prediction, and proper display.","Second, we advocate for more focus on users who have special roles, like starters and veriﬁed users.",2022-05-06 08:23:26+00:00,Characterizing Multi-Domain False News and Underlying User Effects on Chinese Weibo,cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']","[arxiv.Result.Author('Qiang Sheng'), arxiv.Result.Author('Juan Cao'), arxiv.Result.Author('H. Russell Bernard'), arxiv.Result.Author('Kai Shu'), arxiv.Result.Author('Jintao Li'), arxiv.Result.Author('Huan Liu')]","False news that spreads on social media has proliferated over the past years
and has led to multi-aspect threats in the real world. While there are studies
of false news on specific domains (like politics or health care), little work
is found comparing false news across domains. In this article, we investigate
false news across nine domains on Weibo, the largest Twitter-like social media
platform in China, from 2009 to 2019. The newly collected data comprise 44,728
posts in the nine domains, published by 40,215 users, and reposted over 3.4
million times. Based on the distributions and spreads of the multi-domain
dataset, we observe that false news in domains that are close to daily life
like health and medicine generated more posts but diffused less effectively
than those in other domains like politics, and that political false news had
the most effective capacity for diffusion. The widely diffused false news posts
on Weibo were associated strongly with certain types of users -- by gender,
age, etc. Further, these posts provoked strong emotions in the reposts and
diffused further with the active engagement of false-news starters. Our
findings have the potential to help design false news detection systems in
suspicious news discovery, veracity prediction, and display and explanation.
The comparison of the findings on Weibo with those of existing work
demonstrates nuanced patterns, suggesting the need for more research on data
from diverse platforms, countries, or languages to tackle the global issue of
false news. The code and new anonymized dataset are available at
https://github.com/ICTMCG/Characterizing-Weibo-Multi-Domain-False-News."
6026,"We further study
                                                                                                                       the performance of different approaches on mathoverflow, which
                                                                                                                       is a huge dataset with 2, 464, 606 nodes and 17, 823, 525 edges.","performs two to three orders of magnitude faster than SBG and
                                                                                                                       6.2.5 Performance in the Hyper Scale Networks.","It
                                                                                                                       is noticed that SBG and CE-SBG cannot get results in a valid time
                                                                                                                       period on mathoverflow, while O-SBG can get the results in a valid
Reconnecting the Estranged Relationships: Optimizing the Influence Propagation in Evolving Networks

109Time (sec)    O-SBG                              109        O-SBG                102, 165, 164 number of influenced users on average when 𝑄 = 20
107                                     Time (sec)CE-SBG107    CE-SBG               in eu-core (i.e., 𝑛𝑜𝑑𝑒𝑠 = 986, temporal edges = 332, 334, average
105              SBG                                105        SBG                  degree = 25.28), respectively.",2022-05-11 02:16:39+00:00,Reconnecting the Estranged Relationships: Optimizing the Influence Propagation in Evolving Networks,cs.SI,"['cs.SI', 'cs.DB']","[arxiv.Result.Author('Taotao Cai'), arxiv.Result.Author('Qi Lei'), arxiv.Result.Author('Quan Z. Sheng'), arxiv.Result.Author('Shuiqiao Yang'), arxiv.Result.Author('Jian Yang'), arxiv.Result.Author('Wei Emma Zhang')]","Influence Maximization (IM), which aims to select a set of users from a
social network to maximize the expected number of influenced users, has
recently received significant attention for mass communication and commercial
marketing. Existing research efforts dedicated to the IM problem depend on a
strong assumption: the selected seed users are willing to spread the
information after receiving benefits from a company or organization. In
reality, however, some seed users may be reluctant to spread the information,
or need to be paid higher to be motivated. Furthermore, the existing IM works
pay little attention to capture user's influence propagation in the future
period as well. In this paper, we target a new research problem, named
Reconnecting Top-l Relationships (RTlR) query, which aims to find l number of
previous existing relationships but being stranged later, such that
reconnecting these relationships will maximize the expected benefit of
influenced users by the given group in a future period. We prove that the RTlR
problem is NP-hard. An efficient greedy algorithm is proposed to answer the
RTlR queries with the influence estimation technique and the well-chosen link
prediction method to predict the near future network structure. We also design
a pruning method to reduce unnecessary probing from candidate edges. Further, a
carefully designed order-based algorithm is proposed to accelerate the RTlR
queries. Finally, we conduct extensive experiments on real-world datasets to
demonstrate the effectiveness and efficiency of our proposed methods."
6096,"In this work, we systematically modify the homophily within

groups and the size of the minority, leaving the variation of node                                                       2

activity and edge density for a further study.","The clustering coefficient of node 𝑣𝑖 is defined as:
       𝑗

𝑣𝑖 and 𝑣 𝑗 and it is determined by their class membership.","In particular, in order                   𝑐𝑣    =               deg𝑡𝑜𝑡 (𝑣 ) − 1          −   2 deg↔ (𝑣      𝑇  (𝑣𝑖 )  (7)
                                                                                            𝑖     deg𝑡𝑜𝑡 (𝑣 )                                             )

to measure the influence of algorithms (RQ1) and homophily (RQ2)                                     𝑖                   𝑖                             𝑖

in the recommendations, we generate 4 networks for each com-                     where 𝑇 (𝑣𝑖 ) is the number of directed triangles through node

bination of homophily parameters ℎ𝑚𝑚, ℎ𝑀𝑀 ∈ {0.0, 0.1, .",2022-05-12 12:21:11+00:00,Link recommendations: Their impact on network structure and minorities,cs.SI,"['cs.SI', 'physics.soc-ph']","[arxiv.Result.Author('Antonio Ferrara'), arxiv.Result.Author('Lisette Espín-Noboa'), arxiv.Result.Author('Fariba Karimi'), arxiv.Result.Author('Claudia Wagner')]","Network-based people recommendation algorithms are widely employed on the Web
to suggest new connections in social media or professional platforms. While
such recommendations bring people together, the feedback loop between the
algorithms and the changes in network structure may exacerbate social biases.
These biases include rich-get-richer effects, filter bubbles, and polarization.
However, social networks are diverse complex systems and recommendations may
affect them differently, depending on their structural properties. In this
work, we explore five people recommendation algorithms by systematically
applying them over time to different synthetic networks. In particular, we
measure to what extent these recommendations change the structure of
bi-populated networks and show how these changes affect the minority group. Our
systematic experimentation helps to better understand when link recommendation
algorithms are beneficial or harmful to minority groups in social networks. In
particular, our findings suggest that, while all algorithms tend to close
triangles and increase cohesion, all algorithms except Node2Vec are prone to
favor and suggest nodes with high in-degree. Furthermore, we found that,
especially when both classes are heterophilic, recommendation algorithms can
reduce the visibility of minorities."
6360,"following, we will further study how user characteristics of
QAnon and non-QAnon supporters on Parler differ.",In the                    We now examine the virality of QAnon-related content.,"In the past, QAnon-related content has gone viral on main-
                                                                         stream social media (Sternisko, Cichocka, and van Bavel
Class label  #Users [%]         #Posts [%]            #Comments [%]      2020).",2022-05-18 10:07:12+00:00,Finding Qs: Profiling QAnon Supporters on Parler,cs.SI,['cs.SI'],"[arxiv.Result.Author('Dominik Bär'), arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","The social media platform ""Parler"" has emerged into a prominent fringe
community where a significant part of the user base are self-reported
supporters of QAnon, a far-right conspiracy theory alleging that a cabal of
elites controls global politics. QAnon is considered to have had an influential
role in the public discourse during the 2020 U.S. presidential election.
However, little is known about QAnon supporters on Parler and what sets them
aside from other users. Building up on social identity theory, we aim at
profiling the characteristics of QAnon supporters on Parler. We analyze a
large-scale dataset with more than 600,000 profiles of English-speaking users
on Parler. Based on users' profiles, posts, and comments, we then extract a
comprehensive set of user features, linguistic features, network features, and
content features. This allows us to perform user profiling and understand to
what extent these features discriminate between QAnon and non-QAnon supporters
on Parler. Our analysis is three-fold: (1) We quantify the number of QAnon
supporters on Parler, finding that 34,913 users (5.5% of all users) openly
report to support the conspiracy. (2) We examine differences between QAnon vs.
non-QAnon supporters. We find that QAnon supporters differ statistically
significantly from non-QAnon supporters across multiple dimensions. For
example, they have, on average, a larger number of followers, followees, and
posts, and thus have a large impact on the Parler network. (3) We use machine
learning to identify which user characteristics discriminate QAnon from
non-QAnon supporters. We find that user features, linguistic features, network
features, and content features, can - to a large extent - discriminate QAnon
vs. non-QAnon supporters on Parler. In particular, we find that user features
are highly discriminatory, followed by content features and linguistic
features."
6361,"following, we will further study how user characteristics of
QAnon and non-QAnon supporters on Parler differ.",In the                    We now examine the virality of QAnon-related content.,"In the past, QAnon-related content has gone viral on main-
                                                                         stream social media (Sternisko, Cichocka, and van Bavel
Class label  #Users [%]         #Posts [%]            #Comments [%]      2020).",2022-05-18 10:07:12+00:00,Finding Qs: Profiling QAnon Supporters on Parler,cs.SI,['cs.SI'],"[arxiv.Result.Author('Dominik Bär'), arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","The social media platform ""Parler"" has emerged into a prominent fringe
community where a significant part of the user base are self-reported
supporters of QAnon, a far-right conspiracy theory alleging that a cabal of
elites controls global politics. QAnon is considered to have had an influential
role in the public discourse during the 2020 U.S. presidential election.
However, little is known about QAnon supporters on Parler and what sets them
aside from other users. Building up on social identity theory, we aim at
profiling the characteristics of QAnon supporters on Parler. We analyze a
large-scale dataset with more than 600,000 profiles of English-speaking users
on Parler. Based on users' profiles, posts, and comments, we then extract a
comprehensive set of user features, linguistic features, network features, and
content features. This allows us to perform user profiling and understand to
what extent these features discriminate between QAnon and non-QAnon supporters
on Parler. Our analysis is three-fold: (1) We quantify the number of QAnon
supporters on Parler, finding that 34,913 users (5.5% of all users) openly
report to support the conspiracy. (2) We examine differences between QAnon vs.
non-QAnon supporters. We find that QAnon supporters differ statistically
significantly from non-QAnon supporters across multiple dimensions. For
example, they have, on average, a larger number of followers, followees, and
posts, and thus have a large impact on the Parler network. (3) We use machine
learning to identify which user characteristics discriminate QAnon from
non-QAnon supporters. We find that user features, linguistic features, network
features, and content features, can - to a large extent - discriminate QAnon
vs. non-QAnon supporters on Parler. In particular, we find that user features
are highly discriminatory, followed by content features and linguistic
features."
7347,"To facilitate further research, we
                                                  consolidate all implemented codes and datasets into the TwiBot-22 evaluation
                                                  framework, where researchers could consistently evaluate new models and datasets.","In addition, we re-implement 35
                                                  representative Twitter bot detection baselines and evaluate them on 9 datasets,
                                                  including TwiBot-22, to promote a fair comparison of model performance and
                                                  a holistic understanding of research progress.","The TwiBot-22 Twitter bot detection benchmark and evaluation framework are
                                                  publicly available at https://twibot22.github.io/.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7348,"We consolidate all datasets and
implemented codes into the TwiBot-22 evaluation framework to facilitate further research.","To compare TwiBot-22 with existing datasets, we re-implement 35 Twitter bot
detection baselines and evaluate them on 9 datasets, including TwiBot-22, to provide a holistic view
of research progress and highlight the advantages of TwiBot-22.","Our main
contributions are summarized as follows:

• We propose TwiBot-22, a graph-based Twitter bot detection dataset that establishes the largest
  benchmark to date, provides diversiﬁed entities and relations in the Twitter network, and has
  considerably improved annotation quality.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7349,"In light of these challenges, we present TwiBot-22 to alleviate these issues,
promote a re-thinking of research progress, and facilitate further research in Twitter bot detection.","3
In addition, these datasets suffer from limited dataset scale, incomplete graph structure, and low
annotation quality and they increasingly fall short of adequately and consistently benchmarking novel
graph-based approaches.","2.2 Graph-based Social Network Analysis

Users in online social networks interact with each other and become part of the network structure,
while the network structure is essential in understanding the patterns of social media [Carrington
et al., 2005].",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7350,"• Performance on TwiBot-22 is on average 4.8% lower than on TwiBot-20 across all baseline methods,
  which demonstrates that Twitter bot detection is still an open problem that calls for further research.","[2022] achieves near-sota performance on TwiBot-20, while
  failing to scale to TwiBot-22 as our implementation encounters the out-of-memory problem.","7
Table 3: Removing the graph-related model component from graph-based methods (w/o G) while
comparing to their original versions (Prev.)",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7351,"We hope our
efforts would facilitate further research in Twitter bot detection through:

                                                           8
Figure 3: Training models on fold i and testing on fold j.","5 Evaluation Framework

We consolidate Twitter bot detection datasets, data prepossessing codes, and all 35 implemented
baselines into the TwiBot-22 evaluation framework and make it publicly available.","We present model accuracy and report the
average value of each heatmap (avg), which serves as an overall indicator of generalization ability.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7352,"To facilitate
                                                   further research, we consolidate all implemented codes and datasets into the
                                                  TwiBot-22 evaluation framework, where researchers could consistently evaluate
                                                   new models and datasets.","In addition,
                                                  we re-implement 35 representative Twitter bot detection baselines and evaluate
                                                   them on 9 datasets, including TwiBot-22, to promote a fair comparison of model
                                                   performance and a holistic understanding of research progress.","The TwiBot-22 Twitter bot detection benchmark and
                                                   evaluation framework are publicly available at https://twibot22.github.io/.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7353,"We consolidate all datasets and
implemented codes into the TwiBot-22 evaluation framework to facilitate further research.","To compare TwiBot-22 with existing datasets, we re-implement 35 Twitter bot
detection baselines and evaluate them on 9 datasets, including TwiBot-22, to provide a holistic view
of research progress and highlight the advantages of TwiBot-22.","Our main
contributions are summarized as follows:

• We propose TwiBot-22, a graph-based Twitter bot detection dataset that establishes the largest
  benchmark to date, provides diversiﬁed entities and relations in the Twitter network, and has
  considerably improved annotation quality.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7354,"In light of these challenges, we present TwiBot-22 to alleviate these issues,
promote a re-thinking of research progress, and facilitate further research in Twitter bot detection.","In addition, these datasets suffer from limited dataset scale, incomplete graph structure, and low
annotation quality and they increasingly fall short of adequately and consistently benchmarking novel
graph-based approaches.","2.2 Graph-based Social Network Analysis

Users in online social networks interact with each other and become part of the network structure,
while the network structure is essential in understanding the patterns of social media [Carrington
et al., 2005].",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7355,"[2019] 59.9 61.8 +1.9 72.1 70.7 −1.4 70.7 66.9 −3.8 5.7 3.5 −2.2

Moghaddam and Abbaspour [2022] 74.0 72.2 −1.8 77.9 75.8 −2.1 73.8 73.3 −0.5 32.1 32.0 −0.1

Knauth [2019]             81.9 81.4 −0.5 85.2 84.9 −0.3 71.3 71.5 +0.2 37.1 11.3 −25.8

EvolveBot [Yang et al., 2013] 65.8 65.1 −0.7 69.7 69.3 −0.4 71.1 71.0 −0.1 14.1 14.0 −0.1

BotRGCN [Feng et al., 2021b] 85.7 82.6 −3.1 87.3 83.8 −3.5 79.7 75.4 −4.3 57.5 41.2 −16.3

RGT [Feng et al., 2021c]  86.6 82.6 −4.0 88.0 83.8 −4.2 76.5 75.4 −1.1 42.9 41.2 −1.7

• Performance on TwiBot-22 is on average 4.8% lower than on TwiBot-20 across all baseline methods,
  which demonstrates that Twitter bot detection is still an open problem that calls for further research.",Ali Alhosseini et al.,"This could be attributed to the fact that Twitter bots are constantly evolving to improve their disguise
  and evade detection, thus bot detection methods should also adapt and evolve.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7356,"We hope our
efforts would facilitate further research in Twitter bot detection through:

• establishing a uniﬁed interface for different types of Twitter bot detection datasets
• providing 35 representative baselines and well-documented implementations
• enriching the evaluation framework with new datasets and methods proposed in future research

Please refer to https://twibot22.github.io/ for more details.","5 Evaluation Framework

We consolidate Twitter bot detection datasets, data prepossessing codes, and all 35 implemented
baselines into the TwiBot-22 evaluation framework and make it publicly available.","6 Conclusion and Future Work

In this paper, we propose TwiBot-22, a graph-based Twitter bot detection benchmark.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7357,"To facilitate
                                                   further research, we consolidate all implemented codes and datasets into the
                                                  TwiBot-22 evaluation framework, where researchers could consistently evaluate
                                                   new models and datasets.","In addition,
                                                  we re-implement 35 representative Twitter bot detection baselines and evaluate
                                                   them on 9 datasets, including TwiBot-22, to promote a fair comparison of model
                                                   performance and a holistic understanding of research progress.","The TwiBot-22 Twitter bot detection benchmark and
                                                   evaluation framework are publicly available at https://twibot22.github.io/.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7358,"We consolidate all datasets and
implemented codes into the TwiBot-22 evaluation framework to facilitate further research.","To compare TwiBot-22 with existing datasets, we re-implement 35 Twitter bot
detection baselines and evaluate them on 9 datasets, including TwiBot-22, to provide a holistic view
of research progress and highlight the advantages of TwiBot-22.","Our main
contributions are summarized as follows:

• We propose TwiBot-22, a graph-based Twitter bot detection dataset that establishes the largest
  benchmark to date, provides diversiﬁed entities and relations in the Twitter network, and has
  considerably improved annotation quality.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7359,"In light of these challenges, we present TwiBot-22 to alleviate these issues,
promote a re-thinking of research progress, and facilitate further research in Twitter bot detection.","In addition, these datasets suffer from limited dataset scale, incomplete graph structure, and low
annotation quality and they increasingly fall short of adequately and consistently benchmarking novel
graph-based approaches.","2.2 Graph-based Social Network Analysis

Users in online social networks interact with each other and become part of the network structure,
while the network structure is essential in understanding the patterns of social media [Carrington
et al., 2005].",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7360,"[2019] 59.9 61.8 +1.9 72.1 70.7 −1.4 70.7 66.9 −3.8 5.7 3.5 −2.2

Moghaddam and Abbaspour [2022] 74.0 72.2 −1.8 77.9 75.8 −2.1 73.8 73.3 −0.5 32.1 32.0 −0.1

Knauth [2019]             81.9 81.4 −0.5 85.2 84.9 −0.3 71.3 71.5 +0.2 37.1 11.3 −25.8

EvolveBot [Yang et al., 2013] 65.8 65.1 −0.7 69.7 69.3 −0.4 71.1 71.0 −0.1 14.1 14.0 −0.1

BotRGCN [Feng et al., 2021b] 85.7 82.6 −3.1 87.3 83.8 −3.5 79.7 75.4 −4.3 57.5 41.2 −16.3

RGT [Feng et al., 2021c]  86.6 82.6 −4.0 88.0 83.8 −4.2 76.5 75.4 −1.1 42.9 41.2 −1.7

• Performance on TwiBot-22 is on average 4.8% lower than on TwiBot-20 across all baseline methods,
  which demonstrates that Twitter bot detection is still an open problem that calls for further research.",Ali Alhosseini et al.,"This could be attributed to the fact that Twitter bots are constantly evolving to improve their disguise
  and evade detection, thus bot detection methods should also adapt and evolve.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7361,"We hope our
efforts would facilitate further research in Twitter bot detection through:

• establishing a uniﬁed interface for different types of Twitter bot detection datasets
• providing 35 representative baselines and well-documented implementations
• enriching the evaluation framework with new datasets and methods proposed in future research

Please refer to https://twibot22.github.io/ for more details.","5 Evaluation Framework

We consolidate Twitter bot detection datasets, data prepossessing codes, and all 35 implemented
baselines into the TwiBot-22 evaluation framework and make it publicly available.","6 Conclusion and Future Work

In this paper, we propose TwiBot-22, a graph-based Twitter bot detection benchmark.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7362,"To facilitate
                                                   further research, we consolidate all implemented codes and datasets into the
                                                  TwiBot-22 evaluation framework, where researchers could consistently evaluate
                                                   new models and datasets.","In addition,
                                                  we re-implement 35 representative Twitter bot detection baselines and evaluate
                                                   them on 9 datasets, including TwiBot-22, to promote a fair comparison of model
                                                   performance and a holistic understanding of research progress.","The TwiBot-22 Twitter bot detection benchmark and
                                                   evaluation framework are publicly available at https://twibot22.github.io/.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7363,"We consolidate all datasets and
implemented codes into the TwiBot-22 evaluation framework to facilitate further research.","To compare TwiBot-22 with existing datasets, we re-implement 35 Twitter bot
detection baselines and evaluate them on 9 datasets, including TwiBot-22, to provide a holistic view
of research progress and highlight the advantages of TwiBot-22.","Our main
contributions are summarized as follows:

• We propose TwiBot-22, a graph-based Twitter bot detection dataset that establishes the largest
  benchmark to date, provides diversiﬁed entities and relations in the Twitter network, and has
  considerably improved annotation quality.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7364,"In light of these challenges, we present TwiBot-22 to alleviate these issues,
promote a re-thinking of research progress, and facilitate further research in Twitter bot detection.","In addition, these datasets suffer from limited dataset scale, incomplete graph structure, and low
annotation quality and they increasingly fall short of adequately and consistently benchmarking novel
graph-based approaches.","2.2 Graph-based Social Network Analysis

Users in online social networks interact with each other and become part of the network structure,
while the network structure is essential in understanding the patterns of social media [Carrington
et al., 2005].",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7365,"[2019] 59.9 61.8 +1.9 72.1 70.7 −1.4 70.7 66.9 −3.8 5.7 3.5 −2.2

Moghaddam and Abbaspour [2022] 74.0 72.2 −1.8 77.9 75.8 −2.1 73.8 73.3 −0.5 32.1 32.0 −0.1

Knauth [2019]             81.9 81.4 −0.5 85.2 84.9 −0.3 71.3 71.5 +0.2 37.1 11.3 −25.8

EvolveBot [Yang et al., 2013] 65.8 65.1 −0.7 69.7 69.3 −0.4 71.1 71.0 −0.1 14.1 14.0 −0.1

BotRGCN [Feng et al., 2021b] 85.7 82.6 −3.1 87.3 83.8 −3.5 79.7 75.4 −4.3 57.5 41.2 −16.3

RGT [Feng et al., 2021c]  86.6 82.6 −4.0 88.0 83.8 −4.2 76.5 75.4 −1.1 42.9 41.2 −1.7

• Performance on TwiBot-22 is on average 4.8% lower than on TwiBot-20 across all baseline methods,
  which demonstrates that Twitter bot detection is still an open problem that calls for further research.",Ali Alhosseini et al.,"This could be attributed to the fact that Twitter bots are constantly evolving to improve their disguise
  and evade detection, thus bot detection methods should also adapt and evolve.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7366,"We hope our
efforts would facilitate further research in Twitter bot detection through:

• establishing a uniﬁed interface for different types of Twitter bot detection datasets
• providing 35 representative baselines and well-documented implementations
• enriching the evaluation framework with new datasets and methods proposed in future research

Please refer to https://twibot22.github.io/ for more details.","5 Evaluation Framework

We consolidate Twitter bot detection datasets, data prepossessing codes, and all 35 implemented
baselines into the TwiBot-22 evaluation framework and make it publicly available.","6 Conclusion and Future Work

In this paper, we propose TwiBot-22, a graph-based Twitter bot detection benchmark.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7367,"To facilitate
                                                   further research, we consolidate all implemented codes and datasets into the
                                                  TwiBot-22 evaluation framework, where researchers could consistently evaluate
                                                   new models and datasets.","In addition,
                                                  we re-implement 35 representative Twitter bot detection baselines and evaluate
                                                   them on 9 datasets, including TwiBot-22, to promote a fair comparison of model
                                                   performance and a holistic understanding of research progress.","The TwiBot-22 Twitter bot detection benchmark and
                                                   evaluation framework are publicly available at https://twibot22.github.io/.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7368,"We consolidate all datasets and
implemented codes into the TwiBot-22 evaluation framework to facilitate further research.","To compare TwiBot-22 with existing datasets, we re-implement 35 Twitter bot
detection baselines and evaluate them on 9 datasets, including TwiBot-22, to provide a holistic view
of research progress and highlight the advantages of TwiBot-22.","Our main
contributions are summarized as follows:

• We propose TwiBot-22, a graph-based Twitter bot detection dataset that establishes the largest
  benchmark to date, provides diversiﬁed entities and relations in the Twitter network, and has
  considerably improved annotation quality.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7369,"In light of these challenges, we present TwiBot-22 to alleviate these issues, promote a
rethinking of research progress, and facilitate further research in Twitter bot detection.","In addition, these datasets suffer from limited dataset scale, incomplete graph structure, and low
annotation quality while increasingly falling short of consistently benchmarking novel graph-based
approaches.","2.2 Graph-based Social Network Analysis

Users in online social networks interact with each other and become part of the network structure,
while the network structure is essential in understanding the patterns of social media [Carrington
et al., 2005].",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7370,"• Performance on TwiBot-22 is on average 2.7% lower than on TwiBot-20 across all baseline methods,
  which demonstrates that Twitter bot detection is still an open problem that calls for further research.","[2022] achieves near-sota performance on TwiBot-20, while
  failing to scale to TwiBot-22 as our implementation encounters the out-of-memory problem.","This could be attributed to the fact that Twitter bots are constantly evolving to improve their disguise
  and evade detection, thus bot detection methods should also adapt and evolve.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7371,"We hope our
efforts would facilitate further research in Twitter bot detection through:

• establishing a uniﬁed interface for different types of Twitter bot detection datasets
• providing 35 representative baselines and well-documented implementations
• enriching the evaluation framework with new datasets and methods proposed in future research

Please refer to https://twibot22.github.io/ for more details.","5 Evaluation Framework

We consolidate Twitter bot detection datasets, data prepossessing codes, and all 35 implemented
baselines into the TwiBot-22 evaluation framework and make it publicly available.","6 Conclusion and Future Work

In this paper, we propose TwiBot-22, a graph-based Twitter bot detection benchmark.",2022-06-09 15:23:37+00:00,TwiBot-22: Towards Graph-Based Twitter Bot Detection,cs.SI,"['cs.SI', 'cs.AI']","[arxiv.Result.Author('Shangbin Feng'), arxiv.Result.Author('Zhaoxuan Tan'), arxiv.Result.Author('Herun Wan'), arxiv.Result.Author('Ningnan Wang'), arxiv.Result.Author('Zilong Chen'), arxiv.Result.Author('Binchi Zhang'), arxiv.Result.Author('Qinghua Zheng'), arxiv.Result.Author('Wenqian Zhang'), arxiv.Result.Author('Zhenyu Lei'), arxiv.Result.Author('Shujie Yang'), arxiv.Result.Author('Xinshun Feng'), arxiv.Result.Author('Qingyue Zhang'), arxiv.Result.Author('Hongrui Wang'), arxiv.Result.Author('Yuhan Liu'), arxiv.Result.Author('Yuyang Bai'), arxiv.Result.Author('Heng Wang'), arxiv.Result.Author('Zijian Cai'), arxiv.Result.Author('Yanbo Wang'), arxiv.Result.Author('Lijing Zheng'), arxiv.Result.Author('Zihan Ma'), arxiv.Result.Author('Jundong Li'), arxiv.Result.Author('Minnan Luo')]","Twitter bot detection has become an increasingly important task to combat
misinformation, facilitate social media moderation, and preserve the integrity
of the online discourse. State-of-the-art bot detection methods generally
leverage the graph structure of the Twitter network, and they exhibit promising
performance when confronting novel Twitter bots that traditional methods fail
to detect. However, very few of the existing Twitter bot detection datasets are
graph-based, and even these few graph-based datasets suffer from limited
dataset scale, incomplete graph structure, as well as low annotation quality.
In fact, the lack of a large-scale graph-based Twitter bot detection benchmark
that addresses these issues has seriously hindered the development and
evaluation of novel graph-based bot detection approaches. In this paper, we
propose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark
that presents the largest dataset to date, provides diversified entities and
relations on the Twitter network, and has considerably better annotation
quality than existing datasets. In addition, we re-implement 35 representative
Twitter bot detection baselines and evaluate them on 9 datasets, including
TwiBot-22, to promote a fair comparison of model performance and a holistic
understanding of research progress. To facilitate further research, we
consolidate all implemented codes and datasets into the TwiBot-22 evaluation
framework, where researchers could consistently evaluate new models and
datasets. The TwiBot-22 Twitter bot detection benchmark and evaluation
framework are publicly available at https://twibot22.github.io/"
7662,6 we formulate some questions for further research.,"Finally, in Sect.","2 Notions and Notation

For basic notions in graph theory, we refer e.g.",2022-06-15 08:01:34+00:00,A Fast Heuristic for Computing Geodesic Cores in Large Networks,cs.SI,['cs.SI'],"[arxiv.Result.Author('Florian Seiffarth'), arxiv.Result.Author('Tamás Horváth'), arxiv.Result.Author('Stefan Wrobel')]","Motivated by the increasing interest in applications of graph geodesic
convexity in machine learning and data mining, we present a heuristic for
computing the geodesic convex hull of node sets in networks. It generates a set
of almost maximal outerplanar spanning subgraphs for the input graph, computes
the geodesic closure in each of these graphs, and regards a node as an element
of the convex hull if it belongs to the closed sets for at least a user
specified number of outerplanar graphs. Our heuristic algorithm runs in time
linear in the number of edges of the input graph, i.e., it is faster with one
order of magnitude than the standard algorithm computing the closure exactly.
Its performance is evaluated empirically by approximating convexity based
core-periphery decomposition of networks. Our experimental results with large
real-world networks show that for most networks, the proposed heuristic was
able to produce close approximations significantly faster than the standard
algorithm computing the exact convex hulls. For example, while our algorithm
calculated an approximate core-periphery decomposition in 5 hours or less for
networks with more than 20 million edges, the standard algorithm did not
terminate within 50 days."
7832,"The primary recommendations of the studies were roughly equally
divided over time, with roughly half of the studies recommending the digital disease
surveillance method in question over or as complement to traditional clinical surveillance
methods, and the other half stating that it is promising yet awaits further research.","In earlier years, most studies aimed at 1) introducing new digital disease surveillance
methods and 2) track public perception and reaction to influenza; in later years, more studies
aimed at 3) improving and 4) comparing among existence methods, 5) extending these methods
into new geographical regions, as well as ultimately 6) developing assimilated forecast models
for influenza surveillance.","This in part
reflects the general endorsement of GFT by the research community as an acceptable real-time
influenza surveillance tool, while working on improvements and searching for alternatives.",2022-06-19 15:18:37+00:00,Meta-Analysis of the Accuracy of Syndromic Surveillance,cs.SI,['cs.SI'],"[arxiv.Result.Author('Liaquat Hossain'), arxiv.Result.Author('Derek Kham')]","We present the first meta-analysis of co-evolutionary learning networks for
digital disease surveillance research over last 10 years. In doing so, we show
the co-evolution and dynamical changes that occurred in academic research
related to digital disease surveillance for improving accuracy, approach and
results. Using dynamic network analysis, we are able to show the incorporation
of social media-based analytics and algorithms which have been proposed and
later improved by other researchers as co-evolutionary learning networks. This
essentially demonstrates how we improve our research and increase accuracy
through feedback loop for correcting the behaviour of an open system and
perhaps infer learning patterns, reliability and validity using 10 years
scientific research in digital disease surveillance."
7833,"Over time,
there were almost equal and constant proportions of studies endorsing the digital surveillance
method in view over or as complement to traditional surveillance methods, and of studies
stating that the method in view is promising while awaiting further research.","For
loop 2: there were clear shifts over time in study objectives, from aiming to develop original
digital disease surveillance methods and assessing public perception of and reactions to
influenza, to the improvement, comparisons and assimilation of developed methods.","We suggest that
this illustrates the general acceptance of digital disease surveillance methods by the research
community, while the limitations being raised and improved continue to support such an
acceptance.",2022-06-19 15:18:37+00:00,Meta-Analysis of the Accuracy of Syndromic Surveillance,cs.SI,['cs.SI'],"[arxiv.Result.Author('Liaquat Hossain'), arxiv.Result.Author('Derek Kham')]","We present the first meta-analysis of co-evolutionary learning networks for
digital disease surveillance research over last 10 years. In doing so, we show
the co-evolution and dynamical changes that occurred in academic research
related to digital disease surveillance for improving accuracy, approach and
results. Using dynamic network analysis, we are able to show the incorporation
of social media-based analytics and algorithms which have been proposed and
later improved by other researchers as co-evolutionary learning networks. This
essentially demonstrates how we improve our research and increase accuracy
through feedback loop for correcting the behaviour of an open system and
perhaps infer learning patterns, reliability and validity using 10 years
scientific research in digital disease surveillance."
8533,"31

B ANALYSIS FOR RETWEET PROBABILITY

We further study the role of lifetime and crowd effects for retweet probability, that is, the user’s
propensity to share content.",Mechanisms of True and False Rumor Sharing in Social Media: Wisdom-of-Crowds or Herd Behavior?,"For this, we introduce a binary variable Retweeted , indicating whether
a tweet was shared by a user.",2022-07-07 00:14:34+00:00,Mechanisms of True and False Rumor Sharing in Social Media: Wisdom-of-Crowds or Herd Behavior?,cs.SI,['cs.SI'],"[arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","Social media platforms disseminate extensive volumes of online content,
including true and, in particular, false rumors. Previous literature has
studied the diffusion of offline rumors, yet more research is needed to
understand the diffusion of online rumors. In this paper, we examine the role
of lifetime and crowd effects in social media sharing behavior for true vs.
false rumors. Based on 126,301 Twitter cascades, we find that the sharing
behavior is characterized by lifetime and crowd effects that explain
differences in the spread of true as opposed to false rumors. All else equal,
we find that a longer lifetime is associated with less sharing activities, yet
the reduction in sharing is larger for false than for true rumors. Hence,
lifetime is an important determinant explaining why false rumors die out.
Furthermore, we find that the spread of false rumors is characterized by
herding tendencies (rather than wisdom of crowds), whereby the spread of false
rumors becomes proliferated at a larger retweet depth. These findings explain
differences in the diffusion dynamics of true and false rumors and further
offer practical implications for social media platforms."
8534,"32                                                                   Nicolas Pröllochs and Stefan Feuerriegel

B ANALYSIS FOR RETWEET PROBABILITY

We further study the role of lifetime and crowd effects for retweet probability, that is, the user’s
propensity to share content.","In both cases, our results are robust and continue
to support our findings.","For this, we introduce a binary variable Retweeted , indicating whether
a tweet was shared by a user.",2022-07-07 00:14:34+00:00,Mechanisms of True and False Rumor Sharing in Social Media: Collective Intelligence or Herd Behavior?,cs.SI,['cs.SI'],"[arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","Social media platforms disseminate extensive volumes of online content,
including true and, in particular, false rumors. Previous literature has
studied the diffusion of offline rumors, yet more research is needed to
understand the diffusion of online rumors. In this paper, we examine the role
of lifetime and crowd effects in social media sharing behavior for true vs.
false rumors. Based on 126,301 Twitter cascades, we find that the sharing
behavior is characterized by lifetime and crowd effects that explain
differences in the spread of true as opposed to false rumors. All else equal,
we find that a longer lifetime is associated with less sharing activities, yet
the reduction in sharing is larger for false than for true rumors. Hence,
lifetime is an important determinant explaining why false rumors die out.
Furthermore, we find that the spread of false rumors is characterized by
herding tendencies (rather than collective intelligence), whereby the spread of
false rumors becomes proliferated at a larger retweet depth. These findings
explain differences in the diffusion dynamics of true and false rumors and
further offer practical implications for social media platforms."
8719,"We sought to
obtain a baseline characterization of dimensions of inﬂuence of           and/or cryptocurrency and ﬁnance-related tags often observed
selected “inﬂuencer” accounts for further study, as well as provide
initial data about these select online QAnon actors, toward               within QAnon-related accounts like #XRP, #NESARA,
hypothesizing means and motives for promoting QAnon.","The inclusion criteria for Study 1
STUDY 1
                                                                          wwearse as follows: 1) The account routinely promoted QAnon
Study 1 was an initial study of QAnon-related Twitter propaganda
accounts, focusing on “inﬂuencers,” broadly deﬁned, and their             hashtags (e.g., #QAnon, #WWG1WGA, #SaveTheChildren,
networks (Mattan et al., 2017; Sohn and Choi, 2019).","We
predicted that many pro-QAnon accounts would show Twitter                 #GESARA) and/or QAnon themes (e.g., depictions of
behaviors inconsistent with grassroots activities but consistent with
astroturﬁng (Keller et al., 2020).",2022-07-11 18:23:30+00:00,"QAnon Propaganda on Twitter as Information Warfare: Influencers, Networks, and Narratives",cs.SI,['cs.SI'],"[arxiv.Result.Author('L. Dilley'), arxiv.Result.Author('W. Welna'), arxiv.Result.Author('F. Foster')]","QAnon refers to a set of far-right, conspiratorial ideologies that have risen
in popularity in the U.S. since their initial promotion in 2017 on the 4chan
internet message board. A central narrative element of QAnon is that a powerful
group of elite, liberal members of the Democratic Party engage in morally
reprehensible practices, but that former U.S. President Donald J. Trump was
prosecuting them. Five studies investigated the influence and network
connectivity of accounts promoting QAnon on Twitter from August, 2020 through
January, 2021. Selection of Twitter accounts emphasized on-line influencers and
""persons of interest"" known or suspected of participation in QAnon propaganda
promotion activities. Evidence of large-scale coordination among accounts
promoting QAnon was observed, demonstrating rigorous, quantitative evidence of
""astroturfing"" in QAnon propaganda promotion on Twitter, as opposed to strictly
""grassroots"" activities of citizens acting independently. Further, evidence was
obtained supporting that networks of extreme far-right adherents engaged in
organized QAnon propaganda promotion, as revealed by network overlap among
accounts promoting far-right extremist (e.g., anti-Semitic) content and
insurrectionist themes; New Age, occult, and ""esoteric"" themes; and internet
puzzle games like Cicada 3301 and other ""alternate reality games."" Based on
well-grounded theories and findings from the social sciences, it is argued that
QAnon propaganda on Twitter in the months circa the 2020 U.S. Presidential
election likely reflected joint participation of multiple actors, including
nation-states like Russia, in innovative misuse of social media toward
undermining democratic processes by promoting ""magical"" thinking, ostracism of
Democrats and liberals, and salience of White extinction narratives common
among otherwise ideologically diverse groups on the extreme far-right."
8989,"Our results underscore the urgency and impor-
tance of further research in this area.","Moreover, we observe
a signiﬁcant presence of echo chambers in the right-leaning
population.","In sum, the contributions of this work are:

 • We present Retweet-BERT, a simple and elegant ap-
   proach to estimate user ideology based on linguistic ho-
   mophily and social network interactions.",2022-07-18 02:18:20+00:00,Retweet-BERT: Political Leaning Detection Using Language Features and Information Diffusion on Social Networks,cs.SI,"['cs.SI', 'cs.LG', 'physics.soc-ph']","[arxiv.Result.Author('Julie Jiang'), arxiv.Result.Author('Xiang Ren'), arxiv.Result.Author('Emilio Ferrara')]","Estimating the political leanings of social media users is a challenging and
ever more pressing problem given the increase in social media consumption. We
introduce Retweet-BERT, a simple and scalable model to estimate the political
leanings of Twitter users. Retweet-BERT leverages the retweet network structure
and the language used in users' profile descriptions. Our assumptions stem from
patterns of networks and linguistics homophily among people who share similar
ideologies. Retweet-BERT demonstrates competitive performance against other
state-of-the-art baselines, achieving 96%-97% macro-F1 on two recent Twitter
datasets (a COVID-19 dataset and a 2020 United States presidential elections
dataset). We also perform manual validation to validate the performance of
Retweet-BERT on users not in the training data. Finally, in a case study of
COVID-19, we illustrate the presence of political echo chambers on Twitter and
show that it exists primarily among right-leaning users. Our code is
open-sourced and our data is publicly available."
8990,"Our results underscore the urgency and impor-
tance of further research in this area.","Moreover, we observe
a signiﬁcant presence of echo chambers in the right-leaning
population.","In sum, the contributions of this work are:

 • We present Retweet-BERT, a simple and elegant ap-
   proach to estimate user ideology based on linguistic ho-
   mophily and social network interactions.",2022-07-18 02:18:20+00:00,Retweet-BERT: Political Leaning Detection Using Language Features and Information Diffusion on Social Networks,cs.SI,"['cs.SI', 'cs.LG', 'physics.soc-ph']","[arxiv.Result.Author('Julie Jiang'), arxiv.Result.Author('Xiang Ren'), arxiv.Result.Author('Emilio Ferrara')]","Estimating the political leanings of social media users is a challenging and
ever more pressing problem given the increase in social media consumption. We
introduce Retweet-BERT, a simple and scalable model to estimate the political
leanings of Twitter users. Retweet-BERT leverages the retweet network structure
and the language used in users' profile descriptions. Our assumptions stem from
patterns of networks and linguistics homophily among people who share similar
ideologies. Retweet-BERT demonstrates competitive performance against other
state-of-the-art baselines, achieving 96%-97% macro-F1 on two recent Twitter
datasets (a COVID-19 dataset and a 2020 United States presidential elections
dataset). We also perform manual validation to validate the performance of
Retweet-BERT on users not in the training data. Finally, in a case study of
COVID-19, we illustrate the presence of political echo chambers on Twitter and
show that it exists primarily among right-leaning users. Our code is
open-sourced and our data is publicly available."
9192,"We believe this matter merits
further research efforts and we hope this work sheds light on new research directions for the
broader CSCW community.","On the
other hand, non-textual features can also inform predictive modeling, suggesting that there are
distinguishing patterns of social media usage that could help us discern users’ proclivity to gender
identity declaration and users of various gender identity groups.",RQ3: Modeling Gender Pronoun Adoption.,2022-07-22 06:13:45+00:00,What are Your Pronouns? Examining Gender Pronoun Usage on Twitter,cs.SI,['cs.SI'],"[arxiv.Result.Author('Julie Jiang'), arxiv.Result.Author('Emily Chen'), arxiv.Result.Author('Luca Luceri'), arxiv.Result.Author('Goran Murić'), arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Ho-Chun Herbert Chang'), arxiv.Result.Author('Emilio Ferrara')]","Stating your gender pronouns, along with your name, is becoming the new norm
of self-introductions at school, at the workplace, and online. The increasing
prevalence and awareness of nonconforming gender identities put discussions of
developing gender-inclusive language at the forefront. This work presents the
first empirical research on gender pronoun usage on large-scale social media.
Leveraging a Twitter dataset of over 2 billion tweets collected continuously
over two years, we find that the public declaration of gender pronouns is on
the rise, with most people declaring as using she series pronouns, followed by
he series pronouns, and a smaller but considerable amount of non-binary
pronouns. From analyzing Twitter posts and sharing activities, we can discern
users who use gender pronouns from those who do not and also distinguish users
of various gender identities. We further illustrate the relationship between
explicit forms of social network exposure to gender pronouns and their eventual
gender pronoun adoption. This work carries crucial implications for
gender-identity studies and initiates new research directions in gender-related
fairness and inclusion, as well as support against online harassment and
discrimination on social media."
9193,"Building on past literature, we carry out a large-scale
gender inclusivity on social media and stimulate further research.","Given the groundbreaking       disproportionately experienced domestic violence during the lock-
nature of the presented study, our findings provide actionable in-       down and that non-binary people expressed concerns about blood
sights toward a principled understanding of gender identity and          donation.","analysis of not only users who disclosed gender identity but also
                                                                         those who did not, as well as to analyze their Twitter activities
2 BACKGROUND                                                             beyond biography descriptions and text.",2022-07-22 06:13:45+00:00,What are Your Pronouns? Examining Gender Pronoun Usage on Twitter,cs.SI,['cs.SI'],"[arxiv.Result.Author('Julie Jiang'), arxiv.Result.Author('Emily Chen'), arxiv.Result.Author('Luca Luceri'), arxiv.Result.Author('Goran Murić'), arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Ho-Chun Herbert Chang'), arxiv.Result.Author('Emilio Ferrara')]","Stating your gender pronouns, along with your name, is becoming the new norm
of self-introductions at school, at the workplace, and online. The increasing
prevalence and awareness of nonconforming gender identities put discussions of
developing gender-inclusive language at the forefront. This work presents the
first empirical research on gender pronoun usage on large-scale social media.
Leveraging a Twitter dataset of over 2 billion tweets collected continuously
over two years, we find that the public declaration of gender pronouns is on
the rise, with most people declaring as using she series pronouns, followed by
he series pronouns, and a smaller but considerable amount of non-binary
pronouns. From analyzing Twitter posts and sharing activities, we can discern
users who use gender pronouns from those who do not and also distinguish users
of various gender identities. We further illustrate the relationship between
explicit forms of social network exposure to gender pronouns and their eventual
gender pronoun adoption. This work carries crucial implications for
gender-identity studies and initiates new research directions in gender-related
fairness and inclusion, as well as support against online harassment and
discrimination on social media."
9194,"We believe this matter merits      exposure rather than the more admissible organic, involuntary
further research efforts and we hope this work sheds light on new     exposure.","Finally, our definition of social influence is self-selected
various gender pronoun categories.","Notwithstanding these limitations, we believe that our
research directions.",2022-07-22 06:13:45+00:00,What are Your Pronouns? Examining Gender Pronoun Usage on Twitter,cs.SI,['cs.SI'],"[arxiv.Result.Author('Julie Jiang'), arxiv.Result.Author('Emily Chen'), arxiv.Result.Author('Luca Luceri'), arxiv.Result.Author('Goran Murić'), arxiv.Result.Author('Francesco Pierri'), arxiv.Result.Author('Ho-Chun Herbert Chang'), arxiv.Result.Author('Emilio Ferrara')]","Stating your gender pronouns, along with your name, is becoming the new norm
of self-introductions at school, at the workplace, and online. The increasing
prevalence and awareness of nonconforming gender identities put discussions of
developing gender-inclusive language at the forefront. This work presents the
first empirical research on gender pronoun usage on large-scale social media.
Leveraging a Twitter dataset of over 2 billion tweets collected continuously
over two years, we find that the public declaration of gender pronouns is on
the rise, with most people declaring as using she series pronouns, followed by
he series pronouns, and a smaller but considerable amount of non-binary
pronouns. From analyzing Twitter posts and sharing activities, we can discern
users who use gender pronouns from those who do not and also distinguish users
of various gender identities. We further illustrate the relationship between
explicit forms of social network exposure to gender pronouns and their eventual
gender pronoun adoption. This work carries crucial implications for
gender-identity studies and initiates new research directions in gender-related
fairness and inclusion, as well as support against online harassment and
discrimination on social media."
9362,"The results suggest the emergence           general Twitter population, further research would be
of a natural partition of the network into two dense           needed to conﬁrm this.","to        believe that many of the results could extend to the
follow each other.","macro-communities, which are only loosely connected
with their opposing counterparts.",2022-07-27 08:19:18+00:00,Exploring the latent social space of COVID-19 Twitter elites,cs.SI,"['cs.SI', 'stat.AP']","[arxiv.Result.Author('Giacomo De Nicola'), arxiv.Result.Author('Victor H. Tuekam Mambou'), arxiv.Result.Author('Göran Kauermann')]","The COVID-19 pandemic brought upon a massive wave of disinformation,
exacerbating polarization in the increasingly divided landscape of online
discourse. In this context, popular social media users play a major role, as
they have the ability to broadcast messages to large audiences, thus
influencing public opinion. We make use of publicly available Twitter data to
study the behavior of influential users discussing the pandemic, whom we term
COVID-19 Twitter elites. We tackle the issue from a network perspective, by
considering users as nodes and following relationships as directed edges. The
resulting network structure is modeled by embedding the actors in a latent
social space, where users closer to one another have a higher probability of
forming edges. The results suggest the existence of two distinct communities,
which can be interpreted as ""generally pro"" and ""generally against"" vaccine
mandates. We further focus on a number of exposed users, such as politicians,
activists, and news outlets, and discuss their roles in the latent space. Our
findings show that the full spectrum of beliefs between the two poles is
represented, with more radical users positioned towards the extremes of the
space, and more moderate actors in the middle. Our analysis demonstrates how it
is possible to provide a nuanced representation of the COVID-19 Twitter
ecosystem by only considering follows within the network of elites. This
finding corroborates existing evidence on the pervasiveness of echo chamber
effects on the platform, and showcases the power of latent space models for
studying communication on social media."
9363,"to        general Twitter population, further research would be
follow each other.","made use of the latent cluster random eﬀects model             While, given the (well documented) strong inﬂuence of
to map these elite users into a two-dimensional eu-            popular users in the conversation, it is reasonable to
clidean social space, in which users that are closer to        believe that many of the results could extend to the
each other have a higher likelihood to connect, i.e.",The results suggest the emergence           needed to conﬁrm this.,2022-07-27 08:19:18+00:00,Exploring the latent social space of COVID-19 Twitter elites,cs.SI,"['cs.SI', 'stat.AP']","[arxiv.Result.Author('Giacomo De Nicola'), arxiv.Result.Author('Victor H. Tuekam Mambou'), arxiv.Result.Author('Göran Kauermann')]","Within the context of the COVID-19 Infodemic, popular social media users play
a major role, as they have the ability to influence public opinion through
their massive reach. We study the network of influential users discussing the
pandemic on Twitter, where we consider users as nodes, and following
relationships as directed edges. The resulting structure is modeled by
embedding the actors in a latent social space where users closer to one another
have a higher probability of forming edges, thus producing a ``social map'' of
the COVID-19 Twitter universe. The results suggest the existence of two
distinct communities, which can be interpreted as ``generally pro'' and
``generally against'' vaccine mandates. We further show that the two groups are
not fully homogeneous: the latent space accurately captures the entire spectrum
of beliefs between the two extremes, demonstrating how closely the users'
personal opinions tend to be related to who they follow."
9364,"The results suggest the emergence         popular users in the conversation, it is reasonable to
of a natural partition of the network into two dense         believe that many of the results could extend to the
macro-communities, which are only loosely connected          general Twitter population, further research would be
with their opposing counterparts.","to      While, given the (well documented) strong inﬂuence of
follow each other.",By focusing on a           needed to conﬁrm this.,2022-07-27 08:19:18+00:00,COVID-19 and social media: Beyond polarization,cs.SI,"['cs.SI', 'stat.AP']","[arxiv.Result.Author('Giacomo De Nicola'), arxiv.Result.Author('Victor H. Tuekam Mambou'), arxiv.Result.Author('Göran Kauermann')]","Popular social media users play a major role in the COVID-19 infodemic, as
they can influence public opinion through their massive reach. We study the
network of influential users discussing the pandemic on Twitter, where we
consider users as nodes and following relationships as directed edges. The
resulting structure is modeled by embedding the actors in a latent social space
where users closer to one another have a higher probability of forming edges,
thus producing a social map of the COVID-19 Twitter universe. The results
suggest the existence of two different user communities, which can be
interpreted as ""generally pro"" and ""generally against"" vaccine mandates,
corroborating the presence of echo chamber effects. We further show that the
two groups are not entirely homogeneous: the latent space accurately describes
an entire spectrum of beliefs between the two extremes, demonstrating that
polarization, while present, is not the only driver of the discussion."
9498,"One also notes that considering the mapping u →        1      as the
                                                                                      deg out (u)

discount function is only one simple proposal and ﬁnding the best deﬁnition for the discount function

depends on the downstream application and it requires further research.","When u is an in-neighbor of some node, we have degout(u) ≥ 1, so the denominator of the summand

in the above deﬁnition is non-zero.","In the following examples, we

use both versions (discounted and not discounted) of the inward NDFC matrix representation as feature

vectors to train deep learning models for learning PageRanks of directed graphs.",2022-07-30 07:07:30+00:00,Local Graph Embeddings Based on Neighbors Degree Frequency of Nodes,cs.SI,"['cs.SI', 'cs.LG']",[arxiv.Result.Author('Vahid Shirbisheh')],"We propose a local-to-global strategy for graph machine learning and network
analysis by defining certain local features and vector representations of nodes
and then using them to learn globally defined metrics and properties of the
nodes by means of deep neural networks. By extending the notion of the degree
of a node via Breath-First Search, a general family of {\bf parametric
centrality functions} is defined which are able to reveal the importance of
nodes. We introduce the {\bf neighbors degree frequency (NDF)}, as a locally
defined embedding of nodes of undirected graphs into euclidean spaces. This
gives rise to a vectorized labeling of nodes which encodes the structure of
local neighborhoods of nodes and can be used for graph isomorphism testing. We
add flexibility to our construction so that it can handle dynamic graphs as
well. Afterwards, the Breadth-First Search is used to extend NDF vector
representations into two different matrix representations of nodes which
contain higher order information about the neighborhoods of nodes. Our matrix
representations of nodes provide us with a new way of visualizing the shape of
the neighborhood of a node. Furthermore, we use these matrix representations to
obtain feature vectors, which are suitable for typical deep learning
algorithms. To demonstrate these node embeddings actually contain some
information about the nodes, in a series of examples, we show that PageRank and
closeness centrality can be learned by applying deep learning to these local
features. Our constructions are flexible enough to handle evolving graphs.
Finally, we explain how to adapt our constructions for directed graphs."
9638,"Then  we  deﬁne  the  class  of
                                                                                                          1
   This method can effectively identify the pandemic spread
anomaly patterns of any speciﬁc period, which should be                                 Gt as Vrt , with
valuable for further research.","σmj ax  =  max{σ  j  ,  σ2j  ,  ·  ·  ·  , σTj }.",rt = arg max (σtj /σmj ax).,2022-07-28 19:49:42+00:00,Analysis of the Spatio-temporal Dynamics of COVID-19 in Massachusetts via Spectral Graph Wavelet Theory,cs.SI,"['cs.SI', 'cs.LG', 'physics.soc-ph']","[arxiv.Result.Author('Ru Geng'), arxiv.Result.Author('Yixian Gao'), arxiv.Result.Author('Hongkun Zhang'), arxiv.Result.Author('Jian Zu')]","The rapid spread of COVID-19 disease has had a significant impact on the
world. In this paper, we study COVID-19 data interpretation and visualization
using open-data sources for 351 cities and towns in Massachusetts from December
6, 2020 to September 25, 2021. Because cities are embedded in rather complex
transportation networks, we construct the spatio-temporal dynamic graph model,
in which the graph attention neural network is utilized as a deep learning
method to learn the pandemic transition probability among major cities in
Massachusetts. Using the spectral graph wavelet transform (SGWT), we process
the COVID-19 data on the dynamic graph, which enables us to design effective
tools to analyze and detect spatio-temporal patterns in the pandemic spreading.
We design a new node classification method, which effectively identifies the
anomaly cities based on spectral graph wavelet coefficients. It can assist
administrations or public health organizations in monitoring the spread of the
pandemic and developing preventive measures. Unlike most work focusing on the
evolution of confirmed cases over time, we focus on the spatio-temporal
patterns of pandemic evolution among cities. Through the data analysis and
visualization, a better understanding of the epidemiological development at the
city level is obtained and can be helpful with city-specific surveillance."
9639,"In our further study, we will take our focus on the
(9), we can also ﬁnd successful and least successful cities            inﬂuence of neighboring states to improve our method.",By changing the time range of the formula           states.,"In
for any period.",2022-07-28 19:49:42+00:00,Analysis of the Spatio-temporal Dynamics of COVID-19 in Massachusetts via Spectral Graph Wavelet Theory,cs.SI,"['cs.SI', 'cs.LG', 'physics.soc-ph']","[arxiv.Result.Author('Ru Geng'), arxiv.Result.Author('Yixian Gao'), arxiv.Result.Author('Hongkun Zhang'), arxiv.Result.Author('Jian Zu')]","The rapid spread of COVID-19 disease has had a significant impact on the
world. In this paper, we study COVID-19 data interpretation and visualization
using open-data sources for 351 cities and towns in Massachusetts from December
6, 2020 to September 25, 2021. Because cities are embedded in rather complex
transportation networks, we construct the spatio-temporal dynamic graph model,
in which the graph attention neural network is utilized as a deep learning
method to learn the pandemic transition probability among major cities in
Massachusetts. Using the spectral graph wavelet transform (SGWT), we process
the COVID-19 data on the dynamic graph, which enables us to design effective
tools to analyze and detect spatio-temporal patterns in the pandemic spreading.
We design a new node classification method, which effectively identifies the
anomaly cities based on spectral graph wavelet coefficients. It can assist
administrations or public health organizations in monitoring the spread of the
pandemic and developing preventive measures. Unlike most work focusing on the
evolution of confirmed cases over time, we focus on the spatio-temporal
patterns of pandemic evolution among cities. Through the data analysis and
visualization, a better understanding of the epidemiological development at the
city level is obtained and can be helpful with city-specific surveillance."
9640,"Our further research will
patterns of Springﬁeld and Holyoke are similar, we can infer           try to overcome the limited features of the data and train the
a signiﬁcant correlation between them.",Because the spatio-temporal outbreak             pandemic evolution for 41 weeks.,"Indeed, we know that            network on the spatio-temporal dynamic graph to obtain the
they both have large trafﬁc ﬂows and are close to each other,          time-varying transition probability matrix.",2022-07-28 19:49:42+00:00,Analysis of the Spatio-temporal Dynamics of COVID-19 in Massachusetts via Spectral Graph Wavelet Theory,cs.SI,"['cs.SI', 'cs.LG', 'physics.soc-ph']","[arxiv.Result.Author('Ru Geng'), arxiv.Result.Author('Yixian Gao'), arxiv.Result.Author('Hongkun Zhang'), arxiv.Result.Author('Jian Zu')]","The rapid spread of COVID-19 disease has had a significant impact on the
world. In this paper, we study COVID-19 data interpretation and visualization
using open-data sources for 351 cities and towns in Massachusetts from December
6, 2020 to September 25, 2021. Because cities are embedded in rather complex
transportation networks, we construct the spatio-temporal dynamic graph model,
in which the graph attention neural network is utilized as a deep learning
method to learn the pandemic transition probability among major cities in
Massachusetts. Using the spectral graph wavelet transform (SGWT), we process
the COVID-19 data on the dynamic graph, which enables us to design effective
tools to analyze and detect spatio-temporal patterns in the pandemic spreading.
We design a new node classification method, which effectively identifies the
anomaly cities based on spectral graph wavelet coefficients. It can assist
administrations or public health organizations in monitoring the spread of the
pandemic and developing preventive measures. Unlike most work focusing on the
evolution of confirmed cases over time, we focus on the spatio-temporal
patterns of pandemic evolution among cities. Through the data analysis and
visualization, a better understanding of the epidemiological development at the
city level is obtained and can be helpful with city-specific surveillance."
9712,"The experimental results are detailed
for the prediction, yet there was no particular guidance         in Section V. Section VI summarizes the limitations of the
to inform the model in what condition of sentiments the          study and points the direction for further research.","Since    IV describes the model learning algorithm and its employ-
we use the sentiment information of tweets as a resource         ment in our research.","Finally,
price will increase or decrease.",2022-08-04 12:18:07+00:00,Twitter Attribute Classification with Q-Learning on Bitcoin Price Prediction,cs.SI,['cs.SI'],"[arxiv.Result.Author('Sattarov Otabek'), arxiv.Result.Author('Jaeyoung Choi')]","Aspiring to achieve an accurate Bitcoin price prediction based on people's
opinions on Twitter usually requires millions of tweets, using different text
mining techniques (preprocessing, tokenization, stemming, stop word removal),
and developing a machine learning model to perform the prediction. These
attempts lead to the employment of a significant amount of computer power,
central processing unit (CPU) utilization, random-access memory (RAM) usage,
and time. To address this issue, in this paper, we consider a classification of
tweet attributes that effects on price changes and computer resource usage
levels while obtaining an accurate price prediction. To classify tweet
attributes having a high effect on price movement, we collect all
Bitcoin-related tweets posted in a certain period and divide them into four
categories based on the following tweet attributes: $(i)$ the number of
followers of the tweet poster, $(ii)$ the number of comments on the tweet,
$(iii)$ the number of likes, and $(iv)$ the number of retweets. We separately
train and test by using the Q-learning model with the above four categorized
sets of tweets and find the best accurate prediction among them. Especially, we
design several reward functions to improve the prediction accuracy of the
Q-leaning. We compare our approach with a classic approach where all
Bitcoin-related tweets are used as input data for the model, by analyzing the
CPU workloads, RAM usage, memory, time, and prediction accuracy. The results
show that tweets posted by users with the most followers have the most
influence on a future price, and their utilization leads to spending 80\% less
time, 88.8\% less CPU consumption, and 12.5\% more accurate predictions
compared with the classic approach."
9713,"All of these things could be our          price-changes-coincide-with-major-news-events-about-the-
further research.","Further, considering other sources for sentiment
data and other types of cryptocurrencies could also increase     [6] [online] Available: https://www.aier.org/article/bitcoins-largest-
the accuracy of predictions.","cryptocurrency/

                             VII.",2022-08-04 12:18:07+00:00,Twitter Attribute Classification with Q-Learning on Bitcoin Price Prediction,cs.SI,['cs.SI'],"[arxiv.Result.Author('Sattarov Otabek'), arxiv.Result.Author('Jaeyoung Choi')]","Aspiring to achieve an accurate Bitcoin price prediction based on people's
opinions on Twitter usually requires millions of tweets, using different text
mining techniques (preprocessing, tokenization, stemming, stop word removal),
and developing a machine learning model to perform the prediction. These
attempts lead to the employment of a significant amount of computer power,
central processing unit (CPU) utilization, random-access memory (RAM) usage,
and time. To address this issue, in this paper, we consider a classification of
tweet attributes that effects on price changes and computer resource usage
levels while obtaining an accurate price prediction. To classify tweet
attributes having a high effect on price movement, we collect all
Bitcoin-related tweets posted in a certain period and divide them into four
categories based on the following tweet attributes: $(i)$ the number of
followers of the tweet poster, $(ii)$ the number of comments on the tweet,
$(iii)$ the number of likes, and $(iv)$ the number of retweets. We separately
train and test by using the Q-learning model with the above four categorized
sets of tweets and find the best accurate prediction among them. Especially, we
design several reward functions to improve the prediction accuracy of the
Q-leaning. We compare our approach with a classic approach where all
Bitcoin-related tweets are used as input data for the model, by analyzing the
CPU workloads, RAM usage, memory, time, and prediction accuracy. The results
show that tweets posted by users with the most followers have the most
influence on a future price, and their utilization leads to spending 80\% less
time, 88.8\% less CPU consumption, and 12.5\% more accurate predictions
compared with the classic approach."
9745,"The systemic comparison of centrality measures in an

undirected graph is a subject for further research.","PageRank

is computed as follows:

             PR(v) =        𝑃𝑅(𝑢) 1 − 𝛼
                                    +
                            𝑁          𝑇                                                             (3)

                         ∈

While LDC may be compared with eigenvector centrality for undirected graphs, here we

focus exclusively on directed graphs.","Betweenness

Shortest path betweenness was introduced by Freeman (1977) in order to quantify the

extent to which a vertex tends to be on the shortest paths between other vertices—in other

words, to serve as an intermediary.",2022-08-05 13:31:07+00:00,Local Detour Centrality: A Novel Local Centrality Measure for Weighted Networks,cs.SI,['cs.SI'],"[arxiv.Result.Author('Haim Cohen'), arxiv.Result.Author('Yinon Nachshon'), arxiv.Result.Author('Paz M. Naim'), arxiv.Result.Author('Jürgen Jost'), arxiv.Result.Author('Emil Saucan'), arxiv.Result.Author('Anat Maril')]","Centrality, in some sense, captures the extent to which a vertex controls the
flow of information in a network. Here, we propose Local Detour Centrality as a
novel centrality-based betweenness measure that captures the extent to which a
vertex shortens paths between neighboring vertices as compared to alternative
paths. After presenting our measure, we demonstrate empirically that it differs
from other leading central measures, such as betweenness, degree, closeness,
and the number of triangles. Through an empirical case study, we provide a
possible interpretation for Local Detour Centrality as a measure that captures
the extent to which a word is characterized by contextual diversity within a
semantic network. We then examine the relationship between our measure and the
accessibility to knowledge stored in memory. To do so, we show that words that
occur in several different and distinct contexts are significantly more
effective in facilitating the retrieval of subsequent words than are words that
lack this contextual diversity."
9746,"In this broad context, further research might compare centrality
measures in an undirected network or compare the performance of LDC to other betweenness
centrality measures such as random-walk betweenness and current flow betweenness.","From a general perspective, controlling the flow of information in the graph means
systematically offering a faster way of moving from one vertex to another than is possible
with alternative paths.","LDC
might also be extended to include non-geodesic paths as does flow betweenness centrality.",2022-08-05 13:31:07+00:00,Local Detour Centrality: A Novel Local Centrality Measure for Weighted Networks,cs.SI,['cs.SI'],"[arxiv.Result.Author('Haim Cohen'), arxiv.Result.Author('Yinon Nachshon'), arxiv.Result.Author('Paz M. Naim'), arxiv.Result.Author('Jürgen Jost'), arxiv.Result.Author('Emil Saucan'), arxiv.Result.Author('Anat Maril')]","Centrality, in some sense, captures the extent to which a vertex controls the
flow of information in a network. Here, we propose Local Detour Centrality as a
novel centrality-based betweenness measure that captures the extent to which a
vertex shortens paths between neighboring vertices as compared to alternative
paths. After presenting our measure, we demonstrate empirically that it differs
from other leading central measures, such as betweenness, degree, closeness,
and the number of triangles. Through an empirical case study, we provide a
possible interpretation for Local Detour Centrality as a measure that captures
the extent to which a word is characterized by contextual diversity within a
semantic network. We then examine the relationship between our measure and the
accessibility to knowledge stored in memory. To do so, we show that words that
occur in several different and distinct contexts are significantly more
effective in facilitating the retrieval of subsequent words than are words that
lack this contextual diversity."
9747,This question will need to constitute the subject of further research.,"Finally, an
essential question that grows out of our work is the relationship between LDC and various
notions of Ricci curvature for a network, such as Forman, Ollivier, Menger, and Haantjes.","From the semantic perspective, this work is part of a study by Nachshon, Cohen,
Naim et al.",2022-08-05 13:31:07+00:00,Local Detour Centrality: A Novel Local Centrality Measure for Weighted Networks,cs.SI,['cs.SI'],"[arxiv.Result.Author('Haim Cohen'), arxiv.Result.Author('Yinon Nachshon'), arxiv.Result.Author('Paz M. Naim'), arxiv.Result.Author('Jürgen Jost'), arxiv.Result.Author('Emil Saucan'), arxiv.Result.Author('Anat Maril')]","Centrality, in some sense, captures the extent to which a vertex controls the
flow of information in a network. Here, we propose Local Detour Centrality as a
novel centrality-based betweenness measure that captures the extent to which a
vertex shortens paths between neighboring vertices as compared to alternative
paths. After presenting our measure, we demonstrate empirically that it differs
from other leading central measures, such as betweenness, degree, closeness,
and the number of triangles. Through an empirical case study, we provide a
possible interpretation for Local Detour Centrality as a measure that captures
the extent to which a word is characterized by contextual diversity within a
semantic network. We then examine the relationship between our measure and the
accessibility to knowledge stored in memory. To do so, we show that words that
occur in several different and distinct contexts are significantly more
effective in facilitating the retrieval of subsequent words than are words that
lack this contextual diversity."
9893,"The adopted techniques, the availability of the data, the
                                                replicability of the experiments, and the preliminary ﬁndings, other than
                                                being interesting on their own, also pave the way to further research in
                                                the domain.","However, we have identiﬁed several
                                                anomalies in the behavior of particular accounts and in the sentiment
                                                trend for some subjects that represent a starting point for further analy-
                                                sis in the ﬁeld.","Keywords: Online Social Networks · Aspect-Based Sentiment Analysis
                                                · Twitter · Data Mining · Data Analysis · 2022 Russo-Ukrainian Conﬂict

                                       1 Introduction

                                       Online Social Networks (OSN) were born to connect users so that they could
                                       share their emotions, desires, happiness, hobbies and interests as an important
                                       aspect of their socialization.",2022-08-02 11:55:01+00:00,"Characterizing the 2022 Russo-Ukrainian Conflict Through the Lenses of Aspect-Based Sentiment Analysis: Dataset, Methodology, and Preliminary Findings",cs.SI,"['cs.SI', 'cs.CR']","[arxiv.Result.Author('Maurantonio Caprolu'), arxiv.Result.Author('Alireza Sadighian'), arxiv.Result.Author('Roberto Di Pietro')]","Online social networks (OSNs) play a crucial role in today's world. On the
one hand, they allow free speech, information sharing, and social-movements
organization, to cite a few. On the other hand, they are the tool of choice to
spread disinformation, hate speech, and to support propaganda. For these
reasons, OSNs data mining and analysis aimed at detecting disinformation
campaigns that may arm the society and, more in general, poison the democratic
posture of states, are essential activities during key events such as
elections, pandemics, and conflicts. In this paper, we studied the 2022
Russo-Ukrainian conflict on Twitter, one of the most used OSNs. We
quantitatively and qualitatively analyze a dataset of more than 5.5+ million
tweets related to the subject, generated by 1.8+ million unique users. By
leveraging statistical analysis techniques and aspect-based sentiment analysis
(ABSA), we discover hidden insights in the collected data and abnormal patterns
in the users' sentiment that in some cases confirm while in other cases
disprove common beliefs on the conflict. In particular, based on our findings
and contrary to what suggested in some mainstream media, there is no evidence
of massive disinformation campaigns. However, we have identified several
anomalies in the behavior of particular accounts and in the sentiment trend for
some subjects that represent a starting point for further analysis in the
field. The adopted techniques, the availability of the data, the replicability
of the experiments, and the preliminary findings, other than being interesting
on their own, also pave the way to further research in the domain."
9894,"– The replicability of the experiments and the novel techniques adopted, joined
     with the gained insights and the highlighted future work, pave the way for
     further research on the comparative strength and weaknesses among ABSA
     and other data mining techniques.","– We discussed our results revealing statistics and sentiment trends for the ma-
     jor players involved in the conﬂict and provided valuable insights for future
     investigation on disinformation related to the Russo-Ukrainian conﬂict.",Roadmap.,2022-08-02 11:55:01+00:00,"Characterizing the 2022 Russo-Ukrainian Conflict Through the Lenses of Aspect-Based Sentiment Analysis: Dataset, Methodology, and Preliminary Findings",cs.SI,"['cs.SI', 'cs.CR']","[arxiv.Result.Author('Maurantonio Caprolu'), arxiv.Result.Author('Alireza Sadighian'), arxiv.Result.Author('Roberto Di Pietro')]","Online social networks (OSNs) play a crucial role in today's world. On the
one hand, they allow free speech, information sharing, and social-movements
organization, to cite a few. On the other hand, they are the tool of choice to
spread disinformation, hate speech, and to support propaganda. For these
reasons, OSNs data mining and analysis aimed at detecting disinformation
campaigns that may arm the society and, more in general, poison the democratic
posture of states, are essential activities during key events such as
elections, pandemics, and conflicts. In this paper, we studied the 2022
Russo-Ukrainian conflict on Twitter, one of the most used OSNs. We
quantitatively and qualitatively analyze a dataset of more than 5.5+ million
tweets related to the subject, generated by 1.8+ million unique users. By
leveraging statistical analysis techniques and aspect-based sentiment analysis
(ABSA), we discover hidden insights in the collected data and abnormal patterns
in the users' sentiment that in some cases confirm while in other cases
disprove common beliefs on the conflict. In particular, based on our findings
and contrary to what suggested in some mainstream media, there is no evidence
of massive disinformation campaigns. However, we have identified several
anomalies in the behavior of particular accounts and in the sentiment trend for
some subjects that represent a starting point for further analysis in the
field. The adopted techniques, the availability of the data, the replicability
of the experiments, and the preliminary findings, other than being interesting
on their own, also pave the way to further research in the domain."
9895,"However, we identiﬁed several anomalies in users’ be-
havior and sentiment trends for some subjects that call for further research in
the ﬁeld.","Our results do not support the
hypotheses of a mass disinformation campaign, contrary to what claimed by a
few mainstream media.","In particular, accounts with a low Friend Ratio (FR) twitted much
more than regular users, with a sentiment trend for some keywords that di-
verged from other users.",2022-08-02 11:55:01+00:00,"Characterizing the 2022 Russo-Ukrainian Conflict Through the Lenses of Aspect-Based Sentiment Analysis: Dataset, Methodology, and Preliminary Findings",cs.SI,"['cs.SI', 'cs.CR']","[arxiv.Result.Author('Maurantonio Caprolu'), arxiv.Result.Author('Alireza Sadighian'), arxiv.Result.Author('Roberto Di Pietro')]","Online social networks (OSNs) play a crucial role in today's world. On the
one hand, they allow free speech, information sharing, and social-movements
organization, to cite a few. On the other hand, they are the tool of choice to
spread disinformation, hate speech, and to support propaganda. For these
reasons, OSNs data mining and analysis aimed at detecting disinformation
campaigns that may arm the society and, more in general, poison the democratic
posture of states, are essential activities during key events such as
elections, pandemics, and conflicts. In this paper, we studied the 2022
Russo-Ukrainian conflict on Twitter, one of the most used OSNs. We
quantitatively and qualitatively analyze a dataset of more than 5.5+ million
tweets related to the subject, generated by 1.8+ million unique users. By
leveraging statistical analysis techniques and aspect-based sentiment analysis
(ABSA), we discover hidden insights in the collected data and abnormal patterns
in the users' sentiment that in some cases confirm while in other cases
disprove common beliefs on the conflict. In particular, based on our findings
and contrary to what suggested in some mainstream media, there is no evidence
of massive disinformation campaigns. However, we have identified several
anomalies in the behavior of particular accounts and in the sentiment trend for
some subjects that represent a starting point for further analysis in the
field. The adopted techniques, the availability of the data, the replicability
of the experiments, and the preliminary findings, other than being interesting
on their own, also pave the way to further research in the domain."
9896,"As such, this work has
the potential to pave the way for further research in the ﬁeld.","For instance, whether ABSA is capable of a better expressivity

7 https://apnews.com/article/russia-ukraine-volodymyr-zelenskyy-kyiv-technology-
   misinformation-5e884b85f8dbb54d16f5f10d105fe850
Characterizing the 2022 Russo-Ukrainian Conﬂict on Twitter  15

with respect to standard mining and analysis techniques.","References

 1.",2022-08-02 11:55:01+00:00,"Characterizing the 2022 Russo-Ukrainian Conflict Through the Lenses of Aspect-Based Sentiment Analysis: Dataset, Methodology, and Preliminary Findings",cs.SI,"['cs.SI', 'cs.CR']","[arxiv.Result.Author('Maurantonio Caprolu'), arxiv.Result.Author('Alireza Sadighian'), arxiv.Result.Author('Roberto Di Pietro')]","Online social networks (OSNs) play a crucial role in today's world. On the
one hand, they allow free speech, information sharing, and social-movements
organization, to cite a few. On the other hand, they are the tool of choice to
spread disinformation, hate speech, and to support propaganda. For these
reasons, OSNs data mining and analysis aimed at detecting disinformation
campaigns that may arm the society and, more in general, poison the democratic
posture of states, are essential activities during key events such as
elections, pandemics, and conflicts. In this paper, we studied the 2022
Russo-Ukrainian conflict on Twitter, one of the most used OSNs. We
quantitatively and qualitatively analyze a dataset of more than 5.5+ million
tweets related to the subject, generated by 1.8+ million unique users. By
leveraging statistical analysis techniques and aspect-based sentiment analysis
(ABSA), we discover hidden insights in the collected data and abnormal patterns
in the users' sentiment that in some cases confirm while in other cases
disprove common beliefs on the conflict. In particular, based on our findings
and contrary to what suggested in some mainstream media, there is no evidence
of massive disinformation campaigns. However, we have identified several
anomalies in the behavior of particular accounts and in the sentiment trend for
some subjects that represent a starting point for further analysis in the
field. The adopted techniques, the availability of the data, the replicability
of the experiments, and the preliminary findings, other than being interesting
on their own, also pave the way to further research in the domain."
10024,"Second, further research might be required to understand the flow of
psychological traits in conversational turns to detect more organized phishing than single email-based phishing.","First, we will obtain ground truth for the PPTs by labeling them with multiple human
raters enabling us to measure the kappa statistics for testing inter-rater reliability, which in turn can provide a
more accurate estimation of PPTs.","Finally, an investigation of how the individual PPTs contribute to forming a phishing email can provide
valuable insight that can be utilized for more efficient phishing email detection.",2022-08-14 06:39:27+00:00,Improving Phishing Detection Via Psychological Trait Scoring,cs.SI,['cs.SI'],"[arxiv.Result.Author('Sadat Shahriar'), arxiv.Result.Author('Arjun Mukherjee'), arxiv.Result.Author('Omprakash Gnawali')]","Phishing emails exhibit some unique psychological traits which are not
present in legitimate emails. From empirical analysis and previous research, we
find three psychological traits most dominant in Phishing emails - A Sense of
Urgency, Inducing Fear by Threatening, and Enticement with Desire. We manually
label 10% of all phishing emails in our training dataset for these three
traits. We leverage that knowledge by training BERT, Sentence-BERT (SBERT), and
Character-level-CNN models and capturing the nuances via the last layers that
form the Phishing Psychological Trait (PPT) scores. For the phishing email
detection task, we use the pretrained BERT and SBERT model, and concatenate the
PPT scores to feed into a fully-connected neural network model. Our results
show that the addition of PPT scores improves the model performance
significantly, thus indicating the effectiveness of PPT scores in capturing the
psychological nuances. Furthermore, to mitigate the effect of the imbalanced
training dataset, we use the GPT-2 model to generate phishing emails (Radford
et al., 2019). Our best model outperforms the current State-of-the-Art (SOTA)
model's F1 score by 4.54%. Additionally, our analysis of individual PPTs
suggests that Fear provides the strongest cue in detecting phishing emails."
10430,"For this reason, new methods that balance both
aspects may be elaborated in further research.","According to Figure 8, one could argue that considering solely the concentration of POIs can possibly
improve the spatial distributions of origin and destinations displayed in synthetic instances, however, the

                                                                     23
distances decay eﬀect presented in Figure 9 might be lost.","Figure 8: Spatial distribution for Points of Interest (POIs) in the city of “Chicago, Illinois” according to
reported locations in OpenStreetMaps (OSM).",2022-08-23 16:04:08+00:00,Instance generation tool for on-demand transportation problems,cs.SI,"['cs.SI', 'cs.CC']","[arxiv.Result.Author('Michell Queiroz'), arxiv.Result.Author('Flavien Lucas'), arxiv.Result.Author('Kenneth Sorensen')]","We present REQreate, a tool to generate instances for on-demand
transportation problems. Such problems consist of optimizing the routes of
vehicles according to passengers' demand for transportation under space and
time restrictions (requests). REQreate is flexible and can be configured to
generate instances for a large number of problems in this problem class. In
this paper, we demonstrate this by generating instances for the Dial-a-Ride
Problem (DARP) and On-demand Bus Routing Problem (ODBRP). In most of the
literature, researchers either test their algorithms with instances based on
artificial networks or perform real-life case studies on instances derived from
a specific city or region. Furthermore, locations of requests for on-demand
transportation problems are mostly randomly chosen according to a uniform
distribution.
  The aim of REQreate is to overcome these non-realistic and overfitting
shortcomings. Rather than relying on either artificial or limited data, we
retrieve real-world street networks from OpenStreetMaps (OSM). To the best of
our knowledge, this is the first tool to make use of real-life networks to
generate instances for an extensive catalogue of existing and upcoming
on-demand transportation problems. Additionally, we present a simple method
that can be embedded in the instance generation process to produce distinct
urban mobility patterns. We perform an analysis with real life datasets
reported by rideshare companies and compare them with properties of synthetic
instances generated with REQreate. Another contribution of this work is the
introduction of the concept of instance similarity that serves as support to
create diverse benchmark sets, in addition to properties (size, dynamism,
urgency and geographic dispersion) that could be used to comprehend what
affects the performance of algorithms."
10563,"5.6 Future work

Beyond the already outlined future directions, the collected data can be used to further study
patterns of sharing food online.","In the future, performing individual-level studies, as opposed to the
population-level study reported here, will make it possible to disentangle measurement error from
population error.","Future work should further understand who shares food on Twitter
(consumers, skilled individuals, but also non-individual agents, such as restaurants or caterers).",2022-08-30 17:13:16+00:00,Biased Bytes: On the Validity of Estimating Food Consumption from Digital Traces,cs.SI,"['cs.SI', 'cs.CY', 'cs.HC']","[arxiv.Result.Author('Kristina Gligorić'), arxiv.Result.Author('Irena Đorđević'), arxiv.Result.Author('Robert West')]","Given that measuring food consumption at a population scale is a challenging
task, researchers have begun to explore digital traces (e.g., from social media
or from food-tracking applications) as potential proxies. However, it remains
unclear to what extent digital traces reflect real food consumption. The
present study aims to bridge this gap by quantifying the link between dietary
behaviors as captured via social media (Twitter) v.s. a food-tracking
application (MyFoodRepo). We focus on the case of Switzerland and contrast
images of foods collected through the two platforms, by designing and deploying
a novel crowdsourcing framework for estimating biases with respect to
nutritional properties and appearance. We find that the food type distributions
in social media v.s. food tracking diverge; e.g., bread is 2.5 times more
frequent among consumed and tracked foods than on Twitter, whereas cake is 12
times more frequent on Twitter. Controlling for the different food type
distributions, we contrast consumed and tracked foods of a given type with
foods shared on Twitter. Across food types, food posted on Twitter is perceived
as tastier, more caloric, less healthy, less likely to have been consumed at
home, more complex, and larger-portioned, compared to consumed and tracked
foods. The fact that there is a divergence between food consumption as measured
via the two platforms implies that at least one of the two is not a faithful
representation of the true food consumption in the general Swiss population.
Thus, researchers should be attentive and aim to establish evidence of validity
before using digital traces as a proxy for the true food consumption of a
general population. We conclude by discussing the potential sources of these
biases and their implications, outlining pitfalls and threats to validity, and
proposing actionable ways for overcoming them."
10564,"Future work should further study
where they share it from (residential vs. commercial areas), when, and in what context, as well as
what are the predictors of engagement with food on Twitter.","We
expect that further characterizing user types would not change our main conclusions, but would
reveal how biases vary between different strata of Twitter users.","5.7 Implications beyond food

Researching human behaviors beyond food, our crowdsourcing framework can be used to measure
many types of biases, including, but not limited to, politics and activism or behaviors important
for health and well-being, such as fitness and time spent in nature, travel, fashion and aesthetics,
socialization, or pet ownership.",2022-08-30 17:13:16+00:00,Biased Bytes: On the Validity of Estimating Food Consumption from Digital Traces,cs.SI,"['cs.SI', 'cs.CY', 'cs.HC']","[arxiv.Result.Author('Kristina Gligorić'), arxiv.Result.Author('Irena Đorđević'), arxiv.Result.Author('Robert West')]","Given that measuring food consumption at a population scale is a challenging
task, researchers have begun to explore digital traces (e.g., from social media
or from food-tracking applications) as potential proxies. However, it remains
unclear to what extent digital traces reflect real food consumption. The
present study aims to bridge this gap by quantifying the link between dietary
behaviors as captured via social media (Twitter) v.s. a food-tracking
application (MyFoodRepo). We focus on the case of Switzerland and contrast
images of foods collected through the two platforms, by designing and deploying
a novel crowdsourcing framework for estimating biases with respect to
nutritional properties and appearance. We find that the food type distributions
in social media v.s. food tracking diverge; e.g., bread is 2.5 times more
frequent among consumed and tracked foods than on Twitter, whereas cake is 12
times more frequent on Twitter. Controlling for the different food type
distributions, we contrast consumed and tracked foods of a given type with
foods shared on Twitter. Across food types, food posted on Twitter is perceived
as tastier, more caloric, less healthy, less likely to have been consumed at
home, more complex, and larger-portioned, compared to consumed and tracked
foods. The fact that there is a divergence between food consumption as measured
via the two platforms implies that at least one of the two is not a faithful
representation of the true food consumption in the general Swiss population.
Thus, researchers should be attentive and aim to establish evidence of validity
before using digital traces as a proxy for the true food consumption of a
general population. We conclude by discussing the potential sources of these
biases and their implications, outlining pitfalls and threats to validity, and
proposing actionable ways for overcoming them."
10878,"To further study the effect of the threshold choice, we plot the returns versus the feature threshold in Figure 9.","This analysis suggests that the bot probability is not
     as useful for investment strategies compared to the other features.","The
     tweet volume and bot probability show clusters in their respective feature values.",2022-09-07 03:36:55+00:00,Social Media Engagement and Cryptocurrency Performance,cs.SI,"['cs.SI', 'cs.AI', 'cs.NA', 'math.NA']","[arxiv.Result.Author('Khizar Qureshi'), arxiv.Result.Author('Tauhid Zaman')]","We study the problem of predicting the future performance of cryptocurrencies
using social media data. We propose a new model to measure the engagement of
users with topics discussed on social media based on interactions with social
media posts. This model overcomes the limitations of previous volume and
sentiment based approaches. We use this model to estimate engagement
coefficients for 48 cryptocurrencies created between 2019 and 2021 using data
from Twitter from the first month of the cryptocurrencies' existence. We find
that the future returns of the cryptocurrencies are dependent on the engagement
coefficients. Cryptocurrencies whose engagement coefficients are too low or too
high have lower returns. Low engagement coefficients signal a lack of interest,
while high engagement coefficients signal artificial activity which is likely
from automated accounts known as bots. We measure the amount of bot posts for
the cryptocurrencies and find that generally, cryptocurrencies with more bot
posts have lower future returns. While future returns are dependent on both the
bot activity and engagement coefficient, the dependence is strongest for the
engagement coefficient, especially for short-term returns. We show that simple
investment strategies which select cryptocurrencies with engagement
coefficients exceeding a fixed threshold perform well for holding times of a
few months."
10897,"By visualizing the complex networks in
a multi-layer manner, users can further research into vari-               [9] Cai, D., Shao, Z., He, X., Yan, X., Han, J.: Community mining from
ous properties of complex networks including multi-layer                        multi-relational networks.","Wiley
world systems as multidimensional networks have yielded                         Online Library
valuable insight.","In: European Conference on Principles
neighbours (all nodes connected to a node across layers),                       of Data Mining and Knowledge Discovery, pp.",2022-09-06 14:18:21+00:00,MultiViz: A Gephi Plugin for Scalable Visualization of Multi-Layer Networks,cs.SI,['cs.SI'],"[arxiv.Result.Author('Jayamohan Pillai C. S.'), arxiv.Result.Author('Ayan Chatterjee'), arxiv.Result.Author('Geetha M.'), arxiv.Result.Author('Amitava Mukherjee')]","The process of visually presenting networks is an effective way to understand
entity relationships within the networks since it reveals the overall structure
and topology of the network. Real networks are extremely difficult to visualize
due to their immense complexity, which includes vast amounts of data, several
types of interactions, various subsystems and several levels of connectivity as
well as changes over time. This paper introduces the ""MultiViz Plugin,"" a
plugin for gephi, an open-source software tool for graph visualization and
modification, in order to to visualize complex networks in a multi-layer
manner. A collection of settings are availabe through the plugin to transform
an existing network into a multi-layered network. The plugin supports several
layout algorithms and lets user to choose which property of the network to be
used as the layer. The goal of the study is to give the user complete control
over how the network is visualized in a multi-layer fashion. We demonstrate the
ability of the plugin to visualize multi-layer data using a real-life complex
multi-layer datasets."
11471,"There are still gray areas that require further research and policy recom-
mendations for social media companies.","As the boundaries between automated behavior and organic
activity become more blurred, we should ﬁnd ways to detect user intent and
identify early warning signals of coordinated behaviors.","Although these questions are not
trivial to answer, they pose a risk if malicious organizations exploit them.",2022-09-20 21:27:25+00:00,Should we agree to disagree about Twitter's bot problem?,cs.SI,"['cs.SI', 'cs.CY']",[arxiv.Result.Author('Onur Varol')],"Bots, simply defined as accounts controlled by automation, can be used as a
weapon for online manipulation and pose a threat to the health of platforms.
Researchers have studied online platforms to detect, estimate, and characterize
bot accounts. Concerns about the prevalence of bots were raised following Elon
Musk's bid to acquire Twitter. Twitter's recent estimate that 5\% of
monetizable daily active users being bot accounts raised questions about their
methodology. This estimate is based on a specific number of active users and
relies on Twitter's criteria for bot accounts. In this work, we want to stress
that crucial questions need to be answered in order to make a proper estimation
and compare different methodologies. We argue how assumptions on bot-likely
behavior, the detection approach, and the population inspected can affect the
estimation of the percentage of bots on Twitter. Finally, we emphasize the
responsibility of platforms to be vigilant, transparent, and unbiased in
dealing with threats that may affect their users."
11472,"There are still gray areas that require further research and policy recom-
mendations for social media companies.","As the boundaries between automated behavior and organic
activity become more blurred, we should ﬁnd ways to detect user intent and
identify early warning signals of coordinated behaviors.","Although these questions are not
trivial to answer, they pose a risk if malicious organizations exploit them.",2022-09-20 21:27:25+00:00,Should we agree to disagree about Twitter's bot problem?,cs.SI,"['cs.SI', 'cs.CY']",[arxiv.Result.Author('Onur Varol')],"Bots, simply defined as accounts controlled by automation, can be used as a
weapon for online manipulation and pose a threat to the health of platforms.
Researchers have studied online platforms to detect, estimate, and characterize
bot accounts. Concerns about the prevalence of bots were raised following Elon
Musk's bid to acquire Twitter. Twitter's recent estimate that 5\% of
monetizable daily active users being bot accounts raised questions about their
methodology. This estimate is based on a specific number of active users and
relies on Twitter's criteria for bot accounts. In this work, we want to stress
that crucial questions need to be answered in order to make a proper estimation
and compare different methodologies. We argue how assumptions on bot-likely
behavior, the detection approach, and the population inspected can affect the
estimation of the percentage of bots on Twitter. Finally, we emphasize the
responsibility of platforms to be vigilant, transparent, and unbiased in
dealing with threats that may affect their users."
11516,This is an area ripe for further research.,"Preliminary research indicates for example that amenities like Tesla charging
stations and In N Out Burgers are spreading from less to more traditionalistic scenes, while
Walmart stores are doing the opposite.","Figure 10 provides a final illustration of diffusion processes, this time focusing on examining
travel and taste patterns using social media data (in this case, check-ins on Foursquare).",2022-09-21 21:20:55+00:00,Changing the Scene: applying four models of social evolution to the scenescape,cs.SI,['cs.SI'],"[arxiv.Result.Author('Daniel Silver'), arxiv.Result.Author('Thiago H Silva'), arxiv.Result.Author('Patrick Adler')]","This paper elaborates a multi-model approach to studying how local scenes
change. We refer to this as the ""4 D's"" of scene change: development,
differentiation, defense, and diffusion. Each posits somewhat distinct change
processes, and has its own tradition of theory and empirical research, which we
briefly review. After summarizing some major trends in scenes and amenities in
the US context, for each change model, we present some initial findings,
discussing data and methods throughout. Our overall goal is to point toward new
research arcs on change models of scenes, and to give some clear examples and
directions for how to think about and collect data to understand what makes
some scenes change, others not, why, and in what directions."
11519,"Consequently, despite mounting evidence
of the relevance of self-disclosure in eliciting and delivering social support, further research is needed
to determine how textual components of self-disclosing postings influence the reception of social
feedback.","6.3 Factors Driving Social Feedback

The findings of RQ1 and RQ2 imply that members of the COVID-19 support group selectively
choose what kind of personal information to disclose according to their needs, but they do not equally
receive the social support or engagement that they pursue.","Results of RQ3 showed that negative sentiments, the post readability, and the inclusion of
first-person pronouns had strong connections with emotional support elicitation, whereas they did not

                                                                              , Vol.",2022-09-21 22:12:15+00:00,Effects of Online Self-Disclosure on Social Feedback During the COVID-19 Pandemic,cs.SI,['cs.SI'],"[arxiv.Result.Author('Jooyoung Lee'), arxiv.Result.Author('Sarah Rajtmajer'), arxiv.Result.Author('Eesha Srivatsavaya'), arxiv.Result.Author('Shomir Wilson')]","We investigate relationships between online self-disclosure and received
social feedback during the COVID-19 crisis. We crawl a total of 2,399 posts and
29,851 associated comments from the r/COVID19_support subreddit and manually
extract fine-grained personal information categories and types of social
support sought from each post. We develop a BERT-based ensemble classifier to
automatically identify types of support offered in users' comments. We then
analyze the effect of personal information sharing and posts' topical, lexical,
and sentiment markers on the acquisition of support and five interaction
measures (submission scores, the number of comments, the number of unique
commenters, the length and sentiments of comments). Our findings show that: 1)
users were more likely to share their age, education, and location information
when seeking both informational and emotional support, as opposed to pursuing
either one; 2) while personal information sharing was positively correlated
with receiving informational support when requested, it did not correlate with
emotional support; 3) as the degree of self-disclosure increased, information
support seekers obtained higher submission scores and longer comments, whereas
emotional support seekers' self-disclosure resulted in lower submission scores,
fewer comments, and fewer unique commenters; 4) post characteristics affecting
social feedback differed significantly based on types of support sought by post
authors. These results provide empirical evidence for the varying effects of
self-disclosure on acquiring desired support and user involvement online during
the COVID-19 pandemic. Furthermore, this work can assist support seekers hoping
to enhance and prioritize specific types of social feedback."
11590,"Since also the analysis is more complicated, we omit a
further study of the multiplicative law.","The
corresponding multiplicative law in discrete time is

xi[k + 1] = xi[k] ·  1+           α·(|Ndji∩·dNji|+1) − 21 ·δ·(|Nj \Ndii|·+dj|Ni\Nj |−2)                                 · xj[k] − xi[k]      (10)

                            j∈Ni

    Although the physical intuition is similar, the multiplicative process in (10) behaves diﬀerent in
discrete time than the additive law in (9).","We present the analogon of (9) in a matrix form:

Theorem 1 The discrete time process (9) satisﬁes the linear matrix diﬀerence equation

                     x[k + 1] = (I + W − diag (W · u)) · x[k],                                                                               (11)

where the N × 1 vector u is composed of ones, the N × N identity matrix is denoted by I, while the
N × N topology-based matrix W is deﬁned as

W = (α + δ) ∆−1 · A ◦ A2 + A · ∆−1 − 1 · δ ∆−1 · A + A · ∆−1                                                                                 (12)
                                                         2

where ◦ denotes the Hadamard product.",2022-09-23 14:39:36+00:00,Linear Clustering Process on Networks,cs.SI,"['cs.SI', 'math.DS']","[arxiv.Result.Author('Ivan Jokić'), arxiv.Result.Author('Piet Van Mieghem')]","We propose a linear clustering process on a network consisting of two
opposite forces: attraction and repulsion between adjacent nodes. Each node is
mapped to a position on a one-dimensional line. The attraction and repulsion
forces move the nodal position on the line, depending on how similar or
different the neighbourhoods of two adjacent nodes are. Based on each node
position, the number of clusters in a network, together with each node's
cluster membership, is estimated. The performance of the proposed linear
clustering process is benchmarked on synthetic networks against widely accepted
clustering algorithms such as modularity, the Louvain method and the non-back
tracking matrix. The proposed linear clustering process outperforms the most
popular modularity-based methods, such as the Louvain method, while possessing
a comparable computational complexity."
11728,"In that case, further research is needed to re-examine what are the best clustering criteria for student
LCs, and what are the best metrics to evaluate the resulting LCs.","A major limitation of this research is that in the future, once COVID-19 is entirely
beyond concern, the clustering criteria proposed may no longer be the best criteria for LC creation.","Based on literature, LC clustering

                                                                                                                 168
criteria that can support student learning includes external factors, such as access or function of
the group, or internal factors, such as relationships, values, goals, or common interests.",2022-09-20 18:32:09+00:00,VLSI-Inspired Methods for Student Learning Community Creation and Refinement,cs.SI,['cs.SI'],[arxiv.Result.Author('Sheng Lun Cao')],"COVID-19 significantly disrupted how educational contents are delivered in
academic institutions, rapidly accelerating the adoption of online and blended
learning. This thesis explores the creation and refinement of optimized student
learning communities as a mean to support online and blended learning in the
pandemic and post-pandemic setting. Students enrolled in university courses can
be modeled as an enrollment network akin to a circuit netlist. Learning
communities are created by clustering students into groups, optimized for
maximum internal connection to support student learning, and minimum external
connection to reduce disease transmission. Three VLSI-based clustering
algorithms: Hyperedge Coarsening, Modified Hyperedge Coarsening, and Best
Choice, are modified to cluster student enrollment networks. The learning
communities created by the clustering algorithms are further refined by the
Simulated Annealing algorithm using the same optimization criteria. The
Learning Community Creation and Refinement Framework combines all three stages
of network modeling, learning community creation, and learning community
refinement. The proposed framework is tested on both the 3rd year Electrical
Engineering Fall 2020 enrollment dataset and a very large Fall 2020 and Winter
2021 enrollment dataset. Best Choice performed the best among the clustering
algorithms, capable of creating learning communities for the optimization
criteria for a given maximum cluster size. Simulated Annealing can refine the
clustering results by significantly increase cluster quality. The framework is
capable of creating and refining learning communities for both the small and
the large enrollment networks, but it is better suited for creating tailored
learning communities at a program level. Future work, including creating
student learning communities based on other optimization criteria, should be
explored."
11834,"This work also contributes by constructing a new
large scale dataset to further research online discussion structures’ properties.13 Our
results have implications for both content creators and platforms by helping them
understand and shape the users’ interaction platforms with social media platforms.","In particular, we understood the factors aﬀecting the important
structural attributes of a discussion post, namely its width, depth, and size, via the
lens of local and global properties.",Our study is not without limitations.,2022-09-29 14:50:50+00:00,Deconstructing the structure of online conversations on Reddit,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Author('Yulin Yu'), arxiv.Result.Author('Paramveer Dhillon')]","The Internet has made it easier for social scientists to study human behavior
by analyzing their interactions on social media platforms. Many of these
platforms characterize conversations among users via threads, which induce a
tree-like structure. The structural properties of these discussion trees, such
as their width, depth, and size, can be used to make inferences regarding user
discussion patterns and conversation dynamics. In this paper, we seek to
understand the structure of these online discussions on Reddit. We characterize
the structure of these discussions via a set of global and local
discussion-tree properties. The global features constitute information
regarding the community/subreddit of a given post, whereas the local features
are comprised of the properties of the post itself. We perform various
statistical analyses on a year's worth of Reddit data containing a quarter of a
million posts and several million comments. These analyses allow us to tease
apart the relative contribution of a discussion post's global and local
properties and characterize the importance of specific individual features in
determining the discussions' structural patterns. Our results indicate that
both local and global features explain a significant amount of structural
variation. Local features are collectively more important as they explain
significantly more variation in the discussion trees' structural properties
than global features. However, there is significant heterogeneity in the impact
of the various features. Several global features, e.g., the topic, age,
popularity, and the redundancy of content in a subreddit, also play a crucial
role in understanding the specific properties of discussion trees."
12181,"In our case, it also requires further research on the relationship
between rank R and rank L of each block and it is beyond the scope of this chapter.","But we refer the
interested reader to previous heuristics studies which try to estimate a low-rank estimation
[176, 193] for an overview.","For
our work, we set rank R of tensor X as 5 and vary the rank L of block between 10 − 30,
experimental analysis is provided in sub-section 4.5.2.",2022-10-10 02:26:00+00:00,Modeling and Mining Multi-Aspect Graphs With Scalable Streaming Tensor Decomposition,cs.SI,"['cs.SI', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('Ekta Gujral')],"Graphs emerge in almost every real-world application domain, ranging from
online social networks all the way to health data and movie viewership
patterns. Typically, such real-world graphs are big and dynamic, in the sense
that they evolve over time. Furthermore, graphs usually contain multi-aspect
information i.e. in a social network, we can have the ""means of communication""
between nodes, such as who messages whom, who calls whom, and who comments on
whose timeline and so on.
  How can we model and mine useful patterns, such as communities of nodes in
that graph, from such multi-aspect graphs? How can we identify dynamic patterns
in those graphs, and how can we deal with streaming data, when the volume of
data to be processed is very large? In order to answer those questions, in this
thesis, we propose novel tensor-based methods for mining static and dynamic
multi-aspect graphs. In general, a tensor is a higher-order generalization of a
matrix that can represent high-dimensional multi-aspect data such as
time-evolving networks, collaboration networks, and spatio-temporal data like
Electroencephalography (EEG) brain measurements.
  The thesis is organized in two synergistic thrusts: First, we focus on static
multi-aspect graphs, where the goal is to identify coherent communities and
patterns between nodes by leveraging the tensor structure in the data. Second,
as our graphs evolve dynamically, we focus on handling such streaming updates
in the data without having to re-compute the decomposition, but incrementally
update the existing results."
12182,"Also,
extending BTD-NLS to online settings is challenging and requires further research both to
ﬁnd the best ﬁt and to interpret the role of the independent variables used in various inherit
methods.","Hence,
we compare our proposed method against algorithms that decompose full tensor.","It faces diﬃculties in ﬁtting due to the narrow boundaries on the model and less
ﬂexibility.",2022-10-10 02:26:00+00:00,Modeling and Mining Multi-Aspect Graphs With Scalable Streaming Tensor Decomposition,cs.SI,"['cs.SI', 'cs.AI', 'cs.LG']",[arxiv.Result.Author('Ekta Gujral')],"Graphs emerge in almost every real-world application domain, ranging from
online social networks all the way to health data and movie viewership
patterns. Typically, such real-world graphs are big and dynamic, in the sense
that they evolve over time. Furthermore, graphs usually contain multi-aspect
information i.e. in a social network, we can have the ""means of communication""
between nodes, such as who messages whom, who calls whom, and who comments on
whose timeline and so on.
  How can we model and mine useful patterns, such as communities of nodes in
that graph, from such multi-aspect graphs? How can we identify dynamic patterns
in those graphs, and how can we deal with streaming data, when the volume of
data to be processed is very large? In order to answer those questions, in this
thesis, we propose novel tensor-based methods for mining static and dynamic
multi-aspect graphs. In general, a tensor is a higher-order generalization of a
matrix that can represent high-dimensional multi-aspect data such as
time-evolving networks, collaboration networks, and spatio-temporal data like
Electroencephalography (EEG) brain measurements.
  The thesis is organized in two synergistic thrusts: First, we focus on static
multi-aspect graphs, where the goal is to identify coherent communities and
patterns between nodes by leveraging the tensor structure in the data. Second,
as our graphs evolve dynamically, we focus on handling such streaming updates
in the data without having to re-compute the decomposition, but incrementally
update the existing results."
12487,"The case study
4 DISCUSSION                                                              shows that CFS-GeoKG well supports the storage and query of
                                                                          geospatial semantics of a multi-commodity flow network, thereby
We acknowledge several limits associated with the current data            supporting the comprehensive measurement of single-sourcing
source, each of which prompts further research directions.","Division                                       -0.4%
Region        0.867  0.880                     -6.7%                      5 CONCLUSION
              0.766  0.763
              0.647  0.604                                                In this paper, we introduce a GeoKG-based approach to measuring
                                                                          the resilience of a multi-commodity flow network.","First,         dependence and the dependence of geographically distant or
utilizing CFS data requires that we represent both food imported          non-adjacent suppliers/customers.",2022-10-09 23:12:16+00:00,Measuring Network Resilience via Geospatial Knowledge Graph: a Case Study of the US Multi-Commodity Flow Network,cs.SI,"['cs.SI', 'cs.AI', 'I.2.4']","[arxiv.Result.Author('Jinmeng Rao'), arxiv.Result.Author('Song Gao'), arxiv.Result.Author('Michelle Miller'), arxiv.Result.Author('Alfonso Morales')]","Quantifying the resilience in the food system is important for food security
issues. In this work, we present a geospatial knowledge graph (GeoKG)-based
method for measuring the resilience of a multi-commodity flow network.
Specifically, we develop a CFS-GeoKG ontology to describe geospatial semantics
of a multi-commodity flow network comprehensively, and design resilience
metrics that measure the node-level and network-level dependence of
single-sourcing, distant, or non-adjacent suppliers/customers in food supply
chains. We conduct a case study of the US state-level agricultural
multi-commodity flow network with hierarchical commodity types. The results
indicate that, by leveraging GeoKG, our method supports measuring both
node-level and network-level resilience across space and over time and also
helps discover concentration patterns of agricultural resources in the spatial
network at different geographic scales."
12691,"Therefore, we hope this
research is not viewed as a conclusion but as an invitation for further research and development
of knowledge-based expert systems that augment design creativity and enhance innovation.","The knowledge-
based expert system architecture is scalable and allows the inclusion of broader non-patent
natural-language data sources as well as machine learning and artificial intelligence capabilities
for computer ideation beyond computer-aided ideation in the future.","REFERENCES
[1] G. Altshuller, The innovation algorithm: TRIZ, systematic innovation and technical creativity,
        Technical innovation center, Inc., 1999.",2022-10-18 19:00:38+00:00,Guiding Data-Driven Design Ideation by Knowledge Distance,cs.SI,"['cs.SI', 'cs.IR']","[arxiv.Result.Author('Jianxi Luo'), arxiv.Result.Author('Serhad Sarica'), arxiv.Result.Author('Kristin Wood')]","Data-driven conceptual design methods and tools aim to inspire human ideation
for new design concepts by providing external inspirational stimuli. In prior
studies, the stimuli have been limited in terms of coverage, granularity, and
retrieval guidance. Here, we present a knowledge based expert system that
provides design stimuli across the semantic, document and field levels
simultaneously from all fields of engineering and technology and that follows
creativity theories to guide the retrieval and use of stimuli according to the
knowledge distance. The system is centered on the use of a network of all
technology fields in the patent classification system, to store and organize
the world's cumulative data on the technological knowledge, concepts, and
solutions in the total patent database according to statistically estimated
knowledge distance between technology fields. In turn, knowledge distance
guides the network-based exploration and retrieval of inspirational stimuli for
inferences across near and far fields to generate new design ideas by analogy
and combination. With two case studies, we showcase the effectiveness of using
the system to explore and retrieve multilevel inspirational stimuli and
generate new design ideas for both problem solving and open ended innovation.
These case studies also demonstrate the computer aided ideation process, which
is data-driven, computationally augmented, theoretically grounded, visually
inspiring, and rapid."
12946,"We then estimate
                                        the retail industry to a more systematic approach to estimate          the causal impact (i.e., change in customer trafﬁc) of the
                                        the anchor store effect and pave the way for further research to       presence of anchor stores (e.g.","Through this work, we point decision-makers in         across Greater London over three years.","Tesco, Sainsbury’s, Waitrose,
                                        discover more complex causal relationships underlying this effect      Lidl) on non-anchor stores located in the Greater London area
                                        with open data.",2022-10-24 20:05:57+00:00,Causal Analysis on the Anchor Store Effect in a Location-based Social Network,cs.SI,['cs.SI'],"[arxiv.Result.Author('Anish K. Vallapuram'), arxiv.Result.Author('Young D. Kwon'), arxiv.Result.Author('Lik-Hang Lee'), arxiv.Result.Author('Fengli Xu'), arxiv.Result.Author('Pan Hui')]","A particular phenomenon of interest in Retail Economics is the spillover
effect of anchor stores (specific stores with a reputable brand) to non-anchor
stores in terms of customer traffic. Prior works in this area rely on small and
survey-based datasets that are often confidential or expensive to collect on a
large scale. Also, very few works study the underlying causal mechanisms
between factors that underpin the spillover effect. In this work, we analyse
the causal relationship between anchor stores and customer traffic to
non-anchor stores and employ a propensity score matching framework to
investigate this effect more efficiently. First of all, to demonstrate the
effect, we leverage open and mobile data from London Datastore and
Location-Based Social Networks (LBSNs) such as Foursquare. We then perform a
large-scale empirical analysis on customer visit patterns from anchor stores to
non-anchor stores(e.g., non-chain restaurants) located in the Greater London
area as a case study. By studying over 600 neighbourhoods in the GreaterLondon
Area, we find that anchor stores cause a 14.2-26.5% increase in customer
traffic for the non-anchor stores reinforcing the established economic theory.
Moreover, we evaluate the efficiency of our methodology by studying the
confounder balance, dose difference and performance of matching framework on
synthetic data. Through this work, we point decision-makers in the retail
industry to a more systematic approach to estimate the anchor store effect and
pave the way for further research to discover more complex causal relationships
underlying this effect with open data."
13193,"It accounts for 0.35 of the overall inaccuracy
ﬁrst draft of a typology of reporting behaviours, which would
beneﬁt from further research using diﬀerent methods, notably         and could be associated to the reporting behaviour 1.
psychometrical analysis and sociological interviews.","Therefore, we suggest that these categories are considered a         porting.","We call it false noise as it probably mainly results from
Splitting the noise to decrease reporting inaccuracy.",2022-10-31 09:21:01+00:00,Listen to what they say: Better understand and detect online misinformation with user feedback,cs.SI,"['cs.SI', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Hubert Etienne'), arxiv.Result.Author('Onur Çelebi')]","Social media users who report content are key allies in the management of
online misinformation, however, no research has been conducted yet to
understand their role and the different trends underlying their reporting
activity. We suggest an original approach to studying misinformation: examining
it from the reporting users perspective at the content-level and comparatively
across regions and platforms. We propose the first classification of reported
content pieces, resulting from a review of c. 9,000 items reported on Facebook
and Instagram in France, the UK, and the US in June 2020. This allows us to
observe meaningful distinctions regarding reporting content between countries
and platforms as it significantly varies in volume, type, topic, and
manipulation technique. Examining six of these techniques, we identify a novel
one that is specific to Instagram US and significantly more sophisticated than
others, potentially presenting a concrete challenge for algorithmic detection
and human moderation. We also identify four reporting behaviours, from which we
derive four types of noise capable of explaining half of the inaccuracy found
in content reported as misinformation. We finally show that breaking down the
user reporting signal into a plurality of behaviours allows to train a simple,
although competitive, classifier on a small dataset with a combination of basic
users-reports to classify the different types of reported content pieces."
13302,We also acknowledge that further research is needed to estimate a more appropriate prior weight.,Future work should aim to clarify this.,"First,
our experiments showed that if we repeat the estimate of αpcorniotrributor with an initial value of 1, then the
new estimate takes ever larger values, mostly because the variance of the scores then goes to 0.",2022-10-30 09:27:16+00:00,Tournesol: Permissionless Collaborative Algorithmic Governance with Security Guarantees,cs.SI,"['cs.SI', 'cs.CR', 'cs.GT']","[arxiv.Result.Author('Romain Beylerian'), arxiv.Result.Author('Bérangère Colbois'), arxiv.Result.Author('Louis Faucon'), arxiv.Result.Author('Lê Nguyên Hoang'), arxiv.Result.Author('Aidan Jungo'), arxiv.Result.Author(""Alain Le Noac'h""), arxiv.Result.Author('Adrien Matissart')]","Recommendation algorithms play an increasingly central role in our societies.
However, thus far, these algorithms are mostly designed and parameterized
unilaterally by private groups or governmental authorities. In this paper, we
present an end-to-end permissionless collaborative algorithmic governance
method with security guarantees. Our proposed method is deployed as part of an
open-source content recommendation platform https://tournesol.app, whose
recommender is collaboratively parameterized by a community of (non-technical)
contributors. This algorithmic governance is achieved through three main steps.
First, the platform contains a mechanism to assign voting rights to the
contributors. Second, the platform uses a comparison-based model to evaluate
the individual preferences of contributors. Third, the platform aggregates the
judgements of all contributors into collective scores for content
recommendations. We stress that the first and third steps are vulnerable to
attacks from malicious contributors. To guarantee the resilience against fake
accounts, the first step combines email authentication, a vouching mechanism, a
novel variant of the reputation-based EigenTrust algorithm and an adaptive
voting rights assignment for alternatives that are scored by too many untrusted
accounts. To provide resilience against malicious authenticated contributors,
we adapt Mehestan, an algorithm previously proposed for robust sparse voting.
We believe that these algorithms provide an appealing foundation for a
collaborative, effective, scalable, fair, contributor-friendly, interpretable
and secure governance. We conclude by highlighting key challenges to make our
solution applicable to larger-scale settings."
13412,"To further study this problem, Tran et al.","Then, they propose a Curriculum Learning Policy for Influence Maximization

(CLAIM) by using curriculum guided Hindsight Experience Replay [55] and goal directed Geometric-
DQN to learn efficient policies, where the influence spread can be improved more 7.51% than existing
methods.","[182] introduce an end-to-end framework, IM-
META, to deal with the IM problem in attributed networks with unknown topology, where they

formulate it as an optimization problem to select both seed set and query set by three steps: network

inference, reinforced weighted graph generation, and query node selection.",2022-11-06 10:13:42+00:00,A Survey on Influence Maximization: From an ML-Based Combinatorial Optimization,cs.SI,"['cs.SI', 'cs.LG']","[arxiv.Result.Author('Yandi Li'), arxiv.Result.Author('Haobo Gao'), arxiv.Result.Author('Yunxuan Gao'), arxiv.Result.Author('Jianxiong Guo'), arxiv.Result.Author('Weili Wu')]","Influence Maximization (IM) is a classical combinatorial optimization
problem, which can be widely used in mobile networks, social computing, and
recommendation systems. It aims at selecting a small number of users such that
maximizing the influence spread across the online social network. Because of
its potential commercial and academic value, there are a lot of researchers
focusing on studying the IM problem from different perspectives. The main
challenge comes from the NP-hardness of the IM problem and \#P-hardness of
estimating the influence spread, thus traditional algorithms for overcoming
them can be categorized into two classes: heuristic algorithms and
approximation algorithms. However, there is no theoretical guarantee for
heuristic algorithms, and the theoretical design is close to the limit.
Therefore, it is almost impossible to further optimize and improve their
performance. With the rapid development of artificial intelligence, the
technology based on Machine Learning (ML) has achieved remarkable achievements
in many fields. In view of this, in recent years, a number of new methods have
emerged to solve combinatorial optimization problems by using ML-based
techniques. These methods have the advantages of fast solving speed and strong
generalization ability to unknown graphs, which provide a brand-new direction
for solving combinatorial optimization problems. Therefore, we abandon the
traditional algorithms based on iterative search and review the recent
development of ML-based methods, especially Deep Reinforcement Learning, to
solve the IM problem and other variants in social networks. We focus on
summarizing the relevant background knowledge, basic principles, common
methods, and applied research. Finally, the challenges that need to be solved
urgently in future IM research are pointed out."
13492,"Here,
it may be likely that counter-measures from fake news mitigation can be adapted [50, 51]; yet this
requires further research to establish the effectiveness of such interventions.","Second, our results suggest that an ef-
fective counter-measure to curb the spread of propaganda is to reduce the inﬂuence of bots.","Third, propaganda
on social media may inﬂuence public opinion and increase political division.",2022-11-08 10:52:15+00:00,Russian propaganda on social media during the 2022 invasion of Ukraine,cs.SI,['cs.SI'],"[arxiv.Result.Author('Dominique Geissler'), arxiv.Result.Author('Dominik Bär'), arxiv.Result.Author('Nicolas Pröllochs'), arxiv.Result.Author('Stefan Feuerriegel')]","The Russian invasion of Ukraine in February 2022 was accompanied by a
large-scale propaganda campaign. Here, we analyze the spread of Russian
propaganda on social media. For this, we collected N = 349,455 messages from
Twitter with pro-Russian content. Our findings suggest that pro-Russian
messages were mainly disseminated through a systematic, coordinated propaganda
campaign. Overall, pro-Russian content received ~251,000 retweets and thereby
reached around 14.4 million users, primarily in countries such as India, South
Africa, and the United States. We further provide evidence that bots played a
disproportionate role in the dissemination of propaganda and amplified its
proliferation. Overall, 20.28% of the spreaders are classified as bots, most of
which were created in the beginning of the invasion. Together, our results
highlight the new threats to society that originate from coordinated propaganda
campaigns on social media in modern warfare. Our results also suggest that
curbing bots may be an effective strategy to mitigate such campaigns."
13573,"Besides, it is also essential to study fairness, safety, robustness, privacy, and account-
ability in health misinformation detection, which needs further research in the future.","Although these works already conduct some studies on the explainability property
of health misinformation detection, it is still under exploration on combing misinformation con-
tents, user engagements, social structures, and external knowledge to generate convincing model
explanations.","Lastly, there
start to be some research on the intersection of diﬀerent trustworthy properties in machine learn-
ing [39, 114, 124, 227], it is worth studying on building health misinformation detectors that satisfy
multiple trustworthy properties simultaneously.",2022-11-10 01:52:12+00:00,"Combating Health Misinformation in Social Media: Characterization, Detection, Intervention, and Open Issues",cs.SI,"['cs.SI', 'cs.AI', 'cs.CY']","[arxiv.Result.Author('Canyu Chen'), arxiv.Result.Author('Haoran Wang'), arxiv.Result.Author('Matthew Shapiro'), arxiv.Result.Author('Yunyu Xiao'), arxiv.Result.Author('Fei Wang'), arxiv.Result.Author('Kai Shu')]","Social media has been one of the main information consumption sources for the
public, allowing people to seek and spread information more quickly and easily.
However, the rise of various social media platforms also enables the
proliferation of online misinformation. In particular, misinformation in the
health domain has significant impacts on our society such as the COVID-19
infodemic. Therefore, health misinformation in social media has become an
emerging research direction that attracts increasing attention from researchers
of different disciplines. Compared to misinformation in other domains, the key
differences of health misinformation include the potential of causing actual
harm to humans' bodies and even lives, the hardness to identify for normal
people, and the deep connection with medical science. In addition, health
misinformation on social media has distinct characteristics from conventional
channels such as television on multiple dimensions including the generation,
dissemination, and consumption paradigms. Because of the uniqueness and
importance of combating health misinformation in social media, we conduct this
survey to further facilitate interdisciplinary research on this problem. In
this survey, we present a comprehensive review of existing research about
online health misinformation in different disciplines. Furthermore, we also
systematically organize the related literature from three perspectives:
characterization, detection, and intervention. Lastly, we conduct a deep
discussion on the pressing open issues of combating health misinformation in
social media and provide future directions for multidisciplinary researchers."
13628,"This work also presents the ﬁrst study on
links in self-description  -0.26  *** 0.02                         such accounts, and this characterization of accounts can be a
links on web               -0.14  *** 0.02                         basis for further research.","This aligns with the greater use of second-person pronouns
Intercept                  1.04   *** 0.02                         from therapist [9].","2Log-likelihood
                                       -281920                     Professional Identity of Accounts.",2022-11-11 05:34:37+00:00,Exploring Mental Health Communications among Instagram Coaches,cs.SI,"['cs.SI', 'cs.HC']","[arxiv.Result.Author('Ehsan-Ul Haq'), arxiv.Result.Author('Lik-Hang Lee'), arxiv.Result.Author('Gareth Tyson'), arxiv.Result.Author('Reza Hadi Mogavi'), arxiv.Result.Author('Tristan Braud'), arxiv.Result.Author('Pan Hui')]","There has been a significant expansion in the use of online social networks
(OSNs) to support people experiencing mental health issues. This paper studies
the role of Instagram influencers who specialize in coaching people with mental
health issues. Using a dataset of 97k posts, we characterize such users'
linguistic and behavioural features. We explore how these observations impact
audience engagement (as measured by likes). We show that the support provided
by these accounts varies based on their self-declared professional identities.
For instance, Instagram accounts that declare themselves as Authors offer less
support than accounts that label themselves as Coach. We show that increasing
information support in general communication positively affects user
engagement. However, the effect of vocabulary on engagement is not consistent
across the Instagram account types. Our findings shed light on this
understudied topic and guide how mental health practitioners can improve
outreach."
13819,"Causal effects of buy nothing group activity on community health and social capital
would be an interesting topic of further study.","In doing so, the buy nothing movement is likely also creating new social capital, through
the growth of trust in one’s neighbors, the new connections formed, and the many lending libraries and item “trains”
that are now community resources.","Finally, when we look at other Facebook groups that are similar to buy nothing groups along the dimensions of
interaction graph features and other group characteristics, we ﬁnd groups that contain the terms indicating other
pay-it-forward style local gifting communities.",2022-11-16 16:58:41+00:00,Community gifting groups on Facebook,cs.SI,"['cs.SI', 'cs.CY']","[arxiv.Result.Author('Amaç Herdağdelen'), arxiv.Result.Author('Lada Adamic'), arxiv.Result.Author('Bogdan State')]","We use de-identified data from Facebook Groups to study and provide a
descriptive analysis of local gift-giving communities, in particular buy
nothing (BN) groups. These communities allow people to give items they no
longer need, reduce waste, and connect to local community. Millions of people
have joined BN groups on Facebook, with an increasing pace through the COVID-19
pandemic. BN groups are more popular in dense and urban US counties with higher
educational attainment. Compared to other local groups, BN groups have lower
Facebook friendship densities, suggesting they bring together people who are
not already connected. The interaction graphs in BN groups form larger strongly
connected components, indicative of norms of generalized reciprocity. The
interaction patterns in BN groups are similar to other local online gift-giving
groups, with names containing terms such as `free stuff"" and `pay it forward"".
This points to an interaction signature for local online gift-giving
communities."
14126,"We further study the two
How well does our approach work in practice?","SHyRe-
6 EXPERIMENT                                                                                                                      motif very marginally wins if we count the number of datasets on
                                                                                                                                  which one variant achieves the best score.","How do we make                                                                       variants and found that they both capture a strong feature (more in
sense of the reconstruction result?",2022-11-23 23:15:03+00:00,Supervised Hypergraph Reconstruction,cs.SI,"['cs.SI', 'cs.AI', 'cs.DM', 'cs.IR', 'cs.LG']","[arxiv.Result.Author('Yanbang Wang'), arxiv.Result.Author('Jon Kleinberg')]","We study an issue commonly seen with graph data analysis: many real-world
complex systems involving high-order interactions are best encoded by
hypergraphs; however, their datasets often end up being published or studied
only in the form of their projections (with dyadic edges). To understand this
issue, we first establish a theoretical framework to characterize this issue's
implications and worst-case scenarios. The analysis motivates our formulation
of the new task, supervised hypergraph reconstruction: reconstructing a
real-world hypergraph from its projected graph, with the help of some existing
knowledge of the application domain.
  To reconstruct hypergraph data, we start by analyzing hyperedge distributions
in the projection, based on which we create a framework containing two modules:
(1) to handle the enormous search space of potential hyperedges, we design a
sampling strategy with efficacy guarantees that significantly narrows the space
to a smaller set of candidates; (2) to identify hyperedges from the candidates,
we further design a hyperedge classifier in two well-working variants that
capture structural features in the projection. Extensive experiments validate
our claims, approach, and extensions. Remarkably, our approach outperforms all
baselines by an order of magnitude in accuracy on hard datasets. Our code and
data can be downloaded from bit.ly/SHyRe."
14426,"Online misogyny has ofﬂine
effects that requires investigation and further research.","In contrast,
Herring and Martinson (2004) examined gender differences in communication styles and feminist responses to ‘trolling’
and found that the ‘gender nature’ of online abuse messages and hate speech is paramount.","Citron and Norton (2011) hypothesize that the gendered nature
of online harassment and digital abuse is an important facet of women’s overall ‘digital citizenship’.",2022-12-01 13:07:49+00:00,Identifying Different Layers of Online Misogyny,cs.SI,['cs.SI'],"[arxiv.Result.Author('Wienke Strathern'), arxiv.Result.Author('Juergen Pfeffer')]","Social media has become an everyday means of interaction and information
sharing on the Internet. However, posts on social networks are often aggressive
and toxic, especially when the topic is controversial or politically charged.
Radicalization, extreme speech, and in particular online misogyny against women
in the public eye have become alarmingly negative features of online
discussions. The present study proposes a methodological approach to contribute
to ongoing discussions about the multiple ways in which women, their
experiences, and their choices are attacked in polarized social media
responses. Based on a review of theories on and detection methods for misogyny,
we present a classification scheme that incorporates eleven different explicit
as well as implicit layers of online misogyny. We also apply our classes to a
case study related to online aggression against Amber Heard in the context of
her allegations of domestic violence against Johnny Depp. We finally evaluate
the reliability of Google's Perspective API -- a standard for detecting toxic
language -- for determining gender discrimination as toxicity. We show that a
large part of online misogyny, especially when verbalized without expletive
terms but instead more implicitly is not captured automatically."
14820,"City area features       of researches addressing the use of data derived from mobile
related to social activities like places of common interests,        phone networks to obtain location and trafﬁc estimations of
densely populated areas, residential areas, commercial areas,        individuals as a starting point for further research on trafﬁc
etc.","from the CDR col-       proach, their previous work provided a well-organized outline
lected from a densely populated urban area.","are investigated, and the status of social activities in these  management [15].",2022-12-11 01:39:52+00:00,A Hierarchical Approach for Investigating Social Features of a City from Mobile Phone Call Detail Records,cs.SI,['cs.SI'],"[arxiv.Result.Author('Fahim Hasan Khan'), arxiv.Result.Author('Mohammed Eunus Ali')]","Cellphone service-providers continuously collect Call Detail Records (CDR) as
a usage log containing spatio-temporal traces of phone users. We proposed a
multi-layered hierarchical analytical model for large spatio-temporal datasets
and applied that for the progressive exploration of social features of a city,
e.g., social activities, relationships, and groups, from CDR. This approach
utilizes CDR as the preliminary input for the initial layer, and analytical
results from consecutive layers are added to the knowledge-base to be used in
the subsequent layers to explore more detailed social features. Each subsequent
layer uses the results from previous layers, facilitating the discovery of more
in-depth social features not predictable in a single-layered approach using
only raw CDR. This model starts with exploring aggregated overviews of the
social features and gradually focuses on comprehensive details of social
relationships and groups, which facilitates a novel approach for investigating
CDR datasets for the progressive exploration of social features in a
densely-populated city."
14916,"We further study the tem-
Europe, especially refugees in Germany.","The detailed clusters in Refugees in EU in Figure 6c                                                         tify hateful variants in a directed manner by pre-selecting the
imply that people show negative attitudes towards refugees in                                                         textual inﬂuencers in Section 5.2.","In addition, Mus-                                                             poral dynamics of identiﬁed variants of Happy Merchant in
lims, Chinese, and Australians are often the hate targets for                                                         Section 5.2.",2022-12-13 13:38:04+00:00,On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning,cs.SI,"['cs.SI', 'cs.CR', 'cs.CY', 'cs.LG']","[arxiv.Result.Author('Yiting Qu'), arxiv.Result.Author('Xinlei He'), arxiv.Result.Author('Shannon Pierson'), arxiv.Result.Author('Michael Backes'), arxiv.Result.Author('Yang Zhang'), arxiv.Result.Author('Savvas Zannettou')]","The dissemination of hateful memes online has adverse effects on social media
platforms and the real world. Detecting hateful memes is challenging, one of
the reasons being the evolutionary nature of memes; new hateful memes can
emerge by fusing hateful connotations with other cultural ideas or symbols. In
this paper, we propose a framework that leverages multimodal contrastive
learning models, in particular OpenAI's CLIP, to identify targets of hateful
content and systematically investigate the evolution of hateful memes. We find
that semantic regularities exist in CLIP-generated embeddings that describe
semantic relationships within the same modality (images) or across modalities
(images and text). Leveraging this property, we study how hateful memes are
created by combining visual elements from multiple images or fusing textual
information with a hateful image. We demonstrate the capabilities of our
framework for analyzing the evolution of hateful memes by focusing on
antisemitic memes, particularly the Happy Merchant meme. Using our framework on
a dataset extracted from 4chan, we find 3.3K variants of the Happy Merchant
meme, with some linked to specific countries, persons, or organizations. We
envision that our framework can be used to aid human moderators by flagging new
variants of hateful memes so that moderators can manually verify them and
mitigate the problem of hateful content online."
14923,"We leave to further research the possibility of characterizing
in more details the approaches and techniques that are typically in use in each of the
research streams that we identiﬁed, and the related semantic shifts on “EKC”.","In a way,
the evolution that we observed on ﬁgure 2 may also be framed as modest: in a nutshell,
it remains a quantitative conﬁrmation that there is still an active debate between posi-
tive and negative claims around phenomena that are said, by authors, to be connected
to the concept of “EKC”.","5 Conclusion

Our analysis of the ﬁeld structured around the use of “environmental Kuznets curve”
combines two very recent computational methods in an integrated fashion: semantic

                                                  20
and network analyses.",2022-12-13 15:58:24+00:00,The two sides of the Environmental Kuznets Curve: a socio-semantic analysis,cs.SI,"['cs.SI', '91C99', 'J.4; I.2.7']","[arxiv.Result.Author('Telmo Menezes'), arxiv.Result.Author('Antonin Pottier'), arxiv.Result.Author('Camille Roth')]","Since the 1990s, the Environmental Kuznets Curve (EKC) hypothesis posits an
inverted U-shaped relationship between pollutants and economic development. The
hypothesis has attracted a lot of research. We do here a review of more than
2000 papers that have been published on the EKC. To that end, we combine
traditional bibliometric analysis and semantic analysis with a novel method,
that enables us to recover the type of pollutants that are studied as well as
the empirical claims made on EKC (whether the hypothesis is invalidated or
not). We principally exhibit the existence of a few epistemic communities that
are related to distinct time periods, topics and, to some extent, proportion of
positive results on EKC."
14958,"The
                                                                                              semantic path in our scenario is presented in the mode of:
   3) Sensitivity of Hyper-parameters (RQ3): We further study
the impact of learning rate lr, and β in loss function on                                        • v4 −b−e−lo−n−g−t→o c2 −b−e−lo−n−g−t→o v2
the model performance.","In our study, P1 and P2 are set to 100 and 1, respectively.","Due to space limitation, we take                                          User study for verifying the quality of explanations.",2022-12-14 04:51:57+00:00,A Generic Reinforced Explainable Framework with Knowledge Graph for Session-based Recommendation,cs.SI,['cs.SI'],"[arxiv.Result.Author('Huizi Wu'), arxiv.Result.Author('Hui Fang'), arxiv.Result.Author('Zhu Sun'), arxiv.Result.Author('Cong Geng'), arxiv.Result.Author('Xinyu Kong'), arxiv.Result.Author('Yew-Soon Ong')]","Session-based recommendation (SR) has gained increasing attention in recent
years. Quite a great amount of studies have been devoted to designing complex
algorithms to improve recommendation performance, where deep learning methods
account for the majority. However, most of these methods are black-box ones and
ignore to provide moderate explanations to facilitate users' understanding,
which thus might lead to lowered user satisfaction and reduced system revenues.
Therefore, in our study, we propose a generic Reinforced Explainable framework
with Knowledge graph for Session-based recommendation (i.e., REKS), which
strives to improve the existing black-box SR models (denoted as non-explainable
ones) with Markov decision process. In particular, we construct a knowledge
graph with session behaviors and treat SR models as part of the policy network
of Markov decision process. Based on our particularly designed state vector,
reward strategy, and loss function, the reinforcement learning (RL)-based
framework not only achieves improved recommendation accuracy, but also provides
appropriate explanations at the same time. Finally, we instantiate the REKS in
five representative, state-of-the-art SR models (i.e., GRU4REC, NARM, SR-GNN,
GCSAN, BERT4REC), whereby extensive experiments towards these methods on four
datasets demonstrate the effectiveness of our framework on both recommendation
and explanation tasks."
14959,"The
                                                                                              semantic path in our scenario is presented in the mode of:
   3) Sensitivity of Hyper-parameters (RQ3): We further study
the impact of learning rate lr, and β in loss function on                                        • v4 −b−e−lo−n−g−t→o c2 −b−e−lo−n−g−t→o v2
the model performance.","In our study, P1 and P2 are set to 100 and 1, respectively.","Due to space limitation, we take                                          User study for verifying the quality of explanations.",2022-12-14 04:51:57+00:00,A Generic Reinforced Explainable Framework with Knowledge Graph for Session-based Recommendation,cs.SI,['cs.SI'],"[arxiv.Result.Author('Huizi Wu'), arxiv.Result.Author('Hui Fang'), arxiv.Result.Author('Zhu Sun'), arxiv.Result.Author('Cong Geng'), arxiv.Result.Author('Xinyu Kong'), arxiv.Result.Author('Yew-Soon Ong')]","Session-based recommendation (SR) has gained increasing attention in recent
years. Quite a great amount of studies have been devoted to designing complex
algorithms to improve recommendation performance, where deep learning methods
account for the majority. However, most of these methods are black-box ones and
ignore to provide moderate explanations to facilitate users' understanding,
which thus might lead to lowered user satisfaction and reduced system revenues.
Therefore, in our study, we propose a generic Reinforced Explainable framework
with Knowledge graph for Session-based recommendation (i.e., REKS), which
strives to improve the existing black-box SR models (denoted as non-explainable
ones) with Markov decision process. In particular, we construct a knowledge
graph with session behaviors and treat SR models as part of the policy network
of Markov decision process. Based on our particularly designed state vector,
reward strategy, and loss function, the reinforcement learning (RL)-based
framework not only achieves improved recommendation accuracy, but also provides
appropriate explanations at the same time. Finally, we instantiate the REKS in
five representative, state-of-the-art SR models (i.e., GRU4REC, NARM, SR-GNN,
GCSAN, BERT4REC), whereby extensive experiments towards these methods on four
datasets demonstrate the effectiveness of our framework on both recommendation
and explanation tasks."
15354,"With further research, we can possibly provide a
factorable relationship between structure and sentiment.","(2007) where perpetually dynamic perspectives and event
segmentation cause diverse opinions on one event.","With this, we can analyze at-risk communities
and warn them of polarization, develop tools to protect electoral processes, and provide effective
technological moderation when needed.",2022-12-25 20:48:40+00:00,"Search, Structure, and Sentiment: A Comparative Analysis of Network Opinion in Different Query Types on Twitter",cs.SI,"['cs.SI', 'cs.CL', 'cs.CY']",[arxiv.Result.Author('Joshua Midha')],"Understanding the relationship between structure and sentiment is essential
in highlighting future operations with online social networks. More
specifically, within popular conversation on Twitter. This paper provides a
development on the relationship between the two variables: structure, defined
as the composition of a directed network, and sentiment, a quantified value of
the positive/negative connotations of a conversation. We highlight thread
sentiment to be inversely proportional to the strength and connectivity of a
network. The second portion of this paper highlights differences in query
types, specifically how the aforementioned behavior differs within four key
query types. This paper focuses on topical, event-based, geographic, and
individual queries as orientations which have differing behavior. Using
cross-query analysis, we see that the relationship between structure and
sentiment, though still inversely proportional, differs greatly across query
types. We find this relationship to be the most clear within the individual
queries and the least prevalent within the event-based queries. This paper
provides a sociological progression in our understanding of opinion and
networks, while providing a methodological advancement for future studies on
similar subjects."
15369,"16
ences, that would thus require a further study across diﬀerent        information was assigned by the users themselves via their
societal levels and at various scales.",The currency unit of the per capita disposable income was CNY.,tagging behavior.,2022-12-26 12:50:56+00:00,Universality of preference behaviors in online music-listener bipartite networks: A Big Data analysis,cs.SI,"['cs.SI', 'cs.CY', 'physics.soc-ph']","[arxiv.Result.Author('Xiao-Pu Han'), arxiv.Result.Author('Fen Lin'), arxiv.Result.Author('Jonathan J. H. Zhu'), arxiv.Result.Author('Tarik Hadzibeganovic')]","We investigate the formation of musical preferences of millions of users of
the NetEase Cloud Music (NCM), one of the largest online music platforms in
China. We combine the methods from complex networks theory and information
sciences within the context of Big Data analysis to unveil statistical patterns
and community structures underlying the formation and evolution of musical
preference behaviors. Our analyses address the decay patterns of music
influence, users' sensitivity to music, age and gender differences, and their
relationship to regional economic indicators. Employing community detection in
user-music bipartite networks, we identified eight major cultural communities
in the population of NCM users. Female users exhibited higher within-group
variability in preference behavior than males, with a major transition
occurring around the age of 25. Moreveor, the musical tastes and the preference
diversity measures of women were also more strongly associated with economic
factors. However, in spite of the highly variable popularity of music tracks
and the identified cultural and demographic differences, we observed that the
evolution of musical preferences over time followed a power-law-like decaying
function, and that NCM listeners showed the highest sensitivity to music
released in their adolescence, peaking at the age of 13. Our findings suggest
the existence of universal properties in the formation of musical tastes but
also their culture-specific relationship to demographic factors, with
wide-ranging implications for community detection and recommendation system
design in online music platforms."
